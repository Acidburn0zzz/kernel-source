From: Linux Kernel Mailing List <linux-kernel@vger.kernel.org>
Subject: Linux: 2.6.37-rc4
Patch-mainline: 2.6.37-rc4

 This patch contains the differences between 2.6.37-rc3 and -rc4.

Acked-by: Jeff Mahoney <jeffm@suse.com>
Automatically created from "patches.kernel.org/patch-2.6.37-rc3-rc4" by xen-port-patches.py

--- head-2010-12-06.orig/arch/x86/include/mach-xen/asm/fixmap.h	2010-11-22 14:19:40.000000000 +0100
+++ head-2010-12-06/arch/x86/include/mach-xen/asm/fixmap.h	2010-12-06 14:31:14.000000000 +0100
@@ -219,8 +219,8 @@ static inline unsigned long virt_to_fix(
 }
 
 /* Return an pointer with offset calculated */
-static inline unsigned long __set_fixmap_offset(enum fixed_addresses idx,
-				phys_addr_t phys, pgprot_t flags)
+static __always_inline unsigned long
+__set_fixmap_offset(enum fixed_addresses idx, phys_addr_t phys, pgprot_t flags)
 {
 	__set_fixmap(idx, phys, flags);
 	return fix_to_virt(idx) + (phys & (PAGE_SIZE - 1));
--- head-2010-12-06.orig/arch/x86/kernel/entry_32-xen.S	2010-11-23 16:11:19.000000000 +0100
+++ head-2010-12-06/arch/x86/kernel/entry_32-xen.S	2010-12-06 14:31:14.000000000 +0100
@@ -399,7 +399,7 @@ sysenter_past_esp:
 	 * A tiny bit of offset fixup is necessary - 4*4 means the 4 words
 	 * pushed above; +8 corresponds to copy_thread's esp0 setting.
 	 */
-	pushl_cfi (TI_sysenter_return-THREAD_SIZE_asm+8+4*4)(%esp)
+	pushl_cfi ((TI_sysenter_return)-THREAD_SIZE_asm+8+4*4)(%esp)
 	CFI_REL_OFFSET eip, 0
 
 	pushl_cfi %eax
--- head-2010-12-06.orig/arch/x86/kernel/entry_64-xen.S	2010-11-23 16:11:19.000000000 +0100
+++ head-2010-12-06/arch/x86/kernel/entry_64-xen.S	2010-12-06 14:31:14.000000000 +0100
@@ -327,6 +327,7 @@ NMI_MASK = 0x80000000
 
 #ifndef CONFIG_XEN
 /* save partial stack frame */
+	.pushsection .kprobes.text, "ax"
 ENTRY(save_args)
 	XCPT_FRAME
 	cld
@@ -366,6 +367,7 @@ ENTRY(save_args)
 	ret
 	CFI_ENDPROC
 END(save_args)
+	.popsection
 #endif
 
 ENTRY(save_rest)
--- head-2010-12-06.orig/drivers/xen/Makefile	2010-11-23 12:14:00.000000000 +0100
+++ head-2010-12-06/drivers/xen/Makefile	2010-12-06 14:31:14.000000000 +0100
@@ -2,6 +2,7 @@ obj-$(CONFIG_PARAVIRT_XEN)	+= grant-tabl
 xen-biomerge-$(CONFIG_PARAVIRT_XEN) := biomerge.o
 xen-hotplug-$(CONFIG_PARAVIRT_XEN) := cpu_hotplug.o
 xen-balloon-$(CONFIG_PARAVIRT_XEN) := balloon.o
+xen-evtchn-name-$(CONFIG_PARAVIRT_XEN) := xen-evtchn
 
 xen-balloon-$(CONFIG_XEN)	:= balloon/
 obj-$(CONFIG_XEN)		+= core/
@@ -10,6 +11,7 @@ obj-y				+= xenbus/
 obj-$(CONFIG_XEN)		+= char/
 
 xen-backend-$(CONFIG_XEN_BACKEND)	:= util.o
+xen-evtchn-name-$(CONFIG_XEN)		:= evtchn
 
 nostackp := $(call cc-option, -fno-stack-protector)
 ifeq ($(CONFIG_PARAVIRT_XEN),y)
@@ -21,12 +23,15 @@ obj-$(CONFIG_BLOCK)			+= $(xen-biomerge-
 obj-$(CONFIG_HOTPLUG_CPU)		+= $(xen-hotplug-y)
 obj-$(CONFIG_XEN_XENCOMM)		+= xencomm.o
 obj-$(CONFIG_XEN_BALLOON)		+= $(xen-balloon-y)
-obj-$(CONFIG_XEN_DEV_EVTCHN)		+= evtchn.o
+obj-$(CONFIG_XEN_DEV_EVTCHN)		+= $(xen-evtchn-name-y).o
 obj-$(CONFIG_XENFS)			+= xenfs/
 obj-$(CONFIG_XEN_SYS_HYPERVISOR)	+= sys-hypervisor.o
 obj-$(CONFIG_XEN_PLATFORM_PCI)		+= platform-pci.o
 obj-$(CONFIG_SWIOTLB_XEN)		+= swiotlb-xen.o
 obj-$(CONFIG_XEN_DOM0)			+= pci.o
+
+xen-evtchn-y				:= evtchn.o
+
 obj-$(CONFIG_XEN_BLKDEV_BACKEND)	+= blkback/
 obj-$(CONFIG_XEN_BLKDEV_TAP)		+= blktap/
 obj-$(CONFIG_XEN_BLKDEV_TAP2)           += blktap2/
--- head-2010-12-06.orig/drivers/xen/blkfront/blkfront.c	2010-11-24 11:36:24.000000000 +0100
+++ head-2010-12-06/drivers/xen/blkfront/blkfront.c	2010-12-06 14:49:02.000000000 +0100
@@ -374,16 +374,10 @@ static void connect(struct blkfront_info
 	 * If there are barriers, then we use flush.
 	 */
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,37)
-	info->feature_flush = 0;
-
-	/*
-	 * The driver doesn't properly handled empty flushes, so
-	 * lets disable barrier support for now.
-	 */
-#if 0
 	if (!err && barrier)
-		info->feature_flush = REQ_FLUSH;
-#endif
+		info->feature_flush = REQ_FLUSH | REQ_FUA;
+	else
+		info->feature_flush = 0;
 #else
 	if (err)
 		info->feature_flush = QUEUE_ORDERED_DRAIN;
@@ -486,7 +480,7 @@ static inline void ADD_ID_TO_FREELIST(
 	struct blkfront_info *info, unsigned long id)
 {
 	info->shadow[id].req.id  = info->shadow_free;
-	info->shadow[id].request = 0;
+	info->shadow[id].request = NULL;
 	info->shadow_free = id;
 }
 
@@ -667,14 +661,11 @@ int blkif_getgeo(struct block_device *bd
 
 
 /*
- * blkif_queue_request
- *
- * request block io
+ * Generate a Xen blkfront IO request from a blk layer request.  Reads
+ * and writes are handled as expected.  Since we lack a loose flush
+ * request, we map flushes into a full ordered barrier.
  *
- * id: for guest use only.
- * operation: BLKIF_OP_{READ,WRITE,PROBE}
- * buffer: buffer to read/write into. this should be a
- *   virtual address in the guest os.
+ * @req: a request struct
  */
 static int blkif_queue_request(struct request *req)
 {
@@ -703,7 +694,7 @@ static int blkif_queue_request(struct re
 	/* Fill out a communications ring structure. */
 	ring_req = RING_GET_REQUEST(&info->ring, info->ring.req_prod_pvt);
 	id = GET_ID_FROM_FREELIST(info);
-	info->shadow[id].request = (unsigned long)req;
+	info->shadow[id].request = req;
 
 	ring_req->id = id;
 	ring_req->sector_number = (blkif_sector_t)blk_rq_pos(req);
@@ -711,7 +702,11 @@ static int blkif_queue_request(struct re
 
 	ring_req->operation = rq_data_dir(req) ?
 		BLKIF_OP_WRITE : BLKIF_OP_READ;
-	if (req->cmd_flags & (REQ_FLUSH|REQ_FUA))
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,37)
+	if (req->cmd_flags & (REQ_FLUSH | REQ_FUA))
+#else
+	if (req->cmd_flags & REQ_HARDBARRIER)
+#endif
 		ring_req->operation = BLKIF_OP_WRITE_BARRIER;
 
 	ring_req->nr_segments = blk_rq_map_sg(req->q, req, info->sg);
@@ -822,7 +817,7 @@ static irqreturn_t blkif_int(int irq, vo
 
 		bret = RING_GET_RESPONSE(&info->ring, i);
 		id   = bret->id;
-		req  = (struct request *)info->shadow[id].request;
+		req  = info->shadow[id].request;
 
 		blkif_completion(&info->shadow[id]);
 
@@ -836,6 +831,17 @@ static irqreturn_t blkif_int(int irq, vo
 					   " write barrier op failed\n",
 					   info->gd->disk_name);
 				ret = -EOPNOTSUPP;
+			}
+			if (unlikely(bret->status == BLKIF_RSP_ERROR &&
+				     info->shadow[id].req.nr_segments == 0)) {
+				pr_warning("blkfront: %s:"
+					   " empty write barrier op failed\n",
+					   info->gd->disk_name);
+				ret = -EOPNOTSUPP;
+			}
+			if (unlikely(ret)) {
+				if (ret == -EOPNOTSUPP)
+					ret = 0;
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,37)
 				info->feature_flush = 0;
 #else
@@ -932,7 +938,7 @@ static int blkif_recover(struct blkfront
 	/* Stage 3: Find pending requests and requeue them. */
 	for (i = 0; i < BLK_RING_SIZE; i++) {
 		/* Not in use? */
-		if (copy[i].request == 0)
+		if (!copy[i].request)
 			continue;
 
 		/* Grab a request slot and copy shadow state into it. */
@@ -950,8 +956,7 @@ static int blkif_recover(struct blkfront
 				req->seg[j].gref,
 				info->xbdev->otherend_id,
 				pfn_to_mfn(info->shadow[req->id].frame[j]),
-				rq_data_dir((struct request *)
-					    info->shadow[req->id].request) ?
+				rq_data_dir(info->shadow[req->id].request) ?
 				GTF_readonly : 0);
 		info->shadow[req->id].req = *req;
 
--- head-2010-12-06.orig/drivers/xen/blkfront/block.h	2010-11-23 16:11:19.000000000 +0100
+++ head-2010-12-06/drivers/xen/blkfront/block.h	2010-12-06 14:37:35.000000000 +0100
@@ -83,7 +83,7 @@ struct xlbd_major_info
 
 struct blk_shadow {
 	blkif_request_t req;
-	unsigned long request;
+	struct request *request;
 	unsigned long frame[BLKIF_MAX_SEGMENTS_PER_REQUEST];
 };
 
--- head-2010-12-06.orig/drivers/xen/core/evtchn.c	2010-12-06 14:26:39.000000000 +0100
+++ head-2010-12-06/drivers/xen/core/evtchn.c	2010-12-06 14:31:14.000000000 +0100
@@ -120,28 +120,49 @@ static inline u32 mk_irq_info(u32 type, 
  * Accessors for packed IRQ information.
  */
 
-static inline unsigned int evtchn_from_irq(int irq)
+static inline unsigned int evtchn_from_irq_data(struct irq_data *data)
 {
-	const struct irq_cfg *cfg = irq_cfg(irq);
+	const struct irq_cfg *cfg = irq_data_cfg(data);
 
 	return cfg ? cfg->info & ((1U << _EVTCHN_BITS) - 1) : 0;
 }
 
-static inline unsigned int index_from_irq(int irq)
+static inline unsigned int evtchn_from_irq(int irq)
 {
-	const struct irq_cfg *cfg = irq_cfg(irq);
+	struct irq_data *data = irq_get_irq_data(irq);
+
+	return data ? evtchn_from_irq_data(data) : 0;
+}
+
+static inline unsigned int index_from_irq_data(struct irq_data *data)
+{
+	const struct irq_cfg *cfg = irq_data_cfg(data);
 
 	return cfg ? (cfg->info >> _EVTCHN_BITS) & ((1U << _INDEX_BITS) - 1)
 		   : 0;
 }
 
-static inline unsigned int type_from_irq(int irq)
+static inline unsigned int index_from_irq(int irq)
 {
-	const struct irq_cfg *cfg = irq_cfg(irq);
+	struct irq_data *data = irq_get_irq_data(irq);
+
+	return data ? index_from_irq_data(data) : 0;
+}
+
+static inline unsigned int type_from_irq_data(struct irq_data *data)
+{
+	const struct irq_cfg *cfg = irq_data_cfg(data);
 
 	return cfg ? cfg->info >> (32 - _IRQT_BITS) : IRQT_UNBOUND;
 }
 
+static inline unsigned int type_from_irq(int irq)
+{
+	struct irq_data *data = irq_get_irq_data(irq);
+
+	return data ? type_from_irq_data(data) : IRQT_UNBOUND;
+}
+
 unsigned int irq_from_evtchn(unsigned int port)
 {
 	return evtchn_to_irq[port];
@@ -384,7 +405,7 @@ asmlinkage void __irq_entry evtchn_do_up
 
 static struct irq_chip dynirq_chip;
 
-static int find_unbound_irq(unsigned int node)
+static int find_unbound_irq(unsigned int node, struct irq_cfg **pcfg)
 {
 	static int warned;
 	int irq;
@@ -400,6 +421,7 @@ static int find_unbound_irq(unsigned int
 			continue;
 
 		if (!cfg->bindcount) {
+			*pcfg = cfg;
 			desc->status |= IRQ_NOPROBE;
 			set_irq_chip_and_handler_name(irq, &dynirq_chip,
 						      handle_fasteoi_irq,
@@ -419,20 +441,21 @@ static int find_unbound_irq(unsigned int
 
 static int bind_caller_port_to_irq(unsigned int caller_port)
 {
+	struct irq_cfg *cfg;
 	int irq;
 
 	spin_lock(&irq_mapping_update_lock);
 
 	if ((irq = evtchn_to_irq[caller_port]) == -1) {
-		if ((irq = find_unbound_irq(numa_node_id())) < 0)
+		if ((irq = find_unbound_irq(numa_node_id(), &cfg)) < 0)
 			goto out;
 
 		evtchn_to_irq[caller_port] = irq;
-		irq_cfg(irq)->info = mk_irq_info(IRQT_CALLER_PORT,
-						  0, caller_port);
-	}
+		cfg->info = mk_irq_info(IRQT_CALLER_PORT, 0, caller_port);
+	} else
+		cfg = irq_cfg(irq);
 
-	irq_cfg(irq)->bindcount++;
+	cfg->bindcount++;
 
  out:
 	spin_unlock(&irq_mapping_update_lock);
@@ -441,21 +464,22 @@ static int bind_caller_port_to_irq(unsig
 
 static int bind_local_port_to_irq(unsigned int local_port)
 {
+	struct irq_cfg *cfg;
 	int irq;
 
 	spin_lock(&irq_mapping_update_lock);
 
 	BUG_ON(evtchn_to_irq[local_port] != -1);
 
-	if ((irq = find_unbound_irq(numa_node_id())) < 0) {
+	if ((irq = find_unbound_irq(numa_node_id(), &cfg)) < 0) {
 		if (close_evtchn(local_port))
 			BUG();
 		goto out;
 	}
 
 	evtchn_to_irq[local_port] = irq;
-	irq_cfg(irq)->info = mk_irq_info(IRQT_LOCAL_PORT, 0, local_port);
-	irq_cfg(irq)->bindcount++;
+	cfg->info = mk_irq_info(IRQT_LOCAL_PORT, 0, local_port);
+	cfg->bindcount++;
 
  out:
 	spin_unlock(&irq_mapping_update_lock);
@@ -494,12 +518,13 @@ static int bind_interdomain_evtchn_to_ir
 static int bind_virq_to_irq(unsigned int virq, unsigned int cpu)
 {
 	struct evtchn_bind_virq bind_virq;
+	struct irq_cfg *cfg;
 	int evtchn, irq;
 
 	spin_lock(&irq_mapping_update_lock);
 
 	if ((irq = per_cpu(virq_to_irq, cpu)[virq]) == -1) {
-		if ((irq = find_unbound_irq(cpu_to_node(cpu))) < 0)
+		if ((irq = find_unbound_irq(cpu_to_node(cpu), &cfg)) < 0)
 			goto out;
 
 		bind_virq.virq = virq;
@@ -510,14 +535,15 @@ static int bind_virq_to_irq(unsigned int
 		evtchn = bind_virq.port;
 
 		evtchn_to_irq[evtchn] = irq;
-		irq_cfg(irq)->info = mk_irq_info(IRQT_VIRQ, virq, evtchn);
+		cfg->info = mk_irq_info(IRQT_VIRQ, virq, evtchn);
 
 		per_cpu(virq_to_irq, cpu)[virq] = irq;
 
 		bind_evtchn_to_cpu(evtchn, cpu);
-	}
+	} else
+		cfg = irq_cfg(irq);
 
-	irq_cfg(irq)->bindcount++;
+	cfg->bindcount++;
 
  out:
 	spin_unlock(&irq_mapping_update_lock);
@@ -527,12 +553,13 @@ static int bind_virq_to_irq(unsigned int
 static int bind_ipi_to_irq(unsigned int ipi, unsigned int cpu)
 {
 	struct evtchn_bind_ipi bind_ipi;
+	struct irq_cfg *cfg;
 	int evtchn, irq;
 
 	spin_lock(&irq_mapping_update_lock);
 
 	if ((irq = per_cpu(ipi_to_irq, cpu)[ipi]) == -1) {
-		if ((irq = find_unbound_irq(cpu_to_node(cpu))) < 0)
+		if ((irq = find_unbound_irq(cpu_to_node(cpu), &cfg)) < 0)
 			goto out;
 
 		bind_ipi.vcpu = cpu;
@@ -542,14 +569,15 @@ static int bind_ipi_to_irq(unsigned int 
 		evtchn = bind_ipi.port;
 
 		evtchn_to_irq[evtchn] = irq;
-		irq_cfg(irq)->info = mk_irq_info(IRQT_IPI, ipi, evtchn);
+		cfg->info = mk_irq_info(IRQT_IPI, ipi, evtchn);
 
 		per_cpu(ipi_to_irq, cpu)[ipi] = irq;
 
 		bind_evtchn_to_cpu(evtchn, cpu);
-	}
+	} else
+		cfg = irq_cfg(irq);
 
-	irq_cfg(irq)->bindcount++;
+	cfg->bindcount++;
 
  out:
 	spin_unlock(&irq_mapping_update_lock);
@@ -559,23 +587,24 @@ static int bind_ipi_to_irq(unsigned int 
 static void unbind_from_irq(unsigned int irq)
 {
 	unsigned int cpu;
-	int evtchn = evtchn_from_irq(irq);
+	struct irq_data *data = irq_get_irq_data(irq);
+	int evtchn = evtchn_from_irq_data(data);
 
 	spin_lock(&irq_mapping_update_lock);
 
-	if (!--irq_cfg(irq)->bindcount && VALID_EVTCHN(evtchn)) {
-		if ((type_from_irq(irq) != IRQT_CALLER_PORT) &&
+	if (!--irq_data_cfg(data)->bindcount && VALID_EVTCHN(evtchn)) {
+		if ((type_from_irq_data(data) != IRQT_CALLER_PORT) &&
 		    close_evtchn(evtchn))
 			BUG();
 
-		switch (type_from_irq(irq)) {
+		switch (type_from_irq_data(data)) {
 		case IRQT_VIRQ:
 			per_cpu(virq_to_irq, cpu_from_evtchn(evtchn))
-				[index_from_irq(irq)] = -1;
+				[index_from_irq_data(data)] = -1;
 			break;
 		case IRQT_IPI:
 			per_cpu(ipi_to_irq, cpu_from_evtchn(evtchn))
-				[index_from_irq(irq)] = -1;
+				[index_from_irq_data(data)] = -1;
 			break;
 		default:
 			break;
@@ -585,7 +614,7 @@ static void unbind_from_irq(unsigned int
 		bind_evtchn_to_cpu(evtchn, 0);
 
 		evtchn_to_irq[evtchn] = -1;
-		irq_cfg(irq)->info = IRQ_UNBOUND;
+		irq_data_cfg(data)->info = IRQ_UNBOUND;
 
 		/* Zap stats across IRQ changes of use. */
 		for_each_possible_cpu(cpu)
@@ -740,7 +769,7 @@ void rebind_evtchn_to_cpu(int port, unsi
 
 static void rebind_irq_to_cpu(struct irq_data *data, unsigned int tcpu)
 {
-	int evtchn = evtchn_from_irq(data->irq);
+	int evtchn = evtchn_from_irq_data(data);
 
 	if (VALID_EVTCHN(evtchn))
 		rebind_evtchn_to_cpu(evtchn, tcpu);
@@ -757,7 +786,7 @@ static int set_affinity_irq(struct irq_d
 
 int resend_irq_on_evtchn(struct irq_data *data)
 {
-	int masked, evtchn = evtchn_from_irq(data->irq);
+	int masked, evtchn = evtchn_from_irq_data(data);
 
 	if (!VALID_EVTCHN(evtchn))
 		return 1;
@@ -776,7 +805,7 @@ int resend_irq_on_evtchn(struct irq_data
 
 static void unmask_dynirq(struct irq_data *data)
 {
-	int evtchn = evtchn_from_irq(data->irq);
+	int evtchn = evtchn_from_irq_data(data);
 
 	if (VALID_EVTCHN(evtchn))
 		unmask_evtchn(evtchn);
@@ -784,7 +813,7 @@ static void unmask_dynirq(struct irq_dat
 
 static void mask_dynirq(struct irq_data *data)
 {
-	int evtchn = evtchn_from_irq(data->irq);
+	int evtchn = evtchn_from_irq_data(data);
 
 	if (VALID_EVTCHN(evtchn))
 		mask_evtchn(evtchn);
@@ -883,7 +912,7 @@ static void enable_pirq(struct irq_data 
 {
 	struct evtchn_bind_pirq bind_pirq;
 	unsigned int irq = data->irq;
-	int evtchn = evtchn_from_irq(irq);
+	int evtchn = evtchn_from_irq_data(data);
 
 	if (VALID_EVTCHN(evtchn)) {
 		clear_bit(irq - PIRQ_BASE, probing_pirq);
@@ -923,8 +952,7 @@ static unsigned int startup_pirq(struct 
 
 static void shutdown_pirq(struct irq_data *data)
 {
-	unsigned int irq = data->irq;
-	int evtchn = evtchn_from_irq(irq);
+	int evtchn = evtchn_from_irq_data(data);
 
 	if (!VALID_EVTCHN(evtchn))
 		return;
@@ -937,12 +965,12 @@ static void shutdown_pirq(struct irq_dat
 	bind_evtchn_to_cpu(evtchn, 0);
 	evtchn_to_irq[evtchn] = -1;
 	irq_data_cfg(data)->info = mk_irq_info(IRQT_PIRQ,
-					       index_from_irq(irq), 0);
+					       index_from_irq_data(data), 0);
 }
 
 static void unmask_pirq(struct irq_data *data)
 {
-	int evtchn = evtchn_from_irq(data->irq);
+	int evtchn = evtchn_from_irq_data(data);
 
 	if (VALID_EVTCHN(evtchn))
 		pirq_unmask_and_notify(evtchn, data->irq);
@@ -1250,10 +1278,12 @@ int assign_irq_vector(int irq, struct ir
 
 void evtchn_register_pirq(int irq)
 {
+	struct irq_data *data = irq_get_irq_data(irq);
+
 	BUG_ON(irq < PIRQ_BASE || irq - PIRQ_BASE >= nr_pirqs);
-	if (identity_mapped_irq(irq) || type_from_irq(irq) != IRQT_UNBOUND)
+	if (identity_mapped_irq(irq) || type_from_irq_data(data) != IRQT_UNBOUND)
 		return;
-	irq_cfg(irq)->info = mk_irq_info(IRQT_PIRQ, irq, 0);
+	irq_data_cfg(data)->info = mk_irq_info(IRQT_PIRQ, irq, 0);
 	set_irq_chip_and_handler_name(irq, &pirq_chip, handle_fasteoi_irq,
 				      "fasteoi");
 }
@@ -1271,6 +1301,10 @@ int evtchn_map_pirq(int irq, int xen_pir
 			if (identity_mapped_irq(irq))
 				continue;
 			cfg = alloc_irq_and_cfg_at(irq, numa_node_id());
+			if (unlikely(!cfg)) {
+				spin_unlock(&irq_alloc_lock);
+				return -ENOMEM;
+			}
 			if (!index_from_irq(irq)) {
 				BUG_ON(type_from_irq(irq) != IRQT_UNBOUND);
 				cfg->info = mk_irq_info(IRQT_PIRQ,
@@ -1307,10 +1341,12 @@ int evtchn_map_pirq(int irq, int xen_pir
 
 int evtchn_get_xen_pirq(int irq)
 {
+	struct irq_data *data = irq_get_irq_data(irq);
+
 	if (identity_mapped_irq(irq))
 		return irq;
-	BUG_ON(type_from_irq(irq) != IRQT_PIRQ);
-	return index_from_irq(irq);
+	BUG_ON(type_from_irq_data(data) != IRQT_PIRQ);
+	return index_from_irq_data(data);
 }
 
 void __init xen_init_IRQ(void)
--- head-2010-12-06.orig/drivers/xen/evtchn.c	2010-11-25 10:29:57.000000000 +0100
+++ head-2010-12-06/drivers/xen/evtchn.c	2010-12-06 14:31:14.000000000 +0100
@@ -528,7 +528,11 @@ static const struct file_operations evtc
 
 static struct miscdevice evtchn_miscdev = {
 	.minor        = MISC_DYNAMIC_MINOR,
+#ifdef CONFIG_PARAVIRT_XEN
 	.name         = "xen/evtchn",
+#else
+	.name         = "evtchn",
+#endif
 	.nodename     = "xen/evtchn",
 	.fops         = &evtchn_fops,
 };
--- head-2010-12-06.orig/drivers/xen/privcmd/privcmd.c	2010-11-24 11:38:47.000000000 +0100
+++ head-2010-12-06/drivers/xen/privcmd/privcmd.c	2010-12-06 14:53:00.000000000 +0100
@@ -415,7 +415,8 @@ static int privcmd_mmap(struct file * fi
 	if (xen_feature(XENFEAT_auto_translated_physmap))
 		return -ENOSYS;
 
-	/* DONTCOPY is essential for Xen as copy_page_range is broken. */
+	/* DONTCOPY is essential for Xen because copy_page_range doesn't know
+	 * how to recreate these mappings */
 	vma->vm_flags |= VM_RESERVED | VM_IO | VM_PFNMAP | VM_DONTCOPY;
 	vma->vm_ops = &privcmd_vm_ops;
 	vma->vm_private_data = NULL;
--- head-2010-12-06.orig/include/xen/interface/memory.h	2010-11-25 10:54:59.000000000 +0100
+++ head-2010-12-06/include/xen/interface/memory.h	2010-12-06 14:31:14.000000000 +0100
@@ -198,6 +198,7 @@ struct xen_machphys_mapping {
     xen_ulong_t v_start, v_end; /* Start and end virtual addresses.   */
     xen_ulong_t max_mfn;        /* Maximum MFN that can be looked up. */
 };
+DEFINE_GUEST_HANDLE_STRUCT(xen_machphys_mapping);
 typedef struct xen_machphys_mapping xen_machphys_mapping_t;
 DEFINE_XEN_GUEST_HANDLE(xen_machphys_mapping_t);
 
--- head-2010-12-06.orig/include/xen/public/privcmd.h	2010-11-22 13:01:00.000000000 +0100
+++ head-2010-12-06/include/xen/public/privcmd.h	2010-12-06 14:31:14.000000000 +0100
@@ -34,6 +34,7 @@
 #define __LINUX_PUBLIC_PRIVCMD_H__
 
 #include <linux/types.h>
+#include <linux/compiler.h>
 
 typedef struct privcmd_hypercall
 {
