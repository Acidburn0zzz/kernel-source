From: jbeulich@novell.com
Subject: Enhance performance of CONFIG_HIGHPTE on i386
Patch-mainline: obsolete

Index: head-2007-01-16/arch/i386/mm/highmem-xen.c
===================================================================
--- head-2007-01-16.orig/arch/i386/mm/highmem-xen.c	2007-01-19 16:21:14.000000000 +0100
+++ head-2007-01-16/arch/i386/mm/highmem-xen.c	2007-01-19 16:47:47.000000000 +0100
@@ -53,7 +53,9 @@ void *kmap_atomic(struct page *page, enu
 /* Same as kmap_atomic but with PAGE_KERNEL_RO page protection. */
 void *kmap_atomic_pte(struct page *page, enum km_type type)
 {
-	return __kmap_atomic(page, type, PAGE_KERNEL_RO);
+	return __kmap_atomic(page, type,
+	                     test_bit(PG_pinned, &page->flags)
+	                     ? PAGE_KERNEL_RO : kmap_prot);
 }
 
 void kunmap_atomic(void *kvaddr, enum km_type type)
Index: head-2007-01-16/arch/i386/mm/pgtable-xen.c
===================================================================
--- head-2007-01-16.orig/arch/i386/mm/pgtable-xen.c	2007-01-19 16:21:14.000000000 +0100
+++ head-2007-01-16/arch/i386/mm/pgtable-xen.c	2007-01-19 16:47:47.000000000 +0100
@@ -25,7 +25,6 @@
 #include <asm/mmu_context.h>
 
 #include <xen/features.h>
-#include <xen/foreign_page.h>
 #include <asm/hypervisor.h>
 
 static void pgd_test_and_unpin(pgd_t *pgd);
@@ -247,14 +246,6 @@ struct page *pte_alloc_one(struct mm_str
 
 #ifdef CONFIG_HIGHPTE
 	pte = alloc_pages(GFP_KERNEL|__GFP_HIGHMEM|__GFP_REPEAT|__GFP_ZERO, 0);
-	if (pte && PageHighMem(pte)) {
-		struct mmuext_op op;
-
-		kmap_flush_unused();
-		op.cmd = MMUEXT_PIN_L1_TABLE;
-		op.arg1.mfn = pfn_to_mfn(page_to_pfn(pte));
-		BUG_ON(HYPERVISOR_mmuext_op(&op, 1, NULL, DOMID_SELF) < 0);
-	}
 #else
 	pte = alloc_pages(GFP_KERNEL|__GFP_REPEAT|__GFP_ZERO, 0);
 #endif
@@ -275,7 +266,7 @@ void pte_free(struct page *pte)
 		if (!pte_write(*virt_to_ptep(va)))
 			BUG_ON(HYPERVISOR_update_va_mapping(
 			       va, pfn_pte(pfn, PAGE_KERNEL), 0));
-	} else {
+	} else if (test_and_clear_bit(PG_pinned, &pte->flags)) {
 		struct mmuext_op op;
 
 		op.cmd = MMUEXT_UNPIN_TABLE;
@@ -595,13 +586,30 @@ void make_pages_writable(void *va, unsig
 	}
 }
 
-static inline void pgd_walk_set_prot(void *pt, pgprot_t flags)
+static inline void pgd_walk_set_prot(struct page *page, pgprot_t flags)
 {
-	struct page *page = virt_to_page(pt);
 	unsigned long pfn = page_to_pfn(page);
 
-	if (PageHighMem(page))
+	if (PageHighMem(page)) {
+		struct mmuext_op op;
+
+		if (pgprot_val(flags) & _PAGE_RW) {
+			if (!test_and_clear_bit(PG_pinned, &page->flags))
+				return;
+			op.cmd = MMUEXT_UNPIN_TABLE;
+		}
+		else {
+			if (test_and_set_bit(PG_pinned, &page->flags))
+				return;
+			/* Only L1 tables can be allocated from highmem. */
+			op.cmd = MMUEXT_PIN_L1_TABLE;
+		}
+		op.arg1.mfn = pfn_to_mfn(pfn);
+		kmap_flush_unused();
+		BUG_ON(HYPERVISOR_mmuext_op(&op, 1, NULL, DOMID_SELF) < 0);
 		return;
+	}
+
 	BUG_ON(HYPERVISOR_update_va_mapping(
 		(unsigned long)__va(pfn << PAGE_SHIFT),
 		pfn_pte(pfn, flags), 0));
@@ -612,7 +620,6 @@ static void pgd_walk(pgd_t *pgd_base, pg
 	pgd_t *pgd = pgd_base;
 	pud_t *pud;
 	pmd_t *pmd;
-	pte_t *pte;
 	int    g, u, m;
 
 	if (xen_feature(XENFEAT_auto_translated_physmap))
@@ -623,18 +630,17 @@ static void pgd_walk(pgd_t *pgd_base, pg
 			continue;
 		pud = pud_offset(pgd, 0);
 		if (PTRS_PER_PUD > 1) /* not folded */
-			pgd_walk_set_prot(pud,flags);
+			pgd_walk_set_prot(virt_to_page(pud),flags);
 		for (u = 0; u < PTRS_PER_PUD; u++, pud++) {
 			if (pud_none(*pud))
 				continue;
 			pmd = pmd_offset(pud, 0);
 			if (PTRS_PER_PMD > 1) /* not folded */
-				pgd_walk_set_prot(pmd,flags);
+				pgd_walk_set_prot(virt_to_page(pmd),flags);
 			for (m = 0; m < PTRS_PER_PMD; m++, pmd++) {
 				if (pmd_none(*pmd))
 					continue;
-				pte = pte_offset_kernel(pmd,0);
-				pgd_walk_set_prot(pte,flags);
+				pgd_walk_set_prot(pmd_page(*pmd),flags);
 			}
 		}
 	}
Index: head-2007-01-16/include/asm-i386/mach-xen/asm/page.h
===================================================================
--- head-2007-01-16.orig/include/asm-i386/mach-xen/asm/page.h	2007-01-19 16:21:14.000000000 +0100
+++ head-2007-01-16/include/asm-i386/mach-xen/asm/page.h	2007-01-19 16:49:10.000000000 +0100
@@ -28,7 +28,6 @@
 #include <asm/bug.h>
 #include <xen/interface/xen.h>
 #include <xen/features.h>
-#include <xen/foreign_page.h>
 
 #ifdef CONFIG_XEN_SCRUB_PAGES
 #define scrub_pages(_p,_n) memset((void *)(_p), 0, (_n) << PAGE_SHIFT)
Index: head-2007-01-16/include/asm-i386/mach-xen/asm/pgalloc.h
===================================================================
--- head-2007-01-16.orig/include/asm-i386/mach-xen/asm/pgalloc.h	2007-01-17 13:41:56.000000000 +0100
+++ head-2007-01-16/include/asm-i386/mach-xen/asm/pgalloc.h	2007-01-19 16:47:47.000000000 +0100
@@ -5,28 +5,31 @@
 #include <linux/threads.h>
 #include <linux/mm.h>		/* for struct page */
 #include <asm/io.h>		/* for phys_to_virt and page_to_pseudophys */
-
-/* Is this pagetable pinned? */
-#define PG_pinned	PG_arch_1
+#include <asm/hypervisor.h>
 
 #define pmd_populate_kernel(mm, pmd, pte) \
 		set_pmd(pmd, __pmd(_PAGE_TABLE + __pa(pte)))
 
 #define pmd_populate(mm, pmd, pte) 					\
 do {									\
+	unsigned long pfn = page_to_pfn(pte);				\
 	if (test_bit(PG_pinned, &virt_to_page((mm)->pgd)->flags)) {	\
 		if (!PageHighMem(pte))					\
 			BUG_ON(HYPERVISOR_update_va_mapping(		\
-			  (unsigned long)__va(page_to_pfn(pte)<<PAGE_SHIFT),\
-			  pfn_pte(page_to_pfn(pte), PAGE_KERNEL_RO), 0));\
-		set_pmd(pmd, __pmd(_PAGE_TABLE +			\
-			((unsigned long long)page_to_pfn(pte) <<	\
-				(unsigned long long) PAGE_SHIFT)));	\
-	} else {							\
-		*(pmd) = __pmd(_PAGE_TABLE +				\
-			((unsigned long long)page_to_pfn(pte) <<	\
-				(unsigned long long) PAGE_SHIFT));	\
-	}								\
+			  (unsigned long)__va(pfn << PAGE_SHIFT),	\
+			  pfn_pte(pfn, PAGE_KERNEL_RO), 0));		\
+		else if (!test_and_set_bit(PG_pinned, &pte->flags)) {	\
+			struct mmuext_op op;				\
+			kmap_flush_unused();				\
+			op.cmd = MMUEXT_PIN_L1_TABLE;			\
+			op.arg1.mfn = pfn_to_mfn(pfn);			\
+			BUG_ON(HYPERVISOR_mmuext_op(&op, 1, NULL,	\
+			                            DOMID_SELF) < 0);	\
+		}							\
+		set_pmd(pmd,						\
+		        __pmd(_PAGE_TABLE + ((paddr_t)pfn << PAGE_SHIFT))); \
+	} else							\
+		*(pmd) = __pmd(_PAGE_TABLE + ((paddr_t)pfn << PAGE_SHIFT)); \
 } while (0)
 
 /*
Index: head-2007-01-16/include/asm-i386/mach-xen/asm/pgtable.h
===================================================================
--- head-2007-01-16.orig/include/asm-i386/mach-xen/asm/pgtable.h	2007-01-19 16:21:14.000000000 +0100
+++ head-2007-01-16/include/asm-i386/mach-xen/asm/pgtable.h	2007-01-19 16:47:47.000000000 +0100
@@ -25,6 +25,9 @@
 #include <linux/list.h>
 #include <linux/spinlock.h>
 
+/* Is this pagetable pinned? */
+#define PG_pinned	PG_arch_1
+
 struct mm_struct;
 struct vm_area_struct;
 
Index: head-2007-01-16/include/asm-x86_64/mach-xen/asm/page.h
===================================================================
--- head-2007-01-16.orig/include/asm-x86_64/mach-xen/asm/page.h	2007-01-17 13:41:57.000000000 +0100
+++ head-2007-01-16/include/asm-x86_64/mach-xen/asm/page.h	2007-01-19 16:49:38.000000000 +0100
@@ -8,7 +8,6 @@
 #include <asm/bug.h>
 #endif
 #include <xen/interface/xen.h> 
-#include <xen/foreign_page.h>
 
 #ifdef CONFIG_XEN_SCRUB_PAGES
 #define scrub_pages(_p,_n) memset((void *)(_p), 0, (_n) << PAGE_SHIFT)
Index: head-2007-01-16/include/linux/page-flags.h
===================================================================
--- head-2007-01-16.orig/include/linux/page-flags.h	2007-01-16 15:24:06.000000000 +0100
+++ head-2007-01-16/include/linux/page-flags.h	2007-01-19 16:50:35.000000000 +0100
@@ -91,6 +91,7 @@
 #define PG_nosave_free		18	/* Used for system suspend/resume */
 #define PG_buddy		19	/* Page is free, on buddy lists */
 
+#define PG_foreign		20	/* Page is owned by foreign allocator. */
 
 #if (BITS_PER_LONG > 32)
 /*
@@ -251,6 +252,18 @@ static inline void SetPageUptodate(struc
 #define SetPageUncached(page)	set_bit(PG_uncached, &(page)->flags)
 #define ClearPageUncached(page)	clear_bit(PG_uncached, &(page)->flags)
 
+#define PageForeign(page)	test_bit(PG_foreign, &(page)->flags)
+#define SetPageForeign(page, dtor) do {		\
+	set_bit(PG_foreign, &(page)->flags);	\
+	(page)->mapping = (void *)dtor;		\
+} while (0)
+#define ClearPageForeign(page) do {		\
+	clear_bit(PG_foreign, &(page)->flags);	\
+	(page)->mapping = NULL;			\
+} while (0)
+#define PageForeignDestructor(page)		\
+	( (void (*) (struct page *)) (page)->mapping )(page)
+
 struct page;	/* forward declaration */
 
 extern void cancel_dirty_page(struct page *page, unsigned int account_size);
Index: head-2007-01-16/include/xen/foreign_page.h
===================================================================
--- head-2007-01-16.orig/include/xen/foreign_page.h	2007-01-17 10:09:52.000000000 +0100
+++ /dev/null	1970-01-01 00:00:00.000000000 +0000
@@ -1,30 +0,0 @@
-/******************************************************************************
- * foreign_page.h
- * 
- * Provide a "foreign" page type, that is owned by a foreign allocator and 
- * not the normal buddy allocator in page_alloc.c
- * 
- * Copyright (c) 2004, K A Fraser
- */
-
-#ifndef __ASM_XEN_FOREIGN_PAGE_H__
-#define __ASM_XEN_FOREIGN_PAGE_H__
-
-#define PG_foreign		PG_arch_1
-
-#define PageForeign(page)	test_bit(PG_foreign, &(page)->flags)
-
-#define SetPageForeign(page, dtor) do {		\
-	set_bit(PG_foreign, &(page)->flags);	\
-	(page)->mapping = (void *)dtor;		\
-} while (0)
-
-#define ClearPageForeign(page) do {		\
-	clear_bit(PG_foreign, &(page)->flags);	\
-	(page)->mapping = NULL;			\
-} while (0)
-
-#define PageForeignDestructor(page)	\
-	( (void (*) (struct page *)) (page)->mapping )
-
-#endif /* __ASM_XEN_FOREIGN_PAGE_H__ */
Index: head-2007-01-16/mm/page_alloc.c
===================================================================
--- head-2007-01-16.orig/mm/page_alloc.c	2007-01-17 11:22:11.000000000 +0100
+++ head-2007-01-16/mm/page_alloc.c	2007-01-19 16:52:04.000000000 +0100
@@ -46,10 +46,6 @@
 #include <asm/div64.h>
 #include "internal.h"
 
-#ifdef CONFIG_XEN
-#include <include/xen/foreign_page.h>
-#endif
-
 /*
  * MCD - HACK: Find somewhere to initialize this EARLY, or make this
  * initializer cleaner
@@ -203,7 +199,11 @@ static void bad_page(struct page *page)
 			1 << PG_slab    |
 			1 << PG_swapcache |
 			1 << PG_writeback |
-			1 << PG_buddy );
+			1 << PG_buddy	|
+#ifdef CONFIG_X86_XEN
+			1 << PG_pinned	|
+#endif
+			1 << PG_foreign );
 	set_page_count(page, 0);
 	reset_page_mapcount(page);
 	page->mapping = NULL;
@@ -438,7 +438,11 @@ static inline int free_pages_check(struc
 			1 << PG_swapcache |
 			1 << PG_writeback |
 			1 << PG_reserved |
-			1 << PG_buddy ))))
+			1 << PG_buddy	|
+#ifdef CONFIG_X86_XEN
+			1 << PG_pinned	|
+#endif
+			1 << PG_foreign ))))
 		bad_page(page);
 	if (PageDirty(page))
 		__ClearPageDirty(page);
@@ -494,12 +498,10 @@ static void __free_pages_ok(struct page 
 	int i;
 	int reserved = 0;
 
-#ifdef CONFIG_XEN
 	if (PageForeign(page)) {
-		(PageForeignDestructor(page))(page);
+		PageForeignDestructor(page);
 		return;
 	}
-#endif
 	for (i = 0 ; i < (1 << order) ; ++i)
 		reserved += free_pages_check(page + i);
 	if (reserved)
@@ -594,7 +596,11 @@ static int prep_new_page(struct page *pa
 			1 << PG_swapcache |
 			1 << PG_writeback |
 			1 << PG_reserved |
-			1 << PG_buddy ))))
+			1 << PG_buddy	|
+#ifdef CONFIG_X86_XEN
+			1 << PG_pinned	|
+#endif
+			1 << PG_foreign ))))
 		bad_page(page);
 
 	/*
Index: head-2007-01-16/arch/i386/mm/fault-xen.c
===================================================================
--- head-2007-01-16.orig/arch/i386/mm/fault-xen.c	2007-01-19 16:21:14.000000000 +0100
+++ head-2007-01-16/arch/i386/mm/fault-xen.c	2007-01-19 16:53:28.000000000 +0100
@@ -264,9 +264,12 @@ static void dump_fault_path(unsigned lon
 		p += (address >> 21) * 2;
 		printk(KERN_ALERT "%08lx -> *pme = %08lx:%08lx\n", 
 		       page, p[1], p[0]);
-#ifndef CONFIG_HIGHPTE
+		mfn  = (p[0] >> PAGE_SHIFT) | (p[1] << 20);
+#ifdef CONFIG_HIGHPTE
+		if (mfn_to_pfn(mfn) >= highstart_pfn)
+			return;
+#endif
 		if (p[0] & 1) {
-			mfn  = (p[0] >> PAGE_SHIFT) | (p[1] << 20);
 			page = mfn_to_pfn(mfn) << PAGE_SHIFT; 
 			p  = (unsigned long *) __va(page);
 			address &= 0x001fffff;
@@ -274,7 +277,6 @@ static void dump_fault_path(unsigned lon
 			printk(KERN_ALERT "%08lx -> *pte = %08lx:%08lx\n",
 			       page, p[1], p[0]);
 		}
-#endif
 	}
 }
 #else
@@ -286,13 +288,16 @@ static void dump_fault_path(unsigned lon
 	page = ((unsigned long *) __va(page))[address >> 22];
 	printk(KERN_ALERT "*pde = ma %08lx pa %08lx\n", page,
 	       machine_to_phys(page));
+#ifdef CONFIG_HIGHPTE
 	/*
 	 * We must not directly access the pte in the highpte
-	 * case, the page table might be allocated in highmem.
+	 * case if the page table is located in highmem.
 	 * And lets rather not kmap-atomic the pte, just in case
 	 * it's allocated already.
 	 */
-#ifndef CONFIG_HIGHPTE
+	if ((page >> PAGE_SHIFT) >= highstart_pfn)
+		return;
+#endif
 	if (page & 1) {
 		page &= PAGE_MASK;
 		address &= 0x003ff000;
@@ -301,7 +306,6 @@ static void dump_fault_path(unsigned lon
 		printk(KERN_ALERT "*pte = ma %08lx pa %08lx\n", page,
 		       machine_to_phys(page));
 	}
-#endif
 }
 #endif
 
