Subject: Linux 2.6.16.9
Patch-Mainline: 2.6.16.9
From: Greg Kroah-Hartman <gregkh@suse.de>

Signed-off-by: Greg Kroah-Hartman <gregkh@suse.de>

Index: head-2006-06-06/arch/x86_64/kernel/entry-xen.S
===================================================================
--- head-2006-06-06.orig/arch/x86_64/kernel/entry-xen.S	2006-06-06 12:51:13.000000000 +0200
+++ head-2006-06-06/arch/x86_64/kernel/entry-xen.S	2006-06-06 12:53:17.000000000 +0200
@@ -221,6 +221,10 @@ rff_trace:
  *
  * XXX	if we had a free scratch register we could save the RSP into the stack frame
  *      and report it properly in ps. Unfortunately we haven't.
+ *
+ * When user can change the frames always force IRET. That is because
+ * it deals with uncanonical addresses better. SYSRET has trouble
+ * with them due to bugs in both AMD and Intel CPUs.
  */ 			 		
 
 ENTRY(system_call)
@@ -289,7 +293,10 @@ sysret_signal:
 	xorl %esi,%esi # oldset -> arg2
 	call ptregscall_common
 1:	movl $_TIF_NEED_RESCHED,%edi
-	jmp sysret_check
+	/* Use IRET because user could have changed frame. This
+	   works because ptregscall_common has called FIXUP_TOP_OF_STACK. */
+	cli
+	jmp int_with_check
 	
 badsys:
 	movq $-ENOSYS,RAX-ARGOFFSET(%rsp)
@@ -315,7 +322,8 @@ tracesys:			 
 	call syscall_trace_leave
 	RESTORE_TOP_OF_STACK %rbx
 	RESTORE_REST
-	jmp ret_from_sys_call
+	/* Use IRET because user could have changed frame */
+	jmp int_ret_from_sys_call
 	CFI_ENDPROC
 		
 /* 
@@ -449,25 +457,9 @@ ENTRY(stub_execve)
 	CFI_ADJUST_CFA_OFFSET -8
 	CFI_REGISTER rip, r11
 	SAVE_REST
-	movq %r11, %r15
-	CFI_REGISTER rip, r15
 	FIXUP_TOP_OF_STACK %r11
 	call sys_execve
-	GET_THREAD_INFO(%rcx)
-	bt $TIF_IA32,threadinfo_flags(%rcx)
-	CFI_REMEMBER_STATE
-	jc exec_32bit
 	RESTORE_TOP_OF_STACK %r11
-	movq %r15, %r11
-	CFI_REGISTER rip, r11
-	RESTORE_REST
-	pushq %r11
-	CFI_ADJUST_CFA_OFFSET 8
-	CFI_REL_OFFSET rip, 0
-	ret
-
-exec_32bit:
-	CFI_RESTORE_STATE
 	movq %rax,RAX(%rsp)
 	RESTORE_REST
 	jmp int_ret_from_sys_call
Index: head-2006-06-06/arch/x86_64/kernel/process-xen.c
===================================================================
--- head-2006-06-06.orig/arch/x86_64/kernel/process-xen.c	2006-06-06 12:52:56.000000000 +0200
+++ head-2006-06-06/arch/x86_64/kernel/process-xen.c	2006-06-06 12:53:17.000000000 +0200
@@ -475,18 +475,6 @@ __switch_to(struct task_struct *prev_p, 
 	multicall_entry_t _mcl[8], *mcl = _mcl;
 
 	/*
-	 * This is basically '__unlazy_fpu', except that we queue a
-	 * multicall to indicate FPU task switch, rather than
-	 * synchronously trapping to Xen.
-	 */
-	if (prev_p->thread_info->status & TS_USEDFPU) {
-		__save_init_fpu(prev_p); /* _not_ save_init_fpu() */
-		mcl->op      = __HYPERVISOR_fpu_taskswitch;
-		mcl->args[0] = 1;
-		mcl++;
-	}
-
-	/*
 	 * Reload esp0, LDT and the page table pointer:
 	 */
 	mcl->op      = __HYPERVISOR_stack_switch;
@@ -562,6 +550,20 @@ __switch_to(struct task_struct *prev_p, 
 	prev->userrsp = read_pda(oldrsp); 
 	write_pda(oldrsp, next->userrsp); 
 	write_pda(pcurrent, next_p); 
+
+	/*
+	 * This is basically 'unlazy_fpu', except that we do a
+	 * hypercall to indicate FPU task switch, rather than
+	 * synchronously trapping to Xen.
+	 */
+ 	/* This must be here to ensure both math_state_restore() and
+	   kernel_fpu_begin() work consistently.
+	   And the AMD workaround requires it to be after DS reload. */
+	if (prev_p->thread_info->status & TS_USEDFPU) {
+		__save_init_fpu(prev_p); /* _not_ save_init_fpu() */
+		HYPERVISOR_fpu_taskswitch(1);
+	}
+
 	write_pda(kernelstack,
 		  task_stack_page(next_p) + THREAD_SIZE - PDA_STACKOFFSET);
 
Index: head-2006-06-06/arch/x86_64/kernel/setup-xen.c
===================================================================
--- head-2006-06-06.orig/arch/x86_64/kernel/setup-xen.c	2006-06-06 12:52:56.000000000 +0200
+++ head-2006-06-06/arch/x86_64/kernel/setup-xen.c	2006-06-06 12:53:17.000000000 +0200
@@ -1148,6 +1148,10 @@ static int __init init_amd(struct cpuinf
 	if (c->x86 == 15 && ((level >= 0x0f48 && level < 0x0f50) || level >= 0x0f58))
 		set_bit(X86_FEATURE_REP_GOOD, &c->x86_capability);
 
+	/* Enable workaround for FXSAVE leak */
+	if (c->x86 >= 6)
+		set_bit(X86_FEATURE_FXSAVE_LEAK, &c->x86_capability);
+
 	r = get_model_name(c);
 	if (!r) { 
 		switch (c->x86) { 
