From: jbeulich@novell.com
Subject: Unmap temporary mappings established for setup of 1:1 mappings.
References: 175787

Index: head-2006-06-06/arch/x86_64/kernel/setup-xen.c
===================================================================
--- head-2006-06-06.orig/arch/x86_64/kernel/setup-xen.c	2006-06-06 14:13:44.000000000 +0200
+++ head-2006-06-06/arch/x86_64/kernel/setup-xen.c	2006-06-06 12:55:07.000000000 +0200
@@ -806,14 +806,6 @@ void __init setup_arch(char **cmdline_p)
 #ifdef CONFIG_XEN
 	{
 		int i, j, k, fpp;
-		unsigned long va;
-
-		/* 'Initial mapping' of initrd must be destroyed. */
-		for (va = xen_start_info->mod_start;
-		     va < (xen_start_info->mod_start+xen_start_info->mod_len);
-		     va += PAGE_SIZE) {
-			HYPERVISOR_update_va_mapping(va, __pte_ma(0), 0);
-		}
 
 		if (!xen_feature(XENFEAT_auto_translated_physmap)) {
 			/* Make sure we have a large enough P->M table. */
@@ -829,14 +821,6 @@ void __init setup_arch(char **cmdline_p)
 				PFN_PHYS(PFN_UP(xen_start_info->nr_pages *
 						sizeof(unsigned long))));
 
-			/* Destroyed 'initial mapping' of old p2m table. */
-			for (va = xen_start_info->mfn_list;
-			     va < (xen_start_info->mfn_list +
-				   (xen_start_info->nr_pages*sizeof(unsigned long)));
-			     va += PAGE_SIZE) {
-				HYPERVISOR_update_va_mapping(va, __pte_ma(0), 0);
-			}
-
 			/*
 			 * Initialise the list of the frames that specify the
 			 * list of frames that make up the p2m table. Used by
Index: head-2006-06-06/arch/x86_64/mm/init-xen.c
===================================================================
--- head-2006-06-06.orig/arch/x86_64/mm/init-xen.c	2006-06-06 14:13:44.000000000 +0200
+++ head-2006-06-06/arch/x86_64/mm/init-xen.c	2006-06-06 14:14:41.000000000 +0200
@@ -56,6 +56,8 @@
 struct dma_mapping_ops* dma_ops;
 EXPORT_SYMBOL(dma_ops);
 
+int after_bootmem;
+
 extern unsigned long *contiguous_bitmap;
 
 #ifndef CONFIG_XEN
@@ -76,7 +78,7 @@ extern unsigned long start_pfn;
 	(((mfn_to_pfn((addr) >> PAGE_SHIFT)) << PAGE_SHIFT) +	\
 	__START_KERNEL_map)))
 
-static void early_make_page_readonly(void *va, unsigned int feature)
+static void __meminit early_make_page_readonly(void *va, unsigned int feature)
 {
 	unsigned long addr, _va = (unsigned long)va;
 	pte_t pte, *ptep;
@@ -85,6 +87,11 @@ static void early_make_page_readonly(voi
 	if (xen_feature(feature))
 		return;
 
+	if (after_bootmem) {
+		make_page_readonly(va, feature);
+		return;
+	}
+
 	addr = (unsigned long) page[pgd_index(_va)];
 	addr_to_page(addr, page);
 
@@ -200,10 +207,6 @@ void show_mem(void)
 	printk(KERN_INFO "%lu pages swap cached\n",cached);
 }
 
-/* References to section boundaries */
-
-int after_bootmem;
-
 static void *spp_getpage(void)
 { 
 	void *ptr;
@@ -372,7 +375,8 @@ void __set_fixmap_user (enum fixed_addre
 	set_pte_phys(address, phys, prot, SET_FIXMAP_USER); 
 }
 
-unsigned long __initdata table_start, tables_space; 
+unsigned long __initdata table_start;
+static unsigned long __initdata tables_space;
 
 unsigned long get_machine_pfn(unsigned long addr)
 {
@@ -444,9 +448,9 @@ phys_pmd_init(pmd_t *pmd, unsigned long 
 		pte = alloc_static_page(&pte_phys);
 		pte_save = pte;
 		for (k = 0; k < PTRS_PER_PTE; pte++, k++, address += PTE_SIZE) {
-			if ((address >= end) ||
-			    ((address >> PAGE_SHIFT) >=
-			     xen_start_info->nr_pages)) { 
+			if (address >= (after_bootmem
+			                ? end
+			                : xen_start_info->nr_pages << PAGE_SHIFT)) {
 				__set_pte(pte, __pte(0)); 
 				continue;
 			}
@@ -546,7 +550,7 @@ void __init xen_init_pt(void)
 		mk_kernel_pgd(__pa_symbol(level3_user_pgt)));
 }
 
-void __init extend_init_mapping(void) 
+static void __init extend_init_mapping(void)
 {
 	unsigned long va = __START_KERNEL_map;
 	unsigned long phys, addr, *pte_page;
@@ -617,7 +621,8 @@ static void __init find_early_table_spac
 	table_start = start_pfn;
 
 	early_printk("kernel direct mapping tables up to %lx @ %lx-%lx\n",
-		end, table_start << PAGE_SHIFT, start_pfn << PAGE_SHIFT);
+		end, table_start << PAGE_SHIFT,
+		(table_start << PAGE_SHIFT) + tables_space);
 }
 
 /* Setup the direct mapping of the physical memory at PAGE_OFFSET.
@@ -664,15 +669,27 @@ void __meminit init_memory_mapping(unsig
 
 	if (!after_bootmem) {
 		BUG_ON(start_pfn != table_start + (tables_space >> PAGE_SHIFT));
-		/*
-		 * Destroy the temporary mappings created above. Prevents
-		 * overlap with modules area (if init mapping is very big).
-		 */
-		start = __START_KERNEL_map + (table_start << PAGE_SHIFT);
-		end   = start + tables_space;
-		for (; start < end; start += PAGE_SIZE)
-			WARN_ON(HYPERVISOR_update_va_mapping(
-				start, __pte_ma(0), 0));
+
+		/* Re-vector virtual addresses pointing into the initial
+		   mapping to the just established permanent ones. */
+		xen_start_info = __va(__pa(xen_start_info));
+		xen_start_info->pt_base = (unsigned long)__va(__pa(xen_start_info->pt_base));
+		if (!xen_feature(XENFEAT_auto_translated_physmap)) {
+			phys_to_machine_mapping = __va(__pa(xen_start_info->mfn_list));
+			xen_start_info->mfn_list = (unsigned long)phys_to_machine_mapping;
+		}
+		if (xen_start_info->mod_start)
+			xen_start_info->mod_start = (unsigned long)__va(__pa(xen_start_info->mod_start));
+
+		/* Destroy the Xen-created mappings beyond the kernel image as well
+		   as the temporary mappings created in init_memory_mapping(). */
+		start = PAGE_ALIGN((unsigned long)_end);
+		end = __START_KERNEL_map + (start_pfn << PAGE_SHIFT);
+		for (; start < end; start += PAGE_SIZE) {
+			/* Should also clear out and reclaim any page table
+			   pages no longer needed... */
+			WARN_ON(HYPERVISOR_update_va_mapping(start, __pte_ma(0), 0));
+		}
 	}
 
 	__flush_tlb_all();
