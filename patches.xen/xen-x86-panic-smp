From: jbeulich@novell.com
Subject: panic/shutdown handling adjustments
Patch-mainline: obsolete

Prevent interrupts (and hence possibly scheduler operations) from
occuring on (against) a CPU after removing it from cpu_online_map
during panic/shutdown.
(Background: I found it quite annoying to see scheduler related
badness or BUG messages after a panic, eventually even leading to
important information scrolling off the screen.)

Index: head-2007-03-19/arch/i386/kernel/smp-xen.c
===================================================================
--- head-2007-03-19.orig/arch/i386/kernel/smp-xen.c	2007-03-21 15:31:39.000000000 +0100
+++ head-2007-03-19/arch/i386/kernel/smp-xen.c	2007-03-21 11:49:37.000000000 +0100
@@ -494,35 +494,14 @@ void unlock_ipi_call_lock(void)
 
 static struct call_data_struct *call_data;
 
-/**
- * smp_call_function(): Run a function on all other CPUs.
- * @func: The function to run. This must be fast and non-blocking.
- * @info: An arbitrary pointer to pass to the function.
- * @nonatomic: currently unused.
- * @wait: If true, wait (atomically) until function has completed on other CPUs.
- *
- * Returns 0 on success, else a negative status code. Does not return until
- * remote CPUs are nearly ready to execute <<func>> or are or have executed.
- *
- * You must not call this function with disabled interrupts or from a
- * hardware interrupt handler or from a bottom half handler.
- */
-int smp_call_function (void (*func) (void *info), void *info, int nonatomic,
-			int wait)
+static void __smp_call_function(void (*func) (void *info), void *info,
+				int nonatomic, int wait)
 {
 	struct call_data_struct data;
-	int cpus;
+	int cpus = num_online_cpus() - 1;
 
-	/* Holding any lock stops cpus from going down. */
-	spin_lock(&call_lock);
-	cpus = num_online_cpus() - 1;
-	if (!cpus) {
-		spin_unlock(&call_lock);
-		return 0;
-	}
-
-	/* Can deadlock when called with interrupts disabled */
-	WARN_ON(irqs_disabled());
+	if (!cpus)
+		return;
 
 	data.func = func;
 	data.info = info;
@@ -544,6 +523,30 @@ int smp_call_function (void (*func) (voi
 	if (wait)
 		while (atomic_read(&data.finished) != cpus)
 			barrier();
+}
+
+/**
+ * smp_call_function(): Run a function on all other CPUs.
+ * @func: The function to run. This must be fast and non-blocking.
+ * @info: An arbitrary pointer to pass to the function.
+ * @nonatomic: currently unused.
+ * @wait: If true, wait (atomically) until function has completed on other CPUs.
+ *
+ * Returns 0 on success, else a negative status code. Does not return until
+ * remote CPUs are nearly ready to execute <<func>> or are or have executed.
+ *
+ * You must not call this function with disabled interrupts or from a
+ * hardware interrupt handler or from a bottom half handler.
+ */
+int smp_call_function (void (*func) (void *info), void *info, int nonatomic,
+			int wait)
+{
+	/* Can deadlock when called with interrupts disabled */
+	WARN_ON(irqs_disabled());
+
+	/* Holding any lock stops cpus from going down. */
+	spin_lock(&call_lock);
+	__smp_call_function(func, info, nonatomic, wait);
 	spin_unlock(&call_lock);
 
 	return 0;
@@ -552,14 +555,12 @@ EXPORT_SYMBOL(smp_call_function);
 
 static void stop_this_cpu (void * dummy)
 {
+	local_irq_disable();
 	/*
 	 * Remove this CPU:
 	 */
 	cpu_clear(smp_processor_id(), cpu_online_map);
-	local_irq_disable();
-#if 0
-	disable_local_APIC();
-#endif
+	mask_evtchn_local();
 	if (cpu_data[smp_processor_id()].hlt_works_ok)
 		for(;;) halt();
 	for (;;);
@@ -571,13 +572,16 @@ static void stop_this_cpu (void * dummy)
 
 void smp_send_stop(void)
 {
-	smp_call_function(stop_this_cpu, NULL, 1, 0);
-
-	local_irq_disable();
-#if 0
-	disable_local_APIC();
-#endif
-	local_irq_enable();
+	/* Don't deadlock on the call lock in panic */
+	int nolock = !spin_trylock(&call_lock);
+	unsigned long flags;
+
+	local_irq_save(flags);
+	__smp_call_function(stop_this_cpu, NULL, 0, 0);
+	if (!nolock)
+		spin_unlock(&call_lock);
+	mask_evtchn_local();
+	local_irq_restore(flags);
 }
 
 /*
Index: head-2007-03-19/arch/x86_64/kernel/smp-xen.c
===================================================================
--- head-2007-03-19.orig/arch/x86_64/kernel/smp-xen.c	2007-03-21 15:31:39.000000000 +0100
+++ head-2007-03-19/arch/x86_64/kernel/smp-xen.c	2007-03-21 11:49:37.000000000 +0100
@@ -478,48 +478,35 @@ int smp_call_function (void (*func) (voi
 }
 EXPORT_SYMBOL(smp_call_function);
 
-void smp_stop_cpu(void)
+static void stop_this_cpu(void *dummy)
 {
-	unsigned long flags;
+	local_irq_disable();
 	/*
 	 * Remove this CPU:
 	 */
 	cpu_clear(smp_processor_id(), cpu_online_map);
-	local_irq_save(flags);
-#ifndef CONFIG_XEN
-	disable_local_APIC();
-#endif
-	local_irq_restore(flags); 
-}
-
-static void smp_really_stop_cpu(void *dummy)
-{
-	smp_stop_cpu(); 
-	for (;;) 
+	mask_evtchn_local();
+	for (;;)
 		halt();
-} 
+}
 
 void smp_send_stop(void)
 {
-	int nolock = 0;
+	int nolock;
+	unsigned long flags;
+
 #ifndef CONFIG_XEN
 	if (reboot_force)
 		return;
 #endif
-	/* Don't deadlock on the call lock in panic */
-	if (!spin_trylock(&call_lock)) {
-		/* ignore locking because we have panicked anyways */
-		nolock = 1;
-	}
-	__smp_call_function(smp_really_stop_cpu, NULL, 0, 0);
+
+	nolock = !spin_trylock(&call_lock);
+	local_irq_save(flags);
+	__smp_call_function(stop_this_cpu, NULL, 0, 0);
 	if (!nolock)
 		spin_unlock(&call_lock);
-
-	local_irq_disable();
-#ifndef CONFIG_XEN
-	disable_local_APIC();
-#endif
-	local_irq_enable();
+	mask_evtchn_local();
+	local_irq_restore(flags);
 }
 
 /*
Index: head-2007-03-19/drivers/xen/core/evtchn.c
===================================================================
--- head-2007-03-19.orig/drivers/xen/core/evtchn.c	2007-03-21 15:31:39.000000000 +0100
+++ head-2007-03-19/drivers/xen/core/evtchn.c	2007-03-21 15:31:52.000000000 +0100
@@ -154,6 +154,16 @@ static inline unsigned int cpu_from_evtc
 	return cpu_evtchn[evtchn];
 }
 
+void mask_evtchn_local(void)
+{
+	unsigned i, cpu = smp_processor_id();
+	shared_info_t *s = HYPERVISOR_shared_info;
+
+	for (i = 0; i < NR_EVENT_CHANNELS; ++i)
+		if (cpu_evtchn[i] == cpu)
+			synch_set_bit(i, &s->evtchn_mask[0]);
+}
+
 #else
 
 static inline unsigned long active_evtchns(unsigned int cpu, shared_info_t *sh,
Index: head-2007-03-19/include/asm-x86_64/mach-xen/asm/smp.h
===================================================================
--- head-2007-03-19.orig/include/asm-x86_64/mach-xen/asm/smp.h	2007-03-21 15:31:39.000000000 +0100
+++ head-2007-03-19/include/asm-x86_64/mach-xen/asm/smp.h	2007-03-21 11:49:37.000000000 +0100
@@ -40,7 +40,6 @@ extern void lock_ipi_call_lock(void);
 extern void unlock_ipi_call_lock(void);
 extern int smp_num_siblings;
 extern void smp_send_reschedule(int cpu);
-void smp_stop_cpu(void);
 
 extern cpumask_t cpu_sibling_map[NR_CPUS];
 extern cpumask_t cpu_core_map[NR_CPUS];
Index: head-2007-03-19/include/xen/evtchn.h
===================================================================
--- head-2007-03-19.orig/include/xen/evtchn.h	2007-03-21 15:31:39.000000000 +0100
+++ head-2007-03-19/include/xen/evtchn.h	2007-03-21 11:49:37.000000000 +0100
@@ -104,6 +104,8 @@ void evtchn_device_upcall(int port);
 void mask_evtchn(int port);
 void unmask_evtchn(int port);
 
+extern void mask_evtchn_local(void);
+
 static inline void clear_evtchn(int port)
 {
 	shared_info_t *s = HYPERVISOR_shared_info;
