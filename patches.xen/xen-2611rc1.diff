From: garloff@suse.de
Subject: Adapt Xen to 2.6.11rc1

This is a quick hack to get xen to compile with 2.6.11rc1.
BEWARE!
It's very unlikely that the resulting kernel will boot.

diff -uNrp linux-2.6.10/arch/xen/i386/kernel/pci-dma.c linux-2.6.10/arch/xen/i386/kernel/pci-dma.c
--- linux-2.6.10/arch/xen/i386/kernel/pci-dma.c	2005-01-21 12:25:48.703898476 +0000
+++ linux-2.6.10/arch/xen/i386/kernel/pci-dma.c	2005-01-21 12:19:32.849125930 +0000
@@ -36,6 +36,7 @@ xen_contig_memory(unsigned long vstart, 
 	 * hypercalls reduced.
 	 */
 	pgd_t         *pgd; 
+	pud_t         *pud; 
 	pmd_t         *pmd;
 	pte_t         *pte;
 	unsigned long  pfn, i, flags;
@@ -47,7 +48,8 @@ xen_contig_memory(unsigned long vstart, 
 	/* 1. Zap current PTEs, giving away the underlying pages. */
 	for (i = 0; i < (1<<order); i++) {
 		pgd = pgd_offset_k(   (vstart + (i*PAGE_SIZE)));
-		pmd = pmd_offset(pgd, (vstart + (i*PAGE_SIZE)));
+		pud = pud_offset(pgd, (vstart + (i*PAGE_SIZE)));
+		pmd = pmd_offset(pud, (vstart + (i*PAGE_SIZE)));
 		pte = pte_offset_kernel(pmd, (vstart + (i*PAGE_SIZE)));
 		pfn = pte->pte_low >> PAGE_SHIFT;
 		queue_l1_entry_update(pte, 0);
@@ -63,7 +65,8 @@ xen_contig_memory(unsigned long vstart, 
 	/* 3. Map the new extent in place of old pages. */
 	for (i = 0; i < (1<<order); i++) {
 		pgd = pgd_offset_k(   (vstart + (i*PAGE_SIZE)));
-		pmd = pmd_offset(pgd, (vstart + (i*PAGE_SIZE)));
+		pud = pud_offset(pgd, (vstart + (i*PAGE_SIZE)));
+		pmd = pmd_offset(pud, (vstart + (i*PAGE_SIZE)));
 		pte = pte_offset_kernel(pmd, (vstart + (i*PAGE_SIZE)));
 		queue_l1_entry_update(
 			pte, ((pfn+i)<<PAGE_SHIFT)|__PAGE_KERNEL);
diff -uNrp linux-2.6.10/arch/xen/i386/mm/fault.c linux-2.6.10/arch/xen/i386/mm/fault.c
--- linux-2.6.10/arch/xen/i386/mm/fault.c	2005-01-21 12:25:48.704898140 +0000
+++ linux-2.6.10/arch/xen/i386/mm/fault.c	2005-01-21 12:19:32.850125594 +0000
@@ -525,6 +525,7 @@ vmalloc_fault:
 		 */
 		int index = pgd_index(address);
 		pgd_t *pgd, *pgd_k;
+		pud_t *pud, *pud_k;
 		pmd_t *pmd, *pmd_k;
 		pte_t *pte_k;
 
@@ -534,13 +535,17 @@ vmalloc_fault:
 		if (!pgd_present(*pgd_k))
 			goto no_context;
 
+		pud = pud_offset(pgd, address);
+		pud_k = pud_offset(pgd_k, address);
+		if (!pud_present(*pud_k))
+			goto no_context;
 		/*
 		 * set_pgd(pgd, *pgd_k); here would be useless on PAE
 		 * and redundant with the set_pmd() on non-PAE.
 		 */
 
-		pmd = pmd_offset(pgd, address);
-		pmd_k = pmd_offset(pgd_k, address);
+		pmd = pmd_offset(pud, address);
+		pmd_k = pmd_offset(pud_k, address);
 		if (!pmd_present(*pmd_k))
 			goto no_context;
 		set_pmd(pmd, *pmd_k);
diff -uNrp linux-2.6.10/arch/xen/i386/mm/hypervisor.c linux-2.6.10/arch/xen/i386/mm/hypervisor.c
--- linux-2.6.10/arch/xen/i386/mm/hypervisor.c	2005-01-21 12:25:48.705897804 +0000
+++ linux-2.6.10/arch/xen/i386/mm/hypervisor.c	2005-01-21 12:19:32.850125594 +0000
@@ -348,6 +348,7 @@ void xen_machphys_update(unsigned long m
 unsigned long allocate_empty_lowmem_region(unsigned long pages)
 {
     pgd_t         *pgd; 
+    pud_t         *pud;
     pmd_t         *pmd;
     pte_t         *pte;
     unsigned long *pfn_array;
@@ -368,7 +369,8 @@ unsigned long allocate_empty_lowmem_regi
     for ( i = 0; i < (1<<order); i++ )
     {
         pgd = pgd_offset_k(   (vstart + (i*PAGE_SIZE)));
-        pmd = pmd_offset(pgd, (vstart + (i*PAGE_SIZE)));
+        pud = pud_offset_k(   (vstart + (i*PAGE_SIZE)));
+        pmd = pmd_offset(pud, (vstart + (i*PAGE_SIZE)));
         pte = pte_offset_kernel(pmd, (vstart + (i*PAGE_SIZE))); 
         pfn_array[i] = pte->pte_low >> PAGE_SHIFT;
         queue_l1_entry_update(pte, 0);
diff -uNrp linux-2.6.10/arch/xen/i386/mm/init.c linux-2.6.10/arch/xen/i386/mm/init.c
--- linux-2.6.10/arch/xen/i386/mm/init.c	2005-01-21 12:25:48.706897468 +0000
+++ linux-2.6.10/arch/xen/i386/mm/init.c	2005-01-21 13:22:24.800435377 +0000
@@ -55,15 +55,18 @@ static int noinline do_test_wp_bit(void)
  */
 static pmd_t * __init one_md_table_init(pgd_t *pgd)
 {
+	pud_t *pud;
 	pmd_t *pmd_table;
 		
 #ifdef CONFIG_X86_PAE
 	pmd_table = (pmd_t *) alloc_bootmem_low_pages(PAGE_SIZE);
 	set_pgd(pgd, __pgd(__pa(pmd_table) | _PAGE_PRESENT));
-	if (pmd_table != pmd_offset(pgd, 0)) 
+	pud = pud_offset(pgd, 0);
+	if (pmd_table != pmd_offset(pud, 0)) 
 		BUG();
 #else
-	pmd_table = pmd_offset(pgd, 0);
+	pud = pud_offset(pgd, 0);
+	pmd_table = pmd_offset(pud, 0);
 #endif
 
 	return pmd_table;
@@ -102,6 +105,7 @@ static pte_t * __init one_page_table_ini
 static void __init page_table_range_init (unsigned long start, unsigned long end, pgd_t *pgd_base)
 {
 	pgd_t *pgd;
+	pud_t *pud;
 	pmd_t *pmd;
 	int pgd_idx, pmd_idx;
 	unsigned long vaddr;
@@ -115,7 +119,8 @@ static void __init page_table_range_init
 		if (pgd_none(*pgd)) 
 			one_md_table_init(pgd);
 
-		pmd = pmd_offset(pgd, vaddr);
+		pud = pud_offset(pgd, vaddr);
+		pmd = pmd_offset(pud, vaddr);
 		for (; (pmd_idx < PTRS_PER_PMD) && (vaddr != end); pmd++, pmd_idx++) {
 			if (pmd_none(*pmd)) 
 				one_page_table_init(pmd);
@@ -128,7 +133,7 @@ static void __init page_table_range_init
 
 static inline int is_kernel_text(unsigned long addr)
 {
-	if (addr >= (unsigned long)_stext && addr <= (unsigned long)__init_end)
+	if (addr >= PAGE_OFFSET && addr <= (unsigned long)__init_end)
 		return 1;
 	return 0;
 }
@@ -249,7 +254,7 @@ EXPORT_SYMBOL(kmap_prot);
 EXPORT_SYMBOL(kmap_pte);
 
 #define kmap_get_fixmap_pte(vaddr)					\
-	pte_offset_kernel(pmd_offset(pgd_offset_k(vaddr), (vaddr)), (vaddr))
+	pte_offset_kernel(pmd_offset(pud_offset(pgd_offset_k(vaddr), vaddr), (vaddr)), (vaddr))
 
 void __init kmap_init(void)
 {
@@ -265,6 +270,7 @@ void __init kmap_init(void)
 void __init permanent_kmaps_init(pgd_t *pgd_base)
 {
 	pgd_t *pgd;
+	pud_t *pud;
 	pmd_t *pmd;
 	pte_t *pte;
 	unsigned long vaddr;
@@ -273,7 +279,8 @@ void __init permanent_kmaps_init(pgd_t *
 	page_table_range_init(vaddr, vaddr + PAGE_SIZE*LAST_PKMAP, pgd_base);
 
 	pgd = swapper_pg_dir + pgd_index(vaddr);
-	pmd = pmd_offset(pgd, vaddr);
+	pud = pud_offset(pgd, vaddr);
+	pmd = pmd_offset(pud, vaddr);
 	pte = pte_offset_kernel(pmd, vaddr);
 	pkmap_page_table = pte;	
 }
@@ -464,7 +471,7 @@ u64 __supported_pte_mask = ~_PAGE_NX;
  * on      Enable
  * off     Disable
  */
-static int __init noexec_setup(char *str)
+void __init noexec_setup(const char *str)
 {
 	if (!strncmp(str, "on",2) && cpu_has_nx) {
 		__supported_pte_mask |= _PAGE_NX;
@@ -473,11 +480,8 @@ static int __init noexec_setup(char *str
 		disable_nx = 1;
 		__supported_pte_mask &= ~_PAGE_NX;
 	}
-	return 1;
 }
 
-__setup("noexec=", noexec_setup);
-
 int nx_enabled = 0;
 #ifdef CONFIG_X86_PAE
 
@@ -607,7 +611,6 @@ void __init test_wp_bit(void)
 static void __init set_max_mapnr_init(void)
 {
 #ifdef CONFIG_HIGHMEM
-	highmem_start_page = pfn_to_page(highstart_pfn);
 	max_mapnr = num_physpages = highend_pfn;
 #else
 	max_mapnr = num_physpages = max_low_pfn;
diff -uNrp linux-2.6.10/arch/xen/i386/mm/ioremap.c linux-2.6.10/arch/xen/i386/mm/ioremap.c
--- linux-2.6.10/arch/xen/i386/mm/ioremap.c	2005-01-21 12:25:48.707897133 +0000
+++ linux-2.6.10/arch/xen/i386/mm/ioremap.c	2005-01-21 12:19:32.852124923 +0000
@@ -118,7 +118,7 @@ void __iomem * __ioremap(unsigned long p
 	/*
 	 * Ok, go for it..
 	 */
-	area = get_vm_area(size, VM_IOREMAP);
+	area = get_vm_area(size, VM_IOREMAP | (flags << 20));
 	if (!area)
 		return NULL;
 	area->phys_addr = phys_addr;
@@ -205,7 +205,7 @@ void iounmap(volatile void __iomem *addr
 		return;
 	} 
 
-	if (p->flags && is_local_lowmem(p->phys_addr)) { 
+	if ((p->flags >> 20) && is_local_lowmem(p->phys_addr)) {
 		change_page_attr(virt_to_page(bus_to_virt(p->phys_addr)),
 				 p->size >> PAGE_SHIFT,
 				 PAGE_KERNEL); 				 
@@ -357,7 +357,13 @@ int __direct_remap_area_pages(struct mm_
 		BUG();
 	spin_lock(&mm->page_table_lock);
 	do {
-		pmd_t *pmd = pmd_alloc(mm, dir, address);
+		pud_t *pud;
+		pmd_t *pmd;
+
+		pud = pud_alloc(mm, dir, address);
+		if (!pud)
+			break;
+		pmd = pmd_alloc(mm, pud, address);
 		if (!pmd)
 			return -ENOMEM;
 		direct_remap_area_pmd(mm, pmd, address, end - address, &v);
diff -uNrp linux-2.6.10/arch/xen/i386/mm/pageattr.c linux-2.6.10/arch/xen/i386/mm/pageattr.c
--- linux-2.6.10/arch/xen/i386/mm/pageattr.c	2005-01-21 12:25:48.708896797 +0000
+++ linux-2.6.10/arch/xen/i386/mm/pageattr.c	2005-01-21 12:19:32.853124587 +0000
@@ -20,10 +20,14 @@ static struct list_head df_list = LIST_H
 pte_t *lookup_address(unsigned long address) 
 { 
 	pgd_t *pgd = pgd_offset_k(address); 
+	pud_t *pud;
 	pmd_t *pmd;
 	if (pgd_none(*pgd))
 		return NULL;
-	pmd = pmd_offset(pgd, address); 	       
+	pud = pud_offset(pgd, address);
+	if (pud_none(*pud))
+		return NULL;
+	pmd = pmd_offset(pud, address); 	       
 	if (pmd_none(*pmd))
 		return NULL;
 	if (pmd_large(*pmd))
@@ -77,9 +81,11 @@ static void set_pmd_pte(pte_t *kpte, uns
 	spin_lock_irqsave(&pgd_lock, flags);
 	for (page = pgd_list; page; page = (struct page *)page->index) {
 		pgd_t *pgd;
+		pud_t *pud;
 		pmd_t *pmd;
 		pgd = (pgd_t *)page_address(page) + pgd_index(address);
-		pmd = pmd_offset(pgd, address);
+		pud = pud_offset(pgd, address);
+		pmd = pmd_offset(pud, address);
 		set_pte_atomic((pte_t *)pmd, pte);
 	}
 	spin_unlock_irqrestore(&pgd_lock, flags);
@@ -92,7 +98,7 @@ static void set_pmd_pte(pte_t *kpte, uns
 static inline void revert_page(struct page *kpte_page, unsigned long address)
 {
 	pte_t *linear = (pte_t *) 
-		pmd_offset(pgd_offset(&init_mm, address), address);
+		pmd_offset(pud_offset(pgd_offset(&init_mm, address), address), address);
 	set_pmd_pte(linear,  address,
 		    pfn_pte((__pa(address) & LARGE_PAGE_MASK) >> PAGE_SHIFT,
 			    PAGE_KERNEL_LARGE));
@@ -105,10 +111,7 @@ __change_page_attr(struct page *page, pg
 	unsigned long address;
 	struct page *kpte_page;
 
-#ifdef CONFIG_HIGHMEM
-	if (page >= highmem_start_page) 
-		BUG(); 
-#endif
+	BUG_ON(PageHighMem(page));
 	address = (unsigned long)page_address(page);
 
 	kpte = lookup_address(address);
@@ -117,27 +120,35 @@ __change_page_attr(struct page *page, pg
 	kpte_page = virt_to_page(kpte);
 	if (pgprot_val(prot) != pgprot_val(PAGE_KERNEL)) { 
 		if ((pte_val(*kpte) & _PAGE_PSE) == 0) { 
-			pte_t old = *kpte;
-			pte_t standard = mk_pte(page, PAGE_KERNEL); 
 			set_pte_batched(kpte, mk_pte(page, prot)); 
-			if (pte_same(old,standard))
-				get_page(kpte_page);
 		} else {
 			struct page *split = split_large_page(address, prot); 
 			if (!split)
 				return -ENOMEM;
-			get_page(kpte_page);
 			set_pmd_pte(kpte,address,mk_pte(split, PAGE_KERNEL));
-		}	
+			kpte_page = split;
+		}
+		get_page(kpte_page);
 	} else if ((pte_val(*kpte) & _PAGE_PSE) == 0) { 
 		set_pte_batched(kpte, mk_pte(page, PAGE_KERNEL));
 		__put_page(kpte_page);
-	}
+	} else
+		BUG();
 
-	if (cpu_has_pse && (page_count(kpte_page) == 1)) {
-		list_add(&kpte_page->lru, &df_list);
-		revert_page(kpte_page, address);
-	} 
+	/*
+	 * If the pte was reserved, it means it was created at boot
+	 * time (not via split_large_page) and in turn we must not
+	 * replace it with a largepage.
+	 */
+	if (!PageReserved(kpte_page)) {
+		/* memleak and potential failed 2M page regeneration */
+		BUG_ON(!page_count(kpte_page));
+
+		if (cpu_has_pse && (page_count(kpte_page) == 1)) {
+			list_add(&kpte_page->lru, &df_list);
+			revert_page(kpte_page, address);
+		}
+	}
 	return 0;
 } 
 
diff -uNrp linux-2.6.10/arch/xen/i386/mm/pgtable.c linux-2.6.10/arch/xen/i386/mm/pgtable.c
--- linux-2.6.10/arch/xen/i386/mm/pgtable.c	2005-01-21 12:25:48.708896797 +0000
+++ linux-2.6.10/arch/xen/i386/mm/pgtable.c	2005-01-21 13:22:59.703701797 +0000
@@ -65,6 +65,7 @@ void show_mem(void)
 static void set_pte_pfn(unsigned long vaddr, unsigned long pfn, pgprot_t flags)
 {
 	pgd_t *pgd;
+	pud_t *pud;
 	pmd_t *pmd;
 	pte_t *pte;
 
@@ -73,7 +74,12 @@ static void set_pte_pfn(unsigned long va
 		BUG();
 		return;
 	}
-	pmd = pmd_offset(pgd, vaddr);
+	pud = pud_offset(pgd, vaddr);
+	if (pud_none(*pud)) {
+		BUG();
+		return;
+	}
+	pmd = pmd_offset(pud, vaddr);
 	if (pmd_none(*pmd)) {
 		BUG();
 		return;
@@ -97,6 +103,7 @@ static void set_pte_pfn_ma(unsigned long
 			   pgprot_t flags)
 {
 	pgd_t *pgd;
+	pud_t *pud;
 	pmd_t *pmd;
 	pte_t *pte;
 
@@ -105,7 +112,12 @@ static void set_pte_pfn_ma(unsigned long
 		BUG();
 		return;
 	}
-	pmd = pmd_offset(pgd, vaddr);
+	pud = pud_offset(pgd, vaddr);
+	if (pud_none(*pud)) {
+		BUG();
+		return;
+	}
+	pmd = pmd_offset(pud, vaddr);
 	if (pmd_none(*pmd)) {
 		BUG();
 		return;
@@ -130,6 +142,7 @@ static void set_pte_pfn_ma(unsigned long
 void set_pmd_pfn(unsigned long vaddr, unsigned long pfn, pgprot_t flags)
 {
 	pgd_t *pgd;
+	pud_t *pud;
 	pmd_t *pmd;
 
 	if (vaddr & (PMD_SIZE-1)) {		/* vaddr is misaligned */
@@ -145,7 +158,8 @@ void set_pmd_pfn(unsigned long vaddr, un
 		printk ("set_pmd_pfn: pgd_none\n");
 		return; /* BUG(); */
 	}
-	pmd = pmd_offset(pgd, vaddr);
+	pud = pud_offset(pgd, vaddr);
+	pmd = pmd_offset(pud, vaddr);
 	set_pmd(pmd, pfn_pmd(pfn, flags));
 	/*
 	 * It's enough to flush this one mapping.
@@ -178,9 +192,8 @@ void __set_fixmap_ma (enum fixed_address
 
 pte_t *pte_alloc_one_kernel(struct mm_struct *mm, unsigned long address)
 {
-	pte_t *pte = (pte_t *)__get_free_page(GFP_KERNEL|__GFP_REPEAT);
+	pte_t *pte = (pte_t *)__get_free_page(GFP_KERNEL|__GFP_REPEAT|__GFP_ZERO);
 	if (pte) {
-		clear_page(pte);
 		make_page_readonly(pte);
 		xen_flush_page_update_queue();
 	}
@@ -216,11 +229,11 @@ struct page *pte_alloc_one(struct mm_str
 #ifdef CONFIG_HIGHPTE
 	struct page *pte;
 
-	pte = alloc_pages(GFP_KERNEL|__GFP_HIGHMEM|__GFP_REPEAT, 0);
+	pte = alloc_pages(GFP_KERNEL|__GFP_HIGHMEM|__GFP_REPEAT|__GFP_ZERO, 0);
 	if (pte == NULL)
 		return pte;
 	if (pte >= highmem_start_page) {
-		clear_highpage(pte);
+		//clear_highpage(pte);
 		return pte;
 	}
 	/* not a highmem page -- free page and grab one from the cache */
@@ -357,14 +370,15 @@ void pgd_free(pgd_t *pgd)
 	if (PTRS_PER_PMD > 1)
 		for (i = 0; i < USER_PTRS_PER_PGD; ++i)
 			kmem_cache_free(pmd_cache, (void *)__va(pgd_val(pgd[i])-1));
-	/* in the non-PAE case, clear_page_tables() clears user pgd entries */
+	/* in the non-PAE case, clear_page_range() clears user pgd entries */
 	kmem_cache_free(pgd_cache, pgd);
 }
 
 void make_lowmem_page_readonly(void *va)
 {
 	pgd_t *pgd = pgd_offset_k((unsigned long)va);
-	pmd_t *pmd = pmd_offset(pgd, (unsigned long)va);
+	pud_t *pud = pud_offset(pgd, (unsigned long)va);
+	pmd_t *pmd = pmd_offset(pud, (unsigned long)va);
 	pte_t *pte = pte_offset_kernel(pmd, (unsigned long)va);
 	queue_l1_entry_update(pte, (*(unsigned long *)pte)&~_PAGE_RW);
 }
@@ -372,7 +386,8 @@ void make_lowmem_page_readonly(void *va)
 void make_lowmem_page_writable(void *va)
 {
 	pgd_t *pgd = pgd_offset_k((unsigned long)va);
-	pmd_t *pmd = pmd_offset(pgd, (unsigned long)va);
+	pud_t *pud = pud_offset(pgd, (unsigned long)va);
+	pmd_t *pmd = pmd_offset(pud, (unsigned long)va);
 	pte_t *pte = pte_offset_kernel(pmd, (unsigned long)va);
 	queue_l1_entry_update(pte, (*(unsigned long *)pte)|_PAGE_RW);
 }
@@ -380,7 +395,8 @@ void make_lowmem_page_writable(void *va)
 void make_page_readonly(void *va)
 {
 	pgd_t *pgd = pgd_offset_k((unsigned long)va);
-	pmd_t *pmd = pmd_offset(pgd, (unsigned long)va);
+	pud_t *pud = pud_offset(pgd, (unsigned long)va);
+	pmd_t *pmd = pmd_offset(pud, (unsigned long)va);
 	pte_t *pte = pte_offset_kernel(pmd, (unsigned long)va);
 	queue_l1_entry_update(pte, (*(unsigned long *)pte)&~_PAGE_RW);
 	if ( (unsigned long)va >= (unsigned long)high_memory )
@@ -397,7 +413,8 @@ void make_page_readonly(void *va)
 void make_page_writable(void *va)
 {
 	pgd_t *pgd = pgd_offset_k((unsigned long)va);
-	pmd_t *pmd = pmd_offset(pgd, (unsigned long)va);
+	pud_t *pud = pud_offset(pgd, (unsigned long)va);
+	pmd_t *pmd = pmd_offset(pud, (unsigned long)va);
 	pte_t *pte = pte_offset_kernel(pmd, (unsigned long)va);
 	queue_l1_entry_update(pte, (*(unsigned long *)pte)|_PAGE_RW);
 	if ( (unsigned long)va >= (unsigned long)high_memory )
diff -uNrp linux-2.6.10/include/asm-xen/asm-i386/page.h linux-2.6.10/include/asm-xen/asm-i386/page.h
--- linux-2.6.10/include/asm-xen/asm-i386/page.h	2005-01-21 12:25:48.709896461 +0000
+++ linux-2.6.10/include/asm-xen/asm-i386/page.h	2005-01-21 13:12:12.899117496 +0000
@@ -81,12 +81,15 @@ typedef struct { unsigned long pte_low, 
 typedef struct { unsigned long long pmd; } pmd_t;
 typedef struct { unsigned long long pgd; } pgd_t;
 typedef struct { unsigned long long pgprot; } pgprot_t;
+#define pmd_val(x)	((x).pmd)
 #define pte_val(x)	((x).pte_low | ((unsigned long long)(x).pte_high << 32))
+#define __pmd(x) ((pmd_t) { (x) } )
 #define HPAGE_SHIFT	21
 #else
 typedef struct { unsigned long pte_low; } pte_t;
-typedef struct { unsigned long pmd; } pmd_t;
 typedef struct { unsigned long pgd; } pgd_t;
+//typedef struct { pgd_t pgd; } pud_t;
+//typedef struct { pud_t pud; } pmd_t;
 typedef struct { unsigned long pgprot; } pgprot_t;
 #define boot_pte_t pte_t /* or would you rather have a typedef */
 #define pte_val(x)	(((x).pte_low & 1) ? machine_to_phys((x).pte_low) : \
@@ -103,28 +106,38 @@ typedef struct { unsigned long pgprot; }
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 #endif
 
-
+#if 0
 static inline unsigned long pmd_val(pmd_t x)
 {
-	unsigned long ret = x.pmd;
-	if (ret) ret = machine_to_phys(ret);
+	unsigned long ret = pmd_val(x);
+	if (ret)
+		ret = machine_to_phys(ret);
 	return ret;
 }
 #define pgd_val(x)	({ BUG(); (unsigned long)0; })
-#define pgprot_val(x)	((x).pgprot)
 
 static inline pte_t __pte(unsigned long x)
 {
-	if (x & 1) x = phys_to_machine(x);
+	if (x & 1) 
+		x = phys_to_machine(x);
 	return ((pte_t) { (x) });
 }
-#define __pte_ma(x)	((pte_t) { (x) } )
 static inline pmd_t __pmd(unsigned long x)
 {
-	if ((x & 1)) x = phys_to_machine(x);
+	if ((x & 1)) 
+		x = phys_to_machine(x);
 	return ((pmd_t) { (x) });
 }
-#define __pgd(x)	({ BUG(); (pgprot_t) { 0 }; })
+#else
+//#include <asm-generic/pgtable-nopmd.h>
+//#include <asm-xen/asm-i386/pgtable.h>
+#endif
+
+#define __pte_ma(x)	((pte_t) { (x) } )
+#define __pte(x) ((pte_t) { (x) } )
+#define pgprot_val(x)	((x).pgprot)
+#define pgd_val(x)	((x).pgd)
+#define __pgd(x) ((pgd_t) { (x) } )
 #define __pgprot(x)	((pgprot_t) { (x) } )
 
 #endif /* !__ASSEMBLY__ */
diff -uNrp linux-2.6.10/include/asm-xen/asm-i386/pgalloc.h linux-2.6.10/include/asm-xen/asm-i386/pgalloc.h
--- linux-2.6.10/include/asm-xen/asm-i386/pgalloc.h	2005-01-21 12:25:48.710896125 +0000
+++ linux-2.6.10/include/asm-xen/asm-i386/pgalloc.h	2005-01-21 13:07:12.532079744 +0000
@@ -7,6 +7,7 @@
 #include <linux/threads.h>
 #include <linux/mm.h>		/* for struct page */
 #include <asm/io.h>		/* for phys_to_virt and page_to_pseudophys */
+#include <asm-generic/pgtable-nopmd.h>
 
 #define pmd_populate_kernel(mm, pmd, pte) \
 		set_pmd(pmd, __pmd(_PAGE_TABLE + __pa(pte)))
@@ -19,6 +20,12 @@ static inline void pmd_populate(struct m
 	flush_page_update_queue();
 }
 /*
+#define pmd_populate(mm, pmd, pte)				\
+	set_pmd(pmd, __pmd(_PAGE_TABLE +			\
+		((unsigned long long)page_to_pfn(pte) <<	\
+			(unsigned long long) PAGE_SHIFT)))
+*/
+/*
  * Allocate and free page tables.
  */
 
@@ -45,10 +52,11 @@ extern void pte_free(struct page *pte);
  * (In the PAE case we free the pmds as part of the pgd.)
  */
 
-#define pmd_alloc_one(mm, addr)		({ BUG(); ((pmd_t *)2); })
-#define pmd_free(x)			do { } while (0)
-#define __pmd_free_tlb(tlb,x)		do { } while (0)
-#define pgd_populate(mm, pmd, pte)	BUG()
+//#define pmd_alloc_one(mm, addr)		({ BUG(); ((pmd_t *)2); })
+//#define pmd_free(x)			do { } while (0)
+//#define __pmd_free_tlb(tlb,x)		do { } while (0)
+//#define pud_populate(mm, pmd, pte)	BUG()
+//#define pgd_populate(mm, pmd, pte)	BUG()
 
 #define check_pgt_cache()	do { } while (0)
 
diff -uNrp linux-2.6.10/include/asm-xen/asm-i386/pgtable-2level.h linux-2.6.10/include/asm-xen/asm-i386/pgtable-2level.h
--- linux-2.6.10/include/asm-xen/asm-i386/pgtable-2level.h	2005-01-21 12:25:48.710896125 +0000
+++ linux-2.6.10/include/asm-xen/asm-i386/pgtable-2level.h	2005-01-21 12:57:41.814898813 +0000
@@ -1,24 +1,14 @@
 #ifndef _I386_PGTABLE_2LEVEL_H
 #define _I386_PGTABLE_2LEVEL_H
 
+#include <asm-generic/pgtable-nopmd.h>
+
 #define pte_ERROR(e) \
 	printk("%s:%d: bad pte %08lx.\n", __FILE__, __LINE__, (e).pte_low)
-#define pmd_ERROR(e) \
-	printk("%s:%d: bad pmd %08lx.\n", __FILE__, __LINE__, pmd_val(e))
 #define pgd_ERROR(e) \
 	printk("%s:%d: bad pgd %08lx.\n", __FILE__, __LINE__, pgd_val(e))
 
 /*
- * The "pgd_xxx()" functions here are trivial for a folded two-level
- * setup: the pgd is never bad, and a pmd always exists (as it's folded
- * into the pgd entry)
- */
-static inline int pgd_none(pgd_t pgd)		{ return 0; }
-static inline int pgd_bad(pgd_t pgd)		{ return 0; }
-static inline int pgd_present(pgd_t pgd)	{ return 1; }
-#define pgd_clear(xp)				do { } while (0)
-
-/*
  * Certain architectures need to do special things when PTEs
  * within a page table are directly modified.  Thus, the following
  * hook is made available.
@@ -27,20 +17,7 @@ static inline int pgd_present(pgd_t pgd)
 	queue_l1_entry_update(pteptr, (pteval).pte_low)
 #define set_pte(pteptr, pteval) (*(pteptr) = pteval)
 #define set_pte_atomic(pteptr, pteval) set_pte(pteptr,pteval)
-/*
- * (pmds are folded into pgds so this doesn't get actually called,
- * but the define is needed for a generic inline function.)
- */
-#define set_pmd(pmdptr, pmdval) xen_l2_entry_update((pmdptr), (pmdval).pmd)
-#define set_pgd(pgdptr, pgdval) ((void)0)
-
-#define pgd_page(pgd) \
-((unsigned long) __va(pgd_val(pgd) & PAGE_MASK))
-
-static inline pmd_t * pmd_offset(pgd_t * dir, unsigned long address)
-{
-	return (pmd_t *) dir;
-}
+#define set_pmd(pmdptr, pmdval) (*(pmdptr) = (pmdval))
 
 /*
  * A note on implementation of this atomic 'get-and-clear' operation.
@@ -98,6 +75,10 @@ static inline pte_t ptep_get_and_clear(p
 #define pfn_pte_ma(pfn, prot)	__pte_ma(((pfn) << PAGE_SHIFT) | pgprot_val(prot))
 #define pfn_pmd(pfn, prot)	__pmd(((pfn) << PAGE_SHIFT) | pgprot_val(prot))
 
+#define pmd_page(pmd) (pfn_to_page(pmd_val(pmd) >> PAGE_SHIFT))
+#define pmd_page_kernel(pmd) \
+ ((unsigned long) __va(pmd_val(pmd) & PAGE_MASK))
+
 /*
  * All present user pages are user-executable:
  */
diff -uNrp linux-2.6.10/include/asm-xen/asm-i386/pgtable.h linux-2.6.10/include/asm-xen/asm-i386/pgtable.h
--- linux-2.6.10/include/asm-xen/asm-i386/pgtable.h	2005-01-21 12:25:48.711895790 +0000
+++ linux-2.6.10/include/asm-xen/asm-i386/pgtable.h	2005-01-21 13:21:25.466382015 +0000
@@ -54,12 +54,12 @@ void paging_init(void);
  */
 #ifdef CONFIG_X86_PAE
 # include <asm/pgtable-3level-defs.h>
+# define PMD_SIZE	(1UL << PMD_SHIFT)
+# define PMD_MASK	(~(PMD_SIZE-1))
 #else
 # include <asm/pgtable-2level-defs.h>
 #endif
 
-#define PMD_SIZE	(1UL << PMD_SHIFT)
-#define PMD_MASK	(~(PMD_SIZE-1))
 #define PGDIR_SIZE	(1UL << PGDIR_SHIFT)
 #define PGDIR_MASK	(~(PGDIR_SIZE-1))
 
@@ -316,20 +316,13 @@ static inline pte_t pte_modify(pte_t pte
 
 #define page_pte(page) page_pte_prot(page, __pgprot(0))
 
-#define pmd_page_kernel(pmd) \
-((unsigned long) __va(pmd_val(pmd) & PAGE_MASK))
-
 #define pmd_clear(xp)	do {					\
 	set_pmd(xp, __pmd(0));					\
 	xen_flush_page_update_queue();				\
 } while (0)
 
-#ifndef CONFIG_DISCONTIGMEM
-#define pmd_page(pmd) (pfn_to_page(pmd_val(pmd) >> PAGE_SHIFT))
-#endif /* !CONFIG_DISCONTIGMEM */
-
 #define pmd_large(pmd) \
-	((pmd_val(pmd) & (_PAGE_PSE|_PAGE_PRESENT)) == (_PAGE_PSE|_PAGE_PRESENT))
+ ((pmd_val(pmd) & (_PAGE_PSE|_PAGE_PRESENT)) == (_PAGE_PSE|_PAGE_PRESENT))
 
 /*
  * the pgd page can be thought of an array like this: pgd_t[PTRS_PER_PGD]
@@ -338,6 +331,7 @@ static inline pte_t pte_modify(pte_t pte
  * control the given virtual address
  */
 #define pgd_index(address) (((address) >> PGDIR_SHIFT) & (PTRS_PER_PGD-1))
+#define pgd_index_k(addr) pgd_index(addr)
 
 /*
  * pgd_offset() returns a (pgd_t *)
@@ -391,6 +385,7 @@ extern pte_t *lookup_address(unsigned lo
  static inline int set_kernel_exec(unsigned long vaddr, int enable) { return 0;}
 #endif
 
+extern void noexec_setup(const char *str);
 #if defined(CONFIG_HIGHPTE)
 #define pte_offset_map(dir, address) \
 	((pte_t *)kmap_atomic_pte(pmd_page(*(dir)),KM_PTE0) + \
@@ -463,7 +458,8 @@ void make_pages_writable(void *va, unsig
 #define arbitrary_virt_to_machine(__va)					\
 ({									\
 	pgd_t *__pgd = pgd_offset_k((unsigned long)(__va));		\
-	pmd_t *__pmd = pmd_offset(__pgd, (unsigned long)(__va));	\
+	pud_t *__pud = pud_offset(__pgd, (unsigned long)(__va));	\
+	pmd_t *__pmd = pmd_offset(__pud, (unsigned long)(__va));	\
 	pte_t *__pte = pte_offset_kernel(__pmd, (unsigned long)(__va));	\
 	unsigned long __pa = (*(unsigned long *)__pte) & PAGE_MASK;	\
 	__pa | ((unsigned long)(__va) & (PAGE_SIZE-1));			\
diff -uNrp linux-2.6.10/arch/xen/i386/kernel/i386_ksyms.c linux-2.6.10.new/arch/xen/i386/kernel/i386_ksyms.c
--- linux-2.6.10/arch/xen/i386/kernel/i386_ksyms.c	2005-01-21 14:18:11.354095655 +0000
+++ linux-2.6.10.new/arch/xen/i386/kernel/i386_ksyms.c	2005-01-21 14:01:23.239612746 +0000
@@ -61,7 +61,6 @@ extern unsigned long get_cmos_time(void)
 
 /* platform dependent support */
 EXPORT_SYMBOL(boot_cpu_data);
-EXPORT_SYMBOL(MCA_bus);
 #ifdef CONFIG_DISCONTIGMEM
 EXPORT_SYMBOL(node_data);
 EXPORT_SYMBOL(physnode_map);
diff -uNrp linux-2.6.10/arch/xen/i386/kernel/setup.c linux-2.6.10.new/arch/xen/i386/kernel/setup.c
--- linux-2.6.10/arch/xen/i386/kernel/setup.c	2005-01-21 14:18:11.362092967 +0000
+++ linux-2.6.10.new/arch/xen/i386/kernel/setup.c	2005-01-21 14:08:47.023689410 +0000
@@ -96,6 +96,9 @@ unsigned int mca_pentium_flag;
 /* For PCI or other memory-mapped resources */
 unsigned long pci_mem_start = 0x10000000;
 
+/* Boot loader ID as an integer, for the benefit of proc_dointvec */
+int bootloader_type;
+
 /* user-defined highmem size */
 static unsigned int highmem_pages = -1;
 
@@ -1373,6 +1376,7 @@ void __init setup_arch(char **cmdline_p)
 		BIOS_revision = SYS_DESC_TABLE.table[2];
 	}
 	aux_device_present = AUX_DEVICE_INFO;
+	bootloader_type = LOADER_TYPE;
 
 #ifdef CONFIG_XEN_PHYSDEV_ACCESS
 	/* This is drawn from a dump from vgacon:startup in standard Linux. */
Files linux-2.6.10/arch/xen/i386/kernel/vsyscall-int80.so and linux-2.6.10.new/arch/xen/i386/kernel/vsyscall-int80.so differ
Files linux-2.6.10/arch/xen/i386/kernel/vsyscall-sysenter.so and linux-2.6.10.new/arch/xen/i386/kernel/vsyscall-sysenter.so differ
diff -uNrp linux-2.6.10/arch/xen/i386/mm/highmem.c linux-2.6.10.new/arch/xen/i386/mm/highmem.c
--- linux-2.6.10/arch/xen/i386/mm/highmem.c	2005-01-21 14:18:11.371089943 +0000
+++ linux-2.6.10.new/arch/xen/i386/mm/highmem.c	2005-01-21 14:07:21.851273147 +0000
@@ -3,7 +3,7 @@
 void *kmap(struct page *page)
 {
 	might_sleep();
-	if (page < highmem_start_page)
+	if (!PageHighMem(page))
 		return page_address(page);
 	return kmap_high(page);
 }
@@ -12,7 +12,7 @@ void kunmap(struct page *page)
 {
 	if (in_interrupt())
 		BUG();
-	if (page < highmem_start_page)
+	if (!PageHighMem(page))
 		return;
 	kunmap_high(page);
 }
@@ -32,7 +32,7 @@ void *kmap_atomic(struct page *page, enu
 
 	/* even !CONFIG_PREEMPT needs this, for in_atomic in do_page_fault */
 	inc_preempt_count();
-	if (page < highmem_start_page)
+	if (!PageHighMem(page))
 		return page_address(page);
 
 	idx = type + KM_TYPE_NR*smp_processor_id();
@@ -55,7 +55,7 @@ void *kmap_atomic_pte(struct page *page,
 
 	/* even !CONFIG_PREEMPT needs this, for in_atomic in do_page_fault */
 	inc_preempt_count();
-	if (page < highmem_start_page)
+	if (!PageHighMem(page))
 		return page_address(page);
 
 	idx = type + KM_TYPE_NR*smp_processor_id();
diff -uNrp linux-2.6.10/include/asm-xen/asm-i386/pgtable-2level-defs.h linux-2.6.10.new/include/asm-xen/asm-i386/pgtable-2level-defs.h
--- linux-2.6.10/include/asm-xen/asm-i386/pgtable-2level-defs.h	2005-01-21 14:18:11.421073143 +0000
+++ linux-2.6.10.new/include/asm-xen/asm-i386/pgtable-2level-defs.h	2005-01-21 14:00:53.418619049 +0000
@@ -13,8 +13,6 @@
  * the i386 is two-level, so we don't really have any
  * PMD directory physically.
  */
-#define PMD_SHIFT	22
-#define PTRS_PER_PMD	1
 
 #define PTRS_PER_PTE	1024
 
diff -uNrp linux-2.6.10/include/asm-xen/asm-i386/processor.h linux-2.6.10.new/include/asm-xen/asm-i386/processor.h
--- linux-2.6.10/include/asm-xen/asm-i386/processor.h	2005-01-21 14:18:11.424072135 +0000
+++ linux-2.6.10.new/include/asm-xen/asm-i386/processor.h	2005-01-21 14:09:50.386424415 +0000
@@ -65,6 +65,7 @@ struct cpuinfo_x86 {
 	int	f00f_bug;
 	int	coma_bug;
 	unsigned long loops_per_jiffy;
+	unsigned char x86_num_cores;
 } __attribute__((__aligned__(SMP_CACHE_BYTES)));
 
 #define X86_VENDOR_INTEL 0
@@ -104,6 +105,12 @@ extern void print_cpu_info(struct cpuinf
 extern unsigned int init_intel_cacheinfo(struct cpuinfo_x86 *c);
 extern void dodgy_tsc(void);
 
+#ifdef CONFIG_X86_HT
+extern void detect_ht(struct cpuinfo_x86 *c);
+#else
+static inline void detect_ht(struct cpuinfo_x86 *c) {}
+#endif
+
 /*
  * EFLAGS bits
  */
@@ -270,11 +277,6 @@ static inline void clear_in_cr4 (unsigne
 	outb((data), 0x23); \
 } while (0)
 
-/*
- * Bus types (default is ISA, but people can check others with these..)
- */
-extern int MCA_bus;
-
 static inline void __monitor(const void *eax, unsigned long ecx,
 		unsigned long edx)
 {
@@ -298,6 +300,8 @@ extern unsigned int machine_id;
 extern unsigned int machine_submodel_id;
 extern unsigned int BIOS_revision;
 extern unsigned int mca_pentium_flag;
+/* Boot loader type from the setup header */
+extern int bootloader_type;
 
 /*
  * User space process size: 3GB (default).
diff -uNrp linux-2.6.10/include/asm-xen/hypervisor.h linux-2.6.10.new/include/asm-xen/hypervisor.h
--- linux-2.6.10/include/asm-xen/hypervisor.h	2005-01-21 14:18:11.434068775 +0000
+++ linux-2.6.10.new/include/asm-xen/hypervisor.h	2005-01-21 14:00:36.736216705 +0000
@@ -38,6 +38,7 @@
 #include <asm-xen/xen-public/io/domain_controller.h>
 #include <asm/ptrace.h>
 #include <asm/page.h>
+#include <asm-generic/pgtable-nopmd.h>
 
 /* arch/xen/i386/kernel/setup.c */
 union xen_start_info_union
--- linux-2.6.10/arch/xen/i386/Kconfig.orig	2005-01-21 14:27:28.502830000 +0000
+++ linux-2.6.10/arch/xen/i386/Kconfig	2005-01-21 14:46:36.218201686 +0000
@@ -253,6 +253,10 @@ config RWSEM_XCHGADD_ALGORITHM
 	depends on !M386
 	default y
 
+config GENERIC_CALIBRATE_DELAY
+	bool
+	default y
+
 config X86_PPRO_FENCE
 	bool
 	depends on M686 || M586MMX || M586TSC || M586 || M486 || M386
