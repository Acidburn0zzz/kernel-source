Subject: xen3: 2.6.13 adaptions (i386).
From: jbeulich@novell.com

$subject says all.

Signed-off-by: Gerd Knorr <kraxel@suse.de>
Index: linux-2.6.12/include/asm-xen/asm-i386/io.h
===================================================================
--- linux-2.6.12.orig/include/asm-xen/asm-i386/io.h
+++ linux-2.6.12/include/asm-xen/asm-i386/io.h
@@ -361,9 +361,9 @@ static inline unsigned type in##bwl(int 
 }
 #endif
 
 
-#if __UNSAFE_IO__
+#ifdef __UNSAFE_IO__
 #define ____BUILDIO(bwl,bw,type) \
 static inline void out##bwl##_local(unsigned type value, int port) { \
 	__asm__ __volatile__("out" #bwl " %" #bw "0, %w1" : : "a"(value), "Nd"(port)); \
 } \
Index: linux-2.6.12/drivers/xen/blktap/blktap_controlmsg.c
===================================================================
--- linux-2.6.12.orig/drivers/xen/blktap/blktap_controlmsg.c
+++ linux-2.6.12/drivers/xen/blktap/blktap_controlmsg.c
@@ -7,10 +7,10 @@
  * Copyright (c) 2004, Andrew Warfield
  *
  */
  
-#include "blktap.h"
 #include <asm-xen/evtchn.h>
+#include "blktap.h"
 
 static char *blkif_state_name[] = {
     [BLKIF_STATE_CLOSED]       = "closed",
     [BLKIF_STATE_DISCONNECTED] = "disconnected",
Index: linux-2.6.12/arch/xen/kernel/vmlinux-i386.lds.S
===================================================================
--- /dev/null
+++ linux-2.6.12/arch/xen/kernel/vmlinux-i386.lds.S
@@ -0,0 +1,134 @@
+/* ld script to make i386 Linux kernel
+ * Written by Martin Mares <mj@atrey.karlin.mff.cuni.cz>;
+ */
+
+#include <asm-generic/vmlinux.lds.h>
+#include <asm/thread_info.h>
+#include <asm/page.h>
+
+OUTPUT_FORMAT("elf32-i386", "elf32-i386", "elf32-i386")
+OUTPUT_ARCH(i386)
+ENTRY(startup_32)
+jiffies = jiffies_64;
+SECTIONS
+{
+  . = __PAGE_OFFSET + 0x100000;
+  /* read-only */
+  _text = .;			/* Text and read-only data */
+  .text : {
+	*(.text)
+	SCHED_TEXT
+	LOCK_TEXT
+	*(.fixup)
+	*(.gnu.warning)
+	} = 0x9090
+
+  _etext = .;			/* End of text section */
+
+  . = ALIGN(16);		/* Exception table */
+  __start___ex_table = .;
+  __ex_table : { *(__ex_table) }
+  __stop___ex_table = .;
+
+  RODATA
+
+  /* writeable */
+  .data : {			/* Data */
+	*(.data)
+	CONSTRUCTORS
+	}
+
+  . = ALIGN(4096);
+  __nosave_begin = .;
+  .data_nosave : { *(.data.nosave) }
+  . = ALIGN(4096);
+  __nosave_end = .;
+
+  . = ALIGN(4096);
+  .data.page_aligned : { *(.data.idt) }
+
+  . = ALIGN(32);
+  .data.cacheline_aligned : { *(.data.cacheline_aligned) }
+
+  _edata = .;			/* End of data section */
+
+  . = ALIGN(THREAD_SIZE);	/* init_task */
+  .data.init_task : { *(.data.init_task) }
+
+  /* will be freed after init */
+  . = ALIGN(4096);		/* Init code and data */
+  __init_begin = .;
+  .init.text : {
+	_sinittext = .;
+	*(.init.text)
+	_einittext = .;
+  }
+  .init.data : { *(.init.data) }
+  . = ALIGN(16);
+  __setup_start = .;
+  .init.setup : { *(.init.setup) }
+  __setup_end = .;
+  __initcall_start = .;
+  .initcall.init : {
+	*(.initcall1.init)
+	*(.initcall2.init)
+	*(.initcall3.init)
+	*(.initcall4.init)
+	*(.initcall5.init)
+	*(.initcall6.init)
+	*(.initcall7.init)
+  }
+  __initcall_end = .;
+  __con_initcall_start = .;
+  .con_initcall.init : { *(.con_initcall.init) }
+  __con_initcall_end = .;
+  SECURITY_INIT
+  . = ALIGN(4);
+  __alt_instructions = .;
+  .altinstructions : { *(.altinstructions) }
+  __alt_instructions_end = .;
+ .altinstr_replacement : { *(.altinstr_replacement) }
+  /* .exit.text is discard at runtime, not link time, to deal with references
+     from .altinstructions and .eh_frame */
+  .exit.text : { *(.exit.text) }
+  .exit.data : { *(.exit.data) }
+  . = ALIGN(4096);
+  __initramfs_start = .;
+  .init.ramfs : { *(.init.ramfs) }
+  __initramfs_end = .;
+  . = ALIGN(32);
+  __per_cpu_start = .;
+  .data.percpu  : { *(.data.percpu) }
+  __per_cpu_end = .;
+  . = ALIGN(4096);
+  __init_end = .;
+  /* freed after init ends here */
+
+  __bss_start = .;		/* BSS */
+  .bss : {
+	*(.bss.page_aligned)
+	*(.bss)
+  }
+  . = ALIGN(4);
+  __bss_stop = .;
+
+  _end = . ;
+
+  /* This is where the kernel creates the early boot page tables */
+  . = ALIGN(4096);
+  pg0 = .;
+
+  /* Sections to be discarded */
+  /DISCARD/ : {
+	*(.exitcall.exit)
+	}
+
+  /* Stabs debugging sections.  */
+  .stab 0 : { *(.stab) }
+  .stabstr 0 : { *(.stabstr) }
+  .stab.excl 0 : { *(.stab.excl) }
+  .stab.exclstr 0 : { *(.stab.exclstr) }
+  .stab.index 0 : { *(.stab.index) }
+  .stab.indexstr 0 : { *(.stab.indexstr) }
+  .comment 0 : { *(.comment) }
+}
Index: linux-2.6.12/arch/xen/kernel/Makefile
===================================================================
--- linux-2.6.12.orig/arch/xen/kernel/Makefile
+++ linux-2.6.12/arch/xen/kernel/Makefile
@@ -6,9 +6,9 @@ XENARCH	:= $(subst ",,$(CONFIG_XENARCH))
 
 CPPFLAGS_vmlinux.lds += -U$(XENARCH)
 
 $(obj)/vmlinux.lds.S:
-	@ln -fsn $(srctree)/arch/$(XENARCH)/kernel/vmlinux.lds.S $@
+	@ln -fsn $(srctree)/arch/xen/kernel/vmlinux-$(XENARCH).lds.S $@
 
 extra-y += vmlinux.lds
 
 obj-y   := ctrl_if.o evtchn.o fixup.o reboot.o gnttab.o devmem.o
Index: linux-2.6.12/arch/i386/power/cpu.c
===================================================================
--- linux-2.6.12.orig/arch/i386/power/cpu.c
+++ linux-2.6.12/arch/i386/power/cpu.c
@@ -83,9 +83,12 @@ static void fix_processor_context(void)
 	int cpu = smp_processor_id();
 	struct tss_struct * t = &per_cpu(init_tss, cpu);
 
 	set_tss_desc(cpu,t);	/* This just modifies memory; should not be necessary. But... This is necessary, because 386 hardware has concept of busy TSS or some similar stupidity. */
+ #ifndef CONFIG_XEN
+ 	/* set_tss_desc already clears the busy bit on xen*/
         per_cpu(cpu_gdt_table, cpu)[GDT_ENTRY_TSS].b &= 0xfffffdff;
+ #endif
 
 	load_TR_desc();				/* This does ltr */
 	load_LDT(&current->active_mm->context);	/* This does lldt */
 
Index: linux-2.6.12/arch/xen/kernel/vmlinux-x86_64.lds.S
===================================================================
--- /dev/null
+++ linux-2.6.12/arch/xen/kernel/vmlinux-x86_64.lds.S
@@ -0,0 +1,169 @@
+/* ld script to make x86-64 Linux kernel
+ * Written by Martin Mares <mj@atrey.karlin.mff.cuni.cz>;
+ */
+
+#include <asm-generic/vmlinux.lds.h>
+#include <linux/config.h>
+
+OUTPUT_FORMAT("elf64-x86-64", "elf64-x86-64", "elf64-x86-64")
+OUTPUT_ARCH(i386:x86-64)
+ENTRY(phys_startup_64)
+jiffies_64 = jiffies;
+SECTIONS
+{
+  . = 0xffffffff80100000;
+  phys_startup_64 = startup_64 - LOAD_OFFSET;
+  _text = .;			/* Text and read-only data */
+  .text : {
+	*(.text)
+	SCHED_TEXT
+	LOCK_TEXT
+	*(.fixup)
+	*(.gnu.warning)
+	} = 0x9090
+  .text.lock : { *(.text.lock) }	/* out-of-line lock text */
+
+  _etext = .;			/* End of text section */
+
+  . = ALIGN(16);		/* Exception table */
+  __start___ex_table = .;
+  __ex_table : { *(__ex_table) }
+  __stop___ex_table = .;
+
+  RODATA
+
+  .data : {			/* Data */
+	*(.data)
+	CONSTRUCTORS
+	}
+
+  _edata = .;			/* End of data section */
+
+  __bss_start = .;		/* BSS */
+  .bss : {
+	*(.bss.page_aligned)
+	*(.bss)
+	}
+  __bss_end = .;
+
+  . = ALIGN(CONFIG_X86_L1_CACHE_BYTES);
+  .data.cacheline_aligned : { *(.data.cacheline_aligned) }
+
+  . = ALIGN(CONFIG_X86_L1_CACHE_BYTES);
+  .data.read_mostly : AT(ADDR(.data.read_mostly) - LOAD_OFFSET) {
+  	*(.data.read_mostly)
+  }
+
+#define AFTER(x)      BINALIGN(LOADADDR(x) + SIZEOF(x), 16)
+#define BINALIGN(x,y) (((x) + (y) - 1)  & ~((y) - 1))
+#define CACHE_ALIGN(x) BINALIGN(x, CONFIG_X86_L1_CACHE_BYTES)
+
+  .vsyscall_0 -10*1024*1024: AT ((LOADADDR(.data.cacheline_aligned) + SIZEOF(.data.cacheline_aligned) + 4095) & ~(4095)) { *(.vsyscall_0) }
+  __vsyscall_0 = LOADADDR(.vsyscall_0);
+  . = ALIGN(CONFIG_X86_L1_CACHE_BYTES);
+  .xtime_lock : AT CACHE_ALIGN(AFTER(.vsyscall_0)) { *(.xtime_lock) }
+  xtime_lock = LOADADDR(.xtime_lock);
+  .vxtime : AT AFTER(.xtime_lock) { *(.vxtime) }
+  vxtime = LOADADDR(.vxtime);
+  .wall_jiffies : AT AFTER(.vxtime) { *(.wall_jiffies) }
+  wall_jiffies = LOADADDR(.wall_jiffies);
+  .sys_tz : AT AFTER(.wall_jiffies) { *(.sys_tz) }
+  sys_tz = LOADADDR(.sys_tz);
+  .sysctl_vsyscall : AT AFTER(.sys_tz) { *(.sysctl_vsyscall) }
+  sysctl_vsyscall = LOADADDR(.sysctl_vsyscall);
+  .xtime : AT AFTER(.sysctl_vsyscall) { *(.xtime) }
+  xtime = LOADADDR(.xtime);
+  . = ALIGN(CONFIG_X86_L1_CACHE_BYTES);
+  .jiffies : AT CACHE_ALIGN(AFTER(.xtime)) { *(.jiffies) }
+  jiffies = LOADADDR(.jiffies);
+  .vsyscall_1 ADDR(.vsyscall_0) + 1024: AT (LOADADDR(.vsyscall_0) + 1024) { *(.vsyscall_1) }
+  . = LOADADDR(.vsyscall_0) + 4096;
+
+  . = ALIGN(8192);		/* init_task */
+  .data.init_task : { *(.data.init_task) }
+
+  . = ALIGN(4096);
+  .data.page_aligned : { *(.data.page_aligned) }
+
+  . = ALIGN(4096);		/* Init code and data */
+  __init_begin = .;
+  .init.text : {
+	_sinittext = .;
+	*(.init.text)
+	_einittext = .;
+  }
+  __initdata_begin = .;
+  .init.data : { *(.init.data) }
+  __initdata_end = .;
+  . = ALIGN(16);
+  __setup_start = .;
+  .init.setup : { *(.init.setup) }
+  __setup_end = .;
+  __initcall_start = .;
+  .initcall.init : {
+	*(.initcall1.init)
+	*(.initcall2.init)
+	*(.initcall3.init)
+	*(.initcall4.init)
+	*(.initcall5.init)
+	*(.initcall6.init)
+	*(.initcall7.init)
+  }
+  __initcall_end = .;
+  __con_initcall_start = .;
+  .con_initcall.init : { *(.con_initcall.init) }
+  __con_initcall_end = .;
+  SECURITY_INIT
+  . = ALIGN(8);
+  __alt_instructions = .;
+  .altinstructions : { *(.altinstructions) }
+  __alt_instructions_end = .;
+ .altinstr_replacement : { *(.altinstr_replacement) }
+  /* .exit.text is discard at runtime, not link time, to deal with references
+     from .altinstructions and .eh_frame */
+  .exit.text : { *(.exit.text) }
+  .exit.data : { *(.exit.data) }
+  . = ALIGN(4096);
+  __initramfs_start = .;
+  .init.ramfs : { *(.init.ramfs) }
+  __initramfs_end = .;
+  . = ALIGN(32);
+  __per_cpu_start = .;
+  .data.percpu  : { *(.data.percpu) }
+  __per_cpu_end = .;
+  . = ALIGN(4096);
+  __init_end = .;
+
+  . = ALIGN(4096);
+  __nosave_begin = .;
+  .data_nosave : { *(.data.nosave) }
+  . = ALIGN(4096);
+  __nosave_end = .;
+
+  _end = . ;
+
+  /* Sections to be discarded */
+  /DISCARD/ : {
+	*(.exitcall.exit)
+#ifndef CONFIG_DEBUG_INFO
+	*(.eh_frame)
+#endif
+	}
+
+  /* DWARF 2 */
+  .debug_info     0 : { *(.debug_info) }
+  .debug_abbrev   0 : { *(.debug_abbrev) }
+  .debug_line     0 : { *(.debug_line) }
+  .debug_frame    0 : { *(.debug_frame) }
+  .debug_str      0 : { *(.debug_str) }
+  .debug_loc      0 : { *(.debug_loc) }
+  .debug_macinfo  0 : { *(.debug_macinfo) }
+  /* SGI/MIPS DWARF 2 extensions */
+  .debug_weaknames 0 : { *(.debug_weaknames) }
+  .debug_funcnames 0 : { *(.debug_funcnames) }
+  .debug_typenames 0 : { *(.debug_typenames) }
+  .debug_varnames  0 : { *(.debug_varnames) }
+
+
+  .comment 0 : { *(.comment) }
+}
Index: linux-2.6.12/arch/xen/x86_64/kernel/head64.c
===================================================================
--- linux-2.6.12.orig/arch/xen/x86_64/kernel/head64.c
+++ linux-2.6.12/arch/xen/x86_64/kernel/head64.c
@@ -88,8 +88,9 @@ extern char _end[];
 
 void __init x86_64_start_kernel(char * real_mode_data)
 {
 	int i;
+	char *s;
 
         phys_to_machine_mapping = (u32 *)xen_start_info.mfn_list;
         start_pfn = (__pa(xen_start_info.pt_base) >> PAGE_SHIFT) +  xen_start_info.nr_pt_frames;
 
Index: linux-2.6.12/arch/xen/Kconfig.drivers
===================================================================
--- linux-2.6.12.orig/arch/xen/Kconfig.drivers
+++ linux-2.6.12/arch/xen/Kconfig.drivers
@@ -32,8 +32,9 @@ endif
 
 source "net/Kconfig"
 
 if XEN_PHYSDEV_ACCESS
+source "drivers/net/Kconfig"
 source "drivers/isdn/Kconfig"
 source "drivers/telephony/Kconfig"
 source "drivers/input/Kconfig"
 source "drivers/char/Kconfig"
Index: linux-2.6.12/arch/xen/x86_64/kernel/entry.S
===================================================================
--- linux-2.6.12.orig/arch/xen/x86_64/kernel/entry.S
+++ linux-2.6.12/arch/xen/x86_64/kernel/entry.S
@@ -750,12 +750,12 @@ ecrit:  /**** END OF CRITICAL REGION ***
 	
 # Hypervisor uses this for application faults while it executes.
 ENTRY(failsafe_callback)
 	addq $0x10,%rsp /* skip rcx and r11 */	
-1:	movl (%rsp),%ds
-2:	movl 8(%rsp),%es
-3:	movl 16(%rsp),%fs
-4:	movl 24(%rsp),%gs
+1:	mov  (%rsp),%ds
+2:	mov  8(%rsp),%es
+3:	mov  16(%rsp),%fs
+4:	mov  24(%rsp),%gs
 	addq $0x20,%rsp /* skip the above selectors */		
 	SAVE_ALL
 	jmp  error_exit
 .section .fixup,"ax";	\
Index: linux-2.6.12/include/asm-xen/asm-x86_64/mmu_context.h
===================================================================
--- linux-2.6.12.orig/include/asm-xen/asm-x86_64/mmu_context.h
+++ linux-2.6.12/include/asm-xen/asm-x86_64/mmu_context.h
@@ -32,22 +32,22 @@ static inline void __prepare_arch_switch
 	 * Save away %es, %ds, %fs and %gs. Must happen before reload
 	 * of cr3/ldt (i.e., not in __switch_to).
 	 */
 	__asm__ __volatile__ (
-		"movl %%es,%0 ; movl %%ds,%1 ; movl %%fs,%2 ; movl %%gs,%3"
+		"mov %%es,%0 ; mov %%ds,%1 ; mov %%fs,%2 ; mov %%gs,%3"
 		: "=m" (current->thread.es),
 		  "=m" (current->thread.ds),
 		  "=m" (current->thread.fsindex),
 		  "=m" (current->thread.gsindex) );
 
 	if (current->thread.ds)
-		__asm__ __volatile__ ( "movl %0,%%ds" : : "r" (0) );
+		__asm__ __volatile__ ( "mov %0,%%ds" : : "r" (0) );
 
 	if (current->thread.es)
-		__asm__ __volatile__ ( "movl %0,%%es" : : "r" (0) );
+		__asm__ __volatile__ ( "mov %0,%%es" : : "r" (0) );
 
 	if (current->thread.fsindex) {
-		__asm__ __volatile__ ( "movl %0,%%fs" : : "r" (0) );
+		__asm__ __volatile__ ( "mov %0,%%fs" : : "r" (0) );
 		current->thread.fs = 0;
 	}
 
 	if (current->thread.gsindex) {
@@ -113,9 +113,9 @@ static inline void switch_mm(struct mm_s
 }
 
 #define deactivate_mm(tsk,mm)	do { \
 	load_gs_index(0); \
-	asm volatile("movl %0,%%fs"::"r"(0));  \
+	asm volatile("mov %0,%%fs"::"r"(0));  \
 } while(0)
 
 #define activate_mm(prev, next) do {		\
 	switch_mm((prev),(next),NULL);		\
