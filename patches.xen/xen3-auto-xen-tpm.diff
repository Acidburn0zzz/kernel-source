Subject: xen3 xen-tpm
From: jbeulich@novell.com

autogenerated from http://xenbits.xensource.com/xen-unstable.hg (tip 8819)

--- linux-2.6.16-rc2/drivers/char/tpm/Makefile	2006-02-03 16:29:51.000000000 +0100
+++ xenlinux-2.6.16-rc2/drivers/char/tpm/Makefile	2006-02-06 09:28:08.000000000 +0100
@@ -8,3 +8,4 @@ endif
 obj-$(CONFIG_TCG_NSC) += tpm_nsc.o
 obj-$(CONFIG_TCG_ATMEL) += tpm_atmel.o
 obj-$(CONFIG_TCG_INFINEON) += tpm_infineon.o
+obj-$(CONFIG_TCG_XEN) += tpm_xen.o
--- linux-2.6.16-rc2/drivers/char/tpm/tpm.c	2006-02-03 16:29:51.000000000 +0100
+++ xenlinux-2.6.16-rc2/drivers/char/tpm/tpm.c	2006-02-08 09:43:29.000000000 +0100
@@ -30,7 +30,8 @@
 
 enum tpm_const {
 	TPM_MINOR = 224,	/* officially assigned */
-	TPM_BUFSIZE = 2048,
+	TPM_MIN_BUFSIZE = 2048,
+	TPM_MAX_BUFSIZE = 64 * 1024,
 	TPM_NUM_DEVICES = 256,
 	TPM_NUM_MASK_ENTRIES = TPM_NUM_DEVICES / (8 * sizeof(int))
 };
@@ -52,14 +53,14 @@ static void timeout_work(void * ptr)
 
 	down(&chip->buffer_mutex);
 	atomic_set(&chip->data_pending, 0);
-	memset(chip->data_buffer, 0, TPM_BUFSIZE);
+	memset(chip->data_buffer, 0, chip->vendor->buffersize);
 	up(&chip->buffer_mutex);
 }
 
 /*
  * Internal kernel interface to transmit TPM commands
  */
-static ssize_t tpm_transmit(struct tpm_chip *chip, const char *buf,
+static ssize_t tpm_transmit(struct tpm_chip * chip, const char *buf,
 			    size_t bufsiz)
 {
 	ssize_t rc;
@@ -351,7 +352,7 @@ int tpm_open(struct inode *inode, struct
 
 	spin_unlock(&driver_lock);
 
-	chip->data_buffer = kmalloc(TPM_BUFSIZE * sizeof(u8), GFP_KERNEL);
+	chip->data_buffer = kmalloc(chip->vendor->buffersize * sizeof(u8), GFP_KERNEL);
 	if (chip->data_buffer == NULL) {
 		chip->num_opens--;
 		put_device(chip->dev);
@@ -399,8 +400,8 @@ ssize_t tpm_write(struct file *file, con
 
 	down(&chip->buffer_mutex);
 
-	if (in_size > TPM_BUFSIZE)
-		in_size = TPM_BUFSIZE;
+	if (in_size > chip->vendor->buffersize)
+		in_size = chip->vendor->buffersize;
 
 	if (copy_from_user
 	    (chip->data_buffer, (void __user *) buf, in_size)) {
@@ -409,9 +410,11 @@ ssize_t tpm_write(struct file *file, con
 	}
 
 	/* atomic tpm command send and result receive */
-	out_size = tpm_transmit(chip, chip->data_buffer, TPM_BUFSIZE);
+	out_size = tpm_transmit(chip, chip->data_buffer, 
+	                        chip->vendor->buffersize);
 
 	atomic_set(&chip->data_pending, out_size);
+	atomic_set(&chip->data_position, 0);
 	up(&chip->buffer_mutex);
 
 	/* Set a timeout by which the reader must come claim the result */
@@ -427,20 +430,34 @@ ssize_t tpm_read(struct file * file, cha
 {
 	struct tpm_chip *chip = file->private_data;
 	int ret_size;
+	int pos, pending = 0;
 
 	del_singleshot_timer_sync(&chip->user_read_timer);
 	flush_scheduled_work();
 	ret_size = atomic_read(&chip->data_pending);
-	atomic_set(&chip->data_pending, 0);
 	if (ret_size > 0) {	/* relay data */
 		if (size < ret_size)
 			ret_size = size;
 
+		pos = atomic_read(&chip->data_position);
+
 		down(&chip->buffer_mutex);
-		if (copy_to_user(buf, chip->data_buffer, ret_size))
+		if (copy_to_user(buf, &chip->data_buffer[pos], ret_size)) {
 			ret_size = -EFAULT;
+		} else {
+			pending = atomic_read(&chip->data_pending) - ret_size;
+			if ( pending ) {
+				atomic_set( &chip->data_pending, pending );
+				atomic_set( &chip->data_position, pos+ret_size );
+			}
+		}
 		up(&chip->buffer_mutex);
 	}
+	
+	if ( ret_size <= 0 || pending == 0 ) {
+		atomic_set( &chip->data_pending, 0 );
+		del_singleshot_timer_sync(&chip->user_read_timer);
+	}
 
 	return ret_size;
 }
@@ -544,6 +561,12 @@ int tpm_register_hardware(struct device 
 	chip->user_read_timer.data = (unsigned long) chip;
 
 	chip->vendor = entry;
+	
+	if (entry->buffersize < TPM_MIN_BUFSIZE) {
+		entry->buffersize = TPM_MIN_BUFSIZE;
+	} else if (entry->buffersize > TPM_MAX_BUFSIZE) {
+		entry->buffersize = TPM_MAX_BUFSIZE;
+	}
 
 	chip->dev_num = -1;
 
--- linux-2.6.16-rc2/drivers/char/tpm/tpm.h	2006-02-03 16:29:51.000000000 +0100
+++ xenlinux-2.6.16-rc2/drivers/char/tpm/tpm.h	2006-02-06 09:28:08.000000000 +0100
@@ -50,6 +50,7 @@ struct tpm_vendor_specific {
 	u8 req_complete_mask;
 	u8 req_complete_val;
 	u8 req_canceled;
+	u32 buffersize;
 	void __iomem *iobase;		/* ioremapped address */
 	unsigned long base;		/* TPM base address */
 
@@ -74,6 +75,7 @@ struct tpm_chip {
 	/* Data passed to and from the tpm via the read/write calls */
 	u8 *data_buffer;
 	atomic_t data_pending;
+	atomic_t data_position;
 	struct semaphore buffer_mutex;
 
 	struct timer_list user_read_timer;	/* user needs to claim result */
--- linux-2.6.16-rc2/drivers/char/tpm/tpm_xen.c	1970-01-01 01:00:00.000000000 +0100
+++ xenlinux-2.6.16-rc2/drivers/char/tpm/tpm_xen.c	2006-02-08 09:43:29.000000000 +0100
@@ -0,0 +1,523 @@
+/*
+ * Copyright (C) 2004 IBM Corporation
+ *
+ * Authors:
+ * Leendert van Doorn <leendert@watson.ibm.com>
+ * Dave Safford <safford@watson.ibm.com>
+ * Reiner Sailer <sailer@watson.ibm.com>
+ * Kylene Hall <kjhall@us.ibm.com>
+ * Stefan Berger <stefanb@us.ibm.com>
+ *
+ * Maintained by: <tpmdd_devel@lists.sourceforge.net>
+ *
+ * Device driver for TCG/TCPA TPM (trusted platform module) for XEN.
+ * Specifications at www.trustedcomputinggroup.org
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation, version 2 of the
+ * License.
+ *
+ */
+
+#include <asm/uaccess.h>
+#include <linux/list.h>
+#include <xen/tpmfe.h>
+#include <linux/device.h>
+#include <linux/interrupt.h>
+#include "tpm.h"
+
+/* read status bits */
+enum {
+	STATUS_BUSY = 0x01,
+	STATUS_DATA_AVAIL = 0x02,
+	STATUS_READY = 0x04
+};
+
+#define MIN(x,y)  ((x) < (y)) ? (x) : (y)
+
+struct transmission {
+	struct list_head next;
+	unsigned char *request;
+	unsigned int request_len;
+	unsigned char *rcv_buffer;
+	unsigned int  buffersize;
+	unsigned int flags;
+};
+
+enum {
+	TRANSMISSION_FLAG_WAS_QUEUED = 0x1
+};
+
+struct data_exchange {
+	struct transmission *current_request;
+	spinlock_t           req_list_lock;
+	wait_queue_head_t    req_wait_queue;
+
+	struct list_head     queued_requests;
+
+	struct transmission *current_response;
+	spinlock_t           resp_list_lock;
+	wait_queue_head_t    resp_wait_queue;     // processes waiting for responses
+
+	struct transmission *req_cancelled;       // if a cancellation was encounterd
+
+	unsigned int         fe_status;
+	unsigned int         flags;
+};
+
+enum {
+	DATAEX_FLAG_QUEUED_ONLY = 0x1
+};
+
+static struct data_exchange dataex;
+
+static unsigned long disconnect_time;
+
+static struct tpmfe_device tpmfe;
+
+/* local function prototypes */
+static void __exit cleanup_xen(void);
+
+
+/* =============================================================
+ * Some utility functions
+ * =============================================================
+ */
+static inline struct transmission *
+transmission_alloc(void)
+{
+	return kzalloc(sizeof(struct transmission), GFP_KERNEL);
+}
+
+static inline unsigned char *
+transmission_set_buffer(struct transmission *t,
+                        unsigned char *buffer, unsigned int len)
+{
+	kfree(t->request);
+	t->request = kmalloc(len, GFP_KERNEL);
+	if (t->request) {
+		memcpy(t->request,
+		       buffer,
+		       len);
+		t->request_len = len;
+	}
+	return t->request;
+}
+
+static inline void
+transmission_free(struct transmission *t)
+{
+	kfree(t->request);
+	kfree(t->rcv_buffer);
+	kfree(t);
+}
+
+/* =============================================================
+ * Interface with the TPM shared memory driver for XEN
+ * =============================================================
+ */
+static int tpm_recv(const u8 *buffer, size_t count, const void *ptr)
+{
+	int ret_size = 0;
+	struct transmission *t;
+
+	/*
+	 * The list with requests must contain one request
+	 * only and the element there must be the one that
+	 * was passed to me from the front-end.
+	 */
+	if (dataex.current_request != ptr) {
+		printk("WARNING: The request pointer is different than the "
+		       "pointer the shared memory driver returned to me. "
+		       "%p != %p\n",
+		       dataex.current_request, ptr);
+	}
+
+	/*
+	 * If the request has been cancelled, just quit here
+	 */
+	if (dataex.req_cancelled == (struct transmission *)ptr) {
+		if (dataex.current_request == dataex.req_cancelled) {
+			dataex.current_request = NULL;
+		}
+		transmission_free(dataex.req_cancelled);
+		dataex.req_cancelled = NULL;
+		return 0;
+	}
+
+	if (NULL != (t = dataex.current_request)) {
+		transmission_free(t);
+		dataex.current_request = NULL;
+	}
+
+	t = transmission_alloc();
+	if (t) {
+		unsigned long flags;
+		t->rcv_buffer = kmalloc(count, GFP_KERNEL);
+		if (! t->rcv_buffer) {
+			transmission_free(t);
+			return -ENOMEM;
+		}
+		t->buffersize = count;
+		memcpy(t->rcv_buffer, buffer, count);
+		ret_size = count;
+
+		spin_lock_irqsave(&dataex.resp_list_lock ,flags);
+		dataex.current_response = t;
+		spin_unlock_irqrestore(&dataex.resp_list_lock, flags);
+		wake_up_interruptible(&dataex.resp_wait_queue);
+	}
+	return ret_size;
+}
+
+
+static void tpm_fe_status(unsigned int flags)
+{
+	dataex.fe_status = flags;
+	if ((dataex.fe_status & TPMFE_STATUS_CONNECTED) == 0) {
+		disconnect_time = jiffies;
+	}
+}
+
+/* =============================================================
+ * Interface with the generic TPM driver
+ * =============================================================
+ */
+static int tpm_xen_recv(struct tpm_chip *chip, u8 * buf, size_t count)
+{
+	unsigned long flags;
+	int rc = 0;
+
+	spin_lock_irqsave(&dataex.resp_list_lock, flags);
+	/*
+	 * Check if the previous operation only queued the command
+	 * In this case there won't be a response, so I just
+	 * return from here and reset that flag. In any other
+	 * case I should receive a response from the back-end.
+	 */
+	if ((dataex.flags & DATAEX_FLAG_QUEUED_ONLY) != 0) {
+		dataex.flags &= ~DATAEX_FLAG_QUEUED_ONLY;
+		spin_unlock_irqrestore(&dataex.resp_list_lock, flags);
+		/*
+		 * a little hack here. The first few measurements
+		 * are queued since there's no way to talk to the
+		 * TPM yet (due to slowness of the control channel)
+		 * So we just make IMA happy by giving it 30 NULL
+		 * bytes back where the most important part is
+		 * that the result code is '0'.
+		 */
+
+		count = MIN(count, 30);
+		memset(buf, 0x0, count);
+		return count;
+	}
+	/*
+	 * Check whether something is in the responselist and if
+	 * there's nothing in the list wait for something to appear.
+	 */
+
+	if (NULL == dataex.current_response) {
+		spin_unlock_irqrestore(&dataex.resp_list_lock, flags);
+		interruptible_sleep_on_timeout(&dataex.resp_wait_queue,
+		                               1000);
+		spin_lock_irqsave(&dataex.resp_list_lock ,flags);
+	}
+
+	if (NULL != dataex.current_response) {
+		struct transmission *t = dataex.current_response;
+		dataex.current_response = NULL;
+		rc = MIN(count, t->buffersize);
+		memcpy(buf, t->rcv_buffer, rc);
+		transmission_free(t);
+	}
+
+	spin_unlock_irqrestore(&dataex.resp_list_lock, flags);
+	return rc;
+}
+
+static int tpm_xen_send(struct tpm_chip *chip, u8 * buf, size_t count)
+{
+	/*
+	 * We simply pass the packet onto the XEN shared
+	 * memory driver.
+	 */
+	unsigned long flags;
+	int rc;
+	struct transmission *t = transmission_alloc();
+
+	spin_lock_irqsave(&dataex.req_list_lock, flags);
+	/*
+	 * If there's a current request, it must be the
+	 * previous request that has timed out.
+	 */
+	if (dataex.current_request != NULL) {
+		printk("WARNING: Sending although there is a request outstanding.\n"
+		       "         Previous request must have timed out.\n");
+		transmission_free(dataex.current_request);
+		dataex.current_request = NULL;
+	}
+
+	if (t != NULL) {
+		unsigned int error = 0;
+		/*
+		 * Queue the packet if the driver below is not
+		 * ready, yet, or there is any packet already
+		 * in the queue.
+		 * If the driver below is ready, unqueue all
+		 * packets first before sending our current
+		 * packet.
+		 * For each unqueued packet, except for the
+		 * last (=current) packet, call the function
+		 * tpm_xen_recv to wait for the response to come
+		 * back.
+		 */
+		if ((dataex.fe_status & TPMFE_STATUS_CONNECTED) == 0) {
+			if (time_after(jiffies, disconnect_time + HZ * 10)) {
+				rc = -ENOENT;
+			} else {
+				/*
+				 * copy the request into the buffer
+				 */
+				if (transmission_set_buffer(t, buf, count)
+				    == NULL) {
+					transmission_free(t);
+					rc = -ENOMEM;
+					goto exit;
+				}
+				dataex.flags |= DATAEX_FLAG_QUEUED_ONLY;
+				list_add_tail(&t->next, &dataex.queued_requests);
+				rc = 0;
+			}
+		} else {
+			/*
+			 * Check whether there are any packets in the queue
+			 */
+			while (!list_empty(&dataex.queued_requests)) {
+				/*
+				 * Need to dequeue them.
+				 * Read the result into a dummy buffer.
+				 */
+				unsigned char buffer[1];
+				struct transmission *qt = (struct transmission *) dataex.queued_requests.next;
+				list_del(&qt->next);
+				dataex.current_request = qt;
+				spin_unlock_irqrestore(&dataex.req_list_lock,
+				                       flags);
+
+				rc = tpm_fe_send(tpmfe.tpm_private,
+				                 qt->request,
+				                 qt->request_len,
+				                 qt);
+
+				if (rc < 0) {
+					spin_lock_irqsave(&dataex.req_list_lock, flags);
+					if ((qt = dataex.current_request) != NULL) {
+						/*
+						 * requeue it at the beginning
+						 * of the list
+						 */
+						list_add(&qt->next,
+						         &dataex.queued_requests);
+					}
+					dataex.current_request = NULL;
+					error = 1;
+					break;
+				}
+				/*
+				 * After this point qt is not valid anymore!
+				 * It is freed when the front-end is delivering the data
+				 * by calling tpm_recv
+				 */
+
+				/*
+				 * Try to receive the response now into the provided dummy
+				 * buffer (I don't really care about this response since
+				 * there is no receiver anymore for this response)
+				 */
+				rc = tpm_xen_recv(chip, buffer, sizeof(buffer));
+
+				spin_lock_irqsave(&dataex.req_list_lock, flags);
+			}
+
+			if (error == 0) {
+				/*
+				 * Finally, send the current request.
+				 */
+				dataex.current_request = t;
+				/*
+				 * Call the shared memory driver
+				 * Pass to it the buffer with the request, the
+				 * amount of bytes in the request and
+				 * a void * pointer (here: transmission structure)
+				 */
+				rc = tpm_fe_send(tpmfe.tpm_private,
+				                 buf, count, t);
+				/*
+				 * The generic TPM driver will call
+				 * the function to receive the response.
+				 */
+				if (rc < 0) {
+					dataex.current_request = NULL;
+					goto queue_it;
+				}
+			} else {
+queue_it:
+				if (transmission_set_buffer(t, buf, count) == NULL) {
+					transmission_free(t);
+					rc = -ENOMEM;
+					goto exit;
+				}
+				/*
+				 * An error occurred. Don't event try
+				 * to send the current request. Just
+				 * queue it.
+				 */
+				dataex.flags |= DATAEX_FLAG_QUEUED_ONLY;
+				list_add_tail(&t->next,
+				              &dataex.queued_requests);
+				rc = 0;
+			}
+		}
+	} else {
+		rc = -ENOMEM;
+	}
+
+exit:
+	spin_unlock_irqrestore(&dataex.req_list_lock, flags);
+	return rc;
+}
+
+static void tpm_xen_cancel(struct tpm_chip *chip)
+{
+	unsigned long flags;
+	spin_lock_irqsave(&dataex.resp_list_lock,flags);
+
+	dataex.req_cancelled = dataex.current_request;
+
+	spin_unlock_irqrestore(&dataex.resp_list_lock,flags);
+}
+
+static u8 tpm_xen_status(struct tpm_chip *chip)
+{
+	unsigned long flags;
+	u8 rc = 0;
+	spin_lock_irqsave(&dataex.resp_list_lock, flags);
+	/*
+	 * Data are available if:
+	 *  - there's a current response
+	 *  - the last packet was queued only (this is fake, but necessary to
+	 *      get the generic TPM layer to call the receive function.)
+	 */
+	if (NULL != dataex.current_response ||
+	    0 != (dataex.flags & DATAEX_FLAG_QUEUED_ONLY)) {
+		rc = STATUS_DATA_AVAIL;
+	}
+	spin_unlock_irqrestore(&dataex.resp_list_lock, flags);
+	return rc;
+}
+
+static struct file_operations tpm_xen_ops = {
+	.owner = THIS_MODULE,
+	.llseek = no_llseek,
+	.open = tpm_open,
+	.read = tpm_read,
+	.write = tpm_write,
+	.release = tpm_release,
+};
+
+static DEVICE_ATTR(pubek, S_IRUGO, tpm_show_pubek, NULL);
+static DEVICE_ATTR(pcrs, S_IRUGO, tpm_show_pcrs, NULL);
+static DEVICE_ATTR(caps, S_IRUGO, tpm_show_caps, NULL);
+static DEVICE_ATTR(cancel, S_IWUSR |S_IWGRP, NULL, tpm_store_cancel);
+
+static struct attribute* xen_attrs[] = {
+	&dev_attr_pubek.attr,
+	&dev_attr_pcrs.attr,
+	&dev_attr_caps.attr,
+	&dev_attr_cancel.attr,
+	NULL,
+};
+
+static struct attribute_group xen_attr_grp = { .attrs = xen_attrs };
+
+static struct tpm_vendor_specific tpm_xen = {
+	.recv = tpm_xen_recv,
+	.send = tpm_xen_send,
+	.cancel = tpm_xen_cancel,
+	.status = tpm_xen_status,
+	.req_complete_mask = STATUS_BUSY | STATUS_DATA_AVAIL,
+	.req_complete_val  = STATUS_DATA_AVAIL,
+	.req_canceled = STATUS_READY,
+	.base = 0,
+	.attr_group = &xen_attr_grp,
+	.miscdev.fops = &tpm_xen_ops,
+	.buffersize = 64 * 1024,
+};
+
+static struct device tpm_device = {
+	.bus_id = "vtpm",
+};
+
+static struct tpmfe_device tpmfe = {
+	.receive = tpm_recv,
+	.status  = tpm_fe_status,
+};
+
+
+static int __init init_xen(void)
+{
+	int rc;
+
+	/*
+	 * Register device with the low lever front-end
+	 * driver
+	 */
+	if ((rc = tpm_fe_register_receiver(&tpmfe)) < 0) {
+		return rc;
+	}
+
+	/*
+	 * Register our device with the system.
+	 */
+	if ((rc = device_register(&tpm_device)) < 0) {
+		tpm_fe_unregister_receiver();
+		return rc;
+	}
+
+	tpm_xen.buffersize = tpmfe.max_tx_size;
+
+	if ((rc = tpm_register_hardware(&tpm_device, &tpm_xen)) < 0) {
+		device_unregister(&tpm_device);
+		tpm_fe_unregister_receiver();
+		return rc;
+	}
+
+	dataex.current_request = NULL;
+	spin_lock_init(&dataex.req_list_lock);
+	init_waitqueue_head(&dataex.req_wait_queue);
+	INIT_LIST_HEAD(&dataex.queued_requests);
+
+	dataex.current_response = NULL;
+	spin_lock_init(&dataex.resp_list_lock);
+	init_waitqueue_head(&dataex.resp_wait_queue);
+
+	disconnect_time = jiffies;
+
+	return 0;
+}
+
+static void __exit cleanup_xen(void)
+{
+	tpm_remove_hardware(&tpm_device);
+	device_unregister(&tpm_device);
+	tpm_fe_unregister_receiver();
+}
+
+module_init(init_xen);
+module_exit(cleanup_xen);
+
+MODULE_AUTHOR("Stefan Berger (stefanb@us.ibm.com)");
+MODULE_DESCRIPTION("TPM Driver for XEN (shared memory)");
+MODULE_VERSION("1.0");
+MODULE_LICENSE("GPL");
