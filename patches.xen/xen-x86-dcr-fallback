Subject: Add fallback when XENMEM_exchange fails to replace contiguous region
From: jbeulich@novell.com
Patch-mainline: obsolete
References: 181869

This avoids losing precious special memory in places where any memory can be
used.

Index: head-2006-08-28/arch/i386/mm/hypervisor.c
===================================================================
--- head-2006-08-28.orig/arch/i386/mm/hypervisor.c	2006-08-16 10:22:14.000000000 +0200
+++ head-2006-08-28/arch/i386/mm/hypervisor.c	2006-08-28 10:52:46.000000000 +0200
@@ -42,6 +42,7 @@
 #include <xen/interface/memory.h>
 #include <linux/module.h>
 #include <linux/percpu.h>
+#include <linux/highmem.h>
 #include <asm/tlbflush.h>
 
 #ifdef CONFIG_X86_64
@@ -445,6 +446,67 @@ void xen_destroy_contiguous_region(unsig
 		BUG();
 
 	balloon_unlock(flags);
+
+	if (unlikely(!success)) {
+		/* Try hard to get the special memory back to Xen. */
+		exchange.in.extent_order = 0;
+		set_xen_guest_handle(exchange.in.extent_start, &in_frame);
+
+		for (i = 0; i < (1UL<<order); i++) {
+			struct page *page = alloc_page(GFP_HIGHUSER);
+			unsigned long pfn;
+
+			if (!page) {
+				printk(KERN_WARNING "Xen and kernel out of memory "
+				       "while trying to release an order %u "
+				       "contiguous region\n", order);
+				break;
+			}
+			pfn = page_to_pfn(page);
+			if (!PageHighMem(page)) {
+				void *v = __va(pfn << PAGE_SHIFT);
+
+				scrub_pages(v, 1);
+				if (HYPERVISOR_update_va_mapping((unsigned long)v,
+								 __pte_ma(0),
+								 UVMF_INVLPG|UVMF_ALL))
+					BUG();
+			}
+#ifdef CONFIG_XEN_SCRUB_PAGES
+			else {
+				void *v = kmap(page);
+
+				scrub_pages(v, 1);
+				kunmap(page);
+				kmap_flush_unused();
+			}
+#endif
+
+			balloon_lock(flags);
+
+			frame = pfn_to_mfn(pfn);
+			set_phys_to_machine(pfn, INVALID_P2M_ENTRY);
+
+			if (HYPERVISOR_update_va_mapping(vstart,
+							 pfn_pte_ma(frame, PAGE_KERNEL),
+							 UVMF_INVLPG|UVMF_ALL))
+				BUG();
+			pfn = __pa(vstart) >> PAGE_SHIFT;
+			set_phys_to_machine(pfn, frame);
+			xen_machphys_update(frame, pfn);
+
+			if (HYPERVISOR_memory_op(XENMEM_decrease_reservation,
+						 &exchange.in) != 1)
+				BUG();
+
+			balloon_unlock(flags);
+
+			balloon_free_empty_page_range(page, 1);
+
+			in_frame++;
+			vstart += PAGE_SIZE;
+		}
+	}
 }
 
 #ifdef __i386__
Index: head-2006-08-28/drivers/xen/balloon/balloon.c
===================================================================
--- head-2006-08-28.orig/drivers/xen/balloon/balloon.c	2006-08-28 10:51:38.000000000 +0200
+++ head-2006-08-28/drivers/xen/balloon/balloon.c	2006-08-28 10:54:20.000000000 +0200
@@ -637,22 +637,37 @@ struct page *balloon_alloc_empty_page_ra
 	return NULL;
 }
 
-void balloon_dealloc_empty_page_range(
-	struct page *page, unsigned long nr_pages)
+static void _balloon_free_empty_page_range(
+	struct page *page, unsigned long nr_pages, int account)
 {
 	unsigned long i, flags;
-	unsigned int  order = get_order(nr_pages * PAGE_SIZE);
 
 	balloon_lock(flags);
-	for (i = 0; i < (1UL << order); i++) {
+	for (i = 0; i < nr_pages; i++) {
 		BUG_ON(page_count(page + i) != 1);
 		balloon_append(page + i);
 	}
+	if (account) {
+		current_pages -= nr_pages;
+		totalram_pages = current_pages;
+	}
 	balloon_unlock(flags);
 
 	schedule_work(&balloon_worker);
 }
 
+void balloon_dealloc_empty_page_range(
+	struct page *page, unsigned long nr_pages)
+{
+	_balloon_free_empty_page_range(page, 1UL << get_order(nr_pages * PAGE_SIZE), 0);
+}
+
+void balloon_free_empty_page_range(
+	struct page *page, unsigned long nr_pages)
+{
+	_balloon_free_empty_page_range(page, nr_pages, 1);
+}
+
 void balloon_release_driver_page(struct page *page)
 {
 	unsigned long flags;
Index: head-2006-08-28/include/xen/balloon.h
===================================================================
--- head-2006-08-28.orig/include/xen/balloon.h	2006-08-28 10:03:40.000000000 +0200
+++ head-2006-08-28/include/xen/balloon.h	2006-08-28 10:55:13.000000000 +0200
@@ -52,6 +52,12 @@ void
 balloon_dealloc_empty_page_range(
 	struct page *page, unsigned long nr_pages);
 
+/* Free an empty page range (not allocated through
+   balloon_alloc_empty_page_range), adding to the balloon. */
+void
+balloon_free_empty_page_range(
+	struct page *page, unsigned long nr_pages);
+
 void
 balloon_release_driver_page(
 	struct page *page);
