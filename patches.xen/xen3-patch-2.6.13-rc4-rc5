Subject: patch-2.6.13-rc5
From: torvalds@osdl.org


Signed-off-by: Olaf Hering <olh@suse.de>

Automatically created from "patches.fixes/patch-2.6.13-rc4-rc5" by xen-port-patches.py

diff -purN linux-2.6.13-rc4/arch/xen/i386/kernel/mpparse.c linux-2.6.13-rc5/arch/xen/i386/kernel/mpparse.c
--- linux-2.6.13-rc4/arch/xen/i386/kernel/mpparse.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/i386/kernel/mpparse.c	2005-08-02 06:45:48.000000000 +0200
@@ -1116,7 +1116,15 @@ int mp_register_gsi (u32 gsi, int edge_l
 		 */
 		int irq = gsi;
 		if (gsi < MAX_GSI_NUM) {
-			gsi = pci_irq++;
+			if (gsi > 15)
+				gsi = pci_irq++;
+#ifdef CONFIG_ACPI_BUS
+			/*
+			 * Don't assign IRQ used by ACPI SCI
+			 */
+			if (gsi == acpi_fadt.sci_int)
+				gsi = pci_irq++;
+#endif
 			gsi_to_irq[irq] = gsi;
 		} else {
 			printk(KERN_ERR "GSI %u is too high\n", gsi);
diff -purN linux-2.6.13-rc4/arch/xen/i386/pci/irq.c linux-2.6.13-rc5/arch/xen/i386/pci/irq.c
--- linux-2.6.13-rc4/arch/xen/i386/pci/irq.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/i386/pci/irq.c	2005-08-02 06:45:48.000000000 +0200
@@ -56,6 +56,7 @@ struct irq_router_handler {
 };
 
 int (*pcibios_enable_irq)(struct pci_dev *dev) = NULL;
+void (*pcibios_disable_irq)(struct pci_dev *dev) = NULL;
 
 /*
  *  Check passed address for the PCI IRQ Routing Table signature
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/Kconfig linux-2.6.13-rc5/arch/xen/x86_64/Kconfig
--- linux-2.6.13-rc4/arch/xen/x86_64/Kconfig	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/Kconfig	2005-08-02 06:45:48.000000000 +0200
@@ -329,12 +329,15 @@ config HPET_EMULATE_RTC
 
 config GART_IOMMU
 	bool "IOMMU support"
+	default y
 	depends on PCI
 	help
-	  Support the K8 IOMMU. Needed to run systems with more than 4GB of memory
+	  Support the IOMMU. Needed to run systems with more than 3GB of memory
 	  properly with 32-bit PCI devices that do not support DAC (Double Address
 	  Cycle). The IOMMU can be turned off at runtime with the iommu=off parameter.
 	  Normally the kernel will take the right choice by itself.
+	  This option includes a driver for the AMD Opteron/Athlon64 IOMMU
+	  and a software emulation used on some other systems.
 	  If unsure, say Y.
 
 # need this always enabled with GART_IOMMU for the VIA workaround
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/Makefile linux-2.6.13-rc5/arch/xen/x86_64/Makefile
--- linux-2.6.13-rc4/arch/xen/x86_64/Makefile	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/Makefile	2005-08-02 06:45:48.000000000 +0200
@@ -21,18 +21,6 @@
 #
 # $Id: Makefile,v 1.31 2002/03/22 15:56:07 ak Exp $
 
-#
-# early bootup linking needs 32bit. You can either use real 32bit tools
-# here or 64bit tools in 32bit mode.
-#
-IA32_CC := $(CC) $(CPPFLAGS) -m32 -O2 -fomit-frame-pointer
-IA32_LD := $(LD) -m elf_i386
-IA32_AS := $(CC) $(AFLAGS) -m32 -Wa,--32 -traditional -c
-IA32_OBJCOPY := $(CROSS_COMPILE)objcopy
-IA32_CPP := $(CROSS_COMPILE)gcc -m32 -E
-export IA32_CC IA32_LD IA32_AS IA32_OBJCOPY IA32_CPP
-
-
 LDFLAGS		:= -m elf_x86_64
 OBJCOPYFLAGS	:= -O binary -R .note -R .comment -S
 LDFLAGS_vmlinux :=
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/ia32/Makefile linux-2.6.13-rc5/arch/xen/x86_64/ia32/Makefile
--- linux-2.6.13-rc4/arch/xen/x86_64/ia32/Makefile	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/ia32/Makefile	2005-08-02 06:45:48.000000000 +0200
@@ -4,14 +4,14 @@
 
 obj-$(CONFIG_IA32_EMULATION) := ia32entry.o sys_ia32.o ia32_ioctl.o \
 	ia32_signal.o tls32.o \
-	ia32_binfmt.o fpu32.o ptrace32.o syscall32.o
+	ia32_binfmt.o fpu32.o ptrace32.o syscall32.o syscall32_syscall.o
 
 sysv-$(CONFIG_SYSVIPC) := ipc32.o
 obj-$(CONFIG_IA32_EMULATION) += $(sysv-y)
 
 obj-$(CONFIG_IA32_AOUT) += ia32_aout.o
 
-$(obj)/syscall32.o: $(src)/syscall32.c \
+$(obj)/syscall32_syscall.o: \
 	$(foreach F,sysenter syscall,$(obj)/vsyscall-$F.so)
 
 # Teach kbuild about targets
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/ia32/syscall32.c linux-2.6.13-rc5/arch/xen/x86_64/ia32/syscall32.c
--- linux-2.6.13-rc4/arch/xen/x86_64/ia32/syscall32.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/ia32/syscall32.c	2005-08-02 06:45:48.000000000 +0200
@@ -14,16 +14,6 @@
 #include <asm/tlbflush.h>
 #include <asm/ia32_unistd.h>
 
-/* 32bit VDSOs mapped into user space. */ 
-asm(".section \".init.data\",\"aw\"\n"
-    "syscall32_syscall:\n"
-    ".incbin \"arch/x86_64/ia32/vsyscall-syscall.so\"\n"
-    "syscall32_syscall_end:\n"
-    "syscall32_sysenter:\n"
-    ".incbin \"arch/x86_64/ia32/vsyscall-sysenter.so\"\n"
-    "syscall32_sysenter_end:\n"
-    ".previous");
-
 extern unsigned char syscall32_syscall[], syscall32_syscall_end[];
 extern unsigned char syscall32_sysenter[], syscall32_sysenter_end[];
 extern int sysctl_vsyscall32;
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/entry.S linux-2.6.13-rc5/arch/xen/x86_64/kernel/entry.S
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/entry.S	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/entry.S	2005-08-02 06:45:48.000000000 +0200
@@ -76,7 +76,7 @@
 
 	.macro FAKE_STACK_FRAME child_rip
 	/* push in order ss, rsp, eflags, cs, rip */
-	xorq %rax, %rax
+	xorl %eax, %eax
 	pushq %rax /* ss */
 	CFI_ADJUST_CFA_OFFSET	8
 	pushq %rax /* rsp */
@@ -423,7 +423,7 @@ ENTRY(stub_rt_sigreturn)
 	testl $3,CS(%rdi)
 	je 1f
 	swapgs	
-1:	addl $1,%gs:pda_irqcount	# RED-PEN should check preempt count
+1:	incl	%gs:pda_irqcount	# RED-PEN should check preempt count
 	movq %gs:pda_irqstackptr,%rax
 	cmoveq %rax,%rsp							
 	pushq %rdi			# save old stack	
@@ -436,7 +436,7 @@ ENTRY(common_interrupt)
 ret_from_intr:		
 	popq  %rdi
 	cli	
-	subl $1,%gs:pda_irqcount
+	decl %gs:pda_irqcount
 #ifdef CONFIG_DEBUG_INFO
 	movq RBP(%rdi),%rbp
 #endif
@@ -494,7 +494,7 @@ retint_signal:
 	sti
 	SAVE_REST
 	movq $-1,ORIG_RAX(%rsp) 			
-	xorq %rsi,%rsi		# oldset
+	xorl %esi,%esi		# oldset
 	movq %rsp,%rdi		# &pt_regs
 	call do_notify_resume
 	RESTORE_REST
@@ -752,7 +752,7 @@ child_rip:
 	movq %rsi, %rdi
 	call *%rax
 	# exit
-	xorq %rdi, %rdi
+	xorl %edi, %edi
 	call do_exit
 
 /*
@@ -918,3 +918,15 @@ ENTRY(machine_check)
 ENTRY(call_debug)
        zeroentry do_call_debug
 
+ENTRY(call_softirq)
+	movq %gs:pda_irqstackptr,%rax
+	pushq %r15
+	movq %rsp,%r15
+	incl %gs:pda_irqcount
+	cmove %rax,%rsp
+	call __do_softirq
+	movq %r15,%rsp
+	decl %gs:pda_irqcount
+	popq %r15
+	ret
+
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/genapic.c linux-2.6.13-rc5/arch/xen/x86_64/kernel/genapic.c
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/genapic.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/genapic.c	2005-08-02 06:45:48.000000000 +0200
@@ -31,6 +31,7 @@ u8 x86_cpu_to_log_apicid[NR_CPUS] = { [0
 
 extern struct genapic apic_cluster;
 extern struct genapic apic_flat;
+extern struct genapic apic_physflat;
 
 struct genapic *genapic = &apic_flat;
 
@@ -44,12 +45,7 @@ void __init clustered_apic_check(void)
 	u8 clusters, max_cluster;
 	u8 id;
 	u8 cluster_cnt[NUM_APIC_CLUSTERS];
-
-	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
-		/* AMD always uses flat mode right now */
-		genapic = &apic_flat;
-		goto print;
-	}
+	int num_cpus = 0;
 
 #if defined(CONFIG_ACPI_BUS)
 	/*
@@ -64,15 +60,34 @@ void __init clustered_apic_check(void)
 #endif
 
 	memset(cluster_cnt, 0, sizeof(cluster_cnt));
-
 	for (i = 0; i < NR_CPUS; i++) {
 		id = bios_cpu_apicid[i];
-		if (id != BAD_APICID)
-			cluster_cnt[APIC_CLUSTERID(id)]++;
+		if (id == BAD_APICID)
+			continue;
+		num_cpus++;
+		cluster_cnt[APIC_CLUSTERID(id)]++;
 	}
 
+	/* Don't use clustered mode on AMD platforms. */
+ 	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
+		genapic = &apic_physflat;
+#ifndef CONFIG_CPU_HOTPLUG
+		/* In the CPU hotplug case we cannot use broadcast mode
+		   because that opens a race when a CPU is removed.
+		   Stay at physflat mode in this case.
+		   It is bad to do this unconditionally though. Once
+		   we have ACPI platform support for CPU hotplug
+		   we should detect hotplug capablity from ACPI tables and
+		   only do this when really needed. -AK */
+		if (num_cpus <= 8)
+			genapic = &apic_flat;
+#endif
+ 		goto print;
+ 	}
+
 	clusters = 0;
 	max_cluster = 0;
+
 	for (i = 0; i < NUM_APIC_CLUSTERS; i++) {
 		if (cluster_cnt[i] > 0) {
 			++clusters;
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/head.S linux-2.6.13-rc5/arch/xen/x86_64/kernel/head.S
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/head.S	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/head.S	2005-08-02 06:45:48.000000000 +0200
@@ -137,14 +137,14 @@ startup_64:
 	wrmsr
 
 	/* Setup cr0 */
-	xorq	%rax, %rax
-	btsq	$31, %rax			/* Enable paging */
-	btsq	$0, %rax			/* Enable protected mode */
-	btsq	$1, %rax			/* Enable MP */
-	btsq	$4, %rax			/* Enable ET */
-	btsq	$5, %rax			/* Enable NE */
-	btsq	$16, %rax			/* Enable WP */
-	btsq	$18, %rax			/* Enable AM */
+#define CR0_PM				1		/* protected mode */
+#define CR0_MP				(1<<1)
+#define CR0_ET				(1<<4)
+#define CR0_NE				(1<<5)
+#define CR0_WP				(1<<16)
+#define CR0_AM				(1<<18)
+#define CR0_PAGING 			(1<<31)
+	movl $CR0_PM|CR0_MP|CR0_ET|CR0_NE|CR0_WP|CR0_AM|CR0_PAGING,%eax
 	/* Make changes effective */
 	movq	%rax, %cr0
 
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/irq.c linux-2.6.13-rc5/arch/xen/x86_64/kernel/irq.c
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/irq.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/irq.c	2005-08-02 06:45:48.000000000 +0200
@@ -135,3 +135,22 @@ void fixup_irqs(cpumask_t map)
 	local_irq_disable();
 }
 #endif
+
+extern void call_softirq(void);
+
+asmlinkage void do_softirq(void)
+{
+ 	__u32 pending;
+ 	unsigned long flags;
+
+ 	if (in_interrupt())
+ 		return;
+
+ 	local_irq_save(flags);
+ 	pending = local_softirq_pending();
+ 	/* Switch to interrupt stack */
+ 	if (pending)
+		call_softirq();
+ 	local_irq_restore(flags);
+}
+EXPORT_SYMBOL(do_softirq);
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/mpparse.c linux-2.6.13-rc5/arch/xen/x86_64/kernel/mpparse.c
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/mpparse.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/mpparse.c	2005-08-02 06:45:48.000000000 +0200
@@ -109,7 +109,7 @@ static int __init mpf_checksum(unsigned 
 
 static void __init MP_processor_info (struct mpc_config_processor *m)
 {
-	int ver;
+	int ver, cpu;
 	static int found_bsp=0;
 
 	if (!(m->mpc_cpuflag & CPU_ENABLED))
@@ -131,7 +131,7 @@ static void __init MP_processor_info (st
 		return;
 	}
 
-	num_processors++;
+	cpu = num_processors++;
 
 	if (m->mpc_apicid > MAX_APICS) {
 		printk(KERN_ERR "Processor #%d INVALID. (Max ID: %d).\n",
@@ -155,13 +155,18 @@ static void __init MP_processor_info (st
  		 * in same order as logical cpu numbers. Hence the first
  		 * entry is BSP, and so on.
  		 */
+		cpu = 0;
+
  		bios_cpu_apicid[0] = m->mpc_apicid;
  		x86_cpu_to_apicid[0] = m->mpc_apicid;
  		found_bsp = 1;
- 	} else {
- 		bios_cpu_apicid[num_processors - found_bsp] = m->mpc_apicid;
- 		x86_cpu_to_apicid[num_processors - found_bsp] = m->mpc_apicid;
- 	}
+ 	} else
+		cpu = num_processors - found_bsp;
+	bios_cpu_apicid[cpu] = m->mpc_apicid;
+	x86_cpu_to_apicid[cpu] = m->mpc_apicid;
+
+	cpu_set(cpu, cpu_possible_map);
+	cpu_set(cpu, cpu_present_map);
 }
 
 static void __init MP_bus_info (struct mpc_config_bus *m)
@@ -965,8 +970,21 @@ int mp_register_gsi(u32 gsi, int edge_le
 		 * due to unused I/O APIC pins.
 		 */
 		int irq = gsi;
-		gsi = pci_irq++;
-		gsi_to_irq[irq] = gsi;
+		if (gsi < MAX_GSI_NUM) {
+			if (gsi > 15)
+				gsi = pci_irq++;
+#ifdef CONFIG_ACPI_BUS
+			/*
+			 * Don't assign IRQ used by ACPI SCI
+			 */
+			if (gsi == acpi_fadt.sci_int)
+				gsi = pci_irq++;
+#endif
+			gsi_to_irq[irq] = gsi;
+		} else {
+			printk(KERN_ERR "GSI %u is too high\n", gsi);
+			return gsi;
+		}
 	}
 
 	io_apic_set_pci_routing(ioapic, ioapic_pin, gsi,
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/setup.c linux-2.6.13-rc5/arch/xen/x86_64/kernel/setup.c
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/setup.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/setup.c	2005-08-02 06:45:48.000000000 +0200
@@ -765,8 +765,6 @@ static void __init amd_detect_cmp(struct
 	int cpu = smp_processor_id();
 	int node = 0;
 	unsigned bits;
-	if (c->x86_num_cores == 1)
-		return;
 
 	bits = 0;
 	while ((1 << bits) < c->x86_num_cores)
@@ -1081,8 +1079,7 @@ void __cpuinit identify_cpu(struct cpuin
 	else
 		mtrr_ap_init();
 #ifdef CONFIG_NUMA
-	if (c != &boot_cpu_data)
-		numa_add_cpu(c - cpu_data);
+	numa_add_cpu(smp_processor_id());
 #endif
 }
  
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/setup64.c linux-2.6.13-rc5/arch/xen/x86_64/kernel/setup64.c
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/setup64.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/setup64.c	2005-08-02 06:45:48.000000000 +0200
@@ -12,6 +12,7 @@
 #include <linux/string.h>
 #include <linux/bootmem.h>
 #include <linux/bitops.h>
+#include <linux/module.h>
 #include <asm/bootsetup.h>
 #include <asm/pda.h>
 #include <asm/pgtable.h>
@@ -22,10 +23,8 @@
 #include <asm/smp.h>
 #include <asm/i387.h>
 #include <asm/percpu.h>
-#include <asm/mtrr.h>
 #include <asm/proto.h>
-#include <asm/mman.h>
-#include <asm/numa.h>
+#include <asm/sections.h>
 
 char x86_boot_params[BOOT_PARAM_SIZE] __initdata = {0,};
 
@@ -33,11 +32,6 @@ cpumask_t cpu_initialized __cpuinitdata 
 
 struct x8664_pda cpu_pda[NR_CPUS] __cacheline_aligned; 
 
-extern struct task_struct init_task;
-
-extern unsigned char __per_cpu_start[], __per_cpu_end[]; 
-
-extern struct desc_ptr cpu_gdt_descr[];
 struct desc_ptr idt_descr = { 256 * 16, (unsigned long) idt_table }; 
 
 char boot_cpu_stack[IRQSTACKSIZE] __attribute__((section(".bss.page_aligned")));
@@ -101,7 +95,7 @@ void __init setup_per_cpu_areas(void)
 #endif
 
 	for (i = 0; i < NR_CPUS; i++) { 
-		unsigned char *ptr;
+		char *ptr;
 
 		if (!NODE_DATA(cpu_to_node(i))) {
 			printk("cpu with no node %d, num_online_nodes %d\n",
@@ -190,11 +184,7 @@ void __cpuinit check_efer(void)
  */
 void __cpuinit cpu_init (void)
 {
-#ifdef CONFIG_SMP
 	int cpu = stack_smp_processor_id();
-#else
-	int cpu = smp_processor_id();
-#endif
 	struct tss_struct *t = &per_cpu(init_tss, cpu);
 	unsigned long v; 
 	char *estacks = NULL; 
@@ -214,7 +204,7 @@ void __cpuinit cpu_init (void)
 
 	printk("Initializing CPU#%d\n", cpu);
 
-		clear_in_cr4(X86_CR4_VME|X86_CR4_PVI|X86_CR4_TSD|X86_CR4_DE);
+	clear_in_cr4(X86_CR4_VME|X86_CR4_PVI|X86_CR4_TSD|X86_CR4_DE);
 
 	/*
 	 * Initialize the per-CPU GDT with the boot GDT,
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/smp.c linux-2.6.13-rc5/arch/xen/x86_64/kernel/smp.c
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/smp.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/smp.c	2005-08-02 06:45:48.000000000 +0200
@@ -129,10 +129,9 @@ asmlinkage void smp_invalidate_interrupt
 		} else
 			leave_mm(cpu);
 	}
+out:
 	ack_APIC_irq();
 	cpu_clear(cpu, flush_cpumask);
-
-out:
 	put_cpu_no_resched();
 }
 
@@ -294,6 +293,69 @@ void unlock_ipi_call_lock(void)
 }
 
 /*
+ * this function sends a 'generic call function' IPI to one other CPU
+ * in the system.
+ */
+static void __smp_call_function_single (int cpu, void (*func) (void *info), void *info,
+				int nonatomic, int wait)
+{
+	struct call_data_struct data;
+	int cpus = 1;
+
+	data.func = func;
+	data.info = info;
+	atomic_set(&data.started, 0);
+	data.wait = wait;
+	if (wait)
+		atomic_set(&data.finished, 0);
+
+	call_data = &data;
+	wmb();
+	/* Send a message to all other CPUs and wait for them to respond */
+	send_IPI_mask(cpumask_of_cpu(cpu), CALL_FUNCTION_VECTOR);
+
+	/* Wait for response */
+	while (atomic_read(&data.started) != cpus)
+		cpu_relax();
+
+	if (!wait)
+		return;
+
+	while (atomic_read(&data.finished) != cpus)
+		cpu_relax();
+}
+
+/*
+ * smp_call_function_single - Run a function on another CPU
+ * @func: The function to run. This must be fast and non-blocking.
+ * @info: An arbitrary pointer to pass to the function.
+ * @nonatomic: Currently unused.
+ * @wait: If true, wait until function has completed on other CPUs.
+ *
+ * Retrurns 0 on success, else a negative status code.
+ *
+ * Does not return until the remote CPU is nearly ready to execute <func>
+ * or is or has executed.
+ */
+
+int smp_call_function_single (int cpu, void (*func) (void *info), void *info,
+	int nonatomic, int wait)
+{
+	/* prevent preemption and reschedule on another processor */
+	int me = get_cpu();
+	if (cpu == me) {
+		WARN_ON(1);
+		put_cpu();
+		return -EBUSY;
+	}
+	spin_lock_bh(&call_lock);
+	__smp_call_function_single(cpu, func, info, nonatomic, wait);
+	spin_unlock_bh(&call_lock);
+	put_cpu();
+	return 0;
+}
+
+/*
  * this function sends a 'generic call function' IPI to all other CPUs
  * in the system.
  */
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/smpboot.c linux-2.6.13-rc5/arch/xen/x86_64/kernel/smpboot.c
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/smpboot.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/smpboot.c	2005-08-02 06:45:48.000000000 +0200
@@ -113,24 +113,6 @@ struct task_struct *idle_thread_array[NR
 #define set_idle_for_cpu(x,p)   (idle_thread_array[(x)] = (p))
 
 /*
- * cpu_possible_map should be static, it cannot change as cpu's
- * are onlined, or offlined. The reason is per-cpu data-structures
- * are allocated by some modules at init time, and dont expect to
- * do this dynamically on cpu arrival/departure.
- * cpu_present_map on the other hand can change dynamically.
- * In case when cpu_hotplug is not compiled, then we resort to current
- * behaviour, which is cpu_possible == cpu_present.
- * If cpu-hotplug is supported, then we need to preallocate for all
- * those NR_CPUS, hence cpu_possible_map represents entire NR_CPUS range.
- * - Ashok Raj
- */
-#ifdef CONFIG_HOTPLUG_CPU
-#define fixup_cpu_possible_map(x)	cpu_set((x), cpu_possible_map)
-#else
-#define fixup_cpu_possible_map(x)
-#endif
-
-/*
  * Currently trivial. Write the real->protected mode
  * bootstrap into the page concerned. The caller
  * has made sure it's suitably aligned.
@@ -229,9 +211,6 @@ static __cpuinit void sync_master(void *
 {
 	unsigned long flags, i;
 
-	if (smp_processor_id() != 0)
-		return;
-
 	go[MASTER] = 0;
 
 	local_irq_save(flags);
@@ -280,7 +259,7 @@ get_delta(long *rt, long *master)
 	return tcenter - best_tm;
 }
 
-static __cpuinit void sync_tsc(void)
+static __cpuinit void sync_tsc(unsigned int master)
 {
 	int i, done = 0;
 	long delta, adj, adjust_latency = 0;
@@ -294,9 +273,17 @@ static __cpuinit void sync_tsc(void)
 	} t[NUM_ROUNDS] __cpuinitdata;
 #endif
 
+	printk(KERN_INFO "CPU %d: Syncing TSC to CPU %u.\n",
+		smp_processor_id(), master);
+
 	go[MASTER] = 1;
 
-	smp_call_function(sync_master, NULL, 1, 0);
+	/* It is dangerous to broadcast IPI as cpus are coming up,
+	 * as they may not be ready to accept them.  So since
+	 * we only need to send the ipi to the boot cpu direct
+	 * the message, and avoid the race.
+	 */
+	smp_call_function_single(master, sync_master, NULL, 1, 0);
 
 	while (go[MASTER])	/* wait for master to be ready */
 		no_cpu_relax();
@@ -340,16 +327,14 @@ static __cpuinit void sync_tsc(void)
 	printk(KERN_INFO
 	       "CPU %d: synchronized TSC with CPU %u (last diff %ld cycles, "
 	       "maxerr %lu cycles)\n",
-	       smp_processor_id(), boot_cpu_id, delta, rt);
+	       smp_processor_id(), master, delta, rt);
 }
 
 static void __cpuinit tsc_sync_wait(void)
 {
 	if (notscsync || !cpu_has_tsc)
 		return;
-	printk(KERN_INFO "CPU %d: Syncing TSC to CPU %u.\n", smp_processor_id(),
-			boot_cpu_id);
-	sync_tsc();
+	sync_tsc(boot_cpu_id);
 }
 
 static __init int notscsync_setup(char *s)
@@ -773,8 +758,9 @@ do_rest:
 	initial_code = start_secondary;
 	clear_ti_thread_flag(c_idle.idle->thread_info, TIF_FORK);
 
-	printk(KERN_INFO "Booting processor %d/%d rip %lx rsp %lx\n", cpu, apicid,
-	       start_rip, init_rsp);
+	printk(KERN_INFO "Booting processor %d/%d APIC 0x%x\n", cpu,
+		cpus_weight(cpu_present_map),
+		apicid);
 
 	/*
 	 * This grunge runs the startup process for
@@ -924,6 +910,27 @@ static __init void enforce_max_cpus(unsi
 	}
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+/*
+ * cpu_possible_map should be static, it cannot change as cpu's
+ * are onlined, or offlined. The reason is per-cpu data-structures
+ * are allocated by some modules at init time, and dont expect to
+ * do this dynamically on cpu arrival/departure.
+ * cpu_present_map on the other hand can change dynamically.
+ * In case when cpu_hotplug is not compiled, then we resort to current
+ * behaviour, which is cpu_possible == cpu_present.
+ * If cpu-hotplug is supported, then we need to preallocate for all
+ * those NR_CPUS, hence cpu_possible_map represents entire NR_CPUS range.
+ * - Ashok Raj
+ */
+static void prefill_possible_map(void)
+{
+	int i;
+	for (i = 0; i < NR_CPUS; i++)
+		cpu_set(i, cpu_possible_map);
+}
+#endif
+
 /*
  * Various sanity checks.
  */
@@ -987,25 +994,15 @@ static int __init smp_sanity_check(unsig
  */
 void __init smp_prepare_cpus(unsigned int max_cpus)
 {
-	int i;
-
 	nmi_watchdog_default();
 	current_cpu_data = boot_cpu_data;
 	current_thread_info()->cpu = 0;  /* needed? */
 
 	enforce_max_cpus(max_cpus);
 
-	/*
-	 * Fill in cpu_present_mask
-	 */
-	for (i = 0; i < NR_CPUS; i++) {
-		int apicid = cpu_present_to_apicid(i);
-		if (physid_isset(apicid, phys_cpu_present_map)) {
-			cpu_set(i, cpu_present_map);
-			cpu_set(i, cpu_possible_map);
-		}
-		fixup_cpu_possible_map(i);
-	}
+#ifdef CONFIG_HOTPLUG_CPU
+	prefill_possible_map();
+#endif
 
 	if (smp_sanity_check(max_cpus) < 0) {
 		printk(KERN_INFO "SMP disabled\n");
@@ -1189,8 +1186,7 @@ void __cpu_die(unsigned int cpu)
 			printk ("CPU %d is now offline\n", cpu);
 			return;
 		}
-		current->state = TASK_UNINTERRUPTIBLE;
-		schedule_timeout(HZ/10);
+		msleep(100);
 	}
  	printk(KERN_ERR "CPU %u didn't die...\n", cpu);
 }
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/kernel/traps.c linux-2.6.13-rc5/arch/xen/x86_64/kernel/traps.c
--- linux-2.6.13-rc4/arch/xen/x86_64/kernel/traps.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/kernel/traps.c	2005-08-02 06:45:48.000000000 +0200
@@ -594,9 +594,6 @@ asmlinkage void default_do_nmi(struct pt
 	if (!cpu)
 		reason = get_nmi_reason();
 
-	if (!cpu_online(cpu))
-		return;
-
 	if (!(reason & 0xc0)) {
 		if (notify_die(DIE_NMI_IPI, "nmi_ipi", regs, reason, 0, SIGINT)
 								== NOTIFY_STOP)
diff -purN linux-2.6.13-rc4/arch/xen/x86_64/mm/fault.c linux-2.6.13-rc5/arch/xen/x86_64/mm/fault.c
--- linux-2.6.13-rc4/arch/xen/x86_64/mm/fault.c	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/arch/xen/x86_64/mm/fault.c	2005-08-02 06:45:48.000000000 +0200
@@ -23,7 +23,6 @@
 #include <linux/vt_kern.h>		/* For unblank_screen() */
 #include <linux/compiler.h>
 #include <linux/module.h>
-#include <linux/kprobes.h>
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
diff -purN linux-2.6.13-rc4/include/asm-xen/asm-x86_64/desc.h linux-2.6.13-rc5/include/asm-xen/asm-x86_64/desc.h
--- linux-2.6.13-rc4/include/asm-xen/asm-x86_64/desc.h	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/include/asm-xen/asm-x86_64/desc.h	2005-08-02 06:45:48.000000000 +0200
@@ -75,6 +75,7 @@ struct desc_ptr {
  */
 extern struct desc_struct default_ldt[];
 extern struct gate_struct idt_table[]; 
+extern struct desc_ptr cpu_gdt_descr[];
 
 static inline void _set_gate(void *adr, unsigned type, unsigned long func, unsigned dpl, unsigned ist)  
 {
diff -purN linux-2.6.13-rc4/include/asm-xen/asm-x86_64/irq.h linux-2.6.13-rc5/include/asm-xen/asm-x86_64/irq.h
--- linux-2.6.13-rc4/include/asm-xen/asm-x86_64/irq.h	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/include/asm-xen/asm-x86_64/irq.h	2005-08-02 06:45:48.000000000 +0200
@@ -57,4 +57,6 @@ int handle_IRQ_event(unsigned int, struc
 extern void fixup_irqs(cpumask_t map);
 #endif
 
+#define __ARCH_HAS_DO_SOFTIRQ 1
+
 #endif /* _ASM_IRQ_H */
diff -purN linux-2.6.13-rc4/include/asm-xen/asm-x86_64/pgtable.h linux-2.6.13-rc5/include/asm-xen/asm-x86_64/pgtable.h
--- linux-2.6.13-rc4/include/asm-xen/asm-x86_64/pgtable.h	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/include/asm-xen/asm-x86_64/pgtable.h	2005-08-02 06:45:48.000000000 +0200
@@ -176,6 +176,8 @@ extern inline void pgd_clear (pgd_t * pg
 	(_PAGE_PRESENT | _PAGE_USER | _PAGE_ACCESSED | _PAGE_PCD)
 #define __PAGE_KERNEL_LARGE \
 	(__PAGE_KERNEL | _PAGE_PSE)
+#define __PAGE_KERNEL_LARGE_EXEC \
+	(__PAGE_KERNEL_EXEC | _PAGE_PSE)
 
 #define MAKE_GLOBAL(x) __pgprot((x) | _PAGE_GLOBAL)
 
diff -purN linux-2.6.13-rc4/include/asm-xen/asm-x86_64/smp.h linux-2.6.13-rc5/include/asm-xen/asm-x86_64/smp.h
--- linux-2.6.13-rc4/include/asm-xen/asm-x86_64/smp.h	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/include/asm-xen/asm-x86_64/smp.h	2005-08-02 06:45:48.000000000 +0200
@@ -46,12 +46,12 @@ extern int pic_mode;
 extern void lock_ipi_call_lock(void);
 extern void unlock_ipi_call_lock(void);
 extern int smp_num_siblings;
-extern void smp_flush_tlb(void);
-extern void smp_message_irq(int cpl, void *dev_id, struct pt_regs *regs);
 extern void smp_send_reschedule(int cpu);
-extern void smp_invalidate_rcv(void);		/* Process an NMI */
 extern void zap_low_mappings(void);
 void smp_stop_cpu(void);
+extern int smp_call_function_single(int cpuid, void (*func) (void *info),
+				void *info, int retry, int wait);
+
 extern cpumask_t cpu_sibling_map[NR_CPUS];
 extern cpumask_t cpu_core_map[NR_CPUS];
 extern u8 phys_proc_id[NR_CPUS];
diff -purN linux-2.6.13-rc4/include/asm-xen/asm-x86_64/system.h linux-2.6.13-rc5/include/asm-xen/asm-x86_64/system.h
--- linux-2.6.13-rc4/include/asm-xen/asm-x86_64/system.h	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/include/asm-xen/asm-x86_64/system.h	2005-08-02 06:45:48.000000000 +0200
@@ -116,12 +116,12 @@ struct alt_instr { 
 /*
  * Alternative inline assembly with input.
  * 
- * Pecularities:
+ * Peculiarities:
  * No memory clobber here. 
  * Argument numbers start with 1.
  * Best is to use constraints that are fixed size (like (%1) ... "r")
  * If you use variable sized constraints like "m" or "g" in the 
- * replacement maake sure to pad to the worst case length.
+ * replacement make sure to pad to the worst case length.
  */
 #define alternative_input(oldinstr, newinstr, feature, input...)	\
 	asm volatile ("661:\n\t" oldinstr "\n662:\n"			\
@@ -335,9 +335,6 @@ void cpu_idle_wait(void);
 void disable_hlt(void);
 void enable_hlt(void);
 
-#define HAVE_EAT_KEY
-void eat_key(void);
-
 extern unsigned long arch_align_stack(unsigned long sp);
 
 #endif
diff -purN linux-2.6.13-rc4/include/asm-xen/asm-x86_64/tlbflush.h linux-2.6.13-rc5/include/asm-xen/asm-x86_64/tlbflush.h
--- linux-2.6.13-rc4/include/asm-xen/asm-x86_64/tlbflush.h	2005-07-29 00:44:44.000000000 +0200
+++ linux-2.6.13-rc5/include/asm-xen/asm-x86_64/tlbflush.h	2005-08-02 06:45:48.000000000 +0200
@@ -56,8 +56,9 @@ extern unsigned long pgkern_mask;
  *  - flush_tlb_kernel_range(start, end) flushes a range of kernel pages
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  *
- * ..but the x86_64 has somewhat limited tlb flushing capabilities,
- * and page-granular flushes are available only on i486 and up.
+ * x86-64 can only flush individual pages or full VMs. For a range flush
+ * we always do the full VM. Might be worth trying if for a small
+ * range a few INVLPGs in a row are a win.
  */
 
 #ifndef CONFIG_SMP
@@ -115,7 +116,9 @@ static inline void flush_tlb_range(struc
 static inline void flush_tlb_pgtables(struct mm_struct *mm,
 				      unsigned long start, unsigned long end)
 {
-	/* x86_64 does not keep any page table caches in TLB */
+	/* x86_64 does not keep any page table caches in a software TLB.
+	   The CPUs do in their hardware TLBs, but they are handled
+	   by the normal TLB flushing algorithms. */
 }
 
 #endif /* _X8664_TLBFLUSH_H */
