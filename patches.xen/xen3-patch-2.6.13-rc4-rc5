Subject: patch-2.6.13-rc5
From: torvalds@osdl.org


Signed-off-by: Olaf Hering <olh@suse.de>

Automatically created from "patches.fixes/patch-2.6.13-rc4-rc5" by xen-port-patches.py
Further porting to arch/xen by jbeulich

Index: xen-2005-08-19/arch/xen/i386/kernel/mpparse.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/i386/kernel/mpparse.c	2005-08-19 14:34:38.075343520 +0200
+++ xen-2005-08-19/arch/xen/i386/kernel/mpparse.c	2005-08-19 14:37:13.356737160 +0200
@@ -1131,7 +1131,15 @@
 		 */
 		int irq = gsi;
 		if (gsi < MAX_GSI_NUM) {
-			gsi = pci_irq++;
+			if (gsi > 15)
+				gsi = pci_irq++;
+#ifdef CONFIG_ACPI_BUS
+			/*
+			 * Don't assign IRQ used by ACPI SCI
+			 */
+			if (gsi == acpi_fadt.sci_int)
+				gsi = pci_irq++;
+#endif
 			gsi_to_irq[irq] = gsi;
 		} else {
 			printk(KERN_ERR "GSI %u is too high\n", gsi);
Index: xen-2005-08-19/arch/xen/i386/pci/irq.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/i386/pci/irq.c	2005-08-19 14:37:12.056934760 +0200
+++ xen-2005-08-19/arch/xen/i386/pci/irq.c	2005-08-19 14:37:13.359736704 +0200
@@ -56,6 +56,7 @@
 };
 
 int (*pcibios_enable_irq)(struct pci_dev *dev) = NULL;
+void (*pcibios_disable_irq)(struct pci_dev *dev) = NULL;
 
 #ifdef CONFIG_XEN_PRIVILEGED_GUEST
 /*
Index: xen-2005-08-19/arch/xen/x86_64/Kconfig
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/Kconfig	2005-08-19 14:36:59.809796608 +0200
+++ xen-2005-08-19/arch/xen/x86_64/Kconfig	2005-08-19 14:37:13.363736096 +0200
@@ -332,12 +332,15 @@
 
 config GART_IOMMU
 	bool "IOMMU support"
+	default y
 	depends on PCI
 	help
-	  Support the K8 IOMMU. Needed to run systems with more than 4GB of memory
+	  Support the IOMMU. Needed to run systems with more than 3GB of memory
 	  properly with 32-bit PCI devices that do not support DAC (Double Address
 	  Cycle). The IOMMU can be turned off at runtime with the iommu=off parameter.
 	  Normally the kernel will take the right choice by itself.
+	  This option includes a driver for the AMD Opteron/Athlon64 IOMMU
+	  and a software emulation used on some other systems.
 	  If unsure, say Y.
 
 # need this always enabled with GART_IOMMU for the VIA workaround
Index: xen-2005-08-19/arch/xen/x86_64/ia32/syscall32.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/ia32/syscall32.c	2005-08-19 14:37:12.060934152 +0200
+++ xen-2005-08-19/arch/xen/x86_64/ia32/syscall32.c	2005-08-19 14:37:13.365735792 +0200
@@ -14,34 +14,11 @@
 #include <asm/tlbflush.h>
 #include <asm/ia32_unistd.h>
 
-#define USE_INT80
+#include "syscall32_syscall.S"
 
 #ifdef USE_INT80
-/* 32bit VDSOs mapped into user space. */ 
-asm(".section \".init.data\",\"aw\"\n"
-    "syscall32_int80:\n"
-    ".incbin \"arch/xen/x86_64/ia32/vsyscall-int80.so\"\n"
-    "syscall32_int80_end:\n"
-    "syscall32_syscall:\n"
-    ".incbin \"arch/xen/x86_64/ia32/vsyscall-syscall.so\"\n"
-    "syscall32_syscall_end:\n"
-    "syscall32_sysenter:\n"
-    ".incbin \"arch/xen/x86_64/ia32/vsyscall-sysenter.so\"\n"
-    "syscall32_sysenter_end:\n"
-    ".previous");
-
 extern unsigned char syscall32_int80[], syscall32_int80_end[];
 #else
-/* 32bit VDSOs mapped into user space. */ 
-asm(".section \".init.data\",\"aw\"\n"
-    "syscall32_syscall:\n"
-    ".incbin \"arch/xen/x86_64/ia32/vsyscall-syscall.so\"\n"
-    "syscall32_syscall_end:\n"
-    "syscall32_sysenter:\n"
-    ".incbin \"arch/xen/x86_64/ia32/vsyscall-sysenter.so\"\n"
-    "syscall32_sysenter_end:\n"
-    ".previous");
-
 static int use_sysenter = -1;
 #endif
 
Index: xen-2005-08-19/arch/xen/x86_64/kernel/entry.S
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/entry.S	2005-08-19 14:34:38.079342912 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/entry.S	2005-08-19 14:37:13.367735488 +0200
@@ -77,7 +77,7 @@
 
 	.macro FAKE_STACK_FRAME child_rip
 	/* push in order ss, rsp, eflags, cs, rip */
-	xorq %rax, %rax
+	xorl %eax, %eax
 	pushq %rax /* ss */
 	CFI_ADJUST_CFA_OFFSET	8
 	pushq %rax /* rsp */
@@ -452,7 +452,7 @@
 	je 1f
 	swapgs	
 #endif        
-1:	addl $1,%gs:pda_irqcount	# RED-PEN should check preempt count
+1:	incl %gs:pda_irqcount	# RED-PEN should check preempt count
 	movq %gs:pda_irqstackptr,%rax
 	cmoveq %rax,%rsp							
 	pushq %rdi			# save old stack	
@@ -501,7 +501,7 @@
         XEN_UNBLOCK_EVENTS(%rsi)
 	SAVE_REST
 	movq $-1,ORIG_RAX(%rsp) 			
-	xorq %rsi,%rsi		# oldset
+	xorl %esi,%esi		# oldset
 	movq %rsp,%rdi		# &pt_regs
 	call do_notify_resume
 	RESTORE_REST
@@ -841,7 +841,7 @@
 	movq %rsi, %rdi
 	call *%rax
 	# exit
-	xorq %rdi, %rdi
+	xorl %edi, %edi
 	call do_exit
 
 /*
@@ -1058,3 +1058,15 @@
        zeroentry do_call_debug
 
 
+ENTRY(call_softirq)
+	movq %gs:pda_irqstackptr,%rax
+	pushq %r15
+	movq %rsp,%r15
+	incl %gs:pda_irqcount
+	cmoveq %rax,%rsp
+	call __do_softirq
+	movq %r15,%rsp
+	decl %gs:pda_irqcount
+	popq %r15
+	ret
+
Index: xen-2005-08-19/arch/xen/x86_64/kernel/genapic.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/genapic.c	2005-08-19 14:34:38.080342760 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/genapic.c	2005-08-19 14:37:13.369735184 +0200
@@ -31,6 +31,7 @@
 
 extern struct genapic apic_cluster;
 extern struct genapic apic_flat;
+extern struct genapic apic_physflat;
 
 #ifndef CONFIG_XEN
 struct genapic *genapic = &apic_flat;
@@ -50,12 +51,7 @@
 	u8 clusters, max_cluster;
 	u8 id;
 	u8 cluster_cnt[NUM_APIC_CLUSTERS];
-
-	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
-		/* AMD always uses flat mode right now */
-		genapic = &apic_flat;
-		goto print;
-	}
+	int num_cpus = 0;
 
 #if defined(CONFIG_ACPI_BUS)
 	/*
@@ -70,15 +66,34 @@
 #endif
 
 	memset(cluster_cnt, 0, sizeof(cluster_cnt));
-
 	for (i = 0; i < NR_CPUS; i++) {
 		id = bios_cpu_apicid[i];
-		if (id != BAD_APICID)
-			cluster_cnt[APIC_CLUSTERID(id)]++;
+		if (id == BAD_APICID)
+			continue;
+		num_cpus++;
+		cluster_cnt[APIC_CLUSTERID(id)]++;
 	}
 
+	/* Don't use clustered mode on AMD platforms. */
+ 	if (boot_cpu_data.x86_vendor == X86_VENDOR_AMD) {
+		genapic = &apic_physflat;
+#ifndef CONFIG_CPU_HOTPLUG
+		/* In the CPU hotplug case we cannot use broadcast mode
+		   because that opens a race when a CPU is removed.
+		   Stay at physflat mode in this case.
+		   It is bad to do this unconditionally though. Once
+		   we have ACPI platform support for CPU hotplug
+		   we should detect hotplug capablity from ACPI tables and
+		   only do this when really needed. -AK */
+		if (num_cpus <= 8)
+			genapic = &apic_flat;
+#endif
+ 		goto print;
+ 	}
+
 	clusters = 0;
 	max_cluster = 0;
+
 	for (i = 0; i < NUM_APIC_CLUSTERS; i++) {
 		if (cluster_cnt[i] > 0) {
 			++clusters;
Index: xen-2005-08-19/arch/xen/x86_64/kernel/irq.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/irq.c	2005-08-19 14:34:38.078343064 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/irq.c	2005-08-19 14:37:13.370735032 +0200
@@ -137,3 +137,22 @@
 	local_irq_disable();
 }
 #endif
+
+extern void call_softirq(void);
+
+asmlinkage void do_softirq(void)
+{
+ 	__u32 pending;
+ 	unsigned long flags;
+
+ 	if (in_interrupt())
+ 		return;
+
+ 	local_irq_save(flags);
+ 	pending = local_softirq_pending();
+ 	/* Switch to interrupt stack */
+ 	if (pending)
+		call_softirq();
+ 	local_irq_restore(flags);
+}
+EXPORT_SYMBOL(do_softirq);
Index: xen-2005-08-19/arch/xen/x86_64/kernel/mpparse.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/mpparse.c	2005-08-19 14:34:38.082342456 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/mpparse.c	2005-08-19 14:37:13.373734576 +0200
@@ -110,7 +110,7 @@
 #ifndef CONFIG_XEN
 static void __init MP_processor_info (struct mpc_config_processor *m)
 {
-	int ver;
+	int ver, cpu;
 	static int found_bsp=0;
 
 	if (!(m->mpc_cpuflag & CPU_ENABLED))
@@ -132,7 +132,7 @@
 		return;
 	}
 
-	num_processors++;
+	cpu = num_processors++;
 
 	if (m->mpc_apicid > MAX_APICS) {
 		printk(KERN_ERR "Processor #%d INVALID. (Max ID: %d).\n",
@@ -156,13 +156,18 @@
  		 * in same order as logical cpu numbers. Hence the first
  		 * entry is BSP, and so on.
  		 */
+		cpu = 0;
+
  		bios_cpu_apicid[0] = m->mpc_apicid;
  		x86_cpu_to_apicid[0] = m->mpc_apicid;
  		found_bsp = 1;
- 	} else {
- 		bios_cpu_apicid[num_processors - found_bsp] = m->mpc_apicid;
- 		x86_cpu_to_apicid[num_processors - found_bsp] = m->mpc_apicid;
- 	}
+ 	} else
+		cpu = num_processors - found_bsp;
+	bios_cpu_apicid[cpu] = m->mpc_apicid;
+	x86_cpu_to_apicid[cpu] = m->mpc_apicid;
+
+	cpu_set(cpu, cpu_possible_map);
+	cpu_set(cpu, cpu_present_map);
 }
 #else
 void __init MP_processor_info (struct mpc_config_processor *m)
@@ -970,8 +975,21 @@
 		 * due to unused I/O APIC pins.
 		 */
 		int irq = gsi;
-		gsi = pci_irq++;
-		gsi_to_irq[irq] = gsi;
+		if (gsi < MAX_GSI_NUM) {
+			if (gsi > 15)
+				gsi = pci_irq++;
+#ifdef CONFIG_ACPI_BUS
+			/*
+			 * Don't assign IRQ used by ACPI SCI
+			 */
+			if (gsi == acpi_fadt.sci_int)
+				gsi = pci_irq++;
+#endif
+			gsi_to_irq[irq] = gsi;
+		} else {
+			printk(KERN_ERR "GSI %u is too high\n", gsi);
+			return gsi;
+		}
 	}
 
 	io_apic_set_pci_routing(ioapic, ioapic_pin, gsi,
Index: xen-2005-08-19/arch/xen/x86_64/kernel/setup.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/setup.c	2005-08-19 14:36:59.812796152 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/setup.c	2005-08-19 14:37:13.376734120 +0200
@@ -986,8 +986,6 @@
 	int cpu = smp_processor_id();
 	int node = 0;
 	unsigned bits;
-	if (c->x86_num_cores == 1)
-		return;
 
 	bits = 0;
 	while ((1 << bits) < c->x86_num_cores)
@@ -1302,8 +1300,7 @@
 	else
 		mtrr_ap_init();
 #ifdef CONFIG_NUMA
-	if (c != &boot_cpu_data)
-		numa_add_cpu(c - cpu_data);
+	numa_add_cpu(smp_processor_id());
 #endif
 }
  
Index: xen-2005-08-19/arch/xen/x86_64/kernel/setup64.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/setup64.c	2005-08-19 14:34:38.081342608 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/setup64.c	2005-08-19 14:37:13.378733816 +0200
@@ -16,6 +16,7 @@
 #include <linux/string.h>
 #include <linux/bootmem.h>
 #include <linux/bitops.h>
+#include <linux/module.h>
 #include <asm/bootsetup.h>
 #include <asm/pda.h>
 #include <asm/pgtable.h>
@@ -26,10 +27,8 @@
 #include <asm/smp.h>
 #include <asm/i387.h>
 #include <asm/percpu.h>
-#include <asm/mtrr.h>
 #include <asm/proto.h>
-#include <asm/mman.h>
-#include <asm/numa.h>
+#include <asm/sections.h>
 #ifdef CONFIG_XEN
 #include <asm-xen/hypervisor.h>
 #endif
@@ -39,11 +38,6 @@
 
 struct x8664_pda cpu_pda[NR_CPUS] __cacheline_aligned; 
 
-extern struct task_struct init_task;
-
-extern unsigned char __per_cpu_start[], __per_cpu_end[]; 
-
-extern struct desc_ptr cpu_gdt_descr[];
 struct desc_ptr idt_descr = { 256 * 16, (unsigned long) idt_table }; 
 
 char boot_cpu_stack[IRQSTACKSIZE] __attribute__((section(".bss.page_aligned")));
@@ -107,7 +101,7 @@
 #endif
 
 	for (i = 0; i < NR_CPUS; i++) { 
-		unsigned char *ptr;
+		char *ptr;
 
 		if (!NODE_DATA(cpu_to_node(i))) {
 			printk("cpu with no node %d, num_online_nodes %d\n",
@@ -246,11 +240,7 @@
  */
 void __cpuinit cpu_init (void)
 {
-#ifdef CONFIG_SMP
 	int cpu = stack_smp_processor_id();
-#else
-	int cpu = smp_processor_id();
-#endif
 	struct tss_struct *t = &per_cpu(init_tss, cpu);
 	unsigned long v; 
 	char *estacks = NULL; 
@@ -270,7 +260,7 @@
 
 	printk("Initializing CPU#%d\n", cpu);
 
-		clear_in_cr4(X86_CR4_VME|X86_CR4_PVI|X86_CR4_TSD|X86_CR4_DE);
+	clear_in_cr4(X86_CR4_VME|X86_CR4_PVI|X86_CR4_TSD|X86_CR4_DE);
 
 	/*
 	 * Initialize the per-CPU GDT with the boot GDT,
Index: xen-2005-08-19/arch/xen/x86_64/kernel/smp.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/smp.c	2005-08-19 14:34:38.078343064 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/smp.c	2005-08-19 14:37:13.380733512 +0200
@@ -136,10 +136,9 @@
 		} else
 			leave_mm(cpu);
 	}
+out:
 	ack_APIC_irq();
 	cpu_clear(cpu, flush_cpumask);
-
-out:
 	put_cpu_no_resched();
 }
 
@@ -313,6 +312,69 @@
 }
 
 /*
+ * this function sends a 'generic call function' IPI to one other CPU
+ * in the system.
+ */
+static void __smp_call_function_single (int cpu, void (*func) (void *info), void *info,
+				int nonatomic, int wait)
+{
+	struct call_data_struct data;
+	int cpus = 1;
+
+	data.func = func;
+	data.info = info;
+	atomic_set(&data.started, 0);
+	data.wait = wait;
+	if (wait)
+		atomic_set(&data.finished, 0);
+
+	call_data = &data;
+	wmb();
+	/* Send a message to all other CPUs and wait for them to respond */
+	send_IPI_mask(cpumask_of_cpu(cpu), CALL_FUNCTION_VECTOR);
+
+	/* Wait for response */
+	while (atomic_read(&data.started) != cpus)
+		cpu_relax();
+
+	if (!wait)
+		return;
+
+	while (atomic_read(&data.finished) != cpus)
+		cpu_relax();
+}
+
+/*
+ * smp_call_function_single - Run a function on another CPU
+ * @func: The function to run. This must be fast and non-blocking.
+ * @info: An arbitrary pointer to pass to the function.
+ * @nonatomic: Currently unused.
+ * @wait: If true, wait until function has completed on other CPUs.
+ *
+ * Retrurns 0 on success, else a negative status code.
+ *
+ * Does not return until the remote CPU is nearly ready to execute <func>
+ * or is or has executed.
+ */
+
+int smp_call_function_single (int cpu, void (*func) (void *info), void *info,
+	int nonatomic, int wait)
+{
+	/* prevent preemption and reschedule on another processor */
+	int me = get_cpu();
+	if (cpu == me) {
+		WARN_ON(1);
+		put_cpu();
+		return -EBUSY;
+	}
+	spin_lock_bh(&call_lock);
+	__smp_call_function_single(cpu, func, info, nonatomic, wait);
+	spin_unlock_bh(&call_lock);
+	put_cpu();
+	return 0;
+}
+
+/*
  * this function sends a 'generic call function' IPI to all other CPUs
  * in the system.
  */
Index: xen-2005-08-19/arch/xen/x86_64/kernel/smpboot.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/smpboot.c	2005-08-19 14:37:12.063933696 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/smpboot.c	2005-08-19 14:37:13.383733056 +0200
@@ -126,24 +126,6 @@
 #define set_idle_for_cpu(x,p)   (idle_thread_array[(x)] = (p))
 
 /*
- * cpu_possible_map should be static, it cannot change as cpu's
- * are onlined, or offlined. The reason is per-cpu data-structures
- * are allocated by some modules at init time, and dont expect to
- * do this dynamically on cpu arrival/departure.
- * cpu_present_map on the other hand can change dynamically.
- * In case when cpu_hotplug is not compiled, then we resort to current
- * behaviour, which is cpu_possible == cpu_present.
- * If cpu-hotplug is supported, then we need to preallocate for all
- * those NR_CPUS, hence cpu_possible_map represents entire NR_CPUS range.
- * - Ashok Raj
- */
-#ifdef CONFIG_HOTPLUG_CPU
-#define fixup_cpu_possible_map(x)	cpu_set((x), cpu_possible_map)
-#else
-#define fixup_cpu_possible_map(x)
-#endif
-
-/*
  * Currently trivial. Write the real->protected mode
  * bootstrap into the page concerned. The caller
  * has made sure it's suitably aligned.
@@ -244,9 +226,6 @@
 {
 	unsigned long flags, i;
 
-	if (smp_processor_id() != 0)
-		return;
-
 	go[MASTER] = 0;
 
 	local_irq_save(flags);
@@ -295,7 +274,7 @@
 	return tcenter - best_tm;
 }
 
-static __cpuinit void sync_tsc(void)
+static __cpuinit void sync_tsc(unsigned int master)
 {
 	int i, done = 0;
 	long delta, adj, adjust_latency = 0;
@@ -309,9 +288,17 @@
 	} t[NUM_ROUNDS] __cpuinitdata;
 #endif
 
+	printk(KERN_INFO "CPU %d: Syncing TSC to CPU %u.\n",
+		smp_processor_id(), master);
+
 	go[MASTER] = 1;
 
-	smp_call_function(sync_master, NULL, 1, 0);
+	/* It is dangerous to broadcast IPI as cpus are coming up,
+	 * as they may not be ready to accept them.  So since
+	 * we only need to send the ipi to the boot cpu direct
+	 * the message, and avoid the race.
+	 */
+	smp_call_function_single(master, sync_master, NULL, 1, 0);
 
 	while (go[MASTER])	/* wait for master to be ready */
 		no_cpu_relax();
@@ -355,16 +342,14 @@
 	printk(KERN_INFO
 	       "CPU %d: synchronized TSC with CPU %u (last diff %ld cycles, "
 	       "maxerr %lu cycles)\n",
-	       smp_processor_id(), boot_cpu_id, delta, rt);
+	       smp_processor_id(), master, delta, rt);
 }
 
 static void __cpuinit tsc_sync_wait(void)
 {
 	if (notscsync || !cpu_has_tsc)
 		return;
-	printk(KERN_INFO "CPU %d: Syncing TSC to CPU %u.\n", smp_processor_id(),
-			boot_cpu_id);
-	sync_tsc();
+	sync_tsc(boot_cpu_id);
 }
 
 static __init int notscsync_setup(char *s)
@@ -845,8 +830,9 @@
 	initial_code = start_secondary;
 	clear_ti_thread_flag(c_idle.idle->thread_info, TIF_FORK);
 
-	printk(KERN_INFO "Booting processor %d/%d rip %lx rsp %lx\n", cpu, apicid,
-	       start_rip, init_rsp);
+	printk(KERN_INFO "Booting processor %d/%d APIC 0x%x\n", cpu,
+		cpus_weight(cpu_present_map),
+		apicid);
 
 	/*
 	 * This grunge runs the startup process for
@@ -1088,6 +1074,27 @@
 	}
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+/*
+ * cpu_possible_map should be static, it cannot change as cpu's
+ * are onlined, or offlined. The reason is per-cpu data-structures
+ * are allocated by some modules at init time, and dont expect to
+ * do this dynamically on cpu arrival/departure.
+ * cpu_present_map on the other hand can change dynamically.
+ * In case when cpu_hotplug is not compiled, then we resort to current
+ * behaviour, which is cpu_possible == cpu_present.
+ * If cpu-hotplug is supported, then we need to preallocate for all
+ * those NR_CPUS, hence cpu_possible_map represents entire NR_CPUS range.
+ * - Ashok Raj
+ */
+static void prefill_possible_map(void)
+{
+	int i;
+	for (i = 0; i < NR_CPUS; i++)
+		cpu_set(i, cpu_possible_map);
+}
+#endif
+
 /*
  * Various sanity checks.
  */
@@ -1158,8 +1165,6 @@
  */
 void __init smp_prepare_cpus(unsigned int max_cpus)
 {
-	int i;
-
 #if defined(CONFIG_XEN) && !defined(CONFIG_XEN_PRIVILEGED_GUEST)
 #else
 	nmi_watchdog_default();
@@ -1169,21 +1174,9 @@
 
 	enforce_max_cpus(max_cpus);
 
-	/*
-	 * Fill in cpu_present_mask
-	 */
-	for (i = 0; i < NR_CPUS; i++) {
-#ifndef CONFIG_XEN
-		int apicid = cpu_present_to_apicid(i);
-		if (physid_isset(apicid, phys_cpu_present_map)) {
-#else
-		if (i < HYPERVISOR_shared_info->n_vcpu) {
+#ifdef CONFIG_HOTPLUG_CPU
+	prefill_possible_map();
 #endif
-			cpu_set(i, cpu_present_map);
-			cpu_set(i, cpu_possible_map);
-		}
-		fixup_cpu_possible_map(i);
-	}
 
 	if (smp_sanity_check(max_cpus) < 0) {
 		printk(KERN_INFO "SMP disabled\n");
@@ -1386,8 +1379,7 @@
 			printk ("CPU %d is now offline\n", cpu);
 			return;
 		}
-		current->state = TASK_UNINTERRUPTIBLE;
-		schedule_timeout(HZ/10);
+		msleep(100);
 	}
 	printk(KERN_ERR "CPU %u didn't die...\n", cpu);
 }
Index: xen-2005-08-19/arch/xen/x86_64/kernel/traps.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/kernel/traps.c	2005-08-19 14:34:38.081342608 +0200
+++ xen-2005-08-19/arch/xen/x86_64/kernel/traps.c	2005-08-19 14:37:13.385732752 +0200
@@ -596,9 +596,6 @@
 	if (!cpu)
 		reason = get_nmi_reason();
 
-	if (!cpu_online(cpu))
-		return;
-
 	if (!(reason & 0xc0)) {
 		if (notify_die(DIE_NMI_IPI, "nmi_ipi", regs, reason, 0, SIGINT)
 								== NOTIFY_STOP)
Index: xen-2005-08-19/arch/xen/x86_64/mm/fault.c
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/mm/fault.c	2005-08-19 14:34:38.076343368 +0200
+++ xen-2005-08-19/arch/xen/x86_64/mm/fault.c	2005-08-19 14:37:13.387732448 +0200
@@ -24,7 +24,6 @@
 #include <linux/compiler.h>
 #include <linux/module.h>
 #include <linux/percpu.h>
-#include <linux/kprobes.h>
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
Index: xen-2005-08-19/include/asm-xen/asm-x86_64/desc.h
===================================================================
--- xen-2005-08-19.orig/include/asm-xen/asm-x86_64/desc.h	2005-08-19 14:34:38.083342304 +0200
+++ xen-2005-08-19/include/asm-xen/asm-x86_64/desc.h	2005-08-19 14:37:13.389732144 +0200
@@ -91,6 +91,7 @@
  */
 extern struct desc_struct default_ldt[];
 extern struct gate_struct idt_table[]; 
+extern struct desc_ptr cpu_gdt_descr[];
 
 static inline void _set_gate(void *adr, unsigned type, unsigned long func, unsigned dpl, unsigned ist)  
 {
Index: xen-2005-08-19/include/asm-xen/asm-x86_64/irq.h
===================================================================
--- xen-2005-08-19.orig/include/asm-xen/asm-x86_64/irq.h	2005-08-19 14:34:38.083342304 +0200
+++ xen-2005-08-19/include/asm-xen/asm-x86_64/irq.h	2005-08-19 14:37:13.390731992 +0200
@@ -38,4 +38,6 @@
 extern void fixup_irqs(cpumask_t map);
 #endif
 
+#define __ARCH_HAS_DO_SOFTIRQ 1
+
 #endif /* _ASM_IRQ_H */
Index: xen-2005-08-19/include/asm-xen/asm-x86_64/pgtable.h
===================================================================
--- xen-2005-08-19.orig/include/asm-xen/asm-x86_64/pgtable.h	2005-08-19 14:34:38.084342152 +0200
+++ xen-2005-08-19/include/asm-xen/asm-x86_64/pgtable.h	2005-08-19 14:37:13.393731536 +0200
@@ -216,6 +216,8 @@
 	(_PAGE_PRESENT | _PAGE_USER | _PAGE_ACCESSED | _PAGE_PCD | _PAGE_USER )
 #define __PAGE_KERNEL_LARGE \
 	(__PAGE_KERNEL | _PAGE_PSE | _PAGE_USER )
+#define __PAGE_KERNEL_LARGE_EXEC \
+	(__PAGE_KERNEL_EXEC | _PAGE_PSE | _PAGE_USER )
 
 
 /*
Index: xen-2005-08-19/include/asm-xen/asm-x86_64/smp.h
===================================================================
--- xen-2005-08-19.orig/include/asm-xen/asm-x86_64/smp.h	2005-08-19 14:34:38.083342304 +0200
+++ xen-2005-08-19/include/asm-xen/asm-x86_64/smp.h	2005-08-19 14:37:13.394731384 +0200
@@ -46,12 +46,12 @@
 extern void lock_ipi_call_lock(void);
 extern void unlock_ipi_call_lock(void);
 extern int smp_num_siblings;
-extern void smp_flush_tlb(void);
-extern void smp_message_irq(int cpl, void *dev_id, struct pt_regs *regs);
 extern void smp_send_reschedule(int cpu);
-extern void smp_invalidate_rcv(void);		/* Process an NMI */
 extern void zap_low_mappings(void);
 void smp_stop_cpu(void);
+extern int smp_call_function_single(int cpuid, void (*func) (void *info),
+				void *info, int retry, int wait);
+
 extern cpumask_t cpu_sibling_map[NR_CPUS];
 extern cpumask_t cpu_core_map[NR_CPUS];
 extern u8 phys_proc_id[NR_CPUS];
Index: xen-2005-08-19/include/asm-xen/asm-x86_64/system.h
===================================================================
--- xen-2005-08-19.orig/include/asm-xen/asm-x86_64/system.h	2005-08-19 14:34:38.084342152 +0200
+++ xen-2005-08-19/include/asm-xen/asm-x86_64/system.h	2005-08-19 14:37:13.396731080 +0200
@@ -120,12 +120,12 @@
 /*
  * Alternative inline assembly with input.
  * 
- * Pecularities:
+ * Peculiarities:
  * No memory clobber here. 
  * Argument numbers start with 1.
  * Best is to use constraints that are fixed size (like (%1) ... "r")
  * If you use variable sized constraints like "m" or "g" in the 
- * replacement maake sure to pad to the worst case length.
+ * replacement make sure to pad to the worst case length.
  */
 #define alternative_input(oldinstr, newinstr, feature, input...)	\
 	asm volatile ("661:\n\t" oldinstr "\n662:\n"			\
@@ -397,9 +397,6 @@
 void disable_hlt(void);
 void enable_hlt(void);
 
-#define HAVE_EAT_KEY
-void eat_key(void);
-
 extern unsigned long arch_align_stack(unsigned long sp);
 
 #endif
Index: xen-2005-08-19/include/asm-xen/asm-x86_64/tlbflush.h
===================================================================
--- xen-2005-08-19.orig/include/asm-xen/asm-x86_64/tlbflush.h	2005-08-19 14:34:38.085342000 +0200
+++ xen-2005-08-19/include/asm-xen/asm-x86_64/tlbflush.h	2005-08-19 14:37:13.397730928 +0200
@@ -32,8 +32,9 @@
  *  - flush_tlb_kernel_range(start, end) flushes a range of kernel pages
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  *
- * ..but the x86_64 has somewhat limited tlb flushing capabilities,
- * and page-granular flushes are available only on i486 and up.
+ * x86-64 can only flush individual pages or full VMs. For a range flush
+ * we always do the full VM. Might be worth trying if for a small
+ * range a few INVLPGs in a row are a win.
  */
 
 #ifndef CONFIG_SMP
@@ -91,7 +92,9 @@
 static inline void flush_tlb_pgtables(struct mm_struct *mm,
 				      unsigned long start, unsigned long end)
 {
-	/* x86_64 does not keep any page table caches in TLB */
+	/* x86_64 does not keep any page table caches in a software TLB.
+	   The CPUs do in their hardware TLBs, but they are handled
+	   by the normal TLB flushing algorithms. */
 }
 
 #endif /* _X8664_TLBFLUSH_H */
Index: xen-2005-08-19/arch/xen/x86_64/ia32/syscall32_syscall.S
===================================================================
--- /dev/null	1970-01-01 00:00:00.000000000 +0000
+++ xen-2005-08-19/arch/xen/x86_64/ia32/syscall32_syscall.S	2005-08-19 14:37:13.398730776 +0200
@@ -0,0 +1,34 @@
+#define USE_INT80
+
+#ifdef __ASSEMBLY__
+
+/* 32bit VDSOs mapped into user space. */
+
+	.section ".init.data","aw"
+
+#ifdef USE_INT80
+
+	.globl syscall32_int80
+	.globl syscall32_int80_end
+
+syscall32_int80:
+	.incbin "arch/x86_64/ia32/vsyscall-int80.so"
+syscall32_int80_end:
+
+#endif
+
+	.globl syscall32_syscall
+	.globl syscall32_syscall_end
+
+syscall32_syscall:
+	.incbin "arch/x86_64/ia32/vsyscall-syscall.so"
+syscall32_syscall_end:
+
+	.globl syscall32_sysenter
+	.globl syscall32_sysenter_end
+
+syscall32_sysenter:
+	.incbin "arch/x86_64/ia32/vsyscall-sysenter.so"
+syscall32_sysenter_end:
+
+#endif
Index: xen-2005-08-19/arch/xen/x86_64/ia32/Makefile
===================================================================
--- xen-2005-08-19.orig/arch/xen/x86_64/ia32/Makefile	2005-08-19 14:34:38.076343368 +0200
+++ xen-2005-08-19/arch/xen/x86_64/ia32/Makefile	2005-08-19 14:37:13.400730472 +0200
@@ -5,7 +5,7 @@
 
 CFLAGS	+= -Iarch/$(XENARCH)/kernel
 
-obj-$(CONFIG_IA32_EMULATION) := ia32entry.o syscall32.o
+obj-$(CONFIG_IA32_EMULATION) := ia32entry.o syscall32.o syscall32_syscall.o
 
 c-obj-$(CONFIG_IA32_EMULATION) := sys_ia32.o ia32_ioctl.o \
 	ia32_signal.o tls32.o \
@@ -18,7 +18,7 @@
 
 c-obj-$(CONFIG_IA32_AOUT) += ia32_aout.o
 
-$(obj)/syscall32.o: $(src)/syscall32.c \
+$(obj)/syscall32_syscall.o: \
 	$(foreach F,int80 sysenter syscall,$(obj)/vsyscall-$F.so)
 
 # Teach kbuild about targets
