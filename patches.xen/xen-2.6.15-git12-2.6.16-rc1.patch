Subject: Update Xen-specific files for 2.6.16-rc1
From: jbeulich@novell.com

Index: head-2006-01-19/arch/i386/xen/mm/init.c
===================================================================
--- head-2006-01-19.orig/arch/i386/xen/mm/init.c	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/arch/i386/xen/mm/init.c	2006-01-19 10:41:38.000000000 +0100
@@ -314,7 +314,7 @@ static void __init permanent_kmaps_init(
 	pkmap_page_table = pte;	
 }
 
-static void __devinit free_new_highpage(struct page *page, int pfn)
+static void __meminit free_new_highpage(struct page *page, int pfn)
 {
 	set_page_count(page, 1);
 	if (pfn < xen_start_info->nr_pages)
Index: head-2006-01-19/arch/x86_64/xen/ia32/Makefile
===================================================================
--- head-2006-01-19.orig/arch/x86_64/xen/ia32/Makefile	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/arch/x86_64/xen/ia32/Makefile	2006-01-19 10:41:38.000000000 +0100
@@ -6,7 +6,7 @@ CFLAGS	+= -Iarch/x86_64/kernel
 obj-$(CONFIG_IA32_EMULATION) := ia32entry.o syscall32.o syscall32_syscall.o
 
 c-obj-$(CONFIG_IA32_EMULATION) := sys_ia32.o ia32_signal.o tls32.o \
-	ia32_binfmt.o fpu32.o ptrace32.o 
+	ia32_binfmt.o fpu32.o ptrace32.o mmap32.o
 
 s-obj-y :=
 
Index: head-2006-01-19/arch/x86_64/xen/kernel/entry.S
===================================================================
--- head-2006-01-19.orig/arch/x86_64/xen/kernel/entry.S	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/arch/x86_64/xen/kernel/entry.S	2006-01-19 10:41:38.000000000 +0100
@@ -48,6 +48,7 @@
 #include <asm/unistd.h>
 #include <asm/thread_info.h>
 #include <asm/hw_irq.h>
+#include <asm/page.h>
 #include <asm/errno.h>
 #include <asm-xen/xen-public/arch-x86_64.h>
 
@@ -689,9 +690,6 @@ ENTRY(spurious_interrupt)
 #if 0
 	/* error code is on the stack already */
 	/* handle NMI like exceptions that can happen everywhere */
-#ifndef DEBUG_IST
-# define DEBUG_IST 0
-#endif
 	.macro paranoidentry sym, ist=0
         movq (%rsp),%rcx
         movq 8(%rsp),%r11
@@ -713,11 +711,11 @@ ENTRY(spurious_interrupt)
 	movq ORIG_RAX(%rsp),%rsi
 	movq $-1,ORIG_RAX(%rsp)
 	.if \ist
-	subq	$EXCEPTION_STACK_SIZE, per_cpu__init_tss + TSS_ist + (\ist - 1) * 8(%rbp)
+	subq	$EXCEPTION_STKSZ, per_cpu__init_tss + TSS_ist + (\ist - 1) * 8(%rbp)
 	.endif
 	call \sym
 	.if \ist
-	addq	$EXCEPTION_STACK_SIZE, per_cpu__init_tss + TSS_ist + (\ist - 1) * 8(%rbp)
+	addq	$EXCEPTION_STKSZ, per_cpu__init_tss + TSS_ist + (\ist - 1) * 8(%rbp)
 	.endif
 	cli
 	.endm
Index: head-2006-01-19/arch/x86_64/xen/kernel/head.S
===================================================================
--- head-2006-01-19.orig/arch/x86_64/xen/kernel/head.S	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/arch/x86_64/xen/kernel/head.S	2006-01-19 11:53:44.000000000 +0100
@@ -91,14 +91,19 @@ ENTRY(lgdt_finish)
 ENTRY(stext)
 ENTRY(_stext)
 
+	$page = 0
+#define NEXT_PAGE(name) \
+	$page = $page + 1; \
+	.org $page * 0x1000; \
+ENTRY(name)
+
 	/*
 	 * This default setting generates an ident mapping at address 0x100000
 	 * and a mapping for the kernel that precisely maps virtual address
 	 * 0xffffffff80000000 to physical address 0x000000. (always using
 	 * 2Mbyte large pages provided by PAE mode)
 	 */
-.org 0x1000
-ENTRY(init_level4_pgt)
+NEXT_PAGE(init_level4_pgt)
 	.fill	512,8,0
 
         /*
@@ -108,132 +113,29 @@ ENTRY(init_level4_pgt)
          * We also use this page to establish the initiali mapping for
          * vsyscall area.
          */
-.org 0x2000
-ENTRY(init_level4_user_pgt)
+NEXT_PAGE(init_level4_user_pgt)
 	.fill	512,8,0
 
 	/*
 	 * In Xen the following pre-initialized pgt entries are re-initialized.
 	 */
-.org 0x3000
-ENTRY(level3_kernel_pgt)
-	.fill	510,8,0
-	/* (2^48-(2*1024*1024*1024)-((2^39)*511))/(2^30) = 510 */
-	.quad	0x0000000000005007 + __PHYSICAL_START	/* -> level2_kernel_pgt */
-	.fill	1,8,0
-
-.org 0x4000
-ENTRY(level2_ident_pgt)
-	/* 40MB for bootup. 	*/
-	.quad	0x0000000000000083
-	.quad	0x0000000000200083
-	.quad	0x0000000000400083
-	.quad	0x0000000000600083
-	.quad	0x0000000000800083
-	.quad	0x0000000000A00083
-	.quad	0x0000000000C00083
-	.quad	0x0000000000E00083
-	.quad	0x0000000001000083
-	.quad	0x0000000001200083
-	.quad	0x0000000001400083
-	.quad	0x0000000001600083
-	.quad	0x0000000001800083
-	.quad	0x0000000001A00083
-	.quad	0x0000000001C00083
-	.quad	0x0000000001E00083
-	.quad	0x0000000002000083
-	.quad	0x0000000002200083
-	.quad	0x0000000002400083
-	.quad	0x0000000002600083
-	/* Temporary mappings for the super early allocator in arch/x86_64/mm/init.c */
-	.globl temp_boot_pmds
-temp_boot_pmds:
-	.fill	492,8,0
-
-.org 0x5000
-ENTRY(level2_kernel_pgt)
-	/* 40MB kernel mapping. The kernel code cannot be bigger than that.
-	   When you change this change KERNEL_TEXT_SIZE in page.h too. */
-	/* (2^48-(2*1024*1024*1024)-((2^39)*511)-((2^30)*510)) = 0 */
-	.quad	0x0000000000000183
-	.quad	0x0000000000200183
-	.quad	0x0000000000400183
-	.quad	0x0000000000600183
-	.quad	0x0000000000800183
-	.quad	0x0000000000A00183
-	.quad	0x0000000000C00183
-	.quad	0x0000000000E00183
-	.quad	0x0000000001000183
-	.quad	0x0000000001200183
-	.quad	0x0000000001400183
-	.quad	0x0000000001600183
-	.quad	0x0000000001800183
-	.quad	0x0000000001A00183
-	.quad	0x0000000001C00183
-	.quad	0x0000000001E00183
-	.quad	0x0000000002000183
-	.quad	0x0000000002200183
-	.quad	0x0000000002400183
-	.quad	0x0000000002600183
-	/* Module mapping starts here */
-	.fill	492,8,0
-	
+NEXT_PAGE(level3_kernel_pgt)
+	.fill	512,8,0
+
         /*
          * This is used for vsyscall area mapping as we have a different
          * level4 page table for user.
          */
-.org 0x6000
-ENTRY(level3_user_pgt)
-        .fill	512,8,0
-
-.org 0x7000
-.org 0x8000
-ENTRY(empty_zero_page)
-
-.org 0x9000
-ENTRY(empty_bad_page)
-
-.org 0xa000
-ENTRY(empty_bad_pte_table)
-
-.org 0xb000
-ENTRY(empty_bad_pmd_table)
-
-.org 0xc000
-ENTRY(level3_physmem_pgt)
-	.quad	0x0000000000005007 + __PHYSICAL_START	/* -> level2_kernel_pgt (so that __va works even before pagetable_init) */
-
-	
-	.org 0xd000
-#ifdef CONFIG_ACPI_SLEEP
-ENTRY(wakeup_level4_pgt)
-	.quad	0x0000000000002007 + __PHYSICAL_START	/* -> level3_ident_pgt */
-	.fill	255,8,0
-	.quad	0x000000000000a007 + __PHYSICAL_START
-	.fill	254,8,0
-	/* (2^48-(2*1024*1024*1024))/(2^39) = 511 */
-	.quad	0x0000000000003007 + __PHYSICAL_START	/* -> level3_kernel_pgt */
-#endif
+NEXT_PAGE(level3_user_pgt)
+	.fill	512,8,0
 
-#ifndef CONFIG_XEN
-#ifndef CONFIG_HOTPLUG_CPU
-	__INITDATA
-#endif
-	/*
-	 * This default setting generates an ident mapping at address 0x100000
-	 * and a mapping for the kernel that precisely maps virtual address
-	 * 0xffffffff80000000 to physical address 0x000000. (always using
-	 * 2Mbyte large pages provided by PAE mode)
-	 */
-	.align PAGE_SIZE
-ENTRY(boot_level4_pgt)
-	.quad	0x0000000000002007 + __PHYSICAL_START	/* -> level3_ident_pgt */
-	.fill	255,8,0
-	.quad	0x000000000000a007 + __PHYSICAL_START
-	.fill	254,8,0
-	/* (2^48-(2*1024*1024*1024))/(2^39) = 511 */
-	.quad	0x0000000000003007 + __PHYSICAL_START	/* -> level3_kernel_pgt */
-#endif
+NEXT_PAGE(level2_kernel_pgt)
+	.fill	512,8,0
+
+NEXT_PAGE(empty_zero_page)
+	.fill	512,8,0
+
+#undef NEXT_PAGE
 
 	.data
 
Index: head-2006-01-19/arch/x86_64/xen/kernel/setup64.c
===================================================================
--- head-2006-01-19.orig/arch/x86_64/xen/kernel/setup64.c	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/arch/x86_64/xen/kernel/setup64.c	2006-01-19 10:42:59.000000000 +0100
@@ -45,7 +45,7 @@ struct desc_ptr idt_descr = { 256 * 16, 
 char boot_cpu_stack[IRQSTACKSIZE] __attribute__((section(".bss.page_aligned")));
 
 unsigned long __supported_pte_mask __read_mostly = ~0UL;
-static int do_not_nx __initdata = 0;
+static int do_not_nx __cpuinitdata = 0;
 
 /* noexec=on|off
 Control non executable mappings for 64bit processes.
Index: head-2006-01-19/arch/x86_64/xen/mm/Makefile
===================================================================
--- head-2006-01-19.orig/arch/x86_64/xen/mm/Makefile	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/arch/x86_64/xen/mm/Makefile	2006-01-19 10:41:38.000000000 +0100
@@ -5,7 +5,7 @@
 CFLAGS	+= -Iarch/x86_64/mm
 
 obj-y	:= init.o fault.o pageattr.o
-c-obj-y	:= extable.o
+c-obj-y	:= extable.o mmap.o
 
 i386-obj-y := hypervisor.o ioremap.o
 
@@ -22,7 +22,7 @@ $(patsubst %.o,$(obj)/%.c,$(c-obj-y) $(c
 	@ln -fsn $(srctree)/arch/x86_64/mm/$(notdir $@) $@
 
 $(patsubst %.o,$(obj)/%.c,$(i386-obj-y)):
-	ln -fsn $(srctree)/arch/i386/xen/mm/$(notdir $@) $@
+	@ln -fsn $(srctree)/arch/i386/xen/mm/$(notdir $@) $@
 
 obj-y	+= $(c-obj-y) $(i386-obj-y)
 
Index: head-2006-01-19/arch/x86_64/xen/mm/init.c
===================================================================
--- head-2006-01-19.orig/arch/x86_64/xen/mm/init.c	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/arch/x86_64/xen/mm/init.c	2006-01-19 12:02:47.000000000 +0100
@@ -27,6 +27,8 @@
 #include <linux/proc_fs.h>
 #include <linux/pci.h>
 #include <linux/dma-mapping.h>
+#include <linux/module.h>
+#include <linux/memory_hotplug.h>
 
 #include <asm/processor.h>
 #include <asm/system.h>
@@ -376,9 +378,17 @@ unsigned long get_machine_pfn(unsigned l
         return pte_mfn(*pte);
 } 
 
-static __init void *alloc_static_page(unsigned long *phys)
+static __meminit void *alloc_static_page(unsigned long *phys)
 {
 	unsigned long va = (start_pfn << PAGE_SHIFT) + __START_KERNEL_map;
+
+	if (after_bootmem) {
+		void *adr = (void *)get_zeroed_page(GFP_ATOMIC);
+
+		*phys = __pa(adr);
+		return adr;
+	}
+
 	*phys = start_pfn << PAGE_SHIFT;
 	start_pfn++;
 	memset((void *)va, 0, PAGE_SIZE);
@@ -411,60 +421,81 @@ static inline int make_readonly(unsigned
 	return readonly;
 }
 
-static void __init phys_pud_init(pud_t *pud, unsigned long address, unsigned long end)
+static void __meminit
+phys_pmd_init(pmd_t *pmd, unsigned long address, unsigned long end)
+{
+	unsigned i, k;
+
+	for (i = 0; i < PTRS_PER_PMD; pmd++, i++) {
+		unsigned long pte_phys;
+		pte_t *pte, *pte_save;
+
+		if (address >= end) {
+			for (; i < PTRS_PER_PMD; i++, pmd++)
+				set_pmd(pmd,  __pmd(0));
+			break;
+		}
+		pte = alloc_static_page(&pte_phys);
+		pte_save = pte;
+		for (k = 0; k < PTRS_PER_PTE; pte++, k++, address += PTE_SIZE) {
+			if ((address >= end) ||
+			    ((address >> PAGE_SHIFT) >= xen_start_info->nr_pages)) {
+				__set_pte(pte, __pte(0));
+				continue;
+			}
+			if (make_readonly(address)) {
+				__set_pte(pte,
+				          __pte(address | (_KERNPG_TABLE & ~_PAGE_RW)));
+				continue;
+			}
+			__set_pte(pte, __pte(address | _KERNPG_TABLE));
+		}
+		pte = pte_save;
+		early_make_page_readonly(pte);
+		xen_pte_pin(pte_phys);
+		set_pmd(pmd, __pmd(pte_phys | _KERNPG_TABLE));
+	}
+}
+
+static void __meminit
+phys_pmd_update(pud_t *pud, unsigned long address, unsigned long end)
+{
+	pmd_t *pmd = pmd_offset(pud, (unsigned long)__va(address));
+
+	if (pmd_none(*pmd)) {
+		spin_lock(&init_mm.page_table_lock);
+		phys_pmd_init(pmd, address, end);
+		spin_unlock(&init_mm.page_table_lock);
+		__flush_tlb_all();
+	}
+}
+
+static void __meminit phys_pud_init(pud_t *pud, unsigned long address, unsigned long end)
 { 
-        long i, j, k; 
-        unsigned long paddr;
+	long i = pud_index(address);
 
-	i = pud_index(address);
 	pud = pud + i;
 
+	if (after_bootmem && pud_val(*pud)) {
+		phys_pmd_update(pud, address, end);
+		return;
+	}
+
 	for (; i < PTRS_PER_PUD; pud++, i++) {
-		unsigned long pmd_phys;
+		unsigned long paddr, pmd_phys;
 		pmd_t *pmd;
 
-		paddr = address + i*PUD_SIZE;
-		if (paddr >= end) { 
-			for (; i < PTRS_PER_PUD; i++, pud++) 
-				set_pud(pud, __pud(0)); 
+		paddr = (address & PGDIR_MASK) + i*PUD_SIZE;
+		if (paddr >= end)
 			break;
-		} 
 
 		pmd = alloc_static_page(&pmd_phys);
                 early_make_page_readonly(pmd);
                 xen_pmd_pin(pmd_phys);
+		spin_lock(&init_mm.page_table_lock);
 		set_pud(pud, __pud(pmd_phys | _KERNPG_TABLE));
-
-      		for (j = 0; j < PTRS_PER_PMD; pmd++, j++) {
-                        unsigned long pte_phys;
-                        pte_t *pte, *pte_save;
-
-			if (paddr >= end) { 
-				for (; j < PTRS_PER_PMD; j++, pmd++)
-					set_pmd(pmd,  __pmd(0)); 
-				break;
-			}
-                        pte = alloc_static_page(&pte_phys);
-                        pte_save = pte;
-                        for (k = 0; k < PTRS_PER_PTE; pte++, k++, paddr += PTE_SIZE) {
-                                if ((paddr >= end) ||
-                                    ((paddr >> PAGE_SHIFT) >=
-                                     xen_start_info->nr_pages)) { 
-                                        __set_pte(pte, __pte(0)); 
-                                        continue;
-                                }
-                                if (make_readonly(paddr)) {
-                                        __set_pte(pte, 
-                                                __pte(paddr | (_KERNPG_TABLE & ~_PAGE_RW)));
-                                        continue;
-                                }
-                                __set_pte(pte, __pte(paddr | _KERNPG_TABLE));
-                        }
-                        pte = pte_save;
-                        early_make_page_readonly(pte);  
-                        xen_pte_pin(pte_phys);
-			set_pmd(pmd, __pmd(pte_phys | _KERNPG_TABLE));
-		}
+		phys_pmd_init(pmd, paddr, end);
+		spin_unlock(&init_mm.page_table_lock);
 	}
 	__flush_tlb();
 } 
@@ -481,6 +512,9 @@ static void __init find_early_table_spac
 		round_up(puds * 8, PAGE_SIZE) + 
 		round_up(pmds * 8, PAGE_SIZE) + 
 		round_up(ptes * 8, PAGE_SIZE); 
+
+	printk("kernel direct mapping tables upto %lx @ %lx-%lx\n",
+	       __pa(end), table_start<<PAGE_SHIFT, start_pfn<<PAGE_SHIFT);
 }
 
 void __init xen_init_pt(void)
@@ -582,36 +616,44 @@ void __init extend_init_mapping(void) 
 /* Setup the direct mapping of the physical memory at PAGE_OFFSET.
    This runs before bootmem is initialized and gets pages directly from the 
    physical memory. To access them they are temporarily mapped. */
-void __init init_memory_mapping(unsigned long start, unsigned long end)
+void __meminit init_memory_mapping(unsigned long start, unsigned long end)
 { 
 	unsigned long next; 
 
 	Dprintk("init_memory_mapping\n");
 
-	find_early_table_space(end);
-	extend_init_mapping();
-
-	table_start = start_pfn;
+	if (!after_bootmem) {
+		find_early_table_space(end);
+		extend_init_mapping();
+		table_start = start_pfn;
+	}
 
 	start = (unsigned long)__va(start);
 	end = (unsigned long)__va(end);
 
 	for (; start < end; start = next) {
 		unsigned long pud_phys; 
-		pud_t *pud = alloc_static_page(&pud_phys);
-		early_make_page_readonly(pud);
+		pud_t *pud;
+
+		if (after_bootmem) {
+			pud = pud_offset_k(start & PGDIR_MASK);
+			make_page_readonly(pud);
+			pud_phys = __pa(pud);
+		}
+		else {
+			pud = alloc_static_page(&pud_phys);
+			early_make_page_readonly(pud);
+		}
 		xen_pud_pin(pud_phys);
 		next = start + PGDIR_SIZE;
 		if (next > end) 
 			next = end; 
 		phys_pud_init(pud, __pa(start), __pa(next));
-		set_pgd(pgd_offset_k(start), mk_kernel_pgd(pud_phys));
+		if (!after_bootmem)
+			set_pgd(pgd_offset_k(start), mk_kernel_pgd(pud_phys));
 	}
 
-	printk("kernel direct mapping tables upto %lx @ %lx-%lx\n",
-	       __pa(end), table_start<<PAGE_SHIFT, start_pfn<<PAGE_SHIFT);
-
-	BUG_ON(start_pfn != (table_start + (tables_space >> PAGE_SHIFT)));
+	BUG_ON(!after_bootmem && start_pfn != table_start + (tables_space >> PAGE_SHIFT));
 
 	__flush_tlb_all();
 }
@@ -687,6 +729,9 @@ size_zones(unsigned long *z, unsigned lo
 void __init paging_init(void)
 {
 	unsigned long zones[MAX_NR_ZONES], holes[MAX_NR_ZONES];
+
+	memory_present(0, 0, end_pfn);
+	sparse_init();
 	size_zones(zones, holes, 0, end_pfn);
 	free_area_init_node(0, NODE_DATA(0), zones,
 			    __pa(PAGE_OFFSET) >> PAGE_SHIFT, holes);
@@ -748,6 +793,50 @@ void __init clear_kernel_mapping(unsigne
 	__flush_tlb_all();
 } 
 
+/*
+ * Memory hotplug specific functions
+ * These are only for non-NUMA machines right now.
+ */
+#ifdef CONFIG_MEMORY_HOTPLUG
+
+void online_page(struct page *page)
+{
+	ClearPageReserved(page);
+	set_page_count(page, 1);
+	__free_page(page);
+	totalram_pages++;
+	num_physpages++;
+}
+
+int add_memory(u64 start, u64 size)
+{
+	struct pglist_data *pgdat = NODE_DATA(0);
+	struct zone *zone = pgdat->node_zones + MAX_NR_ZONES-2;
+	unsigned long start_pfn = start >> PAGE_SHIFT;
+	unsigned long nr_pages = size >> PAGE_SHIFT;
+	int ret;
+
+	ret = __add_pages(zone, start_pfn, nr_pages);
+	if (ret)
+		goto error;
+
+	init_memory_mapping(start, (start + size -1));
+
+	return ret;
+error:
+	printk("%s: Problem encountered in __add_pages!\n", __func__);
+	return ret;
+}
+EXPORT_SYMBOL_GPL(add_memory);
+
+int remove_memory(u64 start, u64 size)
+{
+	return -EINVAL;
+}
+EXPORT_SYMBOL_GPL(remove_memory);
+
+#endif
+
 static struct kcore_list kcore_mem, kcore_vmalloc, kcore_kernel, kcore_modules,
 			 kcore_vsyscall;
 
@@ -872,7 +961,7 @@ void mark_rodata_ro(void)
 #ifdef CONFIG_BLK_DEV_INITRD
 void free_initrd_mem(unsigned long start, unsigned long end)
 {
-	if (start < (unsigned long)&_end)
+	if (start >= end)
 		return;
 	printk ("Freeing initrd memory: %ldk freed\n", (end - start) >> 10);
 	for (; start < end; start += PAGE_SIZE) {
Index: head-2006-01-19/include/asm-x86_64/mach-xen/asm/page.h
===================================================================
--- head-2006-01-19.orig/include/asm-x86_64/mach-xen/asm/page.h	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/include/asm-x86_64/mach-xen/asm/page.h	2006-01-19 10:41:38.000000000 +0100
@@ -46,6 +46,13 @@
 #define IRQSTACK_ORDER 2
 #define IRQSTACKSIZE (PAGE_SIZE << IRQSTACK_ORDER)
 
+#define STACKFAULT_STACK 1
+#define DOUBLEFAULT_STACK 2
+#define NMI_STACK 3
+#define DEBUG_STACK 4
+#define MCE_STACK 5
+#define N_EXCEPTION_STACKS 5  /* hw limit: 7 */
+
 #define LARGE_PAGE_MASK (~(LARGE_PAGE_SIZE-1))
 #define LARGE_PAGE_SIZE (1UL << PMD_SHIFT)
 
Index: head-2006-01-19/include/asm-x86_64/mach-xen/asm/processor.h
===================================================================
--- head-2006-01-19.orig/include/asm-x86_64/mach-xen/asm/processor.h	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/include/asm-x86_64/mach-xen/asm/processor.h	2006-01-19 11:53:38.000000000 +0100
@@ -298,13 +298,6 @@ struct thread_struct {
 #define INIT_MMAP \
 { &init_mm, 0, 0, NULL, PAGE_SHARED, VM_READ | VM_WRITE | VM_EXEC, 1, NULL, NULL }
 
-#define STACKFAULT_STACK 1
-#define DOUBLEFAULT_STACK 2 
-#define NMI_STACK 3 
-#define DEBUG_STACK 4 
-#define MCE_STACK 5
-#define N_EXCEPTION_STACKS 5  /* hw limit: 7 */
-
 #define start_thread(regs,new_rip,new_rsp) do { \
 	asm volatile("movl %0,%%fs; movl %0,%%es; movl %0,%%ds": :"r" (0));	 \
 	load_gs_index(0);							\
@@ -506,4 +499,6 @@ extern unsigned long boot_option_idle_ov
 /* Boot loader type from the setup header */
 extern int bootloader_type;
 
+#define HAVE_ARCH_PICK_MMAP_LAYOUT 1
+
 #endif /* __ASM_X86_64_PROCESSOR_H */
Index: head-2006-01-19/include/asm-x86_64/mach-xen/asm/system.h
===================================================================
--- head-2006-01-19.orig/include/asm-x86_64/mach-xen/asm/system.h	2006-01-19 10:41:20.000000000 +0100
+++ head-2006-01-19/include/asm-x86_64/mach-xen/asm/system.h	2006-01-19 10:41:38.000000000 +0100
@@ -392,9 +392,6 @@ do {									\
 		preempt_enable_no_resched();				\
 } while (0)
 
-#define safe_halt()		((void)0)
-#define halt()			((void)0)
-
 #define __save_and_cli(x)						\
 do {									\
 	vcpu_info_t *_vcpu;						\
@@ -406,6 +403,9 @@ do {									\
 	barrier();							\
 } while (0)
 
+#define safe_halt()		((void)0)
+#define halt()			((void)0)
+
 void cpu_idle_wait(void);
 
 #define local_irq_save(x)	__save_and_cli(x)
