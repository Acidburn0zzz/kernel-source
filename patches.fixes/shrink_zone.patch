note! this has slightly different math then the original patch

original:
 		max_scan = (zone->nr_inactive + zone->nr_inactive) >> priority;

suse:
 		max_scan = (zone->nr_active + zone->nr_inactive) >> priority;

# This is a BitKeeper generated diff -Nru style patch.
#
# ChangeSet
#   2004/05/19 16:35:17-07:00 akpm@osdl.org 
#   [PATCH] Fix arithmetic in shrink_zone()
#   
#   From: Nick Piggin <nickpiggin@yahoo.com.au>
#   
#   If the zone has a very small number of inactive pages, local variable
#   `ratio' can be huge and we do way too much scanning.  So much so that Ingo
#   hit an NMI watchdog expiry, although that was because the zone would have a
#   had a single refcount-zero page in it, and that logic recently got fixed up
#   via get_page_testone().
#   
#   Nick's patch simply puts a sane-looking upper bound on the number of pages
#   which we'll scan in this round.
#   
#   
#   It fixes another failure case: if the inactive list becomes very small
#   compared to the size of the active list, active list scanning (and therefore
#   inactive list refilling) also becomes small.
#   
#   This patch causes inactive list scanning to be keyed off the size of the
#   active+inactive lists.  It has the plus of hiding active and inactive
#   balancing implementation from the higher level scanning code.  It will
#   slightly change other aspects of scanning behaviour, but probably not
#   significantly.
# 
# mm/vmscan.c
#   2004/05/19 09:02:49-07:00 akpm@osdl.org +22 -11
#   Fix arithmetic in shrink_zone()
# 
diff -uNrp linux-2.6.5/mm/vmscan.c linux-2.6.5.shrink_zone/mm/vmscan.c
--- linux-2.6.5/mm/vmscan.c	2004-06-02 16:57:42.000000000 +0200
+++ linux-2.6.5.shrink_zone/mm/vmscan.c	2004-06-02 17:00:05.000000000 +0200
@@ -737,23 +737,33 @@ static int
 shrink_zone(struct zone *zone, int max_scan, unsigned int gfp_mask,
 		int *total_scanned, struct page_state *ps)
 {
-	unsigned long ratio;
+	unsigned long scan_active;
 	int count;
 
 	/*
 	 * Try to keep the active list 2/3 of the size of the cache.  And
 	 * make sure that refill_inactive is given a decent number of pages.
 	 *
-	 * The "ratio+1" here is important.  With pagecache-intensive workloads
-	 * the inactive list is huge, and `ratio' evaluates to zero all the
-	 * time.  Which pins the active list memory.  So we add one to `ratio'
-	 * just to make sure that the kernel will slowly sift through the
-	 * active list.
+	 * The "scan_active + 1" here is important.  With pagecache-intensive
+	 * workloads the inactive list is huge, and `ratio' evaluates to zero
+	 * all the time.  Which pins the active list memory.  So we add one to
+	 * `scan_active' just to make sure that the kernel will slowly sift
+	 * through the active list.
 	 */
-	ratio = (unsigned long)SWAP_CLUSTER_MAX * zone->nr_active /
-				((zone->nr_inactive | 1) * 2);
+	if (zone->nr_active >= 4*(zone->nr_inactive*2 + 1)) {
+		/* Don't scan more than 4 times the inactive list scan size */
+		scan_active = 4*max_scan;
+	} else {
+		unsigned long long tmp;
+
+		/* Cast to long long so the multiply doesn't overflow */
+
+		tmp = (unsigned long long)max_scan * zone->nr_active;
+		do_div(tmp, zone->nr_inactive*2 + 1);
+		scan_active = (unsigned long)tmp;
+	}
 
-	atomic_add(ratio+1, &zone->nr_scan_active);
+	atomic_add(scan_active + 1, &zone->nr_scan_active);
 	count = atomic_read(&zone->nr_scan_active);
 	if (count >= SWAP_CLUSTER_MAX) {
 		atomic_set(&zone->nr_scan_active, 0);
@@ -802,7 +812,7 @@ shrink_caches(struct zone **zones, int p
 		if (zone->all_unreclaimable && priority != DEF_PRIORITY)
 			continue;	/* Let kswapd poll it */
 
-		max_scan = zone->nr_inactive >> priority;
+		max_scan = (zone->nr_active + zone->nr_inactive) >> priority;
 		ret += shrink_zone(zone, max_scan, gfp_mask, total_scanned, ps);
 	}
 	return ret;
@@ -967,7 +977,8 @@ scan:
 					all_zones_ok = 0;
 			}
 			zone->temp_priority = priority;
-			max_scan = zone->nr_inactive >> priority;
+			max_scan = (zone->nr_active + zone->nr_inactive)
+								>> priority;
 			reclaimed = shrink_zone(zone, max_scan, GFP_KERNEL,
 					&total_scanned, ps);
 			total_scanned += pages_scanned;
