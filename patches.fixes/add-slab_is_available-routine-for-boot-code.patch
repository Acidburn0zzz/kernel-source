Subject: [PATCH] add slab_is_available() routine for boot code                                                                                                        
From: Mike Kravetz <kravetz@us.ibm.com>                                                                                                                               
References: 175093 - LTC23814

slab_is_available() indicates slab based allocators are available
for use.  SPARSEMEM code needs to know this as it can be called
at various times during the boot process.

Signed-off-by: Mike Kravetz <kravetz@us.ibm.com>
Signed-off-by: Olaf Hering <olh@suse.de>

---
 include/linux/slab.h |    1 +
 mm/slab.c            |    8 ++++++++
 mm/sparse.c          |    9 ++++++---
 3 files changed, 15 insertions(+), 3 deletions(-)

Index: linux-2.6.16/include/linux/slab.h
===================================================================
--- linux-2.6.16.orig/include/linux/slab.h
+++ linux-2.6.16/include/linux/slab.h
@@ -125,6 +125,7 @@ static inline void *kcalloc(size_t n, si
 
 extern void kfree(const void *);
 extern unsigned int ksize(const void *);
+extern int slab_is_available(void);
 
 #ifdef CONFIG_NUMA
 extern void *kmem_cache_alloc_node(kmem_cache_t *, gfp_t flags, int node);
Index: linux-2.6.16/mm/slab.c
===================================================================
--- linux-2.6.16.orig/mm/slab.c
+++ linux-2.6.16/mm/slab.c
@@ -673,6 +673,14 @@ static enum {
 	FULL
 } g_cpucache_up;
 
+/*
+ * used by boot code to determine if it can use slab based allocator
+ */
+int slab_is_available(void)
+{
+	return g_cpucache_up == FULL;
+}
+
 static DEFINE_PER_CPU(struct work_struct, reap_work);
 
 static void free_block(struct kmem_cache *cachep, void **objpp, int len, int node);
Index: linux-2.6.16/mm/sparse.c
===================================================================
--- linux-2.6.16.orig/mm/sparse.c
+++ linux-2.6.16/mm/sparse.c
@@ -32,7 +32,10 @@ static struct mem_section *sparse_index_
 	unsigned long array_size = SECTIONS_PER_ROOT *
 				   sizeof(struct mem_section);
 
-	section = alloc_bootmem_node(NODE_DATA(nid), array_size);
+	if (slab_is_available())
+		section = kmalloc_node(array_size, GFP_KERNEL, nid);
+	else
+		section = alloc_bootmem_node(NODE_DATA(nid), array_size);
 
 	if (section)
 		memset(section, 0, array_size);
@@ -281,9 +284,9 @@ int sparse_add_one_section(struct zone *
 
 	ret = sparse_init_one_section(ms, section_nr, memmap);
 
-	if (ret <= 0)
-		__kfree_section_memmap(memmap, nr_pages);
 out:
 	pgdat_resize_unlock(pgdat, &flags);
+	if (ret <= 0)
+		__kfree_section_memmap(memmap, nr_pages);
 	return ret;
 }
