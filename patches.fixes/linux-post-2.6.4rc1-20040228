diff -purN linux-post-2.6.3-20040227/arch/arm/Makefile linux-post-2.6.4rc1-20040228/arch/arm/Makefile
--- linux-post-2.6.3-20040227/arch/arm/Makefile	2004-02-19 03:43:07.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/Makefile	2004-02-26 14:22:24.000000000 +0000
@@ -31,6 +31,7 @@ comma = ,
 # Note that GCC does not numerically define an architecture version
 # macro, but instead defines a whole series of macros which makes
 # testing for a specific architecture or later rather impossible.
+arch-$(CONFIG_CPU_32v6)		:=-D__LINUX_ARM_ARCH__=6 -march=armv5t -Wa,-march=armv6
 arch-$(CONFIG_CPU_32v5)		:=-D__LINUX_ARM_ARCH__=5 $(call check_gcc,-march=armv5te,-march=armv4)
 arch-$(CONFIG_CPU_32v4)		:=-D__LINUX_ARM_ARCH__=4 -march=armv4
 arch-$(CONFIG_CPU_32v3)		:=-D__LINUX_ARM_ARCH__=3 -march=armv3
@@ -45,6 +46,7 @@ tune-$(CONFIG_CPU_ARM926T)	:=-mtune=arm9
 tune-$(CONFIG_CPU_SA110)	:=-mtune=strongarm110
 tune-$(CONFIG_CPU_SA1100)	:=-mtune=strongarm1100
 tune-$(CONFIG_CPU_XSCALE)	:=$(call check_gcc,-mtune=xscale,-mtune=strongarm110) -Wa,-mcpu=xscale
+tune-$(CONFIG_CPU_V6)		:=-mtune=strongarm
 
 # Need -Uarm for gcc < 3.x
 CFLAGS_BOOT	:=-mapcs-32 $(arch-y) $(tune-y) -mshort-load-bytes -msoft-float -Wa,-mno-fpu -Uarm
diff -purN linux-post-2.6.3-20040227/arch/arm/boot/compressed/head.S linux-post-2.6.4rc1-20040228/arch/arm/boot/compressed/head.S
--- linux-post-2.6.3-20040227/arch/arm/boot/compressed/head.S	2003-10-14 19:58:50.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/boot/compressed/head.S	2004-02-27 16:35:10.000000000 +0000
@@ -585,7 +585,7 @@ __armv3_cache_off:
  * On entry,
  *  r6 = processor ID
  * On exit,
- *  r1, r2, r3, r12 corrupted
+ *  r1, r2, r3, r11, r12 corrupted
  * This routine must preserve:
  *  r0, r4, r5, r6, r7
  */
@@ -595,9 +595,25 @@ cache_clean_flush:
 		b	call_cache_fn
 
 __armv4_cache_flush:
-		bic	r1, pc, #31
-		add	r2, r1, #65536		@ 2x the largest dcache size
-1:		ldr	r3, [r1], #32		@ s/w flush D cache
+		mov	r2, #64*1024		@ default: 32K dcache size (*2)
+		mov	r11, #32		@ default: 32 byte line size
+		mrc	p15, 0, r3, c0, c0, 1	@ read cache type
+		teq	r3, r6			@ cache ID register present?
+		beq	no_cache_id
+		mov	r1, r3, lsr #18
+		and	r1, r1, #7
+		mov	r2, #1024
+		mov	r2, r2, lsl r1		@ base dcache size *2
+		tst	r3, #1 << 14		@ test M bit
+		addne	r2, r2, r2, lsr #1	@ +1/2 size if M == 1
+		mov	r3, r3, lsr #12
+		and	r3, r3, #3
+		mov	r11, #8
+		mov	r11, r11, lsl r3	@ cache line size in bytes
+no_cache_id:
+		bic	r1, pc, #63		@ align to longest cache line
+		add	r2, r1, r2
+1:		ldr	r3, [r1], r11		@ s/w flush D cache
 		teq	r1, r2
 		bne	1b
 
diff -purN linux-post-2.6.3-20040227/arch/arm/common/Makefile linux-post-2.6.4rc1-20040228/arch/arm/common/Makefile
--- linux-post-2.6.3-20040227/arch/arm/common/Makefile	2003-06-18 22:23:20.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/common/Makefile	2004-02-27 14:00:38.000000000 +0000
@@ -5,6 +5,6 @@
 obj-y				+= platform.o
 obj-$(CONFIG_ARM_AMBA)		+= amba.o
 obj-$(CONFIG_ICST525)		+= icst525.o
-obj-$(CONFIG_SA1111)		+= sa1111.o sa1111-pcibuf.o sa1111-pcipool.o
+obj-$(CONFIG_SA1111)		+= sa1111.o sa1111-pcibuf.o
 obj-$(CONFIG_PCI_HOST_PLX90X0)	+= plx90x0.o
 obj-$(CONFIG_PCI_HOST_VIA82C505) += via82c505.o
diff -purN linux-post-2.6.3-20040227/arch/arm/common/amba.c linux-post-2.6.4rc1-20040228/arch/arm/common/amba.c
--- linux-post-2.6.3-20040227/arch/arm/common/amba.c	2004-02-14 18:22:46.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/common/amba.c	2004-02-27 17:17:05.000000000 +0000
@@ -315,16 +315,30 @@ amba_find_device(const char *busid, stru
 	return data.dev;
 }
 
+/**
+ *	amba_request_regions - request all mem regions associated with device
+ *	@dev: amba_device structure for device
+ *	@name: name, or NULL to use driver name
+ */
 int amba_request_regions(struct amba_device *dev, const char *name)
 {
 	int ret = 0;
 
+	if (!name)
+		name = dev->dev.driver->name;
+
 	if (!request_mem_region(dev->res.start, SZ_4K, name))
 		ret = -EBUSY;
 
 	return ret;
 }
 
+/**
+ *	amba_release_regions - release mem regions assoicated with device
+ *	@dev: amba_device structure for device
+ *
+ *	Release regions claimed by a successful call to amba_request_regions.
+ */
 void amba_release_regions(struct amba_device *dev)
 {
 	release_mem_region(dev->res.start, SZ_4K);
diff -purN linux-post-2.6.3-20040227/arch/arm/common/sa1111-pcibuf.c linux-post-2.6.4rc1-20040228/arch/arm/common/sa1111-pcibuf.c
--- linux-post-2.6.3-20040227/arch/arm/common/sa1111-pcibuf.c	2003-02-10 16:37:16.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/common/sa1111-pcibuf.c	2004-02-27 14:00:38.000000000 +0000
@@ -1,7 +1,7 @@
 /*
- *  linux/arch/arm/mach-sa1100/pci-sa1111.c
+ *  linux/arch/arm/mach-sa1100/sa1111-pcibuf.c
  *
- *  Special pci_{map/unmap/dma_sync}_* routines for SA-1111.
+ *  Special dma_{map/unmap/dma_sync}_* routines for SA-1111.
  *
  *  These functions utilize bouncer buffers to compensate for a bug in
  *  the SA-1111 hardware which don't allow DMA to/from addresses
@@ -17,20 +17,17 @@
  *  version 2 as published by the Free Software Foundation.
  * */
 
+//#define DEBUG
+
 #include <linux/module.h>
 #include <linux/init.h>
 #include <linux/slab.h>
-#include <linux/pci.h>
 #include <linux/list.h>
+#include <linux/device.h>
+#include <linux/dma-mapping.h>
+#include <linux/dmapool.h>
 #include <asm/hardware/sa1111.h>
 
-//#define DEBUG
-#ifdef DEBUG
-#define DPRINTK(...) do { printk(KERN_DEBUG __VA_ARGS__); } while (0)
-#else
-#define DPRINTK(...) do { } while (0)
-#endif
-
 //#define STATS
 #ifdef STATS
 #define DO_STATS(X) do { X ; } while (0)
@@ -46,12 +43,13 @@ struct safe_buffer {
 	/* original request */
 	void		*ptr;
 	size_t		size;
-	int		direction;
+	enum dma_data_direction direction;
 
 	/* safe buffer info */
-	struct pci_pool *pool;
+	struct dma_pool *pool;
 	void		*safe;
 	dma_addr_t	safe_dma_addr;
+	struct device	*dev;
 };
 
 static LIST_HEAD(safe_buffers);
@@ -60,7 +58,7 @@ static LIST_HEAD(safe_buffers);
 #define SIZE_SMALL	1024
 #define SIZE_LARGE	(4*1024)
 
-static struct pci_pool *small_buffer_pool, *large_buffer_pool;
+static struct dma_pool *small_buffer_pool, *large_buffer_pool;
 
 #ifdef STATS
 static unsigned long sbp_allocs __initdata = 0;
@@ -70,95 +68,90 @@ static unsigned long total_allocs __init
 static void print_alloc_stats(void)
 {
 	printk(KERN_INFO
-	       "sa1111_pcibuf: sbp: %lu, lbp: %lu, other: %lu, total: %lu\n",
+	       "sa1111_dmabuf: sbp: %lu, lbp: %lu, other: %lu, total: %lu\n",
 	       sbp_allocs, lbp_allocs,
 	       total_allocs - sbp_allocs - lbp_allocs, total_allocs);
 }
 #endif
 
-static int __init
-create_safe_buffer_pools(void)
+static int __init create_safe_buffer_pools(void)
 {
-	small_buffer_pool = pci_pool_create("sa1111_small_dma_buffer",
-					    SA1111_FAKE_PCIDEV,
-					    SIZE_SMALL,
+	small_buffer_pool = dma_pool_create("sa1111_small_dma_buffer",
+					    NULL, SIZE_SMALL,
 					    0 /* byte alignment */,
 					    0 /* no page-crossing issues */);
-	if (0 == small_buffer_pool) {
+	if (small_buffer_pool == NULL) {
 		printk(KERN_ERR
-		       "sa1111_pcibuf: could not allocate small pci pool\n");
-		return -1;
+		       "sa1111_dmabuf: could not allocate small pci pool\n");
+		return -ENOMEM;
 	}
 
-	large_buffer_pool = pci_pool_create("sa1111_large_dma_buffer",
-					    SA1111_FAKE_PCIDEV,
-					    SIZE_LARGE,
+	large_buffer_pool = dma_pool_create("sa1111_large_dma_buffer",
+					    NULL, SIZE_LARGE,
 					    0 /* byte alignment */,
 					    0 /* no page-crossing issues */);
-	if (0 == large_buffer_pool) {
+	if (large_buffer_pool == NULL) {
 		printk(KERN_ERR
-		       "sa1111_pcibuf: could not allocate large pci pool\n");
-		pci_pool_destroy(small_buffer_pool);
-		small_buffer_pool = 0;
-		return -1;
+		       "sa1111_dmabuf: could not allocate large pci pool\n");
+		dma_pool_destroy(small_buffer_pool);
+		small_buffer_pool = NULL;
+		return -ENOMEM;
 	}
 
-	printk(KERN_INFO
-	       "sa1111_pcibuf: buffer sizes: small=%u, large=%u\n",
+	printk(KERN_INFO "SA1111: DMA buffer sizes: small=%u, large=%u\n",
 	       SIZE_SMALL, SIZE_LARGE);
 
 	return 0;
 }
 
-static void __exit
-destroy_safe_buffer_pools(void)
+static void __exit destroy_safe_buffer_pools(void)
 {
 	if (small_buffer_pool)
-		pci_pool_destroy(small_buffer_pool);
+		dma_pool_destroy(small_buffer_pool);
 	if (large_buffer_pool)
-		pci_pool_destroy(large_buffer_pool);
+		dma_pool_destroy(large_buffer_pool);
 
-	small_buffer_pool = large_buffer_pool = 0;
+	small_buffer_pool = large_buffer_pool = NULL;
 }
 
 
 /* allocate a 'safe' buffer and keep track of it */
-static struct safe_buffer *
-alloc_safe_buffer(void *ptr, size_t size, int direction)
+static struct safe_buffer *alloc_safe_buffer(struct device *dev, void *ptr,
+					     size_t size,
+					     enum dma_data_direction dir)
 {
 	struct safe_buffer *buf;
-	struct pci_pool *pool;
+	struct dma_pool *pool;
 	void *safe;
 	dma_addr_t safe_dma_addr;
 
-	DPRINTK("%s(ptr=%p, size=%d, direction=%d)\n",
-		__func__, ptr, size, direction);
+	dev_dbg(dev, "%s(ptr=%p, size=%d, direction=%d)\n",
+		__func__, ptr, size, dir);
 
 	DO_STATS ( total_allocs++ );
 
 	buf = kmalloc(sizeof(struct safe_buffer), GFP_ATOMIC);
-	if (buf == 0) {
+	if (buf == NULL) {
 		printk(KERN_WARNING "%s: kmalloc failed\n", __func__);
 		return 0;
 	}
 
 	if (size <= SIZE_SMALL) {
 		pool = small_buffer_pool;
-		safe = pci_pool_alloc(pool, GFP_ATOMIC, &safe_dma_addr);
+		safe = dma_pool_alloc(pool, GFP_ATOMIC, &safe_dma_addr);
 
 		DO_STATS ( sbp_allocs++ );
 	} else if (size <= SIZE_LARGE) {
 		pool = large_buffer_pool;
-		safe = pci_pool_alloc(pool, GFP_ATOMIC, &safe_dma_addr);
+		safe = dma_pool_alloc(pool, GFP_ATOMIC, &safe_dma_addr);
 
 		DO_STATS ( lbp_allocs++ );
 	} else {
-		pool = 0;
-		safe = pci_alloc_consistent(SA1111_FAKE_PCIDEV, size,
-					    &safe_dma_addr);
+		pool = NULL;
+		safe = dma_alloc_coherent(dev, size, &safe_dma_addr, GFP_ATOMIC);
 	}
 
-	if (safe == 0) {
+	if (safe == NULL) {
 		printk(KERN_WARNING
 		       "%s: could not alloc dma memory (size=%d)\n",
 		       __func__, size);
@@ -175,20 +168,20 @@ alloc_safe_buffer(void *ptr, size_t size
 
 	buf->ptr = ptr;
 	buf->size = size;
-	buf->direction = direction;
+	buf->direction = dir;
 	buf->pool = pool;
 	buf->safe = safe;
 	buf->safe_dma_addr = safe_dma_addr;
+	buf->dev = dev;
 
-	MOD_INC_USE_COUNT;
 	list_add(&buf->node, &safe_buffers);
 
 	return buf;
 }
 
 /* determine if a buffer is from our "safe" pool */
-static struct safe_buffer *
-find_safe_buffer(dma_addr_t safe_dma_addr)
+static struct safe_buffer *find_safe_buffer(struct device *dev,
+					    dma_addr_t safe_dma_addr)
 {
 	struct list_head *entry;
 
@@ -196,7 +189,8 @@ find_safe_buffer(dma_addr_t safe_dma_add
 		struct safe_buffer *b =
 			list_entry(entry, struct safe_buffer, node);
 
-		if (b->safe_dma_addr == safe_dma_addr) {
+		if (b->safe_dma_addr == safe_dma_addr &&
+		    b->dev == dev) {
 			return b;
 		}
 	}
@@ -204,25 +198,22 @@ find_safe_buffer(dma_addr_t safe_dma_add
 	return 0;
 }
 
-static void
-free_safe_buffer(struct safe_buffer *buf)
+static void free_safe_buffer(struct safe_buffer *buf)
 {
-	DPRINTK("%s(buf=%p)\n", __func__, buf);
+	pr_debug("%s(buf=%p)\n", __func__, buf);
 
 	list_del(&buf->node);
 
 	if (buf->pool)
-		pci_pool_free(buf->pool, buf->safe, buf->safe_dma_addr);
+		dma_pool_free(buf->pool, buf->safe, buf->safe_dma_addr);
 	else
-		pci_free_consistent(SA1111_FAKE_PCIDEV, buf->size, buf->safe,
-				    buf->safe_dma_addr);
+		dma_free_coherent(buf->dev, buf->size, buf->safe,
+				  buf->safe_dma_addr);
 	kfree(buf);
-
-	MOD_DEC_USE_COUNT;
 }
 
-static inline int
-dma_range_is_safe(dma_addr_t addr, size_t size)
+static inline int dma_range_is_safe(struct device *dev, dma_addr_t addr,
+				    size_t size)
 {
 	unsigned int physaddr = SA1111_DMA_ADDR((unsigned int) addr);
 
@@ -248,13 +239,13 @@ static unsigned long bounce_count __init
 static void print_map_stats(void)
 {
 	printk(KERN_INFO
-	       "sa1111_pcibuf: map_op_count=%lu, bounce_count=%lu\n",
+	       "sa1111_dmabuf: map_op_count=%lu, bounce_count=%lu\n",
 	       map_op_count, bounce_count);
 }
 #endif
 
-static dma_addr_t
-map_single(void *ptr, size_t size, int direction)
+static dma_addr_t map_single(struct device *dev, void *ptr,
+			     size_t size, enum dma_data_direction dir)
 {
 	dma_addr_t dma_addr;
 
@@ -262,37 +253,36 @@ map_single(void *ptr, size_t size, int d
 
 	dma_addr = virt_to_bus(ptr);
 
-	if (!dma_range_is_safe(dma_addr, size)) {
+	if (!dma_range_is_safe(dev, dma_addr, size)) {
 		struct safe_buffer *buf;
 
 		DO_STATS ( bounce_count++ ) ;
 
-		buf = alloc_safe_buffer(ptr, size, direction);
-		if (buf == 0) {
+		buf = alloc_safe_buffer(dev, ptr, size, dir);
+		if (buf == NULL) {
 			printk(KERN_ERR
 			       "%s: unable to map unsafe buffer %p!\n",
 			       __func__, ptr);
 			return 0;
 		}
 
-		DPRINTK("%s: unsafe buffer %p (phy=%p) mapped to %p (phy=%p)\n",
+		dev_dbg(dev, "%s: unsafe buffer %p (phy=%08lx) mapped to %p (phy=%08x)\n",
 			__func__,
-			buf->ptr, (void *) virt_to_bus(buf->ptr),
-			buf->safe, (void *) buf->safe_dma_addr);
+			buf->ptr, virt_to_bus(buf->ptr),
+			buf->safe, buf->safe_dma_addr);
 
-		if ((direction == PCI_DMA_TODEVICE) ||
-		    (direction == PCI_DMA_BIDIRECTIONAL)) {
-			DPRINTK("%s: copy out from unsafe %p, to safe %p, size %d\n",
+		if (dir == DMA_TO_DEVICE || dir == DMA_BIDIRECTIONAL) {
+			dev_dbg(dev, "%s: copy out from unsafe %p, to safe %p, size %d\n",
 				__func__, ptr, buf->safe, size);
 			memcpy(buf->safe, ptr, size);
 		}
-		consistent_sync(buf->safe, size, direction);
 
 		dma_addr = buf->safe_dma_addr;
-	} else {
-		consistent_sync(ptr, size, direction);
+		ptr = buf->safe;
 	}
 
+	consistent_sync(ptr, size, dir);
+
 #ifdef STATS
 	if (map_op_count % 1000 == 0)
 		print_map_stats();
@@ -301,28 +291,26 @@ map_single(void *ptr, size_t size, int d
 	return dma_addr;
 }
 
-static void
-unmap_single(dma_addr_t dma_addr, size_t size, int direction)
+static void unmap_single(struct device *dev, dma_addr_t dma_addr,
+			 size_t size, enum dma_data_direction dir)
 {
 	struct safe_buffer *buf;
 
-	buf = find_safe_buffer(dma_addr);
+	buf = find_safe_buffer(dev, dma_addr);
 
 	if (buf) {
 		BUG_ON(buf->size != size);
-		BUG_ON(buf->direction != direction);
+		BUG_ON(buf->direction != dir);
 
-		DPRINTK("%s: unsafe buffer %p (phy=%p) mapped to %p (phy=%p)\n",
+		dev_dbg(dev, "%s: unsafe buffer %p (phy=%08lx) mapped to %p (phy=%08lx)\n",
 			__func__,
-			buf->ptr, (void *) virt_to_bus(buf->ptr),
-			buf->safe, (void *) buf->safe_dma_addr);
-
+			buf->ptr, virt_to_bus(buf->ptr),
+			buf->safe, buf->safe_dma_addr);
 
 		DO_STATS ( bounce_count++ );
 
-		if ((direction == PCI_DMA_FROMDEVICE) ||
-		    (direction == PCI_DMA_BIDIRECTIONAL)) {
-			DPRINTK("%s: copy back from safe %p, to unsafe %p size %d\n",
+		if (dir == DMA_FROM_DEVICE || dir == DMA_BIDIRECTIONAL) {
+			dev_dbg(dev, "%s: copy back from safe %p, to unsafe %p size %d\n",
 				__func__, buf->safe, buf->ptr, size);
 			memcpy(buf->ptr, buf->safe, size);
 		}
@@ -330,44 +318,46 @@ unmap_single(dma_addr_t dma_addr, size_t
 	}
 }
 
-static void
-sync_single(dma_addr_t dma_addr, size_t size, int direction)
+static void sync_single(struct device *dev, dma_addr_t dma_addr,
+			size_t size, enum dma_data_direction dir)
 {
 	struct safe_buffer *buf;
+	void *ptr;
 
-	buf = find_safe_buffer(dma_addr);
+	buf = find_safe_buffer(dev, dma_addr);
 
 	if (buf) {
 		BUG_ON(buf->size != size);
-		BUG_ON(buf->direction != direction);
+		BUG_ON(buf->direction != dir);
 
-		DPRINTK("%s: unsafe buffer %p (phy=%p) mapped to %p (phy=%p)\n",
+		dev_dbg(dev, "%s: unsafe buffer %p (phy=%08lx) mapped to %p (phy=%08lx)\n",
 			__func__,
-			buf->ptr, (void *) virt_to_bus(buf->ptr),
-			buf->safe, (void *) buf->safe_dma_addr);
+			buf->ptr, virt_to_bus(buf->ptr),
+			buf->safe, buf->safe_dma_addr);
 
 		DO_STATS ( bounce_count++ );
 
-		switch (direction) {
-		case PCI_DMA_FROMDEVICE:
-			DPRINTK("%s: copy back from safe %p, to unsafe %p size %d\n",
+		switch (dir) {
+		case DMA_FROM_DEVICE:
+			dev_dbg(dev, "%s: copy back from safe %p, to unsafe %p size %d\n",
 				__func__, buf->safe, buf->ptr, size);
 			memcpy(buf->ptr, buf->safe, size);
 			break;
-		case PCI_DMA_TODEVICE:
-			DPRINTK("%s: copy out from unsafe %p, to safe %p, size %d\n",
+		case DMA_TO_DEVICE:
+			dev_dbg(dev, "%s: copy out from unsafe %p, to safe %p, size %d\n",
 				__func__,buf->ptr, buf->safe, size);
 			memcpy(buf->safe, buf->ptr, size);
 			break;
-		case PCI_DMA_BIDIRECTIONAL:
+		case DMA_BIDIRECTIONAL:
 			BUG();	/* is this allowed?  what does it mean? */
 		default:
 			BUG();
 		}
-		consistent_sync(buf->safe, size, direction);
+		ptr = buf->safe;
 	} else {
-		consistent_sync(bus_to_virt(dma_addr), size, direction);
+		ptr = bus_to_virt(dma_addr);
 	}
+	consistent_sync(ptr, size, dir);
 }
 
 /* ************************************************** */
@@ -378,20 +368,20 @@ sync_single(dma_addr_t dma_addr, size_t 
  * substitute the safe buffer for the unsafe one.
  * (basically move the buffer from an unsafe area to a safe one)
  */
-dma_addr_t
-sa1111_map_single(void *ptr, size_t size, int direction)
+dma_addr_t sa1111_map_single(struct device *dev, void *ptr,
+			     size_t size, enum dma_data_direction dir)
 {
 	unsigned long flags;
 	dma_addr_t dma_addr;
 
-	DPRINTK("%s(ptr=%p,size=%d,dir=%x)\n",
-	       __func__, ptr, size, direction);
+	dev_dbg(dev, "%s(ptr=%p,size=%d,dir=%x)\n",
+	       __func__, ptr, size, dir);
 
-	BUG_ON(direction == PCI_DMA_NONE);
+	BUG_ON(dir == DMA_NONE);
 
 	local_irq_save(flags);
 
-	dma_addr = map_single(ptr, size, direction);
+	dma_addr = map_single(dev, ptr, size, dir);
 
 	local_irq_restore(flags);
 
@@ -404,34 +394,31 @@ sa1111_map_single(void *ptr, size_t size
  * the safe buffer.  (basically return things back to the way they
  * should be)
  */
-
-void
-sa1111_unmap_single(dma_addr_t dma_addr, size_t size, int direction)
+void sa1111_unmap_single(struct device *dev, dma_addr_t dma_addr,
+		         size_t size, enum dma_data_direction dir)
 {
 	unsigned long flags;
 
-	DPRINTK("%s(ptr=%p,size=%d,dir=%x)\n",
-		__func__, (void *) dma_addr, size, direction);
-
-	BUG_ON(direction == PCI_DMA_NONE);
+	dev_dbg(dev, "%s(ptr=%08lx,size=%d,dir=%x)\n",
+		__func__, dma_addr, size, dir);
 
 	local_irq_save(flags);
 
-	unmap_single(dma_addr, size, direction);
+	unmap_single(dev, dma_addr, size, dir);
 
 	local_irq_restore(flags);
 }
 
-int
-sa1111_map_sg(struct scatterlist *sg, int nents, int direction)
+int sa1111_map_sg(struct device *dev, struct scatterlist *sg,
+		  int nents, enum dma_data_direction dir)
 {
 	unsigned long flags;
 	int i;
 
-	DPRINTK("%s(sg=%p,nents=%d,dir=%x)\n",
-		__func__, sg, nents, direction);
+	dev_dbg(dev, "%s(sg=%p,nents=%d,dir=%x)\n",
+		__func__, sg, nents, dir);
 
-	BUG_ON(direction == PCI_DMA_NONE);
+	BUG_ON(dir == DMA_NONE);
 
 	local_irq_save(flags);
 
@@ -441,8 +428,7 @@ sa1111_map_sg(struct scatterlist *sg, in
 		unsigned int length = sg->length;
 		void *ptr = page_address(page) + offset;
 
-		sg->dma_address =
-			map_single(ptr, length, direction);
+		sg->dma_address = map_single(dev, ptr, length, dir);
 	}
 
 	local_irq_restore(flags);
@@ -450,16 +436,14 @@ sa1111_map_sg(struct scatterlist *sg, in
 	return nents;
 }
 
-void
-sa1111_unmap_sg(struct scatterlist *sg, int nents, int direction)
+void sa1111_unmap_sg(struct device *dev, struct scatterlist *sg,
+		     int nents, enum dma_data_direction dir)
 {
 	unsigned long flags;
 	int i;
 
-	DPRINTK("%s(sg=%p,nents=%d,dir=%x)\n",
-		__func__, sg, nents, direction);
-
-	BUG_ON(direction == PCI_DMA_NONE);
+	dev_dbg(dev, "%s(sg=%p,nents=%d,dir=%x)\n",
+		__func__, sg, nents, dir);
 
 	local_irq_save(flags);
 
@@ -467,37 +451,35 @@ sa1111_unmap_sg(struct scatterlist *sg, 
 		dma_addr_t dma_addr = sg->dma_address;
 		unsigned int length = sg->length;
 
-		unmap_single(dma_addr, length, direction);
+		unmap_single(dev, dma_addr, length, dir);
 	}
 
 	local_irq_restore(flags);
 }
 
-void
-sa1111_dma_sync_single(dma_addr_t dma_addr, size_t size, int direction)
+void sa1111_dma_sync_single(struct device *dev, dma_addr_t dma_addr,
+			    size_t size, enum dma_data_direction dir)
 {
 	unsigned long flags;
 
-	DPRINTK("%s(ptr=%p,size=%d,dir=%x)\n",
-		__func__, (void *) dma_addr, size, direction);
+	dev_dbg(dev, "%s(ptr=%08lx,size=%d,dir=%x)\n",
+		__func__, dma_addr, size, dir);
 
 	local_irq_save(flags);
 
-	sync_single(dma_addr, size, direction);
+	sync_single(dev, dma_addr, size, dir);
 
 	local_irq_restore(flags);
 }
 
-void
-sa1111_dma_sync_sg(struct scatterlist *sg, int nents, int direction)
+void sa1111_dma_sync_sg(struct device *dev, struct scatterlist *sg,
+			int nents, enum dma_data_direction dir)
 {
 	unsigned long flags;
 	int i;
 
-	DPRINTK("%s(sg=%p,nents=%d,dir=%x)\n",
-		__func__, sg, nents, direction);
-
-	BUG_ON(direction == PCI_DMA_NONE);
+	dev_dbg(dev, "%s(sg=%p,nents=%d,dir=%x)\n",
+		__func__, sg, nents, dir);
 
 	local_irq_save(flags);
 
@@ -505,7 +487,7 @@ sa1111_dma_sync_sg(struct scatterlist *s
 		dma_addr_t dma_addr = sg->dma_address;
 		unsigned int length = sg->length;
 
-		sync_single(dma_addr, length, direction);
+		sync_single(dev, dma_addr, length, dir);
 	}
 
 	local_irq_restore(flags);
@@ -520,20 +502,15 @@ EXPORT_SYMBOL(sa1111_dma_sync_sg);
 
 /* **************************************** */
 
-static int __init sa1111_pcibuf_init(void)
+static int __init sa1111_dmabuf_init(void)
 {
-	int ret;
-
-	printk(KERN_DEBUG
-	       "sa1111_pcibuf: initializing SA-1111 DMA workaround\n");
-
-	ret = create_safe_buffer_pools();
+	printk(KERN_DEBUG "sa1111_dmabuf: initializing SA-1111 DMA buffers\n");
 
-	return ret;
+	return create_safe_buffer_pools();
 }
-module_init(sa1111_pcibuf_init);
+module_init(sa1111_dmabuf_init);
 
-static void __exit sa1111_pcibuf_exit(void)
+static void __exit sa1111_dmabuf_exit(void)
 {
 	BUG_ON(!list_empty(&safe_buffers));
 
@@ -544,8 +521,8 @@ static void __exit sa1111_pcibuf_exit(vo
 
 	destroy_safe_buffer_pools();
 }
-module_exit(sa1111_pcibuf_exit);
+module_exit(sa1111_dmabuf_exit);
 
 MODULE_AUTHOR("Christopher Hoover <ch@hpl.hp.com>");
-MODULE_DESCRIPTION("Special pci_{map/unmap/dma_sync}_* routines for SA-1111.");
+MODULE_DESCRIPTION("Special dma_{map/unmap/dma_sync}_* routines for SA-1111.");
 MODULE_LICENSE("GPL");
diff -purN linux-post-2.6.3-20040227/arch/arm/common/sa1111-pcipool.c linux-post-2.6.4rc1-20040228/arch/arm/common/sa1111-pcipool.c
--- linux-post-2.6.3-20040227/arch/arm/common/sa1111-pcipool.c	2003-09-30 00:26:33.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/common/sa1111-pcipool.c	1970-01-01 00:00:00.000000000 +0000
@@ -1,388 +0,0 @@
-/*
-  NOTE:
-
-  this code was lifted straight out of drivers/pci/pci.c;
-  when compiling for the Intel StrongARM SA-1110/SA-1111 the
-  usb-ohci.c driver needs these routines even when the architecture
-  has no pci bus...
-*/
-
-#include <linux/config.h>
-#include <linux/module.h>
-#include <linux/types.h>
-#include <linux/kernel.h>
-#include <linux/pci.h>
-#include <linux/string.h>
-#include <linux/init.h>
-#include <linux/slab.h>
-#include <linux/spinlock.h>
-#include <linux/bitops.h>
-
-#include <asm/page.h>
-
-/*
- * Pool allocator ... wraps the pci_alloc_consistent page allocator, so
- * small blocks are easily used by drivers for bus mastering controllers.
- * This should probably be sharing the guts of the slab allocator.
- */
-
-struct pci_pool {	/* the pool */
-	struct list_head	page_list;
-	spinlock_t		lock;
-	size_t			blocks_per_page;
-	size_t			size;
-	struct pci_dev		*dev;
-	size_t			allocation;
-	char			name [32];
-	wait_queue_head_t	waitq;
-};
-
-struct pci_page {	/* cacheable header for 'allocation' bytes */
-	struct list_head	page_list;
-	void			*vaddr;
-	dma_addr_t		dma;
-	unsigned long		bitmap [0];
-};
-
-#define	POOL_TIMEOUT_JIFFIES	((100 /* msec */ * HZ) / 1000)
-#define	POOL_POISON_BYTE	0xa7
-
-// #define CONFIG_PCIPOOL_DEBUG
-
-static inline const char *slot_name(const struct pci_pool *pool)
-{
-	struct pci_dev *pdev = (struct pci_dev *)pool->dev;
-
-	if (pdev == 0)
-		return "[0]";
-
-	else if (pcidev_is_sa1111(pdev))
-		return "[SA-1111]";
-	else
-		return pci_name(pdev);
-}
-
-
-/**
- * pci_pool_create - Creates a pool of pci consistent memory blocks, for dma.
- * @name: name of pool, for diagnostics
- * @pdev: pci device that will be doing the DMA
- * @size: size of the blocks in this pool.
- * @align: alignment requirement for blocks; must be a power of two
- * @allocation: returned blocks won't cross this boundary (or zero)
- * Context: !in_interrupt()
- *
- * Returns a pci allocation pool with the requested characteristics, or
- * null if one can't be created.  Given one of these pools, pci_pool_alloc()
- * may be used to allocate memory.  Such memory will all have "consistent"
- * DMA mappings, accessible by the device and its driver without using
- * cache flushing primitives.  The actual size of blocks allocated may be
- * larger than requested because of alignment.
- *
- * If allocation is nonzero, objects returned from pci_pool_alloc() won't
- * cross that size boundary.  This is useful for devices which have
- * addressing restrictions on individual DMA transfers, such as not crossing
- * boundaries of 4KBytes.
- */
-struct pci_pool *
-pci_pool_create (const char *name, struct pci_dev *pdev,
-	size_t size, size_t align, size_t allocation)
-{
-	struct pci_pool		*retval;
-
-	if (align == 0)
-		align = 1;
-	if (size == 0)
-		return 0;
-	else if (size < align)
-		size = align;
-	else if ((size % align) != 0) {
-		size += align + 1;
-		size &= ~(align - 1);
-	}
-
-	if (allocation == 0) {
-		if (PAGE_SIZE < size)
-			allocation = size;
-		else
-			allocation = PAGE_SIZE;
-		// FIXME: round up for less fragmentation
-	} else if (allocation < size)
-		return 0;
-
-	if (!(retval = kmalloc (sizeof *retval, SLAB_KERNEL)))
-		return retval;
-
-	strlcpy (retval->name, name, sizeof retval->name);
-
-	retval->dev = pdev;
-	INIT_LIST_HEAD (&retval->page_list);
-	spin_lock_init (&retval->lock);
-	retval->size = size;
-	retval->allocation = allocation;
-	retval->blocks_per_page = allocation / size;
-	init_waitqueue_head (&retval->waitq);
-
-#ifdef CONFIG_PCIPOOL_DEBUG
-	printk (KERN_DEBUG "pcipool create %s/%s size %d, %d/page (%d alloc)\n",
-		slot_name(retval), retval->name, size,
-		retval->blocks_per_page, allocation);
-#endif
-
-	return retval;
-}
-
-
-static struct pci_page *
-pool_alloc_page (struct pci_pool *pool, int mem_flags)
-{
-	struct pci_page	*page;
-	int		mapsize;
-
-	mapsize = pool->blocks_per_page;
-	mapsize = (mapsize + BITS_PER_LONG - 1) / BITS_PER_LONG;
-	mapsize *= sizeof (long);
-
-	page = (struct pci_page *) kmalloc (mapsize + sizeof *page, mem_flags);
-	if (!page)
-		return 0;
-	page->vaddr = pci_alloc_consistent (pool->dev,
-					    pool->allocation,
-					    &page->dma);
-	if (page->vaddr) {
-		memset (page->bitmap, 0xff, mapsize);	// bit set == free
-#ifdef	CONFIG_DEBUG_SLAB
-		memset (page->vaddr, POOL_POISON_BYTE, pool->allocation);
-#endif
-		list_add (&page->page_list, &pool->page_list);
-	} else {
-		kfree (page);
-		page = 0;
-	}
-	return page;
-}
-
-
-static inline int
-is_page_busy (int blocks, unsigned long *bitmap)
-{
-	while (blocks > 0) {
-		if (*bitmap++ != ~0UL)
-			return 1;
-		blocks -= BITS_PER_LONG;
-	}
-	return 0;
-}
-
-static void
-pool_free_page (struct pci_pool *pool, struct pci_page *page)
-{
-	dma_addr_t	dma = page->dma;
-
-#ifdef	CONFIG_DEBUG_SLAB
-	memset (page->vaddr, POOL_POISON_BYTE, pool->allocation);
-#endif
-	pci_free_consistent (pool->dev, pool->allocation, page->vaddr, dma);
-	list_del (&page->page_list);
-	kfree (page);
-}
-
-
-/**
- * pci_pool_destroy - destroys a pool of pci memory blocks.
- * @pool: pci pool that will be destroyed
- *
- * Caller guarantees that no more memory from the pool is in use,
- * and that nothing will try to use the pool after this call.
- */
-void
-pci_pool_destroy (struct pci_pool *pool)
-{
-	unsigned long		flags;
-
-#ifdef CONFIG_PCIPOOL_DEBUG
-	printk (KERN_DEBUG "pcipool destroy %s/%s\n",
-		slot_name(pool), pool->name);
-#endif
-
-	spin_lock_irqsave (&pool->lock, flags);
-	while (!list_empty (&pool->page_list)) {
-		struct pci_page		*page;
-		page = list_entry (pool->page_list.next,
-				struct pci_page, page_list);
-		if (is_page_busy (pool->blocks_per_page, page->bitmap)) {
-			printk (KERN_ERR "pci_pool_destroy %s/%s, %p busy\n",
-				slot_name(pool), pool->name, page->vaddr);
-			/* leak the still-in-use consistent memory */
-			list_del (&page->page_list);
-			kfree (page);
-		} else
-			pool_free_page (pool, page);
-	}
-	spin_unlock_irqrestore (&pool->lock, flags);
-	kfree (pool);
-}
-
-
-/**
- * pci_pool_alloc - get a block of consistent memory
- * @pool: pci pool that will produce the block
- * @mem_flags: SLAB_KERNEL or SLAB_ATOMIC
- * @handle: pointer to dma address of block
- *
- * This returns the kernel virtual address of a currently unused block,
- * and reports its dma address through the handle.
- * If such a memory block can't be allocated, null is returned.
- */
-void *
-pci_pool_alloc (struct pci_pool *pool, int mem_flags, dma_addr_t *handle)
-{
-	unsigned long		flags;
-	struct list_head	*entry;
-	struct pci_page		*page;
-	int			map, block;
-	size_t			offset;
-	void			*retval;
-
-restart:
-	spin_lock_irqsave (&pool->lock, flags);
-	list_for_each (entry, &pool->page_list) {
-		int		i;
-		page = list_entry (entry, struct pci_page, page_list);
-		/* only cachable accesses here ... */
-		for (map = 0, i = 0;
-				i < pool->blocks_per_page;
-				i += BITS_PER_LONG, map++) {
-			if (page->bitmap [map] == 0)
-				continue;
-			block = ffz (~ page->bitmap [map]);
-			if ((i + block) < pool->blocks_per_page) {
-				clear_bit (block, &page->bitmap [map]);
-				offset = (BITS_PER_LONG * map) + block;
-				offset *= pool->size;
-				goto ready;
-			}
-		}
-	}
-	if (!(page = pool_alloc_page (pool, mem_flags))) {
-		if (mem_flags == SLAB_KERNEL) {
-			DECLARE_WAITQUEUE (wait, current);
-
-			current->state = TASK_INTERRUPTIBLE;
-			add_wait_queue (&pool->waitq, &wait);
-			spin_unlock_irqrestore (&pool->lock, flags);
-
-			schedule_timeout (POOL_TIMEOUT_JIFFIES);
-
-			remove_wait_queue (&pool->waitq, &wait);
-			goto restart;
-		}
-		retval = 0;
-		goto done;
-	}
-
-	clear_bit (0, &page->bitmap [0]);
-	offset = 0;
-ready:
-	retval = offset + page->vaddr;
-	*handle = offset + page->dma;
-done:
-	spin_unlock_irqrestore (&pool->lock, flags);
-	return retval;
-}
-
-
-static struct pci_page *
-pool_find_page (struct pci_pool *pool, dma_addr_t dma)
-{
-	unsigned long		flags;
-	struct list_head	*entry;
-	struct pci_page		*page;
-
-	spin_lock_irqsave (&pool->lock, flags);
-	list_for_each (entry, &pool->page_list) {
-		page = list_entry (entry, struct pci_page, page_list);
-		if (dma < page->dma)
-			continue;
-		if (dma < (page->dma + pool->allocation))
-			goto done;
-	}
-	page = 0;
-done:
-	spin_unlock_irqrestore (&pool->lock, flags);
-	return page;
-}
-
-
-/**
- * pci_pool_free - put block back into pci pool
- * @pool: the pci pool holding the block
- * @vaddr: virtual address of block
- * @dma: dma address of block
- *
- * Caller promises neither device nor driver will again touch this block
- * unless it is first re-allocated.
- */
-void
-pci_pool_free (struct pci_pool *pool, void *vaddr, dma_addr_t dma)
-{
-	struct pci_page		*page;
-	unsigned long		flags;
-	int			map, block;
-
-	if ((page = pool_find_page (pool, dma)) == 0) {
-		printk (KERN_ERR "pci_pool_free %s/%s, %p/%lx (bad dma)\n",
-			pool->dev ? pci_name(pool->dev) : NULL,
-			pool->name, vaddr, (unsigned long) dma);
-		return;
-	}
-
-	block = dma - page->dma;
-	block /= pool->size;
-	map = block / BITS_PER_LONG;
-	block %= BITS_PER_LONG;
-
-#ifdef	CONFIG_DEBUG_SLAB
-	if (((dma - page->dma) + (void *)page->vaddr) != vaddr) {
-		printk (KERN_ERR "pci_pool_free %s/%s, %p (bad vaddr)/%lx\n",
-			pool->dev ? pci_name(pool->dev) : NULL,
-			pool->name, vaddr, (unsigned long) dma);
-		return;
-	}
-	if (page->bitmap [map] & (1UL << block)) {
-		printk (KERN_ERR "pci_pool_free %s/%s, dma %x already free\n",
-			pool->dev ? pci_name(pool->dev) : NULL,
-			pool->name, dma);
-		return;
-	}
-	memset (vaddr, POOL_POISON_BYTE, pool->size);
-#endif
-
-	spin_lock_irqsave (&pool->lock, flags);
-	set_bit (block, &page->bitmap [map]);
-	if (waitqueue_active (&pool->waitq))
-		wake_up (&pool->waitq);
-	/*
-	 * Resist a temptation to do
-	 *    if (!is_page_busy(bpp, page->bitmap)) pool_free_page(pool, page);
-	 * it is not interrupt safe. Better have empty pages hang around.
-	 */
-	spin_unlock_irqrestore (&pool->lock, flags);
-}
-
-EXPORT_SYMBOL (pci_pool_create);
-EXPORT_SYMBOL (pci_pool_destroy);
-EXPORT_SYMBOL (pci_pool_alloc);
-EXPORT_SYMBOL (pci_pool_free);
-
-/* **************************************** */
-
-static int __init pcipool_init(void)
-{
-	MOD_INC_USE_COUNT;	/* never unload */
-
-	return 0;
-}
-module_init(pcipool_init);
-
-MODULE_LICENSE("GPL");
diff -purN linux-post-2.6.3-20040227/arch/arm/kernel/Makefile linux-post-2.6.4rc1-20040228/arch/arm/kernel/Makefile
--- linux-post-2.6.3-20040227/arch/arm/kernel/Makefile	2003-09-03 08:25:59.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/kernel/Makefile	2004-02-27 15:20:26.000000000 +0000
@@ -11,7 +11,6 @@ obj-y		:= arch.o compat.o dma.o entry-ar
 		   time.o traps.o
 
 obj-$(CONFIG_APM)		+= apm.o
-obj-$(CONFIG_PM)		+= pm.o
 obj-$(CONFIG_ARCH_ACORN)	+= ecard.o time-acorn.o
 obj-$(CONFIG_ARCH_CLPS7500)	+= time-acorn.o
 obj-$(CONFIG_FOOTBRIDGE)	+= isa.o
diff -purN linux-post-2.6.3-20040227/arch/arm/kernel/asm-offsets.c linux-post-2.6.4rc1-20040228/arch/arm/kernel/asm-offsets.c
--- linux-post-2.6.3-20040227/arch/arm/kernel/asm-offsets.c	2004-01-30 14:47:40.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/kernel/asm-offsets.c	2004-02-26 14:22:24.000000000 +0000
@@ -47,6 +47,10 @@ int main(void)
 {
   DEFINE(TSK_ACTIVE_MM,		offsetof(struct task_struct, active_mm));
   BLANK();
+#if __LINUX_ARM_ARCH__ >= 6
+  DEFINE(MM_CONTEXT_ID,		offsetof(struct mm_struct, context.id));
+#endif
+  BLANK();
   DEFINE(VMA_VM_MM,		offsetof(struct vm_area_struct, vm_mm));
   DEFINE(VMA_VM_FLAGS,		offsetof(struct vm_area_struct, vm_flags));
   BLANK();
diff -purN linux-post-2.6.3-20040227/arch/arm/kernel/entry-header.S linux-post-2.6.4rc1-20040228/arch/arm/kernel/entry-header.S
--- linux-post-2.6.3-20040227/arch/arm/kernel/entry-header.S	2003-08-24 13:17:52.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/kernel/entry-header.S	2004-02-26 14:22:24.000000000 +0000
@@ -66,6 +66,15 @@
 	msr	cpsr_c, \mode
 	.endm
 
+#if __LINUX_ARM_ARCH__ >= 6
+	.macro	disable_irq, temp
+	cpsid	i
+	.endm
+
+	.macro	enable_irq, temp
+	cpsie	i
+	.endm
+#else
 	.macro	disable_irq, temp
 	set_cpsr_c \temp, #PSR_I_BIT | MODE_SVC
 	.endm
@@ -73,6 +82,7 @@
 	.macro	enable_irq, temp
 	set_cpsr_c \temp, #MODE_SVC
 	.endm
+#endif
 
 	.macro	save_user_regs
 	sub	sp, sp, #S_FRAME_SIZE
diff -purN linux-post-2.6.3-20040227/arch/arm/kernel/irq.c linux-post-2.6.4rc1-20040228/arch/arm/kernel/irq.c
--- linux-post-2.6.3-20040227/arch/arm/kernel/irq.c	2003-12-29 21:37:39.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/kernel/irq.c	2004-02-27 15:39:19.000000000 +0000
@@ -31,6 +31,7 @@
 #include <linux/seq_file.h>
 #include <linux/errno.h>
 #include <linux/list.h>
+#include <linux/kallsyms.h>
 
 #include <asm/irq.h>
 #include <asm/system.h>
@@ -225,6 +226,34 @@ static int check_irq_lock(struct irqdesc
 }
 
 static void
+report_bad_irq(unsigned int irq, struct pt_regs *regs, struct irqdesc *desc, int ret)
+{
+	static int count = 100;
+	struct irqaction *action;
+
+	if (!count)
+		return;
+
+	count--;
+
+	if (ret != IRQ_HANDLED && ret != IRQ_NONE) {
+		printk("irq%u: bogus retval mask %x\n", irq, ret);
+	} else {
+		printk("irq%u: nobody cared\n", irq);
+	}
+	show_regs(regs);
+	dump_stack();
+	printk(KERN_ERR "handlers:");
+	action = desc->action;
+	do {
+		printk("\n" KERN_ERR "[<%p>]", action->handler);
+		print_symbol(" (%s)", (unsigned long)action->handler);
+		action = action->next;
+	} while (action);
+	printk("\n");
+}
+
+static int
 __do_irq(unsigned int irq, struct irqaction *action, struct pt_regs *regs)
 {
 	unsigned int status;
@@ -247,18 +276,7 @@ __do_irq(unsigned int irq, struct irqact
 
 	spin_lock_irq(&irq_controller_lock);
 
-	if (retval != 1) {
-		static int count = 100;
-		if (count) {
-			count--;
-			if (retval) {
-				printk("irq event %d: bogus retval mask %x\n",
-					irq, retval);
-			} else {
-				printk("irq %d: nobody cared\n", irq);
-			}
-		}
-	}
+	return retval;
 }
 
 /*
@@ -276,8 +294,11 @@ do_simple_IRQ(unsigned int irq, struct i
 	kstat_cpu(cpu).irqs[irq]++;
 
 	action = desc->action;
-	if (action)
-		__do_irq(irq, desc->action, regs);
+	if (action) {
+		int ret = __do_irq(irq, action, regs);
+		if (ret != IRQ_HANDLED)
+			report_bad_irq(irq, regs, desc, ret);
+	}
 }
 
 /*
@@ -313,6 +334,7 @@ do_edge_IRQ(unsigned int irq, struct irq
 
 	do {
 		struct irqaction *action;
+		int ret;
 
 		action = desc->action;
 		if (!action)
@@ -323,7 +345,9 @@ do_edge_IRQ(unsigned int irq, struct irq
 			desc->chip->unmask(irq);
 		}
 
-		__do_irq(irq, action, regs);
+		ret = __do_irq(irq, action, regs);
+		if (ret != IRQ_HANDLED)
+			report_bad_irq(irq, regs, desc, ret);
 	} while (desc->pending && !desc->disable_depth);
 
 	desc->running = 0;
@@ -368,7 +392,10 @@ do_level_IRQ(unsigned int irq, struct ir
 		 */
 		action = desc->action;
 		if (action) {
-			__do_irq(irq, desc->action, regs);
+			int ret = __do_irq(irq, desc->action, regs);
+
+			if (ret != IRQ_HANDLED)
+				report_bad_irq(irq, regs, desc, ret);
 
 			if (likely(!desc->disable_depth &&
 				   !check_irq_lock(desc, irq, regs)))
diff -purN linux-post-2.6.3-20040227/arch/arm/kernel/pm.c linux-post-2.6.4rc1-20040228/arch/arm/kernel/pm.c
--- linux-post-2.6.3-20040227/arch/arm/kernel/pm.c	2003-10-04 10:21:31.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/kernel/pm.c	1970-01-01 00:00:00.000000000 +0000
@@ -1,84 +0,0 @@
-/*
- *  linux/arch/arm/kernel/suspend.c
- *
- * This program is free software; you can redistribute it and/or
- * modify it under the terms of the GNU General Public License.
- *
- *  This is the common support code for suspending an ARM machine.
- *  pm_do_suspend() is responsible for actually putting the CPU to
- *  sleep.
- */
-#include <linux/config.h>
-#include <linux/init.h>
-#include <linux/sysctl.h>
-#include <linux/pm.h>
-#include <linux/errno.h>
-#include <linux/sched.h>
-
-#ifdef CONFIG_SYSCTL
-/*
- * We really want this to die.  It's a disgusting hack using unallocated
- * sysctl numbers.  We should be using a real interface.
- */
-
-static int
-pm_sysctl_proc_handler(ctl_table *ctl, int write, struct file *filp,
-		       void *buffer, size_t *lenp)
-{
-	int ret = -EIO;
-	printk("PM: task %s (pid %d) uses deprecated sysctl PM interface\n",
-		current->comm, current->pid);
-	if (write)
-		ret = pm_suspend(PM_SUSPEND_MEM);
-	return ret;
-}
-
-/*
- * This came from arch/arm/mach-sa1100/pm.c:
- * Copyright (c) 2001 Cliff Brake <cbrake@accelent.com>
- *  with modifications by Nicolas Pitre and Russell King.
- *
- * ARGH!  ACPI people defined CTL_ACPI in linux/acpi.h rather than
- * linux/sysctl.h.
- *
- * This means our interface here won't survive long - it needs a new
- * interface.  Quick hack to get this working - use sysctl id 9999.
- */
-#warning ACPI broke the kernel, this interface needs to be fixed up.
-#define CTL_ACPI 9999
-#define ACPI_S1_SLP_TYP 19
-
-static struct ctl_table pm_table[] =
-{
-	{
-		.ctl_name	= ACPI_S1_SLP_TYP,
-		.procname	= "suspend",
-		.mode		= 0200,
-		.proc_handler	= pm_sysctl_proc_handler,
-	},
-	{0}
-};
-
-static struct ctl_table pm_dir_table[] =
-{
-	{
-		.ctl_name	= CTL_ACPI,
-		.procname	= "pm",
-		.mode		= 0555,
-		.child		= pm_table,
-	},
-	{0}
-};
-
-/*
- * Initialize power interface
- */
-static int __init pm_init(void)
-{
-	register_sysctl_table(pm_dir_table, 1);
-	return 0;
-}
-
-fs_initcall(pm_init);
-
-#endif
diff -purN linux-post-2.6.3-20040227/arch/arm/kernel/setup.c linux-post-2.6.4rc1-20040228/arch/arm/kernel/setup.c
--- linux-post-2.6.3-20040227/arch/arm/kernel/setup.c	2003-11-06 20:45:40.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/kernel/setup.c	2004-02-26 14:22:24.000000000 +0000
@@ -118,21 +118,21 @@ static struct resource io_res[] = {
 #define lp2 io_res[2]
 
 static const char *cache_types[16] = {
-	"write-through",
-	"write-back",
-	"write-back",
+	"VIVT write-through",
+	"VIVT write-back",
+	"VIVT write-back",
 	"undefined 3",
 	"undefined 4",
 	"undefined 5",
-	"write-back",
-	"write-back",
+	"VIVT write-back",
+	"VIVT write-back",
 	"undefined 8",
 	"undefined 9",
 	"undefined 10",
 	"undefined 11",
 	"undefined 12",
 	"undefined 13",
-	"undefined 14",
+	"VIPT write-back",
 	"undefined 15",
 };
 
@@ -151,7 +151,7 @@ static const char *cache_clean[16] = {
 	"undefined 11",
 	"undefined 12",
 	"undefined 13",
-	"undefined 14",
+	"cp15 c7 ops",
 	"undefined 15",
 };
 
@@ -170,7 +170,7 @@ static const char *cache_lockdown[16] = 
 	"undefined 11",
 	"undefined 12",
 	"undefined 13",
-	"undefined 14",
+	"format C",
 	"undefined 15",
 };
 
@@ -183,7 +183,7 @@ static const char *proc_arch[] = {
 	"5T",
 	"5TE",
 	"5TEJ",
-	"?(9)",
+	"6TEJ",
 	"?(10)",
 	"?(11)",
 	"?(12)",
diff -purN linux-post-2.6.3-20040227/arch/arm/lib/io-readsl-armv4.S linux-post-2.6.4rc1-20040228/arch/arm/lib/io-readsl-armv4.S
--- linux-post-2.6.3-20040227/arch/arm/lib/io-readsl-armv4.S	2003-08-14 17:45:36.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/lib/io-readsl-armv4.S	2004-02-27 15:48:17.000000000 +0000
@@ -19,10 +19,24 @@ ENTRY(__raw_readsl)
 		ands	ip, r1, #3
 		bne	2f
 
-1:		ldr	r3, [r0]
-		str	r3, [r1], #4
-		subs	r2, r2, #1
-		bne	1b
+		subs	r2, r2, #4
+		bmi	1001f
+		stmfd	sp!, {r4, lr}
+1000:		ldr	r3, [r0, #0]
+		ldr	r4, [r0, #0]
+		ldr	ip, [r0, #0]
+		ldr	lr, [r0, #0]
+		subs	r2, r2, #4
+		stmia	r1!, {r3, r4, ip, lr}
+		bpl	1000b
+		ldmfd	sp!, {r4, lr}
+1001:		tst	r2, #2
+		ldrne	r3, [r0, #0]
+		ldrne	ip, [r0, #0]
+		stmneia	r1!, {r3, ip}
+		tst	r2, #1
+		ldrne	r3, [r0, #0]
+		strne	r3, [r1, #0]
 		mov	pc, lr
 
 2:		cmp	ip, #2
diff -purN linux-post-2.6.3-20040227/arch/arm/mach-sa1100/generic.c linux-post-2.6.4rc1-20040228/arch/arm/mach-sa1100/generic.c
--- linux-post-2.6.3-20040227/arch/arm/mach-sa1100/generic.c	2004-02-14 18:45:46.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mach-sa1100/generic.c	2004-02-27 17:03:10.000000000 +0000
@@ -18,6 +18,7 @@
 #include <linux/cpufreq.h>
 #include <linux/ioport.h>
 
+#include <asm/div64.h>
 #include <asm/hardware.h>
 #include <asm/system.h>
 #include <asm/pgtable.h>
@@ -112,6 +113,21 @@ EXPORT_SYMBOL(cpufreq_get);
 #endif
 
 /*
+ * This is the SA11x0 sched_clock implementation.  This has
+ * a resolution of 271ns, and a maximum value of 1165s.
+ *  ( * 1E9 / 3686400 => * 78125 / 288)
+ */
+unsigned long long sched_clock(void)
+{
+	unsigned long long v;
+
+	v = (unsigned long long)OSCR * 78125;
+	do_div(v, 288);
+
+	return v;
+}
+
+/*
  * Default power-off for SA1100
  */
 static void sa1100_power_off(void)
@@ -151,6 +167,36 @@ static struct platform_device sa11x0udc_
 	.resource	= sa11x0udc_resources,
 };
 
+static struct resource sa11x0uart1_resources[] = {
+	[0] = {
+		.start	= 0x80010000,
+		.end	= 0x8001ffff,
+		.flags	= IORESOURCE_MEM,
+	},
+};
+
+static struct platform_device sa11x0uart1_device = {
+	.name		= "sa11x0-uart",
+	.id		= 1,
+	.num_resources	= ARRAY_SIZE(sa11x0uart1_resources),
+	.resource	= sa11x0uart1_resources,
+};
+
+static struct resource sa11x0uart3_resources[] = {
+	[0] = {
+		.start	= 0x80050000,
+		.end	= 0x8005ffff,
+		.flags	= IORESOURCE_MEM,
+	},
+};
+
+static struct platform_device sa11x0uart3_device = {
+	.name		= "sa11x0-uart",
+	.id		= 3,
+	.num_resources	= ARRAY_SIZE(sa11x0uart3_resources),
+	.resource	= sa11x0uart3_resources,
+};
+
 static struct resource sa11x0mcp_resources[] = {
 	[0] = {
 		.start	= 0x80060000,
@@ -218,6 +264,8 @@ static struct platform_device sa11x0pcmc
 
 static struct platform_device *sa11x0_devices[] __initdata = {
 	&sa11x0udc_device,
+	&sa11x0uart1_device,
+	&sa11x0uart3_device,
 	&sa11x0mcp_device,
 	&sa11x0ssp_device,
 	&sa11x0pcmcia_device,
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/Kconfig linux-post-2.6.4rc1-20040228/arch/arm/mm/Kconfig
--- linux-post-2.6.3-20040227/arch/arm/mm/Kconfig	2004-02-19 15:58:57.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/Kconfig	2004-02-26 14:22:24.000000000 +0000
@@ -223,6 +223,17 @@ config CPU_XSCALE
 	select CPU_TLB_V4WBI
 	select CPU_MINICACHE
 
+# ARMv6
+config CPU_V6
+	bool "Support ARM V6 processor"
+	depends on ARCH_INTEGRATOR
+	select CPU_32v6
+	select CPU_ABRT_EV6
+	select CPU_CACHE_V6
+	select CPU_COPY_V6
+	select CPU_TLB_V6
+
+# Figure out what processor architecture version we should be using.
 # This defines the compiler instruction set which depends on the machine type.
 config CPU_32v3
 	bool
@@ -233,6 +244,9 @@ config CPU_32v4
 config CPU_32v5
 	bool
 
+config CPU_32v6
+	bool
+
 # The abort model
 config CPU_ABRT_EV4
 	bool
@@ -249,6 +263,9 @@ config CPU_ABRT_EV5T
 config CPU_ABRT_EV5TJ
 	bool
 
+config CPU_ABRT_EV6
+	bool
+
 # The cache model
 config CPU_CACHE_V3
 	bool
@@ -262,6 +279,9 @@ config CPU_CACHE_V4WT
 config CPU_CACHE_V4WB
 	bool
 
+config CPU_CACHE_V6
+	bool
+
 # The copy-page model
 config CPU_COPY_V3
 	bool
@@ -272,6 +292,9 @@ config CPU_COPY_V4WT
 config CPU_COPY_V4WB
 	bool
 
+config CPU_COPY_V6
+	bool
+
 # This selects the TLB model
 config CPU_TLB_V3
 	bool
@@ -306,7 +329,7 @@ comment "Processor Features"
 
 config ARM_THUMB
 	bool "Support Thumb user binaries"
-	depends on CPU_ARM720T || CPU_ARM920T || CPU_ARM922T || CPU_ARM925T || CPU_ARM926T || CPU_ARM1020 || CPU_ARM1020E || CPU_ARM1022 || CPU_ARM1026 || CPU_XSCALE
+	depends on CPU_ARM720T || CPU_ARM920T || CPU_ARM922T || CPU_ARM925T || CPU_ARM926T || CPU_ARM1020 || CPU_ARM1020E || CPU_ARM1022 || CPU_ARM1026 || CPU_XSCALE || CPU_V6
 	default y
 	help
 	  Say Y if you want to include kernel support for running user space
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/Makefile linux-post-2.6.4rc1-20040228/arch/arm/mm/Makefile
--- linux-post-2.6.3-20040227/arch/arm/mm/Makefile	2004-02-19 15:58:58.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/Makefile	2004-02-26 14:22:25.000000000 +0000
@@ -15,15 +15,18 @@ obj-$(CONFIG_CPU_ABRT_EV4T)	+= abort-ev4
 obj-$(CONFIG_CPU_ABRT_LV4T)	+= abort-lv4t.o
 obj-$(CONFIG_CPU_ABRT_EV5T)	+= abort-ev5t.o
 obj-$(CONFIG_CPU_ABRT_EV5TJ)	+= abort-ev5tj.o
+obj-$(CONFIG_CPU_ABRT_EV6)	+= abort-ev6.o
 
 obj-$(CONFIG_CPU_CACHE_V3)	+= cache-v3.o
 obj-$(CONFIG_CPU_CACHE_V4)	+= cache-v4.o
 obj-$(CONFIG_CPU_CACHE_V4WT)	+= cache-v4wt.o
 obj-$(CONFIG_CPU_CACHE_V4WB)	+= cache-v4wb.o
+obj-$(CONFIG_CPU_CACHE_V6)	+= cache-v6.o
 
 obj-$(CONFIG_CPU_COPY_V3)	+= copypage-v3.o
 obj-$(CONFIG_CPU_COPY_V4WT)	+= copypage-v4wt.o
 obj-$(CONFIG_CPU_COPY_V4WB)	+= copypage-v4wb.o
+obj-$(CONFIG_CPU_COPY_V6)	+= copypage-v6.o mmu.o
 obj-$(CONFIG_CPU_SA1100)	+= copypage-v4mc.o
 obj-$(CONFIG_CPU_XSCALE)	+= copypage-xscale.o
 
@@ -33,6 +36,7 @@ obj-$(CONFIG_CPU_TLB_V3)	+= tlb-v3.o
 obj-$(CONFIG_CPU_TLB_V4WT)	+= tlb-v4.o
 obj-$(CONFIG_CPU_TLB_V4WB)	+= tlb-v4wb.o
 obj-$(CONFIG_CPU_TLB_V4WBI)	+= tlb-v4wbi.o
+obj-$(CONFIG_CPU_TLB_V6)	+= tlb-v6.o
 
 obj-$(CONFIG_CPU_ARM610)	+= proc-arm6_7.o
 obj-$(CONFIG_CPU_ARM710)	+= proc-arm6_7.o
@@ -48,3 +52,4 @@ obj-$(CONFIG_CPU_ARM1026)	+= proc-arm102
 obj-$(CONFIG_CPU_SA110)		+= proc-sa110.o
 obj-$(CONFIG_CPU_SA1100)	+= proc-sa1100.o
 obj-$(CONFIG_CPU_XSCALE)	+= proc-xscale.o
+obj-$(CONFIG_CPU_V6)		+= proc-v6.o blockops.o
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/abort-ev6.S linux-post-2.6.4rc1-20040228/arch/arm/mm/abort-ev6.S
--- linux-post-2.6.3-20040227/arch/arm/mm/abort-ev6.S	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/abort-ev6.S	2004-02-26 14:22:27.000000000 +0000
@@ -0,0 +1,23 @@
+#include <linux/linkage.h>
+#include <asm/assembler.h>
+/*
+ * Function: v6_early_abort
+ *
+ * Params  : r2 = address of aborted instruction
+ *         : r3 = saved SPSR
+ *
+ * Returns : r0 = address of abort
+ *	   : r1 = FSR, bit 11 = write
+ *	   : r2-r8 = corrupted
+ *	   : r9 = preserved
+ *	   : sp = pointer to registers
+ *
+ * Purpose : obtain information about current aborted instruction.
+ */
+	.align	5
+ENTRY(v6_early_abort)
+	mrc	p15, 0, r1, c5, c0, 0		@ get FSR
+	mrc	p15, 0, r0, c6, c0, 0		@ get FAR
+	mov	pc, lr
+
+
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/abort-lv4t.S linux-post-2.6.4rc1-20040228/arch/arm/mm/abort-lv4t.S
--- linux-post-2.6.3-20040227/arch/arm/mm/abort-lv4t.S	2004-02-22 23:38:41.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/abort-lv4t.S	2004-02-26 12:13:53.000000000 +0000
@@ -188,38 +188,33 @@ ENTRY(v4t_late_abort)
 .data_thumb_pushpop:
 	tst	r8, #1 << 10
 	beq	.data_unknown
-	mov	r7, #0x11
-	and	r6, r8, r7
-	and	r2, r8, r7, lsl #1
+	and	r6, r8, #0x55			@ hweight8(r8) + R bit
+	and	r2, r8, #0xaa
 	add	r6, r6, r2, lsr #1
-	and	r2, r8, r7, lsl #2
+	and	r2, r6, #0xcc
+	and	r6, r6, #0x33
 	add	r6, r6, r2, lsr #2
-	and	r2, r8, r7, lsl #3
-	add	r6, r6, r2, lsr #3
-	add	r6, r6, r6, lsr #4
-	and	r2, r8, #0x0100			@ catch 'R' bit for push/pop
-	add	r6, r6, r2, lsr #8
+	movs	r7, r8, lsr #9			@ C = r8 bit 8 (R bit)
+	adc	r6, r6, r6, lsr #4		@ high + low nibble + R bit
 	and	r6, r6, #15			@ number of regs to transfer
 	ldr	r7, [sp, #13 << 2]
 	tst	r8, #1 << 11
-	addne	r7, r7, r6, lsl #2		@ increment SP if PUSH
-	subeq	r7, r7, r6, lsl #2		@ decrement SP if POP
+	addeq	r7, r7, r6, lsl #2		@ increment SP if PUSH
+	subne	r7, r7, r6, lsl #2		@ decrement SP if POP
 	str	r7, [sp, #13 << 2]
 	mov	pc, lr
 
 .data_thumb_ldmstm:
-	mov	r7, #0x11
-	and	r6, r8, r7
-	and	r2, r8, r7, lsl #1
+	and	r6, r8, #0x55			@ hweight8(r8)
+	and	r2, r8, #0xaa
 	add	r6, r6, r2, lsr #1
-	and	r2, r8, r7, lsl #2
+	and	r2, r6, #0xcc
+	and	r6, r6, #0x33
 	add	r6, r6, r2, lsr #2
-	and	r2, r8, r7, lsl #3
-	add	r6, r6, r2, lsr #3
 	add	r6, r6, r6, lsr #4
-	and	r6, r6, #15			@ number of regs to transfer
 	and	r5, r8, #7 << 8
 	ldr	r7, [sp, r5, lsr #6]
+	and	r6, r6, #15			@ number of regs to transfer
 	sub	r7, r7, r6, lsl #2		@ always decrement
 	str	r7, [sp, r5, lsr #6]
 	mov	pc, lr
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/blockops.c linux-post-2.6.4rc1-20040228/arch/arm/mm/blockops.c
--- linux-post-2.6.3-20040227/arch/arm/mm/blockops.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/blockops.c	2004-02-26 14:22:33.000000000 +0000
@@ -0,0 +1,183 @@
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/mm.h>
+
+#include <asm/memory.h>
+#include <asm/ptrace.h>
+#include <asm/cacheflush.h>
+#include <asm/traps.h>
+
+extern struct cpu_cache_fns blk_cache_fns;
+
+#define HARVARD_CACHE
+
+/*
+ *	blk_flush_kern_dcache_page(kaddr)
+ *
+ *	Ensure that the data held in the page kaddr is written back
+ *	to the page in question.
+ *
+ *	- kaddr   - kernel address (guaranteed to be page aligned)
+ */
+static void __attribute__((naked))
+blk_flush_kern_dcache_page(void *kaddr)
+{
+	asm(
+	"add	r1, r0, %0							\n\
+1:	.word	0xec401f0e	@ mcrr	p15, 0, r0, r1, c14, 0	@ blocking	\n\
+	mov	r0, #0								\n\
+	mcr	p15, 0, r0, c7, c5, 0						\n\
+	mcr	p15, 0, r0, c7, c10, 4						\n\
+	mov	pc, lr"
+	:
+	: "I" (PAGE_SIZE));
+}
+
+/*
+ *	blk_dma_inv_range(start,end)
+ *
+ *	Invalidate the data cache within the specified region; we will
+ *	be performing a DMA operation in this region and we want to
+ *	purge old data in the cache.
+ *
+ *	- start   - virtual start address of region
+ *	- end     - virtual end address of region
+ */
+static void __attribute__((naked))
+blk_dma_inv_range_unified(unsigned long start, unsigned long end)
+{
+	asm(
+	"tst	r0, %0								\n\
+	mcrne	p15, 0, r0, c7, c11, 1		@ clean unified line		\n\
+	tst	r1, %0								\n\
+	mcrne	p15, 0, r1, c7, c15, 1		@ clean & invalidate unified line\n\
+	.word	0xec401f06	@ mcrr	p15, 0, r1, r0, c6, 0	@ blocking	\n\
+	mov	r0, #0								\n\
+	mcr	p15, 0, r0, c7, c10, 4		@ drain write buffer		\n\
+	mov	pc, lr"
+	:
+	: "I" (L1_CACHE_BYTES - 1));
+}
+
+static void __attribute__((naked))
+blk_dma_inv_range_harvard(unsigned long start, unsigned long end)
+{
+	asm(
+	"tst	r0, %0								\n\
+	mcrne	p15, 0, r0, c7, c10, 1		@ clean D line			\n\
+	tst	r1, %0								\n\
+	mcrne	p15, 0, r1, c7, c14, 1		@ clean & invalidate D line	\n\
+	.word	0xec401f06	@ mcrr	p15, 0, r1, r0, c6, 0	@ blocking	\n\
+	mov	r0, #0								\n\
+	mcr	p15, 0, r0, c7, c10, 4		@ drain write buffer		\n\
+	mov	pc, lr"
+	:
+	: "I" (L1_CACHE_BYTES - 1));
+}
+
+/*
+ *	blk_dma_clean_range(start,end)
+ *	- start   - virtual start address of region
+ *	- end     - virtual end address of region
+ */
+static void __attribute__((naked))
+blk_dma_clean_range(unsigned long start, unsigned long end)
+{
+	asm(
+	".word	0xec401f0c	@ mcrr	p15, 0, r1, r0, c12, 0	@ blocking	\n\
+	mov	r0, #0								\n\
+	mcr	p15, 0, r0, c7, c10, 4		@ drain write buffer		\n\
+	mov	pc, lr");
+}
+
+/*
+ *	blk_dma_flush_range(start,end)
+ *	- start   - virtual start address of region
+ *	- end     - virtual end address of region
+ */
+static void __attribute__((naked))
+blk_dma_flush_range(unsigned long start, unsigned long end)
+{
+	asm(
+	".word	0xec401f0e	@ mcrr	p15, 0, r1, r0, c14, 0	@ blocking	\n\
+	mov	pc, lr");
+}
+
+static int blockops_trap(struct pt_regs *regs, unsigned int instr)
+{
+	regs->ARM_r4 |= regs->ARM_r2;
+	regs->ARM_pc += 4;
+	return 0;
+}
+
+static char *func[] = {
+	"Prefetch data range",
+	"Clean+Invalidate data range",
+	"Clean data range",
+	"Invalidate data range",
+	"Invalidate instr range"
+};
+
+static struct undef_hook blockops_hook __initdata = {
+	.instr_mask	= 0x0fffffd0,
+	.instr_val	= 0x0c401f00,
+	.cpsr_mask	= PSR_T_BIT,
+	.cpsr_val	= 0,
+	.fn		= blockops_trap,
+};
+
+static int __init blockops_check(void)
+{
+	register unsigned int err asm("r4") = 0;
+	unsigned int cache_type;
+	int i;
+
+	asm("mcr p15, 0, %0, c0, c0, 1" : "=r" (cache_type));
+
+	printk("Checking V6 block cache operations:\n");
+	register_undef_hook(&blockops_hook);
+
+	__asm__ ("mov	r0, %0\n\t"
+		"mov	r1, %1\n\t"
+		"mov	r2, #1\n\t"
+		".word	0xec401f2c @ mcrr p15, 0, r1, r0, c12, 2\n\t"
+		"mov	r2, #2\n\t"
+		".word	0xec401f0e @ mcrr p15, 0, r1, r0, c14, 0\n\t"
+		"mov	r2, #4\n\t"
+		".word	0xec401f0c @ mcrr p15, 0, r1, r0, c12, 0\n\t"
+		"mov	r2, #8\n\t"
+		".word	0xec401f06 @ mcrr p15, 0, r1, r0, c6, 0\n\t"
+		"mov	r2, #16\n\t"
+		".word	0xec401f05 @ mcrr p15, 0, r1, r0, c5, 0\n\t"
+		:
+		: "r" (PAGE_OFFSET), "r" (PAGE_OFFSET + 128)
+		: "r0", "r1", "r2");
+
+	unregister_undef_hook(&blockops_hook);
+
+	for (i = 0; i < ARRAY_SIZE(func); i++, err >>= 1)
+		printk("%30s: %ssupported\n", func[i], err & 1 ? "not " : "");
+
+	if ((err & 8) == 0) {
+		printk(" --> Using %s block cache invalidate\n",
+			cache_type & (1 << 24) ? "harvard" : "unified");
+		if (cache_type & (1 << 24))
+			cpu_cache.dma_inv_range = blk_dma_inv_range_harvard;
+		else
+			cpu_cache.dma_inv_range = blk_dma_inv_range_unified;
+	}
+	if ((err & 4) == 0) {
+		printk(" --> Using block cache clean\n");
+		cpu_cache.dma_clean_range        = blk_dma_clean_range;
+	}
+	if ((err & 2) == 0) {
+		printk(" --> Using block cache clean+invalidate\n");
+		cpu_cache.dma_flush_range        = blk_dma_flush_range;
+		cpu_cache.flush_kern_dcache_page = blk_flush_kern_dcache_page;
+	}
+
+	return 0;
+}
+
+__initcall(blockops_check);
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/cache-v6.S linux-post-2.6.4rc1-20040228/arch/arm/mm/cache-v6.S
--- linux-post-2.6.3-20040227/arch/arm/mm/cache-v6.S	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/cache-v6.S	2004-02-26 14:22:39.000000000 +0000
@@ -0,0 +1,208 @@
+/*
+ *  linux/arch/arm/mm/cache-v6.S
+ *
+ *  Copyright (C) 2001 Deep Blue Solutions Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ *  This is the "shell" of the ARMv6 processor support.
+ */
+#include <linux/linkage.h>
+#include <linux/init.h>
+#include <asm/assembler.h>
+
+#include "proc-macros.S"
+
+#define HARVARD_CACHE
+#define CACHE_LINE_SIZE		32
+#define D_CACHE_LINE_SIZE	32
+
+/*
+ *	v6_flush_cache_all()
+ *
+ *	Flush the entire cache.
+ *
+ *	It is assumed that:
+ */
+ENTRY(v6_flush_kern_cache_all)
+	mov	r0, #0
+#ifdef HARVARD_CACHE
+	mcr	p15, 0, r0, c7, c14, 0		@ D cache clean+invalidate
+	mcr	p15, 0, r0, c7, c5, 0		@ I+BTB cache invalidate
+#else
+	mcr	p15, 0, r0, c7, c15, 0		@ Cache clean+invalidate
+#endif
+	mov	pc, lr
+
+/*
+ *	v6_flush_cache_all()
+ *
+ *	Flush all TLB entries in a particular address space
+ *
+ *	- mm    - mm_struct describing address space
+ */
+ENTRY(v6_flush_user_cache_all)
+	/*FALLTHROUGH*/
+
+/*
+ *	v6_flush_cache_range(start, end, flags)
+ *
+ *	Flush a range of TLB entries in the specified address space.
+ *
+ *	- start - start address (may not be aligned)
+ *	- end   - end address (exclusive, may not be aligned)
+ *	- flags	- vm_area_struct flags describing address space
+ *
+ *	It is assumed that:
+ *	- we have a VIPT cache.
+ */
+ENTRY(v6_flush_user_cache_range)
+	mov	pc, lr
+
+/*
+ *	v6_coherent_kern_range(start,end)
+ *
+ *	Ensure that the I and D caches are coherent within specified
+ *	region.  This is typically used when code has been written to
+ *	a memory region, and will be executed.
+ *
+ *	- start   - virtual start address of region
+ *	- end     - virtual end address of region
+ *
+ *	It is assumed that:
+ *	- the Icache does not read data from the write buffer
+ */
+ENTRY(v6_coherent_kern_range)
+	bic	r0, r0, #CACHE_LINE_SIZE - 1
+1:
+#ifdef HARVARD_CACHE
+	mcr	p15, 0, r0, c7, c10, 1		@ clean D line
+	mcr	p15, 0, r0, c7, c5, 1		@ invalidate I line
+#endif
+	mcr	p15, 0, r0, c7, c5, 7		@ invalidate BTB entry
+	add	r0, r0, #CACHE_LINE_SIZE
+	cmp	r0, r1
+	blo	1b
+#ifdef HARVARD_CACHE
+	mov	r0, #0
+	mcr	p15, 0, r0, c7, c10, 4		@ drain write buffer
+#endif
+	mov	pc, lr
+
+/*
+ *	v6_flush_kern_dcache_page(kaddr)
+ *
+ *	Ensure that the data held in the page kaddr is written back
+ *	to the page in question.
+ *
+ *	- kaddr   - kernel address (guaranteed to be page aligned)
+ */
+ENTRY(v6_flush_kern_dcache_page)
+	add	r1, r0, #PAGE_SZ
+1:
+#ifdef HARVARD_CACHE
+	mcr	p15, 0, r0, c7, c14, 1		@ clean & invalidate D line
+#else
+	mcr	p15, 0, r0, c7, c15, 1		@ clean & invalidate unified line
+#endif	
+	add	r0, r0, #D_CACHE_LINE_SIZE
+	cmp	r0, r1
+	blo	1b
+#ifdef HARVARD_CACHE
+	mov	r0, #0
+	mcr	p15, 0, r0, c7, c10, 4
+#endif
+	mov	pc, lr
+
+
+/*
+ *	v6_dma_inv_range(start,end)
+ *
+ *	Invalidate the data cache within the specified region; we will
+ *	be performing a DMA operation in this region and we want to
+ *	purge old data in the cache.
+ *
+ *	- start   - virtual start address of region
+ *	- end     - virtual end address of region
+ */
+ENTRY(v6_dma_inv_range)
+	tst	r0, #D_CACHE_LINE_SIZE - 1
+	bic	r0, r0, #D_CACHE_LINE_SIZE - 1
+#ifdef HARVARD_CACHE
+	mcrne	p15, 0, r0, c7, c10, 1		@ clean D line
+#else
+	mcrne	p15, 0, r0, c7, c11, 1		@ clean unified line
+#endif
+	tst	r1, #D_CACHE_LINE_SIZE - 1
+	bic	r1, r1, #D_CACHE_LINE_SIZE - 1
+#ifdef HARVARD_CACHE
+	mcrne	p15, 0, r1, c7, c14, 1		@ clean & invalidate D line
+#else
+	mcrne	p15, 0, r1, c7, c15, 1		@ clean & invalidate unified line
+#endif
+1:
+#ifdef HARVARD_CACHE
+	mcr	p15, 0, r0, c7, c6, 1		@ invalidate D line
+#else
+	mcr	p15, 0, r0, c7, c7, 1		@ invalidate unified line
+#endif
+	add	r0, r0, #D_CACHE_LINE_SIZE
+	cmp	r0, r1
+	blo	1b
+	mcr	p15, 0, r0, c7, c10, 4		@ drain write buffer
+	mov	pc, lr
+
+/*
+ *	v6_dma_clean_range(start,end)
+ *	- start   - virtual start address of region
+ *	- end     - virtual end address of region
+ */
+ENTRY(v6_dma_clean_range)
+	bic	r0, r0, #D_CACHE_LINE_SIZE - 1
+1:
+#ifdef HARVARD_CACHE
+	mcr	p15, 0, r0, c7, c10, 1		@ clean D line
+#else
+	mcr	p15, 0, r0, c7, c11, 1		@ clean unified line
+#endif
+	add	r0, r0, #D_CACHE_LINE_SIZE
+	cmp	r0, r1
+	blo	1b
+	mov	r0, #0
+	mcr	p15, 0, r0, c7, c10, 4		@ drain write buffer
+	mov	pc, lr
+
+/*
+ *	v6_dma_flush_range(start,end)
+ *	- start   - virtual start address of region
+ *	- end     - virtual end address of region
+ */
+ENTRY(v6_dma_flush_range)
+	bic	r0, r0, #D_CACHE_LINE_SIZE - 1
+1:
+#ifdef HARVARD_CACHE
+	mcr	p15, 0, r0, c7, c14, 1		@ clean & invalidate D line
+#else
+	mcr	p15, 0, r0, c7, c15, 1		@ clean & invalidate line
+#endif
+	add	r0, r0, #D_CACHE_LINE_SIZE
+	blo	1b
+	mov	r0, #0
+	mcr	p15, 0, r0, c7, c10, 4		@ drain write buffer
+	mov	pc, lr
+
+	__INITDATA
+
+	.type	v6_cache_fns, #object
+ENTRY(v6_cache_fns)
+	.long	v6_flush_kern_cache_all
+	.long	v6_flush_user_cache_all
+	.long	v6_flush_user_cache_range
+	.long	v6_coherent_kern_range
+	.long	v6_flush_kern_dcache_page
+	.long	v6_dma_inv_range
+	.long	v6_dma_clean_range
+	.long	v6_dma_flush_range
+	.size	v6_cache_fns, . - v6_cache_fns
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/copypage-v6.c linux-post-2.6.4rc1-20040228/arch/arm/mm/copypage-v6.c
--- linux-post-2.6.3-20040227/arch/arm/mm/copypage-v6.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/copypage-v6.c	2004-02-26 14:22:45.000000000 +0000
@@ -0,0 +1,99 @@
+/*
+ *  linux/arch/arm/mm/copypage-v6.c
+ *
+ *  Copyright (C) 2002 Deep Blue Solutions Ltd, All Rights Reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ */
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/mm.h>
+
+#include <asm/page.h>
+#include <asm/pgalloc.h>
+#include <asm/pgtable.h>
+#include <asm/shmparam.h>
+#include <asm/tlbflush.h>
+
+#if SHMLBA > 16384
+#error FIX ME
+#endif
+
+#define from_address	(0xffff8000)
+#define from_pgprot	PAGE_KERNEL
+#define to_address	(0xffffc000)
+#define to_pgprot	PAGE_KERNEL
+
+static pte_t *from_pte;
+static pte_t *to_pte;
+static spinlock_t v6_lock = SPIN_LOCK_UNLOCKED;
+
+#define DCACHE_COLOUR(vaddr) ((vaddr & (SHMLBA - 1)) >> PAGE_SHIFT)
+
+/*
+ * Copy the page, taking account of the cache colour.
+ */
+void v6_copy_user_page(void *kto, const void *kfrom, unsigned long vaddr)
+{
+	unsigned int offset = DCACHE_COLOUR(vaddr);
+	unsigned long from, to;
+
+	spin_lock(&v6_lock);
+
+	set_pte(from_pte + offset, pfn_pte(__pa(kfrom) >> PAGE_SHIFT, from_pgprot));
+	set_pte(to_pte + offset, pfn_pte(__pa(kto) >> PAGE_SHIFT, to_pgprot));
+
+	from = from_address + (offset << PAGE_SHIFT);
+	to   = to_address + (offset << PAGE_SHIFT);
+
+	flush_tlb_kernel_page(from);
+	flush_tlb_kernel_page(to);
+
+	copy_page((void *)to, (void *)from);
+
+	spin_unlock(&v6_lock);
+}
+
+void v6_clear_user_page(void *kaddr, unsigned long vaddr)
+{
+	unsigned int offset = DCACHE_COLOUR(vaddr);
+	unsigned long to = to_address + (offset << PAGE_SHIFT);
+
+	spin_lock(&v6_lock);
+
+	set_pte(to_pte + offset, pfn_pte(__pa(kaddr) >> PAGE_SHIFT, to_pgprot));
+	flush_tlb_kernel_page(to);
+	clear_page((void *)to);
+
+	spin_unlock(&v6_lock);
+}
+
+struct cpu_user_fns v6_user_fns __initdata = {
+	.cpu_clear_user_page	= v6_clear_user_page,
+	.cpu_copy_user_page	= v6_copy_user_page,
+};
+
+static int __init v6_userpage_init(void)
+{
+	pgd_t *pgd;
+	pmd_t *pmd;
+
+	pgd = pgd_offset_k(from_address);
+	pmd = pmd_alloc(&init_mm, pgd, from_address);
+	if (!pmd)
+		BUG();
+	from_pte = pte_alloc_kernel(&init_mm, pmd, from_address);
+	if (!from_pte)
+		BUG();
+
+	to_pte = pte_alloc_kernel(&init_mm, pmd, to_address);
+	if (!to_pte)
+		BUG();
+
+	return 0;
+}
+
+__initcall(v6_userpage_init);
+
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/mm-armv.c linux-post-2.6.4rc1-20040228/arch/arm/mm/mm-armv.c
--- linux-post-2.6.3-20040227/arch/arm/mm/mm-armv.c	2004-01-04 17:27:58.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/mm-armv.c	2004-02-27 18:14:53.000000000 +0000
@@ -585,20 +585,31 @@ void __init iotable_init(struct map_desc
 		create_mapping(io_desc + i);
 }
 
-static inline void free_memmap(int node, unsigned long start, unsigned long end)
+static inline void
+free_memmap(int node, unsigned long start_pfn, unsigned long end_pfn)
 {
+	struct page *start_pg, *end_pg;
 	unsigned long pg, pgend;
 
-	start = __phys_to_virt(start);
-	end   = __phys_to_virt(end);
-
-	pg    = PAGE_ALIGN((unsigned long)(virt_to_page(start)));
-	pgend = ((unsigned long)(virt_to_page(end))) & PAGE_MASK;
+	/*
+	 * Convert start_pfn/end_pfn to a struct page pointer.
+	 */
+	start_pg = pfn_to_page(start_pfn);
+	end_pg = pfn_to_page(end_pfn);
 
-	start = __virt_to_phys(pg);
-	end   = __virt_to_phys(pgend);
+	/*
+	 * Convert to physical addresses, and
+	 * round start upwards and end downwards.
+	 */
+	pg = PAGE_ALIGN(__pa(start_pg));
+	pgend = __pa(end_pg) & PAGE_MASK;
 
-	free_bootmem_node(NODE_DATA(node), start, end - start);
+	/*
+	 * If there are free pages between these,
+	 * free the section of the memmap array.
+	 */
+	if (pg < pgend)
+		free_bootmem_node(NODE_DATA(node), pg, pgend - pg);
 }
 
 static inline void free_unused_memmap_node(int node, struct meminfo *mi)
@@ -615,7 +626,12 @@ static inline void free_unused_memmap_no
 		if (mi->bank[i].size == 0 || mi->bank[i].node != node)
 			continue;
 
-		bank_start = mi->bank[i].start & PAGE_MASK;
+		bank_start = mi->bank[i].start >> PAGE_SHIFT;
+		if (bank_start < prev_bank_end) {
+			printk(KERN_ERR "MEM: unordered memory banks.  "
+				"Not freeing memmap.\n");
+			break;
+		}
 
 		/*
 		 * If we had a previous bank, and there is a space
@@ -625,7 +641,7 @@ static inline void free_unused_memmap_no
 			free_memmap(node, prev_bank_end, bank_start);
 
 		prev_bank_end = PAGE_ALIGN(mi->bank[i].start +
-					   mi->bank[i].size);
+					   mi->bank[i].size) >> PAGE_SHIFT;
 	}
 }
 
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/proc-macros.S linux-post-2.6.4rc1-20040228/arch/arm/mm/proc-macros.S
--- linux-post-2.6.3-20040227/arch/arm/mm/proc-macros.S	2002-03-19 18:01:35.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/proc-macros.S	2004-02-26 14:22:25.000000000 +0000
@@ -35,3 +35,17 @@
 	ldr	\rd, [\rd, #TI_TASK]
 	ldr	\rd, [\rd, #TSK_ACTIVE_MM]
 	.endm
+
+/*
+ * mmid - get context id from mm pointer (mm->context.id)
+ */
+	.macro	mmid, rd, rn
+	ldr	\rd, [\rn, #MM_CONTEXT_ID]
+	.endm
+
+/*
+ * mask_asid - mask the ASID from the context ID
+ */
+	.macro	asid, rd, rn
+	and	\rd, \rn, #255
+	.endm
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/proc-v6.S linux-post-2.6.4rc1-20040228/arch/arm/mm/proc-v6.S
--- linux-post-2.6.3-20040227/arch/arm/mm/proc-v6.S	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/proc-v6.S	2004-02-26 14:22:50.000000000 +0000
@@ -0,0 +1,267 @@
+/*
+ *  linux/arch/arm/mm/proc-v6.S
+ *
+ *  Copyright (C) 2001 Deep Blue Solutions Ltd.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ *  This is the "shell" of the ARMv6 processor support.
+ */
+#include <linux/linkage.h>
+#include <asm/assembler.h>
+#include <asm/constants.h>
+#include <asm/procinfo.h>
+#include <asm/pgtable.h>
+
+#include "proc-macros.S"
+
+#define D_CACHE_LINE_SIZE	32
+
+	.macro	cpsie, flags
+	.ifc \flags, f
+	.long	0xf1080040
+	.exitm
+	.endif
+	.ifc \flags, i
+	.long	0xf1080080
+	.exitm
+	.endif
+	.ifc \flags, if
+	.long	0xf10800c0
+	.exitm
+	.endif
+	.err
+	.endm
+
+	.macro	cpsid, flags
+	.ifc \flags, f
+	.long	0xf10c0040
+	.exitm
+	.endif
+	.ifc \flags, i
+	.long	0xf10c0080
+	.exitm
+	.endif
+	.ifc \flags, if
+	.long	0xf10c00c0
+	.exitm
+	.endif
+	.err
+	.endm
+
+ENTRY(cpu_v6_proc_init)
+	mov	pc, lr
+
+ENTRY(cpu_v6_proc_fin)
+	mov	pc, lr
+
+/*
+ *	cpu_v6_reset(loc)
+ *
+ *	Perform a soft reset of the system.  Put the CPU into the
+ *	same state as it would be if it had been reset, and branch
+ *	to what would be the reset vector.
+ *
+ *	- loc   - location to jump to for soft reset
+ *
+ *	It is assumed that:
+ */
+	.align	5
+ENTRY(cpu_v6_reset)
+	mov	pc, r0
+
+/*
+ *	cpu_v6_do_idle()
+ *
+ *	Idle the processor (eg, wait for interrupt).
+ *
+ *	IRQs are already disabled.
+ */
+ENTRY(cpu_v6_do_idle)
+	mcr	p15, 0, r1, c7, c0, 4		@ wait for interrupt
+	mov	pc, lr
+
+ENTRY(cpu_v6_dcache_clean_area)
+#ifndef TLB_CAN_READ_FROM_L1_CACHE
+1:	mcr	p15, 0, r0, c7, c10, 1		@ clean D entry
+	add	r0, r0, #D_CACHE_LINE_SIZE
+	subs	r1, r1, #D_CACHE_LINE_SIZE
+	bhi	1b
+#endif
+	mov	pc, lr
+
+/*
+ *	cpu_arm926_switch_mm(pgd_phys, tsk)
+ *
+ *	Set the translation table base pointer to be pgd_phys
+ *
+ *	- pgd_phys - physical address of new TTB
+ *
+ *	It is assumed that:
+ *	- we are not using split page tables
+ */
+ENTRY(cpu_v6_switch_mm)
+	mov	r2, #0
+	ldr	r1, [r1, #MM_CONTEXT_ID]	@ get mm->context.id
+	mcr	p15, 0, r2, c7, c10, 4		@ drain write buffer
+	mcr	p15, 0, r0, c2, c0, 0		@ set TTB 0
+	mcr	p15, 0, r1, c13, c0, 1		@ set context ID
+	mov	pc, lr
+
+#define nG	(1 << 11)
+#define APX	(1 << 9)
+#define AP1	(1 << 5)
+#define AP0	(1 << 4)
+#define XN	(1 << 0)
+
+/*
+ *	cpu_v6_set_pte(ptep, pte)
+ *
+ *	Set a level 2 translation table entry.
+ *
+ *	- ptep  - pointer to level 2 translation table entry
+ *		  (hardware version is stored at -1024 bytes)
+ *	- pte   - PTE value to store
+ *
+ *	Permissions:
+ *	  YUWD  APX AP1 AP0	SVC	User
+ *	  0xxx   0   0   0	no acc	no acc
+ *	  100x   1   0   1	r/o	no acc
+ *	  10x0   1   0   1	r/o	no acc
+ *	  1011   0   0   1	r/w	no acc
+ *	  110x   1   1   0	r/o	r/o
+ *	  11x0   1   1   0	r/o	r/o
+ *	  1111   0   1   1	r/w	r/w
+ */
+ENTRY(cpu_v6_set_pte)
+	str	r1, [r0], #-2048		@ linux version
+
+	bic	r2, r1, #0x00000ff0
+	bic	r2, r2, #0x00000003
+	orr	r2, r2, #AP0 | 2
+
+	tst	r1, #L_PTE_WRITE
+	tstne	r1, #L_PTE_DIRTY
+	orreq	r2, r2, #APX
+
+	tst	r1, #L_PTE_USER
+	orrne	r2, r2, #AP1 | nG
+	tstne	r2, #APX
+	eorne	r2, r2, #AP0
+
+	tst	r1, #L_PTE_YOUNG
+	biceq	r2, r2, #APX | AP1 | AP0
+
+@	tst	r1, #L_PTE_EXEC
+@	orreq	r2, r2, #XN
+
+	tst	r1, #L_PTE_PRESENT
+	moveq	r2, #0
+
+	str	r2, [r0]
+	mcr	p15, 0, r0, c7, c10, 1 @ flush_pte
+	mov	pc, lr
+
+
+
+
+cpu_v6_name:
+	.asciz	"Some Random V6 Processor"
+	.align
+
+	.section ".text.init", #alloc, #execinstr
+
+/*
+ *	__v6_setup
+ *
+ *	Initialise TLB, Caches, and MMU state ready to switch the MMU
+ *	on.  Return in r0 the new CP15 C1 control register setting.
+ *
+ *	We automatically detect if we have a Harvard cache, and use the
+ *	Harvard cache control instructions insead of the unified cache
+ *	control instructions.
+ *
+ *	This should be able to cover all ARMv6 cores.
+ *
+ *	It is assumed that:
+ *	- cache type register is implemented
+ */
+__v6_setup:
+	mrc	p15, 0, r10, c0, c0, 1		@ read cache type register
+	tst	r10, #1 << 24			@ Harvard cache?
+	mov	r10, #0
+	mcrne	p15, 0, r10, c7, c14, 0		@ clean+invalidate D cache
+	mcrne	p15, 0, r10, c7, c5, 0		@ invalidate I cache
+	mcreq	p15, 0, r10, c7, c15, 0		@ clean+invalidate cache
+	mcr	p15, 0, r10, c7, c10, 4		@ drain write buffer
+	mcr	p15, 0, r10, c8, c7, 0		@ invalidate I + D TLBs
+	mcr	p15, 0, r10, c2, c0, 2		@ TTB control register
+	mcr	p15, 0, r4, c2, c0, 0		@ load TTB0
+	mcr	p15, 0, r4, c2, c0, 1		@ load TTB1
+	mov	r10, #0x1f			@ domains 0, 1 = manager
+	mcr	p15, 0, r10, c3, c0, 0		@ load domain access register
+	mrc	p15, 0, r0, c1, c0, 0		@ read control register
+	ldr	r10, cr1_clear			@ get mask for bits to clear
+	bic	r0, r0, r10			@ clear bits them
+	ldr	r10, cr1_set			@ get mask for bits to set
+	orr	r0, r0, r10			@ set them
+	mov	pc, lr				@ return to head.S:__ret
+
+	/*
+	 *         V X F   I D LR
+	 * .... ...E PUI. .T.T 4RVI ZFRS BLDP WCAM
+	 * rrrr rrrx xxx0 0101 xxxx xxxx x111 xxxx < forced
+	 *         0 110       0011 1.00 .111 1101 < we want
+	 */
+	.type	cr1_clear, #object
+	.type	cr1_set, #object
+cr1_clear:
+	.word	0x0120c302
+cr1_set:
+	.word	0x00c0387d
+
+	.type	v6_processor_functions, #object
+ENTRY(v6_processor_functions)
+	.word	v6_early_abort
+	.word	cpu_v6_proc_init
+	.word	cpu_v6_proc_fin
+	.word	cpu_v6_reset
+	.word	cpu_v6_do_idle
+	.word	cpu_v6_dcache_clean_area
+	.word	cpu_v6_switch_mm
+	.word	cpu_v6_set_pte
+	.size	v6_processor_functions, . - v6_processor_functions
+
+	.type	cpu_arch_name, #object
+cpu_arch_name:
+	.asciz	"armv6"
+	.size	cpu_arch_name, . - cpu_arch_name
+
+	.type	cpu_elf_name, #object
+cpu_elf_name:
+	.asciz	"v6"
+	.size	cpu_elf_name, . - cpu_elf_name
+	.align
+
+	.section ".proc.info", #alloc, #execinstr
+
+	/*
+	 * Match any ARMv6 processor core.
+	 */
+	.type	__v6_proc_info, #object
+__v6_proc_info:
+	.long	0x00070000
+	.long	0x00ff0000
+	.long	0x00000c0e
+	b	__v6_setup
+	.long	cpu_arch_name
+	.long	cpu_elf_name
+	.long	HWCAP_SWP | HWCAP_HALF | HWCAP_FAST_MULT | HWCAP_VFP
+	.long	cpu_v6_name
+	.long	v6_processor_functions
+	.long	v6wbi_tlb_fns
+	.long	v6_user_fns
+	.long	v6_cache_fns
+	.size	__v6_proc_info, . - __v6_proc_info
diff -purN linux-post-2.6.3-20040227/arch/arm/mm/tlb-v6.S linux-post-2.6.4rc1-20040228/arch/arm/mm/tlb-v6.S
--- linux-post-2.6.3-20040227/arch/arm/mm/tlb-v6.S	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/mm/tlb-v6.S	2004-02-26 14:22:56.000000000 +0000
@@ -0,0 +1,92 @@
+/*
+ *  linux/arch/arm/mm/tlb-v6.S
+ *
+ *  Copyright (C) 1997-2002 Russell King
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ *  ARM architecture version 6 TLB handling functions.
+ *  These assume a split I/D TLB.
+ */
+#include <linux/linkage.h>
+#include <asm/constants.h>
+#include <asm/page.h>
+#include <asm/tlbflush.h>
+#include "proc-macros.S"
+
+#define HARVARD_TLB
+
+/*
+ *	v6wbi_flush_user_tlb_range(start, end, vma)
+ *
+ *	Invalidate a range of TLB entries in the specified address space.
+ *
+ *	- start - start address (may not be aligned)
+ *	- end   - end address (exclusive, may not be aligned)
+ *	- vma   - vma_struct describing address range
+ *
+ *	It is assumed that:
+ *	- the "Invalidate single entry" instruction will invalidate
+ *	  both the I and the D TLBs on Harvard-style TLBs
+ */
+ENTRY(v6wbi_flush_user_tlb_range)
+	vma_vm_mm r3, r2			@ get vma->vm_mm
+	mov	ip, #0
+	mmid	r3, r3				@ get vm_mm->context.id
+	mcr	p15, 0, ip, c7, c10, 4		@ drain write buffer
+	mov	r0, r0, lsr #PAGE_SHIFT		@ align address
+	mov	r1, r1, lsr #PAGE_SHIFT
+	asid	r3, r3				@ mask ASID
+	orr	r0, r3, r0, lsl #PAGE_SHIFT	@ Create initial MVA
+	mov	r1, r1, lsl #PAGE_SHIFT
+	vma_vm_flags r2, r2			@ get vma->vm_flags
+1:
+#ifdef HARVARD_TLB
+	mcr	p15, 0, r0, c8, c6, 1		@ TLB invalidate D MVA (was 1)
+	tst	r2, #VM_EXEC			@ Executable area ?
+	mcrne	p15, 0, r0, c8, c5, 1		@ TLB invalidate I MVA (was 1)
+#else
+	mcr	p15, 0, r0, c8, c7, 1		@ TLB invalidate MVA (was 1)
+#endif
+	add	r0, r0, #PAGE_SZ
+	cmp	r0, r1
+	blo	1b
+	mov	pc, lr
+
+/*
+ *	v6wbi_flush_kern_tlb_range(start,end)
+ *
+ *	Invalidate a range of kernel TLB entries
+ *
+ *	- start - start address (may not be aligned)
+ *	- end   - end address (exclusive, may not be aligned)
+ */
+ENTRY(v6wbi_flush_kern_tlb_range)
+	mov	r2, #0
+	mcr	p15, 0, r2, c7, c10, 4		@ drain write buffer
+	mov	r0, r0, lsr #PAGE_SHIFT		@ align address
+	mov	r1, r1, lsr #PAGE_SHIFT
+	mov	r0, r0, lsl #PAGE_SHIFT
+	mov	r1, r1, lsl #PAGE_SHIFT
+1:
+#ifdef HARVARD_TLB
+	mcr	p15, 0, r0, c8, c6, 1		@ TLB invalidate D MVA
+	mcr	p15, 0, r0, c8, c5, 1		@ TLB invalidate I MVA
+#else
+	mcr	p15, 0, r0, c8, c7, 1		@ TLB invalidate MVA
+#endif
+	add	r0, r0, #PAGE_SZ
+	cmp	r0, r1
+	blo	1b
+	mov	pc, lr
+
+	.section ".text.init", #alloc, #execinstr
+
+	.type	v6wbi_tlb_fns, #object
+ENTRY(v6wbi_tlb_fns)
+	.long	v6wbi_flush_user_tlb_range
+	.long	v6wbi_flush_kern_tlb_range
+	.long	v6wbi_tlb_flags
+	.size	v6wbi_tlb_fns, . - v6wbi_tlb_fns
diff -purN linux-post-2.6.3-20040227/arch/arm/nwfpe/fpmodule.c linux-post-2.6.4rc1-20040228/arch/arm/nwfpe/fpmodule.c
--- linux-post-2.6.3-20040227/arch/arm/nwfpe/fpmodule.c	2003-03-29 20:44:32.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/nwfpe/fpmodule.c	2004-02-27 10:13:00.000000000 +0000
@@ -50,11 +50,6 @@
 
 #ifdef MODULE
 void fp_send_sig(unsigned long sig, struct task_struct *p, int priv);
-#if LINUX_VERSION_CODE > 0x20115
-MODULE_AUTHOR("Scott Bambrough <scottb@rebel.com>");
-MODULE_DESCRIPTION("NWFPE floating point emulator (" NWFPE_BITS " precision)");
-#endif
-
 #else
 #define fp_send_sig	send_sig
 #define kern_fp_enter	fp_enter
@@ -172,3 +167,7 @@ void float_raise(signed char flags)
 
 module_init(fpe_init);
 module_exit(fpe_exit);
+
+MODULE_AUTHOR("Scott Bambrough <scottb@rebel.com>");
+MODULE_DESCRIPTION("NWFPE floating point emulator (" NWFPE_BITS " precision)");
+MODULE_LICENSE("GPL");
diff -purN linux-post-2.6.3-20040227/arch/arm/tools/mach-types linux-post-2.6.4rc1-20040228/arch/arm/tools/mach-types
--- linux-post-2.6.3-20040227/arch/arm/tools/mach-types	2003-09-19 16:25:19.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/arm/tools/mach-types	2004-02-27 15:26:12.000000000 +0000
@@ -6,7 +6,7 @@
 # To add an entry into this database, please see Documentation/arm/README,
 # or contact rmk@arm.linux.org.uk
 #
-# Last update: Thu Sep 18 17:15:55 2003
+# Last update: Tue Feb 24 17:17:50 2004
 #
 # machine_is_xxx	CONFIG_xxxx		MACH_TYPE_xxx		number
 #
@@ -202,7 +202,7 @@ karo			ARCH_KARO		KARO			190
 fester			SA1100_FESTER		FESTER			191
 gpi			ARCH_GPI		GPI			192
 smdk2410		ARCH_SMDK2410		SMDK2410		193
-premium			ARCH_PREMIUM		PREMIUM			194
+i519			ARCH_I519		I519			194
 nexio			SA1100_NEXIO		NEXIO			195
 bitbox			SA1100_BITBOX		BITBOX			196
 g200			SA1100_G200		G200			197
@@ -259,7 +259,7 @@ stork_nest		ARCH_STORK_NEST		STORK_NEST	
 stork_egg		ARCH_STORK_EGG		STORK_EGG		248
 wismo			SA1100_WISMO		WISMO			249
 ezlinx			ARCH_EZLINX		EZLINX			250
-at91rm9200		ARCH_AT91		AT91			251
+at91rm9200		ARCH_AT91RM9200		AT91RM9200		251
 orion			ARCH_ORION		ORION			252
 neptune			ARCH_NEPTUNE		NEPTUNE			253
 hackkit			SA1100_HACKKIT		HACKKIT			254
@@ -295,7 +295,7 @@ viper			ARCH_VIPER		VIPER			283
 adsbitsyplus		SA1100_ADSBITSYPLUS	ADSBITSYPLUS		284
 adsagc			SA1100_ADSAGC		ADSAGC			285
 stp7312			ARCH_STP7312		STP7312			286
-nx_phnx			ARCH_PXA255		PXA255			287
+nx_phnx			MACH_NX_PHNX		NX_PHNX			287
 wep_ep250		ARCH_WEP_EP250		WEP_EP250		288
 inhandelf3		ARCH_INHANDELF3		INHANDELF3		289
 adi_coyote		ARCH_ADI_COYOTE		ADI_COYOTE		290
@@ -364,7 +364,7 @@ ixrd425			ARCH_IXRD425		IXRD425			352
 iq80315			ARCH_IQ80315		IQ80315			353
 nmp7312			ARCH_NMP7312		NMP7312			354
 cx861xx			ARCH_CX861XX		CX861XX			355
-ixp2000			ARCH_IXP2000		IXP2000			356
+enp2611			ARCH_ENP2611		ENP2611			356
 xda			SA1100_XDA		XDA			357
 csir_ims		ARCH_CSIR_IMS		CSIR_IMS		358
 ixp421_dnaeeth		ARCH_IXP421_DNAEETH	IXP421_DNAEETH		359
@@ -385,3 +385,92 @@ gumstik			ARCH_GUMSTIK		GUMSTIK			373
 rcube			ARCH_RCUBE		RCUBE			374
 rea_olv			ARCH_REA_OLV		REA_OLV			375
 pxa_iphone		ARCH_PXA_IPHONE		PXA_IPHONE		376
+s3c3410			ARCH_S3C3410		S3C3410			377
+espd_4510b		ARCH_ESPD_4510B		ESPD_4510B		378
+mp1x			ARCH_MP1X		MP1X			379
+at91rm9200tb		ARCH_AT91RM9200TB	AT91RM9200TB		380
+adsvgx			ARCH_ADSVGX		ADSVGX			381
+omap1610		ARCH_OMAP1610		OMAP1610		382
+pelee			ARCH_PELEE		PELEE			383
+e7xx			ARCH_E7XX		E7XX			384
+iq80331			ARCH_IQ80331		IQ80331			385
+versatile_pb		ARCH_VERSATILE_PB	VERSATILE_PB		387
+kev7a400		MACH_KEV7A400		KEV7A400		388
+lpd7a400		MACH_LPD7A400		LPD7A400		389
+lpd7a404		MACH_LPD7A404		LPD7A404		390
+fujitsu_camelot		ARCH_FUJITSU_CAMELOT	FUJITSU_CAMELOT		391
+janus2m			ARCH_JANUS2M		JANUS2M			392
+embtf			MACH_EMBTF		EMBTF			393
+hpm			MACH_HPM		HPM			394
+smdk2410tk		MACH_SMDK2410TK		SMDK2410TK		395
+smdk2410aj		MACH_SMDK2410AJ		SMDK2410AJ		396
+streetracer		MACH_STREETRACER	STREETRACER		397
+eframe			MACH_EFRAME		EFRAME			398
+csb337			MACH_CSB337		CSB337			399
+pxa_lark		MACH_PXA_LARK		PXA_LARK		400
+pxa_pnp2110		MACH_PNP2110		PNP2110			401
+tcc72x			MACH_TCC72X		TCC72X			402
+altair			MACH_ALTAIR		ALTAIR			403
+kc3			MACH_KC3		KC3			404
+sinteftd		MACH_SINTEFTD		SINTEFTD		405
+mainstone		MACH_MAINSTONE		MAINSTONE		406
+aday4x			MACH_ADAY4X		ADAY4X			407
+lite300			MACH_LITE300		LITE300			408
+s5c7376			MACH_S5C7376		S5C7376			409
+mt02			MACH_MT02		MT02			410
+mport3s			MACH_MPORT3S		MPORT3S			411
+ra_alpha		MACH_RA_ALPHA		RA_ALPHA		412
+xcep			MACH_XCEP		XCEP			413
+arcom_mercury		MACH_ARCOM_MERCURY	ARCOM_MERCURY		414
+stargate		MACH_STARGATE		STARGATE		415
+armadilloj		MACH_ARMADILLOJ		ARMADILLOJ		416
+elroy_jack		MACH_ELROY_JACK		ELROY_JACK		417
+backend			MACH_BACKEND		BACKEND			418
+s5linbox		MACH_S5LINBOX		S5LINBOX		419
+nomadik			MACH_NOMADIK		NOMADIK			420
+ia_cpu_9200		MACH_IA_CPU_9200	IA_CPU_9200		421
+at91_bja1		MACH_AT91_BJA1		AT91_BJA1		422
+corgi			MACH_CORGI		CORGI			423
+poodle			MACH_POODLE		POODLE			424
+ten			MACH_TEN		TEN			425
+roverp5p		MACH_ROVERP5P		ROVERP5P		426
+sc2700			MACH_SC2700		SC2700			427
+ex_eagle		MACH_EX_EAGLE		EX_EAGLE		428
+nx_pxa12		MACH_NX_PXA12		NX_PXA12		429
+nx_pxa5			MACH_NX_PXA5		NX_PXA5			430
+blackboard2		MACH_BLACKBOARD2	BLACKBOARD2		431
+i819			MACH_I819		I819			432
+ixmb995e		MACH_IXMB995E		IXMB995E		433
+skyrider		MACH_SKYRIDER		SKYRIDER		434
+skyhawk			MACH_SKYHAWK		SKYHAWK			435
+enterprise		MACH_ENTERPRISE		ENTERPRISE		436
+dep2410			MACH_DEP2410		DEP2410			437
+armcore			MACH_ARMCORE		ARMCORE			438
+hobbit			MACH_HOBBIT		HOBBIT			439
+h7210			MACH_H7210		H7210			440
+pxa_netdcu5		MACH_PXA_NETDCU5	PXA_NETDCU5		441
+acc			MACH_ACC		ACC			442
+esl_sarva		MACH_ESL_SARVA		ESL_SARVA		443
+xm250			MACH_XM250		XM250			444
+t6tc1xb			MACH_T6TC1XB		T6TC1XB			445
+ess710			MACH_ESS710		ESS710			446
+mx3ads			MACH_MX3ADS		MX3ADS			447
+himalaya		MACH_HIMALAYA		HIMALAYA		448
+bolfenk			MACH_BOLFENK		BOLFENK			449
+at91rm9200kr		MACH_AT91RM9200KR	AT91RM9200KR		450
+edb9312			MACH_EDB9312		EDB9312			451
+omap_generic		MACH_OMAP_GENERIC	OMAP_GENERIC		452
+aximx3			MACH_AXIMX3		AXIMX3			453
+eb67xdip		MACH_EB67XDIP		EB67XDIP		454
+webtxs			MACH_WEBTXS		WEBTXS			455
+hawk			MACH_HAWK		HAWK			456
+ccat91sbc001		MACH_CCAT91SBC001	CCAT91SBC001		457
+expresso		MACH_EXPRESSO		EXPRESSO		458
+h4000			MACH_H4000		H4000			459
+dino			MACH_DINO		DINO			460
+ml675k			MACH_ML675K		ML675K			461
+edb9301			MACH_EDB9301		EDB9301			462
+edb9315			MACH_EDB9315		EDB9315			463
+reciva_tt		MACH_RECIVA_TT		RECIVA_TT		464
+cstcb01			MACH_CSTCB01		CSTCB01			465
+cstcb1			MACH_CSTCB1		CSTCB1			466
diff -purN linux-post-2.6.3-20040227/arch/ppc64/Kconfig linux-post-2.6.4rc1-20040228/arch/ppc64/Kconfig
--- linux-post-2.6.3-20040227/arch/ppc64/Kconfig	2004-02-27 05:25:15.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/Kconfig	2004-02-27 07:24:31.000000000 +0000
@@ -89,6 +89,17 @@ config PPC_PMAC
 	bool "Apple PowerMac G5 support"
 	select ADB_PMU
 
+config PMAC_DART
+	bool "Enable DART/IOMMU on PowerMac (allow >2G of RAM)"
+	depends on PPC_PMAC
+	depends on EXPERIMENTAL
+	default n
+	help
+	  Enabling DART makes it possible to boot a PowerMac G5 with more
+	  than 2GB of memory. Note that the code is very new and untested
+	  at this time, so it has to be considered experimental. Enabling
+	  this might result in data loss.
+
 config PPC_PMAC64
 	bool
 	depends on PPC_PMAC
@@ -109,6 +120,18 @@ config POWER4_ONLY
 	  binary will not work on POWER3 or RS64 processors when compiled with
 	  binutils 2.15 or later.
 
+config IOMMU_VMERGE
+	bool "Enable IOMMU virtual merging (EXPERIMENTAL)"
+	depends on EXPERIMENTAL
+	default n
+	help
+	  Cause IO segments sent to a device for DMA to be merged virtually
+	  by the IOMMU when they happen to have been allocated contiguously.
+	  This doesn't add pressure to the IOMMU allocator. However, some
+	  drivers don't support getting large merged segments coming back
+	  from *_map_sg(). Say Y if you know the drivers you are using are
+	  properly handling this case.
+
 config SMP
 	bool "Symmetric multi-processing support"
 	---help---
@@ -287,9 +310,6 @@ config VIOTAPE
 	  If you are running Linux on an iSeries system and you want Linux
 	  to read and/or write a tape drive owned by OS/400, say Y here.
 
-config VETH
-	tristate "iSeries Virtual Ethernet driver support"
-
 endmenu
 
 config VIOPATH
diff -purN linux-post-2.6.3-20040227/arch/ppc64/configs/iSeries_defconfig linux-post-2.6.4rc1-20040228/arch/ppc64/configs/iSeries_defconfig
--- linux-post-2.6.3-20040227/arch/ppc64/configs/iSeries_defconfig	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/configs/iSeries_defconfig	2004-02-27 13:23:20.000000000 +0000
@@ -0,0 +1,798 @@
+#
+# Automatically generated make config: don't edit
+#
+CONFIG_64BIT=y
+CONFIG_MMU=y
+CONFIG_RWSEM_XCHGADD_ALGORITHM=y
+CONFIG_GENERIC_ISA_DMA=y
+CONFIG_HAVE_DEC_LOCK=y
+CONFIG_EARLY_PRINTK=y
+CONFIG_COMPAT=y
+CONFIG_FRAME_POINTER=y
+CONFIG_FORCE_MAX_ZONEORDER=13
+
+#
+# Code maturity level options
+#
+CONFIG_EXPERIMENTAL=y
+CONFIG_CLEAN_COMPILE=y
+CONFIG_STANDALONE=y
+
+#
+# General setup
+#
+CONFIG_SWAP=y
+CONFIG_SYSVIPC=y
+# CONFIG_BSD_PROCESS_ACCT is not set
+CONFIG_SYSCTL=y
+CONFIG_LOG_BUF_SHIFT=17
+CONFIG_HOTPLUG=y
+CONFIG_IKCONFIG=y
+CONFIG_IKCONFIG_PROC=y
+CONFIG_EMBEDDED=y
+CONFIG_KALLSYMS=y
+CONFIG_FUTEX=y
+CONFIG_EPOLL=y
+CONFIG_IOSCHED_NOOP=y
+CONFIG_IOSCHED_AS=y
+CONFIG_IOSCHED_DEADLINE=y
+# CONFIG_CC_OPTIMIZE_FOR_SIZE is not set
+
+#
+# Loadable module support
+#
+CONFIG_MODULES=y
+CONFIG_MODULE_UNLOAD=y
+# CONFIG_MODULE_FORCE_UNLOAD is not set
+CONFIG_OBSOLETE_MODPARM=y
+# CONFIG_MODVERSIONS is not set
+# CONFIG_KMOD is not set
+
+#
+# Platform support
+#
+CONFIG_PPC_ISERIES=y
+# CONFIG_PPC_PSERIES is not set
+CONFIG_PPC=y
+CONFIG_PPC64=y
+# CONFIG_POWER4_ONLY is not set
+CONFIG_SMP=y
+CONFIG_NR_CPUS=32
+CONFIG_MSCHUNKS=y
+CONFIG_LPARCFG=y
+
+#
+# General setup
+#
+CONFIG_PCI=y
+CONFIG_PCI_DOMAINS=y
+CONFIG_BINFMT_ELF=y
+# CONFIG_BINFMT_MISC is not set
+CONFIG_PCI_LEGACY_PROC=y
+CONFIG_PCI_NAMES=y
+
+#
+# PCMCIA/CardBus support
+#
+# CONFIG_PCMCIA is not set
+
+#
+# PCI Hotplug Support
+#
+# CONFIG_HOTPLUG_PCI is not set
+
+#
+# Device Drivers
+#
+
+#
+# Generic Driver Options
+#
+CONFIG_FW_LOADER=m
+
+#
+# Memory Technology Devices (MTD)
+#
+# CONFIG_MTD is not set
+
+#
+# Parallel port support
+#
+# CONFIG_PARPORT is not set
+
+#
+# Plug and Play support
+#
+
+#
+# Block devices
+#
+# CONFIG_BLK_DEV_FD is not set
+# CONFIG_BLK_CPQ_DA is not set
+# CONFIG_BLK_CPQ_CISS_DA is not set
+# CONFIG_BLK_DEV_DAC960 is not set
+# CONFIG_BLK_DEV_UMEM is not set
+CONFIG_BLK_DEV_LOOP=y
+# CONFIG_BLK_DEV_CRYPTOLOOP is not set
+CONFIG_BLK_DEV_NBD=m
+CONFIG_BLK_DEV_RAM=y
+CONFIG_BLK_DEV_RAM_SIZE=4096
+CONFIG_BLK_DEV_INITRD=y
+# CONFIG_DCSSBLK is not set
+
+#
+# ATA/ATAPI/MFM/RLL support
+#
+# CONFIG_IDE is not set
+
+#
+# SCSI device support
+#
+CONFIG_SCSI=y
+CONFIG_SCSI_PROC_FS=y
+
+#
+# SCSI support type (disk, tape, CD-ROM)
+#
+CONFIG_BLK_DEV_SD=y
+CONFIG_CHR_DEV_ST=y
+# CONFIG_CHR_DEV_OSST is not set
+CONFIG_BLK_DEV_SR=y
+CONFIG_BLK_DEV_SR_VENDOR=y
+CONFIG_CHR_DEV_SG=y
+
+#
+# Some SCSI devices (e.g. CD jukebox) support multiple LUNs
+#
+CONFIG_SCSI_MULTI_LUN=y
+CONFIG_SCSI_REPORT_LUNS=y
+CONFIG_SCSI_CONSTANTS=y
+# CONFIG_SCSI_LOGGING is not set
+
+#
+# SCSI low-level drivers
+#
+# CONFIG_BLK_DEV_3W_XXXX_RAID is not set
+# CONFIG_SCSI_ACARD is not set
+# CONFIG_SCSI_AACRAID is not set
+# CONFIG_SCSI_AIC7XXX is not set
+# CONFIG_SCSI_AIC7XXX_OLD is not set
+# CONFIG_SCSI_AIC79XX is not set
+# CONFIG_SCSI_ADVANSYS is not set
+# CONFIG_SCSI_MEGARAID is not set
+# CONFIG_SCSI_SATA is not set
+# CONFIG_SCSI_BUSLOGIC is not set
+# CONFIG_SCSI_CPQFCTS is not set
+# CONFIG_SCSI_DMX3191D is not set
+# CONFIG_SCSI_EATA is not set
+# CONFIG_SCSI_EATA_PIO is not set
+# CONFIG_SCSI_FUTURE_DOMAIN is not set
+# CONFIG_SCSI_GDTH is not set
+# CONFIG_SCSI_IPS is not set
+# CONFIG_SCSI_INIA100 is not set
+# CONFIG_SCSI_SYM53C8XX_2 is not set
+# CONFIG_SCSI_QLOGIC_ISP is not set
+# CONFIG_SCSI_QLOGIC_FC is not set
+# CONFIG_SCSI_QLOGIC_1280 is not set
+CONFIG_SCSI_QLA2XXX=y
+# CONFIG_SCSI_QLA21XX is not set
+# CONFIG_SCSI_QLA22XX is not set
+# CONFIG_SCSI_QLA2300 is not set
+# CONFIG_SCSI_QLA2322 is not set
+# CONFIG_SCSI_QLA6312 is not set
+# CONFIG_SCSI_QLA6322 is not set
+# CONFIG_SCSI_DC395x is not set
+# CONFIG_SCSI_DC390T is not set
+# CONFIG_SCSI_DEBUG is not set
+
+#
+# Multi-device support (RAID and LVM)
+#
+CONFIG_MD=y
+CONFIG_BLK_DEV_MD=y
+CONFIG_MD_LINEAR=y
+CONFIG_MD_RAID0=y
+CONFIG_MD_RAID1=y
+CONFIG_MD_RAID5=y
+CONFIG_MD_RAID6=y
+# CONFIG_MD_MULTIPATH is not set
+CONFIG_BLK_DEV_DM=y
+CONFIG_DM_IOCTL_V4=y
+CONFIG_DM_CRYPT=m
+
+#
+# Fusion MPT device support
+#
+# CONFIG_FUSION is not set
+
+#
+# IEEE 1394 (FireWire) support
+#
+# CONFIG_IEEE1394 is not set
+
+#
+# I2O device support
+#
+
+#
+# Macintosh device drivers
+#
+
+#
+# Networking support
+#
+CONFIG_NET=y
+
+#
+# Networking options
+#
+CONFIG_PACKET=y
+# CONFIG_PACKET_MMAP is not set
+# CONFIG_NETLINK_DEV is not set
+CONFIG_UNIX=y
+CONFIG_NET_KEY=m
+CONFIG_INET=y
+CONFIG_IP_MULTICAST=y
+# CONFIG_IP_ADVANCED_ROUTER is not set
+# CONFIG_IP_PNP is not set
+CONFIG_NET_IPIP=y
+# CONFIG_NET_IPGRE is not set
+# CONFIG_IP_MROUTE is not set
+# CONFIG_ARPD is not set
+CONFIG_INET_ECN=y
+CONFIG_SYN_COOKIES=y
+CONFIG_INET_AH=m
+CONFIG_INET_ESP=m
+CONFIG_INET_IPCOMP=m
+
+#
+# IP: Virtual Server Configuration
+#
+# CONFIG_IP_VS is not set
+# CONFIG_IPV6 is not set
+# CONFIG_DECNET is not set
+# CONFIG_BRIDGE is not set
+CONFIG_NETFILTER=y
+# CONFIG_NETFILTER_DEBUG is not set
+
+#
+# IP: Netfilter Configuration
+#
+CONFIG_IP_NF_CONNTRACK=m
+CONFIG_IP_NF_FTP=m
+CONFIG_IP_NF_IRC=m
+CONFIG_IP_NF_TFTP=m
+CONFIG_IP_NF_AMANDA=m
+CONFIG_IP_NF_QUEUE=m
+CONFIG_IP_NF_IPTABLES=m
+CONFIG_IP_NF_MATCH_LIMIT=m
+CONFIG_IP_NF_MATCH_IPRANGE=m
+CONFIG_IP_NF_MATCH_MAC=m
+CONFIG_IP_NF_MATCH_PKTTYPE=m
+CONFIG_IP_NF_MATCH_MARK=m
+CONFIG_IP_NF_MATCH_MULTIPORT=m
+CONFIG_IP_NF_MATCH_TOS=m
+CONFIG_IP_NF_MATCH_RECENT=m
+CONFIG_IP_NF_MATCH_ECN=m
+CONFIG_IP_NF_MATCH_DSCP=m
+CONFIG_IP_NF_MATCH_AH_ESP=m
+CONFIG_IP_NF_MATCH_LENGTH=m
+CONFIG_IP_NF_MATCH_TTL=m
+CONFIG_IP_NF_MATCH_TCPMSS=m
+CONFIG_IP_NF_MATCH_HELPER=m
+CONFIG_IP_NF_MATCH_STATE=m
+CONFIG_IP_NF_MATCH_CONNTRACK=m
+CONFIG_IP_NF_MATCH_OWNER=m
+CONFIG_IP_NF_FILTER=m
+CONFIG_IP_NF_TARGET_REJECT=m
+CONFIG_IP_NF_NAT=m
+CONFIG_IP_NF_NAT_NEEDED=y
+CONFIG_IP_NF_TARGET_MASQUERADE=m
+CONFIG_IP_NF_TARGET_REDIRECT=m
+CONFIG_IP_NF_TARGET_NETMAP=m
+CONFIG_IP_NF_TARGET_SAME=m
+# CONFIG_IP_NF_NAT_LOCAL is not set
+CONFIG_IP_NF_NAT_SNMP_BASIC=m
+CONFIG_IP_NF_NAT_IRC=m
+CONFIG_IP_NF_NAT_FTP=m
+CONFIG_IP_NF_NAT_TFTP=m
+CONFIG_IP_NF_NAT_AMANDA=m
+CONFIG_IP_NF_MANGLE=m
+CONFIG_IP_NF_TARGET_TOS=m
+CONFIG_IP_NF_TARGET_ECN=m
+CONFIG_IP_NF_TARGET_DSCP=m
+CONFIG_IP_NF_TARGET_MARK=m
+CONFIG_IP_NF_TARGET_CLASSIFY=m
+CONFIG_IP_NF_TARGET_LOG=m
+CONFIG_IP_NF_TARGET_ULOG=m
+CONFIG_IP_NF_TARGET_TCPMSS=m
+CONFIG_IP_NF_ARPTABLES=m
+CONFIG_IP_NF_ARPFILTER=m
+CONFIG_IP_NF_ARP_MANGLE=m
+CONFIG_IP_NF_COMPAT_IPCHAINS=m
+CONFIG_IP_NF_COMPAT_IPFWADM=m
+CONFIG_XFRM=y
+CONFIG_XFRM_USER=m
+
+#
+# SCTP Configuration (EXPERIMENTAL)
+#
+CONFIG_IPV6_SCTP__=y
+# CONFIG_IP_SCTP is not set
+# CONFIG_ATM is not set
+# CONFIG_VLAN_8021Q is not set
+CONFIG_LLC=y
+# CONFIG_LLC2 is not set
+# CONFIG_IPX is not set
+# CONFIG_ATALK is not set
+# CONFIG_X25 is not set
+# CONFIG_LAPB is not set
+# CONFIG_NET_DIVERT is not set
+# CONFIG_ECONET is not set
+# CONFIG_WAN_ROUTER is not set
+# CONFIG_NET_FASTROUTE is not set
+# CONFIG_NET_HW_FLOWCONTROL is not set
+
+#
+# QoS and/or fair queueing
+#
+# CONFIG_NET_SCHED is not set
+
+#
+# Network testing
+#
+# CONFIG_NET_PKTGEN is not set
+CONFIG_NETDEVICES=y
+
+#
+# ARCnet devices
+#
+# CONFIG_ARCNET is not set
+CONFIG_DUMMY=m
+CONFIG_BONDING=m
+# CONFIG_EQUALIZER is not set
+CONFIG_TUN=m
+
+#
+# Ethernet (10 or 100Mbit)
+#
+CONFIG_NET_ETHERNET=y
+CONFIG_MII=y
+# CONFIG_OAKNET is not set
+# CONFIG_HAPPYMEAL is not set
+# CONFIG_SUNGEM is not set
+# CONFIG_NET_VENDOR_3COM is not set
+
+#
+# Tulip family network device support
+#
+# CONFIG_NET_TULIP is not set
+# CONFIG_HP100 is not set
+CONFIG_NET_PCI=y
+CONFIG_PCNET32=y
+# CONFIG_AMD8111_ETH is not set
+# CONFIG_ADAPTEC_STARFIRE is not set
+# CONFIG_B44 is not set
+# CONFIG_FORCEDETH is not set
+# CONFIG_DGRS is not set
+# CONFIG_EEPRO100 is not set
+CONFIG_E100=y
+# CONFIG_E100_NAPI is not set
+# CONFIG_FEALNX is not set
+# CONFIG_NATSEMI is not set
+# CONFIG_NE2K_PCI is not set
+# CONFIG_8139CP is not set
+# CONFIG_8139TOO is not set
+# CONFIG_SIS900 is not set
+# CONFIG_EPIC100 is not set
+# CONFIG_SUNDANCE is not set
+# CONFIG_VIA_RHINE is not set
+
+#
+# Ethernet (1000 Mbit)
+#
+CONFIG_ACENIC=y
+CONFIG_ACENIC_OMIT_TIGON_I=y
+# CONFIG_DL2K is not set
+CONFIG_E1000=y
+# CONFIG_E1000_NAPI is not set
+# CONFIG_NS83820 is not set
+# CONFIG_HAMACHI is not set
+# CONFIG_YELLOWFIN is not set
+# CONFIG_R8169 is not set
+# CONFIG_SIS190 is not set
+# CONFIG_SK98LIN is not set
+# CONFIG_TIGON3 is not set
+
+#
+# Ethernet (10000 Mbit)
+#
+CONFIG_IXGB=m
+# CONFIG_IXGB_NAPI is not set
+# CONFIG_VETH is not set
+# CONFIG_FDDI is not set
+# CONFIG_HIPPI is not set
+CONFIG_PPP=m
+# CONFIG_PPP_MULTILINK is not set
+# CONFIG_PPP_FILTER is not set
+CONFIG_PPP_ASYNC=m
+CONFIG_PPP_SYNC_TTY=m
+CONFIG_PPP_DEFLATE=m
+CONFIG_PPP_BSDCOMP=m
+CONFIG_PPPOE=m
+# CONFIG_SLIP is not set
+
+#
+# Wireless LAN (non-hamradio)
+#
+# CONFIG_NET_RADIO is not set
+
+#
+# Token Ring devices
+#
+CONFIG_TR=y
+CONFIG_IBMOL=y
+# CONFIG_IBMLS is not set
+# CONFIG_3C359 is not set
+# CONFIG_TMS380TR is not set
+# CONFIG_NET_FC is not set
+# CONFIG_SHAPER is not set
+
+#
+# Wan interfaces
+#
+# CONFIG_WAN is not set
+
+#
+# Amateur Radio support
+#
+# CONFIG_HAMRADIO is not set
+
+#
+# IrDA (infrared) support
+#
+# CONFIG_IRDA is not set
+
+#
+# Bluetooth support
+#
+# CONFIG_BT is not set
+
+#
+# ISDN subsystem
+#
+# CONFIG_ISDN is not set
+
+#
+# Telephony Support
+#
+# CONFIG_PHONE is not set
+
+#
+# Input device support
+#
+CONFIG_INPUT=y
+
+#
+# Userland interfaces
+#
+# CONFIG_INPUT_MOUSEDEV is not set
+# CONFIG_INPUT_JOYDEV is not set
+# CONFIG_INPUT_TSDEV is not set
+# CONFIG_INPUT_EVDEV is not set
+# CONFIG_INPUT_EVBUG is not set
+
+#
+# Input I/O drivers
+#
+# CONFIG_GAMEPORT is not set
+CONFIG_SOUND_GAMEPORT=y
+CONFIG_SERIO=y
+# CONFIG_SERIO_I8042 is not set
+CONFIG_SERIO_SERPORT=y
+# CONFIG_SERIO_CT82C710 is not set
+# CONFIG_SERIO_PCIPS2 is not set
+
+#
+# Input Device Drivers
+#
+# CONFIG_INPUT_KEYBOARD is not set
+# CONFIG_INPUT_MOUSE is not set
+# CONFIG_INPUT_JOYSTICK is not set
+# CONFIG_INPUT_TOUCHSCREEN is not set
+# CONFIG_INPUT_MISC is not set
+
+#
+# Character devices
+#
+# CONFIG_VT is not set
+# CONFIG_SERIAL_NONSTANDARD is not set
+
+#
+# Serial drivers
+#
+# CONFIG_SERIAL_8250 is not set
+
+#
+# Non-8250 serial port support
+#
+CONFIG_UNIX98_PTYS=y
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
+
+#
+# Mice
+#
+# CONFIG_BUSMOUSE is not set
+# CONFIG_QIC02_TAPE is not set
+
+#
+# IPMI
+#
+# CONFIG_IPMI_HANDLER is not set
+
+#
+# Watchdog Cards
+#
+# CONFIG_WATCHDOG is not set
+# CONFIG_NVRAM is not set
+# CONFIG_RTC is not set
+# CONFIG_GEN_RTC is not set
+# CONFIG_DTLK is not set
+# CONFIG_R3964 is not set
+# CONFIG_APPLICOM is not set
+
+#
+# Ftape, the floppy tape device driver
+#
+# CONFIG_AGP is not set
+# CONFIG_DRM is not set
+CONFIG_RAW_DRIVER=y
+CONFIG_MAX_RAW_DEVS=256
+
+#
+# I2C support
+#
+# CONFIG_I2C is not set
+
+#
+# Multimedia devices
+#
+# CONFIG_VIDEO_DEV is not set
+
+#
+# Digital Video Broadcasting Devices
+#
+# CONFIG_DVB is not set
+
+#
+# Graphics support
+#
+# CONFIG_FB is not set
+
+#
+# Sound
+#
+# CONFIG_SOUND is not set
+
+#
+# USB support
+#
+# CONFIG_USB is not set
+
+#
+# USB Gadget Support
+#
+# CONFIG_USB_GADGET is not set
+
+#
+# File systems
+#
+CONFIG_EXT2_FS=y
+CONFIG_EXT2_FS_XATTR=y
+CONFIG_EXT2_FS_POSIX_ACL=y
+# CONFIG_EXT2_FS_SECURITY is not set
+CONFIG_EXT3_FS=y
+CONFIG_EXT3_FS_XATTR=y
+CONFIG_EXT3_FS_POSIX_ACL=y
+# CONFIG_EXT3_FS_SECURITY is not set
+CONFIG_JBD=y
+# CONFIG_JBD_DEBUG is not set
+CONFIG_FS_MBCACHE=y
+CONFIG_REISERFS_FS=y
+# CONFIG_REISERFS_CHECK is not set
+# CONFIG_REISERFS_PROC_INFO is not set
+CONFIG_JFS_FS=y
+CONFIG_JFS_POSIX_ACL=y
+# CONFIG_JFS_DEBUG is not set
+# CONFIG_JFS_STATISTICS is not set
+CONFIG_FS_POSIX_ACL=y
+CONFIG_XFS_FS=m
+# CONFIG_XFS_RT is not set
+# CONFIG_XFS_QUOTA is not set
+# CONFIG_XFS_SECURITY is not set
+CONFIG_XFS_POSIX_ACL=y
+# CONFIG_MINIX_FS is not set
+# CONFIG_ROMFS_FS is not set
+# CONFIG_QUOTA is not set
+CONFIG_AUTOFS_FS=m
+# CONFIG_AUTOFS4_FS is not set
+
+#
+# CD-ROM/DVD Filesystems
+#
+CONFIG_ISO9660_FS=y
+# CONFIG_JOLIET is not set
+# CONFIG_ZISOFS is not set
+CONFIG_UDF_FS=m
+
+#
+# DOS/FAT/NT Filesystems
+#
+CONFIG_FAT_FS=y
+CONFIG_MSDOS_FS=y
+CONFIG_VFAT_FS=y
+# CONFIG_NTFS_FS is not set
+
+#
+# Pseudo filesystems
+#
+CONFIG_PROC_FS=y
+CONFIG_PROC_KCORE=y
+# CONFIG_DEVFS_FS is not set
+CONFIG_DEVPTS_FS_XATTR=y
+# CONFIG_DEVPTS_FS_SECURITY is not set
+CONFIG_TMPFS=y
+# CONFIG_HUGETLBFS is not set
+# CONFIG_HUGETLB_PAGE is not set
+CONFIG_RAMFS=y
+
+#
+# Miscellaneous filesystems
+#
+# CONFIG_ADFS_FS is not set
+# CONFIG_AFFS_FS is not set
+# CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
+# CONFIG_BEFS_FS is not set
+# CONFIG_BFS_FS is not set
+# CONFIG_EFS_FS is not set
+CONFIG_CRAMFS=y
+# CONFIG_VXFS_FS is not set
+# CONFIG_HPFS_FS is not set
+# CONFIG_QNX4FS_FS is not set
+# CONFIG_SYSV_FS is not set
+# CONFIG_UFS_FS is not set
+
+#
+# Network File Systems
+#
+CONFIG_NFS_FS=y
+CONFIG_NFS_V3=y
+CONFIG_NFS_V4=y
+# CONFIG_NFS_DIRECTIO is not set
+CONFIG_NFSD=y
+CONFIG_NFSD_V3=y
+CONFIG_NFSD_V4=y
+CONFIG_NFSD_TCP=y
+CONFIG_LOCKD=y
+CONFIG_LOCKD_V4=y
+CONFIG_EXPORTFS=y
+CONFIG_SUNRPC=y
+CONFIG_SUNRPC_GSS=m
+CONFIG_RPCSEC_GSS_KRB5=m
+# CONFIG_SMB_FS is not set
+CONFIG_CIFS=m
+# CONFIG_NCP_FS is not set
+# CONFIG_CODA_FS is not set
+# CONFIG_AFS_FS is not set
+
+#
+# Partition Types
+#
+# CONFIG_PARTITION_ADVANCED is not set
+CONFIG_MSDOS_PARTITION=y
+
+#
+# Native Language Support
+#
+CONFIG_NLS=y
+CONFIG_NLS_DEFAULT="iso8859-1"
+# CONFIG_NLS_CODEPAGE_437 is not set
+# CONFIG_NLS_CODEPAGE_737 is not set
+# CONFIG_NLS_CODEPAGE_775 is not set
+# CONFIG_NLS_CODEPAGE_850 is not set
+# CONFIG_NLS_CODEPAGE_852 is not set
+# CONFIG_NLS_CODEPAGE_855 is not set
+# CONFIG_NLS_CODEPAGE_857 is not set
+# CONFIG_NLS_CODEPAGE_860 is not set
+# CONFIG_NLS_CODEPAGE_861 is not set
+# CONFIG_NLS_CODEPAGE_862 is not set
+# CONFIG_NLS_CODEPAGE_863 is not set
+# CONFIG_NLS_CODEPAGE_864 is not set
+# CONFIG_NLS_CODEPAGE_865 is not set
+# CONFIG_NLS_CODEPAGE_866 is not set
+# CONFIG_NLS_CODEPAGE_869 is not set
+# CONFIG_NLS_CODEPAGE_936 is not set
+# CONFIG_NLS_CODEPAGE_950 is not set
+# CONFIG_NLS_CODEPAGE_932 is not set
+# CONFIG_NLS_CODEPAGE_949 is not set
+# CONFIG_NLS_CODEPAGE_874 is not set
+# CONFIG_NLS_ISO8859_8 is not set
+# CONFIG_NLS_CODEPAGE_1250 is not set
+# CONFIG_NLS_CODEPAGE_1251 is not set
+# CONFIG_NLS_ISO8859_1 is not set
+# CONFIG_NLS_ISO8859_2 is not set
+# CONFIG_NLS_ISO8859_3 is not set
+# CONFIG_NLS_ISO8859_4 is not set
+# CONFIG_NLS_ISO8859_5 is not set
+# CONFIG_NLS_ISO8859_6 is not set
+# CONFIG_NLS_ISO8859_7 is not set
+# CONFIG_NLS_ISO8859_9 is not set
+# CONFIG_NLS_ISO8859_13 is not set
+# CONFIG_NLS_ISO8859_14 is not set
+# CONFIG_NLS_ISO8859_15 is not set
+# CONFIG_NLS_KOI8_R is not set
+# CONFIG_NLS_KOI8_U is not set
+# CONFIG_NLS_UTF8 is not set
+
+#
+# iSeries device drivers
+#
+CONFIG_VIOCONS=y
+CONFIG_VIODASD=y
+CONFIG_VIOCD=y
+# CONFIG_VIOCD_AZTECH is not set
+# CONFIG_VIOTAPE is not set
+CONFIG_VIOPATH=y
+
+#
+# Profiling support
+#
+CONFIG_PROFILING=y
+CONFIG_OPROFILE=y
+
+#
+# Kernel hacking
+#
+CONFIG_DEBUG_KERNEL=y
+CONFIG_DEBUG_STACKOVERFLOW=y
+CONFIG_DEBUG_STACK_USAGE=y
+# CONFIG_DEBUG_SLAB is not set
+CONFIG_MAGIC_SYSRQ=y
+# CONFIG_DEBUGGER is not set
+# CONFIG_PPCDBG is not set
+# CONFIG_DEBUG_INFO is not set
+
+#
+# Security options
+#
+# CONFIG_SECURITY is not set
+
+#
+# Cryptographic options
+#
+CONFIG_CRYPTO=y
+CONFIG_CRYPTO_HMAC=y
+CONFIG_CRYPTO_NULL=m
+CONFIG_CRYPTO_MD4=m
+CONFIG_CRYPTO_MD5=m
+CONFIG_CRYPTO_SHA1=m
+CONFIG_CRYPTO_SHA256=m
+CONFIG_CRYPTO_SHA512=m
+CONFIG_CRYPTO_DES=m
+CONFIG_CRYPTO_BLOWFISH=m
+CONFIG_CRYPTO_TWOFISH=m
+CONFIG_CRYPTO_SERPENT=m
+CONFIG_CRYPTO_AES=m
+CONFIG_CRYPTO_CAST5=m
+CONFIG_CRYPTO_CAST6=m
+CONFIG_CRYPTO_DEFLATE=m
+CONFIG_CRYPTO_TEST=m
+
+#
+# Library routines
+#
+CONFIG_CRC32=y
+CONFIG_ZLIB_INFLATE=y
+CONFIG_ZLIB_DEFLATE=m
diff -purN linux-post-2.6.3-20040227/arch/ppc64/configs/pSeries_defconfig linux-post-2.6.4rc1-20040228/arch/ppc64/configs/pSeries_defconfig
--- linux-post-2.6.3-20040227/arch/ppc64/configs/pSeries_defconfig	2004-02-12 05:17:38.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/configs/pSeries_defconfig	2004-02-27 13:20:30.000000000 +0000
@@ -25,7 +25,8 @@ CONFIG_SWAP=y
 CONFIG_SYSVIPC=y
 # CONFIG_BSD_PROCESS_ACCT is not set
 CONFIG_SYSCTL=y
-CONFIG_LOG_BUF_SHIFT=16
+CONFIG_LOG_BUF_SHIFT=17
+CONFIG_HOTPLUG=y
 CONFIG_IKCONFIG=y
 CONFIG_IKCONFIG_PROC=y
 # CONFIG_EMBEDDED is not set
@@ -78,7 +79,22 @@ CONFIG_BINFMT_ELF=y
 # CONFIG_BINFMT_MISC is not set
 CONFIG_PCI_LEGACY_PROC=y
 CONFIG_PCI_NAMES=y
-# CONFIG_HOTPLUG is not set
+
+#
+# PCMCIA/CardBus support
+#
+# CONFIG_PCMCIA is not set
+
+#
+# PCI Hotplug Support
+#
+CONFIG_HOTPLUG_PCI=m
+# CONFIG_HOTPLUG_PCI_FAKE is not set
+# CONFIG_HOTPLUG_PCI_CPCI is not set
+# CONFIG_HOTPLUG_PCI_PCIE is not set
+# CONFIG_HOTPLUG_PCI_SHPC is not set
+CONFIG_HOTPLUG_PCI_RPA=m
+CONFIG_HOTPLUG_PCI_RPA_DLPAR=m
 CONFIG_PROC_DEVICETREE=y
 # CONFIG_CMDLINE_BOOL is not set
 
@@ -89,6 +105,7 @@ CONFIG_PROC_DEVICETREE=y
 #
 # Generic Driver Options
 #
+CONFIG_FW_LOADER=m
 
 #
 # Memory Technology Devices (MTD)
@@ -118,11 +135,67 @@ CONFIG_BLK_DEV_NBD=m
 CONFIG_BLK_DEV_RAM=y
 CONFIG_BLK_DEV_RAM_SIZE=4096
 CONFIG_BLK_DEV_INITRD=y
+# CONFIG_DCSSBLK is not set
 
 #
 # ATA/ATAPI/MFM/RLL support
 #
-# CONFIG_IDE is not set
+CONFIG_IDE=y
+CONFIG_BLK_DEV_IDE=y
+
+#
+# Please see Documentation/ide.txt for help/info on IDE drives
+#
+CONFIG_BLK_DEV_IDEDISK=y
+# CONFIG_IDEDISK_MULTI_MODE is not set
+# CONFIG_IDEDISK_STROKE is not set
+CONFIG_BLK_DEV_IDECD=y
+# CONFIG_BLK_DEV_IDETAPE is not set
+# CONFIG_BLK_DEV_IDEFLOPPY is not set
+# CONFIG_BLK_DEV_IDESCSI is not set
+# CONFIG_IDE_TASK_IOCTL is not set
+# CONFIG_IDE_TASKFILE_IO is not set
+
+#
+# IDE chipset support/bugfixes
+#
+CONFIG_IDE_GENERIC=y
+CONFIG_BLK_DEV_IDEPCI=y
+CONFIG_IDEPCI_SHARE_IRQ=y
+# CONFIG_BLK_DEV_OFFBOARD is not set
+CONFIG_BLK_DEV_GENERIC=y
+# CONFIG_BLK_DEV_OPTI621 is not set
+CONFIG_BLK_DEV_SL82C105=y
+CONFIG_BLK_DEV_IDEDMA_PCI=y
+# CONFIG_BLK_DEV_IDEDMA_FORCED is not set
+CONFIG_IDEDMA_PCI_AUTO=y
+# CONFIG_IDEDMA_ONLYDISK is not set
+CONFIG_BLK_DEV_ADMA=y
+# CONFIG_BLK_DEV_AEC62XX is not set
+# CONFIG_BLK_DEV_ALI15X3 is not set
+# CONFIG_BLK_DEV_AMD74XX is not set
+# CONFIG_BLK_DEV_CMD64X is not set
+# CONFIG_BLK_DEV_TRIFLEX is not set
+# CONFIG_BLK_DEV_CY82C693 is not set
+# CONFIG_BLK_DEV_CS5520 is not set
+# CONFIG_BLK_DEV_CS5530 is not set
+# CONFIG_BLK_DEV_HPT34X is not set
+# CONFIG_BLK_DEV_HPT366 is not set
+# CONFIG_BLK_DEV_SC1200 is not set
+# CONFIG_BLK_DEV_PIIX is not set
+# CONFIG_BLK_DEV_NS87415 is not set
+# CONFIG_BLK_DEV_PDC202XX_OLD is not set
+# CONFIG_BLK_DEV_PDC202XX_NEW is not set
+# CONFIG_BLK_DEV_SVWKS is not set
+# CONFIG_BLK_DEV_SIIMAGE is not set
+# CONFIG_BLK_DEV_SLC90E66 is not set
+# CONFIG_BLK_DEV_TRM290 is not set
+# CONFIG_BLK_DEV_VIA82CXXX is not set
+CONFIG_BLK_DEV_IDEDMA=y
+# CONFIG_IDEDMA_IVB is not set
+CONFIG_IDEDMA_AUTO=y
+# CONFIG_DMA_NONPCI is not set
+# CONFIG_BLK_DEV_HD is not set
 
 #
 # SCSI device support
@@ -178,12 +251,12 @@ CONFIG_SCSI_SYM53C8XX_MAX_TAGS=64
 # CONFIG_SCSI_QLOGIC_FC is not set
 # CONFIG_SCSI_QLOGIC_1280 is not set
 CONFIG_SCSI_QLA2XXX=y
-CONFIG_SCSI_QLA21XX=y
-CONFIG_SCSI_QLA22XX=y
-# CONFIG_SCSI_QLA2300 is not set
-# CONFIG_SCSI_QLA2322 is not set
-# CONFIG_SCSI_QLA6312 is not set
-# CONFIG_SCSI_QLA6322 is not set
+CONFIG_SCSI_QLA21XX=m
+CONFIG_SCSI_QLA22XX=m
+CONFIG_SCSI_QLA2300=m
+CONFIG_SCSI_QLA2322=m
+CONFIG_SCSI_QLA6312=m
+CONFIG_SCSI_QLA6322=m
 # CONFIG_SCSI_DC395x is not set
 # CONFIG_SCSI_DC390T is not set
 # CONFIG_SCSI_DEBUG is not set
@@ -197,10 +270,11 @@ CONFIG_MD_LINEAR=y
 CONFIG_MD_RAID0=y
 CONFIG_MD_RAID1=y
 CONFIG_MD_RAID5=y
-# CONFIG_MD_RAID6 is not set
+CONFIG_MD_RAID6=y
 # CONFIG_MD_MULTIPATH is not set
 CONFIG_BLK_DEV_DM=y
 CONFIG_DM_IOCTL_V4=y
+CONFIG_DM_CRYPT=m
 
 #
 # Fusion MPT device support
@@ -208,7 +282,7 @@ CONFIG_DM_IOCTL_V4=y
 # CONFIG_FUSION is not set
 
 #
-# IEEE 1394 (FireWire) support (EXPERIMENTAL)
+# IEEE 1394 (FireWire) support
 #
 # CONFIG_IEEE1394 is not set
 
@@ -246,10 +320,73 @@ CONFIG_SYN_COOKIES=y
 CONFIG_INET_AH=m
 CONFIG_INET_ESP=m
 CONFIG_INET_IPCOMP=m
+
+#
+# IP: Virtual Server Configuration
+#
+# CONFIG_IP_VS is not set
 # CONFIG_IPV6 is not set
 # CONFIG_DECNET is not set
 # CONFIG_BRIDGE is not set
-# CONFIG_NETFILTER is not set
+CONFIG_NETFILTER=y
+# CONFIG_NETFILTER_DEBUG is not set
+
+#
+# IP: Netfilter Configuration
+#
+CONFIG_IP_NF_CONNTRACK=m
+CONFIG_IP_NF_FTP=m
+CONFIG_IP_NF_IRC=m
+CONFIG_IP_NF_TFTP=m
+CONFIG_IP_NF_AMANDA=m
+CONFIG_IP_NF_QUEUE=m
+CONFIG_IP_NF_IPTABLES=m
+CONFIG_IP_NF_MATCH_LIMIT=m
+CONFIG_IP_NF_MATCH_IPRANGE=m
+CONFIG_IP_NF_MATCH_MAC=m
+CONFIG_IP_NF_MATCH_PKTTYPE=m
+CONFIG_IP_NF_MATCH_MARK=m
+CONFIG_IP_NF_MATCH_MULTIPORT=m
+CONFIG_IP_NF_MATCH_TOS=m
+CONFIG_IP_NF_MATCH_RECENT=m
+CONFIG_IP_NF_MATCH_ECN=m
+CONFIG_IP_NF_MATCH_DSCP=m
+CONFIG_IP_NF_MATCH_AH_ESP=m
+CONFIG_IP_NF_MATCH_LENGTH=m
+CONFIG_IP_NF_MATCH_TTL=m
+CONFIG_IP_NF_MATCH_TCPMSS=m
+CONFIG_IP_NF_MATCH_HELPER=m
+CONFIG_IP_NF_MATCH_STATE=m
+CONFIG_IP_NF_MATCH_CONNTRACK=m
+CONFIG_IP_NF_MATCH_OWNER=m
+CONFIG_IP_NF_FILTER=m
+CONFIG_IP_NF_TARGET_REJECT=m
+CONFIG_IP_NF_NAT=m
+CONFIG_IP_NF_NAT_NEEDED=y
+CONFIG_IP_NF_TARGET_MASQUERADE=m
+CONFIG_IP_NF_TARGET_REDIRECT=m
+CONFIG_IP_NF_TARGET_NETMAP=m
+CONFIG_IP_NF_TARGET_SAME=m
+# CONFIG_IP_NF_NAT_LOCAL is not set
+CONFIG_IP_NF_NAT_SNMP_BASIC=m
+CONFIG_IP_NF_NAT_IRC=m
+CONFIG_IP_NF_NAT_FTP=m
+CONFIG_IP_NF_NAT_TFTP=m
+CONFIG_IP_NF_NAT_AMANDA=m
+CONFIG_IP_NF_MANGLE=m
+CONFIG_IP_NF_TARGET_TOS=m
+CONFIG_IP_NF_TARGET_ECN=m
+CONFIG_IP_NF_TARGET_DSCP=m
+CONFIG_IP_NF_TARGET_MARK=m
+CONFIG_IP_NF_TARGET_CLASSIFY=m
+CONFIG_IP_NF_TARGET_LOG=m
+CONFIG_IP_NF_TARGET_ULOG=m
+CONFIG_IP_NF_TARGET_TCPMSS=m
+CONFIG_IP_NF_ARPTABLES=m
+CONFIG_IP_NF_ARPFILTER=m
+CONFIG_IP_NF_ARP_MANGLE=m
+CONFIG_IP_NF_COMPAT_IPCHAINS=m
+CONFIG_IP_NF_COMPAT_IPFWADM=m
 CONFIG_XFRM=y
 CONFIG_XFRM_USER=m
 
@@ -260,6 +397,7 @@ CONFIG_IPV6_SCTP__=y
 # CONFIG_IP_SCTP is not set
 # CONFIG_ATM is not set
 # CONFIG_VLAN_8021Q is not set
+CONFIG_LLC=y
 # CONFIG_LLC2 is not set
 # CONFIG_IPX is not set
 # CONFIG_ATALK is not set
@@ -317,6 +455,7 @@ CONFIG_PCNET32=y
 # CONFIG_DGRS is not set
 # CONFIG_EEPRO100 is not set
 CONFIG_E100=y
+# CONFIG_E100_NAPI is not set
 # CONFIG_FEALNX is not set
 # CONFIG_NATSEMI is not set
 # CONFIG_NE2K_PCI is not set
@@ -341,14 +480,16 @@ CONFIG_E1000=y
 # CONFIG_R8169 is not set
 # CONFIG_SIS190 is not set
 # CONFIG_SK98LIN is not set
-# CONFIG_TIGON3 is not set
+CONFIG_TIGON3=y
 
 #
 # Ethernet (10000 Mbit)
 #
-# CONFIG_IXGB is not set
+CONFIG_IXGB=m
+# CONFIG_IXGB_NAPI is not set
 # CONFIG_FDDI is not set
 # CONFIG_HIPPI is not set
+CONFIG_IBMVETH=m
 CONFIG_PPP=m
 # CONFIG_PPP_MULTILINK is not set
 # CONFIG_PPP_FILTER is not set
@@ -367,7 +508,11 @@ CONFIG_PPPOE=m
 #
 # Token Ring devices
 #
-# CONFIG_TR is not set
+CONFIG_TR=y
+CONFIG_IBMOL=y
+# CONFIG_IBMLS is not set
+# CONFIG_3C359 is not set
+# CONFIG_TMS380TR is not set
 # CONFIG_NET_FC is not set
 # CONFIG_SHAPER is not set
 
@@ -394,7 +539,7 @@ CONFIG_PPPOE=m
 #
 # ISDN subsystem
 #
-# CONFIG_ISDN_BOOL is not set
+# CONFIG_ISDN is not set
 
 #
 # Telephony Support
@@ -469,7 +614,8 @@ CONFIG_SERIAL_CORE=y
 CONFIG_SERIAL_CORE_CONSOLE=y
 # CONFIG_SERIAL_PMACZILOG is not set
 CONFIG_UNIX98_PTYS=y
-CONFIG_UNIX98_PTY_COUNT=256
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
 CONFIG_HVC_CONSOLE=y
 
 #
@@ -505,7 +651,60 @@ CONFIG_MAX_RAW_DEVS=256
 #
 # I2C support
 #
-# CONFIG_I2C is not set
+CONFIG_I2C=y
+# CONFIG_I2C_CHARDEV is not set
+
+#
+# I2C Algorithms
+#
+CONFIG_I2C_ALGOBIT=y
+# CONFIG_I2C_ALGOPCF is not set
+
+#
+# I2C Hardware Bus support
+#
+# CONFIG_I2C_ALI1535 is not set
+# CONFIG_I2C_ALI15X3 is not set
+# CONFIG_I2C_AMD756 is not set
+# CONFIG_I2C_AMD8111 is not set
+# CONFIG_I2C_ELV is not set
+# CONFIG_I2C_I801 is not set
+# CONFIG_I2C_I810 is not set
+# CONFIG_I2C_ISA is not set
+# CONFIG_I2C_NFORCE2 is not set
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_PROSAVAGE is not set
+# CONFIG_I2C_SAVAGE4 is not set
+# CONFIG_SCx200_ACB is not set
+# CONFIG_I2C_SIS5595 is not set
+# CONFIG_I2C_SIS630 is not set
+# CONFIG_I2C_SIS96X is not set
+# CONFIG_I2C_VELLEMAN is not set
+# CONFIG_I2C_VIA is not set
+# CONFIG_I2C_VIAPRO is not set
+# CONFIG_I2C_VOODOO3 is not set
+
+#
+# I2C Hardware Sensors Chip support
+#
+# CONFIG_I2C_SENSOR is not set
+# CONFIG_SENSORS_ADM1021 is not set
+# CONFIG_SENSORS_ASB100 is not set
+# CONFIG_SENSORS_EEPROM is not set
+# CONFIG_SENSORS_FSCHER is not set
+# CONFIG_SENSORS_GL518SM is not set
+# CONFIG_SENSORS_IT87 is not set
+# CONFIG_SENSORS_LM75 is not set
+# CONFIG_SENSORS_LM78 is not set
+# CONFIG_SENSORS_LM83 is not set
+# CONFIG_SENSORS_LM85 is not set
+# CONFIG_SENSORS_LM90 is not set
+# CONFIG_SENSORS_VIA686A is not set
+# CONFIG_SENSORS_W83781D is not set
+# CONFIG_SENSORS_W83L785TS is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+# CONFIG_I2C_DEBUG_CHIP is not set
 
 #
 # Multimedia devices
@@ -533,8 +732,12 @@ CONFIG_FB_MATROX_MILLENIUM=y
 CONFIG_FB_MATROX_MYSTIQUE=y
 CONFIG_FB_MATROX_G450=y
 CONFIG_FB_MATROX_G100=y
+# CONFIG_FB_MATROX_I2C is not set
 CONFIG_FB_MATROX_MULTIHEAD=y
-# CONFIG_FB_RADEON is not set
+# CONFIG_FB_RADEON_OLD is not set
+CONFIG_FB_RADEON=y
+CONFIG_FB_RADEON_I2C=y
+# CONFIG_FB_RADEON_DEBUG is not set
 # CONFIG_FB_ATY128 is not set
 # CONFIG_FB_ATY is not set
 # CONFIG_FB_SIS is not set
@@ -573,7 +776,106 @@ CONFIG_LOGO_LINUX_CLUT224=y
 #
 # USB support
 #
-# CONFIG_USB is not set
+CONFIG_USB=m
+# CONFIG_USB_DEBUG is not set
+
+#
+# Miscellaneous USB options
+#
+CONFIG_USB_DEVICEFS=y
+# CONFIG_USB_BANDWIDTH is not set
+# CONFIG_USB_DYNAMIC_MINORS is not set
+
+#
+# USB Host Controller Drivers
+#
+CONFIG_USB_EHCI_HCD=m
+CONFIG_USB_OHCI_HCD=m
+# CONFIG_USB_UHCI_HCD is not set
+
+#
+# USB Device Class drivers
+#
+# CONFIG_USB_BLUETOOTH_TTY is not set
+# CONFIG_USB_ACM is not set
+# CONFIG_USB_PRINTER is not set
+CONFIG_USB_STORAGE=m
+# CONFIG_USB_STORAGE_DEBUG is not set
+# CONFIG_USB_STORAGE_DATAFAB is not set
+# CONFIG_USB_STORAGE_FREECOM is not set
+# CONFIG_USB_STORAGE_ISD200 is not set
+# CONFIG_USB_STORAGE_DPCM is not set
+# CONFIG_USB_STORAGE_HP8200e is not set
+# CONFIG_USB_STORAGE_SDDR09 is not set
+# CONFIG_USB_STORAGE_SDDR55 is not set
+# CONFIG_USB_STORAGE_JUMPSHOT is not set
+
+#
+# USB Human Interface Devices (HID)
+#
+CONFIG_USB_HID=m
+CONFIG_USB_HIDINPUT=y
+# CONFIG_HID_FF is not set
+CONFIG_USB_HIDDEV=y
+
+#
+# USB HID Boot Protocol drivers
+#
+# CONFIG_USB_KBD is not set
+# CONFIG_USB_MOUSE is not set
+# CONFIG_USB_AIPTEK is not set
+# CONFIG_USB_WACOM is not set
+# CONFIG_USB_KBTAB is not set
+# CONFIG_USB_POWERMATE is not set
+# CONFIG_USB_XPAD is not set
+
+#
+# USB Imaging devices
+#
+# CONFIG_USB_MDC800 is not set
+# CONFIG_USB_MICROTEK is not set
+# CONFIG_USB_HPUSBSCSI is not set
+
+#
+# USB Multimedia devices
+#
+# CONFIG_USB_DABUSB is not set
+
+#
+# Video4Linux support is needed for USB Multimedia device support
+#
+
+#
+# USB Network adaptors
+#
+# CONFIG_USB_CATC is not set
+# CONFIG_USB_KAWETH is not set
+# CONFIG_USB_PEGASUS is not set
+# CONFIG_USB_RTL8150 is not set
+# CONFIG_USB_USBNET is not set
+
+#
+# USB port drivers
+#
+
+#
+# USB Serial Converter support
+#
+# CONFIG_USB_SERIAL is not set
+
+#
+# USB Miscellaneous drivers
+#
+# CONFIG_USB_EMI62 is not set
+# CONFIG_USB_EMI26 is not set
+# CONFIG_USB_TIGL is not set
+# CONFIG_USB_AUERSWALD is not set
+# CONFIG_USB_RIO500 is not set
+# CONFIG_USB_LEGOTOWER is not set
+# CONFIG_USB_BRLVGER is not set
+# CONFIG_USB_LCD is not set
+# CONFIG_USB_LED is not set
+# CONFIG_USB_TEST is not set
 
 #
 # USB Gadget Support
@@ -635,7 +937,6 @@ CONFIG_VFAT_FS=y
 CONFIG_PROC_FS=y
 CONFIG_PROC_KCORE=y
 # CONFIG_DEVFS_FS is not set
-CONFIG_DEVPTS_FS=y
 CONFIG_DEVPTS_FS_XATTR=y
 # CONFIG_DEVPTS_FS_SECURITY is not set
 CONFIG_TMPFS=y
@@ -649,6 +950,7 @@ CONFIG_RAMFS=y
 # CONFIG_ADFS_FS is not set
 # CONFIG_AFFS_FS is not set
 # CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
 # CONFIG_BEFS_FS is not set
 # CONFIG_BFS_FS is not set
 # CONFIG_EFS_FS is not set
@@ -680,7 +982,6 @@ CONFIG_RPCSEC_GSS_KRB5=m
 CONFIG_CIFS=m
 # CONFIG_NCP_FS is not set
 # CONFIG_CODA_FS is not set
-# CONFIG_INTERMEZZO_FS is not set
 # CONFIG_AFS_FS is not set
 
 #
@@ -742,8 +1043,11 @@ CONFIG_OPROFILE=y
 # Kernel hacking
 #
 CONFIG_DEBUG_KERNEL=y
+CONFIG_DEBUG_STACKOVERFLOW=y
+CONFIG_DEBUG_STACK_USAGE=y
 # CONFIG_DEBUG_SLAB is not set
 CONFIG_MAGIC_SYSRQ=y
+CONFIG_DEBUGGER=y
 CONFIG_XMON=y
 CONFIG_XMON_DEFAULT=y
 # CONFIG_PPCDBG is not set
diff -purN linux-post-2.6.3-20040227/arch/ppc64/defconfig linux-post-2.6.4rc1-20040228/arch/ppc64/defconfig
--- linux-post-2.6.3-20040227/arch/ppc64/defconfig	2004-01-31 08:15:27.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/defconfig	2004-02-27 13:20:30.000000000 +0000
@@ -25,7 +25,8 @@ CONFIG_SWAP=y
 CONFIG_SYSVIPC=y
 # CONFIG_BSD_PROCESS_ACCT is not set
 CONFIG_SYSCTL=y
-CONFIG_LOG_BUF_SHIFT=16
+CONFIG_LOG_BUF_SHIFT=17
+CONFIG_HOTPLUG=y
 CONFIG_IKCONFIG=y
 CONFIG_IKCONFIG_PROC=y
 # CONFIG_EMBEDDED is not set
@@ -54,7 +55,10 @@ CONFIG_OBSOLETE_MODPARM=y
 CONFIG_PPC_PSERIES=y
 CONFIG_PPC=y
 CONFIG_PPC64=y
+CONFIG_PPC_OF=y
 CONFIG_ALTIVEC=y
+# CONFIG_PPC_PMAC is not set
+# CONFIG_BOOTX_TEXT is not set
 # CONFIG_POWER4_ONLY is not set
 CONFIG_SMP=y
 CONFIG_IRQ_ALL_CPUS=y
@@ -75,7 +79,22 @@ CONFIG_BINFMT_ELF=y
 # CONFIG_BINFMT_MISC is not set
 CONFIG_PCI_LEGACY_PROC=y
 CONFIG_PCI_NAMES=y
-# CONFIG_HOTPLUG is not set
+
+#
+# PCMCIA/CardBus support
+#
+# CONFIG_PCMCIA is not set
+
+#
+# PCI Hotplug Support
+#
+CONFIG_HOTPLUG_PCI=m
+# CONFIG_HOTPLUG_PCI_FAKE is not set
+# CONFIG_HOTPLUG_PCI_CPCI is not set
+# CONFIG_HOTPLUG_PCI_PCIE is not set
+# CONFIG_HOTPLUG_PCI_SHPC is not set
+CONFIG_HOTPLUG_PCI_RPA=m
+CONFIG_HOTPLUG_PCI_RPA_DLPAR=m
 CONFIG_PROC_DEVICETREE=y
 # CONFIG_CMDLINE_BOOL is not set
 
@@ -86,6 +105,7 @@ CONFIG_PROC_DEVICETREE=y
 #
 # Generic Driver Options
 #
+CONFIG_FW_LOADER=m
 
 #
 # Memory Technology Devices (MTD)
@@ -100,7 +120,6 @@ CONFIG_PROC_DEVICETREE=y
 #
 # Plug and Play support
 #
-# CONFIG_PNP is not set
 
 #
 # Block devices
@@ -116,11 +135,67 @@ CONFIG_BLK_DEV_NBD=m
 CONFIG_BLK_DEV_RAM=y
 CONFIG_BLK_DEV_RAM_SIZE=4096
 CONFIG_BLK_DEV_INITRD=y
+# CONFIG_DCSSBLK is not set
 
 #
 # ATA/ATAPI/MFM/RLL support
 #
-# CONFIG_IDE is not set
+CONFIG_IDE=y
+CONFIG_BLK_DEV_IDE=y
+
+#
+# Please see Documentation/ide.txt for help/info on IDE drives
+#
+CONFIG_BLK_DEV_IDEDISK=y
+# CONFIG_IDEDISK_MULTI_MODE is not set
+# CONFIG_IDEDISK_STROKE is not set
+CONFIG_BLK_DEV_IDECD=y
+# CONFIG_BLK_DEV_IDETAPE is not set
+# CONFIG_BLK_DEV_IDEFLOPPY is not set
+# CONFIG_BLK_DEV_IDESCSI is not set
+# CONFIG_IDE_TASK_IOCTL is not set
+# CONFIG_IDE_TASKFILE_IO is not set
+
+#
+# IDE chipset support/bugfixes
+#
+CONFIG_IDE_GENERIC=y
+CONFIG_BLK_DEV_IDEPCI=y
+CONFIG_IDEPCI_SHARE_IRQ=y
+# CONFIG_BLK_DEV_OFFBOARD is not set
+CONFIG_BLK_DEV_GENERIC=y
+# CONFIG_BLK_DEV_OPTI621 is not set
+CONFIG_BLK_DEV_SL82C105=y
+CONFIG_BLK_DEV_IDEDMA_PCI=y
+# CONFIG_BLK_DEV_IDEDMA_FORCED is not set
+CONFIG_IDEDMA_PCI_AUTO=y
+# CONFIG_IDEDMA_ONLYDISK is not set
+CONFIG_BLK_DEV_ADMA=y
+# CONFIG_BLK_DEV_AEC62XX is not set
+# CONFIG_BLK_DEV_ALI15X3 is not set
+# CONFIG_BLK_DEV_AMD74XX is not set
+# CONFIG_BLK_DEV_CMD64X is not set
+# CONFIG_BLK_DEV_TRIFLEX is not set
+# CONFIG_BLK_DEV_CY82C693 is not set
+# CONFIG_BLK_DEV_CS5520 is not set
+# CONFIG_BLK_DEV_CS5530 is not set
+# CONFIG_BLK_DEV_HPT34X is not set
+# CONFIG_BLK_DEV_HPT366 is not set
+# CONFIG_BLK_DEV_SC1200 is not set
+# CONFIG_BLK_DEV_PIIX is not set
+# CONFIG_BLK_DEV_NS87415 is not set
+# CONFIG_BLK_DEV_PDC202XX_OLD is not set
+# CONFIG_BLK_DEV_PDC202XX_NEW is not set
+# CONFIG_BLK_DEV_SVWKS is not set
+# CONFIG_BLK_DEV_SIIMAGE is not set
+# CONFIG_BLK_DEV_SLC90E66 is not set
+# CONFIG_BLK_DEV_TRM290 is not set
+# CONFIG_BLK_DEV_VIA82CXXX is not set
+CONFIG_BLK_DEV_IDEDMA=y
+# CONFIG_IDEDMA_IVB is not set
+CONFIG_IDEDMA_AUTO=y
+# CONFIG_DMA_NONPCI is not set
+# CONFIG_BLK_DEV_HD is not set
 
 #
 # SCSI device support
@@ -175,14 +250,15 @@ CONFIG_SCSI_SYM53C8XX_MAX_TAGS=64
 # CONFIG_SCSI_QLOGIC_ISP is not set
 # CONFIG_SCSI_QLOGIC_FC is not set
 # CONFIG_SCSI_QLOGIC_1280 is not set
-CONFIG_SCSI_QLA2XXX_CONFIG=y
 CONFIG_SCSI_QLA2XXX=y
-CONFIG_SCSI_QLA21XX=y
-CONFIG_SCSI_QLA22XX=y
-CONFIG_SCSI_QLA23XX=y
+CONFIG_SCSI_QLA21XX=m
+CONFIG_SCSI_QLA22XX=m
+CONFIG_SCSI_QLA2300=m
+CONFIG_SCSI_QLA2322=m
+CONFIG_SCSI_QLA6312=m
+CONFIG_SCSI_QLA6322=m
 # CONFIG_SCSI_DC395x is not set
 # CONFIG_SCSI_DC390T is not set
-# CONFIG_SCSI_NSP32 is not set
 # CONFIG_SCSI_DEBUG is not set
 
 #
@@ -194,10 +270,11 @@ CONFIG_MD_LINEAR=y
 CONFIG_MD_RAID0=y
 CONFIG_MD_RAID1=y
 CONFIG_MD_RAID5=y
-# CONFIG_MD_RAID6 is not set
+CONFIG_MD_RAID6=y
 # CONFIG_MD_MULTIPATH is not set
 CONFIG_BLK_DEV_DM=y
 CONFIG_DM_IOCTL_V4=y
+CONFIG_DM_CRYPT=m
 
 #
 # Fusion MPT device support
@@ -205,14 +282,17 @@ CONFIG_DM_IOCTL_V4=y
 # CONFIG_FUSION is not set
 
 #
-# IEEE 1394 (FireWire) support (EXPERIMENTAL)
+# IEEE 1394 (FireWire) support
 #
 # CONFIG_IEEE1394 is not set
 
 #
 # I2O device support
 #
-# CONFIG_I2O is not set
+
+#
+# Macintosh device drivers
+#
 
 #
 # Networking support
@@ -240,10 +320,73 @@ CONFIG_SYN_COOKIES=y
 CONFIG_INET_AH=m
 CONFIG_INET_ESP=m
 CONFIG_INET_IPCOMP=m
+
+#
+# IP: Virtual Server Configuration
+#
+# CONFIG_IP_VS is not set
 # CONFIG_IPV6 is not set
 # CONFIG_DECNET is not set
 # CONFIG_BRIDGE is not set
-# CONFIG_NETFILTER is not set
+CONFIG_NETFILTER=y
+# CONFIG_NETFILTER_DEBUG is not set
+
+#
+# IP: Netfilter Configuration
+#
+CONFIG_IP_NF_CONNTRACK=m
+CONFIG_IP_NF_FTP=m
+CONFIG_IP_NF_IRC=m
+CONFIG_IP_NF_TFTP=m
+CONFIG_IP_NF_AMANDA=m
+CONFIG_IP_NF_QUEUE=m
+CONFIG_IP_NF_IPTABLES=m
+CONFIG_IP_NF_MATCH_LIMIT=m
+CONFIG_IP_NF_MATCH_IPRANGE=m
+CONFIG_IP_NF_MATCH_MAC=m
+CONFIG_IP_NF_MATCH_PKTTYPE=m
+CONFIG_IP_NF_MATCH_MARK=m
+CONFIG_IP_NF_MATCH_MULTIPORT=m
+CONFIG_IP_NF_MATCH_TOS=m
+CONFIG_IP_NF_MATCH_RECENT=m
+CONFIG_IP_NF_MATCH_ECN=m
+CONFIG_IP_NF_MATCH_DSCP=m
+CONFIG_IP_NF_MATCH_AH_ESP=m
+CONFIG_IP_NF_MATCH_LENGTH=m
+CONFIG_IP_NF_MATCH_TTL=m
+CONFIG_IP_NF_MATCH_TCPMSS=m
+CONFIG_IP_NF_MATCH_HELPER=m
+CONFIG_IP_NF_MATCH_STATE=m
+CONFIG_IP_NF_MATCH_CONNTRACK=m
+CONFIG_IP_NF_MATCH_OWNER=m
+CONFIG_IP_NF_FILTER=m
+CONFIG_IP_NF_TARGET_REJECT=m
+CONFIG_IP_NF_NAT=m
+CONFIG_IP_NF_NAT_NEEDED=y
+CONFIG_IP_NF_TARGET_MASQUERADE=m
+CONFIG_IP_NF_TARGET_REDIRECT=m
+CONFIG_IP_NF_TARGET_NETMAP=m
+CONFIG_IP_NF_TARGET_SAME=m
+# CONFIG_IP_NF_NAT_LOCAL is not set
+CONFIG_IP_NF_NAT_SNMP_BASIC=m
+CONFIG_IP_NF_NAT_IRC=m
+CONFIG_IP_NF_NAT_FTP=m
+CONFIG_IP_NF_NAT_TFTP=m
+CONFIG_IP_NF_NAT_AMANDA=m
+CONFIG_IP_NF_MANGLE=m
+CONFIG_IP_NF_TARGET_TOS=m
+CONFIG_IP_NF_TARGET_ECN=m
+CONFIG_IP_NF_TARGET_DSCP=m
+CONFIG_IP_NF_TARGET_MARK=m
+CONFIG_IP_NF_TARGET_CLASSIFY=m
+CONFIG_IP_NF_TARGET_LOG=m
+CONFIG_IP_NF_TARGET_ULOG=m
+CONFIG_IP_NF_TARGET_TCPMSS=m
+CONFIG_IP_NF_ARPTABLES=m
+CONFIG_IP_NF_ARPFILTER=m
+CONFIG_IP_NF_ARP_MANGLE=m
+CONFIG_IP_NF_COMPAT_IPCHAINS=m
+CONFIG_IP_NF_COMPAT_IPFWADM=m
 CONFIG_XFRM=y
 CONFIG_XFRM_USER=m
 
@@ -254,6 +397,7 @@ CONFIG_IPV6_SCTP__=y
 # CONFIG_IP_SCTP is not set
 # CONFIG_ATM is not set
 # CONFIG_VLAN_8021Q is not set
+CONFIG_LLC=y
 # CONFIG_LLC2 is not set
 # CONFIG_IPX is not set
 # CONFIG_ATALK is not set
@@ -311,6 +455,7 @@ CONFIG_PCNET32=y
 # CONFIG_DGRS is not set
 # CONFIG_EEPRO100 is not set
 CONFIG_E100=y
+# CONFIG_E100_NAPI is not set
 # CONFIG_FEALNX is not set
 # CONFIG_NATSEMI is not set
 # CONFIG_NE2K_PCI is not set
@@ -335,14 +480,16 @@ CONFIG_E1000=y
 # CONFIG_R8169 is not set
 # CONFIG_SIS190 is not set
 # CONFIG_SK98LIN is not set
-# CONFIG_TIGON3 is not set
+CONFIG_TIGON3=y
 
 #
 # Ethernet (10000 Mbit)
 #
-# CONFIG_IXGB is not set
+CONFIG_IXGB=m
+# CONFIG_IXGB_NAPI is not set
 # CONFIG_FDDI is not set
 # CONFIG_HIPPI is not set
+CONFIG_IBMVETH=m
 CONFIG_PPP=m
 # CONFIG_PPP_MULTILINK is not set
 # CONFIG_PPP_FILTER is not set
@@ -361,7 +508,11 @@ CONFIG_PPPOE=m
 #
 # Token Ring devices
 #
-# CONFIG_TR is not set
+CONFIG_TR=y
+CONFIG_IBMOL=y
+# CONFIG_IBMLS is not set
+# CONFIG_3C359 is not set
+# CONFIG_TMS380TR is not set
 # CONFIG_NET_FC is not set
 # CONFIG_SHAPER is not set
 
@@ -388,7 +539,7 @@ CONFIG_PPPOE=m
 #
 # ISDN subsystem
 #
-# CONFIG_ISDN_BOOL is not set
+# CONFIG_ISDN is not set
 
 #
 # Telephony Support
@@ -461,8 +612,10 @@ CONFIG_SERIAL_8250_NR_UARTS=4
 #
 CONFIG_SERIAL_CORE=y
 CONFIG_SERIAL_CORE_CONSOLE=y
+# CONFIG_SERIAL_PMACZILOG is not set
 CONFIG_UNIX98_PTYS=y
-CONFIG_UNIX98_PTY_COUNT=256
+CONFIG_LEGACY_PTYS=y
+CONFIG_LEGACY_PTY_COUNT=256
 CONFIG_HVC_CONSOLE=y
 
 #
@@ -498,7 +651,60 @@ CONFIG_MAX_RAW_DEVS=256
 #
 # I2C support
 #
-# CONFIG_I2C is not set
+CONFIG_I2C=y
+# CONFIG_I2C_CHARDEV is not set
+
+#
+# I2C Algorithms
+#
+CONFIG_I2C_ALGOBIT=y
+# CONFIG_I2C_ALGOPCF is not set
+
+#
+# I2C Hardware Bus support
+#
+# CONFIG_I2C_ALI1535 is not set
+# CONFIG_I2C_ALI15X3 is not set
+# CONFIG_I2C_AMD756 is not set
+# CONFIG_I2C_AMD8111 is not set
+# CONFIG_I2C_ELV is not set
+# CONFIG_I2C_I801 is not set
+# CONFIG_I2C_I810 is not set
+# CONFIG_I2C_ISA is not set
+# CONFIG_I2C_NFORCE2 is not set
+# CONFIG_I2C_PARPORT_LIGHT is not set
+# CONFIG_I2C_PROSAVAGE is not set
+# CONFIG_I2C_SAVAGE4 is not set
+# CONFIG_SCx200_ACB is not set
+# CONFIG_I2C_SIS5595 is not set
+# CONFIG_I2C_SIS630 is not set
+# CONFIG_I2C_SIS96X is not set
+# CONFIG_I2C_VELLEMAN is not set
+# CONFIG_I2C_VIA is not set
+# CONFIG_I2C_VIAPRO is not set
+# CONFIG_I2C_VOODOO3 is not set
+
+#
+# I2C Hardware Sensors Chip support
+#
+# CONFIG_I2C_SENSOR is not set
+# CONFIG_SENSORS_ADM1021 is not set
+# CONFIG_SENSORS_ASB100 is not set
+# CONFIG_SENSORS_EEPROM is not set
+# CONFIG_SENSORS_FSCHER is not set
+# CONFIG_SENSORS_GL518SM is not set
+# CONFIG_SENSORS_IT87 is not set
+# CONFIG_SENSORS_LM75 is not set
+# CONFIG_SENSORS_LM78 is not set
+# CONFIG_SENSORS_LM83 is not set
+# CONFIG_SENSORS_LM85 is not set
+# CONFIG_SENSORS_LM90 is not set
+# CONFIG_SENSORS_VIA686A is not set
+# CONFIG_SENSORS_W83781D is not set
+# CONFIG_SENSORS_W83L785TS is not set
+# CONFIG_I2C_DEBUG_CORE is not set
+# CONFIG_I2C_DEBUG_BUS is not set
+# CONFIG_I2C_DEBUG_CHIP is not set
 
 #
 # Multimedia devices
@@ -526,8 +732,12 @@ CONFIG_FB_MATROX_MILLENIUM=y
 CONFIG_FB_MATROX_MYSTIQUE=y
 CONFIG_FB_MATROX_G450=y
 CONFIG_FB_MATROX_G100=y
+# CONFIG_FB_MATROX_I2C is not set
 CONFIG_FB_MATROX_MULTIHEAD=y
-# CONFIG_FB_RADEON is not set
+# CONFIG_FB_RADEON_OLD is not set
+CONFIG_FB_RADEON=y
+CONFIG_FB_RADEON_I2C=y
+# CONFIG_FB_RADEON_DEBUG is not set
 # CONFIG_FB_ATY128 is not set
 # CONFIG_FB_ATY is not set
 # CONFIG_FB_SIS is not set
@@ -566,9 +776,110 @@ CONFIG_LOGO_LINUX_CLUT224=y
 #
 # USB support
 #
-# CONFIG_USB is not set
+CONFIG_USB=m
+# CONFIG_USB_DEBUG is not set
+
+#
+# Miscellaneous USB options
+#
+CONFIG_USB_DEVICEFS=y
+# CONFIG_USB_BANDWIDTH is not set
+# CONFIG_USB_DYNAMIC_MINORS is not set
+
+#
+# USB Host Controller Drivers
+#
+CONFIG_USB_EHCI_HCD=m
+CONFIG_USB_OHCI_HCD=m
+# CONFIG_USB_UHCI_HCD is not set
+
+#
+# USB Device Class drivers
+#
+# CONFIG_USB_BLUETOOTH_TTY is not set
+# CONFIG_USB_ACM is not set
+# CONFIG_USB_PRINTER is not set
+CONFIG_USB_STORAGE=m
+# CONFIG_USB_STORAGE_DEBUG is not set
+# CONFIG_USB_STORAGE_DATAFAB is not set
+# CONFIG_USB_STORAGE_FREECOM is not set
+# CONFIG_USB_STORAGE_ISD200 is not set
+# CONFIG_USB_STORAGE_DPCM is not set
+# CONFIG_USB_STORAGE_HP8200e is not set
+# CONFIG_USB_STORAGE_SDDR09 is not set
+# CONFIG_USB_STORAGE_SDDR55 is not set
+# CONFIG_USB_STORAGE_JUMPSHOT is not set
+
+#
+# USB Human Interface Devices (HID)
+#
+CONFIG_USB_HID=m
+CONFIG_USB_HIDINPUT=y
+# CONFIG_HID_FF is not set
+CONFIG_USB_HIDDEV=y
+
+#
+# USB HID Boot Protocol drivers
+#
+# CONFIG_USB_KBD is not set
+# CONFIG_USB_MOUSE is not set
+# CONFIG_USB_AIPTEK is not set
+# CONFIG_USB_WACOM is not set
+# CONFIG_USB_KBTAB is not set
+# CONFIG_USB_POWERMATE is not set
+# CONFIG_USB_XPAD is not set
+
+#
+# USB Imaging devices
+#
+# CONFIG_USB_MDC800 is not set
+# CONFIG_USB_MICROTEK is not set
+# CONFIG_USB_HPUSBSCSI is not set
+
+#
+# USB Multimedia devices
+#
+# CONFIG_USB_DABUSB is not set
+
+#
+# Video4Linux support is needed for USB Multimedia device support
+#
+
+#
+# USB Network adaptors
+#
+# CONFIG_USB_CATC is not set
+# CONFIG_USB_KAWETH is not set
+# CONFIG_USB_PEGASUS is not set
+# CONFIG_USB_RTL8150 is not set
+# CONFIG_USB_USBNET is not set
+
+#
+# USB port drivers
+#
+
+#
+# USB Serial Converter support
+#
+# CONFIG_USB_SERIAL is not set
+
+#
+# USB Miscellaneous drivers
+#
 # CONFIG_USB_EMI62 is not set
 # CONFIG_USB_EMI26 is not set
+# CONFIG_USB_TIGL is not set
+# CONFIG_USB_AUERSWALD is not set
+# CONFIG_USB_RIO500 is not set
+# CONFIG_USB_LEGOTOWER is not set
+# CONFIG_USB_BRLVGER is not set
+# CONFIG_USB_LCD is not set
+# CONFIG_USB_LED is not set
+# CONFIG_USB_TEST is not set
+
+#
+# USB Gadget Support
+#
 # CONFIG_USB_GADGET is not set
 
 #
@@ -596,6 +907,7 @@ CONFIG_FS_POSIX_ACL=y
 CONFIG_XFS_FS=m
 # CONFIG_XFS_RT is not set
 # CONFIG_XFS_QUOTA is not set
+# CONFIG_XFS_SECURITY is not set
 CONFIG_XFS_POSIX_ACL=y
 # CONFIG_MINIX_FS is not set
 # CONFIG_ROMFS_FS is not set
@@ -625,7 +937,6 @@ CONFIG_VFAT_FS=y
 CONFIG_PROC_FS=y
 CONFIG_PROC_KCORE=y
 # CONFIG_DEVFS_FS is not set
-CONFIG_DEVPTS_FS=y
 CONFIG_DEVPTS_FS_XATTR=y
 # CONFIG_DEVPTS_FS_SECURITY is not set
 CONFIG_TMPFS=y
@@ -639,6 +950,7 @@ CONFIG_RAMFS=y
 # CONFIG_ADFS_FS is not set
 # CONFIG_AFFS_FS is not set
 # CONFIG_HFS_FS is not set
+# CONFIG_HFSPLUS_FS is not set
 # CONFIG_BEFS_FS is not set
 # CONFIG_BFS_FS is not set
 # CONFIG_EFS_FS is not set
@@ -670,7 +982,6 @@ CONFIG_RPCSEC_GSS_KRB5=m
 CONFIG_CIFS=m
 # CONFIG_NCP_FS is not set
 # CONFIG_CODA_FS is not set
-# CONFIG_INTERMEZZO_FS is not set
 # CONFIG_AFS_FS is not set
 
 #
@@ -732,8 +1043,11 @@ CONFIG_OPROFILE=y
 # Kernel hacking
 #
 CONFIG_DEBUG_KERNEL=y
+CONFIG_DEBUG_STACKOVERFLOW=y
+CONFIG_DEBUG_STACK_USAGE=y
 # CONFIG_DEBUG_SLAB is not set
 CONFIG_MAGIC_SYSRQ=y
+CONFIG_DEBUGGER=y
 CONFIG_XMON=y
 CONFIG_XMON_DEFAULT=y
 # CONFIG_PPCDBG is not set
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/Makefile linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/Makefile
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/Makefile	2004-02-23 16:39:12.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/Makefile	2004-02-27 22:44:57.000000000 +0000
@@ -10,11 +10,12 @@ obj-y               :=	setup.o entry.o t
 			align.o semaphore.o bitops.o stab.o pacaData.o \
 			udbg.o binfmt_elf32.o sys_ppc32.o ioctl32.o \
 			ptrace32.o signal32.o pmc.o rtc.o init_task.o \
-			lmb.o cputable.o cpu_setup_power4.o idle_power4.o
+			lmb.o cputable.o cpu_setup_power4.o idle_power4.o \
+			iommu.o
 
 obj-$(CONFIG_PPC_OF) +=	of_device.o
 
-obj-$(CONFIG_PCI)	+= pci.o pci_dn.o pci_dma.o
+obj-$(CONFIG_PCI)	+= pci.o pci_dn.o pci_iommu.o
 
 ifdef CONFIG_PPC_ISERIES
 obj-$(CONFIG_PCI)	+= iSeries_pci.o iSeries_pci_reset.o \
@@ -28,12 +29,12 @@ obj-$(CONFIG_PPC_ISERIES) += iSeries_irq
 			     HvCall.o HvLpConfig.o LparData.o mf_proc.o \
 			     iSeries_setup.o ItLpQueue.o hvCall.o \
 			     mf.o HvLpEvent.o iSeries_proc.o iSeries_htab.o \
-			     proc_pmc.o
+			     proc_pmc.o iSeries_iommu.o
 
 obj-$(CONFIG_PPC_PSERIES) += pSeries_pci.o pSeries_lpar.o pSeries_hvCall.o \
 			     eeh.o nvram.o pSeries_nvram.o rtasd.o ras.o \
 			     open_pic.o xics.o pSeries_htab.o rtas.o \
-			     chrp_setup.o i8259.o prom.o vio.o
+			     chrp_setup.o i8259.o prom.o vio.o pSeries_iommu.o
 
 obj-$(CONFIG_PROC_FS)		+= proc_ppc64.o
 obj-$(CONFIG_RTAS_FLASH)	+= rtas_flash.o
@@ -49,6 +50,8 @@ obj-$(CONFIG_BOOTX_TEXT)	+= btext.o
 obj-$(CONFIG_PPC_PMAC)		+= pmac_setup.o pmac_feature.o pmac_pci.o \
 				   pmac_time.o pmac_nvram.o pmac_low_i2c.o \
 				   open_pic_u3.o
+obj-$(CONFIG_PMAC_DART)		+= pmac_iommu.o
+
 ifdef CONFIG_SMP
 obj-$(CONFIG_PPC_PMAC)		+= pmac_smp.o smp-tbsync.o
 endif
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/chrp_setup.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/chrp_setup.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/chrp_setup.c	2004-02-23 16:39:09.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/chrp_setup.c	2004-02-27 23:02:35.000000000 +0000
@@ -51,7 +51,7 @@
 #include <asm/prom.h>
 #include <asm/rtas.h>
 #include <asm/pci-bridge.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 #include <asm/dma.h>
 #include <asm/machdep.h>
 #include <asm/irq.h>
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/head.S linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/head.S
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/head.S	2004-02-23 16:39:09.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/head.S	2004-02-27 22:59:30.000000000 +0000
@@ -826,7 +826,14 @@ SystemCall_common:
 _GLOBAL(do_hash_page_ISI)
 	li	r4,0
 _GLOBAL(do_hash_page_DSI)
-	rlwimi	r4,r23,32-13,30,30	/* Insert MSR_PR as _PAGE_USER */
+	/*
+	 * We need to set the _PAGE_USER bit if MSR_PR is set or if we are
+	 * accessing a userspace segment (even from the kernel). We assume
+	 * kernel addresses always have the high bit set.
+	 */
+	rotldi	r0,r3,15		/* Move high bit into MSR_PR position */
+	orc	r0,r23,r0
+	rlwimi	r4,r0,32-13,30,30	/* Insert into _PAGE_USER */
 	ori	r4,r4,1			/* add _PAGE_PRESENT */
 
 	mflr	r21			/* Save LR in r21 */
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/iSeries_iommu.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/iSeries_iommu.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/iSeries_iommu.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/iSeries_iommu.c	2004-02-27 18:28:03.000000000 +0000
@@ -0,0 +1,258 @@
+/*
+ * arch/ppc64/kernel/iSeries_iommu.c
+ *
+ * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
+ * 
+ * Rewrite, cleanup: 
+ *
+ * Copyright (C) 2004 Olof Johansson <olof@austin.ibm.com>, IBM Corporation
+ *
+ * Dynamic DMA mapping support, iSeries-specific parts.
+ *
+ * 
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ */
+
+#include <linux/config.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/string.h>
+#include <linux/pci.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/rtas.h>
+#include <asm/ppcdebug.h>
+
+#include <asm/iSeries/HvCallXm.h>
+#include <asm/iSeries/LparData.h>
+#include <asm/iommu.h>
+#include <asm/pci-bridge.h>
+#include <asm/iSeries/iSeries_pci.h>
+
+#include <asm/machdep.h>
+
+#include "pci.h"
+
+
+static struct iommu_table veth_iommu_table;	/* Tce table for virtual ethernet */
+static struct iommu_table vio_iommu_table;	/* Tce table for virtual I/O */
+
+static struct iSeries_Device_Node veth_dev_node = { .LogicalSlot = 0xFF, .iommu_table = &veth_iommu_table };
+static struct iSeries_Device_Node vio_dev_node  = { .LogicalSlot = 0xFF, .iommu_table = &vio_iommu_table };
+
+static struct pci_dev _veth_dev = { .sysdata = &veth_dev_node };
+static struct pci_dev _vio_dev  = { .sysdata = &vio_dev_node, .dev.bus = &pci_bus_type  };
+
+/*
+ * I wonder what the deal is with these.  Nobody uses them.  Why do they
+ * exist? Why do we export them to modules? Why is this comment here, and
+ * why didn't I just delete them?
+ */
+struct pci_dev *iSeries_veth_dev = &_veth_dev;
+struct device *iSeries_vio_dev = &_vio_dev.dev;
+
+EXPORT_SYMBOL(iSeries_veth_dev);
+EXPORT_SYMBOL(iSeries_vio_dev);
+
+extern struct list_head iSeries_Global_Device_List;
+
+
+static void tce_build_iSeries(struct iommu_table *tbl, long index, long npages,
+			      unsigned long uaddr, int direction)
+{
+	u64 rc;
+	union tce_entry tce;
+	
+	while (npages--) {
+		tce.te_word = 0;
+		tce.te_bits.tb_rpn = (virt_to_absolute(uaddr)) >> PAGE_SHIFT;
+
+		if (tbl->it_type == TCE_VB) {
+			/* Virtual Bus */
+			tce.te_bits.tb_valid = 1;
+			tce.te_bits.tb_allio = 1;
+			if (direction != PCI_DMA_TODEVICE)
+				tce.te_bits.tb_rdwr = 1;
+		} else {
+			/* PCI Bus */
+			tce.te_bits.tb_rdwr = 1; /* Read allowed */
+			if (direction != PCI_DMA_TODEVICE)
+				tce.te_bits.tb_pciwr = 1;
+		}
+		
+		rc = HvCallXm_setTce((u64)tbl->it_index, 
+				     (u64)index, 
+				     tce.te_word);
+		if (rc)
+			panic("PCI_DMA: HvCallXm_setTce failed, Rc: 0x%lx\n", rc);
+
+		index++;
+		uaddr += PAGE_SIZE;
+	}
+}
+
+static void tce_free_iSeries(struct iommu_table *tbl, long index, long npages)
+{
+	u64 rc;
+	union tce_entry tce;
+
+	while (npages--) {
+		tce.te_word = 0;
+		rc = HvCallXm_setTce((u64)tbl->it_index,
+				     (u64)index,
+				     tce.te_word);
+
+		if (rc) 
+			panic("PCI_DMA: HvCallXm_setTce failed, Rc: 0x%lx\n", rc);
+
+		index++;
+	}
+
+}
+
+void __init iommu_vio_init(void)
+{
+	struct iommu_table *t;
+	struct iommu_table_cb cb;
+	unsigned long cbp;
+
+	cb.itc_busno = 255;    /* Bus 255 is the virtual bus */
+	cb.itc_virtbus = 0xff; /* Ask for virtual bus */
+	
+	cbp = virt_to_absolute((unsigned long)&cb);
+	HvCallXm_getTceTableParms(cbp);
+	
+	veth_iommu_table.it_size        = cb.itc_size / 2;
+	veth_iommu_table.it_busno       = cb.itc_busno;
+	veth_iommu_table.it_offset      = cb.itc_offset;
+	veth_iommu_table.it_index       = cb.itc_index;
+	veth_iommu_table.it_type        = TCE_VB;
+	veth_iommu_table.it_entrysize	= sizeof(union tce_entry);
+	veth_iommu_table.it_blocksize	= 1;
+
+	t = iommu_init_table(&veth_iommu_table);
+
+	if (!t)
+		printk("Virtual Bus VETH TCE table failed.\n");
+
+	vio_iommu_table.it_size         = cb.itc_size - veth_iommu_table.it_size;
+	vio_iommu_table.it_busno        = cb.itc_busno;
+	vio_iommu_table.it_offset       = cb.itc_offset +
+		veth_iommu_table.it_size * (PAGE_SIZE/sizeof(union tce_entry));
+	vio_iommu_table.it_index        = cb.itc_index;
+	vio_iommu_table.it_type         = TCE_VB; 
+	vio_iommu_table.it_entrysize	= sizeof(union tce_entry);
+	vio_iommu_table.it_blocksize	= 1;
+
+	t = iommu_init_table(&vio_iommu_table);
+
+	if (!t) 
+		printk("Virtual Bus VIO TCE table failed.\n");
+}
+
+
+/*
+ * This function compares the known tables to find an iommu_table
+ * that has already been built for hardware TCEs.                          
+ */
+static struct iommu_table *iommu_table_find(struct iommu_table * tbl)
+{
+	struct iSeries_Device_Node *dp;
+
+	for (dp =  (struct iSeries_Device_Node *)iSeries_Global_Device_List.next;
+	     dp != (struct iSeries_Device_Node *)&iSeries_Global_Device_List;
+	     dp =  (struct iSeries_Device_Node *)dp->Device_List.next) 
+		if (dp->iommu_table                 != NULL &&
+		    dp->iommu_table->it_type        == TCE_PCI &&
+		    dp->iommu_table->it_offset      == tbl->it_offset &&
+		    dp->iommu_table->it_index       == tbl->it_index &&
+		    dp->iommu_table->it_size        == tbl->it_size) 
+			return dp->iommu_table;
+			
+
+	return NULL;
+}
+
+/*
+ * Call Hv with the architected data structure to get TCE table info.
+ * info. Put the returned data into the Linux representation of the   
+ * TCE table data.                                                     
+ * The Hardware Tce table comes in three flavors.                     
+ * 1. TCE table shared between Buses.                                  
+ * 2. TCE table per Bus.                                               
+ * 3. TCE Table per IOA.                                               
+ */
+static void iommu_table_getparms(struct iSeries_Device_Node* dn,
+				 struct iommu_table* tbl)
+{
+	struct iommu_table_cb *parms;
+
+	parms = (struct iommu_table_cb*)kmalloc(sizeof(*parms), GFP_KERNEL);
+
+	if (parms == NULL) 
+		panic("PCI_DMA: TCE Table Allocation failed.");
+
+	memset(parms, 0, sizeof(*parms));
+
+	parms->itc_busno   = ISERIES_BUS(dn);
+	parms->itc_slotno  = dn->LogicalSlot;
+	parms->itc_virtbus = 0;
+
+	HvCallXm_getTceTableParms(REALADDR(parms));
+
+	if (parms->itc_size == 0)
+		panic("PCI_DMA: parms->size is zero, parms is 0x%p", parms);
+
+	tbl->it_size        = parms->itc_size;
+	tbl->it_busno       = parms->itc_busno;
+	tbl->it_offset      = parms->itc_offset;
+	tbl->it_index       = parms->itc_index;
+	tbl->it_entrysize   = sizeof(union tce_entry);
+	tbl->it_blocksize   = 1;
+	tbl->it_type        = TCE_PCI;
+
+	kfree(parms);
+}
+
+
+void iommu_devnode_init(struct iSeries_Device_Node *dn) {
+	struct iommu_table *tbl;
+
+	tbl = (struct iommu_table *)kmalloc(sizeof(struct iommu_table), GFP_KERNEL);
+
+	iommu_table_getparms(dn, tbl);
+
+	/* Look for existing tce table */
+	dn->iommu_table = iommu_table_find(tbl);
+
+	if (dn->iommu_table == NULL)
+		dn->iommu_table = iommu_init_table(tbl);
+	else
+		kfree(tbl);
+
+	return;
+}
+
+
+void tce_init_iSeries(void)
+{
+	ppc_md.tce_build = tce_build_iSeries;
+	ppc_md.tce_free  = tce_free_iSeries;
+
+	pci_iommu_init();
+}
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/iSeries_pci.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/iSeries_pci.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/iSeries_pci.c	2004-02-25 02:54:12.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/iSeries_pci.c	2004-02-27 23:02:35.000000000 +0000
@@ -36,7 +36,7 @@
 #include <asm/pci-bridge.h>
 #include <asm/ppcdebug.h>
 #include <asm/naca.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 
 #include <asm/iSeries/HvCallPci.h>
 #include <asm/iSeries/HvCallSm.h>
@@ -53,7 +53,7 @@ extern int panic_timeout;
 
 extern unsigned long iSeries_Base_Io_Memory;    
 
-extern struct TceTable *tceTables[256];
+extern struct iommu_table *tceTables[256];
 
 extern void iSeries_MmIoTest(void);
 
@@ -273,7 +273,7 @@ void __init iSeries_pci_final_fixup(void
 			iSeries_Device_Information(pdev, Buffer,
 					sizeof(Buffer));
 			printk("%d. %s\n", DeviceCount, Buffer);
-			create_pci_bus_tce_table((unsigned long)node);
+			iommu_devnode_init(node);
 		} else
 			printk("PCI: Device Tree not found for 0x%016lX\n",
 					(unsigned long)pdev);
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/iommu.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/iommu.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/iommu.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/iommu.c	2004-02-27 17:16:29.000000000 +0000
@@ -0,0 +1,389 @@
+/*
+ * arch/ppc64/kernel/pci_iommu.c
+ * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
+ * 
+ * Rewrite, cleanup, new allocation schemes, virtual merging: 
+ * Copyright (C) 2004 Olof Johansson, IBM Corporation
+ *               and  Ben. Herrenschmidt, IBM Corporation
+ *
+ * Dynamic DMA mapping support, platform-independent parts.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ */
+
+
+#include <linux/config.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/string.h>
+#include <linux/pci.h>
+#include <linux/init.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/iommu.h>
+#include <asm/pci-bridge.h>
+#include <asm/machdep.h>
+#include <asm/bitops.h>
+
+#define DBG(...)
+
+#ifdef CONFIG_IOMMU_VMERGE
+static int novmerge = 0;
+#else
+static int novmerge = 1;
+#endif
+
+static int __init setup_iommu(char *str)
+{
+	if (!strcmp(str, "novmerge"))
+		novmerge = 1;
+	else if (!strcmp(str, "vmerge"))
+		novmerge = 0;
+	return 1;
+}
+
+__setup("iommu=", setup_iommu);
+
+static unsigned long iommu_range_alloc(struct iommu_table *tbl, unsigned long npages,
+			      unsigned long *handle)
+{ 
+	unsigned long n, end, i, start;
+	unsigned long hint;
+	unsigned long limit;
+	int largealloc = npages > 15;
+
+	if (handle && *handle)
+		hint = *handle;
+	else
+		hint = largealloc ? tbl->it_largehint : tbl->it_hint;
+
+	/* Most of this is stolen from x86_64's bit string search function */
+
+	start = hint;
+
+	/* Use only half of the table for small allocs (less than 15 pages). */
+
+	limit = largealloc ? tbl->it_mapsize : tbl->it_mapsize >> 1; 
+
+	if (largealloc && start < (tbl->it_mapsize >> 1))
+		start = tbl->it_mapsize >> 1;
+	
+ again:
+
+	n = find_next_zero_bit(tbl->it_map, limit, start);
+
+	end = n + npages;
+	if (end >= limit) {
+		if (hint) {
+			start = largealloc ? tbl->it_mapsize >> 1 : 0;
+			hint = 0;
+			goto again;
+		} else
+			return NO_TCE;
+	}
+
+	for (i = n; i < end; i++)
+		if (test_bit(i, tbl->it_map)) {
+			start = i+1;
+			goto again;
+		}
+
+	for (i = n; i < end; i++)
+		__set_bit(i, tbl->it_map);
+
+	/* Bump the hint to a new PHB cache line, which
+	 * is 16 entries wide on all pSeries machines.
+	 */
+	if (largealloc)
+		tbl->it_largehint = (end+tbl->it_blocksize-1) &
+					~(tbl->it_blocksize-1);
+	else 
+		tbl->it_hint = (end+tbl->it_blocksize-1) &
+				~(tbl->it_blocksize-1);
+
+	if (handle)
+		*handle = end;
+
+	return n;
+}
+
+dma_addr_t iommu_alloc(struct iommu_table *tbl, void *page,
+		       unsigned int npages, int direction, 
+		       unsigned long *handle)
+{
+	unsigned long entry, flags;
+	dma_addr_t retTce = NO_TCE;
+	
+	spin_lock_irqsave(&(tbl->it_lock), flags);
+
+	/* Allocate a range of entries into the table */
+	entry = iommu_range_alloc(tbl, npages, handle);
+	if (unlikely(entry == NO_TCE)) {
+		spin_unlock_irqrestore(&(tbl->it_lock), flags);
+		return NO_TCE;
+	}
+	
+	/* We got the tces we wanted */
+	entry += tbl->it_offset;	/* Offset into real TCE table */
+	retTce = entry << PAGE_SHIFT;	/* Set the return dma address */
+
+	/* Put the TCEs in the HW table */
+	ppc_md.tce_build(tbl, entry, npages, (unsigned long)page & PAGE_MASK, direction);
+
+	/* Flush/invalidate TLBs if necessary */
+	if (ppc_md.tce_flush)
+		ppc_md.tce_flush(tbl);
+
+	spin_unlock_irqrestore(&(tbl->it_lock), flags);
+
+	return retTce;
+}
+
+static void __iommu_free(struct iommu_table *tbl, dma_addr_t dma_addr, 
+			 unsigned int npages)
+{
+	unsigned long entry, free_entry;
+	unsigned long i;
+
+	entry = dma_addr >> PAGE_SHIFT;
+	free_entry = entry - tbl->it_offset;
+
+	if (((free_entry + npages) > tbl->it_mapsize) ||
+	    (entry < tbl->it_offset)) {
+		if (printk_ratelimit()) {
+			printk(KERN_INFO "iommu_free: invalid entry\n");
+			printk(KERN_INFO "\tentry     = 0x%lx\n", entry); 
+			printk(KERN_INFO "\tdma_ddr   = 0x%lx\n", (u64)dma_addr); 
+			printk(KERN_INFO "\tTable     = 0x%lx\n", (u64)tbl);
+			printk(KERN_INFO "\tbus#      = 0x%lx\n", (u64)tbl->it_busno);
+			printk(KERN_INFO "\tmapsize   = 0x%lx\n", (u64)tbl->it_mapsize);
+			printk(KERN_INFO "\tstartOff  = 0x%lx\n", (u64)tbl->it_offset);
+			printk(KERN_INFO "\tindex     = 0x%lx\n", (u64)tbl->it_index);
+			WARN_ON(1);
+		}
+		return;
+	}
+
+	ppc_md.tce_free(tbl, entry, npages);
+	
+	for (i = 0; i < npages; i++)
+		__clear_bit(free_entry+i, tbl->it_map);
+}
+
+void iommu_free(struct iommu_table *tbl, dma_addr_t dma_addr, 
+		unsigned int npages)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&(tbl->it_lock), flags);
+
+	__iommu_free(tbl, dma_addr, npages);
+
+	/* Flush/invalidate TLBs if necessary */
+	if (ppc_md.tce_flush)
+		ppc_md.tce_flush(tbl);
+
+	spin_unlock_irqrestore(&(tbl->it_lock), flags);
+}
+
+/* 
+ * Build a iommu_table structure.  This contains a bit map which
+ * is used to manage allocation of the tce space.
+ */
+struct iommu_table *iommu_init_table(struct iommu_table *tbl)
+{
+	unsigned long sz;
+	static int welcomed = 0;
+
+	/* it_size is in pages, it_mapsize in number of entries */
+	tbl->it_mapsize = tbl->it_size * tbl->it_entrysize;
+
+	if (systemcfg->platform == PLATFORM_POWERMAC)
+		tbl->it_mapsize = tbl->it_size * (PAGE_SIZE / sizeof(unsigned int));
+	else
+		tbl->it_mapsize = tbl->it_size * (PAGE_SIZE / sizeof(union tce_entry));
+
+	/* sz is the number of bytes needed for the bitmap */
+	sz = (tbl->it_mapsize + 7) >> 3;
+
+	tbl->it_map = (unsigned long *)__get_free_pages(GFP_ATOMIC, get_order(sz));
+	
+	if (!tbl->it_map)
+		panic("iommu_init_table: Can't allocate memory, size %ld bytes\n", sz);
+
+	memset(tbl->it_map, 0, sz);
+
+	tbl->it_hint = 0;
+	tbl->it_largehint = 0;
+	spin_lock_init(&tbl->it_lock);
+
+	if (!welcomed) {
+		printk(KERN_INFO "IOMMU table initialized, virtual merging %s\n",
+		       novmerge ? "disabled" : "enabled");
+		welcomed = 1;
+	}
+
+	return tbl;
+}
+
+
+int iommu_alloc_sg(struct iommu_table *tbl, struct scatterlist *sglist, int nelems,
+		   int direction, unsigned long *handle)
+{
+	dma_addr_t dma_next, dma_addr;
+	unsigned long flags, vaddr, npages, entry;
+	struct scatterlist *s, *outs, *segstart, *ps;
+	int outcount;
+
+	/* Initialize some stuffs */
+	outs = s = segstart = &sglist[0];
+	outcount = 1;
+	ps = NULL;
+
+	/* Init first segment length for error handling */
+	outs->dma_length = 0;
+
+	DBG("mapping %d elements:\n", nelems);
+
+	spin_lock_irqsave(&(tbl->it_lock), flags);
+
+	for (s = outs; nelems; nelems--, s++) {
+		/* Allocate iommu entries for that segment */
+		vaddr = (unsigned long)page_address(s->page) + s->offset;
+		npages = PAGE_ALIGN(vaddr + s->length) - (vaddr & PAGE_MASK);
+		npages >>= PAGE_SHIFT;
+		entry = iommu_range_alloc(tbl, npages, handle);
+
+		DBG("  - vaddr: %lx, size: %lx\n", vaddr, s->length);
+
+		/* Handle failure */
+		if (unlikely(entry == NO_TCE)) {
+			if (printk_ratelimit())
+				printk(KERN_INFO "iommu_alloc failed, tbl %p vaddr %lx"
+				       " npages %lx\n", tbl, vaddr, npages);
+			goto failure;
+		}
+
+		/* Convert entry to a dma_addr_t */
+		entry += tbl->it_offset;
+		dma_addr = entry << PAGE_SHIFT;
+		dma_addr |= s->offset;
+
+		DBG("  - %lx pages, entry: %lx, dma_addr: %lx\n",
+			    npages, entry, dma_addr);
+
+		/* Insert into HW table */
+		ppc_md.tce_build(tbl, entry, npages, vaddr & PAGE_MASK, direction);
+
+		/* If we are in an open segment, try merging */
+		if (segstart != s) {
+			DBG("  - trying merge...\n");
+			/* We cannot merge is:
+			 * - allocated dma_addr isn't contiguous to previous allocation
+			 * - current entry has an offset into the page
+			 * - previous entry didn't end on a page boundary
+			 */
+			if (novmerge || (dma_addr != dma_next) || s->offset ||
+			    (ps->offset + ps->length) % PAGE_SIZE) {
+				/* Can't merge: create a new segment */
+				segstart = s;
+				outcount++; outs++;
+				DBG("    can't merge, new segment.\n");
+			} else {
+				outs->dma_length += s->length;
+				DBG("    merged, new len: %lx\n", outs->dma_length);
+			}
+		}
+
+		/* If we are beginning a new segment, fill entries */
+		if (segstart == s) {
+			DBG("  - filling new segment.\n");
+			outs->dma_address = dma_addr;
+			outs->dma_length = s->length;
+		}
+
+		/* Calculate next page pointer for contiguous check */
+		dma_next = (dma_addr & PAGE_MASK) + (npages << PAGE_SHIFT);
+
+		DBG("  - dma next is: %lx\n", dma_next);
+
+		/* Keep a pointer to the previous entry */
+		ps = s;
+	}
+
+	/* Make sure the update is visible to hardware. */
+	mb();
+
+	/* Flush/invalidate TLBs if necessary */
+	if (ppc_md.tce_flush)
+		ppc_md.tce_flush(tbl);
+
+	spin_unlock_irqrestore(&(tbl->it_lock), flags);
+
+	DBG("mapped %d elements:\n", outcount);
+
+	/* For the sake of iommu_free_sg, we clear out the length in the
+	 * next entry of the sglist if we didn't fill the list completely
+	 */
+	if (outcount < nelems) {
+		outs++;
+		outs->dma_address = NO_TCE;
+		outs->dma_length = 0;
+	}
+	return outcount;
+
+ failure:
+	spin_unlock_irqrestore(&(tbl->it_lock), flags);
+	for (s = &sglist[0]; s <= outs; s++) {
+		if (s->dma_length != 0) {
+			vaddr = s->dma_address & PAGE_MASK;
+			npages = (PAGE_ALIGN(s->dma_address + s->dma_length) - vaddr)
+				>> PAGE_SHIFT;
+			iommu_free(tbl, vaddr, npages);
+		}
+	}
+	return 0;
+}
+
+
+void iommu_free_sg(struct iommu_table *tbl, struct scatterlist *sglist, int nelems,
+		   int direction)
+{
+	unsigned long flags;
+
+	/* Lock the whole operation to try to free as a "chunk" */
+	spin_lock_irqsave(&(tbl->it_lock), flags);
+
+	while (nelems--) {
+		unsigned int npages;
+		dma_addr_t dma_handle = sglist->dma_address;
+
+		if (sglist->dma_length == 0)
+			break;
+		npages = (PAGE_ALIGN(dma_handle + sglist->dma_length)
+			  - (dma_handle & PAGE_MASK)) >> PAGE_SHIFT;
+		__iommu_free(tbl, dma_handle, npages);
+		sglist++;
+	}
+
+	/* Flush/invalidate TLBs if necessary */
+	if (ppc_md.tce_flush)
+		ppc_md.tce_flush(tbl);
+
+	spin_unlock_irqrestore(&(tbl->it_lock), flags);
+}
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/lmb.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/lmb.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/lmb.c	2004-02-23 16:39:05.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/lmb.c	2004-02-27 22:42:19.000000000 +0000
@@ -269,11 +269,13 @@ lmb_phys_mem_size(void)
 	return _lmb->memory.size;
 #else
 	struct lmb_region *_mem = &(_lmb->memory);
-	unsigned long idx = _mem->cnt-1;
-	unsigned long lastbase = _mem->region[idx].physbase;
-	unsigned long lastsize = _mem->region[idx].size;
-	
-	return (lastbase + lastsize);
+	unsigned long total = 0;
+	int i;
+
+	/* add all physical memory to the bootmem map */
+	for (i=0; i < _mem->cnt; i++)
+		total += _mem->region[i].size;
+	return total;
 #endif /* CONFIG_MSCHUNKS */
 }
 
@@ -283,15 +285,13 @@ lmb_end_of_DRAM(void)
 	unsigned long offset = reloc_offset();
 	struct lmb *_lmb = PTRRELOC(&lmb);
 	struct lmb_region *_mem = &(_lmb->memory);
-	unsigned long idx;
+	int idx = _mem->cnt - 1;
 
-	for(idx=_mem->cnt-1; idx >= 0; idx--) {
 #ifdef CONFIG_MSCHUNKS
-		return (_mem->region[idx].physbase + _mem->region[idx].size);
+	return (_mem->region[idx].physbase + _mem->region[idx].size);
 #else
-		return (_mem->region[idx].base + _mem->region[idx].size);
+	return (_mem->region[idx].base + _mem->region[idx].size);
 #endif /* CONFIG_MSCHUNKS */
-	}
 
 	return 0;
 }
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/misc.S linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/misc.S
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/misc.S	2004-02-23 16:39:12.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/misc.S	2004-02-27 22:44:57.000000000 +0000
@@ -210,6 +210,48 @@ _GLOBAL(flush_dcache_range)
 	blr
 
 /*
+ * Like above, but works on non-mapped physical addresses.
+ * Use only for non-LPAR setups ! It also assumes real mode
+ * is cacheable. Used for flushing out the DART before using
+ * it as uncacheable memory 
+ *
+ * flush_dcache_phys_range(unsigned long start, unsigned long stop)
+ *
+ *    flush all bytes from start to stop-1 inclusive
+ */
+_GLOBAL(flush_dcache_phys_range)
+	LOADADDR(r10,naca)		/* Get Naca address */
+	ld	r10,0(r10)
+	LOADADDR(r11,systemcfg)		/* Get systemcfg address */
+	ld	r11,0(r11)
+	lwz	r7,DCACHEL1LINESIZE(r11)	/* Get dcache line size */
+	addi	r5,r7,-1
+	andc	r6,r3,r5		/* round low to line bdy */
+	subf	r8,r6,r4		/* compute length */
+	add	r8,r8,r5		/* ensure we get enough */
+	lwz	r9,DCACHEL1LOGLINESIZE(r10)	/* Get log-2 of dcache line size */
+	srw.	r8,r8,r9		/* compute line count */
+	beqlr				/* nothing to do? */
+	mfmsr	r5			/* Disable MMU Data Relocation */
+	ori	r0,r5,MSR_DR
+	xori	r0,r0,MSR_DR
+	sync
+	mtmsr	r0
+	sync
+	isync
+	mtctr	r8
+0:	dcbst	0,r6
+	add	r6,r6,r7
+	bdnz	0b
+	sync
+	isync
+	mtmsr	r5			/* Re-enable MMU Data Relocation */
+	sync
+	isync
+	blr
+
+
+/*
  * Flush a particular page from the data cache to RAM.
  * Note: this is necessary because the instruction cache does *not*
  * snoop from the data cache.
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pSeries_htab.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pSeries_htab.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pSeries_htab.c	2004-01-19 06:28:25.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pSeries_htab.c	2004-02-27 12:16:07.000000000 +0000
@@ -300,7 +300,7 @@ static void pSeries_flush_hash_range(uns
 	int i, j;
 	HPTE *hptep;
 	Hpte_dword0 dw0;
-	struct ppc64_tlb_batch *batch = &ppc64_tlb_batch[smp_processor_id()];
+	struct ppc64_tlb_batch *batch = &__get_cpu_var(ppc64_tlb_batch);
 
 	/* XXX fix for large ptes */
 	unsigned long large = 0;
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pSeries_iommu.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pSeries_iommu.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pSeries_iommu.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pSeries_iommu.c	2004-02-27 17:16:29.000000000 +0000
@@ -0,0 +1,300 @@
+/*
+ * arch/ppc64/kernel/pSeries_iommu.c
+ *
+ * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
+ *
+ * Rewrite, cleanup: 
+ *
+ * Copyright (C) 2004 Olof Johansson <olof@austin.ibm.com>, IBM Corporation
+ *
+ * Dynamic DMA mapping support, pSeries-specific parts, both SMP and LPAR.
+ *
+ * 
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ */
+
+#include <linux/config.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/string.h>
+#include <linux/pci.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/rtas.h>
+#include <asm/ppcdebug.h>
+#include <asm/iommu.h>
+#include <asm/pci-bridge.h>
+#include <asm/machdep.h>
+#include <asm/abs_addr.h>
+#include "pci.h"
+
+
+/* Only used to pass OF initialization data set in prom.c into the main 
+ * kernel code -- data ultimately copied into regular tce tables.
+ */
+extern struct _of_tce_table of_tce_table[];
+
+
+extern struct pci_controller  *hose_head;
+extern struct pci_controller **hose_tail;
+
+
+static void tce_build_pSeries(struct iommu_table *tbl, long index, 
+			      long npages, unsigned long uaddr, 
+			      int direction)
+{
+	union tce_entry t;
+	union tce_entry *tp;
+
+	t.te_word = 0;
+	t.te_rdwr = 1; // Read allowed 
+
+	if (direction != PCI_DMA_TODEVICE)
+		t.te_pciwr = 1;
+
+	tp = ((union tce_entry *)tbl->it_base) + index;
+
+	while (npages--) {
+		/* can't move this out since we might cross LMB boundary */
+		t.te_rpn = (virt_to_absolute(uaddr)) >> PAGE_SHIFT;
+	
+		tp->te_word = t.te_word;
+
+		uaddr += PAGE_SIZE;
+		tp++;
+	}
+}
+
+
+static void tce_free_pSeries(struct iommu_table *tbl, long index, long npages)
+{
+	union tce_entry t;
+	union tce_entry *tp;
+
+	t.te_word = 0;
+	tp  = ((union tce_entry *)tbl->it_base) + index;
+		
+	while (npages--) {
+		tp->te_word = t.te_word;
+		
+		tp++;
+	}
+}
+
+
+
+static void iommu_buses_init(void)
+{
+	struct pci_controller* phb;
+	struct device_node *dn, *first_dn;
+	int num_slots, num_slots_ilog2;
+	int first_phb = 1;
+
+	/* XXX Should we be using pci_root_buses instead?  -ojn 
+	 */
+
+	for (phb=hose_head; phb; phb=phb->next) {
+		first_dn = ((struct device_node *)phb->arch_data)->child;
+
+		/* Carve 2GB into the largest dma_window_size possible */
+		for (dn = first_dn, num_slots = 0; dn != NULL; dn = dn->sibling)
+			num_slots++;
+		num_slots_ilog2 = __ilog2(num_slots);
+
+		if ((1<<num_slots_ilog2) != num_slots)
+			num_slots_ilog2++;
+
+		phb->dma_window_size = 1 << (22 - num_slots_ilog2);
+
+		/* Reserve 16MB of DMA space on the first PHB.
+		 * We should probably be more careful and use firmware props.
+		 * In reality this space is remapped, not lost.  But we don't
+		 * want to get that smart to handle it -- too much work.
+		 */
+		phb->dma_window_base_cur = first_phb ? (1 << 12) : 0;
+		first_phb = 0;
+
+		for (dn = first_dn; dn != NULL; dn = dn->sibling)
+			iommu_devnode_init(dn);
+	}
+}
+
+
+static void iommu_buses_init_lpar(struct list_head *bus_list)
+{
+	struct list_head *ln;
+	struct pci_bus *bus;
+	struct device_node *busdn;
+	unsigned int *dma_window;
+
+	for (ln=bus_list->next; ln != bus_list; ln=ln->next) {
+		bus = pci_bus_b(ln);
+		busdn = PCI_GET_DN(bus);
+
+		dma_window = (unsigned int *)get_property(busdn, "ibm,dma-window", 0);
+		if (dma_window) {
+			/* Bussubno hasn't been copied yet.
+			 * Do it now because iommu_table_setparms_lpar needs it.
+			 */
+			busdn->bussubno = bus->number;
+			iommu_devnode_init(busdn);
+		}
+
+		/* look for a window on a bridge even if the PHB had one */
+		iommu_buses_init_lpar(&bus->children);
+	}
+}
+
+
+static void iommu_table_setparms(struct pci_controller *phb,
+				 struct device_node *dn,
+				 struct iommu_table *tbl) 
+{
+	phandle node;
+	unsigned long i;
+	struct _of_tce_table *oft;
+
+	node = ((struct device_node *)(phb->arch_data))->node;
+
+	oft = NULL;
+
+	for (i=0; of_tce_table[i].node; i++)
+		if(of_tce_table[i].node == node) {
+			oft = &of_tce_table[i];
+			break;
+		}
+
+	if (!oft)
+		panic("PCI_DMA: iommu_table_setparms: Can't find phb named '%s' in of_tce_table\n", dn->full_name);
+
+	memset((void *)oft->base, 0, oft->size);
+
+	tbl->it_busno = phb->bus->number;
+	
+	/* Units of tce entries */
+	tbl->it_offset = phb->dma_window_base_cur;
+	
+	/* Adjust the current table offset to the next
+	 * region.  Measured in TCE entries. Force an
+	 * alignment to the size allotted per IOA. This
+	 * makes it easier to remove the 1st 16MB.
+      	 */
+	phb->dma_window_base_cur += (phb->dma_window_size>>3);
+	phb->dma_window_base_cur &= 
+		~((phb->dma_window_size>>3)-1);
+	
+	/* Set the tce table size - measured in pages */
+	tbl->it_size = ((phb->dma_window_base_cur -
+			 tbl->it_offset) << 3) >> PAGE_SHIFT;
+	
+	/* Test if we are going over 2GB of DMA space */
+	if (phb->dma_window_base_cur > (1 << 19))
+		panic("PCI_DMA: Unexpected number of IOAs under this PHB.\n"); 
+	
+	tbl->it_base = oft->base;
+	tbl->it_index = 0;
+	tbl->it_entrysize = sizeof(union tce_entry);
+	tbl->it_blocksize = 16;
+}
+
+/*
+ * iommu_table_setparms_lpar
+ *
+ * Function: On pSeries LPAR systems, return TCE table info, given a pci bus.
+ *
+ * ToDo: properly interpret the ibm,dma-window property.  The definition is:
+ *	logical-bus-number	(1 word)
+ *	phys-address		(#address-cells words)
+ *	size			(#cell-size words)
+ *
+ * Currently we hard code these sizes (more or less).
+ */
+static void iommu_table_setparms_lpar(struct pci_controller *phb,
+				      struct device_node *dn,
+				      struct iommu_table *tbl)
+{
+	unsigned int *dma_window;
+
+	dma_window = (unsigned int *)get_property(dn, "ibm,dma-window", 0);
+
+	if (!dma_window)
+		panic("iommu_table_setparms_lpar: device %s has no"
+		      " ibm,dma-window property!\n", dn->full_name);
+
+	tbl->it_busno  = dn->bussubno;
+	tbl->it_size   = (((((unsigned long)dma_window[4] << 32) | 
+			   (unsigned long)dma_window[5]) >> PAGE_SHIFT) << 3) >> PAGE_SHIFT;
+	tbl->it_offset = ((((unsigned long)dma_window[2] << 32) | 
+			   (unsigned long)dma_window[3]) >> 12);
+	tbl->it_base   = 0;
+	tbl->it_index  = dma_window[0];
+	tbl->it_entrysize = sizeof(union tce_entry);
+	tbl->it_blocksize  = 16;
+}
+
+
+void iommu_devnode_init(struct device_node *dn)
+{
+	struct iommu_table *tbl;
+
+	tbl = (struct iommu_table *)kmalloc(sizeof(struct iommu_table), 
+					    GFP_KERNEL);
+	
+	if (systemcfg->platform == PLATFORM_PSERIES_LPAR)
+		iommu_table_setparms_lpar(dn->phb, dn, tbl);
+	else
+		iommu_table_setparms(dn->phb, dn, tbl);
+	
+	dn->iommu_table = iommu_init_table(tbl);
+}
+
+
+void iommu_setup_pSeries(void)
+{
+	struct pci_dev *dev = NULL;
+	struct device_node *dn, *mydn;
+
+	if (systemcfg->platform == PLATFORM_PSERIES_LPAR)
+		iommu_buses_init_lpar(&pci_root_buses);
+	else
+		iommu_buses_init();
+
+	/* Now copy the iommu_table ptr from the bus devices down to every
+	 * pci device_node.  This means get_iommu_table() won't need to search
+	 * up the device tree to find it.
+	 */
+	while ((dev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL) {
+		mydn = dn = PCI_GET_DN(dev);
+
+		while (dn && dn->iommu_table == NULL)
+			dn = dn->parent;
+		if (dn)
+			mydn->iommu_table = dn->iommu_table;
+	}
+}
+
+
+/* These are called very early. */
+void tce_init_pSeries(void)
+{
+	ppc_md.tce_build = tce_build_pSeries;
+	ppc_md.tce_free  = tce_free_pSeries;
+
+	pci_iommu_init();
+}
+
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pSeries_lpar.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pSeries_lpar.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pSeries_lpar.c	2004-02-16 07:30:46.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pSeries_lpar.c	2004-02-27 12:16:07.000000000 +0000
@@ -29,7 +29,7 @@
 #include <asm/abs_addr.h>
 #include <asm/mmu_context.h>
 #include <asm/ppcdebug.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 #include <linux/pci.h>
 #include <asm/naca.h>
 #include <asm/tlbflush.h>
@@ -122,51 +122,59 @@ long plpar_put_term_char(unsigned long t
 				  lbuf[1]);
 }
 
-static void tce_build_pSeriesLP(struct TceTable *tbl, long tcenum, 
+static void tce_build_pSeriesLP(struct iommu_table *tbl, long tcenum, long npages,
 				unsigned long uaddr, int direction )
 {
-	u64 set_tce_rc;
-	union Tce tce;
-	
-	PPCDBG(PPCDBG_TCE, "build_tce: uaddr = 0x%lx\n", uaddr);
-	PPCDBG(PPCDBG_TCE, "\ttcenum = 0x%lx, tbl = 0x%lx, index=%lx\n", 
-	       tcenum, tbl, tbl->index);
-
-	tce.wholeTce = 0;
-	tce.tceBits.rpn = (virt_to_absolute(uaddr)) >> PAGE_SHIFT;
-
-	tce.tceBits.readWrite = 1;
-	if ( direction != PCI_DMA_TODEVICE ) tce.tceBits.pciWrite = 1;
-
-	set_tce_rc = plpar_tce_put((u64)tbl->index, 
-				 (u64)tcenum << 12, 
-				 tce.wholeTce );
-
-	if(set_tce_rc) {
-		printk("tce_build_pSeriesLP: plpar_tce_put failed. rc=%ld\n", set_tce_rc);
-		printk("\tindex   = 0x%lx\n", (u64)tbl->index);
-		printk("\ttcenum  = 0x%lx\n", (u64)tcenum);
-		printk("\ttce val = 0x%lx\n", tce.wholeTce );
+	u64 rc;
+	union tce_entry tce;
+
+	tce.te_word = 0;
+	tce.te_rpn = (virt_to_absolute(uaddr)) >> PAGE_SHIFT;
+	tce.te_rdwr = 1;
+	if (direction != PCI_DMA_TODEVICE)
+		tce.te_pciwr = 1;
+
+	while (npages--) {
+		rc = plpar_tce_put((u64)tbl->it_index, 
+				   (u64)tcenum << 12, 
+				   tce.te_word );
+		
+		if(rc && printk_ratelimit()) {
+			printk("tce_build_pSeriesLP: plpar_tce_put failed. rc=%ld\n", rc);
+			printk("\tindex   = 0x%lx\n", (u64)tbl->it_index);
+			printk("\ttcenum  = 0x%lx\n", (u64)tcenum);
+			printk("\ttce val = 0x%lx\n", tce.te_word );
+			show_stack(current, (unsigned long *)__get_SP());
+		}
+			
+		tcenum++;
+		tce.te_rpn++;
 	}
 }
 
-static void tce_free_one_pSeriesLP(struct TceTable *tbl, long tcenum)
-{
-	u64 set_tce_rc;
-	union Tce tce;
-
-	tce.wholeTce = 0;
-	set_tce_rc = plpar_tce_put((u64)tbl->index, 
-				 (u64)tcenum << 12,
-				 tce.wholeTce );
-	if ( set_tce_rc ) {
-		printk("tce_free_one_pSeriesLP: plpar_tce_put failed\n");
-		printk("\trc      = %ld\n", set_tce_rc);
-		printk("\tindex   = 0x%lx\n", (u64)tbl->index);
-		printk("\ttcenum  = 0x%lx\n", (u64)tcenum);
-		printk("\ttce val = 0x%lx\n", tce.wholeTce );
+static void tce_free_pSeriesLP(struct iommu_table *tbl, long tcenum, long npages)
+{
+	u64 rc;
+	union tce_entry tce;
+
+	tce.te_word = 0;
+
+	while (npages--) {
+		rc = plpar_tce_put((u64)tbl->it_index, 
+				   (u64)tcenum << 12,
+				   tce.te_word );
+		
+		if (rc && printk_ratelimit()) {
+			printk("tce_free_pSeriesLP: plpar_tce_put failed\n");
+			printk("\trc      = %ld\n", rc);
+			printk("\tindex   = 0x%lx\n", (u64)tbl->it_index);
+			printk("\ttcenum  = 0x%lx\n", (u64)tcenum);
+			printk("\ttce val = 0x%lx\n", tce.te_word );
+			show_stack(current, (unsigned long *)__get_SP());
+		}
+		
+		tcenum++;
 	}
-
 }
 
 int vtermno;	/* virtual terminal# for udbg  */
@@ -298,8 +306,10 @@ void pSeriesLP_init_early(void)
 
 	tce_init_pSeries();
 
-	ppc_md.tce_build	 = tce_build_pSeriesLP;
-	ppc_md.tce_free_one	 = tce_free_one_pSeriesLP;
+	ppc_md.tce_build = tce_build_pSeriesLP;
+	ppc_md.tce_free	 = tce_free_pSeriesLP;
+
+	pci_iommu_init();
 
 #ifdef CONFIG_SMP
 	smp_init_pSeries();
@@ -422,10 +432,8 @@ static long pSeries_lpar_hpte_updatepp(u
 
 	lpar_rc = plpar_pte_protect(flags, slot, (avpn << 7));
 
-	if (lpar_rc == H_Not_Found) {
-		udbg_printf("updatepp missed\n");
+	if (lpar_rc == H_Not_Found)
 		return -1;
-	}
 
 	if (lpar_rc != H_Success)
 		panic("bad return code from pte protect rc = %lx\n", lpar_rc);
@@ -523,10 +531,8 @@ static void pSeries_lpar_hpte_invalidate
 	lpar_rc = plpar_pte_remove(H_AVPN, slot, (avpn << 7), &dummy1,
 				   &dummy2);
 
-	if (lpar_rc == H_Not_Found) {
-		udbg_printf("invalidate missed\n");
+	if (lpar_rc == H_Not_Found)
 		return;
-	}
 
 	if (lpar_rc != H_Success)
 		panic("Bad return code from invalidate rc = %lx\n", lpar_rc);
@@ -541,7 +547,7 @@ void pSeries_lpar_flush_hash_range(unsig
 {
 	int i;
 	unsigned long flags;
-	struct ppc64_tlb_batch *batch = &ppc64_tlb_batch[smp_processor_id()];
+	struct ppc64_tlb_batch *batch = &__get_cpu_var(ppc64_tlb_batch);
 
 	spin_lock_irqsave(&pSeries_lpar_tlbie_lock, flags);
 
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pSeries_pci.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pSeries_pci.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pSeries_pci.c	2004-02-12 04:24:38.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pSeries_pci.c	2004-02-27 23:02:35.000000000 +0000
@@ -39,7 +39,7 @@
 #include <asm/pci-bridge.h>
 #include <asm/ppcdebug.h>
 #include <asm/naca.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 
 #include "open_pic.h"
 #include "pci.h"
@@ -699,7 +699,7 @@ void __init pSeries_final_fixup(void)
 	phbs_fixup_io();
 	chrp_request_regions();
 	pci_fix_bus_sysdata();
-	create_tce_tables();
+	iommu_setup_pSeries();
 }
 
 /*********************************************************************** 
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pci.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pci.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pci.c	2004-02-12 04:24:38.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pci.c	2004-02-27 23:02:35.000000000 +0000
@@ -33,7 +33,7 @@
 #include <asm/uaccess.h>
 #include <asm/ppcdebug.h>
 #include <asm/naca.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 #include <asm/machdep.h>
 
 #include "pci.h"
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pci_dma.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pci_dma.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pci_dma.c	2004-02-27 05:25:15.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pci_dma.c	1970-01-01 00:00:00.000000000 +0000
@@ -1,1492 +0,0 @@
-/*
- * pci_dma.c
- * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
- *
- * Dynamic DMA mapping support.
- * 
- * Manages the TCE space assigned to this partition.
- * 
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- * 
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- * 
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
- */
-
-#include <linux/config.h>
-#include <linux/init.h>
-#include <linux/types.h>
-#include <linux/slab.h>
-#include <linux/mm.h>
-#include <linux/spinlock.h>
-#include <linux/string.h>
-#include <linux/pci.h>
-#include <asm/io.h>
-#include <asm/prom.h>
-#include <asm/rtas.h>
-#include <asm/ppcdebug.h>
-
-#include <asm/iSeries/HvCallXm.h>
-#include <asm/iSeries/LparData.h>
-#include <asm/pci_dma.h>
-#include <asm/pci-bridge.h>
-#include <asm/iSeries/iSeries_pci.h>
-
-#include <asm/machdep.h>
-
-#include "pci.h"
-
-/* #define DEBUG_TCE 1   */
-/* #define MONITOR_TCE 1 */ /* Turn on to sanity check TCE generation. */
-
-
-#ifdef CONFIG_PPC_PSERIES
-/* Initialize so this guy does not end up in the BSS section.
- * Only used to pass OF initialization data set in prom.c into the main 
- * kernel code -- data ultimately copied into tceTables[].
- */
-extern struct _of_tce_table of_tce_table[];
-#endif
-
-extern struct pci_controller* hose_head;
-extern struct pci_controller** hose_tail;
-extern struct list_head iSeries_Global_Device_List;
-
-struct TceTable   virtBusVethTceTable;	/* Tce table for virtual ethernet */
-struct TceTable   virtBusVioTceTable;	/* Tce table for virtual I/O */
-
-struct iSeries_Device_Node iSeries_veth_dev_node = { .LogicalSlot = 0xFF, .DevTceTable = &virtBusVethTceTable };
-struct iSeries_Device_Node iSeries_vio_dev_node  = { .LogicalSlot = 0xFF, .DevTceTable = &virtBusVioTceTable };
-
-struct pci_dev    iSeries_veth_dev_st = { .sysdata = &iSeries_veth_dev_node };
-struct pci_dev    iSeries_vio_dev_st  = { .sysdata = &iSeries_vio_dev_node, .dev.bus = &pci_bus_type };
-
-struct pci_dev  * iSeries_veth_dev = &iSeries_veth_dev_st;
-struct device  * iSeries_vio_dev  = &iSeries_vio_dev_st.dev;
-
-/* Device TceTable is stored in Device Node */
-/* struct TceTable * tceTables[256]; */	/* Tce tables for 256 busses
-					 * Bus 255 is the virtual bus
-					 * zero indicates no bus defined
-					 */
-/* allocates a contiguous range of tces (power-of-2 size) */
-static inline long alloc_tce_range(struct TceTable *, 
-				   unsigned order );
-
-/* allocates a contiguous range of tces (power-of-2 size)
- * assumes lock already held
- */
-static long alloc_tce_range_nolock(struct TceTable *, 
-				   unsigned order );
-
-/* frees a contiguous range of tces (power-of-2 size) */
-static inline void free_tce_range(struct TceTable *, 
-				  long tcenum, 
-				  unsigned order );
-
-/* frees a contiguous rnage of tces (power-of-2 size)
- * assumes lock already held
- */
-void free_tce_range_nolock(struct TceTable *, 
-			   long tcenum, 
-			   unsigned order );
-
-/* allocates a range of tces and sets them to the pages  */
-inline dma_addr_t get_tces( struct TceTable *, 
-				   unsigned order, 
-				   void *page, 
-				   unsigned numPages,
-				   int direction );
-
-static long test_tce_range( struct TceTable *, 
-			    long tcenum, 
-			    unsigned order );
-
-static void getTceTableParmsiSeries(struct iSeries_Device_Node* DevNode,
-				      struct TceTable *tce_table_parms );
-
-static void getTceTableParmsPSeries( struct pci_controller *phb, 
-				     struct device_node *dn,
-				     struct TceTable *tce_table_parms );
-
-static void getTceTableParmsPSeriesLP(struct pci_controller *phb,
-				    struct device_node *dn,
-				    struct TceTable *newTceTable );
-
-static struct TceTable* findHwTceTable(struct TceTable * newTceTable );
-
-void create_pci_bus_tce_table( unsigned long token );
-
-u8 iSeries_Get_Bus( struct pci_dev * dv )
-{
-	return 0;
-}
-
-static inline struct TceTable *get_tce_table(struct pci_dev *dev)
-{
-	if (!dev)
-		dev = ppc64_isabridge_dev;
-	if (!dev)
-		return NULL;
-	if (systemcfg->platform == PLATFORM_ISERIES_LPAR) {
- 		return ISERIES_DEVNODE(dev)->DevTceTable;
-	} else {
-		return PCI_GET_DN(dev)->tce_table;
-	}
-}
-
-static unsigned long __inline__ count_leading_zeros64( unsigned long x )
-{
-	unsigned long lz;
-	asm("cntlzd %0,%1" : "=r"(lz) : "r"(x));
-	return lz;
-}
-
-#ifdef CONFIG_PPC_ISERIES
-static void tce_build_iSeries(struct TceTable *tbl, long tcenum, 
-			       unsigned long uaddr, int direction )
-{
-	u64 setTceRc;
-	union Tce tce;
-	
-	PPCDBG(PPCDBG_TCE, "build_tce: uaddr = 0x%lx\n", uaddr);
-	PPCDBG(PPCDBG_TCE, "\ttcenum = 0x%lx, tbl = 0x%lx, index=%lx\n", 
-	       tcenum, tbl, tbl->index);
-
-	tce.wholeTce = 0;
-	tce.tceBits.rpn = (virt_to_absolute(uaddr)) >> PAGE_SHIFT;
-
-	/* If for virtual bus */
-	if ( tbl->tceType == TCE_VB ) {
-		tce.tceBits.valid = 1;
-		tce.tceBits.allIo = 1;
-		if ( direction != PCI_DMA_TODEVICE )
-			tce.tceBits.readWrite = 1;
-	} else {
-		/* If for PCI bus */
-		tce.tceBits.readWrite = 1; // Read allowed 
-		if ( direction != PCI_DMA_TODEVICE )
-			tce.tceBits.pciWrite = 1;
-	}
-
-	setTceRc = HvCallXm_setTce((u64)tbl->index, 
-				   (u64)tcenum, 
-				   tce.wholeTce );
-	if(setTceRc) {
-		panic("PCI_DMA: HvCallXm_setTce failed, Rc: 0x%lx\n", setTceRc);
-	}
-}
-#endif
-
-#ifdef CONFIG_PPC_PSERIES
-static void tce_build_pSeries(struct TceTable *tbl, long tcenum, 
-			       unsigned long uaddr, int direction )
-{
-	union Tce tce;
-	union Tce *tce_addr;
-	
-	PPCDBG(PPCDBG_TCE, "build_tce: uaddr = 0x%lx\n", uaddr);
-	PPCDBG(PPCDBG_TCE, "\ttcenum = 0x%lx, tbl = 0x%lx, index=%lx\n", 
-	       tcenum, tbl, tbl->index);
-
-	tce.wholeTce = 0;
-	tce.tceBits.rpn = (virt_to_absolute(uaddr)) >> PAGE_SHIFT;
-
-	tce.tceBits.readWrite = 1; // Read allowed 
-	if ( direction != PCI_DMA_TODEVICE ) tce.tceBits.pciWrite = 1;
-
-	tce_addr = ((union Tce *)tbl->base) + tcenum;
-	*tce_addr = (union Tce)tce.wholeTce;
-}
-#endif
-
-/* 
- * Build a TceTable structure.  This contains a multi-level bit map which
- * is used to manage allocation of the tce space.
- */
-struct TceTable *build_tce_table( struct TceTable * tbl )
-{
-	unsigned long bits, bytes, totalBytes;
-	unsigned long numBits[NUM_TCE_LEVELS], numBytes[NUM_TCE_LEVELS];
-	unsigned i, k, m;
-	unsigned char * pos, * p, b;
-
-	PPCDBG(PPCDBG_TCEINIT, "build_tce_table: tbl = 0x%lx\n", tbl);
-	spin_lock_init( &(tbl->lock) );
-	
-	tbl->mlbm.maxLevel = 0;
-
-	/* Compute number of bits and bytes for each level of the
-	 * multi-level bit map
-	 */ 
-	totalBytes = 0;
-	bits = tbl->size * (PAGE_SIZE / sizeof( union Tce ));
-	
-	for ( i=0; i<NUM_TCE_LEVELS; ++i ) {
-		bytes = ((bits+63)/64) * 8;
-		PPCDBG(PPCDBG_TCEINIT, "build_tce_table: level %d bits=%ld, bytes=%ld\n", i, bits, bytes );
-		numBits[i] = bits;
-		numBytes[i] = bytes;
-		bits /= 2;
-		totalBytes += bytes;
-	}
-	PPCDBG(PPCDBG_TCEINIT, "build_tce_table: totalBytes=%ld\n", totalBytes );
-	
-	pos = (char *)__get_free_pages( GFP_ATOMIC, get_order( totalBytes ));
- 
-	if ( pos == NULL ) {
-		panic("PCI_DMA: Allocation failed in build_tce_table!\n");
-	}
-
-	/* For each level, fill in the pointer to the bit map,
-	 * and turn on the last bit in the bit map (if the
-	 * number of bits in the map is odd).  The highest
-	 * level will get all of its bits turned on.
-	 */
-	memset( pos, 0, totalBytes );
-	for (i=0; i<NUM_TCE_LEVELS; ++i) {
-		if ( numBytes[i] ) {
-			tbl->mlbm.level[i].map = pos;
-			tbl->mlbm.maxLevel = i;
-
-			if ( numBits[i] & 1 ) {
-				p = pos + numBytes[i] - 1;
-				m = (( numBits[i] % 8) - 1) & 7;
-				*p = 0x80 >> m;
-				PPCDBG(PPCDBG_TCEINIT, "build_tce_table: level %d last bit %x\n", i, 0x80>>m );
-			}
-		}
-		else
-			tbl->mlbm.level[i].map = 0;
-		pos += numBytes[i];
-		tbl->mlbm.level[i].numBits = numBits[i];
-		tbl->mlbm.level[i].numBytes = numBytes[i];
-	}
-
-	/* For the highest level, turn on all the bits */
-	
-	i = tbl->mlbm.maxLevel;
-	p = tbl->mlbm.level[i].map;
-	m = numBits[i];
-	PPCDBG(PPCDBG_TCEINIT, "build_tce_table: highest level (%d) has all bits set\n", i);
-	for (k=0; k<numBytes[i]; ++k) {
-		if ( m >= 8 ) {
-			/* handle full bytes */
-			*p++ = 0xff;
-			m -= 8;
-		}
-		else if(m>0) {
-			/* handle the last partial byte */
-			b = 0x80;
-			*p = 0;
-			while (m) {
-				*p |= b;
-				b >>= 1;
-				--m;
-			}
-		} else {
-			break;
-		}
-	}
-
-	return tbl;
-}
-
-static inline long alloc_tce_range( struct TceTable *tbl, unsigned order )
-{
-	long retval;
-	unsigned long flags;
-	
-	/* Lock the tce allocation bitmap */
-	spin_lock_irqsave( &(tbl->lock), flags );
-
-	/* Do the actual work */
-	retval = alloc_tce_range_nolock( tbl, order );
-	
-	/* Unlock the tce allocation bitmap */
-	spin_unlock_irqrestore( &(tbl->lock), flags );
-
-	return retval;
-}
-
-static long alloc_tce_range_nolock( struct TceTable *tbl, unsigned order )
-{
-	unsigned long numBits, numBytes;
-	unsigned long i, bit, block, mask;
-	long tcenum;
-	u64 * map;
-
-	/* If the order (power of 2 size) requested is larger than our
-	 * biggest, indicate failure
-	 */
-	if(order >= NUM_TCE_LEVELS) {
-		/* This can happen if block of TCE's are not found. This code      */
-		/*  maybe in a recursive loop looking up the bit map for the range.*/
-		panic("PCI_DMA: alloc_tce_range_nolock: invalid order: %d\n",order);
-	}
-	
-	numBits =  tbl->mlbm.level[order].numBits;
-	numBytes = tbl->mlbm.level[order].numBytes;
-	map =      (u64 *)tbl->mlbm.level[order].map;
-
-	/* Initialize return value to -1 (failure) */
-	tcenum = -1;
-
-	/* Loop through the bytes of the bitmap */
-	for (i=0; i<numBytes/8; ++i) {
-		if ( *map ) {
-			/* A free block is found, compute the block
-			 * number (of this size)
-			 */
-			bit = count_leading_zeros64( *map );
-			block = (i * 64) + bit;    /* Bit count to free entry */
-
-			/* turn off the bit in the map to indicate
-			 * that the block is now in use
-			 */
-			mask = 0x1UL << (63 - bit);
-			*map &= ~mask;
-
-			/* compute the index into our tce table for
-			 * the first tce in the block
-			 */
-			PPCDBG(PPCDBG_TCE, "alloc_tce_range_nolock: allocating block %ld, (byte=%ld, bit=%ld) order %d\n", block, i, bit, order );
-			tcenum = block << order;
-			return tcenum;
-		}
-		++map;
-	}
-
-#ifdef DEBUG_TCE
-	if ( tcenum == -1 ) {
-		PPCDBG(PPCDBG_TCE, "alloc_tce_range_nolock: no available blocks of order = %d\n", order );
-		if ( order < tbl->mlbm.maxLevel ) {
-			PPCDBG(PPCDBG_TCE, "alloc_tce_range_nolock: trying next bigger size\n" );
-		}
-		else {
-			panic("PCI_DMA: alloc_tce_range_nolock: maximum size reached...failing\n");
-		}
-	}
-#endif	
-	
-	/* If no block of the requested size was found, try the next
-	 * size bigger.  If one of those is found, return the second
-	 * half of the block to freespace and keep the first half
-	 */
-	if((tcenum == -1) && (order < (NUM_TCE_LEVELS - 1))) {
-		tcenum = alloc_tce_range_nolock( tbl, order+1 );
-		if ( tcenum != -1 ) {
-			free_tce_range_nolock( tbl, tcenum+(1<<order), order );
-		}
-	}
-	
-	/* Return the index of the first tce in the block
-	 * (or -1 if we failed)
-	 */
-	return tcenum;
-}
-
-static inline void free_tce_range(struct TceTable *tbl, 
-				  long tcenum, unsigned order )
-{
-	unsigned long flags;
-
-	/* Lock the tce allocation bitmap */
-	spin_lock_irqsave( &(tbl->lock), flags );
-
-	/* Do the actual work */
-	free_tce_range_nolock( tbl, tcenum, order );
-	
-	/* Unlock the tce allocation bitmap */
-	spin_unlock_irqrestore( &(tbl->lock), flags );
-
-}
-
-void free_tce_range_nolock(struct TceTable *tbl, 
-			   long tcenum, unsigned order )
-{
-	unsigned long block;
-	unsigned byte, bit, mask, b;
-	unsigned char  * map, * bytep;
-
-	if (order >= NUM_TCE_LEVELS) {
-		panic("PCI_DMA: free_tce_range: invalid order: 0x%x\n",order);
-		return;
-	}
-
-	block = tcenum >> order;
-
-#ifdef MONITOR_TCE
-	if ( tcenum != (block << order ) ) {
-		printk("PCI_DMA: Free_tce_range: tcenum %lx misaligned for order %x\n",tcenum, order);
-		return;
-	}
-	if ( block >= tbl->mlbm.level[order].numBits ) {
-		printk("PCI_DMA: Free_tce_range: tcenum %lx is outside the range of this map (order %x, numBits %lx\n", 
-		       tcenum, order, tbl->mlbm.level[order].numBits );
-		return;
-	}
-	if ( test_tce_range( tbl, tcenum, order ) ) {
-		printk("PCI_DMA: Freeing range not allocated: tTceTable %p, tcenum %lx, order %x\n",tbl, tcenum, order );
-		return;
-	}
-#endif
-
-	map = tbl->mlbm.level[order].map;
-	byte  = block / 8;
-	bit   = block % 8;
-	mask  = 0x80 >> bit;
-	bytep = map + byte;
-
-#ifdef DEBUG_TCE
-	PPCDBG(PPCDBG_TCE,"free_tce_range_nolock: freeing block %ld (byte=%d, bit=%d) of order %d\n",
-	       block, byte, bit, order);
-#endif	
-
-#ifdef MONITOR_TCE
-	if ( *bytep & mask ) {
-		panic("PCI_DMA: Tce already free: TceTable %p, tcenum %lx, order %x\n",tbl,tcenum,order);
-	}
-#endif	
-
-	*bytep |= mask;
-
-	/* If there is a higher level in the bit map than this we may be
-	 * able to buddy up this block with its partner.
-	 *   If this is the highest level we can't buddy up
-	 *   If this level has an odd number of bits and
-	 *      we are freeing the last block we can't buddy up
-	 * Don't buddy up if it's in the first 1/4 of the level
-	 */
-	if (( order < tbl->mlbm.maxLevel ) &&
-	    ( block > (tbl->mlbm.level[order].numBits/4) ) &&
-	    (( block < tbl->mlbm.level[order].numBits-1 ) ||
-	      ( 0 == ( tbl->mlbm.level[order].numBits & 1)))) {
-		/* See if we can buddy up the block we just freed */
-		bit  &= 6;		/* get to the first of the buddy bits */
-		mask  = 0xc0 >> bit;	/* build two bit mask */
-		b     = *bytep & mask;	/* Get the two bits */
-		if ( 0 == (b ^ mask) ) { /* If both bits are on */
-			/* both of the buddy blocks are free we can combine them */
-			*bytep ^= mask;	/* turn off the two bits */
-			block = ( byte * 8 ) + bit; /* block of first of buddies */
-			tcenum = block << order;
-			/* free the buddied block */
-			PPCDBG(PPCDBG_TCE, 
-			       "free_tce_range: buddying blocks %ld & %ld\n",
-			       block, block+1);
-			free_tce_range_nolock( tbl, tcenum, order+1 ); 
-		}	
-	}
-}
-
-static long test_tce_range( struct TceTable *tbl, long tcenum, unsigned order )
-{
-	unsigned long block;
-	unsigned byte, bit, mask, b;
-	long	retval, retLeft, retRight;
-	unsigned char  * map;
-	
-	map = tbl->mlbm.level[order].map;
-	block = tcenum >> order;
-	byte = block / 8;		/* Byte within bitmap */
-	bit  = block % 8;		/* Bit within byte */
-	mask = 0x80 >> bit;		
-	b    = (*(map+byte) & mask );	/* 0 if block is allocated, else free */
-	if ( b ) 
-		retval = 1;		/* 1 == block is free */
-	else
-		retval = 0;		/* 0 == block is allocated */
-	/* Test bits at all levels below this to ensure that all agree */
-
-	if (order) {
-		retLeft  = test_tce_range( tbl, tcenum, order-1 );
-		retRight = test_tce_range( tbl, tcenum+(1<<(order-1)), order-1 );
-		if ( retLeft || retRight ) {
-			retval = 2;		
-		}
-	}
-
-	/* Test bits at all levels above this to ensure that all agree */
-	
-	return retval;
-}
-
-inline dma_addr_t get_tces( struct TceTable *tbl, unsigned order, void *page, unsigned numPages, int direction )
-{
-	long tcenum;
-	unsigned long uaddr;
-	unsigned i;
-	dma_addr_t retTce = NO_TCE;
-
-	uaddr = (unsigned long)page & PAGE_MASK;
-	
-	/* Allocate a range of tces */
-	tcenum = alloc_tce_range( tbl, order );
-	if ( tcenum != -1 ) {
-		/* We got the tces we wanted */
-		tcenum += tbl->startOffset;	/* Offset into real TCE table */
-		retTce = tcenum << PAGE_SHIFT;	/* Set the return dma address */
-		/* Setup a tce for each page */
-		for (i=0; i<numPages; ++i) {
-			ppc_md.tce_build(tbl, tcenum, uaddr, direction); 
-			++tcenum;
-			uaddr += PAGE_SIZE;
-		}
-		/* Make sure the update is visible to hardware. 
-		   sync required to synchronize the update to 
-		   the TCE table with the MMIO that will send
-		   the bus address to the IOA */
-		__asm__ __volatile__ ("sync" : : : "memory");
-	}
-	else {
-		panic("PCI_DMA: Tce Allocation failure in get_tces. 0x%p\n",tbl);
-	}
-
-	return retTce; 
-}
-
-#ifdef CONFIG_PPC_ISERIES
-void tce_free_one_iSeries( struct TceTable *tbl, long tcenum )
-{
-	u64 set_tce_rc;
-	union Tce tce;
-	tce.wholeTce = 0;
-	set_tce_rc = HvCallXm_setTce((u64)tbl->index,
-				   (u64)tcenum,
-				   tce.wholeTce);
-	if ( set_tce_rc ) 
-		panic("PCI_DMA: HvCallXm_setTce failed, Rc: 0x%lx\n", set_tce_rc);
-
-}
-#endif
-
-#ifdef CONFIG_PPC_PSERIES
-static void tce_free_one_pSeries( struct TceTable *tbl, long tcenum )
-{
-	union Tce tce;
-	union Tce *tce_addr;
-
-	tce.wholeTce = 0;
-
-	tce_addr  = ((union Tce *)tbl->base) + tcenum;
-	*tce_addr = (union Tce)tce.wholeTce;
-
-}
-#endif
-
-void tce_free(struct TceTable *tbl, dma_addr_t dma_addr, 
-			     unsigned order, unsigned num_pages)
-{
-	long tcenum, total_tces, free_tce;
-	unsigned i;
-
-	total_tces = (tbl->size * (PAGE_SIZE / sizeof(union Tce)));
-	
-	tcenum = dma_addr >> PAGE_SHIFT;
-	free_tce = tcenum - tbl->startOffset;
-
-	if ( ( (free_tce + num_pages) > total_tces ) ||
-	     ( tcenum < tbl->startOffset ) ) {
-		printk("tce_free: invalid tcenum\n");
-		printk("\ttcenum    = 0x%lx\n", tcenum); 
-		printk("\tTCE Table = 0x%lx\n", (u64)tbl);
-		printk("\tbus#      = 0x%lx\n", (u64)tbl->busNumber );
-		printk("\tsize      = 0x%lx\n", (u64)tbl->size);
-		printk("\tstartOff  = 0x%lx\n", (u64)tbl->startOffset );
-		printk("\tindex     = 0x%lx\n", (u64)tbl->index);
-		return;
-	}
-	
-	for (i=0; i<num_pages; ++i) {
-		ppc_md.tce_free_one(tbl, tcenum);
-		++tcenum;
-	}
-
-	/* No sync (to make TCE change visible) is required here.
-	   The lwsync when acquiring the lock in free_tce_range
-	   is sufficient to synchronize with the bitmap.
-	*/
-
-	free_tce_range( tbl, free_tce, order );
-}
-
-#ifdef CONFIG_PPC_ISERIES
-void __init create_virtual_bus_tce_table(void)
-{
-	struct TceTable *t;
-	struct TceTableManagerCB virtBusTceTableParms;
-	u64 absParmsPtr;
-
-	virtBusTceTableParms.busNumber = 255;	/* Bus 255 is the virtual bus */
-	virtBusTceTableParms.virtualBusFlag = 0xff; /* Ask for virtual bus */
-	
-	absParmsPtr = virt_to_absolute( (u64)&virtBusTceTableParms );
-	HvCallXm_getTceTableParms( absParmsPtr );
-	
-	virtBusVethTceTable.size = virtBusTceTableParms.size / 2;
-	virtBusVethTceTable.busNumber = virtBusTceTableParms.busNumber;
-	virtBusVethTceTable.startOffset = virtBusTceTableParms.startOffset;
-	virtBusVethTceTable.index = virtBusTceTableParms.index;
-	virtBusVethTceTable.tceType = TCE_VB;
-
-	virtBusVioTceTable.size = virtBusTceTableParms.size - virtBusVethTceTable.size;
-	virtBusVioTceTable.busNumber = virtBusTceTableParms.busNumber;
-	virtBusVioTceTable.startOffset = virtBusTceTableParms.startOffset +
-			virtBusVethTceTable.size * (PAGE_SIZE/sizeof(union Tce));
-	virtBusVioTceTable.index = virtBusTceTableParms.index;
-	virtBusVioTceTable.tceType = TCE_VB; 
-
-	t = build_tce_table( &virtBusVethTceTable );
-	if ( t ) {
-		/* tceTables[255] = t; */
-		//VirtBusVethTceTable = t;
-		printk( "Virtual Bus VETH TCE table built successfully.\n");
-		printk( "  TCE table size = %ld entries\n", 
-				(unsigned long)t->size*(PAGE_SIZE/sizeof(union Tce)) );
-		printk( "  TCE table token = %d\n",
-				(unsigned)t->index );
-		printk( "  TCE table start entry = 0x%lx\n",
-				(unsigned long)t->startOffset );
-	}
-	else printk( "Virtual Bus VETH TCE table failed.\n");
-
-	t = build_tce_table( &virtBusVioTceTable );
-	if ( t ) {
-		//VirtBusVioTceTable = t;
-		printk( "Virtual Bus VIO TCE table built successfully.\n");
-		printk( "  TCE table size = %ld entries\n", 
-				(unsigned long)t->size*(PAGE_SIZE/sizeof(union Tce)) );
-		printk( "  TCE table token = %d\n",
-				(unsigned)t->index );
-		printk( "  TCE table start entry = 0x%lx\n",
-				(unsigned long)t->startOffset );
-	}
-	else printk( "Virtual Bus VIO TCE table failed.\n");
-}
-#endif
-
-void create_tce_tables_for_buses(struct list_head *bus_list)
-{
-	struct pci_controller* phb;
-	struct device_node *dn, *first_dn;
-	int num_slots, num_slots_ilog2;
-	int first_phb = 1;
-
-	for (phb=hose_head;phb;phb=phb->next) {
-		first_dn = ((struct device_node *)phb->arch_data)->child;
-		/* Carve 2GB into the largest dma_window_size possible */
-		for (dn = first_dn, num_slots = 0; dn != NULL; dn = dn->sibling)
-			num_slots++;
-		num_slots_ilog2 = __ilog2(num_slots);
-		if ((1<<num_slots_ilog2) != num_slots)
-			num_slots_ilog2++;
-		phb->dma_window_size = 1 << (22 - num_slots_ilog2);
-		/* Reserve 16MB of DMA space on the first PHB.
-		 * We should probably be more careful and use firmware props.
-		 * In reality this space is remapped, not lost.  But we don't
-		 * want to get that smart to handle it -- too much work.
-		 */
-		phb->dma_window_base_cur = first_phb ? (1 << 12) : 0;
-		first_phb = 0;
-		for (dn = first_dn, num_slots = 0; dn != NULL; dn = dn->sibling) {
-			create_pci_bus_tce_table((unsigned long)dn);
-		}
-	}
-}
-
-#ifdef CONFIG_PPC_PSERIES
-void create_tce_tables_for_busesLP(struct list_head *bus_list)
-{
-	struct list_head *ln;
-	struct pci_bus *bus;
-	struct device_node *busdn;
-	u32 *dma_window;
-	for (ln=bus_list->next; ln != bus_list; ln=ln->next) {
-		bus = pci_bus_b(ln);
-		busdn = PCI_GET_DN(bus);
-		dma_window = (u32 *)get_property(busdn, "ibm,dma-window", 0);
-		if (dma_window) {
-			/* Bussubno hasn't been copied yet.
-			 * Do it now because getTceTableParmsPSeriesLP needs it.
-			 */
-			busdn->bussubno = bus->number;
-			create_pci_bus_tce_table((unsigned long)busdn);
-		}
-		/* look for a window on a bridge even if the PHB had one */
-		create_tce_tables_for_busesLP(&bus->children);
-	}
-}
-#endif
-
-void create_tce_tables(void) {
-	struct pci_dev *dev = NULL;
-	struct device_node *dn, *mydn;
-
-#ifdef CONFIG_PPC_PSERIES
-	if (systemcfg->platform == PLATFORM_PSERIES_LPAR) {
-		create_tce_tables_for_busesLP(&pci_root_buses);
-	}
-	else
-#endif
-	{
-		create_tce_tables_for_buses(&pci_root_buses);
-	}
-	/* Now copy the tce_table ptr from the bus devices down to every
-	 * pci device_node.  This means get_tce_table() won't need to search
-	 * up the device tree to find it.
-	 */
-	while ((dev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL) {
-		mydn = dn = PCI_GET_DN(dev);
-		while (dn && dn->tce_table == NULL)
-			dn = dn->parent;
-		if (dn) {
-			mydn->tce_table = dn->tce_table;
-		}
-	}
-}
-
-
-/*
- * iSeries token = iSeries_device_Node*
- * pSeries token = pci_controller*
- *
- */
-void create_pci_bus_tce_table( unsigned long token ) {
-	struct TceTable * newTceTable;
-
-	PPCDBG(PPCDBG_TCE, "Entering create_pci_bus_tce_table.\n");
-	PPCDBG(PPCDBG_TCE, "\ttoken = 0x%lx\n", token);
-
-	newTceTable = (struct TceTable *)kmalloc( sizeof(struct TceTable), GFP_KERNEL );
-
-	/*****************************************************************/
- 	/* For the iSeries machines, the HvTce Table can be one of three */
- 	/* flavors,                                                      */
- 	/* - Single bus TCE table,                                       */
- 	/* - Tce Table Share between buses,                              */
- 	/* - Tce Table per logical slot.                                 */
-	/*****************************************************************/
-	if(systemcfg->platform == PLATFORM_ISERIES_LPAR) {
-
-		struct iSeries_Device_Node* DevNode = (struct iSeries_Device_Node*)token;
-		getTceTableParmsiSeries(DevNode,newTceTable);
-
-		/* Look for existing TCE table for this device.          */
-		DevNode->DevTceTable = findHwTceTable(newTceTable );
-		if( DevNode->DevTceTable == NULL) {
-			DevNode->DevTceTable = build_tce_table( newTceTable );
-		}
-		else {
-		    /* We're using a shared table, free this new one.    */
-		    kfree(newTceTable);
-		}
-		printk("Pci Device 0x%p TceTable: %p\n",DevNode,DevNode->DevTceTable);
- 		return;
-	}
-	/* pSeries Leg */
-	else {
-		struct device_node *dn;
-		struct pci_controller *phb;
-
-		dn = (struct device_node *)token;
-		phb = dn->phb;
-		if (systemcfg->platform == PLATFORM_PSERIES)
-			getTceTableParmsPSeries(phb, dn, newTceTable);
-		else
-			getTceTableParmsPSeriesLP(phb, dn, newTceTable);
-
-		dn->tce_table  = build_tce_table( newTceTable );
-	}
-}
-
-/***********************************************************************/
-/* This function compares the known Tce tables to find a TceTable that */
-/* has already been built for hardware TCEs.                           */
-/* Search the complete(all devices) for a TCE table assigned.  If the  */
-/* startOffset, index, and size match, then the TCE for this device has*/
-/* already been built and it should be shared with this device         */
-/***********************************************************************/
-static struct TceTable* findHwTceTable(struct TceTable * newTceTable )
-{
-#ifdef CONFIG_PPC_ISERIES
-	struct list_head* Device_Node_Ptr    = iSeries_Global_Device_List.next;
-	/* Cache the compare values. */
-	u64  startOffset = newTceTable->startOffset;
-	u64  index       = newTceTable->index;
-	u64  size        = newTceTable->size;
-
-	while(Device_Node_Ptr != &iSeries_Global_Device_List) {
-		struct iSeries_Device_Node* CmprNode = (struct iSeries_Device_Node*)Device_Node_Ptr;
-		if( CmprNode->DevTceTable != NULL &&
-		    CmprNode->DevTceTable->tceType == TCE_PCI) {
-			if( CmprNode->DevTceTable->startOffset == startOffset &&
-			    CmprNode->DevTceTable->index       == index       &&
-			    CmprNode->DevTceTable->size        == size        ) {
-				printk("PCI TCE table matches 0x%p \n",CmprNode->DevTceTable);
-				return CmprNode->DevTceTable;
-			}
-		}
-		/* Get next Device Node in List             */
-		Device_Node_Ptr = Device_Node_Ptr->next;
-	}
-#endif
-	return NULL;
-}
-
-/***********************************************************************/
-/* Call Hv with the architected data structure to get TCE table info.  */
-/* info. Put the returned data into the Linux representation of the    */
-/* TCE table data.                                                     */
-/* The Hardware Tce table comes in three flavors.                      */ 
-/* 1. TCE table shared between Buses.                                  */
-/* 2. TCE table per Bus.                                               */
-/* 3. TCE Table per IOA.                                               */
-/***********************************************************************/
-static void getTceTableParmsiSeries(struct iSeries_Device_Node* DevNode,
-				    struct TceTable* newTceTable )
-{
-#ifdef CONFIG_PPC_ISERIES
-	struct TceTableManagerCB* pciBusTceTableParms = (struct TceTableManagerCB*)kmalloc( sizeof(struct TceTableManagerCB), GFP_KERNEL );
-	if(pciBusTceTableParms == NULL) panic("PCI_DMA: TCE Table Allocation failed.");
-
-	memset( (void*)pciBusTceTableParms,0,sizeof(struct TceTableManagerCB) );
-	pciBusTceTableParms->busNumber      = ISERIES_BUS(DevNode);
-	pciBusTceTableParms->logicalSlot    = DevNode->LogicalSlot;
-	pciBusTceTableParms->virtualBusFlag = 0;
-
-	HvCallXm_getTceTableParms( REALADDR(pciBusTceTableParms) );
-
-        /* PciTceTableParms Bus:0x18 Slot:0x04 Start:0x000000 Offset:0x04c000 Size:0x0020 */
-	printk("PciTceTableParms Bus:0x%02lx Slot:0x%02x Start:0x%06lx Offset:0x%06lx Size:0x%04lx\n",
-	       pciBusTceTableParms->busNumber,
-	       pciBusTceTableParms->logicalSlot,
-	       pciBusTceTableParms->start,
-	       pciBusTceTableParms->startOffset,
-	       pciBusTceTableParms->size);
-
-	if(pciBusTceTableParms->size == 0) {
-		printk("PCI_DMA: Possible Structure mismatch, 0x%p\n",pciBusTceTableParms);
-		panic( "PCI_DMA: pciBusTceTableParms->size is zero, halt here!");
-	}
-
-	newTceTable->size        = pciBusTceTableParms->size;
-	newTceTable->busNumber   = pciBusTceTableParms->busNumber;
-	newTceTable->startOffset = pciBusTceTableParms->startOffset;
-	newTceTable->index       = pciBusTceTableParms->index;
-	newTceTable->tceType     = TCE_PCI;
-
-	kfree(pciBusTceTableParms);
-#endif
-}
-
-static void getTceTableParmsPSeries(struct pci_controller *phb,
-				    struct device_node *dn,
-				    struct TceTable *newTceTable ) {
-#ifdef CONFIG_PPC_PSERIES
-	phandle node;
-	unsigned long i;
-
-	node = ((struct device_node *)(phb->arch_data))->node;
-
-	PPCDBG(PPCDBG_TCEINIT, "getTceTableParms: start\n"); 
-	PPCDBG(PPCDBG_TCEINIT, "\tof_tce_table = 0x%lx\n", of_tce_table); 
-	PPCDBG(PPCDBG_TCEINIT, "\tphb          = 0x%lx\n", phb); 
-	PPCDBG(PPCDBG_TCEINIT, "\tdn           = 0x%lx\n", dn); 
-	PPCDBG(PPCDBG_TCEINIT, "\tdn->name     = %s\n", dn->name); 
-	PPCDBG(PPCDBG_TCEINIT, "\tdn->full_name= %s\n", dn->full_name); 
-	PPCDBG(PPCDBG_TCEINIT, "\tnewTceTable  = 0x%lx\n", newTceTable); 
-	PPCDBG(PPCDBG_TCEINIT, "\tdma_window_size = 0x%lx\n", phb->dma_window_size); 
-
-	i = 0;
-	while(of_tce_table[i].node) {
-		PPCDBG(PPCDBG_TCEINIT, "\tof_tce_table[%d].node = 0x%lx\n", 
-		       i, of_tce_table[i].node);
-		PPCDBG(PPCDBG_TCEINIT, "\tof_tce_table[%d].base = 0x%lx\n", 
-		       i, of_tce_table[i].base);
-		PPCDBG(PPCDBG_TCEINIT, "\tof_tce_table[%d].size = 0x%lx\n", 
-		       i, of_tce_table[i].size >> PAGE_SHIFT);
-		PPCDBG(PPCDBG_TCEINIT, "\tphb->arch_data->node = 0x%lx\n", 
-		       node);
-
-		if(of_tce_table[i].node == node) {
-			memset((void *)of_tce_table[i].base, 
-			       0, of_tce_table[i].size);
-			newTceTable->busNumber = phb->bus->number;
-
-			/* Units of tce entries.                        */
-			newTceTable->startOffset = phb->dma_window_base_cur;
-
-			/* Adjust the current table offset to the next  */
-			/* region.  Measured in TCE entries. Force an   */
-			/* alignment to the size alloted per IOA. This  */
-			/* makes it easier to remove the 1st 16MB.      */
-			phb->dma_window_base_cur += (phb->dma_window_size>>3);
-			phb->dma_window_base_cur &= 
-				~((phb->dma_window_size>>3)-1);
-
-			/* Set the tce table size - measured in units   */
-			/* of pages of tce table.                       */
-			newTceTable->size = ((phb->dma_window_base_cur -
-					      newTceTable->startOffset) << 3)
-					      >> PAGE_SHIFT;
-
-			/* Test if we are going over 2GB of DMA space.  */
-			if(phb->dma_window_base_cur > (1 << 19)) { 
-				panic("PCI_DMA: Unexpected number of IOAs under this PHB.\n"); 
-			}
-
-			newTceTable->base = of_tce_table[i].base;
-			newTceTable->index = 0;
-			
-			PPCDBG(PPCDBG_TCEINIT, 
-			       "\tnewTceTable->base        = 0x%lx\n",
-			       newTceTable->base);
-			PPCDBG(PPCDBG_TCEINIT, 
-			       "\tnewTceTable->startOffset = 0x%lx"
-			       "(# tce entries)\n", 
-			       newTceTable->startOffset);
-			PPCDBG(PPCDBG_TCEINIT, 
-			       "\tnewTceTable->size        = 0x%lx"
-			       "(# pages of tce table)\n", 
-			       newTceTable->size);
-		}
-		i++;
-	}
-#endif
-}
-
-/*
- * getTceTableParmsPSeriesLP
- *
- * Function: On pSeries LPAR systems, return TCE table info, given a pci bus.
- *
- * ToDo: properly interpret the ibm,dma-window property.  The definition is:
- *	logical-bus-number	(1 word)
- *	phys-address		(#address-cells words)
- *	size			(#cell-size words)
- *
- * Currently we hard code these sizes (more or less).
- */
-static void getTceTableParmsPSeriesLP(struct pci_controller *phb,
-				    struct device_node *dn,
-				    struct TceTable *newTceTable ) {
-#ifdef CONFIG_PPC_PSERIES
-	u32 *dma_window = (u32 *)get_property(dn, "ibm,dma-window", 0);
-	if (!dma_window) {
-		panic("PCI_DMA: getTceTableParmsPSeriesLP: device %s has no ibm,dma-window property!\n", dn->full_name);
-	}
-
-	newTceTable->busNumber = dn->bussubno;
-	newTceTable->size = (((((unsigned long)dma_window[4] << 32) | (unsigned long)dma_window[5]) >> PAGE_SHIFT) << 3) >> PAGE_SHIFT;
-	newTceTable->startOffset = ((((unsigned long)dma_window[2] << 32) | (unsigned long)dma_window[3]) >> 12);
-	newTceTable->base = 0;
-	newTceTable->index = dma_window[0];
-	PPCDBG(PPCDBG_TCEINIT, "getTceTableParmsPSeriesLP for bus 0x%lx:\n", dn->bussubno);
-	PPCDBG(PPCDBG_TCEINIT, "\tDevice = %s\n", dn->full_name);
-	PPCDBG(PPCDBG_TCEINIT, "\tnewTceTable->index       = 0x%lx\n", newTceTable->index);
-	PPCDBG(PPCDBG_TCEINIT, "\tnewTceTable->startOffset = 0x%lx\n", newTceTable->startOffset);
-	PPCDBG(PPCDBG_TCEINIT, "\tnewTceTable->size        = 0x%lx\n", newTceTable->size);
-#endif
-}
-
-/* Allocates a contiguous real buffer and creates TCEs over it.
- * Returns the virtual address of the buffer and sets dma_handle
- * to the dma address (tce) of the first page.
- */
-static void *tce_alloc_consistent(struct pci_dev *hwdev, size_t size,
-			   dma_addr_t *dma_handle)
-{
-	struct TceTable * tbl;
-	void *ret = NULL;
-	unsigned order, nPages;
-	dma_addr_t tce;
-
-	PPCDBG(PPCDBG_TCE, "pci_alloc_consistent:\n");
-	PPCDBG(PPCDBG_TCE, "\thwdev      = 0x%16.16lx\n", hwdev);
-	PPCDBG(PPCDBG_TCE, "\tsize       = 0x%16.16lx\n", size);
-	PPCDBG(PPCDBG_TCE, "\tdma_handle = 0x%16.16lx\n", dma_handle);	
-
-	size = PAGE_ALIGN(size);
-	order = get_order(size);
-	nPages = 1 << order;
-
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("PCI_DMA: pci_alloc_consistent size to large: 0x%lx \n",size);
- 		return (void *)NO_TCE;
- 	}
-
-	tbl = get_tce_table(hwdev); 
-
-	if ( tbl ) {
-		/* Alloc enough pages (and possibly more) */
-		ret = (void *)__get_free_pages( GFP_ATOMIC, order );
-		if ( ret ) {
-			/* Page allocation succeeded */
-			memset(ret, 0, nPages << PAGE_SHIFT);
-			/* Set up tces to cover the allocated range */
-			tce = get_tces( tbl, order, ret, nPages, PCI_DMA_BIDIRECTIONAL );
-			if ( tce == NO_TCE ) {
-				PPCDBG(PPCDBG_TCE, "pci_alloc_consistent: get_tces failed\n" );
-				free_pages( (unsigned long)ret, order );
-				ret = NULL;
-			}
-			else
-			{
-				*dma_handle = tce;
-			}
-		}
-		else PPCDBG(PPCDBG_TCE, "pci_alloc_consistent: __get_free_pages failed for order = %d\n", order);
-	}
-	else PPCDBG(PPCDBG_TCE, "pci_alloc_consistent: get_tce_table failed for 0x%016lx\n", hwdev);
-
-	PPCDBG(PPCDBG_TCE, "\tpci_alloc_consistent: dma_handle = 0x%16.16lx\n", *dma_handle);	
-	PPCDBG(PPCDBG_TCE, "\tpci_alloc_consistent: return     = 0x%16.16lx\n", ret);	
-	return ret;
-}
-
-static void tce_free_consistent(struct pci_dev *hwdev, size_t size,
-			 void *vaddr, dma_addr_t dma_handle)
-{
-	struct TceTable * tbl;
-	unsigned order, nPages;
-	
-	PPCDBG(PPCDBG_TCE, "pci_free_consistent:\n");
-	PPCDBG(PPCDBG_TCE, "\thwdev = 0x%16.16lx, size = 0x%16.16lx, dma_handle = 0x%16.16lx, vaddr = 0x%16.16lx\n", hwdev, size, dma_handle, vaddr);	
-
-	size = PAGE_ALIGN(size);
-	order = get_order(size);
-	nPages = 1 << order;
-
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("PCI_DMA: pci_free_consistent size to large: 0x%lx \n",size);
- 		return;
- 	}
-	
-	tbl = get_tce_table(hwdev); 
-
-	if ( tbl ) {
-		tce_free(tbl, dma_handle, order, nPages);
-		free_pages( (unsigned long)vaddr, order );
-	}
-}
-
-/* Creates TCEs for a user provided buffer.  The user buffer must be 
- * contiguous real kernel storage (not vmalloc).  The address of the buffer
- * passed here is the kernel (virtual) address of the buffer.  The buffer
- * need not be page aligned, the dma_addr_t returned will point to the same
- * byte within the page as vaddr.
- */
-static dma_addr_t tce_map_single(struct pci_dev *hwdev, void *vaddr, 
-			  size_t size, int direction )
-{
-	struct TceTable * tbl;
-	dma_addr_t dma_handle = NO_TCE;
-	unsigned long uaddr;
-	unsigned order, nPages;
-
-	PPCDBG(PPCDBG_TCE, "pci_map_single:\n");
-	PPCDBG(PPCDBG_TCE, "\thwdev = 0x%16.16lx, size = 0x%16.16lx, direction = 0x%16.16lx, vaddr = 0x%16.16lx\n", hwdev, size, direction, vaddr);	
-	if ( direction == PCI_DMA_NONE )
-		BUG();
-	
-	uaddr = (unsigned long)vaddr;
-	nPages = PAGE_ALIGN( uaddr + size ) - ( uaddr & PAGE_MASK );
-	order = get_order( nPages & PAGE_MASK );
-	nPages >>= PAGE_SHIFT;
-	
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("PCI_DMA: pci_map_single size to large: 0x%lx \n",size);
- 		return NO_TCE;
- 	}
-
-	tbl = get_tce_table(hwdev); 
-
-	if ( tbl ) {
-		dma_handle = get_tces( tbl, order, vaddr, nPages, direction );
-		dma_handle |= ( uaddr & ~PAGE_MASK );
-	}
-
-	return dma_handle;
-}
-
-static void tce_unmap_single( struct pci_dev *hwdev, dma_addr_t dma_handle, size_t size, int direction )
-{
-	struct TceTable * tbl;
-	unsigned order, nPages;
-	
-	PPCDBG(PPCDBG_TCE, "pci_unmap_single:\n");
-	PPCDBG(PPCDBG_TCE, "\thwdev = 0x%16.16lx, size = 0x%16.16lx, direction = 0x%16.16lx, dma_handle = 0x%16.16lx\n", hwdev, size, direction, dma_handle);	
-	if ( direction == PCI_DMA_NONE )
-		BUG();
-
-	nPages = PAGE_ALIGN( dma_handle + size ) - ( dma_handle & PAGE_MASK );
-	order = get_order( nPages & PAGE_MASK );
-	nPages >>= PAGE_SHIFT;
-
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("PCI_DMA: pci_unmap_single 0x%lx size too"
-			" large: 0x%lx \n", (long)dma_handle, (long)size);
- 		return;
- 	}
-	
-	tbl = get_tce_table(hwdev); 
-
-	if ( tbl ) 
-		tce_free(tbl, dma_handle, order, nPages);
-
-}
-
-#if 0
-/* Figure out how many TCEs are actually going to be required
- * to map this scatterlist.  This code is not optimal.  It 
- * takes into account the case where entry n ends in the same
- * page in which entry n+1 starts.  It does not handle the 
- * general case of entry n ending in the same page in which 
- * entry m starts.   
- */
-static unsigned long num_tces_sg( struct scatterlist *sg, int nents )
-{
-	unsigned long nTces, numPages, startPage, endPage, prevEndPage;
-	unsigned i;
-
-	prevEndPage = 0;
-	nTces = 0;
-
-	for (i=0; i<nents; ++i) {
-		/* Compute the starting page number and
-		 * the ending page number for this entry
-		 */
-		startPage = (unsigned long)sg->address >> PAGE_SHIFT;
-		endPage = ((unsigned long)sg->address + sg->length - 1) >> PAGE_SHIFT;
-		numPages = endPage - startPage + 1;
-		/* Simple optimization: if the previous entry ended
-		 * in the same page in which this entry starts
-		 * then we can reduce the required pages by one.
-		 * This matches assumptions in fill_scatterlist_sg and
-		 * create_tces_sg
-		 */
-		if ( startPage == prevEndPage )
-			--numPages;
-		nTces += numPages;
-		prevEndPage = endPage;
-		sg++;
-	}
-	return nTces;
-}
-
-/* Fill in the dma data in the scatterlist
- * return the number of dma sg entries created
- */
-static unsigned fill_scatterlist_sg( struct scatterlist *sg, int nents, 
-				 dma_addr_t dma_addr , unsigned long numTces)
-{
-	struct scatterlist *dma_sg;
-	u32 cur_start_dma;
-	unsigned long cur_len_dma, cur_end_virt, uaddr;
-	unsigned num_dma_ents;
-
-	dma_sg = sg;
-	num_dma_ents = 1;
-
-	/* Process the first sg entry */
-	cur_start_dma = dma_addr + ((unsigned long)sg->address & (~PAGE_MASK));
-	cur_len_dma = sg->length;
-	/* cur_end_virt holds the address of the byte immediately after the
-	 * end of the current buffer.
-	 */
-	cur_end_virt = (unsigned long)sg->address + cur_len_dma;
-	/* Later code assumes that unused sg->dma_address and sg->dma_length
-	 * fields will be zero.  Other archs seem to assume that the user
-	 * (device driver) guarantees that...I don't want to depend on that
-	 */
-	sg->dma_address = sg->dma_length = 0;
-	
-	/* Process the rest of the sg entries */
-	while (--nents) {
-		++sg;
-		/* Clear possibly unused fields. Note: sg >= dma_sg so
-		 * this can't be clearing a field we've already set
-		 */
-		sg->dma_address = sg->dma_length = 0;
-
-		/* Check if it is possible to make this next entry
-		 * contiguous (in dma space) with the previous entry.
-		 */
-		
-		/* The entries can be contiguous in dma space if
-		 * the previous entry ends immediately before the
-		 * start of the current entry (in virtual space)
-		 * or if the previous entry ends at a page boundary
-		 * and the current entry starts at a page boundary.
-		 */
-		uaddr = (unsigned long)sg->address;
-		if ( ( uaddr != cur_end_virt ) &&
-		     ( ( ( uaddr | cur_end_virt ) & (~PAGE_MASK) ) ||
-		       ( ( uaddr & PAGE_MASK ) == ( ( cur_end_virt-1 ) & PAGE_MASK ) ) ) ) {
-			/* This entry can not be contiguous in dma space.
-			 * save the previous dma entry and start a new one
-			 */
-			dma_sg->dma_address = cur_start_dma;
-			dma_sg->dma_length  = cur_len_dma;
-
-			++dma_sg;
-			++num_dma_ents;
-			
-			cur_start_dma += cur_len_dma-1;
-			/* If the previous entry ends and this entry starts
-			 * in the same page then they share a tce.  In that
-			 * case don't bump cur_start_dma to the next page 
-			 * in dma space.  This matches assumptions made in
-			 * num_tces_sg and create_tces_sg.
-			 */
-			if ((uaddr & PAGE_MASK) == ((cur_end_virt-1) & PAGE_MASK))
-				cur_start_dma &= PAGE_MASK;
-			else
-				cur_start_dma = PAGE_ALIGN(cur_start_dma+1);
-			cur_start_dma += ( uaddr & (~PAGE_MASK) );
-			cur_len_dma = 0;
-		}
-		/* Accumulate the length of this entry for the next 
-		 * dma entry
-		 */
-		cur_len_dma += sg->length;
-		cur_end_virt = uaddr + sg->length;
-	}
-	/* Fill in the last dma entry */
-	dma_sg->dma_address = cur_start_dma;
-	dma_sg->dma_length  = cur_len_dma;
-
-	if ((((cur_start_dma +cur_len_dma - 1)>> PAGE_SHIFT) - (dma_addr >> PAGE_SHIFT) + 1) != numTces)
-	  {
-	    PPCDBG(PPCDBG_TCE, "fill_scatterlist_sg: numTces %ld, used tces %d\n",
-		   numTces,
-		   (unsigned)(((cur_start_dma + cur_len_dma - 1) >> PAGE_SHIFT) - (dma_addr >> PAGE_SHIFT) + 1));
-	  }
-	
-
-	return num_dma_ents;
-}
-
-/* Call the hypervisor to create the TCE entries.
- * return the number of TCEs created
- */
-static dma_addr_t create_tces_sg( struct TceTable *tbl, struct scatterlist *sg, 
-		   int nents, unsigned numTces, int direction )
-{
-	unsigned order, i, j;
-	unsigned long startPage, endPage, prevEndPage, numPages, uaddr;
-	long tcenum, starttcenum;
-	dma_addr_t dmaAddr;
-
-	dmaAddr = NO_TCE;
-
-	order = get_order( numTces << PAGE_SHIFT );
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
-		printk("PCI_DMA: create_tces_sg size to large: 0x%x \n",(numTces << PAGE_SHIFT));
- 		return NO_TCE;
- 	}
-
-	/* allocate a block of tces */
-	tcenum = alloc_tce_range( tbl, order );
-	if ( tcenum != -1 ) {
-		tcenum += tbl->startOffset;
-		starttcenum = tcenum;
-		dmaAddr = tcenum << PAGE_SHIFT;
-		prevEndPage = 0;
-		for (j=0; j<nents; ++j) {
-			startPage = (unsigned long)sg->address >> PAGE_SHIFT;
-			endPage = ((unsigned long)sg->address + sg->length - 1) >> PAGE_SHIFT;
-			numPages = endPage - startPage + 1;
-			
-			uaddr = (unsigned long)sg->address;
-
-			/* If the previous entry ended in the same page that
-			 * the current page starts then they share that
-			 * tce and we reduce the number of tces we need
-			 * by one.  This matches assumptions made in
-			 * num_tces_sg and fill_scatterlist_sg
-			 */
-			if ( startPage == prevEndPage ) {
-				--numPages;
-				uaddr += PAGE_SIZE;
-			}
-			
-			for (i=0; i<numPages; ++i) {
-			  ppc_md.tce_build(tbl, tcenum, uaddr, direction); 
-			  ++tcenum;
-			  uaddr += PAGE_SIZE;
-			}
-		
-			prevEndPage = endPage;
-			sg++;
-		}
-		/* Make sure the update is visible to hardware. 
-		   sync required to synchronize the update to 
-		   the TCE table with the MMIO that will send
-		   the bus address to the IOA */
-		__asm__ __volatile__ ("sync" : : : "memory");
-
-		if ((tcenum - starttcenum) != numTces)
-	    		PPCDBG(PPCDBG_TCE, "create_tces_sg: numTces %d, tces used %d\n",
-		   		numTces, (unsigned)(tcenum - starttcenum));
-
-	}
-
-	return dmaAddr;
-}
-
-static int tce_map_sg( struct pci_dev *hwdev, struct scatterlist *sg, int nents, int direction )
-{
-	struct TceTable * tbl;
-	unsigned numTces;
-	int num_dma;
-	dma_addr_t dma_handle;
-
-	PPCDBG(PPCDBG_TCE, "pci_map_sg:\n");
-	PPCDBG(PPCDBG_TCE, "\thwdev = 0x%16.16lx, sg = 0x%16.16lx, direction = 0x%16.16lx, nents = 0x%16.16lx\n", hwdev, sg, direction, nents);	
-	/* Fast path for a single entry scatterlist */
-	if ( nents == 1 ) {
-		sg->dma_address = pci_map_single( hwdev, sg->address, 
-					sg->length, direction );
-		sg->dma_length = sg->length;
-		return 1;
-	}
-	
-	if ( direction == PCI_DMA_NONE )
-		BUG();
-	
-	tbl = get_tce_table(hwdev); 
-
-	if ( tbl ) {
-		/* Compute the number of tces required */
-		numTces = num_tces_sg( sg, nents );
-		/* Create the tces and get the dma address */ 
-		dma_handle = create_tces_sg( tbl, sg, nents, numTces, direction );
-
-		/* Fill in the dma scatterlist */
-		num_dma = fill_scatterlist_sg( sg, nents, dma_handle, numTces );
-	}
-
-	return num_dma;
-}
-
-static void tce_unmap_sg( struct pci_dev *hwdev, struct scatterlist *sg, int nelms, int direction )
-{
-	struct TceTable * tbl;
-	unsigned order, numTces, i;
-	dma_addr_t dma_end_page, dma_start_page;
-	
-	PPCDBG(PPCDBG_TCE, "pci_unmap_sg:\n");
-	PPCDBG(PPCDBG_TCE, "\thwdev = 0x%16.16lx, sg = 0x%16.16lx, direction = 0x%16.16lx, nelms = 0x%16.16lx\n", hwdev, sg, direction, nelms);	
-
-	if ( direction == PCI_DMA_NONE || nelms == 0 )
-		BUG();
-
-	dma_start_page = sg->dma_address & PAGE_MASK;
- 	dma_end_page   = 0;
-	for ( i=nelms; i>0; --i ) {
-		unsigned k = i - 1;
-		if ( sg[k].dma_length ) {
-			dma_end_page = ( sg[k].dma_address +
-					 sg[k].dma_length - 1 ) & PAGE_MASK;
-			break;
-		}
-	}
-
-	numTces = ((dma_end_page - dma_start_page ) >> PAGE_SHIFT) + 1;
-	order = get_order( numTces << PAGE_SHIFT );
-
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("PCI_DMA: dma_start_page:0x%lx  dma_end_page:0x%lx\n",dma_start_page,dma_end_page);
-		printk("PCI_DMA: pci_unmap_sg size to large: 0x%x \n",(numTces << PAGE_SHIFT));
- 		return;
- 	}
-	
-	tbl = get_tce_table(hwdev); 
-
-	if ( tbl ) 
-		tce_free( tbl, dma_start_page, order, numTces );
-
-}
-#else
-static int tce_map_sg(struct pci_dev *pdev, struct scatterlist *sglist, int nelems,
-	       int direction)
-{
-	int i;
-
-	for (i = 0; i < nelems; i++) {
-		void *vaddr = page_address(sglist->page) + sglist->offset;
-
-		sglist->dma_address = pci_map_single(pdev, vaddr,
-						     sglist->length,
-						     direction);
-		sglist->dma_length = sglist->length;
-		sglist++;
-	}
-
-	return nelems;
-}
-
-static void tce_unmap_sg(struct pci_dev *pdev, struct scatterlist *sglist, int nelems,
-		  int direction)
-{
-	while (nelems--) {
-		pci_unmap_single(pdev, sglist->dma_address,
-				 sglist->dma_length, direction);
-		sglist++;
-	}
-}
-#endif
-
-#ifdef CONFIG_PPC_PSERIES
-/* These are called very early. */
-void tce_init_pSeries(void)
-{
-	ppc_md.tce_build = tce_build_pSeries;
-	ppc_md.tce_free_one = tce_free_one_pSeries;
-
-	pci_dma_ops.pci_alloc_consistent = tce_alloc_consistent;
-	pci_dma_ops.pci_free_consistent = tce_free_consistent;
-	pci_dma_ops.pci_map_single = tce_map_single;
-	pci_dma_ops.pci_unmap_single = tce_unmap_single;
-	pci_dma_ops.pci_map_sg = tce_map_sg;
-	pci_dma_ops.pci_unmap_sg = tce_unmap_sg;
-}
-
-#endif
-
-#ifdef CONFIG_PPC_ISERIES
-void tce_init_iSeries(void)
-{
-	ppc_md.tce_build = tce_build_iSeries;
-	ppc_md.tce_free_one = tce_free_one_iSeries;
-
-	pci_dma_ops.pci_alloc_consistent = tce_alloc_consistent;
-	pci_dma_ops.pci_free_consistent = tce_free_consistent;
-	pci_dma_ops.pci_map_single = tce_map_single;
-	pci_dma_ops.pci_unmap_single = tce_unmap_single;
-	pci_dma_ops.pci_map_sg = tce_map_sg;
-	pci_dma_ops.pci_unmap_sg = tce_unmap_sg;
-}
-#endif
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pci_dn.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pci_dn.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pci_dn.c	2004-02-12 04:24:38.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pci_dn.c	2004-02-27 23:02:35.000000000 +0000
@@ -36,7 +36,7 @@
 #include <asm/pci-bridge.h>
 #include <asm/ppcdebug.h>
 #include <asm/naca.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 
 #include "pci.h"
 
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pci_iommu.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pci_iommu.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pci_iommu.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pci_iommu.c	2004-02-27 17:16:29.000000000 +0000
@@ -0,0 +1,242 @@
+/*
+ * arch/ppc64/kernel/pci_iommu.c
+ * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
+ * 
+ * Rewrite, cleanup, new allocation schemes: 
+ * Copyright (C) 2004 Olof Johansson, IBM Corporation
+ *
+ * Dynamic DMA mapping support, platform-independent parts.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ */
+
+
+#include <linux/config.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/string.h>
+#include <linux/pci.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/iommu.h>
+#include <asm/pci-bridge.h>
+#include <asm/machdep.h>
+#include "pci.h"
+
+#ifdef CONFIG_PPC_ISERIES
+#include <asm/iSeries/iSeries_pci.h>
+#endif /* CONFIG_PPC_ISERIES */
+
+#define DBG(...)
+
+static inline struct iommu_table *devnode_table(struct pci_dev *dev)
+{
+	if (!dev)
+		dev = ppc64_isabridge_dev;
+	if (!dev)
+		return NULL;
+
+#ifdef CONFIG_PPC_ISERIES
+	return ISERIES_DEVNODE(dev)->iommu_table;
+#endif /* CONFIG_PPC_ISERIES */
+
+#ifdef CONFIG_PPC_PSERIES
+	return PCI_GET_DN(dev)->iommu_table;
+#endif /* CONFIG_PPC_PSERIES */
+}
+
+
+/* Allocates a contiguous real buffer and creates mappings over it.
+ * Returns the virtual address of the buffer and sets dma_handle
+ * to the dma address (mapping) of the first page.
+ */
+void *pci_iommu_alloc_consistent(struct pci_dev *hwdev, size_t size,
+			   dma_addr_t *dma_handle)
+{
+	struct iommu_table *tbl;
+	void *ret = NULL;
+	dma_addr_t mapping;
+	unsigned int npages, order;
+
+	size = PAGE_ALIGN(size);
+	npages = size >> PAGE_SHIFT;
+	order = get_order(size);
+
+ 	/* Client asked for way too much space.  This is checked later anyway */
+	/* It is easier to debug here for the drivers than in the tce tables.*/
+	if (order >= IOMAP_MAX_ORDER) {
+		printk("PCI_DMA: pci_alloc_consistent size too large: 0x%lx\n",
+			size);
+		return (void *)NO_TCE;
+	}
+
+	tbl = devnode_table(hwdev); 
+
+	if (!tbl)
+		return NULL;
+
+	/* Alloc enough pages (and possibly more) */
+	ret = (void *)__get_free_pages(GFP_ATOMIC, order);
+
+	if (!ret)
+		return NULL;
+
+	memset(ret, 0, size);
+
+	/* Set up tces to cover the allocated range */
+	mapping = iommu_alloc(tbl, ret, npages, PCI_DMA_BIDIRECTIONAL, NULL);
+
+	/* Make sure the update is visible to hardware. */
+	mb();
+
+	if (mapping == NO_TCE) {
+		free_pages((unsigned long)ret, order);
+		ret = NULL;
+	} else
+		*dma_handle = mapping;
+
+	return ret;
+}
+
+
+void pci_iommu_free_consistent(struct pci_dev *hwdev, size_t size,
+			 void *vaddr, dma_addr_t dma_handle)
+{
+	struct iommu_table *tbl;
+	unsigned int npages;
+	
+	size = PAGE_ALIGN(size);
+	npages = size >> PAGE_SHIFT;
+
+	tbl = devnode_table(hwdev); 
+
+	if (tbl) {
+		iommu_free(tbl, dma_handle, npages);
+		free_pages((unsigned long)vaddr, get_order(size));
+	}
+}
+
+
+/* Creates TCEs for a user provided buffer.  The user buffer must be 
+ * contiguous real kernel storage (not vmalloc).  The address of the buffer
+ * passed here is the kernel (virtual) address of the buffer.  The buffer
+ * need not be page aligned, the dma_addr_t returned will point to the same
+ * byte within the page as vaddr.
+ */
+dma_addr_t pci_iommu_map_single(struct pci_dev *hwdev, void *vaddr,
+				size_t size, int direction)
+{
+	struct iommu_table * tbl;
+	dma_addr_t dma_handle = NO_TCE;
+	unsigned long uaddr;
+	unsigned int npages;
+	unsigned long handle = 0;
+
+	BUG_ON(direction == PCI_DMA_NONE);
+
+	uaddr = (unsigned long)vaddr;
+	npages = PAGE_ALIGN(uaddr + size) - (uaddr & PAGE_MASK);
+	npages >>= PAGE_SHIFT;
+
+	tbl = devnode_table(hwdev); 
+
+	if (tbl) {
+		dma_handle = iommu_alloc(tbl, vaddr, npages, direction, &handle);
+		if (dma_handle == NO_TCE) {
+			if (printk_ratelimit())  {
+				printk(KERN_INFO "iommu_alloc failed, tbl %p vaddr %p npages %d\n",
+				       tbl, vaddr, npages);
+			}
+		} else 
+			dma_handle |= (uaddr & ~PAGE_MASK);
+	}
+
+	mb();
+
+	return dma_handle;
+}
+
+
+void pci_iommu_unmap_single(struct pci_dev *hwdev, dma_addr_t dma_handle,
+		      size_t size, int direction)
+{
+	struct iommu_table *tbl;
+	unsigned int npages;
+	
+	BUG_ON(direction == PCI_DMA_NONE);
+
+	npages = (PAGE_ALIGN(dma_handle + size) - (dma_handle & PAGE_MASK))
+		>> PAGE_SHIFT;
+
+	tbl = devnode_table(hwdev); 
+
+	if (tbl) 
+		iommu_free(tbl, dma_handle, npages);
+}
+
+
+int pci_iommu_map_sg(struct pci_dev *pdev, struct scatterlist *sglist, int nelems,
+	       int direction)
+{
+	struct iommu_table * tbl;
+	unsigned long handle;
+
+	BUG_ON(direction == PCI_DMA_NONE);
+
+	if (nelems == 0)
+		return 0;
+
+	tbl = devnode_table(pdev); 
+	if (!tbl)
+		return 0;
+
+	handle = 0;
+
+	return iommu_alloc_sg(tbl, sglist, nelems, direction, &handle);
+}
+
+void pci_iommu_unmap_sg(struct pci_dev *pdev, struct scatterlist *sglist, int nelems,
+		  int direction)
+{
+	struct iommu_table *tbl;
+
+	BUG_ON(direction == PCI_DMA_NONE);
+
+	tbl = devnode_table(pdev); 
+	if (!tbl)
+		return;
+
+	iommu_free_sg(tbl, sglist, nelems, direction);
+}
+
+/* We support DMA to/from any memory page via the iommu */
+static int pci_iommu_dma_supported(struct pci_dev *pdev, u64 mask)
+{
+	return 1;
+}
+
+void pci_iommu_init(void)
+{
+	pci_dma_ops.pci_alloc_consistent = pci_iommu_alloc_consistent;
+	pci_dma_ops.pci_free_consistent = pci_iommu_free_consistent;
+	pci_dma_ops.pci_map_single = pci_iommu_map_single;
+	pci_dma_ops.pci_unmap_single = pci_iommu_unmap_single;
+	pci_dma_ops.pci_map_sg = pci_iommu_map_sg;
+	pci_dma_ops.pci_unmap_sg = pci_iommu_unmap_sg;
+	pci_dma_ops.pci_dma_supported = pci_iommu_dma_supported;
+}
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pmac_iommu.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pmac_iommu.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pmac_iommu.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pmac_iommu.c	2004-02-27 22:44:57.000000000 +0000
@@ -0,0 +1,301 @@
+/*
+ * arch/ppc64/kernel/pmac_iommu.c
+ *
+ * Copyright (C) 2004 Olof Johansson <olof@austin.ibm.com>, IBM Corporation
+ *
+ * Based on pSeries_iommu.c:
+ * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
+ * Copyright (C) 2004 Olof Johansson <olof@austin.ibm.com>, IBM Corporation
+ *
+ * Dynamic DMA mapping support, PowerMac G5 (DART)-specific parts.
+ *
+ * 
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ */
+
+#include <linux/config.h>
+#include <linux/init.h>
+#include <linux/types.h>
+#include <linux/slab.h>
+#include <linux/mm.h>
+#include <linux/spinlock.h>
+#include <linux/string.h>
+#include <linux/pci.h>
+#include <linux/vmalloc.h>
+#include <asm/io.h>
+#include <asm/prom.h>
+#include <asm/rtas.h>
+#include <asm/ppcdebug.h>
+#include <asm/iommu.h>
+#include <asm/pci-bridge.h>
+#include <asm/machdep.h>
+#include <asm/abs_addr.h>
+#include <asm/cacheflush.h>
+#include "pci.h"
+
+
+/* physical base of DART registers */
+#define DART_BASE        0xf8033000UL
+
+/* Offset from base to control register */
+#define DARTCNTL   0
+/* Offset from base to exception register */
+#define DARTEXCP   0x10
+/* Offset from base to TLB tag registers */
+#define DARTTAG    0x1000
+
+
+/* Control Register fields */
+
+/* base address of table (pfn) */
+#define DARTCNTL_BASE_MASK    0xfffff
+#define DARTCNTL_BASE_SHIFT   12
+
+#define DARTCNTL_FLUSHTLB     0x400
+#define DARTCNTL_ENABLE       0x200
+
+/* size of table in pages */
+#define DARTCNTL_SIZE_MASK    0x1ff
+#define DARTCNTL_SIZE_SHIFT   0
+
+/* DART table fields */
+#define DARTMAP_VALID   0x80000000
+#define DARTMAP_RPNMASK 0x00ffffff
+
+/* Physical base address and size of the DART table */
+unsigned long dart_tablebase;
+unsigned long dart_tablesize;
+
+/* Virtual base address of the DART table */
+static u32 *dart_vbase;
+
+/* Mapped base address for the dart */
+static unsigned int *dart; 
+
+/* Dummy val that entries are set to when unused */
+static unsigned int dart_emptyval;
+
+static struct iommu_table iommu_table_pmac;
+static int dart_dirty;
+
+#define DBG(...)
+
+static inline void dart_tlb_invalidate_all(void)
+{
+	unsigned long l = 0;
+	unsigned int reg;
+	unsigned long limit;
+
+	DBG("dart: flush\n");
+
+	/* To invalidate the DART, set the DARTCNTL_FLUSHTLB bit in the
+	 * control register and wait for it to clear.
+	 *
+	 * Gotcha: Sometimes, the DART won't detect that the bit gets
+	 * set. If so, clear it and set it again.
+	 */ 
+
+	limit = 0;
+
+retry:
+	reg = in_be32((unsigned int *)dart+DARTCNTL);
+	reg |= DARTCNTL_FLUSHTLB;
+	out_be32((unsigned int *)dart+DARTCNTL, reg);
+
+	l = 0;
+	while ((in_be32((unsigned int *)dart+DARTCNTL) & DARTCNTL_FLUSHTLB) &&
+		l < (1L<<limit)) {
+		l++;
+	}
+	if (l == (1L<<limit)) {
+		if (limit < 4) {
+			limit++;
+		        reg = in_be32((unsigned int *)dart+DARTCNTL);
+		        reg &= ~DARTCNTL_FLUSHTLB;
+		        out_be32((unsigned int *)dart+DARTCNTL, reg);
+			goto retry;
+		} else
+			panic("U3-DART: TLB did not flush after waiting a long "
+			      "time. Buggy U3 ?");
+	}
+}
+
+static void dart_flush(struct iommu_table *tbl)
+{
+	if (dart_dirty)
+		dart_tlb_invalidate_all();
+	dart_dirty = 0;
+}
+
+static void dart_build_pmac(struct iommu_table *tbl, long index, 
+			    long npages, unsigned long uaddr,
+			    int direction)
+{
+	unsigned int *dp;
+	unsigned int rpn;
+
+	DBG("dart: build at: %lx, %lx, addr: %x\n", index, npages, uaddr);
+
+	dp = ((unsigned int*)tbl->it_base) + index;
+	
+	/* On pmac, all memory is contigous, so we can move this
+	 * out of the loop.
+	 */
+	while (npages--) {
+		rpn = (virt_to_absolute(uaddr)) >> PAGE_SHIFT;
+
+		*(dp++) = DARTMAP_VALID | (rpn & DARTMAP_RPNMASK);
+
+		rpn++;
+		uaddr += PAGE_SIZE;
+	}
+
+	dart_dirty = 1;
+}
+
+
+static void dart_free_pmac(struct iommu_table *tbl, long index, long npages)
+{
+	unsigned int *dp;
+	
+	/* We don't worry about flushing the TLB cache. The only drawback of
+	 * not doing it is that we won't catch buggy device drivers doing
+	 * bad DMAs, but then no 32-bit architecture ever does either.
+	 */
+
+	DBG("dart: free at: %lx, %lx\n", index, npages);
+
+	dp  = ((unsigned int *)tbl->it_base) + index;
+		
+	while (npages--)
+		*(dp++) = dart_emptyval;
+}
+
+
+static int dart_init(struct device_node *dart_node)
+{
+	unsigned int regword;
+	unsigned int i;
+	unsigned long tmp;
+	struct page *p;
+
+	if (dart_tablebase == 0 || dart_tablesize == 0) {
+		printk(KERN_INFO "U3-DART: table not allocated, using direct DMA\n");
+		return -ENODEV;
+	}
+
+	/* Make sure nothing from the DART range remains in the CPU cache
+	 * from a previous mapping that existed before the kernel took
+	 * over
+	 */
+	flush_dcache_phys_range(dart_tablebase, dart_tablebase + dart_tablesize);
+
+	/* Allocate a spare page to map all invalid DART pages. We need to do
+	 * that to work around what looks like a problem with the HT bridge
+	 * prefetching into invalid pages and corrupting data
+	 */
+	tmp = __get_free_pages(GFP_ATOMIC, 1);
+	if (tmp == 0)
+		panic("U3-DART: Cannot allocate spare page !");
+	dart_emptyval = DARTMAP_VALID |
+		((virt_to_absolute(tmp) >> PAGE_SHIFT) & DARTMAP_RPNMASK);
+
+	/* Map in DART registers. FIXME: Use device node to get base address */
+	dart = ioremap(DART_BASE, 0x7000);
+	if (dart == NULL)
+		panic("U3-DART: Cannot map registers !");
+
+	/* Set initial control register contents: table base, 
+	 * table size and enable bit
+	 */
+	regword = DARTCNTL_ENABLE | 
+		((dart_tablebase >> PAGE_SHIFT) << DARTCNTL_BASE_SHIFT) |
+		(((dart_tablesize >> PAGE_SHIFT) & DARTCNTL_SIZE_MASK)
+				 << DARTCNTL_SIZE_SHIFT);
+	p = virt_to_page(dart_tablebase);
+	dart_vbase = ioremap(virt_to_absolute(dart_tablebase), dart_tablesize);
+
+	/* Fill initial table */
+	for (i = 0; i < dart_tablesize/4; i++)
+		dart_vbase[i] = dart_emptyval;
+
+	/* Initialize DART with table base and enable it. */
+	out_be32((unsigned int *)dart, regword);
+
+	/* Invalidate DART to get rid of possible stale TLBs */
+	dart_tlb_invalidate_all();
+
+	iommu_table_pmac.it_busno = 0;
+	
+	/* Units of tce entries */
+	iommu_table_pmac.it_offset = 0;
+	
+	/* Set the tce table size - measured in pages */
+	iommu_table_pmac.it_size = dart_tablesize >> PAGE_SHIFT;
+
+	/* Initialize the common IOMMU code */
+	iommu_table_pmac.it_base = (unsigned long)dart_vbase;
+	iommu_table_pmac.it_index = 0;
+	iommu_table_pmac.it_blocksize = 1;
+	iommu_table_pmac.it_entrysize = sizeof(u32);
+	iommu_init_table(&iommu_table_pmac);
+
+	/* Reserve the last page of the DART to avoid possible prefetch
+	 * past the DART mapped area
+	 */
+	set_bit(iommu_table_pmac.it_mapsize - 1, iommu_table_pmac.it_map);
+
+	printk(KERN_INFO "U3-DART IOMMU initialized\n");
+
+	return 0;
+}
+
+
+void iommu_setup_pmac(void)
+{
+	struct pci_dev *dev = NULL;
+	struct device_node *dn;
+
+	/* Find the DART in the device-tree */
+	dn = of_find_compatible_node(NULL, "dart", "u3-dart");
+	if (dn == NULL)
+		return;
+
+	/* Setup low level TCE operations for the core IOMMU code */
+	ppc_md.tce_build = dart_build_pmac;
+	ppc_md.tce_free  = dart_free_pmac;
+	ppc_md.tce_flush = dart_flush;
+
+	/* Initialize the DART HW */
+	if (dart_init(dn))
+		return;
+
+	/* Setup pci_dma ops */
+	pci_iommu_init();
+
+	/* We only have one iommu table on the mac for now, which makes
+	 * things simple. Setup all PCI devices to point to this table
+	 */
+	while ((dev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL) {
+		dn = PCI_GET_DN(dev);
+
+		if (dn)
+			dn->iommu_table = &iommu_table_pmac;
+	}
+}
+
+
+
+
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pmac_pci.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pmac_pci.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pmac_pci.c	2004-02-12 03:47:58.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pmac_pci.c	2004-02-27 22:44:57.000000000 +0000
@@ -26,6 +26,7 @@
 #include <asm/pci-bridge.h>
 #include <asm/machdep.h>
 #include <asm/pmac_feature.h>
+#include <asm/iommu.h>
 
 #include "pci.h"
 #include "pmac.h"
@@ -655,6 +656,11 @@ void __init pmac_pcibios_fixup(void)
 		pci_read_irq_line(dev);
 
 	pci_fix_bus_sysdata();
+
+#ifdef CONFIG_PMAC_DART
+	iommu_setup_pmac();
+#endif /* CONFIG_PMAC_DART */
+
 }
 
 static void __init pmac_fixup_phb_resources(void)
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pmac_setup.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pmac_setup.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pmac_setup.c	2004-02-24 16:39:08.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pmac_setup.c	2004-02-27 23:02:35.000000000 +0000
@@ -60,7 +60,7 @@
 #include <asm/bitops.h>
 #include <asm/io.h>
 #include <asm/pci-bridge.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 #include <asm/machdep.h>
 #include <asm/dma.h>
 #include <asm/bootx.h>
@@ -181,8 +181,9 @@ void __init pmac_setup_arch(void)
 #ifdef CONFIG_SMP
 	pmac_setup_smp();
 #endif
-	/* Setup the PCI DMA to "direct" for now, until we have proper
-	 * DART support and can deal with more than 2Gb of RAM
+
+	/* Setup the PCI DMA to "direct" by default. May be overriden
+	 * by iommu later on
 	 */
 	pci_dma_init_direct();
 
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/pmac_smp.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pmac_smp.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/pmac_smp.c	2004-02-12 03:47:59.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/pmac_smp.c	2004-02-27 04:00:48.000000000 +0000
@@ -57,7 +57,7 @@ extern void pmac_secondary_start_1(void)
 extern void pmac_secondary_start_2(void);
 extern void pmac_secondary_start_3(void);
 
-extern void smp_openpic_message_pass(int target, int msg, unsigned long data, int wait);
+extern void smp_openpic_message_pass(int target, int msg);
 
 extern struct smp_ops_t *smp_ops;
 
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/ppc_ksyms.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/ppc_ksyms.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/ppc_ksyms.c	2004-02-25 10:31:13.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/ppc_ksyms.c	2004-02-27 18:28:03.000000000 +0000
@@ -53,9 +53,6 @@ extern int do_signal(sigset_t *, struct 
 
 int abs(int);
 
-extern struct pci_dev * iSeries_veth_dev;
-extern struct pci_dev * iSeries_vio_dev;
-
 EXPORT_SYMBOL(do_signal);
 EXPORT_SYMBOL(sys_ioctl);
 
@@ -157,9 +154,6 @@ EXPORT_SYMBOL(eeh_total_mmio_ffs);
 #endif /* CONFIG_PPC_ISERIES */
 #endif /* CONFIG_PCI */
 
-EXPORT_SYMBOL(iSeries_veth_dev);
-EXPORT_SYMBOL(iSeries_vio_dev);
-
 EXPORT_SYMBOL(start_thread);
 EXPORT_SYMBOL(kernel_thread);
 
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/process.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/process.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/process.c	2004-02-23 16:39:12.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/process.c	2004-02-27 12:16:07.000000000 +0000
@@ -49,14 +49,20 @@
 #include <asm/hardirq.h>
 #include <asm/cputable.h>
 #include <asm/sections.h>
+#include <asm/tlbflush.h>
 
 #ifndef CONFIG_SMP
 struct task_struct *last_task_used_math = NULL;
 struct task_struct *last_task_used_altivec = NULL;
 #endif
 
-struct mm_struct ioremap_mm = { pgd             : ioremap_dir  
-                               ,page_table_lock : SPIN_LOCK_UNLOCKED };
+struct mm_struct ioremap_mm = {
+	.pgd		= ioremap_dir,
+	.mm_users	= ATOMIC_INIT(2),
+	.mm_count	= ATOMIC_INIT(1),
+	.cpu_vm_mask	= CPU_MASK_ALL,
+	.page_table_lock = SPIN_LOCK_UNLOCKED,
+};
 
 char *sysmap = NULL;
 unsigned long sysmap_size = 0;
@@ -146,6 +152,8 @@ struct task_struct *__switch_to(struct t
 		new->thread.regs->msr |= MSR_VEC;
 #endif /* CONFIG_ALTIVEC */
 
+	flush_tlb_pending();
+
 	new_thread = &new->thread;
 	old_thread = &current->thread;
 
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/prom.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/prom.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/prom.c	2004-02-25 02:54:12.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/prom.c	2004-02-27 15:48:10.000000000 +0000
@@ -47,7 +47,7 @@
 #include <asm/bitops.h>
 #include <asm/naca.h>
 #include <asm/pci.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 #include <asm/bootinfo.h>
 #include <asm/ppcdebug.h>
 #include <asm/btext.h>
@@ -516,6 +516,9 @@ prom_initialize_naca(unsigned long mem)
 	return mem;
 }
 
+#ifdef CONFIG_PMAC_DART
+static int dart_force_on;
+#endif
 
 static unsigned long __init
 prom_initialize_lmb(unsigned long mem)
@@ -528,6 +531,30 @@ prom_initialize_lmb(unsigned long mem)
 	union lmb_reg_property reg;
 	unsigned long lmb_base, lmb_size;
 	unsigned long num_regs, bytes_per_reg = (_prom->encode_phys_size*2)/8;
+	int nodart = 0;
+
+#ifdef CONFIG_PMAC_DART
+	char *opt;
+
+	opt = strstr(RELOC(cmd_line), RELOC("iommu="));
+	if (opt) {
+		prom_print(RELOC("opt is:"));
+		prom_print(opt);
+		prom_print(RELOC("\n"));
+		opt += 6;
+		while (*opt && *opt == ' ')
+			opt++;
+		if (!strncmp(opt, RELOC("off"), 3))
+			nodart = 1;
+		else if (!strncmp(opt, RELOC("on"), 2))
+			RELOC(dart_force_on) = 1;
+	}
+#else
+	nodart = 1;
+#endif /* CONFIG_PMAC_DART */
+
+	if (nodart)
+		prom_print(RELOC("DART disabled on PowerMac !\n"));
 
 	lmb_init();
 
@@ -553,8 +580,9 @@ prom_initialize_lmb(unsigned long mem)
 				lmb_base = ((unsigned long)reg.addrPM[i].address_hi) << 32;
 				lmb_base |= (unsigned long)reg.addrPM[i].address_lo;
 				lmb_size = reg.addrPM[i].size;
-				if (lmb_base > 0x80000000ull) {
-					prom_print(RELOC("Skipping memory above 2Gb for now, not yet supported\n"));
+				if (nodart && lmb_base > 0x80000000ull) {
+					prom_print(RELOC("Skipping memory above 2Gb for "
+							 "now, DART support disabled\n"));
 					continue;
 				}
 			} else if (_prom->encode_phys_size == 32) {
@@ -733,6 +761,34 @@ prom_dump_lmb(void)
 #endif /* DEBUG_PROM */
 
 
+#ifdef CONFIG_PMAC_DART
+void prom_initialize_dart_table(void)
+{
+	unsigned long offset = reloc_offset();
+	extern unsigned long dart_tablebase;
+	extern unsigned long dart_tablesize;
+
+	/* Only reserve DART space if machine has more than 2GB of RAM
+	 * or if requested with iommu=on on cmdline.
+	 */
+	if (lmb_end_of_DRAM() <= 0x80000000ull && !RELOC(dart_force_on))
+		return;
+
+	/* 512 pages is max DART tablesize. */
+	RELOC(dart_tablesize) = 1UL << 19;
+	/* 16MB (1 << 24) alignment. We allocate a full 16Mb chuck since we
+	 * will blow up an entire large page anyway in the kernel mapping
+	 */
+	RELOC(dart_tablebase) =
+		absolute_to_virt(lmb_alloc_base(1UL<<24, 1UL<<24, 0x80000000L));
+
+	prom_print(RELOC("Dart at: "));
+	prom_print_hex(RELOC(dart_tablebase));
+	prom_print(RELOC("\n"));
+}
+#endif /* CONFIG_PMAC_DART */
+
+
 void
 prom_initialize_tce_table(void)
 {
@@ -1542,6 +1598,11 @@ prom_init(unsigned long r3, unsigned lon
 	if (_systemcfg->platform == PLATFORM_PSERIES)
 		prom_initialize_tce_table();
 
+#ifdef CONFIG_PMAC_DART
+	if (_systemcfg->platform == PLATFORM_POWERMAC)
+		prom_initialize_dart_table();
+#endif
+
 #ifdef CONFIG_BOOTX_TEXT
 	if(_prom->disp_node) {
 		prom_print(RELOC("Setting up bi display...\n"));
@@ -3003,15 +3064,15 @@ static int of_finish_dynamic_node(struct
                node->devfn = (regs[0] >> 8) & 0xff;
        }
 
-	/* fixing up tce_table */
+	/* fixing up iommu_table */
 
 	if(strcmp(node->name, "pci") == 0 &&
                 get_property(node, "ibm,dma-window", NULL)) {
                 node->bussubno = node->busno;
-                create_pci_bus_tce_table((unsigned long)node);
+                iommu_devnode_init(node);
         }
 	else
-		node->tce_table = parent->tce_table;
+		node->iommu_table = parent->iommu_table;
 
 out:
 	of_node_put(parent);
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/stab.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/stab.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/stab.c	2004-02-23 16:39:12.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/stab.c	2004-02-27 22:59:30.000000000 +0000
@@ -32,10 +32,14 @@ static void make_slbe(unsigned long esid
 void stab_initialize(unsigned long stab)
 {
 	unsigned long esid, vsid; 
+	int seg0_largepages = 0;
 
 	esid = GET_ESID(KERNELBASE);
 	vsid = get_kernel_vsid(esid << SID_SHIFT); 
 
+	if (cur_cpu_spec->cpu_features & CPU_FTR_16M_PAGE)
+		seg0_largepages = 1;
+
 	if (cur_cpu_spec->cpu_features & CPU_FTR_SLB) {
 		/* Invalidate the entire SLB & all the ERATS */
 #ifdef CONFIG_PPC_ISERIES
@@ -44,7 +48,7 @@ void stab_initialize(unsigned long stab)
 		asm volatile("isync":::"memory");
 		asm volatile("slbmte  %0,%0"::"r" (0) : "memory");
 		asm volatile("isync; slbia; isync":::"memory");
-		make_slbe(esid, vsid, 0, 1);
+		make_slbe(esid, vsid, seg0_largepages, 1);
 		asm volatile("isync":::"memory");
 #endif
 	} else {
@@ -73,6 +77,8 @@ static int make_ste(unsigned long stab, 
 	unsigned long entry, group, old_esid, castout_entry, i;
 	unsigned int global_entry;
 	STE *ste, *castout_ste;
+	unsigned long kernel_segment = (REGION_ID(esid << SID_SHIFT) != 
+					USER_REGION_ID);
 
 	/* Search the primary group first. */
 	global_entry = (esid & 0x1f) << 3;
@@ -85,6 +91,8 @@ static int make_ste(unsigned long stab, 
 				ste->dw1.dw1.vsid = vsid;
 				ste->dw0.dw0.esid = esid;
 				ste->dw0.dw0.kp = 1;
+				if (!kernel_segment)
+					ste->dw0.dw0.ks = 1;
 				asm volatile("eieio":::"memory");
 				ste->dw0.dw0.v = 1;
 				return (global_entry | entry);
@@ -131,6 +139,8 @@ static int make_ste(unsigned long stab, 
 	old_esid = castout_ste->dw0.dw0.esid;
 	castout_ste->dw0.dw0.esid = esid;
 	castout_ste->dw0.dw0.kp = 1;
+	if (!kernel_segment)
+		castout_ste->dw0.dw0.ks = 1;
 	asm volatile("eieio" : : : "memory");   /* Order update */
 	castout_ste->dw0.dw0.v  = 1;
 	asm volatile("slbie  %0" : : "r" (old_esid << SID_SHIFT)); 
@@ -340,6 +350,8 @@ static void make_slbe(unsigned long esid
 		vsid_data.data.l = 1;
 	if (kernel_segment)
 		vsid_data.data.c = 1;
+	else
+		vsid_data.data.ks = 1;
 
 	esid_data.word0 = 0;
 	esid_data.data.esid = esid;
diff -purN linux-post-2.6.3-20040227/arch/ppc64/kernel/vio.c linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/vio.c
--- linux-post-2.6.3-20040227/arch/ppc64/kernel/vio.c	2004-02-25 02:54:12.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/kernel/vio.c	2004-02-27 12:22:02.000000000 +0000
@@ -20,7 +20,7 @@
 #include <linux/kobject.h>
 #include <linux/mm.h>
 #include <asm/rtas.h>
-#include <asm/pci_dma.h>
+#include <asm/iommu.h>
 #include <asm/dma.h>
 #include <asm/ppcdebug.h>
 #include <asm/vio.h>
@@ -29,12 +29,7 @@
 
 #define DBGENTER() pr_debug("%s entered\n", __FUNCTION__)
 
-extern struct TceTable *build_tce_table(struct TceTable *tbl);
-
-extern dma_addr_t get_tces(struct TceTable *, unsigned order,
-			   void *page, unsigned numPages, int direction);
-extern void tce_free(struct TceTable *tbl, dma_addr_t dma_addr,
-		     unsigned order, unsigned num_pages);
+struct iommu_table *vio_build_iommu_table(struct vio_dev *dev);
 
 static int vio_num_address_cells;
 static struct vio_dev *vio_bus_device; /* fake "parent" device */
@@ -150,7 +145,7 @@ static int __init vio_bus_init(void)
 		return 1;
 	}
 	memset(vio_bus_device, 0, sizeof(struct vio_dev));
-	strcpy(vio_bus_device->dev.bus_id, "vdevice");
+	strcpy(vio_bus_device->dev.bus_id, "vio");
 
 	err = device_register(&vio_bus_device->dev);
 	if (err) {
@@ -199,6 +194,15 @@ static void __devinit vio_dev_release(st
 	kfree(viodev);
 }
 
+static ssize_t viodev_show_name(struct device *dev, char *buf)
+{
+	struct vio_dev *viodev = to_vio_dev(dev);
+	struct device_node *of_node = viodev->archdata;
+
+	return sprintf(buf, "%s\n", of_node->name);
+}
+DEVICE_ATTR(name, S_IRUSR | S_IRGRP | S_IROTH, viodev_show_name, NULL);
+
 /**
  * vio_register_device: - Register a new vio device.
  * @of_node:	The OF node for this device.
@@ -240,7 +244,7 @@ struct vio_dev * __devinit vio_register_
 
 	viodev->archdata = (void *)of_node_get(of_node);
 	viodev->unit_address = *unit_address;
-	viodev->tce_table = vio_build_tce_table(viodev);
+	viodev->iommu_table = vio_build_iommu_table(viodev);
 
 	viodev->irq = NO_IRQ;
 	irq_p = (unsigned int *)get_property(of_node, "interrupts", 0);
@@ -256,8 +260,7 @@ struct vio_dev * __devinit vio_register_
 	/* init generic 'struct device' fields: */
 	viodev->dev.parent = &vio_bus_device->dev;
 	viodev->dev.bus = &vio_bus_type;
-	snprintf(viodev->dev.bus_id, BUS_ID_SIZE, "%s@%lx",
-		of_node->name, viodev->unit_address);
+	snprintf(viodev->dev.bus_id, BUS_ID_SIZE, "%lx", viodev->unit_address);
 	viodev->dev.release = vio_dev_release;
 
 	/* register with generic device framework */
@@ -268,6 +271,7 @@ struct vio_dev * __devinit vio_register_
 		kfree(viodev);
 		return NULL;
 	}
+	device_create_file(&viodev->dev, &dev_attr_name);
 
 	return viodev;
 }
@@ -296,16 +300,16 @@ const void * vio_get_attribute(struct vi
 EXPORT_SYMBOL(vio_get_attribute);
 
 /**
- * vio_build_tce_table: - gets the dma information from OF and builds the TCE tree.
+ * vio_build_iommu_table: - gets the dma information from OF and builds the TCE tree.
  * @dev: the virtual device.
  *
  * Returns a pointer to the built tce tree, or NULL if it can't
  * find property.
 */
-struct TceTable * vio_build_tce_table(struct vio_dev *dev)
+struct iommu_table * vio_build_iommu_table(struct vio_dev *dev)
 {
 	unsigned int *dma_window;
-	struct TceTable *newTceTable;
+	struct iommu_table *newTceTable;
 	unsigned long offset;
 	unsigned long size;
 	int dma_window_property_size;
@@ -315,14 +319,14 @@ struct TceTable * vio_build_tce_table(st
 		return NULL;
 	}
 
-	newTceTable = (struct TceTable *) kmalloc(sizeof(struct TceTable), GFP_KERNEL);
+	newTceTable = (struct iommu_table *) kmalloc(sizeof(struct iommu_table), GFP_KERNEL);
 
 	/* RPA docs say that #address-cells is always 1 for virtual
 		devices, but some older boxes' OF returns 2.  This should
 		be removed by GA, unless there is legacy OFs that still
 		have 2 for #address-cells */
-	size = ((dma_window[1+vio_num_address_cells]
-		>> PAGE_SHIFT) << 3) >> PAGE_SHIFT;
+	size = ((dma_window[1+vio_num_address_cells] >> PAGE_SHIFT) << 3)
+		>> PAGE_SHIFT;
 
 	/* This is just an ugly kludge. Remove as soon as the OF for all
 	machines actually follow the spec and encodes the offset field
@@ -332,7 +336,7 @@ struct TceTable * vio_build_tce_table(st
 	} else if (dma_window_property_size == 20) {
 		size = ((dma_window[4] >> PAGE_SHIFT) << 3) >> PAGE_SHIFT;
 	} else {
-		printk(KERN_WARNING "vio_build_tce_table: Invalid size of ibm,my-dma-window=%i, using 0x80 for size\n", dma_window_property_size);
+		printk(KERN_WARNING "vio_build_iommu_table: Invalid size of ibm,my-dma-window=%i, using 0x80 for size\n", dma_window_property_size);
 		size = 0x80;
 	}
 
@@ -342,14 +346,15 @@ struct TceTable * vio_build_tce_table(st
 	offset = dma_window[1] >>  PAGE_SHIFT;
 
 	/* TCE table size - measured in units of pages of tce table */
-	newTceTable->size = size;
+	newTceTable->it_size		= size;
 	/* offset for VIO should always be 0 */
-	newTceTable->startOffset = offset;
-	newTceTable->busNumber   = 0;
-	newTceTable->index       = (unsigned long)dma_window[0];
-	newTceTable->tceType     = TCE_VB;
+	newTceTable->it_offset		= offset;
+	newTceTable->it_busno		= 0;
+	newTceTable->it_index		= (unsigned long)dma_window[0];
+	newTceTable->it_type		= TCE_VB;
+	newTceTable->it_entrysize	= sizeof(union tce_entry);
 
-	return build_tce_table(newTceTable);
+	return iommu_init_table(newTceTable);
 }
 
 int vio_enable_interrupts(struct vio_dev *dev)
@@ -376,29 +381,21 @@ EXPORT_SYMBOL(vio_disable_interrupts);
 dma_addr_t vio_map_single(struct vio_dev *dev, void *vaddr,
 			  size_t size, int direction )
 {
-	struct TceTable * tbl;
+	struct iommu_table *tbl;
 	dma_addr_t dma_handle = NO_TCE;
 	unsigned long uaddr;
-	unsigned order, nPages;
+	unsigned int npages;
 
-	if(direction == PCI_DMA_NONE) BUG();
+	BUG_ON(direction == PCI_DMA_NONE);
 
 	uaddr = (unsigned long)vaddr;
-	nPages = PAGE_ALIGN( uaddr + size ) - ( uaddr & PAGE_MASK );
-	order = get_order( nPages & PAGE_MASK );
-	nPages >>= PAGE_SHIFT;
-
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("VIO_DMA: vio_map_single size to large: 0x%lx \n",size);
- 		return NO_TCE;
- 	}
+	npages = PAGE_ALIGN( uaddr + size ) - ( uaddr & PAGE_MASK );
+	npages >>= PAGE_SHIFT;
 
-	tbl = dev->tce_table;
+	tbl = dev->iommu_table;
 
-	if(tbl) {
-		dma_handle = get_tces(tbl, order, vaddr, nPages, direction);
+	if (tbl) {
+		dma_handle = iommu_alloc(tbl, vaddr, npages, direction, NULL);
 		dma_handle |= (uaddr & ~PAGE_MASK);
 	}
 
@@ -409,107 +406,92 @@ EXPORT_SYMBOL(vio_map_single);
 void vio_unmap_single(struct vio_dev *dev, dma_addr_t dma_handle,
 		      size_t size, int direction)
 {
-	struct TceTable * tbl;
-	unsigned order, nPages;
-
-	if (direction == PCI_DMA_NONE) BUG();
+	struct iommu_table * tbl;
+	unsigned int npages;
 
-	nPages = PAGE_ALIGN( dma_handle + size ) - ( dma_handle & PAGE_MASK );
-	order = get_order( nPages & PAGE_MASK );
-	nPages >>= PAGE_SHIFT;
+	BUG_ON(direction == PCI_DMA_NONE);
 
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("VIO_DMA: vio_unmap_single 0x%lx size to large: 0x%lx \n",(unsigned long)dma_handle,(unsigned long)size);
- 		return;
- 	}
+	npages = PAGE_ALIGN( dma_handle + size ) - ( dma_handle & PAGE_MASK );
+	npages >>= PAGE_SHIFT;
 
-	tbl = dev->tce_table;
-	if(tbl) tce_free(tbl, dma_handle, order, nPages);
+	tbl = dev->iommu_table;
+	if(tbl)
+		iommu_free(tbl, dma_handle, npages);
 }
 EXPORT_SYMBOL(vio_unmap_single);
 
 int vio_map_sg(struct vio_dev *vdev, struct scatterlist *sglist, int nelems,
 	       int direction)
 {
-	int i;
+	struct iommu_table *tbl;
+	unsigned long handle;
 
-	for (i = 0; i < nelems; i++) {
+	BUG_ON(direction == PCI_DMA_NONE);
 
-		/* 2.4 scsi scatterlists use address field.
-		   Not sure about other subsystems. */
-		void *vaddr;
-#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,5,0)
-		if (sglist->address)
-			vaddr = sglist->address;
-		else
-#endif
-			vaddr = page_address(sglist->page) + sglist->offset;
-
-		sglist->dma_address = vio_map_single(vdev, vaddr,
-						     sglist->length,
-						     direction);
-		sglist->dma_length = sglist->length;
-		sglist++;
-	}
+	if (nelems == 0)
+		return 0;
+
+	tbl = vdev->iommu_table;
+	if (!tbl)
+		return 0;
 
-	return nelems;
+	return iommu_alloc_sg(tbl, sglist, nelems, direction, &handle);
 }
 EXPORT_SYMBOL(vio_map_sg);
 
 void vio_unmap_sg(struct vio_dev *vdev, struct scatterlist *sglist, int nelems,
 		  int direction)
 {
-	while (nelems--) {
-		vio_unmap_single(vdev, sglist->dma_address,
-				 sglist->dma_length, direction);
-		sglist++;
-	}
+	struct iommu_table *tbl;
+
+	BUG_ON(direction == PCI_DMA_NONE);
+
+	tbl = vdev->iommu_table;
+	if (tbl)
+		iommu_free_sg(tbl, sglist, nelems, direction);
 }
+EXPORT_SYMBOL(vio_unmap_sg);
 
 void *vio_alloc_consistent(struct vio_dev *dev, size_t size,
 			   dma_addr_t *dma_handle)
 {
-	struct TceTable * tbl;
+	struct iommu_table * tbl;
 	void *ret = NULL;
-	unsigned order, nPages;
+	unsigned int npages, order;
 	dma_addr_t tce;
 
 	size = PAGE_ALIGN(size);
+	npages = size >> PAGE_SHIFT;
 	order = get_order(size);
-	nPages = 1 << order;
 
  	/* Client asked for way to much space.  This is checked later anyway */
 	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("VIO_DMA: vio_alloc_consistent size to large: 0x%lx \n",size);
+ 	if(order >= IOMAP_MAX_ORDER) {
+ 		printk("VIO_DMA: vio_alloc_consistent size to large: 0x%lx \n", size);
  		return (void *)NO_TCE;
  	}
 
-	tbl = dev->tce_table;
+	tbl = dev->iommu_table;
 
-	if ( tbl ) {
+	if (tbl) {
 		/* Alloc enough pages (and possibly more) */
-		ret = (void *)__get_free_pages( GFP_ATOMIC, order );
-		if ( ret ) {
+		ret = (void *)__get_free_pages(GFP_ATOMIC, order);
+		if (ret) {
 			/* Page allocation succeeded */
-			memset(ret, 0, nPages << PAGE_SHIFT);
+			memset(ret, 0, npages << PAGE_SHIFT);
 			/* Set up tces to cover the allocated range */
-			tce = get_tces( tbl, order, ret, nPages, PCI_DMA_BIDIRECTIONAL );
-			if ( tce == NO_TCE ) {
-				PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: get_tces failed\n" );
-				free_pages( (unsigned long)ret, order );
+			tce = iommu_alloc(tbl, ret, npages, PCI_DMA_BIDIRECTIONAL, NULL);
+			if (tce == NO_TCE) {
+				PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: iommu_alloc failed\n" );
+				free_pages((unsigned long)ret, order);
 				ret = NULL;
+			} else {
+				*dma_handle = tce;
 			}
-			else
-				{
-					*dma_handle = tce;
-				}
 		}
-		else PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: __get_free_pages failed for order = %d\n", order);
+		else PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: __get_free_pages failed for size = %d\n", size);
 	}
-	else PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: get_tce_table failed for 0x%016lx\n", dev);
+	else PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: get_iommu_table failed for 0x%016lx\n", dev);
 
 	PPCDBG(PPCDBG_TCE, "\tvio_alloc_consistent: dma_handle = 0x%16.16lx\n", *dma_handle);
 	PPCDBG(PPCDBG_TCE, "\tvio_alloc_consistent: return     = 0x%16.16lx\n", ret);
@@ -520,28 +502,20 @@ EXPORT_SYMBOL(vio_alloc_consistent);
 void vio_free_consistent(struct vio_dev *dev, size_t size,
 			 void *vaddr, dma_addr_t dma_handle)
 {
-	struct TceTable * tbl;
-	unsigned order, nPages;
+	struct iommu_table *tbl;
+	unsigned int npages;
 
 	PPCDBG(PPCDBG_TCE, "vio_free_consistent:\n");
 	PPCDBG(PPCDBG_TCE, "\tdev = 0x%16.16lx, size = 0x%16.16lx, dma_handle = 0x%16.16lx, vaddr = 0x%16.16lx\n", dev, size, dma_handle, vaddr);
 
 	size = PAGE_ALIGN(size);
-	order = get_order(size);
-	nPages = 1 << order;
-
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= NUM_TCE_LEVELS) {
- 		printk("PCI_DMA: pci_free_consistent size to large: 0x%lx \n",size);
- 		return;
- 	}
+	npages = size >> PAGE_SHIFT;
 
-	tbl = dev->tce_table;
+	tbl = dev->iommu_table;
 
 	if ( tbl ) {
-		tce_free(tbl, dma_handle, order, nPages);
-		free_pages( (unsigned long)vaddr, order );
+		iommu_free(tbl, dma_handle, npages);
+		free_pages((unsigned long)vaddr, get_order(size));
 	}
 }
 EXPORT_SYMBOL(vio_free_consistent);
diff -purN linux-post-2.6.3-20040227/arch/ppc64/mm/Makefile linux-post-2.6.4rc1-20040228/arch/ppc64/mm/Makefile
--- linux-post-2.6.3-20040227/arch/ppc64/mm/Makefile	2004-01-18 11:41:25.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/mm/Makefile	2004-02-27 12:16:07.000000000 +0000
@@ -4,6 +4,6 @@
 
 EXTRA_CFLAGS += -mno-minimal-toc
 
-obj-y := fault.o init.o imalloc.o hash_utils.o hash_low.o
+obj-y := fault.o init.o imalloc.o hash_utils.o hash_low.o tlb.o
 obj-$(CONFIG_DISCONTIGMEM) += numa.o
 obj-$(CONFIG_HUGETLB_PAGE) += hugetlbpage.o
diff -purN linux-post-2.6.3-20040227/arch/ppc64/mm/hash_utils.c linux-post-2.6.4rc1-20040228/arch/ppc64/mm/hash_utils.c
--- linux-post-2.6.3-20040227/arch/ppc64/mm/hash_utils.c	2004-02-12 04:32:56.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/mm/hash_utils.c	2004-02-27 12:16:07.000000000 +0000
@@ -61,6 +61,10 @@
  *
  */
 
+#ifdef CONFIG_PMAC_DART
+extern unsigned long dart_tablebase;
+#endif /* CONFIG_PMAC_DART */
+
 HTAB htab_data = {NULL, 0, 0, 0, 0};
 
 extern unsigned long _SDR1;
@@ -123,6 +127,7 @@ void __init htab_initialize(void)
 	unsigned long table, htab_size_bytes;
 	unsigned long pteg_count;
 	unsigned long mode_rw;
+	int i, use_largepages = 0;
 
 	/*
 	 * Calculate the required size of the htab.  We want the number of
@@ -165,18 +170,40 @@ void __init htab_initialize(void)
 
 	mode_rw = _PAGE_ACCESSED | _PAGE_COHERENT | PP_RWXX;
 
-	/* XXX we currently map kernel text rw, should fix this */
-	if ((cur_cpu_spec->cpu_features & CPU_FTR_16M_PAGE)
-	    && systemcfg->physicalMemorySize > 256*MB) {
-		create_pte_mapping((unsigned long)KERNELBASE, 
-				   KERNELBASE + 256*MB, mode_rw, 0);
-		create_pte_mapping((unsigned long)KERNELBASE + 256*MB, 
-				   KERNELBASE + (systemcfg->physicalMemorySize), 
-				   mode_rw, 1);
-	} else {
-		create_pte_mapping((unsigned long)KERNELBASE, 
-				   KERNELBASE+(systemcfg->physicalMemorySize), 
-				   mode_rw, 0);
+	/* On U3 based machines, we need to reserve the DART area and
+	 * _NOT_ map it to avoid cache paradoxes as it's remapped non
+	 * cacheable later on
+	 */
+	if (cur_cpu_spec->cpu_features & CPU_FTR_16M_PAGE)
+		use_largepages = 1;
+
+	/* add all physical memory to the bootmem map */
+	for (i=0; i < lmb.memory.cnt; i++) {
+		unsigned long base, size;
+
+		base = lmb.memory.region[i].physbase + KERNELBASE;
+		size = lmb.memory.region[i].size;
+
+#ifdef CONFIG_PMAC_DART
+		/* Do not map the DART space. Fortunately, it will be aligned
+		 * in such a way that it will not cross two lmb regions and will
+		 * fit within a single 16Mb page.
+		 * The DART space is assumed to be a full 16Mb region even if we
+		 * only use 2Mb of that space. We will use more of it later for
+		 * AGP GART. We have to use a full 16Mb large page.
+		 */
+		if (dart_tablebase != 0 && dart_tablebase >= base
+		    && dart_tablebase < (base + size)) {
+			if (base != dart_tablebase)
+				create_pte_mapping(base, dart_tablebase, mode_rw,
+						   use_largepages);
+			if ((base + size) > (dart_tablebase + 16*MB))
+				create_pte_mapping(dart_tablebase + 16*MB, base + size,
+						   mode_rw, use_largepages);
+			continue;
+		}
+#endif /* CONFIG_PMAC_DART */
+		create_pte_mapping(base, base + size, mode_rw, use_largepages);
 	}
 }
 #undef KB
@@ -326,8 +353,7 @@ void flush_hash_range(unsigned long cont
 		ppc_md.flush_hash_range(context, number, local);
 	} else {
 		int i;
-		struct ppc64_tlb_batch *batch =
-			&ppc64_tlb_batch[smp_processor_id()];
+		struct ppc64_tlb_batch *batch = &__get_cpu_var(ppc64_tlb_batch);
 
 		for (i = 0; i < number; i++)
 			flush_hash_page(context, batch->addr[i], batch->pte[i],
diff -purN linux-post-2.6.3-20040227/arch/ppc64/mm/init.c linux-post-2.6.4rc1-20040228/arch/ppc64/mm/init.c
--- linux-post-2.6.3-20040227/arch/ppc64/mm/init.c	2004-02-23 16:39:14.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/mm/init.c	2004-02-27 12:16:07.000000000 +0000
@@ -60,10 +60,8 @@
 #include <asm/ppcdebug.h>
 #include <asm/sections.h>
 #include <asm/system.h>
+#include <asm/iommu.h>
 
-#ifdef CONFIG_PPC_ISERIES
-#include <asm/iSeries/iSeries_dma.h>
-#endif
 
 struct mmu_context_queue_t mmu_context_queue;
 int mem_init_done;
@@ -76,11 +74,6 @@ extern struct task_struct *current_set[N
 extern pgd_t ioremap_dir[];
 pgd_t * ioremap_pgd = (pgd_t *)&ioremap_dir;
 
-static void * __ioremap_com(unsigned long addr, unsigned long pa, 
-			    unsigned long ea, unsigned long size, 
-			    unsigned long flags);
-static void map_io_page(unsigned long va, unsigned long pa, int flags);
-
 unsigned long klimit = (unsigned long)_end;
 
 HPTE *Hash=0;
@@ -91,58 +84,10 @@ unsigned long _ASR=0;
 /* max amount of RAM to use */
 unsigned long __max_memory;
 
-/* This is declared as we are using the more or less generic 
- * include/asm-ppc64/tlb.h file -- tgall
- */
-DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
-DEFINE_PER_CPU(struct pte_freelist_batch *, pte_freelist_cur);
-unsigned long pte_freelist_forced_free;
-
-#ifdef CONFIG_SMP
-static void pte_free_smp_sync(void *arg)
-{
-	/* Do nothing, just ensure we sync with all CPUs */
-}
-#endif
-
-/* This is only called when we are critically out of memory
- * (and fail to get a page in pte_free_tlb).
- */
-void pte_free_now(struct page *ptepage)
-{
-	pte_freelist_forced_free++;
-
-	smp_call_function(pte_free_smp_sync, NULL, 0, 1);
-
-	pte_free(ptepage);
-}
-
-static void pte_free_rcu_callback(void *arg)
-{
-	struct pte_freelist_batch *batch = arg;
-	unsigned int i;
-
-	for (i = 0; i < batch->index; i++)
-		pte_free(batch->pages[i]);
-	free_page((unsigned long)batch);
-}
-
-void pte_free_submit(struct pte_freelist_batch *batch)
-{
-	INIT_RCU_HEAD(&batch->rcu);
-	call_rcu(&batch->rcu, pte_free_rcu_callback, batch);
-}
-
-void pte_free_finish(void)
-{
-	/* This is safe as we are holding page_table_lock */
-	struct pte_freelist_batch **batchp = &__get_cpu_var(pte_freelist_cur);
-	
-	if (*batchp == NULL)
-		return;
-	pte_free_submit(*batchp);
-	*batchp = NULL;
-}
+/* info on what we think the IO hole is */
+unsigned long 	io_hole_start;
+unsigned long	io_hole_size;
+unsigned long	top_of_ram;
 
 void show_mem(void)
 {
@@ -173,17 +118,99 @@ void show_mem(void)
 	printk("%d pages swap cached\n",cached);
 }
 
+#ifdef CONFIG_PPC_ISERIES
+
+void *ioremap(unsigned long addr, unsigned long size)
+{
+	return (void *)addr;
+}
+
+extern void *__ioremap(unsigned long addr, unsigned long size,
+		       unsigned long flags)
+{
+	return (void *)addr;
+}
+
+void iounmap(void *addr)
+{
+	return;
+}
+
+#else
+
+/*
+ * map_io_page currently only called by __ioremap
+ * map_io_page adds an entry to the ioremap page table
+ * and adds an entry to the HPT, possibly bolting it
+ */
+static void map_io_page(unsigned long ea, unsigned long pa, int flags)
+{
+	pgd_t *pgdp;
+	pmd_t *pmdp;
+	pte_t *ptep;
+	unsigned long vsid;
+
+	if (mem_init_done) {
+		spin_lock(&ioremap_mm.page_table_lock);
+		pgdp = pgd_offset_i(ea);
+		pmdp = pmd_alloc(&ioremap_mm, pgdp, ea);
+		ptep = pte_alloc_kernel(&ioremap_mm, pmdp, ea);
+
+		pa = absolute_to_phys(pa);
+		set_pte(ptep, pfn_pte(pa >> PAGE_SHIFT, __pgprot(flags)));
+		spin_unlock(&ioremap_mm.page_table_lock);
+	} else {
+		unsigned long va, vpn, hash, hpteg;
+
+		/*
+		 * If the mm subsystem is not fully up, we cannot create a
+		 * linux page table entry for this mapping.  Simply bolt an
+		 * entry in the hardware page table.
+		 */
+		vsid = get_kernel_vsid(ea);
+		va = (vsid << 28) | (ea & 0xFFFFFFF);
+		vpn = va >> PAGE_SHIFT;
+
+		hash = hpt_hash(vpn, 0);
+
+		hpteg = ((hash & htab_data.htab_hash_mask)*HPTES_PER_GROUP);
+
+		/* Panic if a pte grpup is full */
+		if (ppc_md.hpte_insert(hpteg, va, pa >> PAGE_SHIFT, 0,
+				       _PAGE_NO_CACHE|_PAGE_GUARDED|PP_RWXX,
+				       1, 0) == -1) {
+			panic("map_io_page: could not insert mapping");
+		}
+	}
+}
+
+
+static void * __ioremap_com(unsigned long addr, unsigned long pa,
+			    unsigned long ea, unsigned long size,
+			    unsigned long flags)
+{
+	unsigned long i;
+
+	if ((flags & _PAGE_PRESENT) == 0)
+		flags |= pgprot_val(PAGE_KERNEL);
+	if (flags & (_PAGE_NO_CACHE | _PAGE_WRITETHRU))
+		flags |= _PAGE_GUARDED;
+
+	for (i = 0; i < size; i += PAGE_SIZE) {
+		map_io_page(ea+i, pa+i, flags);
+	}
+
+	return (void *) (ea + (addr & ~PAGE_MASK));
+}
+
+
 void *
 ioremap(unsigned long addr, unsigned long size)
 {
-#ifdef CONFIG_PPC_ISERIES
-	return (void*)addr;
-#else
 	void *ret = __ioremap(addr, size, _PAGE_NO_CACHE);
 	if(mem_init_done)
 		return eeh_ioremap(addr, ret);	/* may remap the addr */
 	return ret;
-#endif
 }
 
 void *
@@ -329,7 +356,7 @@ static void unmap_im_area_pmd(pgd_t *dir
  *
  * XXX	what about calls before mem_init_done (ie python_countermeasures())	
  */
-void pSeries_iounmap(void *addr)
+void iounmap(void *addr)
 {
 	unsigned long address, start, end, size;
 	struct mm_struct *mm;
@@ -355,29 +382,18 @@ void pSeries_iounmap(void *addr)
 	spin_lock(&mm->page_table_lock);
 
 	dir = pgd_offset_i(address);
-	flush_cache_all();
+	flush_cache_vunmap(address, end);
 	do {
 		unmap_im_area_pmd(dir, address, end - address);
 		address = (address + PGDIR_SIZE) & PGDIR_MASK;
 		dir++;
 	} while (address && (address < end));
-	__flush_tlb_range(mm, start, end);
+	flush_tlb_kernel_range(start, end);
 
 	spin_unlock(&mm->page_table_lock);
 	return;
 }
 
-void iounmap(void *addr) 
-{
-#ifdef CONFIG_PPC_ISERIES
-	/* iSeries I/O Remap is a noop              */
-	return;
-#else
-	/* DRENG / PPPBBB todo */
-	return pSeries_iounmap(addr);
-#endif
-}
-
 int iounmap_explicit(void *addr, unsigned long size)
 {
 	struct vm_struct *area;
@@ -402,216 +418,7 @@ int iounmap_explicit(void *addr, unsigne
 	return 0;
 }
 
-static void * __ioremap_com(unsigned long addr, unsigned long pa, 
-			    unsigned long ea, unsigned long size, 
-			    unsigned long flags)
-{
-	unsigned long i;
-	
-	if ((flags & _PAGE_PRESENT) == 0)
-		flags |= pgprot_val(PAGE_KERNEL);
-	if (flags & (_PAGE_NO_CACHE | _PAGE_WRITETHRU))
-		flags |= _PAGE_GUARDED;
-
-	for (i = 0; i < size; i += PAGE_SIZE) {
-		map_io_page(ea+i, pa+i, flags);
-	}
-
-	return (void *) (ea + (addr & ~PAGE_MASK));
-}
-
-/*
- * map_io_page currently only called by __ioremap
- * map_io_page adds an entry to the ioremap page table
- * and adds an entry to the HPT, possibly bolting it
- */
-static void map_io_page(unsigned long ea, unsigned long pa, int flags)
-{
-	pgd_t *pgdp;
-	pmd_t *pmdp;
-	pte_t *ptep;
-	unsigned long vsid;
-	
-	if (mem_init_done) {
-		spin_lock(&ioremap_mm.page_table_lock);
-		pgdp = pgd_offset_i(ea);
-		pmdp = pmd_alloc(&ioremap_mm, pgdp, ea);
-		ptep = pte_alloc_kernel(&ioremap_mm, pmdp, ea);
-
-		pa = absolute_to_phys(pa);
-		set_pte(ptep, pfn_pte(pa >> PAGE_SHIFT, __pgprot(flags)));
-		spin_unlock(&ioremap_mm.page_table_lock);
-	} else {
-		unsigned long va, vpn, hash, hpteg;
-
-		/*
-		 * If the mm subsystem is not fully up, we cannot create a
-		 * linux page table entry for this mapping.  Simply bolt an
-		 * entry in the hardware page table. 
-		 */
-		vsid = get_kernel_vsid(ea);
-		va = (vsid << 28) | (ea & 0xFFFFFFF);
-		vpn = va >> PAGE_SHIFT;
-
-		hash = hpt_hash(vpn, 0);
-
-		hpteg = ((hash & htab_data.htab_hash_mask)*HPTES_PER_GROUP);
-
-		/* Panic if a pte grpup is full */
-		if (ppc_md.hpte_insert(hpteg, va, pa >> PAGE_SHIFT, 0,
-				       _PAGE_NO_CACHE|_PAGE_GUARDED|PP_RWXX,
-				       1, 0) == -1) {
-			panic("map_io_page: could not insert mapping");
-		}
-	}
-}
-
-void
-flush_tlb_mm(struct mm_struct *mm)
-{
-	struct vm_area_struct *mp;
-
-	spin_lock(&mm->page_table_lock);
-
-	for (mp = mm->mmap; mp != NULL; mp = mp->vm_next)
-		__flush_tlb_range(mm, mp->vm_start, mp->vm_end);
-
-	/* XXX are there races with checking cpu_vm_mask? - Anton */
-	cpus_clear(mm->cpu_vm_mask);
-
-	spin_unlock(&mm->page_table_lock);
-}
-
-/*
- * Callers should hold the mm->page_table_lock
- */
-void
-flush_tlb_page(struct vm_area_struct *vma, unsigned long vmaddr)
-{
-	unsigned long context = 0;
-	pgd_t *pgd;
-	pmd_t *pmd;
-	pte_t *ptep;
-	pte_t pte;
-	int local = 0;
-	cpumask_t tmp;
-
-	switch( REGION_ID(vmaddr) ) {
-	case VMALLOC_REGION_ID:
-		pgd = pgd_offset_k( vmaddr );
-		break;
-	case IO_REGION_ID:
-		pgd = pgd_offset_i( vmaddr );
-		break;
-	case USER_REGION_ID:
-		pgd = pgd_offset( vma->vm_mm, vmaddr );
-		context = vma->vm_mm->context;
-
-		/* XXX are there races with checking cpu_vm_mask? - Anton */
-		tmp = cpumask_of_cpu(smp_processor_id());
-		if (cpus_equal(vma->vm_mm->cpu_vm_mask, tmp))
-			local = 1;
-
-		break;
-	default:
-		panic("flush_tlb_page: invalid region 0x%016lx", vmaddr);
-	
-	}
-
-	if (!pgd_none(*pgd)) {
-		pmd = pmd_offset(pgd, vmaddr);
-		if (pmd_present(*pmd)) {
-			ptep = pte_offset_kernel(pmd, vmaddr);
-			/* Check if HPTE might exist and flush it if so */
-			pte = __pte(pte_update(ptep, _PAGE_HPTEFLAGS, 0));
-			if ( pte_val(pte) & _PAGE_HASHPTE ) {
-				flush_hash_page(context, vmaddr, pte, local);
-			}
-		}
-		WARN_ON(pmd_hugepage(*pmd));
-	}
-}
-
-struct ppc64_tlb_batch ppc64_tlb_batch[NR_CPUS];
-
-void
-__flush_tlb_range(struct mm_struct *mm, unsigned long start, unsigned long end)
-{
-	pgd_t *pgd;
-	pmd_t *pmd;
-	pte_t *ptep;
-	pte_t pte;
-	unsigned long pgd_end, pmd_end;
-	unsigned long context = 0;
-	struct ppc64_tlb_batch *batch = &ppc64_tlb_batch[smp_processor_id()];
-	unsigned long i = 0;
-	int local = 0;
-	cpumask_t tmp;
-
-	switch(REGION_ID(start)) {
-	case VMALLOC_REGION_ID:
-		pgd = pgd_offset_k(start);
-		break;
-	case IO_REGION_ID:
-		pgd = pgd_offset_i(start);
-		break;
-	case USER_REGION_ID:
-		pgd = pgd_offset(mm, start);
-		context = mm->context;
-
-		/* XXX are there races with checking cpu_vm_mask? - Anton */
-		tmp = cpumask_of_cpu(smp_processor_id());
-		if (cpus_equal(mm->cpu_vm_mask, tmp))
-			local = 1;
-
-		break;
-	default:
-		panic("flush_tlb_range: invalid region for start (%016lx) and end (%016lx)\n", start, end);
-	}
-
-	do {
-		pgd_end = (start + PGDIR_SIZE) & PGDIR_MASK;
-		if (pgd_end > end)
-			pgd_end = end;
-		if (!pgd_none(*pgd)) {
-			pmd = pmd_offset(pgd, start);
-			do {
-				pmd_end = (start + PMD_SIZE) & PMD_MASK;
-				if (pmd_end > end)
-					pmd_end = end;
-				if (pmd_present(*pmd)) {
-					ptep = pte_offset_kernel(pmd, start);
-					do {
-						if (pte_val(*ptep) & _PAGE_HASHPTE) {
-							pte = __pte(pte_update(ptep, _PAGE_HPTEFLAGS, 0));
-							if (pte_val(pte) & _PAGE_HASHPTE) {								
-								batch->pte[i] = pte;
-								batch->addr[i] = start;
-								i++;
-								if (i == PPC64_TLB_BATCH_NR) {
-									flush_hash_range(context, i, local);
-									i = 0;
-								}
-							}
-						}
-						start += PAGE_SIZE;
-						++ptep;
-					} while (start < pmd_end);
-				} else {
-					WARN_ON(pmd_hugepage(*pmd));
-					start = pmd_end;
-				}
-				++pmd;
-			} while (start < pgd_end);
-		} else {
-			start = pgd_end;
-		}
-		++pgd;
-	} while (start < end);
-
-	if (i)
-		flush_hash_range(context, i, local);
-}
+#endif
 
 void free_initmem(void)
 {
@@ -647,8 +454,7 @@ void free_initrd_mem(unsigned long start
  */
 void __init mm_init_ppc64(void)
 {
-	struct paca_struct *lpaca;
-	unsigned long guard_page, index;
+	unsigned long i;
 
 	ppc64_boot_msg(0x100, "MM Init");
 
@@ -660,20 +466,63 @@ void __init mm_init_ppc64(void)
 	mmu_context_queue.head = 0;
 	mmu_context_queue.tail = NUM_USER_CONTEXT-1;
 	mmu_context_queue.size = NUM_USER_CONTEXT;
-	for(index=0; index < NUM_USER_CONTEXT ;index++) {
-		mmu_context_queue.elements[index] = index+FIRST_USER_CONTEXT;
-	}
+	for (i = 0; i < NUM_USER_CONTEXT; i++)
+		mmu_context_queue.elements[i] = i + FIRST_USER_CONTEXT;
+
+	/* This is the story of the IO hole... please, keep seated,
+	 * unfortunately, we are out of oxygen masks at the moment.
+	 * So we need some rough way to tell where your big IO hole
+	 * is. On pmac, it's between 2G and 4G, on POWER3, it's around
+	 * that area as well, on POWER4 we don't have one, etc...
+	 * We need that to implement something approx. decent for
+	 * page_is_ram() so that /dev/mem doesn't map cacheable IO space
+	 * when XFree resquest some IO regions witout using O_SYNC, we
+	 * also need that as a "hint" when sizing the TCE table on POWER3
+	 * So far, the simplest way that seem work well enough for us it
+	 * to just assume that the first discontinuity in our physical
+	 * RAM layout is the IO hole. That may not be correct in the future
+	 * (and isn't on iSeries but then we don't care ;)
+	 */
+	top_of_ram = lmb_end_of_DRAM();
 
-	/* Setup guard pages for the Paca's */
-	for (index = 0; index < NR_CPUS; index++) {
-		lpaca = &paca[index];
-		guard_page = ((unsigned long)lpaca) + 0x1000;
-		ppc_md.hpte_updateboltedpp(PP_RXRX, guard_page);
+#ifndef CONFIG_PPC_ISERIES
+	for (i = 1; i < lmb.memory.cnt; i++) {
+		unsigned long base, prevbase, prevsize;
+
+		prevbase = lmb.memory.region[i-1].physbase;
+		prevsize = lmb.memory.region[i-1].size;
+		base = lmb.memory.region[i].physbase;
+		if (base > (prevbase + prevsize)) {
+			io_hole_start = prevbase + prevsize;
+			io_hole_size = base  - (prevbase + prevsize);
+			break;
+		}
 	}
+#endif /* CONFIG_PPC_ISERIES */
+	if (io_hole_start)
+		printk("IO Hole assumed to be %lx -> %lx\n",
+		       io_hole_start, io_hole_start + io_hole_size - 1);
 
 	ppc64_boot_msg(0x100, "MM Init Done");
 }
 
+
+/*
+ * This is called by /dev/mem to know if a given address has to
+ * be mapped non-cacheable or not
+ */
+int page_is_ram(unsigned long physaddr)
+{
+#ifdef CONFIG_PPC_ISERIES
+	return 1;
+#endif
+	if (physaddr >= top_of_ram)
+		return 0;
+	return io_hole_start == 0 ||  physaddr < io_hole_start ||
+		physaddr >= (io_hole_start + io_hole_size);
+}
+
+
 /*
  * Initialize the bootmem system and give it all the memory we
  * have available.
@@ -698,7 +547,7 @@ void __init do_init_bootmem(void)
 
 	boot_mapsize = init_bootmem(start >> PAGE_SHIFT, total_pages);
 
-	/* add all physical memory to the bootmem map */
+	/* add all physical memory to the bootmem map. Also find the first */
 	for (i=0; i < lmb.memory.cnt; i++) {
 		unsigned long physbase, size;
 
@@ -721,17 +570,28 @@ void __init do_init_bootmem(void)
  */
 void __init paging_init(void)
 {
-	unsigned long zones_size[MAX_NR_ZONES], i;
-
+	unsigned long zones_size[MAX_NR_ZONES];
+	unsigned long zholes_size[MAX_NR_ZONES];
+	unsigned long total_ram = lmb_phys_mem_size();
+
+	printk(KERN_INFO "Top of RAM: 0x%lx, Total RAM: 0x%lx\n",
+	       top_of_ram, total_ram);
+	printk(KERN_INFO "Memory hole size: %ldMB\n",
+	       (top_of_ram - total_ram) >> 20);
 	/*
 	 * All pages are DMA-able so we put them all in the DMA zone.
 	 */
-	zones_size[ZONE_DMA] = lmb_end_of_DRAM() >> PAGE_SHIFT;
-	for (i = 1; i < MAX_NR_ZONES; i++)
-		zones_size[i] = 0;
-	free_area_init(zones_size);
+	memset(zones_size, 0, sizeof(zones_size));
+	memset(zholes_size, 0, sizeof(zholes_size));
+
+	zones_size[ZONE_DMA] = top_of_ram >> PAGE_SHIFT;
+	zholes_size[ZONE_DMA] = (top_of_ram - total_ram) >> PAGE_SHIFT;
+
+	free_area_init_node(0, &contig_page_data, NULL, zones_size,
+			    __pa(PAGE_OFFSET) >> PAGE_SHIFT, zholes_size);
+	mem_map = contig_page_data.node_mem_map;
 }
-#endif
+#endif /* CONFIG_DISCONTIGMEM */
 
 static struct kcore_list kcore_vmem;
 
@@ -827,7 +687,7 @@ void __init mem_init(void)
 	mem_init_done = 1;
 
 #ifdef CONFIG_PPC_ISERIES
-	create_virtual_bus_tce_table();
+	iommu_vio_init();
 #endif
 }
 
diff -purN linux-post-2.6.3-20040227/arch/ppc64/mm/numa.c linux-post-2.6.4rc1-20040228/arch/ppc64/mm/numa.c
--- linux-post-2.6.3-20040227/arch/ppc64/mm/numa.c	2004-02-23 16:39:13.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/mm/numa.c	2004-02-27 22:42:19.000000000 +0000
@@ -30,6 +30,7 @@ int nr_cpus_in_node[MAX_NUMNODES] = { [0
 
 struct pglist_data node_data[MAX_NUMNODES];
 bootmem_data_t plat_node_bdata[MAX_NUMNODES];
+static unsigned long node0_io_hole_size;
 
 EXPORT_SYMBOL(node_data);
 EXPORT_SYMBOL(numa_memory_lookup_table);
@@ -205,8 +206,15 @@ err:
 
 static void __init setup_nonnuma(void)
 {
+	unsigned long top_of_ram = lmb_end_of_DRAM();
+	unsigned long total_ram = lmb_phys_mem_size();
 	unsigned long i;
 
+	printk(KERN_INFO "Top of RAM: 0x%lx, Total RAM: 0x%lx\n",
+	       top_of_ram, total_ram);
+	printk(KERN_INFO "Memory hole size: %ldMB\n",
+	       (top_of_ram - total_ram) >> 20);
+
 	for (i = 0; i < NR_CPUS; i++)
 		map_cpu_to_node(i, 0);
 
@@ -215,8 +223,10 @@ static void __init setup_nonnuma(void)
 	node_data[0].node_start_pfn = 0;
 	node_data[0].node_spanned_pages = lmb_end_of_DRAM() / PAGE_SIZE;
 
-	for (i = 0 ; i < lmb_end_of_DRAM(); i += MEMORY_INCREMENT)
+	for (i = 0 ; i < top_of_ram; i += MEMORY_INCREMENT)
 		numa_memory_lookup_table[i >> MEMORY_INCREMENT_SHIFT] = 0;
+
+	node0_io_hole_size = top_of_ram - total_ram;
 }
 
 void __init do_init_bootmem(void)
@@ -309,11 +319,12 @@ void __init do_init_bootmem(void)
 void __init paging_init(void)
 {
 	unsigned long zones_size[MAX_NR_ZONES];
-	int i, nid;
+	unsigned long zholes_size[MAX_NR_ZONES];
 	struct page *node_mem_map; 
+	int nid;
 
-	for (i = 1; i < MAX_NR_ZONES; i++)
-		zones_size[i] = 0;
+	memset(zones_size, 0, sizeof(zones_size));
+	memset(zholes_size, 0, sizeof(zholes_size));
 
 	for (nid = 0; nid < numnodes; nid++) {
 		unsigned long start_pfn;
@@ -323,8 +334,12 @@ void __init paging_init(void)
 		end_pfn = plat_node_bdata[nid].node_low_pfn;
 
 		zones_size[ZONE_DMA] = end_pfn - start_pfn;
-		dbg("free_area_init node %d %lx %lx\n", nid,
-				zones_size[ZONE_DMA], start_pfn);
+		zholes_size[ZONE_DMA] = 0;
+		if (nid == 0)
+			zholes_size[ZONE_DMA] = node0_io_hole_size;
+
+		dbg("free_area_init node %d %lx %lx (hole: %lx)\n", nid,
+		    zones_size[ZONE_DMA], start_pfn, zholes_size[ZONE_DMA]);
 
 		/* 
 		 * Give this empty node a dummy struct page to avoid
@@ -337,6 +352,6 @@ void __init paging_init(void)
 			node_mem_map = NULL;
 
 		free_area_init_node(nid, NODE_DATA(nid), node_mem_map,
-				    zones_size, start_pfn, NULL);
+				    zones_size, start_pfn, zholes_size);
 	}
 }
diff -purN linux-post-2.6.3-20040227/arch/ppc64/mm/tlb.c linux-post-2.6.4rc1-20040228/arch/ppc64/mm/tlb.c
--- linux-post-2.6.3-20040227/arch/ppc64/mm/tlb.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/arch/ppc64/mm/tlb.c	2004-02-27 12:40:06.000000000 +0000
@@ -0,0 +1,155 @@
+/*
+ * This file contains the routines for flushing entries from the
+ * TLB and MMU hash table.
+ *
+ *  Derived from arch/ppc64/mm/init.c:
+ *    Copyright (C) 1995-1996 Gary Thomas (gdt@linuxppc.org)
+ *
+ *  Modifications by Paul Mackerras (PowerMac) (paulus@cs.anu.edu.au)
+ *  and Cort Dougan (PReP) (cort@cs.nmt.edu)
+ *    Copyright (C) 1996 Paul Mackerras
+ *  Amiga/APUS changes by Jesper Skov (jskov@cygnus.co.uk).
+ *
+ *  Derived from "arch/i386/mm/init.c"
+ *    Copyright (C) 1991, 1992, 1993, 1994  Linus Torvalds
+ *
+ *  Dave Engebretsen <engebret@us.ibm.com>
+ *      Rework for PPC64 port.
+ *
+ *  This program is free software; you can redistribute it and/or
+ *  modify it under the terms of the GNU General Public License
+ *  as published by the Free Software Foundation; either version
+ *  2 of the License, or (at your option) any later version.
+ */
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/mm.h>
+#include <linux/init.h>
+#include <linux/percpu.h>
+#include <asm/pgalloc.h>
+#include <asm/tlbflush.h>
+#include <asm/tlb.h>
+#include <asm/hardirq.h>
+#include <linux/highmem.h>
+#include <asm/rmap.h>
+
+DEFINE_PER_CPU(struct ppc64_tlb_batch, ppc64_tlb_batch);
+
+/* This is declared as we are using the more or less generic
+ * include/asm-ppc64/tlb.h file -- tgall
+ */
+DEFINE_PER_CPU(struct mmu_gather, mmu_gathers);
+DEFINE_PER_CPU(struct pte_freelist_batch *, pte_freelist_cur);
+unsigned long pte_freelist_forced_free;
+
+/*
+ * Update the MMU hash table to correspond with a change to
+ * a Linux PTE.  If wrprot is true, it is permissible to
+ * change the existing HPTE to read-only rather than removing it
+ * (if we remove it we should clear the _PTE_HPTEFLAGS bits).
+ */
+void hpte_update(pte_t *ptep, unsigned long pte, int wrprot)
+{
+	struct page *ptepage;
+	struct mm_struct *mm;
+	unsigned long addr;
+	int i;
+	unsigned long context = 0;
+	struct ppc64_tlb_batch *batch = &__get_cpu_var(ppc64_tlb_batch);
+
+	ptepage = virt_to_page(ptep);
+	mm = (struct mm_struct *) ptepage->mapping;
+	addr = ptep_to_address(ptep);
+
+	if (REGION_ID(addr) == USER_REGION_ID)
+		context = mm->context;
+	i = batch->index;
+
+	/*
+	 * This can happen when we are in the middle of a TLB batch and
+	 * we encounter memory pressure (eg copy_page_range when it tries
+	 * to allocate a new pte). If we have to reclaim memory and end
+	 * up scanning and resetting referenced bits then our batch context
+	 * will change mid stream.
+	 */
+	if (unlikely(i != 0 && context != batch->context)) {
+		flush_tlb_pending();
+		i = 0;
+	}
+
+	if (i == 0) {
+		batch->context = context;
+		batch->mm = mm;
+	}
+	batch->pte[i] = __pte(pte);
+	batch->addr[i] = addr;
+	batch->index = ++i;
+	if (i >= PPC64_TLB_BATCH_NR)
+		flush_tlb_pending();
+}
+
+void __flush_tlb_pending(struct ppc64_tlb_batch *batch)
+{
+	int i;
+	cpumask_t tmp = cpumask_of_cpu(smp_processor_id());
+	int local = 0;
+
+	BUG_ON(in_interrupt());
+
+	i = batch->index;
+	if (cpus_equal(batch->mm->cpu_vm_mask, tmp))
+		local = 1;
+
+	if (i == 1)
+		flush_hash_page(batch->context, batch->addr[0], batch->pte[0],
+				local);
+	else
+		flush_hash_range(batch->context, i, local);
+	batch->index = 0;
+}
+
+#ifdef CONFIG_SMP
+static void pte_free_smp_sync(void *arg)
+{
+	/* Do nothing, just ensure we sync with all CPUs */
+}
+#endif
+
+/* This is only called when we are critically out of memory
+ * (and fail to get a page in pte_free_tlb).
+ */
+void pte_free_now(struct page *ptepage)
+{
+	pte_freelist_forced_free++;
+
+	smp_call_function(pte_free_smp_sync, NULL, 0, 1);
+
+	pte_free(ptepage);
+}
+
+static void pte_free_rcu_callback(void *arg)
+{
+	struct pte_freelist_batch *batch = arg;
+	unsigned int i;
+
+	for (i = 0; i < batch->index; i++)
+		pte_free(batch->pages[i]);
+	free_page((unsigned long)batch);
+}
+
+void pte_free_submit(struct pte_freelist_batch *batch)
+{
+	INIT_RCU_HEAD(&batch->rcu);
+	call_rcu(&batch->rcu, pte_free_rcu_callback, batch);
+}
+
+void pte_free_finish(void)
+{
+	/* This is safe as we are holding page_table_lock */
+	struct pte_freelist_batch **batchp = &__get_cpu_var(pte_freelist_cur);
+
+	if (*batchp == NULL)
+		return;
+	pte_free_submit(*batchp);
+	*batchp = NULL;
+}
diff -purN linux-post-2.6.3-20040227/drivers/char/mem.c linux-post-2.6.4rc1-20040228/drivers/char/mem.c
--- linux-post-2.6.3-20040227/drivers/char/mem.c	2004-02-19 03:42:45.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/char/mem.c	2004-02-27 22:44:02.000000000 +0000
@@ -67,6 +67,14 @@ static inline int uncached_access(struct
 	 * On ia64, we ignore O_SYNC because we cannot tolerate memory attribute aliases.
 	 */
 	return !(efi_mem_attributes(addr) & EFI_MEMORY_WB);
+#elif defined(CONFIG_PPC64)
+	/* On PPC64, we always do non-cacheable access to the IO hole and
+	 * cacheable elsewhere. Cache paradox can checkstop the CPU and
+	 * the high_memory heuristic below is wrong on machines with memory
+	 * above the IO hole... Ah, and of course, XFree86 doesn't pass
+	 * O_SYNC when mapping us to tap IO space. Surprised ?
+	 */
+	return !page_is_ram(addr);
 #else
 	/*
 	 * Accessing memory above the top the kernel knows about or through a file pointer
diff -purN linux-post-2.6.3-20040227/drivers/ide/ide-probe.c linux-post-2.6.4rc1-20040228/drivers/ide/ide-probe.c
--- linux-post-2.6.3-20040227/drivers/ide/ide-probe.c	2004-02-19 00:41:22.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/ide/ide-probe.c	2004-02-27 13:02:07.000000000 +0000
@@ -50,6 +50,7 @@
 #include <linux/spinlock.h>
 #include <linux/pci.h>
 #include <linux/kmod.h>
+#include <linux/pci.h>
 
 #include <asm/byteorder.h>
 #include <asm/irq.h>
@@ -904,6 +905,7 @@ static int ide_init_queue(ide_drive_t *d
 	request_queue_t *q;
 	ide_hwif_t *hwif = HWIF(drive);
 	int max_sectors = 256;
+	int max_sg_entries = PRD_ENTRIES;
 
 	/*
 	 *	Our default set up assumes the normal IDE case,
@@ -926,11 +928,22 @@ static int ide_init_queue(ide_drive_t *d
 		max_sectors = hwif->rqsize;
 	blk_queue_max_sectors(q, max_sectors);
 
-	/* IDE DMA can do PRD_ENTRIES number of segments. */
-	blk_queue_max_hw_segments(q, PRD_ENTRIES);
+#ifdef CONFIG_PCI
+	/* When we have an IOMMU, we may have a problem where pci_map_sg()
+	 * creates segments that don't completely match our boundary
+	 * requirements and thus need to be broken up again. Because it
+	 * doesn't align properly neither, we may actually have to break up
+	 * to more segments than what was we got in the first place, a max
+	 * worst case is twice as many.
+	 * This will be fixed once we teach pci_map_sg() about our boundary
+	 * requirements, hopefully soon
+	 */
+	if (!PCI_DMA_BUS_IS_PHYS)
+		max_sg_entries >>= 1;
+#endif /* CONFIG_PCI */
 
-	/* This is a driver limit and could be eliminated. */
-	blk_queue_max_phys_segments(q, PRD_ENTRIES);
+	blk_queue_max_hw_segments(q, max_sg_entries);
+	blk_queue_max_phys_segments(q, max_sg_entries);
 
 	/* assign drive and gendisk queue */
 	drive->queue = q;
diff -purN linux-post-2.6.3-20040227/drivers/ide/pci/piix.h linux-post-2.6.4rc1-20040228/drivers/ide/pci/piix.h
--- linux-post-2.6.3-20040227/drivers/ide/pci/piix.h	2004-02-27 03:26:53.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/ide/pci/piix.h	2004-02-27 18:01:42.000000000 +0000
@@ -13,39 +13,32 @@ static void init_setup_piix(struct pci_d
 static unsigned int __devinit init_chipset_piix(struct pci_dev *, const char *);
 static void init_hwif_piix(ide_hwif_t *);
 
+#define DECLARE_PIIX_DEV(pci_id, name_str) \
+	{						\
+		.vendor		= PCI_VENDOR_ID_INTEL,	\
+		.device		= pci_id,		\
+		.name		= name_str,		\
+		.init_setup	= init_setup_piix,	\
+		.init_chipset	= init_chipset_piix,	\
+		.init_iops	= NULL,			\
+		.init_hwif	= init_hwif_piix,	\
+		.channels	= 2,			\
+		.autodma	= AUTODMA,		\
+		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}}, \
+		.bootable	= ON_BOARD,		\
+		.extra		= 0,			\
+	}
+
 /*
  *	Table of the various PIIX capability blocks
  *
  */
  
 static ide_pci_device_t piix_pci_info[] __devinitdata = {
-	{	/* 0 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82371FB_0,
-		.name		= "PIIXa",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 1 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82371FB_1,
-		.name		= "PIIXb",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 2 */
+	/* 0  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82371FB_0,  "PIIXa"),
+	/* 1  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82371FB_1,  "PIIXb"),
+
+	{	/* 2 */
 		.vendor		= PCI_VENDOR_ID_INTEL,
 		.device		= PCI_DEVICE_ID_INTEL_82371MX,
 		.name		= "MPIIX",
@@ -58,241 +51,27 @@ static ide_pci_device_t piix_pci_info[] 
 		.enablebits	= {{0x6D,0x80,0x80}, {0x6F,0x80,0x80}},
 		.bootable	= ON_BOARD,
 		.extra		= 0,
-	},{	/* 3 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82371SB_1,
-		.name		= "PIIX3",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 4 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82371AB,
-		.name		= "PIIX4",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 5 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801AB_1,
-		.name		= "ICH0",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 6 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82443MX_1,
-		.name		= "PIIX4",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 7 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801AA_1,
-		.name		= "ICH",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 8 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82372FB_1,
-		.name		= "PIIX4",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 9 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82451NX,
-		.name		= "PIIX4",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= NOAUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 10 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801BA_9,
-		.name		= "ICH2",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 11 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801BA_8,
-		.name		= "ICH2M",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 12 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801CA_10,
-		.name		= "ICH3M",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 13 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801CA_11,
-		.name		= "ICH3",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 14 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801DB_11,
-		.name		= "ICH4",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 15 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801EB_11,
-		.name		= "ICH5",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 16 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801E_11,
-		.name		= "C-ICH",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 17 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801DB_10,
-		.name		= "ICH4",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 18 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_82801EB_1,
-		.name		= "ICH5-SATA",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 19 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_ESB_2,
-		.name		= "ICH5",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{	/* 20 */
-		.vendor		= PCI_VENDOR_ID_INTEL,
-		.device		= PCI_DEVICE_ID_INTEL_ICH6_2,
-		.name		= "ICH6",
-		.init_setup	= init_setup_piix,
-		.init_chipset	= init_chipset_piix,
-		.init_iops	= NULL,
-		.init_hwif	= init_hwif_piix,
-		.channels	= 2,
-		.autodma	= AUTODMA,
-		.enablebits	= {{0x41,0x80,0x80}, {0x43,0x80,0x80}},
-		.bootable	= ON_BOARD,
-		.extra		= 0,
-	},{
+	},
+
+	/* 3  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82371SB_1,  "PIIX3"),
+	/* 4  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82371AB,    "PIIX4"),
+	/* 5  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801AB_1,  "ICH0"),
+	/* 6  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82443MX_1,  "PIIX4"),
+	/* 7  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801AA_1,  "ICH"),
+	/* 8  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82372FB_1,  "PIIX4"),
+	/* 9  */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82451NX,    "PIIX4"),
+	/* 10 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801BA_9,  "ICH2"),
+	/* 11 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801BA_8,  "ICH2M"),
+	/* 12 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801CA_10, "ICH3M"),
+	/* 13 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801CA_11, "ICH3"),
+	/* 14 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801DB_11, "ICH4"),
+	/* 15 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801EB_11, "ICH5"),
+	/* 16 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801E_11,  "C-ICH"),
+	/* 17 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801DB_10, "ICH4"),
+	/* 18 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_82801EB_1,  "ICH5-SATA"),
+	/* 19 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_ESB_2,      "ICH5"),
+	/* 20 */ DECLARE_PIIX_DEV(PCI_DEVICE_ID_INTEL_ICH6_2,     "ICH6"),
+	{
 		.vendor		= 0,
 		.device		= 0,
 		.channels	= 0,
diff -purN linux-post-2.6.3-20040227/drivers/mtd/afs.c linux-post-2.6.4rc1-20040228/drivers/mtd/afs.c
--- linux-post-2.6.3-20040227/drivers/mtd/afs.c	2003-06-23 12:18:11.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/mtd/afs.c	2004-02-27 22:12:51.000000000 +0000
@@ -57,6 +57,17 @@ struct image_info_struct {
 	u32 checksum;		/* Image checksum (inc. this struct)     */
 };
 
+static u32 word_sum(void *words, int num)
+{
+	u32 *p = words;
+	u32 sum = 0;
+
+	while (num--)
+		sum += *p++;
+
+	return sum;
+}
+
 static int
 afs_read_footer(struct mtd_info *mtd, u_int *img_start, u_int *iis_start,
 		u_int off, u_int mask)
@@ -85,6 +96,12 @@ afs_read_footer(struct mtd_info *mtd, u_
 		ret = 0;
 
 	/*
+	 * Check the checksum.
+	 */
+	if (word_sum(&fs, sizeof(fs) / sizeof(u32)) != 0xffffffff)
+		ret = 0;
+
+	/*
 	 * Don't touch the SIB.
 	 */
 	if (fs.type == 2)
@@ -114,16 +131,35 @@ static int
 afs_read_iis(struct mtd_info *mtd, struct image_info_struct *iis, u_int ptr)
 {
 	size_t sz;
-	int ret;
+	int ret, i;
 
 	memset(iis, 0, sizeof(*iis));
 	ret = mtd->read(mtd, ptr, sizeof(*iis), &sz, (u_char *) iis);
-	if (ret >= 0 && sz != sizeof(*iis))
-		ret = -EINVAL;
 	if (ret < 0)
-		printk(KERN_ERR "AFS: mtd read failed at 0x%x: %d\n",
-			ptr, ret);
+		goto failed;
+
+	if (sz != sizeof(*iis)) {
+		ret = -EINVAL;
+		goto failed;
+	}
+
+	ret = 0;
+
+	/*
+	 * Validate the name - it must be NUL terminated.
+	 */
+	for (i = 0; i < sizeof(iis->name); i++)
+		if (iis->name[i] == '\0')
+			break;
 
+	if (i < sizeof(iis->name))
+		ret = 1;
+
+	return ret;
+
+ failed:
+	printk(KERN_ERR "AFS: mtd read failed at 0x%x: %d\n",
+		ptr, ret);
 	return ret;
 }
 
@@ -160,6 +196,8 @@ static int parse_afs_partitions(struct m
 		ret = afs_read_iis(mtd, &iis, iis_ptr);
 		if (ret < 0)
 			break;
+		if (ret == 0)
+			continue;
 
 		sz += sizeof(struct mtd_partition);
 		sz += strlen(iis.name) + 1;
@@ -194,6 +232,8 @@ static int parse_afs_partitions(struct m
 		ret = afs_read_iis(mtd, &iis, iis_ptr);
 		if (ret < 0)
 			break;
+		if (ret == 0)
+			continue;
 
 		strcpy(str, iis.name);
 		size = mtd->erasesize + off - img_ptr;
diff -purN linux-post-2.6.3-20040227/drivers/mtd/maps/integrator-flash.c linux-post-2.6.4rc1-20040228/drivers/mtd/maps/integrator-flash.c
--- linux-post-2.6.3-20040227/drivers/mtd/maps/integrator-flash.c	2003-10-04 15:51:23.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/mtd/maps/integrator-flash.c	2004-02-27 22:43:16.000000000 +0000
@@ -1,8 +1,9 @@
 /*======================================================================
 
-    drivers/mtd/maps/armflash.c: ARM Flash Layout/Partitioning
+    drivers/mtd/maps/integrator-flash.c: ARM Integrator flash map driver
   
     Copyright (C) 2000 ARM Limited
+    Copyright (C) 2003 Deep Blue Solutions Ltd.
   
    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
@@ -21,7 +22,7 @@
    This is access code for flashes using ARM's flash partitioning 
    standards.
 
-   $Id: integrator-flash.c,v 1.12 2003/05/20 20:59:30 dwmw2 Exp $
+   $Id: integrator-flash.c,v 1.15 2004/02/27 22:37:39 rmk Exp $
 
 ======================================================================*/
 
@@ -64,7 +65,7 @@ static void armflash_set_vpp(struct map_
 		info->plat->set_vpp(on);
 }
 
-static const char *probes[] = { "RedBoot", "afs", NULL };
+static const char *probes[] = { "cmdlinepart", "RedBoot", "afs", NULL };
 
 static int armflash_probe(struct device *_dev)
 {
diff -purN linux-post-2.6.3-20040227/drivers/mtd/maps/lubbock-flash.c linux-post-2.6.4rc1-20040228/drivers/mtd/maps/lubbock-flash.c
--- linux-post-2.6.3-20040227/drivers/mtd/maps/lubbock-flash.c	2003-06-23 12:34:07.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/mtd/maps/lubbock-flash.c	2004-02-27 21:11:47.000000000 +0000
@@ -74,7 +74,7 @@ static int __init init_lubbock(void)
 	lubbock_maps[flashboot].name = "Lubbock Boot ROM";
 
 	for (i = 0; i < 2; i++) {
-		lubbock_maps[i].virt = (unsigned long)__ioremap(lubbock_maps[i].phys, WINDOW_SIZE, 0);
+		lubbock_maps[i].virt = (unsigned long)ioremap(lubbock_maps[i].phys, WINDOW_SIZE);
 		if (!lubbock_maps[i].virt) {
 			printk(KERN_WARNING "Failed to ioremap %s\n", lubbock_maps[i].name);
 			if (!ret)
@@ -97,8 +97,8 @@ static int __init init_lubbock(void)
 		}
 		mymtds[i]->owner = THIS_MODULE;
 
-		int ret = parse_mtd_partitions(mymtds[i], probes,
-					       &parsed_parts[i], 0);
+		ret = parse_mtd_partitions(mymtds[i], probes,
+					   &parsed_parts[i], 0);
 
 		if (ret > 0)
 			nr_parsed_parts[i] = ret;
diff -purN linux-post-2.6.3-20040227/drivers/pci/hotplug/Kconfig linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/Kconfig
--- linux-post-2.6.3-20040227/drivers/pci/hotplug/Kconfig	2004-02-26 17:59:20.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/Kconfig	2004-02-28 01:22:51.000000000 +0000
@@ -191,7 +191,7 @@ config HOTPLUG_PCI_SHPC_PHPRM_LEGACY
 
 config HOTPLUG_PCI_RPA
 	tristate "RPA PCI Hotplug driver"
-	depends on HOTPLUG_PCI && PPC_PSERIES && PPC64
+	depends on HOTPLUG_PCI && PPC_PSERIES && PPC64 && !HOTPLUG_PCI_FAKE
 	help
 	  Say Y here if you have a a RPA system that supports PCI Hotplug.
 
diff -purN linux-post-2.6.3-20040227/drivers/pci/hotplug/Makefile linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/Makefile
--- linux-post-2.6.3-20040227/drivers/pci/hotplug/Makefile	2004-02-10 19:01:04.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/Makefile	2004-02-24 14:04:19.000000000 +0000
@@ -25,6 +25,8 @@ cpqphp-objs		:=	cpqphp_core.o	\
 				cpqphp_ctrl.o	\
 				cpqphp_sysfs.o	\
 				cpqphp_pci.o
+cpqphp-$(CONFIG_HOTPLUG_PCI_COMPAQ_NVRAM) += cpqphp_nvram.o
+cpqphp-objs += $(cpqphp-y)
 
 ibmphp-objs		:=	ibmphp_core.o	\
 				ibmphp_ebda.o	\
@@ -49,37 +51,24 @@ pciehp-objs		:=	pciehp_core.o	\
 				pciehp_sysfs.o	\
 				pciehp_hpc.o
 
-shpchp-objs		:=	shpchp_core.o	\
-				shpchp_ctrl.o	\
-				shpchp_pci.o	\
-				shpchp_sysfs.o	\
-				shpchp_hpc.o
-
-ifdef CONFIG_HOTPLUG_PCI_ACPI
-  EXTRA_CFLAGS  += -D_LINUX -I$(TOPDIR)/drivers/acpi
-  ifdef CONFIG_ACPI_DEBUG
-    EXTRA_CFLAGS += -DACPI_DEBUG_OUTPUT
-  endif
-endif
-
-ifeq ($(CONFIG_HOTPLUG_PCI_COMPAQ_NVRAM),y)
-	cpqphp-objs += cpqphp_nvram.o
-endif
-
 ifeq ($(CONFIG_HOTPLUG_PCI_PCIE_PHPRM_NONACPI),y)
   pciehp-objs += pciehprm_nonacpi.o
 else
   pciehp-objs += pciehprm_acpi.o
-  EXTRA_CFLAGS  += -D_LINUX -I$(TOPDIR)/drivers/acpi -I$(TOPDIR)/drivers/acpi/include 
 endif
 
+shpchp-objs		:=	shpchp_core.o	\
+				shpchp_ctrl.o	\
+				shpchp_pci.o	\
+				shpchp_sysfs.o	\
+				shpchp_hpc.o
+
 ifeq ($(CONFIG_HOTPLUG_PCI_SHPC_PHPRM_LEGACY),y)
   shpchp-objs += shpchprm_legacy.o
 else
-   ifeq ($(CONFIG_HOTPLUG_PCI_SHPC_PHPRM_NONACPI),y)
-     shpchp-objs += shpchprm_nonacpi.o
-   else
-      shpchp-objs += shpchprm_acpi.o
-      EXTRA_CFLAGS  += -D_LINUX -I$(TOPDIR)/drivers/acpi 
-   endif
+  ifeq ($(CONFIG_HOTPLUG_PCI_SHPC_PHPRM_NONACPI),y)
+    shpchp-objs += shpchprm_nonacpi.o
+  else
+    shpchp-objs += shpchprm_acpi.o
+  endif
 endif
diff -purN linux-post-2.6.3-20040227/drivers/pci/hotplug/pciehp_ctrl.c linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/pciehp_ctrl.c
--- linux-post-2.6.3-20040227/drivers/pci/hotplug/pciehp_ctrl.c	2004-02-02 22:50:06.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/pciehp_ctrl.c	2004-02-23 22:45:31.000000000 +0000
@@ -188,11 +188,13 @@ u8 pciehp_handle_presence_change(u8 hp_s
 		/*
 		 * Card Present
 		 */
+		info("Card present on Slot(%d)\n", ctrl->first_slot + hp_slot);
 		taskInfo->event_type = INT_PRESENCE_ON;
 	} else {
 		/*
 		 * Not Present
 		 */
+		info("Card not present on Slot(%d)\n", ctrl->first_slot + hp_slot);
 		taskInfo->event_type = INT_PRESENCE_OFF;
 	}
 
diff -purN linux-post-2.6.3-20040227/drivers/pci/hotplug/rpaphp.h linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/rpaphp.h
--- linux-post-2.6.3-20040227/drivers/pci/hotplug/rpaphp.h	2004-02-18 14:23:27.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/rpaphp.h	2004-02-28 01:22:51.000000000 +0000
@@ -54,7 +54,7 @@
 
 #define dbg(format, arg...)					\
 	do {							\
-		if (rpaphp_debug)				\
+		if (debug)					\
 			printk(KERN_DEBUG "%s: " format,	\
 				MY_NAME , ## arg); 		\
 	} while (0)
diff -purN linux-post-2.6.3-20040227/drivers/pci/hotplug/rpaphp_core.c linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/rpaphp_core.c
--- linux-post-2.6.3-20040227/drivers/pci/hotplug/rpaphp_core.c	2004-02-18 14:23:27.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/rpaphp_core.c	2004-02-28 01:22:51.000000000 +0000
@@ -39,7 +39,7 @@
 #include "pci_hotplug.h"
 
 
-static int debug = 1;
+static int debug;
 static struct semaphore rpaphp_sem;
 static LIST_HEAD (rpaphp_slot_head);
 static int num_slots;
@@ -838,8 +838,6 @@ static int __init rpaphp_init(void)
 
 	info(DRIVER_DESC " version: " DRIVER_VERSION "\n");
 
-	rpaphp_debug = debug;
-
 	/* read all the PRA info from the system */
 	retval = init_rpa();
 
diff -purN linux-post-2.6.3-20040227/drivers/pci/hotplug/shpchp.h linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/shpchp.h
--- linux-post-2.6.3-20040227/drivers/pci/hotplug/shpchp.h	2004-02-02 16:32:53.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/shpchp.h	2004-02-23 22:53:13.000000000 +0000
@@ -390,8 +390,8 @@ static inline int wait_for_ctrl_irq (str
 		/* Sleep for up to 1 second */
 		schedule_timeout(1*HZ);
 	} else {
-		/* Sleep for up to 1.5 second */
-		schedule_timeout(1.5*HZ);
+		/* Sleep for up to 2 seconds */
+		schedule_timeout(2*HZ);
 	}
 	set_current_state(TASK_RUNNING);
 	remove_wait_queue(&ctrl->queue, &wait);
diff -purN linux-post-2.6.3-20040227/drivers/pci/hotplug/shpchp_ctrl.c linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/shpchp_ctrl.c
--- linux-post-2.6.3-20040227/drivers/pci/hotplug/shpchp_ctrl.c	2004-02-03 03:03:51.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/shpchp_ctrl.c	2004-02-23 22:45:31.000000000 +0000
@@ -192,11 +192,13 @@ u8 shpchp_handle_presence_change(u8 hp_s
 		/*
 		 * Card Present
 		 */
+		info("Card present on Slot(%d)\n", ctrl->first_slot + hp_slot);
 		taskInfo->event_type = INT_PRESENCE_ON;
 	} else {
 		/*
 		 * Not Present
 		 */
+		info("Card not present on Slot(%d)\n", ctrl->first_slot + hp_slot);
 		taskInfo->event_type = INT_PRESENCE_OFF;
 	}
 
diff -purN linux-post-2.6.3-20040227/drivers/pci/hotplug/shpchp_hpc.c linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/shpchp_hpc.c
--- linux-post-2.6.3-20040227/drivers/pci/hotplug/shpchp_hpc.c	2004-02-02 22:50:09.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/hotplug/shpchp_hpc.c	2004-02-23 22:45:31.000000000 +0000
@@ -1071,9 +1071,14 @@ static irqreturn_t shpc_isr(int IRQ, voi
 	if (!shpchp_poll_mode) { 
 		ctrl = (struct controller *)dev_id;
 		php_ctlr = ctrl->hpc_ctlr_handle;
-	} else 
+	} else { 
 		php_ctlr = (struct php_ctlr_state_s *) dev_id;
+		ctrl = (struct controller *)php_ctlr->callback_instance_id;
+	}
 
+	if (!ctrl)
+		return IRQ_NONE;
+	
 	if (!php_ctlr || !php_ctlr->creg)
 		return IRQ_NONE;
 
@@ -1085,18 +1090,20 @@ static irqreturn_t shpc_isr(int IRQ, voi
 	dbg("%s: shpc_isr proceeds\n", __FUNCTION__);
 	dbg("%s: intr_loc = %x\n",__FUNCTION__, intr_loc); 
 
-	/* Mask Global Interrupt Mask - see implementation note on p. 139 */
-	/* of SHPC spec rev 1.0*/
-	temp_dword = readl(php_ctlr->creg + SERR_INTR_ENABLE);
-	dbg("%s: Before masking global interrupt, temp_dword = %x\n",
-		__FUNCTION__, temp_dword); 
-	temp_dword |= 0x00000001;
-	dbg("%s: After masking global interrupt, temp_dword = %x\n",
-		__FUNCTION__, temp_dword); 
-	writel(temp_dword, php_ctlr->creg + SERR_INTR_ENABLE);
+	if(!shpchp_poll_mode) {
+		/* Mask Global Interrupt Mask - see implementation note on p. 139 */
+		/* of SHPC spec rev 1.0*/
+		temp_dword = readl(php_ctlr->creg + SERR_INTR_ENABLE);
+		dbg("%s: Before masking global interrupt, temp_dword = %x\n",
+			__FUNCTION__, temp_dword); 
+		temp_dword |= 0x00000001;
+		dbg("%s: After masking global interrupt, temp_dword = %x\n",
+			__FUNCTION__, temp_dword); 
+		writel(temp_dword, php_ctlr->creg + SERR_INTR_ENABLE);
 
-	intr_loc2 = readl(php_ctlr->creg + INTR_LOC);  
-	dbg("%s: intr_loc2 = %x\n",__FUNCTION__, intr_loc2); 
+		intr_loc2 = readl(php_ctlr->creg + INTR_LOC);  
+		dbg("%s: intr_loc2 = %x\n",__FUNCTION__, intr_loc2); 
+	}
 
 	if (intr_loc & 0x0001) {
 		/* 
@@ -1159,14 +1166,16 @@ static irqreturn_t shpc_isr(int IRQ, voi
 			dbg("%s: intr_loc2 = %x\n",__FUNCTION__, intr_loc2); 
 		}
 	}
-	/* Unmask Global Interrupt Mask */
-	temp_dword = readl(php_ctlr->creg + SERR_INTR_ENABLE);
-	dbg("%s: 2-Before unmasking global interrupt, temp_dword = %x\n",
-		__FUNCTION__, temp_dword); 
-	temp_dword &= 0xfffffffe;
-	dbg("%s: 2-After unmasking global interrupt, temp_dword = %x\n",
-		__FUNCTION__, temp_dword); 
-	writel(temp_dword, php_ctlr->creg + SERR_INTR_ENABLE);
+	if (!shpchp_poll_mode) {
+		/* Unmask Global Interrupt Mask */
+		temp_dword = readl(php_ctlr->creg + SERR_INTR_ENABLE);
+		dbg("%s: 2-Before unmasking global interrupt, temp_dword = %x\n",
+			__FUNCTION__, temp_dword); 
+		temp_dword &= 0xfffffffe;
+		dbg("%s: 2-After unmasking global interrupt, temp_dword = %x\n",
+			__FUNCTION__, temp_dword); 
+		writel(temp_dword, php_ctlr->creg + SERR_INTR_ENABLE);
+	}
 	
 	return IRQ_HANDLED;
 }
diff -purN linux-post-2.6.3-20040227/drivers/pci/pci.c linux-post-2.6.4rc1-20040228/drivers/pci/pci.c
--- linux-post-2.6.3-20040227/drivers/pci/pci.c	2004-02-10 18:01:13.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/pci.c	2004-02-20 20:00:29.000000000 +0000
@@ -535,11 +535,6 @@ int pci_request_regions(struct pci_dev *
 	return 0;
 
 err_out:
-	printk (KERN_WARNING "PCI: Unable to reserve %s region #%d:%lx@%lx for device %s\n",
-		pci_resource_flags(pdev, i) & IORESOURCE_IO ? "I/O" : "mem",
-		i + 1, /* PCI BAR # */
-		pci_resource_len(pdev, i), pci_resource_start(pdev, i),
-		pci_name(pdev));
 	while(--i >= 0)
 		pci_release_region(pdev, i);
 		
diff -purN linux-post-2.6.3-20040227/drivers/pci/probe.c linux-post-2.6.4rc1-20040228/drivers/pci/probe.c
--- linux-post-2.6.3-20040227/drivers/pci/probe.c	2004-02-19 03:42:58.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/probe.c	2004-02-18 22:41:09.000000000 +0000
@@ -366,6 +366,8 @@ int __devinit pci_scan_bridge(struct pci
 		child = pci_alloc_child_bus(bus, dev, busnr);
 		child->primary = buses & 0xFF;
 		child->subordinate = (buses >> 16) & 0xFF;
+		child->bridge_ctl = bctl;
+
 		cmax = pci_scan_child_bus(child);
 		if (cmax > max) max = cmax;
 	} else {
@@ -400,6 +402,8 @@ int __devinit pci_scan_bridge(struct pci
 		pci_write_config_dword(dev, PCI_PRIMARY_BUS, buses);
 
 		if (!is_cardbus) {
+			child->bridge_ctl = PCI_BRIDGE_CTL_NO_ISA;
+
 			/* Now we can scan all subordinate buses... */
 			max = pci_scan_child_bus(child);
 		} else {
diff -purN linux-post-2.6.3-20040227/drivers/pci/setup-bus.c linux-post-2.6.4rc1-20040228/drivers/pci/setup-bus.c
--- linux-post-2.6.3-20040227/drivers/pci/setup-bus.c	2003-10-21 14:43:30.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/setup-bus.c	2003-11-24 10:33:06.000000000 +0000
@@ -43,13 +43,15 @@
 #define CARDBUS_IO_SIZE		(4096)
 #define CARDBUS_MEM_SIZE	(32*1024*1024)
 
-static int __devinit
+static void __devinit
 pbus_assign_resources_sorted(struct pci_bus *bus)
 {
 	struct pci_dev *dev;
 	struct resource *res;
 	struct resource_list head, *list, *tmp;
-	int idx, found_vga = 0;
+	int idx;
+
+	bus->bridge_ctl &= ~PCI_BRIDGE_CTL_VGA;
 
 	head.next = NULL;
 	list_for_each_entry(dev, &bus->devices, bus_list) {
@@ -57,7 +59,7 @@ pbus_assign_resources_sorted(struct pci_
 
 		if (class == PCI_CLASS_DISPLAY_VGA
 				|| class == PCI_CLASS_NOT_DEFINED_VGA)
-			found_vga = 1;
+			bus->bridge_ctl |= PCI_BRIDGE_CTL_VGA;
 
 		pdev_sort_resources(dev, &head);
 	}
@@ -70,8 +72,6 @@ pbus_assign_resources_sorted(struct pci_
 		list = list->next;
 		kfree(tmp);
 	}
-
-	return found_vga;
 }
 
 static void __devinit
@@ -211,10 +211,7 @@ pci_setup_bridge(struct pci_bus *bus)
 	/* Clear out the upper 32 bits of PREF base. */
 	pci_write_config_dword(bridge, PCI_PREF_BASE_UPPER32, 0);
 
-	/* Check if we have VGA behind the bridge.
-	   Enable ISA in either case (FIXME!). */
-	l = (bus->resource[0]->flags & IORESOURCE_BUS_HAS_VGA) ? 0x0c : 0x04;
-	pci_write_config_word(bridge, PCI_BRIDGE_CONTROL, l);
+	pci_write_config_word(bridge, PCI_BRIDGE_CONTROL, bus->bridge_ctl);
 }
 
 /* Check whether the bridge supports optional I/O and
@@ -498,13 +495,14 @@ void __devinit
 pci_bus_assign_resources(struct pci_bus *bus)
 {
 	struct pci_bus *b;
-	int found_vga = pbus_assign_resources_sorted(bus);
 	struct pci_dev *dev;
 
-	if (found_vga) {
+	pbus_assign_resources_sorted(bus);
+
+	if (bus->bridge_ctl & PCI_BRIDGE_CTL_VGA) {
 		/* Propagate presence of the VGA to upstream bridges */
 		for (b = bus; b->parent; b = b->parent) {
-			b->resource[0]->flags |= IORESOURCE_BUS_HAS_VGA;
+			b->bridge_ctl |= PCI_BRIDGE_CTL_VGA;
 		}
 	}
 	list_for_each_entry(dev, &bus->devices, bus_list) {
diff -purN linux-post-2.6.3-20040227/drivers/pci/setup-res.c linux-post-2.6.4rc1-20040228/drivers/pci/setup-res.c
--- linux-post-2.6.3-20040227/drivers/pci/setup-res.c	2003-12-30 08:44:36.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/pci/setup-res.c	2004-02-20 19:58:19.000000000 +0000
@@ -143,8 +143,9 @@ int pci_assign_resource(struct pci_dev *
 	}
 
 	if (ret) {
-		printk(KERN_ERR "PCI: Failed to allocate resource %d(%lx-%lx) for %s\n",
-		       resno, res->start, res->end, pci_name(dev));
+		printk(KERN_ERR "PCI: Failed to allocate %s resource #%d:%lx@%lx for %s\n",
+		       res->flags & IORESOURCE_IO ? "I/O" : "mem",
+		       resno, size, res->start, pci_name(dev));
 	} else if (resno < PCI_BRIDGE_RESOURCES) {
 		pci_update_resource(dev, res, resno);
 	}
diff -purN linux-post-2.6.3-20040227/drivers/usb/host/ohci-sa1111.c linux-post-2.6.4rc1-20040228/drivers/usb/host/ohci-sa1111.c
--- linux-post-2.6.3-20040227/drivers/usb/host/ohci-sa1111.c	2004-02-11 11:42:39.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/usb/host/ohci-sa1111.c	2004-02-27 21:50:27.000000000 +0000
@@ -105,7 +105,7 @@ static void dump_hci_status(struct usb_h
 }
 #endif
 
-static void usb_hcd_sa1111_hcim_irq (int irq, void *__hcd, struct pt_regs * r)
+static irqreturn_t usb_hcd_sa1111_hcim_irq (int irq, void *__hcd, struct pt_regs * r)
 {
 	struct usb_hcd *hcd = __hcd;
 //	unsigned long status = sa1111_readl(hcd->regs + SA1111_USB_STATUS);
@@ -120,7 +120,7 @@ static void usb_hcd_sa1111_hcim_irq (int
 	}
 #endif
 
-	usb_hcd_irq(irq, hcd, r);
+	return usb_hcd_irq(irq, hcd, r);
 }
 
 /*-------------------------------------------------------------------------*/
diff -purN linux-post-2.6.3-20040227/drivers/video/aty/radeon_base.c linux-post-2.6.4rc1-20040228/drivers/video/aty/radeon_base.c
--- linux-post-2.6.3-20040227/drivers/video/aty/radeon_base.c	2004-02-17 10:37:53.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/drivers/video/aty/radeon_base.c	2004-02-27 22:45:14.000000000 +0000
@@ -222,16 +222,7 @@ static reg_val common_regs[] = {
 	{ I2C_CNTL_1, 0 },
 	{ GEN_INT_CNTL, 0 },
 	{ CAP0_TRIG_CNTL, 0 },
-};
-
-static reg_val common_regs_m6[] = {
-	{ OVR_CLR,      0 },
-	{ OVR_WID_LEFT_RIGHT,   0 },
-	{ OVR_WID_TOP_BOTTOM,   0 },
-	{ OV0_SCALE_CNTL,   0 },
-	{ SUBPIC_CNTL,      0 },
-	{ GEN_INT_CNTL,     0 },
-	{ CAP0_TRIG_CNTL,   0 } 
+	{ CAP1_TRIG_CNTL, 0 },
 };
 
 /*
@@ -1230,7 +1221,7 @@ static void radeon_write_mode (struct ra
 
 	radeon_screen_blank(rinfo, VESA_POWERDOWN);
 
-	for (i=0; i<9; i++)
+	for (i=0; i<10; i++)
 		OUTREG(common_regs[i].reg, common_regs[i].val);
 
 	/* Apply surface registers */
diff -purN linux-post-2.6.3-20040227/fs/locks.c linux-post-2.6.4rc1-20040228/fs/locks.c
--- linux-post-2.6.3-20040227/fs/locks.c	2004-01-19 06:22:24.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/fs/locks.c	2004-02-28 00:44:02.000000000 +0000
@@ -1699,6 +1699,8 @@ void locks_remove_posix(struct file *fil
 	unlock_kernel();
 }
 
+EXPORT_SYMBOL(locks_remove_posix);
+
 /*
  * This function is called on the last close of an open file.
  */
diff -purN linux-post-2.6.3-20040227/fs/readdir.c linux-post-2.6.4rc1-20040228/fs/readdir.c
--- linux-post-2.6.3-20040227/fs/readdir.c	2004-02-04 05:29:14.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/fs/readdir.c	2004-02-27 18:28:52.000000000 +0000
@@ -139,7 +139,7 @@ static int filldir(void * __buf, const c
 {
 	struct linux_dirent __user * dirent;
 	struct getdents_callback * buf = (struct getdents_callback *) __buf;
-	int reclen = ROUND_UP(NAME_OFFSET(dirent) + namlen + 1);
+	int reclen = ROUND_UP(NAME_OFFSET(dirent) + namlen + 2);
 
 	buf->error = -EINVAL;	/* only used if we fail.. */
 	if (reclen > buf->count)
@@ -158,6 +158,8 @@ static int filldir(void * __buf, const c
 		goto efault;
 	if (__put_user(0, dirent->d_name + namlen))
 		goto efault;
+	if (__put_user(d_type, (char *) dirent + reclen - 1))
+		goto efault;
 	buf->previous = dirent;
 	dirent = (void *)dirent + reclen;
 	buf->current_dir = dirent;
diff -purN linux-post-2.6.3-20040227/include/asm-arm/atomic.h linux-post-2.6.4rc1-20040228/include/asm-arm/atomic.h
--- linux-post-2.6.3-20040227/include/asm-arm/atomic.h	2003-09-03 17:17:57.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/atomic.h	2004-02-26 14:22:25.000000000 +0000
@@ -1,35 +1,141 @@
 /*
  *  linux/include/asm-arm/atomic.h
  *
- *  Copyright (c) 1996 Russell King.
+ *  Copyright (C) 1996 Russell King.
+ *  Copyright (C) 2002 Deep Blue Solutions Ltd.
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
  * published by the Free Software Foundation.
- *
- *  Changelog:
- *   27-06-1996	RMK	Created
- *   13-04-1997	RMK	Made functions atomic!
- *   07-12-1997	RMK	Upgraded for v2.1.
- *   26-08-1998	PJB	Added #ifdef __KERNEL__
  */
 #ifndef __ASM_ARM_ATOMIC_H
 #define __ASM_ARM_ATOMIC_H
 
 #include <linux/config.h>
 
-#ifdef CONFIG_SMP
-#error SMP not supported
-#endif
-
 typedef struct { volatile int counter; } atomic_t;
 
 #define ATOMIC_INIT(i)	{ (i) }
 
 #ifdef __KERNEL__
-#include <asm/system.h>
 
 #define atomic_read(v)	((v)->counter)
+
+#if __LINUX_ARM_ARCH__ >= 6
+
+/*
+ * ARMv6 UP and SMP safe atomic ops.  We use load exclusive and
+ * store exclusive to ensure that these are atomic.  We may loop
+ * to ensure that the update happens.  Writing to 'v->counter'
+ * without using the following operations WILL break the atomic
+ * nature of these ops.
+ */
+static inline void atomic_set(atomic_t *v, int i)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__("@ atomic_set\n"
+"1:	ldrex	%0, [%1]\n"
+"	strex	%0, %2, [%1]\n"
+"	teq	%0, #0\n"
+"	bne	1b"
+	: "=&r" (tmp)
+	: "r" (&v->counter), "r" (i)
+	: "cc");
+}
+
+static inline void atomic_add(int i, volatile atomic_t *v)
+{
+	unsigned long tmp, tmp2;
+
+	__asm__ __volatile__("@ atomic_add\n"
+"1:	ldrex	%0, [%2]\n"
+"	add	%0, %0, %3\n"
+"	strex	%1, %0, [%2]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&v->counter), "Ir" (i)
+	: "cc");
+}
+
+static inline void atomic_sub(int i, volatile atomic_t *v)
+{
+	unsigned long tmp, tmp2;
+
+	__asm__ __volatile__("@ atomic_sub\n"
+"1:	ldrex	%0, [%2]\n"
+"	sub	%0, %0, %3\n"
+"	strex	%1, %0, [%2]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&v->counter), "Ir" (i)
+	: "cc");
+}
+
+#define atomic_inc(v)	atomic_add(1, v)
+#define atomic_dec(v)	atomic_sub(1, v)
+
+static inline int atomic_dec_and_test(volatile atomic_t *v)
+{
+	unsigned long tmp;
+	int result;
+
+	__asm__ __volatile__("@ atomic_dec_and_test\n"
+"1:	ldrex	%0, [%2]\n"
+"	sub	%0, %0, #1\n"
+"	strex	%1, %0, [%2]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+	: "=&r" (result), "=r" (tmp)
+	: "r" (&v->counter)
+	: "cc");
+
+	return result == 0;
+}
+
+static inline int atomic_add_negative(int i, volatile atomic_t *v)
+{
+	unsigned long tmp;
+	int result;
+
+	__asm__ __volatile__("@ atomic_add_negative\n"
+"1:	ldrex	%0, [%2]\n"
+"	add	%0, %0, %3\n"
+"	strex	%1, %0, [%2]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+	: "=&r" (result), "=r" (tmp)
+	: "r" (&v->counter), "Ir" (i)
+	: "cc");
+
+	return result < 0;
+}
+
+static inline void atomic_clear_mask(unsigned long mask, unsigned long *addr)
+{
+	unsigned long tmp, tmp2;
+
+	__asm__ __volatile__("@ atomic_clear_mask\n"
+"1:	ldrex	%0, %2\n"
+"	bic	%0, %0, %3\n"
+"	strex	%1, %0, %2\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (addr), "Ir" (mask)
+	: "cc");
+}
+
+#else /* ARM_ARCH_6 */
+
+#include <asm/system.h>
+
+#ifdef CONFIG_SMP
+#error SMP not supported on pre-ARMv6 CPUs
+#endif
+
 #define atomic_set(v,i)	(((v)->counter) = (i))
 
 static inline void atomic_add(int i, volatile atomic_t *v)
@@ -103,6 +209,8 @@ static inline void atomic_clear_mask(uns
 	local_irq_restore(flags);
 }
 
+#endif /* __LINUX_ARM_ARCH__ */
+
 /* Atomic operations are already serializing on ARM */
 #define smp_mb__before_atomic_dec()	barrier()
 #define smp_mb__after_atomic_dec()	barrier()
diff -purN linux-post-2.6.3-20040227/include/asm-arm/cacheflush.h linux-post-2.6.4rc1-20040228/include/asm-arm/cacheflush.h
--- linux-post-2.6.3-20040227/include/asm-arm/cacheflush.h	2004-01-30 15:49:06.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/cacheflush.h	2004-02-26 14:22:25.000000000 +0000
@@ -69,6 +69,14 @@
 # endif
 #endif
 
+#if defined(CONFIG_CPU_V6)
+//# ifdef _CACHE
+#  define MULTI_CACHE 1
+//# else
+//#  define _CACHE v6
+//# endif
+#endif
+
 #if !defined(_CACHE) && !defined(MULTI_CACHE)
 #error Unknown cache maintainence model
 #endif
diff -purN linux-post-2.6.3-20040227/include/asm-arm/dma-mapping.h linux-post-2.6.4rc1-20040228/include/asm-arm/dma-mapping.h
--- linux-post-2.6.3-20040227/include/asm-arm/dma-mapping.h	2003-08-13 23:46:20.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/dma-mapping.h	2004-02-27 14:00:38.000000000 +0000
@@ -22,12 +22,12 @@ extern void consistent_sync(void *kaddr,
  * For SA-1111 these functions are "magic" and utilize bounce
  * bufferes as needed to work around SA-1111 DMA bugs.
  */
-dma_addr_t sa1111_map_single(void *, size_t, int);
-void sa1111_unmap_single(dma_addr_t, size_t, int);
-int sa1111_map_sg(struct scatterlist *, int, int);
-void sa1111_unmap_sg(struct scatterlist *, int, int);
-void sa1111_dma_sync_single(dma_addr_t, size_t, int);
-void sa1111_dma_sync_sg(struct scatterlist *, int, int);
+dma_addr_t sa1111_map_single(struct device *dev, void *, size_t, enum dma_data_direction);
+void sa1111_unmap_single(struct device *dev, dma_addr_t, size_t, enum dma_data_direction);
+int sa1111_map_sg(struct device *dev, struct scatterlist *, int, enum dma_data_direction);
+void sa1111_unmap_sg(struct device *dev, struct scatterlist *, int, enum dma_data_direction);
+void sa1111_dma_sync_single(struct device *dev, dma_addr_t, size_t, enum dma_data_direction);
+void sa1111_dma_sync_sg(struct device *dev, struct scatterlist *, int, enum dma_data_direction);
 
 #ifdef CONFIG_SA1111
 
@@ -122,7 +122,7 @@ dma_map_single(struct device *dev, void 
 	       enum dma_data_direction dir)
 {
 	if (dmadev_is_sa1111(dev))
-		return sa1111_map_single(cpu_addr, size, dir);
+		return sa1111_map_single(dev, cpu_addr, size, dir);
 
 	consistent_sync(cpu_addr, size, dir);
 	return __virt_to_bus((unsigned long)cpu_addr);
@@ -169,7 +169,7 @@ dma_unmap_single(struct device *dev, dma
 		 enum dma_data_direction dir)
 {
 	if (dmadev_is_sa1111(dev))
-		sa1111_unmap_single(handle, size, dir);
+		sa1111_unmap_single(dev, handle, size, dir);
 
 	/* nothing to do */
 }
@@ -224,7 +224,7 @@ dma_map_sg(struct device *dev, struct sc
 	int i;
 
 	if (dmadev_is_sa1111(dev))
-		return sa1111_map_sg(sg, nents, dir);
+		return sa1111_map_sg(dev, sg, nents, dir);
 
 	for (i = 0; i < nents; i++, sg++) {
 		char *virt;
@@ -253,7 +253,7 @@ dma_unmap_sg(struct device *dev, struct 
 	     enum dma_data_direction dir)
 {
 	if (dmadev_is_sa1111(dev)) {
-		sa1111_unmap_sg(sg, nents, dir);
+		sa1111_unmap_sg(dev, sg, nents, dir);
 		return;
 	}
 
@@ -281,7 +281,7 @@ dma_sync_single(struct device *dev, dma_
 		enum dma_data_direction dir)
 {
 	if (dmadev_is_sa1111(dev)) {
-		sa1111_dma_sync_single(handle, size, dir);
+		sa1111_dma_sync_single(dev, handle, size, dir);
 		return;
 	}
 
@@ -308,7 +308,7 @@ dma_sync_sg(struct device *dev, struct s
 	int i;
 
 	if (dmadev_is_sa1111(dev)) {
-		sa1111_dma_sync_sg(sg, nents, dir);
+		sa1111_dma_sync_sg(dev, sg, nents, dir);
 		return;
 	}
 
diff -purN linux-post-2.6.3-20040227/include/asm-arm/glue.h linux-post-2.6.4rc1-20040228/include/asm-arm/glue.h
--- linux-post-2.6.3-20040227/include/asm-arm/glue.h	2003-09-19 13:02:35.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/glue.h	2004-02-26 14:22:26.000000000 +0000
@@ -38,6 +38,7 @@
  *	  v4t_early	- ARMv4 with Thumb early abort handler
  *	  v5tej_early	- ARMv5 with Thumb and Java early abort handler
  *	  xscale	- ARMv5 with Thumb with Xscale extensions
+ *	  v6_early	- ARMv6 generic early abort handler
  */
 #undef CPU_ABORT_HANDLER
 #undef MULTI_ABORT
@@ -98,6 +99,14 @@
 # endif
 #endif
 
+#ifdef CONFIG_CPU_ABRT_EV6
+# ifdef CPU_ABORT_HANDLER
+#  define MULTI_ABORT 1
+# else
+#  define CPU_ABORT_HANDLER v6_early_abort
+# endif
+#endif
+
 #ifndef CPU_ABORT_HANDLER
 #error Unknown data abort handler type
 #endif
diff -purN linux-post-2.6.3-20040227/include/asm-arm/locks.h linux-post-2.6.4rc1-20040228/include/asm-arm/locks.h
--- linux-post-2.6.3-20040227/include/asm-arm/locks.h	2003-09-03 17:17:59.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/locks.h	2004-02-26 14:22:26.000000000 +0000
@@ -12,6 +12,127 @@
 #ifndef __ASM_PROC_LOCKS_H
 #define __ASM_PROC_LOCKS_H
 
+#if __LINUX_ARM_ARCH__ >= 6
+
+#define __down_op(ptr,fail)			\
+	({					\
+	__asm__ __volatile__(			\
+	"@ down_op\n"				\
+"1:	ldrex	lr, [%0]\n"			\
+"	sub	lr, lr, %1\n"			\
+"	strex	ip, lr, [%0]\n"			\
+"	teq	ip, #0\n"			\
+"	bne	1b\n"				\
+"	teq	lr, #0\n"			\
+"	movmi	ip, %0\n"			\
+"	blmi	" #fail				\
+	:					\
+	: "r" (ptr), "I" (1)			\
+	: "ip", "lr", "cc", "memory");		\
+	})
+
+#define __down_op_ret(ptr,fail)			\
+	({					\
+		unsigned int ret;		\
+	__asm__ __volatile__(			\
+	"@ down_op_ret\n"			\
+"1:	ldrex	lr, [%1]\n"			\
+"	sub	lr, lr, %2\n"			\
+"	strex	ip, lr, [%1]\n"			\
+"	teq	ip, #0\n"			\
+"	bne	1b\n"				\
+"	teq	lr, #0\n"			\
+"	movmi	ip, %1\n"			\
+"	movpl	ip, #0\n"			\
+"	blmi	" #fail "\n"			\
+"	mov	%0, ip"				\
+	: "=&r" (ret)				\
+	: "r" (ptr), "I" (1)			\
+	: "ip", "lr", "cc", "memory");		\
+	ret;					\
+	})
+
+#define __up_op(ptr,wake)			\
+	({					\
+	__asm__ __volatile__(			\
+	"@ up_op\n"				\
+"1:	ldrex	lr, [%0]\n"			\
+"	add	lr, lr, %1\n"			\
+"	strex	ip, lr, [%0]\n"			\
+"	teq	ip, #0\n"			\
+"	bne	1b\n"				\
+"	teq	lr, #0\n"			\
+"	movle	ip, %0\n"			\
+"	blle	" #wake				\
+	:					\
+	: "r" (ptr), "I" (1)			\
+	: "ip", "lr", "cc", "memory");		\
+	})
+
+/*
+ * The value 0x01000000 supports up to 128 processors and
+ * lots of processes.  BIAS must be chosen such that sub'ing
+ * BIAS once per CPU will result in the long remaining
+ * negative.
+ */
+#define RW_LOCK_BIAS      0x01000000
+#define RW_LOCK_BIAS_STR "0x01000000"
+
+#define __down_op_write(ptr,fail)		\
+	({					\
+	__asm__ __volatile__(			\
+	"@ down_op_write\n"			\
+"1:	ldrex	lr, [%0]\n"			\
+"	sub	lr, lr, %1\n"			\
+"	strex	ip, lr, [%0]\n"			\
+"	teq	ip, #0\n"			\
+"	bne	1b\n"				\
+"	teq	lr, #0\n"			\
+"	movne	ip, %0\n"			\
+"	blne	" #fail				\
+	:					\
+	: "r" (ptr), "I" (RW_LOCK_BIAS)		\
+	: "ip", "lr", "cc", "memory");		\
+	})
+
+#define __up_op_write(ptr,wake)			\
+	({					\
+	__asm__ __volatile__(			\
+	"@ up_op_read\n"			\
+"1:	ldrex	lr, [%0]\n"			\
+"	add	lr, lr, %1\n"			\
+"	strex	ip, lr, [%0]\n"			\
+"	teq	ip, #0\n"			\
+"	bne	1b\n"				\
+"	movcs	ip, %0\n"			\
+"	blcs	" #wake				\
+	:					\
+	: "r" (ptr), "I" (RW_LOCK_BIAS)		\
+	: "ip", "lr", "cc", "memory");		\
+	})
+
+#define __down_op_read(ptr,fail)		\
+	__down_op(ptr, fail)
+
+#define __up_op_read(ptr,wake)			\
+	({					\
+	__asm__ __volatile__(			\
+	"@ up_op_read\n"			\
+"1:	ldrex	lr, [%0]\n"			\
+"	add	lr, lr, %1\n"			\
+"	strex	ip, lr, [%0]\n"			\
+"	teq	ip, #0\n"			\
+"	bne	1b\n"				\
+"	teq	lr, #0\n"			\
+"	moveq	ip, %0\n"			\
+"	bleq	" #wake				\
+	:					\
+	: "r" (ptr), "I" (1)			\
+	: "ip", "lr", "cc", "memory");		\
+	})
+
+#else
+
 #define __down_op(ptr,fail)			\
 	({					\
 	__asm__ __volatile__(			\
@@ -137,3 +258,5 @@
 	})
 
 #endif
+
+#endif
diff -purN linux-post-2.6.3-20040227/include/asm-arm/page.h linux-post-2.6.4rc1-20040228/include/asm-arm/page.h
--- linux-post-2.6.3-20040227/include/asm-arm/page.h	2003-09-16 18:43:51.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/page.h	2004-02-26 14:22:26.000000000 +0000
@@ -84,6 +84,14 @@
 # endif
 #endif
 
+#ifdef CONFIG_CPU_COPY_V6
+# ifdef _USER
+#  define MULTI_USER 1
+# else
+#  define _USER v6
+# endif
+#endif
+
 #ifndef _USER
 #error Unknown user operations model
 #endif
diff -purN linux-post-2.6.3-20040227/include/asm-arm/proc-fns.h linux-post-2.6.4rc1-20040228/include/asm-arm/proc-fns.h
--- linux-post-2.6.3-20040227/include/asm-arm/proc-fns.h	2003-09-16 18:43:51.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/proc-fns.h	2004-02-26 14:22:26.000000000 +0000
@@ -130,6 +130,14 @@
 #   define CPU_NAME cpu_xscale
 #  endif
 # endif
+# ifdef CONFIG_CPU_V6
+#  ifdef CPU_NAME
+#   undef  MULTI_CPU
+#   define MULTI_CPU
+#  else
+#   define CPU_NAME cpu_v6
+#  endif
+# endif
 #endif
 
 #ifndef MULTI_CPU
diff -purN linux-post-2.6.3-20040227/include/asm-arm/shmparam.h linux-post-2.6.4rc1-20040228/include/asm-arm/shmparam.h
--- linux-post-2.6.3-20040227/include/asm-arm/shmparam.h	2003-09-03 17:17:58.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/shmparam.h	2004-02-26 14:22:26.000000000 +0000
@@ -6,6 +6,10 @@
  * or page size, whichever is greater since the cache aliases
  * every size/ways bytes.
  */
+#if __LINUX_ARM_ARCH__ > 5
+#define	SHMLBA	(4 * PAGE_SIZE)
+#else
 #define	SHMLBA PAGE_SIZE		 /* attach addr a multiple of this */
+#endif
 
 #endif /* _ASMARM_SHMPARAM_H */
diff -purN linux-post-2.6.3-20040227/include/asm-arm/spinlock.h linux-post-2.6.4rc1-20040228/include/asm-arm/spinlock.h
--- linux-post-2.6.3-20040227/include/asm-arm/spinlock.h	2002-02-05 17:39:52.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/spinlock.h	2004-02-26 14:22:26.000000000 +0000
@@ -1,6 +1,160 @@
 #ifndef __ASM_SPINLOCK_H
 #define __ASM_SPINLOCK_H
 
-#error ARM architecture does not support SMP spin locks
+#if __LINUX_ARM_ARCH__ < 6
+#error SMP not supported on pre-ARMv6 CPUs
+#endif
+
+/*
+ * ARMv6 Spin-locking.
+ *
+ * We (exclusively) read the old value, and decrement it.  If it
+ * hits zero, we may have won the lock, so we try (exclusively)
+ * storing it.
+ *
+ * Unlocked value: 0
+ * Locked value: 1
+ */
+typedef struct {
+	volatile unsigned int lock;
+} spinlock_t;
+
+#define SPIN_LOCK_UNLOCKED	(spinlock_t) { 0 }
+
+#define spin_lock_init(x)	do { *(x) = SPIN_LOCK_UNLOCKED; } while (0)
+#define spin_is_locked(x)	((x)->lock != 0)
+#define spin_unlock_wait(x)	do { barrier(); } while (spin_is_locked(x))
+
+static inline void _raw_spin_lock(spinlock_t *lock)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%1]\n"
+"	teq	%0, #0\n"
+"	strexeq	%0, %2, [%1]\n"
+"	teqeq	%0, #0\n"
+"	bne	1b"
+	: "=&r" (tmp)
+	: "r" (&lock->lock), "r" (1)
+	: "cc", "memory");
+}
+
+static inline int _raw_spin_trylock(spinlock_t *lock)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+"	ldrex	%0, [%1]\n"
+"	teq	%0, #0\n"
+"	strexeq	%0, %2, [%1]"
+	: "=&r" (tmp)
+	: "r" (&lock->lock), "r" (1)
+	: "cc", "memory");
+
+	return tmp == 0;
+}
+
+static inline void _raw_spin_unlock(spinlock_t *lock)
+{
+	__asm__ __volatile__(
+"	str	%1, [%0]"
+	:
+	: "r" (&lock->lock), "r" (0)
+	: "cc", "memory");
+}
+
+/*
+ * RWLOCKS
+ */
+typedef struct {
+	volatile unsigned int lock;
+} rwlock_t;
+
+#define RW_LOCK_UNLOCKED	(rwlock_t) { 0 }
+#define rwlock_init(x)		do { *(x) + RW_LOCK_UNLOCKED; } while (0)
+
+/*
+ * Write locks are easy - we just set bit 31.  When unlocking, we can
+ * just write zero since the lock is exclusively held.
+ */
+static inline void _raw_write_lock(rwlock_t *rw)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%1]\n"
+"	teq	%0, #0\n"
+"	strexeq	%0, %2, [%1]\n"
+"	teq	%0, #0\n"
+"	bne	1b"
+	: "=r" (tmp)
+	: "r" (&rw->lock), "r" (0x80000000)
+	: "cc", "memory");
+}
+
+static inline void _raw_write_unlock(rwlock_t *rw)
+{
+	__asm__ __volatile__(
+	"str	%1, [%0]"
+	:
+	: "r" (&rw->lock), "r" (0)
+	: "cc", "memory");
+}
+
+/*
+ * Read locks are a bit more hairy:
+ *  - Exclusively load the lock value.
+ *  - Increment it.
+ *  - Store new lock value if positive, and we still own this location.
+ *    If the value is negative, we've already failed.
+ *  - If we failed to store the value, we want a negative result.
+ *  - If we failed, try again.
+ * Unlocking is similarly hairy.  We may have multiple read locks
+ * currently active.  However, we know we won't have any write
+ * locks.
+ */
+static inline void _raw_read_lock(rwlock_t *rw)
+{
+	unsigned long tmp, tmp2;
+
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%2]\n"
+"	adds	%0, %0, #1\n"
+"	strexpl	%1, %0, [%2]\n"
+"	rsbpls	%0, %1, #0\n"
+"	bmi	1b"
+	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&rw->lock)
+	: "cc", "memory");
+}
+
+static inline void _raw_read_unlock(rwlock_t *rw)
+{
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%2]\n"
+"	sub	%0, %0, #1\n"
+"	strex	%1, %0, [%2]\n"
+"	teq	%1, #0\n"
+"	bne	1b"
+	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&rw->lock)
+	: "cc", "memory");
+}
+
+static inline int _raw_write_trylock(rwlock_t *rw)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+"1:	ldrex	%0, [%1]\n"
+"	teq	%0, #0\n"
+"	strexeq	%0, %2, [%1]"
+	: "=r" (tmp)
+	: "r" (&rw->lock), "r" (0x80000000)
+	: "cc", "memory");
+
+	return tmp == 0;
+}
 
 #endif /* __ASM_SPINLOCK_H */
diff -purN linux-post-2.6.3-20040227/include/asm-arm/system.h linux-post-2.6.4rc1-20040228/include/asm-arm/system.h
--- linux-post-2.6.3-20040227/include/asm-arm/system.h	2003-09-16 21:43:19.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-arm/system.h	2004-02-26 14:22:27.000000000 +0000
@@ -12,7 +12,8 @@
 #define CPU_ARCH_ARMv5		4
 #define CPU_ARCH_ARMv5T		5
 #define CPU_ARCH_ARMv5TE	6
-#define CPU_ARCH_ARMv6		7
+#define CPU_ARCH_ARMv5TEJ	7
+#define CPU_ARCH_ARMv6		8
 
 /*
  * CR1 bits (CP#15 CR1)
@@ -124,6 +125,26 @@ extern struct task_struct *__switch_to(s
 	} while (0)
 
 /*
+ * CPU interrupt mask handling.
+ */
+#if __LINUX_ARM_ARCH__ >= 6
+
+#define local_irq_save(x)					\
+	({							\
+	__asm__ __volatile__(					\
+	"mrs	%0, cpsr		@ local_irq_save\n"	\
+	"cpsid	i"						\
+	: "=r" (x) : : "memory", "cc");				\
+	})
+
+#define local_irq_enable()  __asm__("cpsie i	@ __sti" : : : "memory", "cc")
+#define local_irq_disable() __asm__("cpsid i	@ __cli" : : : "memory", "cc")
+#define local_fiq_enable()  __asm__("cpsie f	@ __stf" : : : "memory", "cc")
+#define local_fiq_disable() __asm__("cpsid f	@ __clf" : : : "memory", "cc")
+
+#else
+
+/*
  * Save the current interrupt enable state & disable IRQs
  */
 #define local_irq_save(x)					\
@@ -199,6 +220,8 @@ extern struct task_struct *__switch_to(s
 	: "memory", "cc");					\
 	})
 
+#endif
+
 /*
  * Save the current interrupt enable state.
  */
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/cacheflush.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/cacheflush.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/cacheflush.h	2003-10-02 07:11:59.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/cacheflush.h	2004-02-27 22:44:57.000000000 +0000
@@ -23,6 +23,9 @@ extern void flush_icache_user_range(stru
 				    struct page *page, unsigned long addr,
 				    int len);
 
+extern void flush_dcache_range(unsigned long start, unsigned long stop);
+extern void flush_dcache_phys_range(unsigned long start, unsigned long stop);
+
 #define copy_to_user_page(vma, page, vaddr, dst, src, len) \
 do { memcpy(dst, src, len); \
      flush_icache_user_range(vma, page, vaddr, len); \
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/iSeries/iSeries_dma.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/iSeries/iSeries_dma.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/iSeries/iSeries_dma.h	2004-01-19 06:28:21.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/iSeries/iSeries_dma.h	1970-01-01 00:00:00.000000000 +0000
@@ -1,95 +0,0 @@
-/*
- * iSeries_dma.h
- * Copyright (C) 2001  Mike Corrigan IBM Corporation
- * 
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- * 
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- * 
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
- */
-
-#ifndef _ISERIES_DMA_H
-#define _ISERIES_DMA_H
-
-#include <asm/types.h>
-#include <linux/spinlock.h>
-
-// NUM_TCE_LEVELS defines the largest contiguous block
-// of dma (tce) space we can get.  NUM_TCE_LEVELS = 10 
-// allows up to 2**9 pages (512 * 4096) = 2 MB
-#define NUM_TCE_LEVELS 10
-
-#define NO_TCE ((dma_addr_t)-1)
-
-// Tces come in two formats, one for the virtual bus and a different
-// format for PCI
-#define TCE_VB  0
-#define TCE_PCI 1
-
-
-union Tce {
-   	u64	wholeTce;
-	struct {
-		u64	cacheBits	:6;	/* Cache hash bits - not used */
-		u64	rsvd		:6;	
-		u64	rpn		:40;	/* Absolute page number */
-		u64	valid		:1;	/* Tce is valid (vb only) */
-		u64	allIo		:1;	/* Tce is valid for all lps (vb only) */
-		u64	lpIndex		:8;	/* LpIndex for user of TCE (vb only) */
-		u64	pciWrite	:1;	/* Write allowed (pci only) */
-		u64	readWrite	:1;	/* Read allowed (pci), Write allowed
-						   (vb) */
-	} tceBits;
-};
-
-struct Bitmap {
-	unsigned long	numBits;
-	unsigned long	numBytes;
-	unsigned char * map;
-};
-
-struct MultiLevelBitmap {
-	unsigned long 	maxLevel;
-	struct Bitmap 	level[NUM_TCE_LEVELS];
-};
-
-struct TceTable {
-	u64	busNumber;
-	u64	size;
-	u64	startOffset;
-	u64	index;
-	spinlock_t	lock;
-	struct MultiLevelBitmap mlbm;
-};
-
-struct HvTceTableManagerCB {
-	u64	busNumber;		/* Bus number for this tce table */
-	u64	start;			/* Will be NULL for secondary */
-	u64	totalSize;		/* Size (in pages) of whole table */
-	u64	startOffset;		/* Index into real tce table of the
-					   start of our section */
-	u64	size;			/* Size (in pages) of our section */
-	u64	index;			/* Index of this tce table (token?) */
-	u16	maxTceTableIndex;	/* Max number of tables for partition */
-	u8	virtualBusFlag;		/* Flag to indicate virtual bus */
-	u8	rsvd[5];
-};
-
-extern struct TceTable virtBusTceTable;	/* Tce table for virtual bus */
-
-extern struct TceTable * build_tce_table( struct HvTceTableManagerCB *,
-					  struct TceTable *);
-extern void              create_virtual_bus_tce_table( void );
-
-extern void		 create_pci_bus_tce_table( unsigned busNumber );
-
-#endif /* _ISERIES_DMA_H */
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/iSeries/iSeries_pci.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/iSeries/iSeries_pci.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/iSeries/iSeries_pci.h	2004-01-19 06:28:24.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/iSeries/iSeries_pci.h	2004-02-27 23:02:35.000000000 +0000
@@ -92,7 +92,7 @@ struct iSeries_Device_Node {
 	int             Flags;          /* Possible flags(disable/bist)*/
 	u16             Vendor;         /* Vendor ID                   */
 	u8              LogicalSlot;    /* Hv Slot Index for Tces      */
-	struct TceTable* DevTceTable;   /* Device TCE Table            */ 
+	struct iommu_table* iommu_table;/* Device TCE Table            */ 
 	u8              PhbId;          /* Phb Card is on.             */
 	u16             Board;          /* Board Number                */
 	u8              FrameId;	/* iSeries spcn Frame Id       */
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/io.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/io.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/io.h	2004-02-06 08:24:50.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/io.h	2004-02-27 23:02:35.000000000 +0000
@@ -181,9 +181,12 @@ static inline void * phys_to_virt(unsign
  */
 #define page_to_phys(page)	(page_to_pfn(page) << PAGE_SHIFT)
 
-#if 0
-#define BIO_VMERGE_BOUNDARY	4096
-#endif
+/* We do NOT want virtual merging, it would put too much pressure on
+ * our iommu allocator. Instead, we want drivers to be smart enough
+ * to coalesce sglists that happen to have been mapped in a contiguous
+ * way by the iommu
+ */
+#define BIO_VMERGE_BOUNDARY	0
 
 #endif /* __KERNEL__ */
 
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/iommu.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/iommu.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/iommu.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/iommu.h	2004-02-27 17:16:29.000000000 +0000
@@ -0,0 +1,153 @@
+/*
+ * iommu.h
+ * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
+ * Rewrite, cleanup:
+ * Copyright (C) 2004 Olof Johansson <olof@austin.ibm.com>, IBM Corporation
+ * 
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
+ */
+
+#ifndef _PCI_DMA_H
+#define _PCI_DMA_H
+
+#include <asm/types.h>
+#include <linux/spinlock.h>
+
+/*
+ * IOMAP_MAX_ORDER defines the largest contiguous block
+ * of dma (tce) space we can get.  IOMAP_MAX_ORDER = 10 
+ * allows up to 2**9 pages (512 * 4096) = 2 MB
+ */
+#define IOMAP_MAX_ORDER 10
+
+#define NO_TCE ((dma_addr_t)-1)
+
+/*
+ * Tces come in two formats, one for the virtual bus and a different
+ * format for PCI
+ */
+#define TCE_VB  0
+#define TCE_PCI 1
+
+/* tce_entry
+ * Used by pSeries (SMP) and iSeries/pSeries LPAR, but there it's
+ * abstracted so layout is irrelevant.
+ */
+union tce_entry {
+   	unsigned long te_word;
+	struct {
+		unsigned int  tb_cacheBits :6;	/* Cache hash bits - not used */
+		unsigned int  tb_rsvd      :6;
+		unsigned long tb_rpn       :40;	/* Real page number */
+		unsigned int  tb_valid     :1;	/* Tce is valid (vb only) */
+		unsigned int  tb_allio     :1;	/* Tce is valid for all lps (vb only) */
+		unsigned int  tb_lpindex   :8;	/* LpIndex for user of TCE (vb only) */
+		unsigned int  tb_pciwr     :1;	/* Write allowed (pci only) */
+		unsigned int  tb_rdwr      :1;	/* Read allowed  (pci), Write allowed (vb) */
+	} te_bits;
+#define te_cacheBits te_bits.tb_cacheBits
+#define te_rpn       te_bits.tb_rpn
+#define te_valid     te_bits.tb_valid
+#define te_allio     te_bits.tb_allio
+#define te_lpindex   te_bits.tb_lpindex
+#define te_pciwr     te_bits.tb_pciwr
+#define te_rdwr      te_bits.tb_rdwr
+};
+
+
+struct iommu_table {
+	unsigned long  it_busno;     /* Bus number this table belongs to */
+	unsigned long  it_size;      /* Size in pages of iommu table */
+	unsigned long  it_offset;    /* Offset into global table */
+	unsigned long  it_base;      /* mapped address of tce table */
+	unsigned long  it_index;     /* which iommu table this is */
+	unsigned long  it_type;      /* type: PCI or Virtual Bus */
+	unsigned long  it_entrysize; /* Size of an entry in bytes */
+	unsigned long  it_blocksize; /* Entries in each block (cacheline) */
+	unsigned long  it_hint;      /* Hint for next alloc */
+	unsigned long  it_largehint; /* Hint for large allocs */
+	spinlock_t     it_lock;      /* Protects it_map */
+	unsigned long  it_mapsize;   /* Size of map in # of entries (bits) */
+	unsigned long *it_map;       /* A simple allocation bitmap for now */
+};
+
+#ifdef CONFIG_PPC_ISERIES
+struct iommu_table_cb {
+	unsigned long	itc_busno;	/* Bus number for this tce table */
+	unsigned long	itc_start;	/* Will be NULL for secondary */
+	unsigned long	itc_totalsize;	/* Size (in pages) of whole table */
+	unsigned long	itc_offset;	/* Index into real tce table of the
+					   start of our section */
+	unsigned long	itc_size;	/* Size (in pages) of our section */
+	unsigned long	itc_index;	/* Index of this tce table */
+	unsigned short	itc_maxtables;	/* Max num of tables for partition */
+	unsigned char	itc_virtbus;	/* Flag to indicate virtual bus */
+ 	unsigned char	itc_slotno;	/* IOA Tce Slot Index */
+ 	unsigned char	itc_rsvd[4];
+};
+
+extern struct iommu_table vio_tce_table;      /* Tce table for virtual bus */
+#endif /* CONFIG_PPC_ISERIES */
+
+struct scatterlist;
+
+#ifdef CONFIG_PPC_PSERIES
+/* Walks all buses and creates iommu tables */
+extern void iommu_setup_pSeries(void);
+extern void iommu_setup_pmac(void);
+
+/* Creates table for an individual device node */
+extern void iommu_devnode_init(struct device_node *dn);
+#endif /* CONFIG_PPC_PSERIES */
+
+#ifdef CONFIG_PPC_ISERIES
+/* Walks all buses and creates iommu tables */
+extern void iommu_setup_iSeries(void);
+
+/* Initializes tables for bio buses */
+extern void __init iommu_vio_init(void);
+
+struct iSeries_Device_Node;
+/* Creates table for an individual device node */
+extern void iommu_devnode_init(struct iSeries_Device_Node *dn);
+#endif /* CONFIG_PPC_ISERIES */
+
+
+/* Initializes an iommu_table based in values set in the passed-in
+ * structure
+ */
+extern struct iommu_table *iommu_init_table(struct iommu_table * tbl);
+
+/* allocates a range of tces and sets them to the pages  */
+extern dma_addr_t iommu_alloc(struct iommu_table *, void *page, 
+			      unsigned int numPages, int direction,
+			      unsigned long *handle);
+extern void iommu_free(struct iommu_table *tbl, dma_addr_t dma_addr, 
+		       unsigned int npages);
+
+/* same with sg lists */
+extern int iommu_alloc_sg(struct iommu_table *table, struct scatterlist *sglist,
+			  int nelems, int direction, unsigned long *handle);
+extern void iommu_free_sg(struct iommu_table *tbl, struct scatterlist *sglist,
+			  int nelems, int direction);
+
+
+extern void tce_init_pSeries(void);
+extern void tce_init_iSeries(void);
+
+extern void pci_iommu_init(void);
+extern void pci_dma_init_direct(void);
+
+#endif
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/machdep.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/machdep.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/machdep.h	2004-02-23 16:39:09.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/machdep.h	2004-02-27 23:02:35.000000000 +0000
@@ -15,7 +15,7 @@
 struct pt_regs;
 struct pci_bus;	
 struct device_node;
-struct TceTable;
+struct iommu_table;
 struct rtc_time;
 
 #ifdef CONFIG_SMP
@@ -53,12 +53,15 @@ struct machdep_calls {
 					    unsigned long number,
 					    int local);
 
-	void		(*tce_build)(struct TceTable * tbl,
-				     long tcenum,
+	void		(*tce_build)(struct iommu_table * tbl,
+				     long index,
+				     long npages,
 				     unsigned long uaddr,
 				     int direction);
-	void		(*tce_free_one)(struct TceTable *tbl,
-				        long tcenum);    
+	void		(*tce_free)(struct iommu_table *tbl,
+				    long index,
+				    long npages);
+	void		(*tce_flush)(struct iommu_table *tbl);
 
 	void		(*setup_arch)(void);
 	/* Optional, may be NULL. */
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/page.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/page.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/page.h	2003-12-30 08:43:20.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/page.h	2004-02-27 22:42:19.000000000 +0000
@@ -163,6 +163,9 @@ static inline int get_order(unsigned lon
 
 #define __pa(x) ((unsigned long)(x)-PAGE_OFFSET)
 
+/* Not 100% correct, for use by /dev/mem only */
+extern int page_is_ram(unsigned long physaddr);
+
 #endif /* __ASSEMBLY__ */
 
 #ifdef MODULE
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/pci.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/pci.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/pci.h	2004-02-27 05:25:16.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/pci.h	2004-02-27 23:02:35.000000000 +0000
@@ -70,6 +70,8 @@ struct pci_dma_ops {
 				      int nents, int direction);
 	void		(*pci_unmap_sg)(struct pci_dev *hwdev, struct scatterlist *sg,
 					int nents, int direction);
+	int		(*pci_dma_supported)(struct pci_dev *hwdev, u64 mask);
+	int		(*pci_dac_dma_supported)(struct pci_dev *hwdev, u64 mask);
 };
 
 extern struct pci_dma_ops pci_dma_ops;
@@ -130,10 +132,25 @@ static inline void pci_dma_sync_sg(struc
  * be supported properly.  For example, if your device can
  * only drive the low 24-bits during PCI bus mastering, then
  * you would pass 0x00ffffff as the mask to this function.
+ * We default to supporting only 32 bits DMA unless we have
+ * an explicit override of this function in pci_dma_ops for
+ * the platform
  */
 static inline int pci_dma_supported(struct pci_dev *hwdev, u64 mask)
 {
-	return 1;
+	if (pci_dma_ops.pci_dma_supported)
+		return pci_dma_ops.pci_dma_supported(hwdev, mask);
+	return (mask < 0x100000000ull);
+}
+
+/* For DAC DMA, we currently don't support it by default, but
+ * we let the platform override this
+ */
+static inline int pci_dac_dma_supported(struct pci_dev *hwdev,u64 mask)
+{
+	if (pci_dma_ops.pci_dac_dma_supported)
+		return pci_dma_ops.pci_dac_dma_supported(hwdev, mask);
+	return 0;
 }
 
 extern int pci_domain_nr(struct pci_bus *bus);
@@ -167,8 +184,6 @@ int pci_mmap_page_range(struct pci_dev *
 #define pci_unmap_len_set(PTR, LEN_NAME, VAL)		\
 	(((PTR)->LEN_NAME) = (VAL))
 
-#define pci_dac_dma_supported(pci_dev, mask)	(0)
-
 /* The PCI address space does equal the physical memory
  * address space.  The networking and block device layers use
  * this boolean for bounce buffer decisions.
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/pci_dma.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/pci_dma.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/pci_dma.h	2004-02-12 04:24:38.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/pci_dma.h	1970-01-01 00:00:00.000000000 +0000
@@ -1,102 +0,0 @@
-/*
- * pci_dma.h
- * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen IBM Corporation
- * 
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License as published by
- * the Free Software Foundation; either version 2 of the License, or
- * (at your option) any later version.
- * 
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- * 
- * You should have received a copy of the GNU General Public License
- * along with this program; if not, write to the Free Software
- * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
- */
-
-#ifndef _PCI_DMA_H
-#define _PCI_DMA_H
-
-#include <asm/types.h>
-#include <linux/spinlock.h>
-
-/*
- * NUM_TCE_LEVELS defines the largest contiguous block
- * of dma (tce) space we can get.  NUM_TCE_LEVELS = 10 
- * allows up to 2**9 pages (512 * 4096) = 2 MB
- */
-#define NUM_TCE_LEVELS 10
-
-#define NO_TCE ((dma_addr_t)-1)
-
-/*
- * Tces come in two formats, one for the virtual bus and a different
- * format for PCI
- */
-#define TCE_VB  0
-#define TCE_PCI 1
-
-union Tce {
-   	u64 wholeTce;
-	struct {
-		u64 cacheBits	:6;	/* Cache hash bits - not used */
-		u64 rsvd	:6;
-		u64 rpn		:40;	/* Absolute page number */
-		u64 valid	:1;	/* Tce is valid (vb only) */
-		u64 allIo	:1;	/* Tce is valid for all lps (vb only) */
-		u64 lpIndex	:8;	/* LpIndex for user of TCE (vb only) */
-		u64 pciWrite	:1;	/* Write allowed (pci only) */
-		u64 readWrite	:1;	/* Read allowed (pci), Write allowed (vb) */
-	} tceBits;
-};
-
-struct Bitmap {
-	unsigned long	numBits;
-	unsigned long	numBytes;
-	unsigned char * map;
-};
-
-struct MultiLevelBitmap {
-	unsigned long 	maxLevel;
-	struct Bitmap 	level[NUM_TCE_LEVELS];
-};
-
-struct TceTable {
-	u64	busNumber;
-	u64	size;
-	u64	startOffset;
-	u64     base;                   /* pSeries native only */
-	u64	index;
-	u64	tceType;
-	spinlock_t lock;
-	struct MultiLevelBitmap mlbm;
-};
-
-struct TceTableManagerCB {
-	u64	busNumber;		/* Bus number for this tce table */
-	u64	start;			/* Will be NULL for secondary */
-	u64	totalSize;		/* Size (in pages) of whole table */
-	u64	startOffset;		/* Index into real tce table of the
-					   start of our section */
-	u64	size;			/* Size (in pages) of our section */
-	u64	index;			/* Index of this tce table (token?) */
-	u16	maxTceTableIndex;	/* Max num of tables for partition */
-	u8	virtualBusFlag;		/* Flag to indicate virtual bus */
- 	u8	logicalSlot;		/* IOA Tce Slot Index */
- 	u8	rsvd[4];
-};
-
-extern struct TceTable virtBusTceTable;	/* Tce table for virtual bus */
-
-extern void create_tce_tables(void);
-extern void create_pci_bus_tce_table(unsigned long);
-
-extern void tce_init_pSeries(void);
-extern void tce_init_iSeries(void);
-
-extern void pci_dma_init_direct(void);
-
-#endif
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/pgtable.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/pgtable.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/pgtable.h	2004-01-31 08:15:29.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/pgtable.h	2004-02-27 12:16:07.000000000 +0000
@@ -12,6 +12,7 @@
 #include <asm/processor.h>		/* For TASK_SIZE */
 #include <asm/mmu.h>
 #include <asm/page.h>
+#include <asm/tlbflush.h>
 #endif /* __ASSEMBLY__ */
 
 /* PMD_SHIFT determines what a second-level page table entry can map */
@@ -288,72 +289,141 @@ static inline pte_t pte_mkyoung(pte_t pt
 	pte_val(pte) |= _PAGE_ACCESSED; return pte; }
 
 /* Atomic PTE updates */
-
-static inline unsigned long pte_update( pte_t *p, unsigned long clr,
-					unsigned long set )
+static inline unsigned long pte_update(pte_t *p, unsigned long clr)
 {
 	unsigned long old, tmp;
-	
+
 	__asm__ __volatile__(
 	"1:	ldarx	%0,0,%3		# pte_update\n\
-	andi.	%1,%0,%7\n\
+	andi.	%1,%0,%6\n\
 	bne-	1b \n\
 	andc	%1,%0,%4 \n\
-	or	%1,%1,%5 \n\
 	stdcx.	%1,0,%3 \n\
 	bne-	1b"
 	: "=&r" (old), "=&r" (tmp), "=m" (*p)
-	: "r" (p), "r" (clr), "r" (set), "m" (*p), "i" (_PAGE_BUSY)
+	: "r" (p), "r" (clr), "m" (*p), "i" (_PAGE_BUSY)
 	: "cc" );
 	return old;
 }
 
+/* PTE updating functions */
+extern void hpte_update(pte_t *ptep, unsigned long pte, int wrprot);
+
 static inline int ptep_test_and_clear_young(pte_t *ptep)
 {
-	return (pte_update(ptep, _PAGE_ACCESSED, 0) & _PAGE_ACCESSED) != 0;
+	unsigned long old;
+
+	old = pte_update(ptep, _PAGE_ACCESSED | _PAGE_HPTEFLAGS);
+	if (old & _PAGE_HASHPTE) {
+		hpte_update(ptep, old, 0);
+		flush_tlb_pending();	/* XXX generic code doesn't flush */
+	}
+	return (old & _PAGE_ACCESSED) != 0;
 }
 
+/*
+ * On RW/DIRTY bit transitions we can avoid flushing the hpte. For the
+ * moment we always flush but we need to fix hpte_update and test if the
+ * optimisation is worth it.
+ */
+#if 1
 static inline int ptep_test_and_clear_dirty(pte_t *ptep)
 {
-	return (pte_update(ptep, _PAGE_DIRTY, 0) & _PAGE_DIRTY) != 0;
+	unsigned long old;
+
+	old = pte_update(ptep, _PAGE_DIRTY | _PAGE_HPTEFLAGS);
+	if (old & _PAGE_HASHPTE)
+		hpte_update(ptep, old, 0);
+	return (old & _PAGE_DIRTY) != 0;
 }
 
-static inline pte_t ptep_get_and_clear(pte_t *ptep)
+static inline void ptep_set_wrprotect(pte_t *ptep)
 {
-	return __pte(pte_update(ptep, ~_PAGE_HPTEFLAGS, 0));
+	unsigned long old;
+
+	old = pte_update(ptep, _PAGE_RW | _PAGE_HPTEFLAGS);
+	if (old & _PAGE_HASHPTE)
+		hpte_update(ptep, old, 0);
+}
+
+/*
+ * We currently remove entries from the hashtable regardless of whether
+ * the entry was young or dirty. The generic routines only flush if the
+ * entry was young or dirty which is not good enough.
+ *
+ * We should be more intelligent about this but for the moment we override
+ * these functions and force a tlb flush unconditionally
+ */
+#define __HAVE_ARCH_PTEP_CLEAR_YOUNG_FLUSH
+#define ptep_clear_flush_young(__vma, __address, __ptep)		\
+({									\
+	int __young = ptep_test_and_clear_young(__ptep);		\
+	flush_tlb_page(__vma, __address);				\
+	__young;							\
+})
+
+#define __HAVE_ARCH_PTEP_CLEAR_DIRTY_FLUSH
+#define ptep_clear_flush_dirty(__vma, __address, __ptep)		\
+({									\
+	int __dirty = ptep_test_and_clear_dirty(__ptep);		\
+	flush_tlb_page(__vma, __address);				\
+	__dirty;							\
+})
+
+#else
+static inline int ptep_test_and_clear_dirty(pte_t *ptep)
+{
+	unsigned long old;
+
+	old = pte_update(ptep, _PAGE_DIRTY);
+	if ((~old & (_PAGE_HASHPTE | _PAGE_RW | _PAGE_DIRTY)) == 0)
+		hpte_update(ptep, old, 1);
+	return (old & _PAGE_DIRTY) != 0;
 }
 
 static inline void ptep_set_wrprotect(pte_t *ptep)
 {
-	pte_update(ptep, _PAGE_RW, 0);
+	unsigned long old;
+
+	old = pte_update(ptep, _PAGE_RW);
+	if ((~old & (_PAGE_HASHPTE | _PAGE_RW | _PAGE_DIRTY)) == 0)
+		hpte_update(ptep, old, 1);
 }
+#endif
 
-static inline void ptep_mkdirty(pte_t *ptep)
+static inline pte_t ptep_get_and_clear(pte_t *ptep)
 {
-	pte_update(ptep, 0, _PAGE_DIRTY);
+	unsigned long old = pte_update(ptep, ~0UL);
+
+	if (old & _PAGE_HASHPTE)
+		hpte_update(ptep, old, 0);
+	return __pte(old);
 }
 
-/*
- * Macro to mark a page protection value as "uncacheable".
- */
-#define pgprot_noncached(prot)	(__pgprot(pgprot_val(prot) | _PAGE_NO_CACHE | _PAGE_GUARDED))
+static inline void pte_clear(pte_t * ptep)
+{
+	unsigned long old = pte_update(ptep, ~0UL);
 
-#define pte_same(A,B)	(((pte_val(A) ^ pte_val(B)) & ~_PAGE_HPTEFLAGS) == 0)
+	if (old & _PAGE_HASHPTE)
+		hpte_update(ptep, old, 0);
+}
 
 /*
  * set_pte stores a linux PTE into the linux page table.
- * On machines which use an MMU hash table we avoid changing the
- * _PAGE_HASHPTE bit.
  */
 static inline void set_pte(pte_t *ptep, pte_t pte)
 {
-	pte_update(ptep, ~_PAGE_HPTEFLAGS, pte_val(pte) & ~_PAGE_HPTEFLAGS);
+	if (pte_present(*ptep))
+		pte_clear(ptep);
+	*ptep = __pte(pte_val(pte)) & ~_PAGE_HPTEFLAGS;
 }
 
-static inline void pte_clear(pte_t * ptep)
-{
-	pte_update(ptep, ~_PAGE_HPTEFLAGS, 0);
-}
+/*
+ * Macro to mark a page protection value as "uncacheable".
+ */
+#define pgprot_noncached(prot)	(__pgprot(pgprot_val(prot) | _PAGE_NO_CACHE | _PAGE_GUARDED))
+
+#define pte_same(A,B)	(((pte_val(A) ^ pte_val(B)) & ~_PAGE_HPTEFLAGS) == 0)
 
 extern unsigned long ioremap_bot, ioremap_base;
 
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/prom.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/prom.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/prom.h	2004-02-12 04:08:14.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/prom.h	2004-02-27 23:02:35.000000000 +0000
@@ -134,7 +134,7 @@ struct property {
  * indication of a real PCI node.  Other nodes leave these fields zeroed.
  */
 struct pci_controller;
-struct TceTable;
+struct iommu_table;
 struct device_node {
 	char	*name;
 	char	*type;
@@ -155,7 +155,7 @@ struct device_node {
 	int	eeh_mode;		/* See eeh.h for possible EEH_MODEs */
 	int	eeh_config_addr;
 	struct  pci_controller *phb;	/* for pci devices */
-	struct	TceTable *tce_table;	/* for phb's or bridges */
+	struct	iommu_table *iommu_table;	/* for phb's or bridges */
 
 	struct	property *properties;
 	struct	device_node *parent;
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/tlb.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/tlb.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/tlb.h	2004-01-19 06:28:26.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/tlb.h	2004-02-27 12:16:07.000000000 +0000
@@ -12,11 +12,9 @@
 #ifndef _PPC64_TLB_H
 #define _PPC64_TLB_H
 
-#include <asm/pgtable.h>
 #include <asm/tlbflush.h>
-#include <asm/page.h>
-#include <asm/mmu.h>
 
+struct mmu_gather;
 static inline void tlb_flush(struct mmu_gather *tlb);
 
 /* Avoid pulling in another include just for this */
@@ -29,66 +27,13 @@ static inline void tlb_flush(struct mmu_
 #define tlb_start_vma(tlb, vma)	do { } while (0)
 #define tlb_end_vma(tlb, vma)	do { } while (0)
 
-/* Should make this at least as large as the generic batch size, but it
- * takes up too much space */
-#define PPC64_TLB_BATCH_NR 192
-
-struct ppc64_tlb_batch {
-	unsigned long index;
-	pte_t pte[PPC64_TLB_BATCH_NR];
-	unsigned long addr[PPC64_TLB_BATCH_NR];
-	unsigned long vaddr[PPC64_TLB_BATCH_NR];
-};
-
-extern struct ppc64_tlb_batch ppc64_tlb_batch[NR_CPUS];
-
-static inline void __tlb_remove_tlb_entry(struct mmu_gather *tlb, pte_t *ptep,
-					unsigned long address)
-{
-	int cpu = smp_processor_id();
-	struct ppc64_tlb_batch *batch = &ppc64_tlb_batch[cpu];
-	unsigned long i = batch->index;
-	pte_t pte;
-	cpumask_t local_cpumask = cpumask_of_cpu(cpu);
-
-	if (pte_val(*ptep) & _PAGE_HASHPTE) {
-		pte = __pte(pte_update(ptep, _PAGE_HPTEFLAGS, 0));
-		if (pte_val(pte) & _PAGE_HASHPTE) {
-
-			batch->pte[i] = pte;
-			batch->addr[i] = address;
-			i++;
-
-			if (i == PPC64_TLB_BATCH_NR) {
-				int local = 0;
-
-				if (cpus_equal(tlb->mm->cpu_vm_mask, local_cpumask))
-					local = 1;
-
-				flush_hash_range(tlb->mm->context, i, local);
-				i = 0;
-			}
-		}
-	}
-
-	batch->index = i;
-}
+#define __tlb_remove_tlb_entry(tlb, pte, address) do { } while (0)
 
 extern void pte_free_finish(void);
 
 static inline void tlb_flush(struct mmu_gather *tlb)
 {
-	int cpu = smp_processor_id();
-	struct ppc64_tlb_batch *batch = &ppc64_tlb_batch[cpu];
-	int local = 0;
-	cpumask_t local_cpumask = cpumask_of_cpu(smp_processor_id());
-
-	if (cpus_equal(tlb->mm->cpu_vm_mask, local_cpumask))
-		local = 1;
-
-	flush_hash_range(tlb->mm->context, batch->index, local);
-	batch->index = 0;
-
+	flush_tlb_pending();
 	pte_free_finish();
 }
 
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/tlbflush.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/tlbflush.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/tlbflush.h	2002-06-07 08:21:41.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/tlbflush.h	2004-02-27 12:16:07.000000000 +0000
@@ -1,10 +1,6 @@
 #ifndef _PPC64_TLBFLUSH_H
 #define _PPC64_TLBFLUSH_H
 
-#include <linux/threads.h>
-#include <linux/mm.h>
-#include <asm/page.h>
-
 /*
  * TLB flushing:
  *
@@ -15,22 +11,39 @@
  *  - flush_tlb_pgtables(mm, start, end) flushes a range of page tables
  */
 
-extern void flush_tlb_mm(struct mm_struct *mm);
-extern void flush_tlb_page(struct vm_area_struct *vma, unsigned long vmaddr);
-extern void __flush_tlb_range(struct mm_struct *mm,
-			    unsigned long start, unsigned long end);
-#define flush_tlb_range(vma, start, end) \
-	__flush_tlb_range(vma->vm_mm, start, end)
+#include <linux/percpu.h>
+#include <asm/page.h>
+
+#define PPC64_TLB_BATCH_NR 192
 
-#define flush_tlb_kernel_range(start, end) \
-	__flush_tlb_range(&init_mm, (start), (end))
+struct mm_struct;
+struct ppc64_tlb_batch {
+	unsigned long index;
+	unsigned long context;
+	struct mm_struct *mm;
+	pte_t pte[PPC64_TLB_BATCH_NR];
+	unsigned long addr[PPC64_TLB_BATCH_NR];
+	unsigned long vaddr[PPC64_TLB_BATCH_NR];
+};
+DECLARE_PER_CPU(struct ppc64_tlb_batch, ppc64_tlb_batch);
 
-static inline void flush_tlb_pgtables(struct mm_struct *mm,
-				      unsigned long start, unsigned long end)
+extern void __flush_tlb_pending(struct ppc64_tlb_batch *batch);
+
+static inline void flush_tlb_pending(void)
 {
-	/* PPC has hw page tables. */
+	struct ppc64_tlb_batch *batch = &__get_cpu_var(ppc64_tlb_batch);
+
+	if (batch->index)
+		__flush_tlb_pending(batch);
 }
 
+#define flush_tlb_mm(mm)			flush_tlb_pending()
+#define flush_tlb_page(vma, addr)		flush_tlb_pending()
+#define flush_tlb_range(vma, start, end) \
+		do { (void)(start); flush_tlb_pending(); } while (0)
+#define flush_tlb_kernel_range(start, end)	flush_tlb_pending()
+#define flush_tlb_pgtables(mm, start, end)	do { } while (0)
+
 extern void flush_hash_page(unsigned long context, unsigned long ea, pte_t pte,
 			    int local);
 void flush_hash_range(unsigned long context, unsigned long number, int local);
diff -purN linux-post-2.6.3-20040227/include/asm-ppc64/vio.h linux-post-2.6.4rc1-20040228/include/asm-ppc64/vio.h
--- linux-post-2.6.3-20040227/include/asm-ppc64/vio.h	2004-02-05 21:11:03.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/asm-ppc64/vio.h	2004-02-27 23:02:35.000000000 +0000
@@ -38,7 +38,7 @@
 struct vio_dev;
 struct vio_driver;
 struct vio_device_id;
-struct TceTable;
+struct iommu_table;
 
 int vio_register_driver(struct vio_driver *drv);
 void vio_unregister_driver(struct vio_driver *drv);
@@ -48,7 +48,7 @@ struct vio_dev * __devinit vio_register_
 void __devinit vio_unregister_device(struct vio_dev *dev);
 const void * vio_get_attribute(struct vio_dev *vdev, void* which, int* length);
 int vio_get_irq(struct vio_dev *dev);
-struct TceTable * vio_build_tce_table(struct vio_dev *dev);
+struct iommu_table * vio_build_iommu_table(struct vio_dev *dev);
 int vio_enable_interrupts(struct vio_dev *dev);
 int vio_disable_interrupts(struct vio_dev *dev);
 
@@ -95,7 +95,7 @@ struct vio_dev {
 	struct device_node *archdata;   /* Open Firmware node */
 	void *driver_data;              /* data private to the driver */
 	unsigned long unit_address;	
-	struct TceTable *tce_table;     /* vio_map_* uses this */
+	struct iommu_table *iommu_table;     /* vio_map_* uses this */
 	unsigned int irq;
 
 	struct device dev;
diff -purN linux-post-2.6.3-20040227/include/linux/pci.h linux-post-2.6.4rc1-20040228/include/linux/pci.h
--- linux-post-2.6.3-20040227/include/linux/pci.h	2004-02-10 17:51:08.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/linux/pci.h	2004-02-18 23:41:55.000000000 +0000
@@ -468,6 +468,8 @@ struct pci_bus {
 
 	char		name[48];
 
+	unsigned short  bridge_ctl;	/* manage NO_ISA/FBB/et al behaviors */
+	unsigned short  pad2;
 	struct device		*bridge;
 	struct class_device	class_dev;
 };
diff -purN linux-post-2.6.3-20040227/include/video/radeon.h linux-post-2.6.4rc1-20040228/include/video/radeon.h
--- linux-post-2.6.3-20040227/include/video/radeon.h	2004-02-12 17:14:53.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/include/video/radeon.h	2004-02-27 22:45:14.000000000 +0000
@@ -24,6 +24,7 @@
 #define AGP_CNTL                               0x0174
 #define BM_STATUS                              0x0160
 #define CAP0_TRIG_CNTL			       0x0950
+#define CAP1_TRIG_CNTL		               0x09c0
 #define VIPH_CONTROL			       0x0C40
 #define VENDOR_ID                              0x0F00  
 #define DEVICE_ID                              0x0F02  
diff -purN linux-post-2.6.3-20040227/net/sctp/sm_statefuns.c linux-post-2.6.4rc1-20040228/net/sctp/sm_statefuns.c
--- linux-post-2.6.3-20040227/net/sctp/sm_statefuns.c	2004-01-16 16:38:18.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/net/sctp/sm_statefuns.c	2004-02-27 17:35:39.000000000 +0000
@@ -4272,8 +4272,7 @@ sctp_disposition_t sctp_sf_t1_timer_expi
 
 	SCTP_DEBUG_PRINTK("Timer T1 expired.\n");
 
-	if ((timeout < asoc->max_init_timeo) &&
-	    (attempts < asoc->max_init_attempts)) {
+	if (attempts < asoc->max_init_attempts) {
 		switch (timer) {
 		case SCTP_EVENT_TIMEOUT_T1_INIT:
 			bp = (struct sctp_bind_addr *) &asoc->base.bind_addr;
diff -purN linux-post-2.6.3-20040227/net/sunrpc/auth_gss/svcauth_gss.c linux-post-2.6.4rc1-20040228/net/sunrpc/auth_gss/svcauth_gss.c
--- linux-post-2.6.3-20040227/net/sunrpc/auth_gss/svcauth_gss.c	2004-02-27 05:32:56.000000000 +0000
+++ linux-post-2.6.4rc1-20040228/net/sunrpc/auth_gss/svcauth_gss.c	2004-02-27 20:27:21.000000000 +0000
@@ -686,7 +686,7 @@ svcauth_gss_accept(struct svc_rqst *rqst
 	u32		*reject_stat = resv->iov_base;
 	int		ret;
 
-	dprintk("RPC: svcauth_gss: argv->iov_len = %d\n",argv->iov_len);
+	dprintk("RPC: svcauth_gss: argv->iov_len = %zd\n",argv->iov_len);
 
 	*authp = rpc_autherr_badcred;
 	if (!svcdata)
