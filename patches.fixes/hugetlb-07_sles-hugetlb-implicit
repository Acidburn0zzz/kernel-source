diff -purN linux-2.6.5-7.5-06/include/linux/sysctl.h linux-2.6.5-7.5-07/include/linux/sysctl.h
--- linux-2.6.5-7.5-06/include/linux/sysctl.h	2004-04-28 14:18:15.000000000 -0700
+++ linux-2.6.5-7.5-07/include/linux/sysctl.h	2004-04-28 14:51:47.581750800 -0700
@@ -137,6 +137,10 @@ enum
 	KERN_MAXTIMESLICE=67,	/* int: nice -20 max timeslice */
 	KERN_MINTIMESLICE=68,	/* int: nice +19 min timeslice */
 	KERN_HZ=69,		/* unsigned long: interal kernel HZ */
+	KERN_SHMUSEHUGEPAGES=70,/* int: back shm with huge pages */
+	KERN_MMAPUSEHUGEPAGES=71,       /* int: back anon mmap with hpages */
+	KERN_HPAGES_MAP_SZ=72,  /* int: min size (MB) of mapping */
+
 };
 
 
diff -purN linux-2.6.5-7.5-06/ipc/shm.c linux-2.6.5-7.5-07/ipc/shm.c
--- linux-2.6.5-7.5-06/ipc/shm.c	2004-04-28 14:18:15.000000000 -0700
+++ linux-2.6.5-7.5-07/ipc/shm.c	2004-04-28 14:51:47.585750192 -0700
@@ -33,6 +33,8 @@
 
 #define shm_flags	shm_perm.mode
 
+int shm_use_hugepages;
+
 static struct file_operations shm_file_operations;
 static struct vm_operations_struct shm_vm_ops;
 
@@ -168,6 +170,31 @@ static struct vm_operations_struct shm_v
 	.get_policy = shmem_get_policy,
 };
 
+#ifdef CONFIG_HUGETLBFS
+static int shm_with_hugepages(int shmflag, size_t size)
+{
+	/* flag specified explicitly */
+	if (shmflag & SHM_HUGETLB)
+		return 1;
+	/* Are we disabled? */
+	if (!shm_use_hugepages)
+		return 0;
+	/* Must be HPAGE aligned */
+	if (size & ~HPAGE_MASK)
+		return 0;
+	/* Do we have enough free huge pages? */
+	if (!is_hugepage_mem_enough(size))
+		return 0;
+	
+	return 1;
+}
+#else
+static inline int shm_with_hugepages(int shmflag, size_t size)
+{
+	return 0;
+}
+#endif
+
 static int newseg (key_t key, int shmflg, size_t size)
 {
 	int error;
@@ -197,9 +224,10 @@ static int newseg (key_t key, int shmflg
 		return error;
 	}
 
-	if (shmflg & SHM_HUGETLB)
+	if (shm_with_hugepages(shmflg, size)) {
+		shmflg |= SHM_HUGETLB;
 		file = hugetlb_zero_setup(size);
-	else {
+	} else {
 		sprintf (name, "SYSV%08x", key);
 		file = shmem_file_setup(name, size, VM_ACCOUNT);
 	}
diff -purN linux-2.6.5-7.5-06/kernel/sysctl.c linux-2.6.5-7.5-07/kernel/sysctl.c
--- linux-2.6.5-7.5-06/kernel/sysctl.c	2004-04-28 14:18:15.000000000 -0700
+++ linux-2.6.5-7.5-07/kernel/sysctl.c	2004-04-28 14:51:47.588749736 -0700
@@ -67,6 +67,8 @@ extern int sysctl_lower_zone_protection;
 extern int min_free_kbytes;
 extern int printk_ratelimit_jiffies;
 extern int printk_ratelimit_burst;
+extern int shm_use_hugepages;
+extern int mmap_use_hugepages, mmap_hugepages_map_sz;
 
 /* this is needed for the proc_dointvec_minmax for [fs_]overflow UID and GID */
 static int maxolduid = 65535;
@@ -673,6 +675,32 @@ static ctl_table kern_table[] = {
 		.mode		= 0444,
 		.proc_handler	= &proc_dointvec,
 	},
+#ifdef CONFIG_HUGETLBFS
+	{
+		.ctl_name	= KERN_SHMUSEHUGEPAGES,
+		.procname	= "shm-use-hugepages",
+		.data		= &shm_use_hugepages,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec,
+	},
+	{
+		.ctl_name	= KERN_MMAPUSEHUGEPAGES,
+		.procname	= "mmap-use-hugepages",
+		.data		= &mmap_use_hugepages,
+		.maxlen		= sizeof(int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec,
+	},
+	{
+		.ctl_name	= KERN_HPAGES_MAP_SZ,
+		.procname	= "mmap-hugepages-min-mapping",
+		.data		= &mmap_hugepages_map_sz,
+		.maxlen		= sizeof(int),
+		.mode		0644,
+		.proc_handler	= &proc_dointvec,
+	},
+#endif
 	{ .ctl_name = 0 }
 };
 
diff -purN linux-2.6.5-7.5-06/mm/mmap.c linux-2.6.5-7.5-07/mm/mmap.c
--- linux-2.6.5-7.5-06/mm/mmap.c	2004-04-28 14:29:02.000000000 -0700
+++ linux-2.6.5-7.5-07/mm/mmap.c	2004-04-28 14:55:08.273241056 -0700
@@ -788,6 +788,35 @@ unacct_error:
 	return error;
 }
 
+#ifdef CONFIG_HUGETLBFS
+static int mmap_hugetlb_implicit(unsigned long len)
+{
+	/* Are we enabled? */
+	if (!mmap_use_hugepages)
+		return 0;
+	/* Must be HPAGE aligned */
+	if (len & ~HPAGE_MASK)
+		return 0;
+	/* Are we capable ? */
+	if (!capable(CAP_IPC_LOCK))
+		return -EPERM;
+	/* Are we under the minimum size? */
+	if (mmap_hugepages_map_sz
+		&& len < (mmap_hugepages_map_sz << 20))
+		return 0;
+	/* Do we have enough huge pages ? */
+	if (!is_hugepage_mem_enough(len))
+		return 0;
+
+	return 1;
+}
+#else
+static inline int mmap_hugetlb_implicit(unsigned long len)
+{
+	return 0;
+}
+#endif /* CONFIG_HUGETLBFS */
+
 /*
  * The caller must hold down_write(current->mm->mmap_sem).
  */
@@ -797,6 +826,7 @@ unsigned long __do_mmap_pgoff(struct mm_
 		unsigned long flags, unsigned long pgoff)
 {
 	struct file *hugetlb_file = NULL;
+	int hugetlb_implicit = 0;
 	unsigned long result;
 
 	if (file) {
@@ -827,12 +857,18 @@ unsigned long __do_mmap_pgoff(struct mm_
 		return -ENOMEM;
 
 	/* Create an implicit hugetlb file if necessary */
-	if (!file && (flags & MAP_HUGETLB)) {
+	if (!file && ((flags & MAP_HUGETLB) ||
+			(hugetlb_implicit = mmap_hugetlb_implicit(len)))) {
 		file = hugetlb_file = hugetlb_zero_setup(len);
-		if (IS_ERR(file))
-			return PTR_ERR(file);
+		if (IS_ERR(file)) {
+			if (!hugetlb_implicit)
+				return PTR_ERR(file);
+			file = hugetlb_file = NULL;
+			hugetlb_implicit = 0;
+		}
 	}
 
+again:
 	result = __finish_do_mmap_pgoff(mm, file, addr, len, prot, flags, pgoff);
 
 	/* Drop reference to implicit hugetlb file, it's already been
@@ -841,6 +877,13 @@ unsigned long __do_mmap_pgoff(struct mm_
 	if (hugetlb_file)
 		fput(hugetlb_file);
 
+	/* If implicit huge tlb & we failed, try again without */
+	if ((result & ~PAGE_MASK) && hugetlb_implicit) {
+		hugetlb_implicit = 0;
+		file = NULL;
+		goto again;
+	}
+
 	return result;
 }
 
