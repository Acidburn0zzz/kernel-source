From: olh@suse.de
Subject: patch-2.6.11-rc3-bk6

 -- www.kernel.org/pub/linux/kernel/v2.6/snapshots/patch-2.6.11-rc3-bk5.log	2005-02-08 13:56:59.000000000 +0100
 ++ www.kernel.org/pub/linux/kernel/v2.6/snapshots/patch-2.6.11-rc3-bk6.log	2005-02-09 13:57:28.000000000 +0100
 ChangeSet@1.2143, 2005-02-07 21:32:50-08:00, andrew.vasquez@qlogic.com
 ChangeSet@1.2132.2.1, 2005-02-08 22:10:09+00:00, buytenh@org.rmk.(none)
   [ARM PATCH] 2457/1: fix two typos in arch/arm/mm/tlb*.S
   
   Patch from Lennert Buytenhek
   
   Fix two typos in arch/arm/mm/tlb*.S
   
   Signed-off-by: Lennert Buytenhek
   Signed-off-by: Russell King
 
 ChangeSet@1.2148, 2005-02-08 08:05:27-08:00, dhowells@redhat.com
   [PATCH] NOMMU: Documentation of no-MMU mmap
   
   The attached patch adds documentation for the behaviour of the no-MMU mmap.
   
   Signed-Off-By: David Howells <dhowells@redhat.com>
   Signed-Off-By: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2147, 2005-02-08 08:05:10-08:00, dhowells@redhat.com
   [PATCH] NOMMU: Improved handling of get_unmapped_area() errors
   
   The attached patch does two things:
   
    (1) We no longer check the return value of file->f_op->get_unmapped_area()
        unless we actually called it. We know addr is zero otherwise because
        we'd've given an error earlier if it wasn't.
   
    (2) If -ENOSYS was returned by that operation, then we assume we actually
        called a driver (such as the framebuffer driver) that might want to
        invoke the operation in a lower level driver (such as matroxfb) if one
        exists, and that it found that one didn't.
   
        We translate the -ENOSYS error into -ENODEV - the error we would have
        given if the operation was not supplied in the file ops.
   
        Doing this permits us an opportunity for arch_get_unmapped_area() or
        something else to be called if we want that to happen, particularly in
        the MMU case.
   
   Signed-Off-By: David Howells <dhowells@redhat.com>
   Signed-Off-By: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2146, 2005-02-08 07:59:56-08:00, torvalds@ppc970.osdl.org
   Fix ATM copy-to-user usage.
   
   More of the Guninski "copy_to_user() takes a size_t" series.
 
 ChangeSet@1.2145, 2005-02-08 07:48:20-08:00, neilb@cse.unsw.edu.au
   [PATCH] nfsd: Allow read access over NFS to files with APPEND bit set.
   
   Write access cannot safely be allowed as NFS doesn't support append, but read
   access should be ok.
   
   Signed-off-by: Neil Brown <neilb@cse.unsw.edu.au>
   Signed-off-by: Andrew Morton <akpm@osdl.org>
   Signed-off-by: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2144, 2005-02-08 07:48:07-08:00, neilb@cse.unsw.edu.au
   [PATCH] nfsd: Don't try to cache reply to nfsv2 readdir.
   
   As readdir returns the reply in a separate page, the cache code cannot find
   the reply (and it would probably be too big anyway) so flag readdir for NOCACHE
   
   Signed-off-by: Olaf Kirch <okir@suse.de>
   Signed-off-by: Neil Brown <neilb@cse.unsw.edu.au>
   Signed-off-by: Andrew Morton <akpm@osdl.org>
   Signed-off-by: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2143, 2005-02-08 07:47:54-08:00, neilb@cse.unsw.edu.au
   [PATCH] raid5 overlapping read hack
   
   If we detect an overlap, we set a flag and wait for a wakeup.  When requests
   are handled, if the flag was set, we perform the wakeup.
   
   Note that the code currently in -mm is badly broken.  With this patch applied,
   it passes tests the use O_DIRECT to cause lots of overlapping requests.
   
   Signed-off-by: Neil Brown <neilb@cse.unsw.edu.au>
   Signed-off-by: Andrew Morton <akpm@osdl.org>
   Signed-off-by: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2142, 2005-02-08 07:47:40-08:00, neilb@cse.unsw.edu.au
   [PATCH] md: remove extra loop from copy_data
   
   copy_data currently loops over bio's in a list, but the caller also does the
   same looping, sometimes with extra work.  So remove the loop from copy_data.
   
   Signed-off-by: Neil Brown <neilb@cse.unsw.edu.au>
   Signed-off-by: Andrew Morton <akpm@osdl.org>
   Signed-off-by: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2141, 2005-02-08 07:47:26-08:00, neilb@cse.unsw.edu.au
   [PATCH] md: fix endless loop when syncing an array that doesn't need any resync.
   
   If the resync checkpoint for an array is at the end of the array, It doesn't
   get set to MAX_SECTOR, so resyncing will be retried.  By updating curr_resync
   early, this problem is fixed.
   
   Signed-off-by: Neil Brown <neilb@cse.unsw.edu.au>
   Signed-off-by: Andrew Morton <akpm@osdl.org>
   Signed-off-by: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2140, 2005-02-08 07:47:13-08:00, neilb@cse.unsw.edu.au
   [PATCH] md: make md work a bit better with devfs
   
   - set ->devfs_name
   - create initial devfs names slightly differently so
     as not to conflict
   - re-read partition table when an array is assembled at boot
     time - not sure why this is needed, but it is.
   
   Signed-off-by: Neil Brown <neilb@cse.unsw.edu.au>
   Signed-off-by: Andrew Morton <akpm@osdl.org>
   Signed-off-by: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2139, 2005-02-08 07:46:57-08:00, neilb@cse.unsw.edu.au
   [PATCH] md: prevent oops when drive set faulty in inactive md array.
   
   hot_add_disk and hot_remove_disk check mddev->pers before proceeding.
   set_disk_faulty should too.
   
   Signed-off-by: Neil Brown <neilb@cse.unsw.edu.au>
   Signed-off-by: Andrew Morton <akpm@osdl.org>
   Signed-off-by: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2138, 2005-02-08 07:46:44-08:00, neilb@cse.unsw.edu.au
   [PATCH] md: fix problems with verion-1 superblock code
   
   - off-by-one error
   - missing recalc of checksum
   
   Signed-off-by: Neil Brown <neilb@cse.unsw.edu.au>
   Signed-off-by: Andrew Morton <akpm@osdl.org>
   Signed-off-by: Linus Torvalds <torvalds@osdl.org>
 
 ChangeSet@1.2128.4.2, 2005-02-08 20:57:43+11:00, airlied@starflyer.(none)
   drm: fix race condition in radeon driver
   
   Close a race which could allow for privilege escalation by users with DRI
   privileges on Radeon hardware.  Essentially, a malicious program could submit
   a packet containing an offset (possibly in main memory) to be rendered from/to,
   while a separate thread switched that offset in userspace rapidly between a
   valid value and an invalid one.  radeon_check_and_fixup_offset() would pull the
   offset in from user space, check it, and spit it back out to user space to be
   copied in later by the emit code.  It would sometimes catch the bad value, but
   sometimes the malicious program could modify it after the check and get an
   invalid offset rendered from/to.
   
   Fix this by allocating a temporary buffer and copying the data in at once.
   While here, make the cliprects stuff not do the VERIFYAREA_READ and
   COPY_FROM_USER_UNCHECKED gymnastics, avoiding a lock order reversal on FreeBSD.
   Performance impact is negligible  -- no difference on r200 to ~1% improvement on
   rv200 in quake3 tests (P4 1Ghz, demofour at 1024x768, n=4 or 5)
   
   From: Eric Anholt <anholt@freebsd.org>
   Signed-off-by: Dave Airlie <airlied@linux.ie>
 
 ChangeSet@1.2128.4.1, 2005-02-08 19:26:24+11:00, airlied@starflyer.(none)
   Invalid bound check of driver defined ioctls in drm_ioctl
   
   Bug fd.o 2489
   Reporter: Aapo Tahkola <aet@rasterburn.org>
   Signed-off-by: Dave Airlie <airlied@linux.ie>
 
 ChangeSet@1.2132.1.11, 2005-02-07 21:32:50-08:00, andrew.vasquez@qlogic.com
 ChangeSet@1.2142, 2005-02-07 21:32:36-08:00, yuasa@hh.iij4u.or.jp
 ChangeSet@1.2132.1.10, 2005-02-07 21:32:36-08:00, yuasa@hh.iij4u.or.jp
 ChangeSet@1.2141, 2005-02-07 21:32:21-08:00, e9925248@student.tuwien.ac.at
 ChangeSet@1.2132.1.9, 2005-02-07 21:32:21-08:00, e9925248@student.tuwien.ac.at
 ChangeSet@1.2140, 2005-02-07 21:32:06-08:00, suresh.b.siddha@intel.com
 ChangeSet@1.2132.1.8, 2005-02-07 21:32:06-08:00, suresh.b.siddha@intel.com
 ChangeSet@1.2139, 2005-02-07 21:31:52-08:00, blaisorblade@yahoo.it
 ChangeSet@1.2132.1.7, 2005-02-07 21:31:52-08:00, blaisorblade@yahoo.it
 ChangeSet@1.2138, 2005-02-07 21:31:37-08:00, blaisorblade@yahoo.it
 ChangeSet@1.2132.1.6, 2005-02-07 21:31:37-08:00, blaisorblade@yahoo.it
 ChangeSet@1.2137, 2005-02-07 21:31:22-08:00, mingo@elte.hu
 ChangeSet@1.2132.1.5, 2005-02-07 21:31:22-08:00, mingo@elte.hu
 ChangeSet@1.2136, 2005-02-07 21:31:08-08:00, nickpiggin@yahoo.com.au
 ChangeSet@1.2132.1.4, 2005-02-07 21:31:08-08:00, nickpiggin@yahoo.com.au
 ChangeSet@1.2135, 2005-02-07 21:30:52-08:00, yust@anti-leasure.ru
 ChangeSet@1.2132.1.3, 2005-02-07 21:30:52-08:00, yust@anti-leasure.ru
 ChangeSet@1.2134, 2005-02-07 21:30:37-08:00, hch@lst.de
 ChangeSet@1.2132.1.2, 2005-02-07 21:30:37-08:00, hch@lst.de
 ChangeSet@1.2133, 2005-02-07 16:43:44-08:00, johnrose@austin.ibm.com
 ChangeSet@1.2135, 2005-02-07 20:27:33-08:00, davem@nuts.davemloft.net
   [SPARC64]: Mask off stack ptr in compat_alloc_user_space() for 32-bit.
   
   Signed-off-by: David S. Miller <davem@davemloft.net>
 
 ChangeSet@1.2132.1.1, 2005-02-07 16:43:44-08:00, johnrose@austin.ibm.com
 ChangeSet@1.2134, 2005-02-07 15:29:42-08:00, davem@nuts.davemloft.net
   [SPARC64]: Update defconfig.
   
   Signed-off-by: David S. Miller <davem@davemloft.net>
 
 ChangeSet@1.2127.1.4, 2005-02-07 11:35:09-08:00, davem@nuts.davemloft.net
   [SPARC64]: Fix off-by-one handling of size in user_fixup.c
   
   Noticed by Jurij Smakov <jurij@wooyd.org>
   
   Signed-off-by: David S. Miller <davem@davemloft.net>
 
diff -purN linux-2.6.11-rc3-bk5/Documentation/nommu-mmap.txt linux-2.6.11-rc3-bk6/Documentation/nommu-mmap.txt
--- linux-2.6.11-rc3-bk5/Documentation/nommu-mmap.txt	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.11-rc3-bk6/Documentation/nommu-mmap.txt	2005-02-09 15:46:42.959399815 +0100
@@ -0,0 +1,141 @@
+			 =============================
+			 NO-MMU MEMORY MAPPING SUPPORT
+			 =============================
+
+The kernel has limited support for memory mapping under no-MMU conditions, such
+as are used in uClinux environments. From the userspace point of view, memory
+mapping is made use of in conjunction with the mmap() system call, the shmat()
+call and the execve() system call. From the kernel's point of view, execve()
+mapping is actually performed by the binfmt drivers, which call back into the
+mmap() routines to do the actual work.
+
+Memory mapping behaviour also involves the way fork(), vfork(), clone() and
+ptrace() work. Under uClinux there is no fork(), and clone() must be supplied
+the CLONE_VM flag.
+
+The behaviour is similar between the MMU and no-MMU cases, but not identical;
+and it's also much more restricted in the latter case:
+
+ (*) Anonymous mapping, MAP_PRIVATE
+
+	In the MMU case: VM regions backed by arbitrary pages; copy-on-write
+	across fork.
+
+	In the no-MMU case: VM regions backed by arbitrary contiguous runs of
+	pages.
+
+ (*) Anonymous mapping, MAP_SHARED
+
+	These behave very much like private mappings, except that they're
+	shared across fork() or clone() without CLONE_VM in the MMU case. Since
+	the no-MMU case doesn't support these, behaviour is identical to
+	MAP_PRIVATE there.
+
+ (*) File, MAP_PRIVATE, PROT_READ / PROT_EXEC, !PROT_WRITE
+
+	In the MMU case: VM regions backed by pages read from file; changes to
+	the underlying file are reflected in the mapping; copied across fork.
+
+	In the no-MMU case: VM regions backed by arbitrary contiguous runs of
+	pages into which the appropriate bit of the file is read; any remaining
+	bit of the mapping is cleared; such mappings are shared if possible;
+	writes to the file do not affect the mapping; writes to the mapping are
+	visible in other processes (no MMU protection), but should not happen.
+
+ (*) File, MAP_PRIVATE, PROT_READ / PROT_EXEC, PROT_WRITE
+
+	In the MMU case: like the non-PROT_WRITE case, except that the pages in
+	question get copied before the write actually happens. From that point
+	on writes to that page in the file no longer get reflected into the
+	mapping's backing pages.
+
+	In the no-MMU case: works exactly as for the non-PROT_WRITE case.
+
+ (*) Regular file / blockdev, MAP_SHARED, PROT_READ / PROT_EXEC / PROT_WRITE
+
+	In the MMU case: VM regions backed by pages read from file; changes to
+	pages written back to file; writes to file reflected into pages backing
+	mapping; shared across fork.
+
+	In the no-MMU case: not supported.
+
+ (*) Memory backed regular file, MAP_SHARED, PROT_READ / PROT_EXEC / PROT_WRITE
+
+	In the MMU case: As for ordinary regular files.
+
+	In the no-MMU case: The filesystem providing the memory-backed file
+	(such as ramfs or tmpfs) may choose to honour an open, truncate, mmap
+	sequence by providing a contiguous sequence of pages to map. In that
+	case, a shared-writable memory mapping will be possible. It will work
+	as for the MMU case. If the filesystem does not provide any such
+	support, then the mapping request will be denied.
+
+ (*) Memory backed chardev, MAP_SHARED, PROT_READ / PROT_EXEC / PROT_WRITE
+
+	In the MMU case: As for ordinary regular files.
+
+	In the no-MMU case: The character device driver may choose to honour
+	the mmap() by providing direct access to the underlying device if it
+	provides memory or quasi-memory that can be accessed directly. Examples
+	of such are frame buffers and flash devices. If the driver does not
+	provide any such support, then the mapping request will be denied.
+
+
+============================
+FURTHER NOTES ON NO-MMU MMAP
+============================
+
+ (*) A request for a private mapping of less than a page in size may not return
+     a page-aligned buffer. This is because the kernel calls kmalloc() to
+     allocate the buffer, not get_free_page().
+
+ (*) A list of all the mappings on the system is visible through /proc/maps in
+     no-MMU mode.
+
+ (*) Supplying MAP_FIXED or a requesting a particular mapping address will
+     result in an error.
+
+ (*) Files mapped privately must have a read method provided by the driver or
+     filesystem so that the contents can be read into the memory allocated. An
+     error will result if they don't. This is most likely to be encountered
+     with character device files, pipes, fifos and sockets.
+
+
+============================================
+PROVIDING SHAREABLE CHARACTER DEVICE SUPPORT
+============================================
+
+To provide shareable character device support, a driver must provide a
+file->f_op->get_unmapped_area() operation. The mmap() routines will call this
+to get a proposed address for the mapping. This may return an error if it
+doesn't wish to honour the mapping because it's too long, at a weird offset,
+under some unsupported combination of flags or whatever.
+
+The vm_ops->close() routine will be invoked when the last mapping on a chardev
+is removed. An existing mapping will be shared, partially or not, if possible
+without notifying the driver.
+
+It is permitted also for the file->f_op->get_unmapped_area() operation to
+return -ENOSYS. This will be taken to mean that this operation just doesn't
+want to handle it, despite the fact it's got an operation. For instance, it
+might try directing the call to a secondary driver which turns out not to
+implement it. Such is the case for the framebuffer driver which attempts to
+direct the call to the device-specific driver.
+
+
+==============================================
+PROVIDING SHAREABLE MEMORY-BACKED FILE SUPPORT
+==============================================
+
+Provision of shared mappings on memory backed files is similar to the provision
+of support for shared mapped character devices. The main difference is that the
+filesystem providing the service will probably allocate a contiguous collection
+of pages and permit mappings to be made on that.
+
+It is recommended that a truncate operation applied to such a file that
+increases the file size, if that file is empty, be taken as a request to gather
+enough pages to honour a mapping. This is required to support POSIX shared
+memory.
+
+Memory backed devices are indicated by the mapping's backing device info having
+the memory_backed flag set.
diff -purN linux-2.6.11-rc3-bk5/Makefile linux-2.6.11-rc3-bk6/Makefile
--- linux-2.6.11-rc3-bk5/Makefile	2005-02-09 15:46:35.731457000 +0100
+++ linux-2.6.11-rc3-bk6/Makefile	2005-02-09 15:46:42.967398571 +0100
@@ -1,7 +1,7 @@
 VERSION = 2
 PATCHLEVEL = 6
 SUBLEVEL = 11
-EXTRAVERSION = -rc3-bk5
+EXTRAVERSION = -rc3-bk6
 NAME=Woozy Numbat
 
 # *DOCUMENTATION*
diff -purN linux-2.6.11-rc3-bk5/arch/arm/mm/tlb-v4.S linux-2.6.11-rc3-bk6/arch/arm/mm/tlb-v4.S
--- linux-2.6.11-rc3-bk5/arch/arm/mm/tlb-v4.S	2005-02-03 02:55:35.000000000 +0100
+++ linux-2.6.11-rc3-bk6/arch/arm/mm/tlb-v4.S	2005-02-09 15:46:42.971397950 +0100
@@ -44,7 +44,7 @@ ENTRY(v4_flush_user_tlb_range)
 	mov	pc, lr
 
 /*
- *	v4_flush_kerm_tlb_range(start, end)
+ *	v4_flush_kern_tlb_range(start, end)
  *
  *	Invalidate a range of TLB entries in the specified kernel
  *	address range.
diff -purN linux-2.6.11-rc3-bk5/arch/arm/mm/tlb-v4wb.S linux-2.6.11-rc3-bk6/arch/arm/mm/tlb-v4wb.S
--- linux-2.6.11-rc3-bk5/arch/arm/mm/tlb-v4wb.S	2005-02-03 02:55:35.000000000 +0100
+++ linux-2.6.11-rc3-bk6/arch/arm/mm/tlb-v4wb.S	2005-02-09 15:46:42.972397795 +0100
@@ -47,7 +47,7 @@ ENTRY(v4wb_flush_user_tlb_range)
 	mov	pc, lr
 
 /*
- *	v4_flush_kerm_tlb_range(start, end)
+ *	v4_flush_kern_tlb_range(start, end)
  *
  *	Invalidate a range of TLB entries in the specified kernel
  *	address range.
diff -purN linux-2.6.11-rc3-bk5/arch/sparc64/defconfig linux-2.6.11-rc3-bk6/arch/sparc64/defconfig
--- linux-2.6.11-rc3-bk5/arch/sparc64/defconfig	2005-02-03 02:55:36.000000000 +0100
+++ linux-2.6.11-rc3-bk6/arch/sparc64/defconfig	2005-02-09 15:46:43.196362988 +0100
@@ -1,7 +1,7 @@
 #
 # Automatically generated make config: don't edit
-# Linux kernel version: 2.6.11-rc1
-# Fri Jan 21 20:03:21 2005
+# Linux kernel version: 2.6.11-rc3
+# Mon Feb  7 15:29:00 2005
 #
 CONFIG_64BIT=y
 CONFIG_MMU=y
@@ -845,6 +845,7 @@ CONFIG_BT_HCIUART_H4=y
 CONFIG_BT_HCIUART_BCSP=y
 CONFIG_BT_HCIUART_BCSP_TXCRC=y
 CONFIG_BT_HCIBCM203X=m
+CONFIG_BT_HCIBPA10X=m
 CONFIG_BT_HCIBFUSB=m
 CONFIG_BT_HCIVHCI=m
 CONFIG_NETDEVICES=y
@@ -1245,7 +1246,12 @@ CONFIG_JFS_SECURITY=y
 # CONFIG_JFS_DEBUG is not set
 # CONFIG_JFS_STATISTICS is not set
 CONFIG_FS_POSIX_ACL=y
+
+#
+# XFS support
+#
 CONFIG_XFS_FS=m
+CONFIG_XFS_EXPORT=y
 # CONFIG_XFS_RT is not set
 CONFIG_XFS_QUOTA=y
 CONFIG_XFS_SECURITY=y
@@ -1520,6 +1526,11 @@ CONFIG_DVB_ATMEL_AT76C651=m
 CONFIG_DVB_VES1820=m
 CONFIG_DVB_TDA10021=m
 CONFIG_DVB_STV0297=m
+
+#
+# ATSC (North American/Korean Terresterial DTV) frontends
+#
+CONFIG_DVB_NXT2002=m
 CONFIG_VIDEO_SAA7146=m
 CONFIG_VIDEO_SAA7146_VV=m
 CONFIG_VIDEO_VIDEOBUF=m
@@ -1527,6 +1538,7 @@ CONFIG_VIDEO_TUNER=m
 CONFIG_VIDEO_BUF=m
 CONFIG_VIDEO_BTCX=m
 CONFIG_VIDEO_IR=m
+CONFIG_VIDEO_TVEEPROM=m
 
 #
 # Sound
diff -purN linux-2.6.11-rc3-bk5/arch/sparc64/lib/user_fixup.c linux-2.6.11-rc3-bk6/arch/sparc64/lib/user_fixup.c
--- linux-2.6.11-rc3-bk5/arch/sparc64/lib/user_fixup.c	2005-02-03 02:57:16.000000000 +0100
+++ linux-2.6.11-rc3-bk6/arch/sparc64/lib/user_fixup.c	2005-02-09 15:46:43.209360968 +0100
@@ -20,11 +20,12 @@ unsigned long copy_from_user_fixup(void 
 	char *dst = to;
 	const char __user *src = from;
 
-	while (size--) {
+	while (size) {
 		if (__get_user(*dst, src))
 			break;
 		dst++;
 		src++;
+		size--;
 	}
 
 	if (size)
@@ -38,11 +39,12 @@ unsigned long copy_to_user_fixup(void __
 	char __user *dst = to;
 	const char *src = from;
 
-	while (size--) {
+	while (size) {
 		if (__put_user(*src, dst))
 			break;
 		dst++;
 		src++;
+		size--;
 	}
 
 	return size;
@@ -53,7 +55,7 @@ unsigned long copy_in_user_fixup(void __
 	char __user *dst = to;
 	char __user *src = from;
 
-	while (size--) {
+	while (size) {
 		char tmp;
 
 		if (__get_user(tmp, src))
@@ -62,6 +64,7 @@ unsigned long copy_in_user_fixup(void __
 			break;
 		dst++;
 		src++;
+		size--;
 	}
 
 	return size;
diff -purN linux-2.6.11-rc3-bk5/drivers/char/drm/drm_drv.c linux-2.6.11-rc3-bk6/drivers/char/drm/drm_drv.c
--- linux-2.6.11-rc3-bk5/drivers/char/drm/drm_drv.c	2005-02-03 02:56:33.000000000 +0100
+++ linux-2.6.11-rc3-bk6/drivers/char/drm/drm_drv.c	2005-02-09 15:46:43.254353975 +0100
@@ -516,7 +516,7 @@ int drm_ioctl( struct inode *inode, stru
 	
 	if (nr < DRIVER_IOCTL_COUNT)
 		ioctl = &drm_ioctls[nr];
-	else if ((nr >= DRM_COMMAND_BASE) || (nr < DRM_COMMAND_BASE + dev->driver->num_ioctls))
+	else if ((nr >= DRM_COMMAND_BASE) && (nr < DRM_COMMAND_BASE + dev->driver->num_ioctls))
 		ioctl = &dev->driver->ioctls[nr - DRM_COMMAND_BASE];
 	else
 		goto err_i1;
diff -purN linux-2.6.11-rc3-bk5/drivers/char/drm/drm_os_linux.h linux-2.6.11-rc3-bk6/drivers/char/drm/drm_os_linux.h
--- linux-2.6.11-rc3-bk5/drivers/char/drm/drm_os_linux.h	2005-02-03 02:56:48.000000000 +0100
+++ linux-2.6.11-rc3-bk6/drivers/char/drm/drm_os_linux.h	2005-02-09 15:46:43.255353820 +0100
@@ -96,9 +96,6 @@ static __inline__ int mtrr_del (int reg,
 	__copy_to_user(arg1, arg2, arg3)
 #define DRM_GET_USER_UNCHECKED(val, uaddr)		\
 	__get_user(val, uaddr)
-#define DRM_PUT_USER_UNCHECKED(uaddr, val)		\
-	__put_user(val, uaddr)
-
 
 #define DRM_GET_PRIV_WITH_RETURN(_priv, _filp) _priv = _filp->private_data
 
diff -purN linux-2.6.11-rc3-bk5/drivers/char/drm/radeon_drv.h linux-2.6.11-rc3-bk6/drivers/char/drm/radeon_drv.h
--- linux-2.6.11-rc3-bk5/drivers/char/drm/radeon_drv.h	2005-02-03 02:55:52.000000000 +0100
+++ linux-2.6.11-rc3-bk6/drivers/char/drm/radeon_drv.h	2005-02-09 15:46:43.257353509 +0100
@@ -1027,25 +1027,27 @@ do {									\
 } while (0)
 
 
-#define OUT_RING_USER_TABLE( tab, sz ) do {			\
+#define OUT_RING_TABLE( tab, sz ) do {					\
 	int _size = (sz);					\
-	int __user *_tab = (tab);					\
+	int *_tab = (int *)(tab);				\
 								\
 	if (write + _size > mask) {				\
-		int i = (mask+1) - write;			\
-		if (DRM_COPY_FROM_USER_UNCHECKED( (int *)(ring+write),	\
-				      _tab, i*4 ))		\
-			return DRM_ERR(EFAULT);		\
+		int _i = (mask+1) - write;			\
+		_size -= _i;					\
+		while (_i > 0 ) {				\
+			*(int *)(ring + write) = *_tab++;	\
+			write++;				\
+			_i--;					\
+		}						\
 		write = 0;					\
-		_size -= i;					\
-		_tab += i;					\
+		_tab += _i;					\
 	}							\
 								\
-	if (_size && DRM_COPY_FROM_USER_UNCHECKED( (int *)(ring+write),	\
-			               _tab, _size*4 ))		\
-		return DRM_ERR(EFAULT);			\
-								\
-	write += _size;						\
+	while (_size > 0) {					\
+		*(ring + write) = *_tab++;			\
+		write++;					\
+		_size--;					\
+	}							\
 	write &= mask;						\
 } while (0)
 
diff -purN linux-2.6.11-rc3-bk5/drivers/char/drm/radeon_state.c linux-2.6.11-rc3-bk6/drivers/char/drm/radeon_state.c
--- linux-2.6.11-rc3-bk5/drivers/char/drm/radeon_state.c	2005-02-03 02:56:34.000000000 +0100
+++ linux-2.6.11-rc3-bk6/drivers/char/drm/radeon_state.c	2005-02-09 15:46:43.266352110 +0100
@@ -93,21 +93,6 @@ static __inline__ int radeon_check_and_f
 	return 0;
 }
 
-static __inline__ int radeon_check_and_fixup_offset_user( drm_radeon_private_t *dev_priv,
-							  drm_file_t *filp_priv,
-							  u32 __user *offset ) {
-	u32 off;
-
-	DRM_GET_USER_UNCHECKED( off, offset );
-
-	if ( radeon_check_and_fixup_offset( dev_priv, filp_priv, &off ) )
-		return DRM_ERR( EINVAL );
-
-	DRM_PUT_USER_UNCHECKED( offset, off );
-
-	return 0;
-}
-
 static __inline__ int radeon_check_and_fixup_packets( drm_radeon_private_t *dev_priv,
 						      drm_file_t *filp_priv,
 						      int id,
@@ -115,18 +100,18 @@ static __inline__ int radeon_check_and_f
 	switch ( id ) {
 
 	case RADEON_EMIT_PP_MISC:
-		if ( radeon_check_and_fixup_offset_user( dev_priv, filp_priv,
-							 &data[( RADEON_RB3D_DEPTHOFFSET
-								 - RADEON_PP_MISC ) / 4] ) ) {
+		if ( radeon_check_and_fixup_offset( dev_priv, filp_priv,
+						    &data[( RADEON_RB3D_DEPTHOFFSET
+							    - RADEON_PP_MISC ) / 4] ) ) {
 			DRM_ERROR( "Invalid depth buffer offset\n" );
 			return DRM_ERR( EINVAL );
 		}
 		break;
 
 	case RADEON_EMIT_PP_CNTL:
-		if ( radeon_check_and_fixup_offset_user( dev_priv, filp_priv,
-							 &data[( RADEON_RB3D_COLOROFFSET
-								 - RADEON_PP_CNTL ) / 4] ) ) {
+		if ( radeon_check_and_fixup_offset( dev_priv, filp_priv,
+						    &data[( RADEON_RB3D_COLOROFFSET
+							    - RADEON_PP_CNTL ) / 4] ) ) {
 			DRM_ERROR( "Invalid colour buffer offset\n" );
 			return DRM_ERR( EINVAL );
 		}
@@ -138,8 +123,8 @@ static __inline__ int radeon_check_and_f
 	case R200_EMIT_PP_TXOFFSET_3:
 	case R200_EMIT_PP_TXOFFSET_4:
 	case R200_EMIT_PP_TXOFFSET_5:
-		if ( radeon_check_and_fixup_offset_user( dev_priv, filp_priv,
-							 &data[0] ) ) {
+		if ( radeon_check_and_fixup_offset( dev_priv, filp_priv,
+						    &data[0] ) ) {
 			DRM_ERROR( "Invalid R200 texture offset\n" );
 			return DRM_ERR( EINVAL );
 		}
@@ -148,9 +133,9 @@ static __inline__ int radeon_check_and_f
 	case RADEON_EMIT_PP_TXFILTER_0:
 	case RADEON_EMIT_PP_TXFILTER_1:
 	case RADEON_EMIT_PP_TXFILTER_2:
-		if ( radeon_check_and_fixup_offset_user( dev_priv, filp_priv,
-							 &data[( RADEON_PP_TXOFFSET_0
-								 - RADEON_PP_TXFILTER_0 ) / 4] ) ) {
+		if ( radeon_check_and_fixup_offset( dev_priv, filp_priv,
+						    &data[( RADEON_PP_TXOFFSET_0
+							    - RADEON_PP_TXFILTER_0 ) / 4] ) ) {
 			DRM_ERROR( "Invalid R100 texture offset\n" );
 			return DRM_ERR( EINVAL );
 		}
@@ -164,9 +149,8 @@ static __inline__ int radeon_check_and_f
 	case R200_EMIT_PP_CUBIC_OFFSETS_5: {
 		int i;
 		for ( i = 0; i < 5; i++ ) {
-			if ( radeon_check_and_fixup_offset_user( dev_priv,
-								 filp_priv,
-								 &data[i] ) ) {
+			if ( radeon_check_and_fixup_offset( dev_priv, filp_priv,
+							    &data[i] ) ) {
 				DRM_ERROR( "Invalid R200 cubic texture offset\n" );
 				return DRM_ERR( EINVAL );
 			}
@@ -250,17 +234,11 @@ static __inline__ int radeon_check_and_f
 						      drm_file_t *filp_priv,
 						      drm_radeon_cmd_buffer_t *cmdbuf,
 						      unsigned int *cmdsz ) {
-	u32 tmp[4];
-	u32 __user *cmd = (u32 __user *)cmdbuf->buf;
-
-	if ( DRM_COPY_FROM_USER_UNCHECKED( tmp, cmd, sizeof( tmp ) ) ) {
-		DRM_ERROR( "Failed to copy data from user space\n" );
-		return DRM_ERR( EFAULT );
-	}
+	u32 *cmd = (u32 *) cmdbuf->buf;
 
-	*cmdsz = 2 + ( ( tmp[0] & RADEON_CP_PACKET_COUNT_MASK ) >> 16 );
+	*cmdsz = 2 + ( ( cmd[0] & RADEON_CP_PACKET_COUNT_MASK ) >> 16 );
 
-	if ( ( tmp[0] & 0xc0000000 ) != RADEON_CP_PACKET3 ) {
+	if ( ( cmd[0] & 0xc0000000 ) != RADEON_CP_PACKET3 ) {
 		DRM_ERROR( "Not a type 3 packet\n" );
 		return DRM_ERR( EINVAL );
 	}
@@ -271,32 +249,27 @@ static __inline__ int radeon_check_and_f
 	}
 
 	/* Check client state and fix it up if necessary */
-	if ( tmp[0] & 0x8000 ) { /* MSB of opcode: next DWORD GUI_CNTL */
+	if ( cmd[0] & 0x8000 ) { /* MSB of opcode: next DWORD GUI_CNTL */
 		u32 offset;
 
-		if ( tmp[1] & ( RADEON_GMC_SRC_PITCH_OFFSET_CNTL
+		if ( cmd[1] & ( RADEON_GMC_SRC_PITCH_OFFSET_CNTL
 			      | RADEON_GMC_DST_PITCH_OFFSET_CNTL ) ) {
-			offset = tmp[2] << 10;
+			offset = cmd[2] << 10;
 			if ( radeon_check_and_fixup_offset( dev_priv, filp_priv, &offset ) ) {
 				DRM_ERROR( "Invalid first packet offset\n" );
 				return DRM_ERR( EINVAL );
 			}
-			tmp[2] = ( tmp[2] & 0xffc00000 ) | offset >> 10;
+			cmd[2] = ( cmd[2] & 0xffc00000 ) | offset >> 10;
 		}
 
-		if ( ( tmp[1] & RADEON_GMC_SRC_PITCH_OFFSET_CNTL ) &&
-		     ( tmp[1] & RADEON_GMC_DST_PITCH_OFFSET_CNTL ) ) {
-			offset = tmp[3] << 10;
+		if ( ( cmd[1] & RADEON_GMC_SRC_PITCH_OFFSET_CNTL ) &&
+		     ( cmd[1] & RADEON_GMC_DST_PITCH_OFFSET_CNTL ) ) {
+			offset = cmd[3] << 10;
 			if ( radeon_check_and_fixup_offset( dev_priv, filp_priv, &offset ) ) {
 				DRM_ERROR( "Invalid second packet offset\n" );
 				return DRM_ERR( EINVAL );
 			}
-			tmp[3] = ( tmp[3] & 0xffc00000 ) | offset >> 10;
-		}
-
-		if ( DRM_COPY_TO_USER_UNCHECKED( cmd, tmp, sizeof( tmp ) ) ) {
-			DRM_ERROR( "Failed to copy data to user space\n" );
-			return DRM_ERR( EFAULT );
+			cmd[3] = ( cmd[3] & 0xffc00000 ) | offset >> 10;
 		}
 	}
 
@@ -2473,7 +2446,7 @@ static int radeon_emit_packets( 
 {
 	int id = (int)header.packet.packet_id;
 	int sz, reg;
-	int __user *data = (int __user *)cmdbuf->buf;
+	int *data = (int *)cmdbuf->buf;
 	RING_LOCALS;
    
 	if (id >= RADEON_MAX_STATE_PACKETS)
@@ -2494,7 +2467,7 @@ static int radeon_emit_packets( 
 
 	BEGIN_RING(sz+1);
 	OUT_RING( CP_PACKET0( reg, (sz-1) ) );
-	OUT_RING_USER_TABLE( data, sz );
+	OUT_RING_TABLE( data, sz );
 	ADVANCE_RING();
 
 	cmdbuf->buf += sz * sizeof(int);
@@ -2508,7 +2481,6 @@ static __inline__ int radeon_emit_scalar
 	drm_radeon_cmd_buffer_t *cmdbuf )
 {
 	int sz = header.scalars.count;
-	int __user *data = (int __user *)cmdbuf->buf;
 	int start = header.scalars.offset;
 	int stride = header.scalars.stride;
 	RING_LOCALS;
@@ -2517,7 +2489,7 @@ static __inline__ int radeon_emit_scalar
 	OUT_RING( CP_PACKET0( RADEON_SE_TCL_SCALAR_INDX_REG, 0 ) );
 	OUT_RING( start | (stride << RADEON_SCAL_INDX_DWORD_STRIDE_SHIFT));
 	OUT_RING( CP_PACKET0_TABLE( RADEON_SE_TCL_SCALAR_DATA_REG, sz-1 ) );
-	OUT_RING_USER_TABLE( data, sz );
+	OUT_RING_TABLE( cmdbuf->buf, sz );
 	ADVANCE_RING();
 	cmdbuf->buf += sz * sizeof(int);
 	cmdbuf->bufsz -= sz * sizeof(int);
@@ -2532,7 +2504,6 @@ static __inline__ int radeon_emit_scalar
 	drm_radeon_cmd_buffer_t *cmdbuf )
 {
 	int sz = header.scalars.count;
-	int __user *data = (int __user *)cmdbuf->buf;
 	int start = ((unsigned int)header.scalars.offset) + 0x100;
 	int stride = header.scalars.stride;
 	RING_LOCALS;
@@ -2541,7 +2512,7 @@ static __inline__ int radeon_emit_scalar
 	OUT_RING( CP_PACKET0( RADEON_SE_TCL_SCALAR_INDX_REG, 0 ) );
 	OUT_RING( start | (stride << RADEON_SCAL_INDX_DWORD_STRIDE_SHIFT));
 	OUT_RING( CP_PACKET0_TABLE( RADEON_SE_TCL_SCALAR_DATA_REG, sz-1 ) );
-	OUT_RING_USER_TABLE( data, sz );
+	OUT_RING_TABLE( cmdbuf->buf, sz );
 	ADVANCE_RING();
 	cmdbuf->buf += sz * sizeof(int);
 	cmdbuf->bufsz -= sz * sizeof(int);
@@ -2554,7 +2525,6 @@ static __inline__ int radeon_emit_vector
 	drm_radeon_cmd_buffer_t *cmdbuf )
 {
 	int sz = header.vectors.count;
-	int __user *data = (int __user *)cmdbuf->buf;
 	int start = header.vectors.offset;
 	int stride = header.vectors.stride;
 	RING_LOCALS;
@@ -2563,7 +2533,7 @@ static __inline__ int radeon_emit_vector
 	OUT_RING( CP_PACKET0( RADEON_SE_TCL_VECTOR_INDX_REG, 0 ) );
 	OUT_RING( start | (stride << RADEON_VEC_INDX_OCTWORD_STRIDE_SHIFT));
 	OUT_RING( CP_PACKET0_TABLE( RADEON_SE_TCL_VECTOR_DATA_REG, (sz-1) ) );
-	OUT_RING_USER_TABLE( data, sz );
+	OUT_RING_TABLE( cmdbuf->buf, sz );
 	ADVANCE_RING();
 
 	cmdbuf->buf += sz * sizeof(int);
@@ -2578,7 +2548,6 @@ static int radeon_emit_packet3( drm_devi
 {
 	drm_radeon_private_t *dev_priv = dev->dev_private;
 	unsigned int cmdsz;
-	int __user *cmd = (int __user *)cmdbuf->buf;
 	int ret;
 	RING_LOCALS;
 
@@ -2591,7 +2560,7 @@ static int radeon_emit_packet3( drm_devi
 	}
 
 	BEGIN_RING( cmdsz );
-	OUT_RING_USER_TABLE( cmd, cmdsz );
+	OUT_RING_TABLE( cmdbuf->buf, cmdsz );
 	ADVANCE_RING();
 
 	cmdbuf->buf += cmdsz * 4;
@@ -2608,7 +2577,6 @@ static int radeon_emit_packet3_cliprect(
 	drm_radeon_private_t *dev_priv = dev->dev_private;
 	drm_clip_rect_t box;
 	unsigned int cmdsz;
-	int __user *cmd = (int __user *)cmdbuf->buf;
 	int ret;
 	drm_clip_rect_t __user *boxes = cmdbuf->boxes;
 	int i = 0;
@@ -2627,7 +2595,7 @@ static int radeon_emit_packet3_cliprect(
 
 	do {
 		if ( i < cmdbuf->nbox ) {
-			if (DRM_COPY_FROM_USER_UNCHECKED( &box, &boxes[i], sizeof(box) ))
+			if (DRM_COPY_FROM_USER( &box, &boxes[i], sizeof(box) ))
 				return DRM_ERR(EFAULT);
 			/* FIXME The second and subsequent times round
 			 * this loop, send a WAIT_UNTIL_3D_IDLE before
@@ -2650,7 +2618,7 @@ static int radeon_emit_packet3_cliprect(
 		}
 		
 		BEGIN_RING( cmdsz );
-		OUT_RING_USER_TABLE( cmd, cmdsz );
+		OUT_RING_TABLE( cmdbuf->buf, cmdsz );
 		ADVANCE_RING();
 
 	} while ( ++i < cmdbuf->nbox );
@@ -2703,7 +2671,8 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 	int idx;
 	drm_radeon_cmd_buffer_t cmdbuf;
 	drm_radeon_cmd_header_t header;
-	int orig_nbox;
+	int orig_nbox, orig_bufsz;
+	char *kbuf=NULL;
 
 	LOCK_TEST_WITH_RETURN( dev, filp );
 
@@ -2720,24 +2689,29 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 	RING_SPACE_TEST_WITH_RETURN( dev_priv );
 	VB_AGE_TEST_WITH_RETURN( dev_priv );
 
+	if (cmdbuf.bufsz > 64*1024 || cmdbuf.bufsz<0) {
+		return DRM_ERR(EINVAL);
+	}
 
-	if (DRM_VERIFYAREA_READ( cmdbuf.buf, cmdbuf.bufsz ))
-		return DRM_ERR(EFAULT);
-
-	if (cmdbuf.nbox &&
-	    DRM_VERIFYAREA_READ(cmdbuf.boxes, 
-			 cmdbuf.nbox * sizeof(drm_clip_rect_t)))
-		return DRM_ERR(EFAULT);
+	/* Allocate an in-kernel area and copy in the cmdbuf.  Do this to avoid
+	 * races between checking values and using those values in other code,
+	 * and simply to avoid a lot of function calls to copy in data.
+	 */
+	orig_bufsz = cmdbuf.bufsz;
+	if (orig_bufsz != 0) {
+		kbuf = drm_alloc(cmdbuf.bufsz, DRM_MEM_DRIVER);
+		if (kbuf == NULL)
+			return DRM_ERR(ENOMEM);
+		if (DRM_COPY_FROM_USER(kbuf, cmdbuf.buf, cmdbuf.bufsz))
+			return DRM_ERR(EFAULT);
+		cmdbuf.buf = kbuf;
+	}
 
 	orig_nbox = cmdbuf.nbox;
 
 	while ( cmdbuf.bufsz >= sizeof(header) ) {
-		
-		if (DRM_GET_USER_UNCHECKED( header.i, (int __user *)cmdbuf.buf )) {
-			DRM_ERROR("__get_user %p\n", cmdbuf.buf);
-			return DRM_ERR(EFAULT);
-		}
 
+		header.i = *(int *)cmdbuf.buf;
 		cmdbuf.buf += sizeof(header);
 		cmdbuf.bufsz -= sizeof(header);
 
@@ -2746,7 +2720,7 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 			DRM_DEBUG("RADEON_CMD_PACKET\n");
 			if (radeon_emit_packets( dev_priv, filp_priv, header, &cmdbuf )) {
 				DRM_ERROR("radeon_emit_packets failed\n");
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 			break;
 
@@ -2754,7 +2728,7 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 			DRM_DEBUG("RADEON_CMD_SCALARS\n");
 			if (radeon_emit_scalars( dev_priv, header, &cmdbuf )) {
 				DRM_ERROR("radeon_emit_scalars failed\n");
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 			break;
 
@@ -2762,7 +2736,7 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 			DRM_DEBUG("RADEON_CMD_VECTORS\n");
 			if (radeon_emit_vectors( dev_priv, header, &cmdbuf )) {
 				DRM_ERROR("radeon_emit_vectors failed\n");
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 			break;
 
@@ -2772,14 +2746,14 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 			if ( idx < 0 || idx >= dma->buf_count ) {
 				DRM_ERROR( "buffer index %d (of %d max)\n",
 					   idx, dma->buf_count - 1 );
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 
 			buf = dma->buflist[idx];
 			if ( buf->filp != filp || buf->pending ) {
 				DRM_ERROR( "bad buffer %p %p %d\n",
 					   buf->filp, filp, buf->pending);
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 
 			radeon_cp_discard_buffer( dev, buf );
@@ -2789,7 +2763,7 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 			DRM_DEBUG("RADEON_CMD_PACKET3\n");
 			if (radeon_emit_packet3( dev, filp_priv, &cmdbuf )) {
 				DRM_ERROR("radeon_emit_packet3 failed\n");
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 			break;
 
@@ -2797,7 +2771,7 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 			DRM_DEBUG("RADEON_CMD_PACKET3_CLIP\n");
 			if (radeon_emit_packet3_cliprect( dev, filp_priv, &cmdbuf, orig_nbox )) {
 				DRM_ERROR("radeon_emit_packet3_clip failed\n");
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 			break;
 
@@ -2805,7 +2779,7 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 			DRM_DEBUG("RADEON_CMD_SCALARS2\n");
 			if (radeon_emit_scalars2( dev_priv, header, &cmdbuf )) {
 				DRM_ERROR("radeon_emit_scalars2 failed\n");
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 			break;
 
@@ -2813,21 +2787,28 @@ int radeon_cp_cmdbuf( DRM_IOCTL_ARGS )
 			DRM_DEBUG("RADEON_CMD_WAIT\n");
 			if (radeon_emit_wait( dev, header.wait.flags )) {
 				DRM_ERROR("radeon_emit_wait failed\n");
-				return DRM_ERR(EINVAL);
+				goto err;
 			}
 			break;
 		default:
 			DRM_ERROR("bad cmd_type %d at %p\n", 
 				  header.header.cmd_type,
 				  cmdbuf.buf - sizeof(header));
-			return DRM_ERR(EINVAL);
+			goto err;
 		}
 	}
 
+	if (orig_bufsz != 0)
+		drm_free(kbuf, orig_bufsz, DRM_MEM_DRIVER);
 
 	DRM_DEBUG("DONE\n");
 	COMMIT_RING();
 	return 0;
+
+err:
+	if (orig_bufsz != 0)
+		drm_free(kbuf, orig_bufsz, DRM_MEM_DRIVER);
+	return DRM_ERR(EINVAL);
 }
 
 
diff -purN linux-2.6.11-rc3-bk5/drivers/md/md.c linux-2.6.11-rc3-bk6/drivers/md/md.c
--- linux-2.6.11-rc3-bk5/drivers/md/md.c	2005-02-09 15:46:36.178387542 +0100
+++ linux-2.6.11-rc3-bk6/drivers/md/md.c	2005-02-09 15:46:43.427327093 +0100
@@ -935,8 +935,8 @@ static void super_1_sync(mddev_t *mddev,
 
 	max_dev = 0;
 	ITERATE_RDEV(mddev,rdev2,tmp)
-		if (rdev2->desc_nr > max_dev)
-			max_dev = rdev2->desc_nr;
+		if (rdev2->desc_nr+1 > max_dev)
+			max_dev = rdev2->desc_nr+1;
 	
 	sb->max_dev = cpu_to_le32(max_dev);
 	for (i=0; i<max_dev;i++)
@@ -953,6 +953,7 @@ static void super_1_sync(mddev_t *mddev,
 	}
 
 	sb->recovery_offset = cpu_to_le64(0); /* not supported yet */
+	sb->sb_csum = calc_sb_1_csum(sb);
 }
 
 
@@ -1472,10 +1473,13 @@ static struct kobject *md_probe(dev_t de
 	}
 	disk->major = MAJOR(dev);
 	disk->first_minor = unit << shift;
-	if (partitioned)
+	if (partitioned) {
 		sprintf(disk->disk_name, "md_d%d", unit);
-	else
+		sprintf(disk->devfs_name, "md/d%d", unit);
+	} else {
 		sprintf(disk->disk_name, "md%d", unit);
+		sprintf(disk->devfs_name, "md/%d", unit);
+	}
 	disk->fops = &md_fops;
 	disk->private_data = mddev;
 	disk->queue = mddev->queue;
@@ -2440,6 +2444,9 @@ static int set_disk_faulty(mddev_t *mdde
 {
 	mdk_rdev_t *rdev;
 
+	if (mddev->pers == NULL)
+		return -ENODEV;
+
 	rdev = find_rdev(mddev, dev);
 	if (!rdev)
 		return -ENODEV;
@@ -3362,10 +3369,12 @@ static void md_do_sync(mddev_t *mddev)
 	init_waitqueue_head(&mddev->recovery_wait);
 	last_check = 0;
 
-	if (j)
+	if (j>2) {
 		printk(KERN_INFO 
 			"md: resuming recovery of %s from checkpoint.\n",
 			mdname(mddev));
+		mddev->curr_resync = j;
+	}
 
 	while (j < max_sectors) {
 		int sectors;
@@ -3447,7 +3456,7 @@ static void md_do_sync(mddev_t *mddev)
 
 	if (!test_bit(MD_RECOVERY_ERR, &mddev->recovery) &&
 	    mddev->curr_resync > 2 &&
-	    mddev->curr_resync > mddev->recovery_cp) {
+	    mddev->curr_resync >= mddev->recovery_cp) {
 		if (test_bit(MD_RECOVERY_INTR, &mddev->recovery)) {
 			printk(KERN_INFO 
 				"md: checkpointing recovery of %s.\n",
@@ -3655,7 +3664,7 @@ int __init md_init(void)
 	for (minor=0; minor < MAX_MD_DEVS; ++minor)
 		devfs_mk_bdev(MKDEV(mdp_major, minor<<MdpMinorShift),
 			      S_IFBLK|S_IRUSR|S_IWUSR,
-			      "md/d%d", minor);
+			      "md/mdp%d", minor);
 
 
 	register_reboot_notifier(&md_notifier);
diff -purN linux-2.6.11-rc3-bk5/drivers/md/raid5.c linux-2.6.11-rc3-bk6/drivers/md/raid5.c
--- linux-2.6.11-rc3-bk5/drivers/md/raid5.c	2005-02-03 02:55:15.000000000 +0100
+++ linux-2.6.11-rc3-bk6/drivers/md/raid5.c	2005-02-09 15:46:43.433326161 +0100
@@ -49,7 +49,7 @@
  * This macro is used to determine the 'next' bio in the list, given the sector
  * of the current stripe+device
  */
-#define r5_next_bio(bio, sect) ( ( bio->bi_sector + (bio->bi_size>>9) < sect + STRIPE_SECTORS) ? bio->bi_next : NULL)
+#define r5_next_bio(bio, sect) ( ( (bio)->bi_sector + ((bio)->bi_size>>9) < sect + STRIPE_SECTORS) ? (bio)->bi_next : NULL)
 /*
  * The following can be used to debug the driver
  */
@@ -232,6 +232,7 @@ static struct stripe_head *__find_stripe
 }
 
 static void unplug_slaves(mddev_t *mddev);
+static void raid5_unplug_device(request_queue_t *q);
 
 static struct stripe_head *get_active_stripe(raid5_conf_t *conf, sector_t sector,
 					     int pd_idx, int noblock) 
@@ -612,11 +613,10 @@ static sector_t compute_blocknr(struct s
 
 
 /*
- * Copy data between a page in the stripe cache, and one or more bion
- * The page could align with the middle of the bio, or there could be 
- * several bion, each with several bio_vecs, which cover part of the page
- * Multiple bion are linked together on bi_next.  There may be extras
- * at the end of this list.  We ignore them.
+ * Copy data between a page in the stripe cache, and a bio.
+ * There are no alignment or size guarantees between the page or the
+ * bio except that there is some overlap.
+ * All iovecs in the bio must be considered.
  */
 static void copy_data(int frombio, struct bio *bio,
 		     struct page *page,
@@ -625,41 +625,38 @@ static void copy_data(int frombio, struc
 	char *pa = page_address(page);
 	struct bio_vec *bvl;
 	int i;
+	int page_offset;
 
-	for (;bio && bio->bi_sector < sector+STRIPE_SECTORS;
-	      bio = r5_next_bio(bio, sector) ) {
-		int page_offset;
-		if (bio->bi_sector >= sector)
-			page_offset = (signed)(bio->bi_sector - sector) * 512;
-		else 
-			page_offset = (signed)(sector - bio->bi_sector) * -512;
-		bio_for_each_segment(bvl, bio, i) {
-			int len = bio_iovec_idx(bio,i)->bv_len;
-			int clen;
-			int b_offset = 0;			
-
-			if (page_offset < 0) {
-				b_offset = -page_offset;
-				page_offset += b_offset;
-				len -= b_offset;
-			}
-
-			if (len > 0 && page_offset + len > STRIPE_SIZE)
-				clen = STRIPE_SIZE - page_offset;	
-			else clen = len;
+	if (bio->bi_sector >= sector)
+		page_offset = (signed)(bio->bi_sector - sector) * 512;
+	else
+		page_offset = (signed)(sector - bio->bi_sector) * -512;
+	bio_for_each_segment(bvl, bio, i) {
+		int len = bio_iovec_idx(bio,i)->bv_len;
+		int clen;
+		int b_offset = 0;
+
+		if (page_offset < 0) {
+			b_offset = -page_offset;
+			page_offset += b_offset;
+			len -= b_offset;
+		}
+
+		if (len > 0 && page_offset + len > STRIPE_SIZE)
+			clen = STRIPE_SIZE - page_offset;
+		else clen = len;
 			
-			if (clen > 0) {
-				char *ba = __bio_kmap_atomic(bio, i, KM_USER0);
-				if (frombio)
-					memcpy(pa+page_offset, ba+b_offset, clen);
-				else
-					memcpy(ba+b_offset, pa+page_offset, clen);
-				__bio_kunmap_atomic(ba, KM_USER0);
-			}	
-			if (clen < len) /* hit end of page */
-				break;
-			page_offset +=  len;
+		if (clen > 0) {
+			char *ba = __bio_kmap_atomic(bio, i, KM_USER0);
+			if (frombio)
+				memcpy(pa+page_offset, ba+b_offset, clen);
+			else
+				memcpy(ba+b_offset, pa+page_offset, clen);
+			__bio_kunmap_atomic(ba, KM_USER0);
 		}
+		if (clen < len) /* hit end of page */
+			break;
+		page_offset +=  len;
 	}
 }
 
@@ -725,6 +722,10 @@ static void compute_parity(struct stripe
 				ptr[count++] = page_address(sh->dev[i].page);
 				chosen = sh->dev[i].towrite;
 				sh->dev[i].towrite = NULL;
+
+				if (test_and_clear_bit(R5_Overlap, &sh->dev[i].flags))
+					wake_up(&conf->wait_for_overlap);
+
 				if (sh->dev[i].written) BUG();
 				sh->dev[i].written = chosen;
 				check_xor();
@@ -737,6 +738,10 @@ static void compute_parity(struct stripe
 			if (i!=pd_idx && sh->dev[i].towrite) {
 				chosen = sh->dev[i].towrite;
 				sh->dev[i].towrite = NULL;
+
+				if (test_and_clear_bit(R5_Overlap, &sh->dev[i].flags))
+					wake_up(&conf->wait_for_overlap);
+
 				if (sh->dev[i].written) BUG();
 				sh->dev[i].written = chosen;
 			}
@@ -793,7 +798,7 @@ static void compute_parity(struct stripe
  * toread/towrite point to the first in a chain. 
  * The bi_next chain must be in order.
  */
-static void add_stripe_bio (struct stripe_head *sh, struct bio *bi, int dd_idx, int forwrite)
+static int add_stripe_bio(struct stripe_head *sh, struct bio *bi, int dd_idx, int forwrite)
 {
 	struct bio **bip;
 	raid5_conf_t *conf = sh->raid_conf;
@@ -810,10 +815,13 @@ static void add_stripe_bio (struct strip
 	else
 		bip = &sh->dev[dd_idx].toread;
 	while (*bip && (*bip)->bi_sector < bi->bi_sector) {
-		BUG_ON((*bip)->bi_sector + ((*bip)->bi_size >> 9) > bi->bi_sector);
+		if ((*bip)->bi_sector + ((*bip)->bi_size >> 9) > bi->bi_sector)
+			goto overlap;
 		bip = & (*bip)->bi_next;
 	}
-/* FIXME do I need to worry about overlapping bion */
+	if (*bip && (*bip)->bi_sector < bi->bi_sector + ((bi->bi_size)>>9))
+		goto overlap;
+
 	if (*bip && bi->bi_next && (*bip) != bi->bi_next)
 		BUG();
 	if (*bip)
@@ -828,7 +836,7 @@ static void add_stripe_bio (struct strip
 		(unsigned long long)sh->sector, dd_idx);
 
 	if (forwrite) {
-		/* check if page is coverred */
+		/* check if page is covered */
 		sector_t sector = sh->dev[dd_idx].sector;
 		for (bi=sh->dev[dd_idx].towrite;
 		     sector < sh->dev[dd_idx].sector + STRIPE_SECTORS &&
@@ -840,6 +848,13 @@ static void add_stripe_bio (struct strip
 		if (sector >= sh->dev[dd_idx].sector + STRIPE_SECTORS)
 			set_bit(R5_OVERWRITE, &sh->dev[dd_idx].flags);
 	}
+	return 1;
+
+ overlap:
+	set_bit(R5_Overlap, &sh->dev[dd_idx].flags);
+	spin_unlock_irq(&conf->device_lock);
+	spin_unlock(&sh->lock);
+	return 0;
 }
 
 
@@ -900,6 +915,8 @@ static void handle_stripe(struct stripe_
 			spin_lock_irq(&conf->device_lock);
 			rbi = dev->toread;
 			dev->toread = NULL;
+			if (test_and_clear_bit(R5_Overlap, &dev->flags))
+				wake_up(&conf->wait_for_overlap);
 			spin_unlock_irq(&conf->device_lock);
 			while (rbi && rbi->bi_sector < dev->sector + STRIPE_SECTORS) {
 				copy_data(0, rbi, dev->page, dev->sector);
@@ -947,6 +964,9 @@ static void handle_stripe(struct stripe_
 			sh->dev[i].towrite = NULL;
 			if (bi) to_write--;
 
+			if (test_and_clear_bit(R5_Overlap, &sh->dev[i].flags))
+				wake_up(&conf->wait_for_overlap);
+
 			while (bi && bi->bi_sector < sh->dev[i].sector + STRIPE_SECTORS){
 				struct bio *nextbi = r5_next_bio(bi, sh->dev[i].sector);
 				clear_bit(BIO_UPTODATE, &bi->bi_flags);
@@ -975,6 +995,8 @@ static void handle_stripe(struct stripe_
 			if (!test_bit(R5_Insync, &sh->dev[i].flags)) {
 				bi = sh->dev[i].toread;
 				sh->dev[i].toread = NULL;
+				if (test_and_clear_bit(R5_Overlap, &sh->dev[i].flags))
+					wake_up(&conf->wait_for_overlap);
 				if (bi) to_read--;
 				while (bi && bi->bi_sector < sh->dev[i].sector + STRIPE_SECTORS){
 					struct bio *nextbi = r5_next_bio(bi, sh->dev[i].sector);
@@ -1402,6 +1424,7 @@ static int make_request (request_queue_t
 	if ( bio_data_dir(bi) == WRITE )
 		md_write_start(mddev);
 	for (;logical_sector < last_sector; logical_sector += STRIPE_SECTORS) {
+		DEFINE_WAIT(w);
 		
 		new_sector = raid5_compute_sector(logical_sector,
 						  raid_disks, data_disks, &dd_idx, &pd_idx, conf);
@@ -1410,17 +1433,28 @@ static int make_request (request_queue_t
 			(unsigned long long)new_sector, 
 			(unsigned long long)logical_sector);
 
+	retry:
+		prepare_to_wait(&conf->wait_for_overlap, &w, TASK_UNINTERRUPTIBLE);
 		sh = get_active_stripe(conf, new_sector, pd_idx, (bi->bi_rw&RWA_MASK));
 		if (sh) {
-
-			add_stripe_bio(sh, bi, dd_idx, (bi->bi_rw&RW_MASK));
-
+			if (!add_stripe_bio(sh, bi, dd_idx, (bi->bi_rw&RW_MASK))) {
+				/* Add failed due to overlap.  Flush everything
+				 * and wait a while
+				 */
+				raid5_unplug_device(mddev->queue);
+				release_stripe(sh);
+				schedule();
+				goto retry;
+			}
+			finish_wait(&conf->wait_for_overlap, &w);
 			raid5_plug_device(conf);
 			handle_stripe(sh);
 			release_stripe(sh);
+
 		} else {
 			/* cannot get stripe for read-ahead, just give-up */
 			clear_bit(BIO_UPTODATE, &bi->bi_flags);
+			finish_wait(&conf->wait_for_overlap, &w);
 			break;
 		}
 			
@@ -1568,6 +1602,7 @@ static int run (mddev_t *mddev)
 
 	spin_lock_init(&conf->device_lock);
 	init_waitqueue_head(&conf->wait_for_stripe);
+	init_waitqueue_head(&conf->wait_for_overlap);
 	INIT_LIST_HEAD(&conf->handle_list);
 	INIT_LIST_HEAD(&conf->delayed_list);
 	INIT_LIST_HEAD(&conf->inactive_list);
diff -purN linux-2.6.11-rc3-bk5/drivers/md/raid6main.c linux-2.6.11-rc3-bk6/drivers/md/raid6main.c
--- linux-2.6.11-rc3-bk5/drivers/md/raid6main.c	2005-02-03 02:54:52.000000000 +0100
+++ linux-2.6.11-rc3-bk6/drivers/md/raid6main.c	2005-02-09 15:46:43.439325228 +0100
@@ -54,7 +54,7 @@
  * This macro is used to determine the 'next' bio in the list, given the sector
  * of the current stripe+device
  */
-#define r5_next_bio(bio, sect) ( ( bio->bi_sector + (bio->bi_size>>9) < sect + STRIPE_SECTORS) ? bio->bi_next : NULL)
+#define r5_next_bio(bio, sect) ( ( (bio)->bi_sector + ((bio)->bi_size>>9) < sect + STRIPE_SECTORS) ? (bio)->bi_next : NULL)
 /*
  * The following can be used to debug the driver
  */
@@ -670,41 +670,38 @@ static void copy_data(int frombio, struc
 	char *pa = page_address(page);
 	struct bio_vec *bvl;
 	int i;
+	int page_offset;
 
-	for (;bio && bio->bi_sector < sector+STRIPE_SECTORS;
-	      bio = r5_next_bio(bio, sector) ) {
-		int page_offset;
-		if (bio->bi_sector >= sector)
-			page_offset = (signed)(bio->bi_sector - sector) * 512;
-		else
-			page_offset = (signed)(sector - bio->bi_sector) * -512;
-		bio_for_each_segment(bvl, bio, i) {
-			int len = bio_iovec_idx(bio,i)->bv_len;
-			int clen;
-			int b_offset = 0;
-
-			if (page_offset < 0) {
-				b_offset = -page_offset;
-				page_offset += b_offset;
-				len -= b_offset;
-			}
-
-			if (len > 0 && page_offset + len > STRIPE_SIZE)
-				clen = STRIPE_SIZE - page_offset;
-			else clen = len;
-
-			if (clen > 0) {
-				char *ba = __bio_kmap_atomic(bio, i, KM_USER0);
-				if (frombio)
-					memcpy(pa+page_offset, ba+b_offset, clen);
-				else
-					memcpy(ba+b_offset, pa+page_offset, clen);
-				__bio_kunmap_atomic(ba, KM_USER0);
-			}
-			if (clen < len) /* hit end of page */
-				break;
-			page_offset +=  len;
+	if (bio->bi_sector >= sector)
+		page_offset = (signed)(bio->bi_sector - sector) * 512;
+	else
+		page_offset = (signed)(sector - bio->bi_sector) * -512;
+	bio_for_each_segment(bvl, bio, i) {
+		int len = bio_iovec_idx(bio,i)->bv_len;
+		int clen;
+		int b_offset = 0;
+
+		if (page_offset < 0) {
+			b_offset = -page_offset;
+			page_offset += b_offset;
+			len -= b_offset;
+		}
+
+		if (len > 0 && page_offset + len > STRIPE_SIZE)
+			clen = STRIPE_SIZE - page_offset;
+		else clen = len;
+
+		if (clen > 0) {
+			char *ba = __bio_kmap_atomic(bio, i, KM_USER0);
+			if (frombio)
+				memcpy(pa+page_offset, ba+b_offset, clen);
+			else
+				memcpy(ba+b_offset, pa+page_offset, clen);
+			__bio_kunmap_atomic(ba, KM_USER0);
 		}
+		if (clen < len) /* hit end of page */
+			break;
+		page_offset +=  len;
 	}
 }
 
@@ -738,6 +735,10 @@ static void compute_parity(struct stripe
 			if ( i != pd_idx && i != qd_idx && sh->dev[i].towrite ) {
 				chosen = sh->dev[i].towrite;
 				sh->dev[i].towrite = NULL;
+
+				if (test_and_clear_bit(R5_Overlap, &sh->dev[i].flags))
+					wake_up(&conf->wait_for_overlap);
+
 				if (sh->dev[i].written) BUG();
 				sh->dev[i].written = chosen;
 			}
@@ -900,7 +901,7 @@ static void compute_block_2(struct strip
  * toread/towrite point to the first in a chain.
  * The bi_next chain must be in order.
  */
-static void add_stripe_bio (struct stripe_head *sh, struct bio *bi, int dd_idx, int forwrite)
+static int add_stripe_bio(struct stripe_head *sh, struct bio *bi, int dd_idx, int forwrite)
 {
 	struct bio **bip;
 	raid6_conf_t *conf = sh->raid_conf;
@@ -917,10 +918,13 @@ static void add_stripe_bio (struct strip
 	else
 		bip = &sh->dev[dd_idx].toread;
 	while (*bip && (*bip)->bi_sector < bi->bi_sector) {
-		BUG_ON((*bip)->bi_sector + ((*bip)->bi_size >> 9) > bi->bi_sector);
-		bip = & (*bip)->bi_next;
+		if ((*bip)->bi_sector + ((*bip)->bi_size >> 9) > bi->bi_sector)
+			goto overlap;
+		bip = &(*bip)->bi_next;
 	}
-/* FIXME do I need to worry about overlapping bion */
+	if (*bip && (*bip)->bi_sector < bi->bi_sector + ((bi->bi_size)>>9))
+		goto overlap;
+
 	if (*bip && bi->bi_next && (*bip) != bi->bi_next)
 		BUG();
 	if (*bip)
@@ -935,7 +939,7 @@ static void add_stripe_bio (struct strip
 		(unsigned long long)sh->sector, dd_idx);
 
 	if (forwrite) {
-		/* check if page is coverred */
+		/* check if page is covered */
 		sector_t sector = sh->dev[dd_idx].sector;
 		for (bi=sh->dev[dd_idx].towrite;
 		     sector < sh->dev[dd_idx].sector + STRIPE_SECTORS &&
@@ -947,6 +951,13 @@ static void add_stripe_bio (struct strip
 		if (sector >= sh->dev[dd_idx].sector + STRIPE_SECTORS)
 			set_bit(R5_OVERWRITE, &sh->dev[dd_idx].flags);
 	}
+	return 1;
+
+ overlap:
+	set_bit(R5_Overlap, &sh->dev[dd_idx].flags);
+	spin_unlock_irq(&conf->device_lock);
+	spin_unlock(&sh->lock);
+	return 0;
 }
 
 
@@ -1010,6 +1021,8 @@ static void handle_stripe(struct stripe_
 			spin_lock_irq(&conf->device_lock);
 			rbi = dev->toread;
 			dev->toread = NULL;
+			if (test_and_clear_bit(R5_Overlap, &dev->flags))
+				wake_up(&conf->wait_for_overlap);
 			spin_unlock_irq(&conf->device_lock);
 			while (rbi && rbi->bi_sector < dev->sector + STRIPE_SECTORS) {
 				copy_data(0, rbi, dev->page, dev->sector);
@@ -1059,6 +1072,9 @@ static void handle_stripe(struct stripe_
 			sh->dev[i].towrite = NULL;
 			if (bi) to_write--;
 
+			if (test_and_clear_bit(R5_Overlap, &sh->dev[i].flags))
+				wake_up(&conf->wait_for_overlap);
+
 			while (bi && bi->bi_sector < sh->dev[i].sector + STRIPE_SECTORS){
 				struct bio *nextbi = r5_next_bio(bi, sh->dev[i].sector);
 				clear_bit(BIO_UPTODATE, &bi->bi_flags);
@@ -1087,6 +1103,8 @@ static void handle_stripe(struct stripe_
 			if (!test_bit(R5_Insync, &sh->dev[i].flags)) {
 				bi = sh->dev[i].toread;
 				sh->dev[i].toread = NULL;
+				if (test_and_clear_bit(R5_Overlap, &sh->dev[i].flags))
+					wake_up(&conf->wait_for_overlap);
 				if (bi) to_read--;
 				while (bi && bi->bi_sector < sh->dev[i].sector + STRIPE_SECTORS){
 					struct bio *nextbi = r5_next_bio(bi, sh->dev[i].sector);
@@ -1566,6 +1584,7 @@ static int make_request (request_queue_t
 	if ( bio_data_dir(bi) == WRITE )
 		md_write_start(mddev);
 	for (;logical_sector < last_sector; logical_sector += STRIPE_SECTORS) {
+		DEFINE_WAIT(w);
 
 		new_sector = raid6_compute_sector(logical_sector,
 						  raid_disks, data_disks, &dd_idx, &pd_idx, conf);
@@ -1574,17 +1593,27 @@ static int make_request (request_queue_t
 		       (unsigned long long)new_sector,
 		       (unsigned long long)logical_sector);
 
+	retry:
+		prepare_to_wait(&conf->wait_for_overlap, &w, TASK_UNINTERRUPTIBLE);
 		sh = get_active_stripe(conf, new_sector, pd_idx, (bi->bi_rw&RWA_MASK));
 		if (sh) {
-
-			add_stripe_bio(sh, bi, dd_idx, (bi->bi_rw&RW_MASK));
-
+			if (!add_stripe_bio(sh, bi, dd_idx, (bi->bi_rw&RW_MASK))) {
+				/* Add failed due to overlap.  Flush everything
+				 * and wait a while
+				 */
+				raid6_unplug_device(mddev->queue);
+				release_stripe(sh);
+				schedule();
+				goto retry;
+			}
+			finish_wait(&conf->wait_for_overlap, &w);
 			raid6_plug_device(conf);
 			handle_stripe(sh);
 			release_stripe(sh);
 		} else {
 			/* cannot get stripe for read-ahead, just give-up */
 			clear_bit(BIO_UPTODATE, &bi->bi_flags);
+			finish_wait(&conf->wait_for_overlap, &w);
 			break;
 		}
 
@@ -1732,6 +1761,7 @@ static int run (mddev_t *mddev)
 
 	spin_lock_init(&conf->device_lock);
 	init_waitqueue_head(&conf->wait_for_stripe);
+	init_waitqueue_head(&conf->wait_for_overlap);
 	INIT_LIST_HEAD(&conf->handle_list);
 	INIT_LIST_HEAD(&conf->delayed_list);
 	INIT_LIST_HEAD(&conf->inactive_list);
diff -purN linux-2.6.11-rc3-bk5/fs/nfsd/nfsproc.c linux-2.6.11-rc3-bk6/fs/nfsd/nfsproc.c
--- linux-2.6.11-rc3-bk5/fs/nfsd/nfsproc.c	2005-02-03 02:55:35.000000000 +0100
+++ linux-2.6.11-rc3-bk6/fs/nfsd/nfsproc.c	2005-02-09 15:46:43.613298191 +0100
@@ -540,7 +540,7 @@ static struct svc_procedure		nfsd_proced
   PROC(symlink,	 symlinkargs,	void,		none,		RC_REPLSTAT, ST),
   PROC(mkdir,	 createargs,	diropres,	fhandle,	RC_REPLBUFF, ST+FH+AT),
   PROC(rmdir,	 diropargs,	void,		none,		RC_REPLSTAT, ST),
-  PROC(readdir,	 readdirargs,	readdirres,	none,		RC_REPLBUFF, 0),
+  PROC(readdir,	 readdirargs,	readdirres,	none,		RC_NOCACHE, 0),
   PROC(statfs,	 fhandle,	statfsres,	none,		RC_NOCACHE, ST+5),
 };
 
diff -purN linux-2.6.11-rc3-bk5/fs/nfsd/vfs.c linux-2.6.11-rc3-bk6/fs/nfsd/vfs.c
--- linux-2.6.11-rc3-bk5/fs/nfsd/vfs.c	2005-02-03 02:55:37.000000000 +0100
+++ linux-2.6.11-rc3-bk6/fs/nfsd/vfs.c	2005-02-09 15:46:43.615431000 +0100
@@ -656,12 +656,15 @@ nfsd_open(struct svc_rqst *rqstp, struct
 	dentry = fhp->fh_dentry;
 	inode = dentry->d_inode;
 
-	/* Disallow access to files with the append-only bit set or
-	 * with mandatory locking enabled
+	/* Disallow write access to files with the append-only bit set
+	 * or any access when mandatory locking enabled
 	 */
 	err = nfserr_perm;
-	if (IS_APPEND(inode) || IS_ISMNDLK(inode))
+	if (IS_APPEND(inode) && (access & MAY_WRITE))
 		goto out;
+	if (IS_ISMNDLK(inode))
+		goto out;
+
 	if (!inode->i_fop)
 		goto out;
 
diff -purN linux-2.6.11-rc3-bk5/include/asm-sparc64/compat.h linux-2.6.11-rc3-bk6/include/asm-sparc64/compat.h
--- linux-2.6.11-rc3-bk5/include/asm-sparc64/compat.h	2005-02-03 02:56:10.000000000 +0100
+++ linux-2.6.11-rc3-bk6/include/asm-sparc64/compat.h	2005-02-09 15:46:43.724414063 +0100
@@ -133,6 +133,8 @@ static __inline__ void __user *compat_al
 
 	if (!(test_thread_flag(TIF_32BIT)))
 		usp += STACK_BIAS;
+	else
+		usp &= 0xffffffffUL;
 
 	return (void __user *) (usp - len);
 }
diff -purN linux-2.6.11-rc3-bk5/include/linux/raid/raid5.h linux-2.6.11-rc3-bk6/include/linux/raid/raid5.h
--- linux-2.6.11-rc3-bk5/include/linux/raid/raid5.h	2005-02-03 02:56:34.000000000 +0100
+++ linux-2.6.11-rc3-bk6/include/linux/raid/raid5.h	2005-02-09 15:46:43.752409712 +0100
@@ -152,6 +152,7 @@ struct stripe_head {
 #define	R5_Wantread	4	/* want to schedule a read */
 #define	R5_Wantwrite	5
 #define	R5_Syncio	6	/* this io need to be accounted as resync io */
+#define	R5_Overlap	7	/* There is a pending overlapping request on this block */
 
 /*
  * Write method
@@ -219,6 +220,7 @@ struct raid5_private_data {
 	atomic_t		active_stripes;
 	struct list_head	inactive_list;
 	wait_queue_head_t	wait_for_stripe;
+	wait_queue_head_t	wait_for_overlap;
 	int			inactive_blocked;	/* release of inactive stripes blocked,
 							 * waiting for 25% to be free
 							 */        
diff -purN linux-2.6.11-rc3-bk5/init/do_mounts_md.c linux-2.6.11-rc3-bk6/init/do_mounts_md.c
--- linux-2.6.11-rc3-bk5/init/do_mounts_md.c	2005-02-03 02:56:48.000000000 +0100
+++ linux-2.6.11-rc3-bk6/init/do_mounts_md.c	2005-02-09 15:46:43.762408158 +0100
@@ -232,6 +232,16 @@ static void __init md_setup_drive(void)
 			err = sys_ioctl(fd, RUN_ARRAY, 0);
 		if (err)
 			printk(KERN_WARNING "md: starting md%d failed\n", minor);
+		else {
+			/* reread the partition table.
+			 * I (neilb) and not sure why this is needed, but I cannot
+			 * boot a kernel with devfs compiled in from partitioned md
+			 * array without it
+			 */
+			sys_close(fd);
+			fd = sys_open(name, 0, 0);
+			sys_ioctl(fd, BLKRRPART, 0);
+		}
 		sys_close(fd);
 	}
 }
diff -purN linux-2.6.11-rc3-bk5/mm/nommu.c linux-2.6.11-rc3-bk6/mm/nommu.c
--- linux-2.6.11-rc3-bk5/mm/nommu.c	2005-02-03 02:56:47.000000000 +0100
+++ linux-2.6.11-rc3-bk6/mm/nommu.c	2005-02-09 15:46:43.779405516 +0100
@@ -4,7 +4,9 @@
  *  Replacement code for mm functions to support CPU's that don't
  *  have any form of memory management unit (thus no virtual memory).
  *
- *  Copyright (c) 2004      David Howells <dhowells@redhat.com>
+ *  See Documentation/nommu-mmap.txt
+ *
+ *  Copyright (c) 2004-2005 David Howells <dhowells@redhat.com>
  *  Copyright (c) 2000-2003 David McCullough <davidm@snapgear.com>
  *  Copyright (c) 2000-2001 D Jeff Dionne <jeff@uClinux.org>
  *  Copyright (c) 2002      Greg Ungerer <gerg@snapgear.com>
@@ -567,12 +569,14 @@ unsigned long do_mmap_pgoff(struct file 
 	 * that it represents a valid section of the address space
 	 * - this is the hook for quasi-memory character devices
 	 */
-	if (file && file->f_op->get_unmapped_area)
+	if (file && file->f_op->get_unmapped_area) {
 		addr = file->f_op->get_unmapped_area(file, addr, len, pgoff, flags);
-
-	if (IS_ERR((void *) addr)) {
-		ret = addr;
-		goto error;
+		if (IS_ERR((void *) addr)) {
+			ret = addr;
+			if (ret == (unsigned long) -ENOSYS)
+				ret = (unsigned long) -ENODEV;
+			goto error;
+		}
 	}
 
 	/* we're going to need a VMA struct as well */
diff -purN linux-2.6.11-rc3-bk5/net/atm/addr.c linux-2.6.11-rc3-bk6/net/atm/addr.c
--- linux-2.6.11-rc3-bk5/net/atm/addr.c	2005-02-03 02:55:01.000000000 +0100
+++ linux-2.6.11-rc3-bk6/net/atm/addr.c	2005-02-09 15:46:43.791403652 +0100
@@ -108,7 +108,7 @@ int atm_del_addr(struct atm_dev *dev, st
 }
 
 int atm_get_addr(struct atm_dev *dev, struct sockaddr_atmsvc __user * buf,
-		 int size)
+		 size_t size)
 {
 	unsigned long flags;
 	struct atm_dev_addr *this;
diff -purN linux-2.6.11-rc3-bk5/net/atm/addr.h linux-2.6.11-rc3-bk6/net/atm/addr.h
--- linux-2.6.11-rc3-bk5/net/atm/addr.h	2005-02-03 02:55:50.000000000 +0100
+++ linux-2.6.11-rc3-bk6/net/atm/addr.h	2005-02-09 15:46:43.792403496 +0100
@@ -13,6 +13,6 @@
 void atm_reset_addr(struct atm_dev *dev);
 int atm_add_addr(struct atm_dev *dev,struct sockaddr_atmsvc *addr);
 int atm_del_addr(struct atm_dev *dev,struct sockaddr_atmsvc *addr);
-int atm_get_addr(struct atm_dev *dev,struct sockaddr_atmsvc __user *buf,int size);
+int atm_get_addr(struct atm_dev *dev,struct sockaddr_atmsvc __user *buf,size_t size);
 
 #endif
