From: ak@suse.de
Subject: Ignore errors during MTRR setup
Suse-bugzilla: 65639

Check for exception
This works around bugs in some Tyan AMD64 motherboards who don't
set the first fixed range MTRR. This would cause the  MTRR driver
to crash later when trying to duplicate the MTRR to other CPUs. 

Better would be to validate all MTRRs, but that's much more 
complicated.

Fixed i386 and x86-64

Index: linux-2.6.10/arch/i386/kernel/cpu/mtrr/state.c
===================================================================
--- linux-2.6.10.orig/arch/i386/kernel/cpu/mtrr/state.c
+++ linux-2.6.10/arch/i386/kernel/cpu/mtrr/state.c
@@ -42,7 +42,7 @@ void set_mtrr_cache_disable(struct set_m
 {
 	if (use_intel()) 
 		/*  Disable MTRRs, and set the default type to uncached  */
-		wrmsr(MTRRdefType_MSR, ctxt->deftype_lo & 0xf300UL,
+		mtrr_wrmsr(MTRRdefType_MSR, ctxt->deftype_lo & 0xf300UL,
 		      ctxt->deftype_hi);
 	else if (is_cpu(CYRIX))
 		/* Cyrix ARRs - everything else were excluded at the top */
@@ -60,7 +60,7 @@ void set_mtrr_done(struct set_mtrr_conte
 		/*  Restore MTRRdefType  */
 		if (use_intel())
 			/* Intel (P6) standard MTRRs */
-			wrmsr(MTRRdefType_MSR, ctxt->deftype_lo, ctxt->deftype_hi);
+			mtrr_wrmsr(MTRRdefType_MSR, ctxt->deftype_lo, ctxt->deftype_hi);
 		else
 			/* Cyrix ARRs - everything else was excluded at the top */
 			setCx86(CX86_CCR3, ctxt->ccr3);
Index: linux-2.6.10/include/asm-i386/msr.h
===================================================================
--- linux-2.6.10.orig/include/asm-i386/msr.h
+++ linux-2.6.10/include/asm-i386/msr.h
@@ -32,6 +32,21 @@ static inline void wrmsrl (unsigned long
 	wrmsr (msr, lo, hi);
 }
 
+/* wrmsr with exception handling */
+#define wrmsr_safe(msr,a,b) ({ int ret__;						\
+	asm volatile("2: wrmsr ; xorl %0,%0\n"						\
+		     "1:\n\t"								\
+		     ".section .fixup,\"ax\"\n\t"					\
+		     "3:  movl %4,%0 ; jmp 1b\n\t"					\
+		     ".previous\n\t"							\
+ 		     ".section __ex_table,\"a\"\n"					\
+		     "   .align 4\n\t"							\
+		     "   .long 	2b,3b\n\t"						\
+		     ".previous"							\
+		     : "=a" (ret__)							\
+		     : "c" (msr), "0" (a), "d" (b), "i" (-EFAULT));\
+	ret__; })
+
 #define rdtsc(low,high) \
      __asm__ __volatile__("rdtsc" : "=a" (low), "=d" (high))
 
Index: linux-2.6.10/arch/i386/kernel/cpu/mtrr/generic.c
===================================================================
--- linux-2.6.10.orig/arch/i386/kernel/cpu/mtrr/generic.c
+++ linux-2.6.10/arch/i386/kernel/cpu/mtrr/generic.c
@@ -21,6 +21,16 @@ struct mtrr_state {
 static unsigned long smp_changes_mask;
 struct mtrr_state mtrr_state = {};
 
+/* Doesn't attempt to pass an error out to MTRR users
+   because it's quite complicated in some cases and probably not 
+   worth it because the best error handling is to ignore it. */
+void mtrr_wrmsr(unsigned msr, unsigned a, unsigned b) 
+{ 
+	if (wrmsr_safe(msr, a, b) < 0) 
+		printk(KERN_ERR 
+			"MTRR: CPU %u: Writing MSR %x to %x:%x failed\n",
+			smp_processor_id(), msr, a, b);
+} 
 
 /*  Get the MSR pair relating to a var range  */
 static void __init
@@ -151,14 +161,14 @@ static int set_fixed_ranges(mtrr_type * 
 
 	rdmsr(MTRRfix64K_00000_MSR, lo, hi);
 	if (p[0] != lo || p[1] != hi) {
-		wrmsr(MTRRfix64K_00000_MSR, p[0], p[1]);
+		mtrr_wrmsr(MTRRfix64K_00000_MSR, p[0], p[1]);
 		changed = TRUE;
 	}
 
 	for (i = 0; i < 2; i++) {
 		rdmsr(MTRRfix16K_80000_MSR + i, lo, hi);
 		if (p[2 + i * 2] != lo || p[3 + i * 2] != hi) {
-			wrmsr(MTRRfix16K_80000_MSR + i, p[2 + i * 2],
+			mtrr_wrmsr(MTRRfix16K_80000_MSR + i, p[2 + i * 2],
 			      p[3 + i * 2]);
 			changed = TRUE;
 		}
@@ -167,7 +177,7 @@ static int set_fixed_ranges(mtrr_type * 
 	for (i = 0; i < 8; i++) {
 		rdmsr(MTRRfix4K_C0000_MSR + i, lo, hi);
 		if (p[6 + i * 2] != lo || p[7 + i * 2] != hi) {
-			wrmsr(MTRRfix4K_C0000_MSR + i, p[6 + i * 2],
+			mtrr_wrmsr(MTRRfix4K_C0000_MSR + i, p[6 + i * 2],
 			      p[7 + i * 2]);
 			changed = TRUE;
 		}
@@ -185,7 +195,7 @@ static int set_mtrr_var_ranges(unsigned 
 	rdmsr(MTRRphysBase_MSR(index), lo, hi);
 	if ((vr->base_lo & 0xfffff0ffUL) != (lo & 0xfffff0ffUL)
 	    || (vr->base_hi & 0xfUL) != (hi & 0xfUL)) {
-		wrmsr(MTRRphysBase_MSR(index), vr->base_lo, vr->base_hi);
+		mtrr_wrmsr(MTRRphysBase_MSR(index), vr->base_lo, vr->base_hi);
 		changed = TRUE;
 	}
 
@@ -193,7 +203,7 @@ static int set_mtrr_var_ranges(unsigned 
 
 	if ((vr->mask_lo & 0xfffff800UL) != (lo & 0xfffff800UL)
 	    || (vr->mask_hi & 0xfUL) != (hi & 0xfUL)) {
-		wrmsr(MTRRphysMask_MSR(index), vr->mask_lo, vr->mask_hi);
+		mtrr_wrmsr(MTRRphysMask_MSR(index), vr->mask_lo, vr->mask_hi);
 		changed = TRUE;
 	}
 	return changed;
@@ -268,7 +278,7 @@ static void prepare_set(void)
 	rdmsr(MTRRdefType_MSR, deftype_lo, deftype_hi);
 
 	/*  Disable MTRRs, and set the default type to uncached  */
-	wrmsr(MTRRdefType_MSR, deftype_lo & 0xf300UL, deftype_hi);
+	mtrr_wrmsr(MTRRdefType_MSR, deftype_lo & 0xf300UL, deftype_hi);
 }
 
 static void post_set(void)
@@ -277,7 +287,7 @@ static void post_set(void)
 	__flush_tlb();
 
 	/* Intel (P6) standard MTRRs */
-	wrmsr(MTRRdefType_MSR, deftype_lo, deftype_hi);
+	mtrr_wrmsr(MTRRdefType_MSR, deftype_lo, deftype_hi);
 		
 	/*  Enable caches  */
 	write_cr0(read_cr0() & 0xbfffffff);
@@ -331,11 +341,11 @@ static void generic_set_mtrr(unsigned in
 	if (size == 0) {
 		/* The invalid bit is kept in the mask, so we simply clear the
 		   relevant mask register to disable a range. */
-		wrmsr(MTRRphysMask_MSR(reg), 0, 0);
+		mtrr_wrmsr(MTRRphysMask_MSR(reg), 0, 0);
 	} else {
-		wrmsr(MTRRphysBase_MSR(reg), base << PAGE_SHIFT | type,
+		mtrr_wrmsr(MTRRphysBase_MSR(reg), base << PAGE_SHIFT | type,
 		      (base & size_and_mask) >> (32 - PAGE_SHIFT));
-		wrmsr(MTRRphysMask_MSR(reg), -size << PAGE_SHIFT | 0x800,
+		mtrr_wrmsr(MTRRphysMask_MSR(reg), -size << PAGE_SHIFT | 0x800,
 		      (-size & size_and_mask) >> (32 - PAGE_SHIFT));
 	}
 
Index: linux-2.6.10/include/asm-x86_64/msr.h
===================================================================
--- linux-2.6.10.orig/include/asm-x86_64/msr.h
+++ linux-2.6.10/include/asm-x86_64/msr.h
@@ -28,8 +28,8 @@
 
 #define wrmsrl(msr,val) wrmsr(msr,(__u32)((__u64)(val)),((__u64)(val))>>32) 
 
-/* wrmsrl with exception handling */
-#define checking_wrmsrl(msr,val) ({ int ret__;						\
+/* wrmsr with exception handling */
+#define wrmsr_safe(msr,a,b) ({ int ret__;						\
 	asm volatile("2: wrmsr ; xorl %0,%0\n"						\
 		     "1:\n\t"								\
 		     ".section .fixup,\"ax\"\n\t"					\
@@ -40,9 +40,11 @@
 		     "   .quad 	2b,3b\n\t"						\
 		     ".previous"							\
 		     : "=a" (ret__)							\
-		     : "c" (msr), "0" ((__u32)val), "d" ((val)>>32), "i" (-EFAULT));\
+		     : "c" (msr), "0" (a), "d" (b), "i" (-EFAULT));\
 	ret__; })
 
+#define checking_wrmsrl(msr,val) wrmsr_safe(msr,(u32)(val),(u32)((val)>>32))
+
 #define rdtsc(low,high) \
      __asm__ __volatile__("rdtsc" : "=a" (low), "=d" (high))
 
Index: linux-2.6.10/arch/i386/kernel/cpu/mtrr/mtrr.h
===================================================================
--- linux-2.6.10.orig/arch/i386/kernel/cpu/mtrr/mtrr.h
+++ linux-2.6.10/arch/i386/kernel/cpu/mtrr/mtrr.h
@@ -96,4 +96,6 @@ void finalize_mtrr_state(void);
 void mtrr_state_warn(void);
 char *mtrr_attrib_to_str(int x);
 
+void mtrr_wrmsr(unsigned, unsigned, unsigned);
+
 extern char * mtrr_if_name[];
