From: Jens Axboe <axboe@suse.de>
Subject: Limit recursion of the request handler
Patch-mainline: 
References: 170315

Don't recurse on block layer requeues, as they are most likely don't
because of driver/hardware starvation problems and rehitting the queue
directly from that path then only does harm.

Same for blk_run_queue(), apply same level of 1-deep recursion that
blk_start_queue() does.

Acked-by: 
Signed-off-by: 

--- linux-2.6.16/block/elevator.c~	2006-05-03 13:41:35.000000000 +0200
+++ linux-2.6.16/block/elevator.c	2006-05-03 13:41:41.000000000 +0200
@@ -314,6 +314,7 @@ void elv_insert(request_queue_t *q, stru
 {
 	struct list_head *pos;
 	unsigned ordseq;
+	int unplug_it = 1;
 
 	rq->q = q;
 
@@ -378,6 +379,11 @@ void elv_insert(request_queue_t *q, stru
 		}
 
 		list_add_tail(&rq->queuelist, pos);
+		/*
+		 * most requeues happen because of a busy condition, don't
+		 * force unplug of the queue for that case.
+		 */
+		unplug_it = 0;
 		break;
 
 	default:
@@ -386,7 +392,7 @@ void elv_insert(request_queue_t *q, stru
 		BUG();
 	}
 
-	if (blk_queue_plugged(q)) {
+	if (unplug_it && blk_queue_plugged(q)) {
 		int nrq = q->rq.count[READ] + q->rq.count[WRITE]
 			- q->in_flight;
 
--- linux-2.6.16/block/ll_rw_blk.c~	2006-05-03 13:41:38.000000000 +0200
+++ linux-2.6.16/block/ll_rw_blk.c	2006-05-03 13:41:41.000000000 +0200
@@ -1722,8 +1722,21 @@ void blk_run_queue(struct request_queue 
 
 	spin_lock_irqsave(q->queue_lock, flags);
 	blk_remove_plug(q);
-	if (!elv_queue_empty(q))
-		q->request_fn(q);
+
+	/*
+	 * Only recurse once to avoid overrunning the stack, let the unplug
+	 * handling reinvoke the handler shortly if we already got there.
+	 */
+	if (!elv_queue_empty(q)) {
+		if (!test_and_set_bit(QUEUE_FLAG_REENTER, &q->queue_flags)) {
+			q->request_fn(q);
+			clear_bit(QUEUE_FLAG_REENTER, &q->queue_flags);
+		} else {
+			blk_plug_device(q);
+			kblockd_schedule_work(&q->unplug_work);
+		}
+	}
+
 	spin_unlock_irqrestore(q->queue_lock, flags);
 }
 EXPORT_SYMBOL(blk_run_queue);
