From: Andrea Arcangeli <aarcange@redhat.com>
Date: Wed, 20 Dec 2017 08:04:48 -0800
Subject: kvm: svm: add MSR_IA32_SPEC_CTRL and MSR_IA32_PRED_CMD
Patch-mainline: submitted on 2018/1/9
References: bnc#1068032 CVE-2017-5715

Signed-off-by: Andrea Arcangeli <aarcange@redhat.com>
Signed-off-by: Jiri Slaby <jslaby@suse.cz>
---
 arch/x86/kvm/svm.c |   22 ++++++++++++++++++++++
 1 file changed, 22 insertions(+)

--- a/arch/x86/kvm/svm.c
+++ b/arch/x86/kvm/svm.c
@@ -184,6 +184,8 @@ struct vcpu_svm {
 		u64 gs_base;
 	} host;
 
+	u64 spec_ctrl;
+
 	u32 *msrpm;
 
 	ulong nmi_iret_rip;
@@ -253,6 +255,8 @@ static const struct svm_direct_access_ms
 	{ .index = MSR_IA32_LASTBRANCHTOIP,		.always = false },
 	{ .index = MSR_IA32_LASTINTFROMIP,		.always = false },
 	{ .index = MSR_IA32_LASTINTTOIP,		.always = false },
+	{ .index = MSR_IA32_SPEC_CTRL,			.always = false },
+	{ .index = MSR_IA32_PRED_CMD,			.always = false },
 	{ .index = MSR_INVALID,				.always = false },
 };
 
@@ -920,6 +924,9 @@ static void svm_vcpu_init_msrpm(u32 *msr
 
 		set_msr_interception(msrpm, direct_access_msrs[i].index, 1, 1);
 	}
+
+	set_msr_interception(msrpm, MSR_IA32_SPEC_CTRL, 0, 0);
+	set_msr_interception(msrpm, MSR_IA32_PRED_CMD,  0, 0);
 }
 
 static void add_msr_offset(u32 offset)
@@ -3605,6 +3612,9 @@ static int svm_get_msr(struct kvm_vcpu *
 	case MSR_VM_CR:
 		msr_info->data = svm->nested.vm_cr_msr;
 		break;
+	case MSR_IA32_SPEC_CTRL:
+		msr_info->data = svm->spec_ctrl;
+		break;
 	case MSR_IA32_UCODE_REV:
 		msr_info->data = 0x01000065;
 		break;
@@ -3760,6 +3770,9 @@ static int svm_set_msr(struct kvm_vcpu *
 	case MSR_VM_IGNNE:
 		vcpu_unimpl(vcpu, "unimplemented wrmsr: 0x%x data 0x%llx\n", ecx, data);
 		break;
+	case MSR_IA32_SPEC_CTRL:
+		svm->spec_ctrl = data;
+		break;
 	case MSR_IA32_APICBASE:
 		if (kvm_vcpu_apicv_active(vcpu))
 			avic_update_vapic_bar(to_svm(vcpu), data);
@@ -4948,6 +4961,10 @@ static void svm_vcpu_run(struct kvm_vcpu
 
 	local_irq_enable();
 
+	if (static_cpu_has(X86_FEATURE_SPEC_CTRL) &&
+	    svm->spec_ctrl != FEATURE_ENABLE_IBRS)
+		wrmsrl(MSR_IA32_SPEC_CTRL, svm->spec_ctrl);
+
 	asm volatile (
 		"push %%" _ASM_BP "; \n\t"
 		"mov %c[rbx](%[svm]), %%" _ASM_BX " \n\t"
@@ -5040,6 +5057,11 @@ static void svm_vcpu_run(struct kvm_vcpu
 #endif
 		);
 
+	if (static_cpu_has(X86_FEATURE_SPEC_CTRL)) {
+		rdmsrl(MSR_IA32_SPEC_CTRL, svm->spec_ctrl);
+		if (svm->spec_ctrl != FEATURE_ENABLE_IBRS)
+			wrmsrl(MSR_IA32_SPEC_CTRL, FEATURE_ENABLE_IBRS);
+	}
 	/* Eliminate branch target predictions from guest mode */
 	vmexit_fill_RSB();
 
