From: okir@suse.de
Subject: Add /proc/sys/fs/nfs sysctls to nfs module

This patch adds the plumbing for adding nfs-specific sysctls to
fs/nfs, and makes nfs_max_readahead tunable as suggested.

Signed-off-by: okir@suse.de

 fs/nfs/client.c   |    2 +-
 fs/nfs/inode.c    |   40 ++++++++++++++++++++++++++++++++++++++++
 fs/nfs/internal.h |    9 +--------
 3 files changed, 42 insertions(+), 9 deletions(-)

--- linux-2.6.19.orig/fs/nfs/inode.c
+++ linux-2.6.19/fs/nfs/inode.c
@@ -32,6 +32,7 @@
 #include <linux/lockd/bind.h>
 #include <linux/smp_lock.h>
 #include <linux/seq_file.h>
+#include <linux/sysctl.h>
 #include <linux/mount.h>
 #include <linux/nfs_idmap.h>
 #include <linux/vfs.h>
@@ -50,6 +51,15 @@
 #define NFSDBG_FACILITY		NFSDBG_VFS
 #define NFS_PARANOIA 1
 
+/* Maximum number of readahead requests.
+ *
+ * People who do NFS over a slow network may want to reduce it to
+ * something closer to 1 for improved interactive response.
+ */
+unsigned int		nfs_max_readahead = RPC_DEF_SLOT_TABLE - 1;
+static unsigned int	nfs_max_readahead_min = 0;
+static unsigned int	nfs_max_readahead_max = RPC_MAX_SLOT_TABLE - 1;
+
 static void nfs_invalidate_inode(struct inode *);
 static int nfs_update_inode(struct inode *, struct nfs_fattr *);
 
@@ -1152,12 +1162,35 @@ static void nfs_destroy_inodecache(void)
 }
 
 /*
+ * NFS sysctls
+ */
+static struct ctl_table_header *nfs_sysctl_table;
+
+static ctl_table nfs_sysctls[] = {
+	{
+		.ctl_name	= -2,
+		.procname	= "nfs_max_readahead",
+		.data		= &nfs_max_readahead,
+		.maxlen		= sizeof(unsigned int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec_minmax,
+		.strategy	= &sysctl_intvec,
+		.extra1		= &nfs_max_readahead_min,
+		.extra2		= &nfs_max_readahead_max
+	},
+	{ .ctl_name = 0 }
+};
+
+/*
  * Initialize NFS
  */
 static int __init init_nfs_fs(void)
 {
+	struct ctl_path ctl_path[] = { { CTL_FS, "fs", 0555 }, { -2, "nfs", 0555 }, { 0 } };
 	int err;
 
+	nfs_sysctl_table = register_sysctl_table_path(nfs_sysctls, ctl_path);
+
 	err = nfs_fs_proc_init();
 	if (err)
 		goto out5;
@@ -1204,6 +1237,10 @@ out3:
 out4:
 	nfs_fs_proc_exit();
 out5:
+	if (nfs_sysctl_table)
+		unregister_sysctl_table(nfs_sysctl_table);
+	nfs_sysctl_table = NULL;
+
 	return err;
 }
 
@@ -1218,6 +1255,9 @@ static void __exit exit_nfs_fs(void)
 	rpc_proc_unregister("nfs");
 #endif
 	unregister_nfs_fs();
+	if (nfs_sysctl_table)
+		unregister_sysctl_table(nfs_sysctl_table);
+	nfs_sysctl_table = NULL;
 	nfs_fs_proc_exit();
 }
 
--- linux-2.6.19.orig/fs/nfs/client.c
+++ linux-2.6.19/fs/nfs/client.c
@@ -656,7 +656,7 @@ static void nfs_server_set_fsinfo(struct
 	if (server->rsize > NFS_MAX_FILE_IO_SIZE)
 		server->rsize = NFS_MAX_FILE_IO_SIZE;
 	server->rpages = (server->rsize + PAGE_CACHE_SIZE - 1) >> PAGE_CACHE_SHIFT;
-	server->backing_dev_info.ra_pages = server->rpages * NFS_MAX_READAHEAD;
+	server->backing_dev_info.ra_pages = server->rpages * nfs_max_readahead;
 
 	if (server->wsize > max_rpc_payload)
 		server->wsize = max_rpc_payload;
--- linux-2.6.19.orig/fs/nfs/internal.h
+++ linux-2.6.19/fs/nfs/internal.h
@@ -8,14 +8,6 @@ struct nfs_string;
 struct nfs_mount_data;
 struct nfs4_mount_data;
 
-/* Maximum number of readahead requests
- * FIXME: this should really be a sysctl so that users may tune it to suit
- *        their needs. People that do NFS over a slow network, might for
- *        instance want to reduce it to something closer to 1 for improved
- *        interactive response.
- */
-#define NFS_MAX_READAHEAD	(RPC_DEF_SLOT_TABLE - 1)
-
 struct nfs_clone_mount {
 	const struct super_block *sb;
 	const struct dentry *dentry;
@@ -124,6 +116,7 @@ extern void nfs_clear_inode(struct inode
 #ifdef CONFIG_NFS_V4
 extern void nfs4_clear_inode(struct inode *);
 #endif
+extern unsigned int nfs_max_readahead;
 
 /* super.c */
 extern struct file_system_type nfs_xdev_fs_type;
