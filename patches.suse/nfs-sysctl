From: okir@suse.de
Subject: Add /proc/sys/fs/nfs sysctls to nfs module

This patch adds the plumbing for adding nfs-specific sysctls to
fs/nfs, and makes nfs_max_readahead tunable as suggested.

Signed-off-by: okir@suse.de

 fs/nfs/inode.c    |   40 ++++++++++++++++++++++++++++++++++++++++
 fs/nfs/internal.h |    1 +
 fs/nfs/super.c    |   10 +---------
 3 files changed, 42 insertions(+), 9 deletions(-)

Index: build/fs/nfs/inode.c
===================================================================
--- build.orig/fs/nfs/inode.c
+++ build/fs/nfs/inode.c
@@ -32,6 +32,7 @@
 #include <linux/lockd/bind.h>
 #include <linux/smp_lock.h>
 #include <linux/seq_file.h>
+#include <linux/sysctl.h>
 #include <linux/mount.h>
 #include <linux/nfs_idmap.h>
 #include <linux/vfs.h>
@@ -50,6 +51,15 @@
 #define NFSDBG_FACILITY		NFSDBG_VFS
 #define NFS_PARANOIA 1
 
+/* Maximum number of readahead requests.
+ *
+ * People who do NFS over a slow network may want to reduce it to
+ * something closer to 1 for improved interactive response.
+ */
+unsigned int		nfs_max_readahead = RPC_DEF_SLOT_TABLE - 1;
+static unsigned int	nfs_max_readahead_min = 0;
+static unsigned int	nfs_max_readahead_max = RPC_MAX_SLOT_TABLE - 1;
+
 static void nfs_invalidate_inode(struct inode *);
 static int nfs_update_inode(struct inode *, struct nfs_fattr *);
 
@@ -1138,12 +1148,35 @@ static void nfs_destroy_inodecache(void)
 }
 
 /*
+ * NFS sysctls
+ */
+static struct ctl_table_header *nfs_sysctl_table;
+
+static ctl_table nfs_sysctls[] = {
+	{
+		.ctl_name	= -2,
+		.procname	= "nfs_max_readahead",
+		.data		= &nfs_max_readahead,
+		.maxlen		= sizeof(unsigned int),
+		.mode		= 0644,
+		.proc_handler	= &proc_dointvec_minmax,
+		.strategy	= &sysctl_intvec,
+		.extra1		= &nfs_max_readahead_min,
+		.extra2		= &nfs_max_readahead_max
+	},
+	{ .ctl_name = 0 }
+};
+
+/*
  * Initialize NFS
  */
 static int __init init_nfs_fs(void)
 {
+	struct ctl_path ctl_path[] = { { CTL_FS, "fs", 0555 }, { -2, "nfs", 0555 }, { 0 } };
 	int err;
 
+	nfs_sysctl_table = register_sysctl_table_path(nfs_sysctls, ctl_path);
+
 	err = nfs_init_nfspagecache();
 	if (err)
 		goto out4;
@@ -1184,6 +1217,10 @@ out2:
 out3:
 	nfs_destroy_nfspagecache();
 out4:
+	if (nfs_sysctl_table)
+		unregister_sysctl_table(nfs_sysctl_table);
+	nfs_sysctl_table = NULL;
+
 	return err;
 }
 
@@ -1198,6 +1235,9 @@ static void __exit exit_nfs_fs(void)
 	rpc_proc_unregister("nfs");
 #endif
 	unregister_nfs_fs();
+	if (nfs_sysctl_table)
+		unregister_sysctl_table(nfs_sysctl_table);
+	nfs_sysctl_table = NULL;
 }
 
 /* Not quite true; I just maintain it */
Index: build/fs/nfs/super.c
===================================================================
--- build.orig/fs/nfs/super.c
+++ build/fs/nfs/super.c
@@ -52,14 +52,6 @@
 
 #define NFSDBG_FACILITY		NFSDBG_VFS
 
-/* Maximum number of readahead requests
- * FIXME: this should really be a sysctl so that users may tune it to suit
- *        their needs. People that do NFS over a slow network, might for
- *        instance want to reduce it to something closer to 1 for improved
- *        interactive response.
- */
-#define NFS_MAX_READAHEAD	(RPC_DEF_SLOT_TABLE - 1)
-
 /*
  * RPC cruft for NFS
  */
@@ -629,7 +621,7 @@ nfs_sb_init(struct super_block *sb, rpc_
 		server->acdirmin = server->acdirmax = 0;
 		sb->s_flags |= MS_SYNCHRONOUS;
 	}
-	server->backing_dev_info.ra_pages = server->rpages * NFS_MAX_READAHEAD;
+	server->backing_dev_info.ra_pages = server->rpages * nfs_max_readahead;
 
 	nfs_super_set_maxbytes(sb, fsinfo.maxfilesize);
 
Index: build/fs/nfs/internal.h
===================================================================
--- build.orig/fs/nfs/internal.h
+++ build/fs/nfs/internal.h
@@ -74,6 +74,7 @@ extern void nfs_clear_inode(struct inode
 #ifdef CONFIG_NFS_V4
 extern void nfs4_clear_inode(struct inode *);
 #endif
+extern unsigned int nfs_max_readahead;
 
 /* super.c */
 extern struct file_system_type nfs_referral_nfs4_fs_type;
