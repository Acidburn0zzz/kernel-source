From: Mike Galbraith <mgalbraith@suse.de>
Date: Mon, 11 Jun 2012 18:21:05 +0200
Subject: [PATCH] sched: ratelimit nohz

Patch-mainline: never, SUSE specific
References: Scheduler enhancements for I7 (bnc#754690)

Entering nohz code on every micro-idle is costing ~10% throughput for netperf
TCP_RR when scheduling cross-cpu.

The higher the context switch rate, the more nohz entry costs.  With this
patch and some cycle recovery patches in my tree, max cross cpu context
switch rate is improved by ~16%, a large portion of which of which is this
ratelimiting. In addition, it is known that this improves the database
initialisation times of sysbench-oltp by at least 20% on some Intel machines.

Note: a similar patch was in mainline briefly, but was reverted due to one
complaint wrt laptop using more power.  The earlier version raised ticks/s
on my Q6600 bof from ~85c to ~128, this version does not, and also blocks
the mb() in rcu_needs_cpu().

Signed-off-by: Mike Galbraith <mgalbraith@suse.de>
---
 include/linux/sched/nohz.h | 5 +++++
 kernel/sched/core.c        | 8 ++++++++
 kernel/time/tick-sched.c   | 2 +-
 3 files changed, 14 insertions(+), 1 deletion(-)

diff --git a/include/linux/sched/nohz.h b/include/linux/sched/nohz.h
index 4995b717500b..c0862f26b8c0 100644
--- a/include/linux/sched/nohz.h
+++ b/include/linux/sched/nohz.h
@@ -25,6 +25,11 @@ static inline void set_cpu_sd_state_idle(void) { }
 #ifdef CONFIG_NO_HZ_COMMON
 void calc_load_enter_idle(void);
 void calc_load_exit_idle(void);
+#ifdef CONFIG_SMP
+extern int sched_needs_cpu(int cpu);
+#else
+static inline int sched_needs_cpu(int cpu) { return 0; }
+#endif
 #else
 static inline void calc_load_enter_idle(void) { }
 static inline void calc_load_exit_idle(void) { }
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index 3223905b96de..ab8f047e641b 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -620,6 +620,14 @@ static inline bool got_nohz_idle_kick(void)
 	return false;
 }
 
+int sched_needs_cpu(int cpu)
+{
+	if (tick_nohz_full_cpu(cpu))
+		return 0;
+
+	return  cpu_rq(cpu)->avg_idle < sysctl_sched_migration_cost;
+}
+
 #else /* CONFIG_NO_HZ_COMMON */
 
 static inline bool got_nohz_idle_kick(void)
diff --git a/kernel/time/tick-sched.c b/kernel/time/tick-sched.c
index 64c97fc130c4..e0cae418c3b9 100644
--- a/kernel/time/tick-sched.c
+++ b/kernel/time/tick-sched.c
@@ -678,7 +678,7 @@ static ktime_t tick_nohz_stop_sched_tick(struct tick_sched *ts,
 	} while (read_seqretry(&jiffies_lock, seq));
 	ts->last_jiffies = basejiff;
 
-	if (rcu_needs_cpu(basemono, &next_rcu) ||
+	if (sched_needs_cpu(cpu) || rcu_needs_cpu(basemono, &next_rcu) ||
 	    arch_needs_cpu() || irq_work_needs_cpu()) {
 		next_tick = basemono + TICK_NSEC;
 	} else {
