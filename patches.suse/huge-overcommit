diff -u linux/include/linux/hugetlb.h-o linux/include/linux/hugetlb.h
--- linux/include/linux/hugetlb.h-o	2004-05-07 12:21:01.000000000 +0200
+++ linux/include/linux/hugetlb.h	2004-05-10 13:18:07.000000000 +0200
@@ -21,6 +21,7 @@
 void huge_page_release(struct page *);
 int hugetlb_report_meminfo(char *);
 int is_hugepage_mem_enough(size_t);
+int __is_hugepage_mem_enough(struct mempolicy *pol, size_t);
 unsigned long hugetlb_total_pages(void);
 struct page *follow_huge_addr(struct mm_struct *mm, struct vm_area_struct *vma,
 			unsigned long address, int write);
@@ -30,8 +31,10 @@
 				pmd_t *pmd, int write);
 int is_aligned_hugepage_range(unsigned long addr, unsigned long len);
 int pmd_huge(pmd_t pmd);
+unsigned long huge_count_pages(unsigned long addr, unsigned long end);
 
 extern int htlbpage_max;
+extern int sysctl_overcommit_hugepages;
 
 static inline void
 mark_mm_hugetlb(struct mm_struct *mm, struct vm_area_struct *vma)
diff -u linux/fs/hugetlbfs/inode.c-o linux/fs/hugetlbfs/inode.c
--- linux/fs/hugetlbfs/inode.c-o	2004-05-07 12:21:00.000000000 +0200
+++ linux/fs/hugetlbfs/inode.c	2004-05-07 17:20:41.000000000 +0200
@@ -32,6 +32,8 @@
 /* some random number */
 #define HUGETLBFS_MAGIC	0x958458f6
 
+int sysctl_overcommit_hugepages;  /* no overcommit by default */
+
 static struct super_operations hugetlbfs_ops;
 static struct address_space_operations hugetlbfs_aops;
 struct file_operations hugetlbfs_file_operations;
@@ -43,6 +45,13 @@
 	.memory_backed	= 1,	/* Does not contribute to dirty memory */
 };
 
+/* Can be overwritten by architecture */
+__attribute__((weak)) unsigned long 
+huge_count_pages(unsigned long addr, unsigned long end)
+{
+	return 0;
+}
+
 static int hugetlbfs_file_mmap(struct file *file, struct vm_area_struct *vma)
 {
 	struct inode *inode = file->f_dentry->d_inode;
@@ -59,6 +68,10 @@
 	if (vma->vm_end - vma->vm_start < HPAGE_SIZE)
 		return -EINVAL;
 
+	if (!sysctl_overcommit_hugepages && 
+	    !is_hugepage_mem_enough(vma->vm_end - vma->vm_start))
+		return -ENOMEM;
+	    
 	vma_len = (loff_t)(vma->vm_end - vma->vm_start);
 
 	down(&inode->i_sem);
diff -u linux/kernel/sysctl.c-o linux/kernel/sysctl.c
--- linux/kernel/sysctl.c-o	2004-05-07 12:21:01.000000000 +0200
+++ linux/kernel/sysctl.c	2004-05-07 16:46:01.000000000 +0200
@@ -801,6 +801,14 @@
 		.mode		= 0644,
 		.proc_handler	= &hugetlb_sysctl_handler,
 	 },
+	{ 
+		.ctl_name = 999,
+		.procname = "overcommit_hugepages",
+		.data     = &sysctl_overcommit_hugepages,
+		.maxlen   = sizeof(int),
+		.mode     = 0644,
+		.proc_handler = &proc_dointvec,
+	},
 #endif
 	{
 		.ctl_name	= VM_LOWER_ZONE_PROTECTION,
diff -u linux/mm/policy.c-o linux/mm/policy.c
--- linux/mm/policy.c-o	2004-05-07 12:21:00.000000000 +0200
+++ linux/mm/policy.c	2004-05-11 17:18:09.000000000 +0200
@@ -258,7 +258,7 @@
 /* Step 1: check the range */
 static struct vm_area_struct *
 check_range(struct mm_struct *mm, unsigned long start, unsigned long end,
-	    unsigned long *nodes, unsigned long flags)
+	    unsigned long *nodes, unsigned long flags, struct mempolicy *pol)
 {
 	int err;
 	struct vm_area_struct *first, *vma, *prev;
@@ -279,6 +279,23 @@
 				break;
 			}
 		}
+		if (is_vm_hugetlb_page(vma) && 
+		    !sysctl_overcommit_hugepages &&
+		    pol && pol->policy == MPOL_BIND) { 
+			unsigned long len; 
+			len = min_t(unsigned long, end, vma->vm_end) -
+				max_t(unsigned long, start, vma->vm_start);
+			len -= huge_count_pages(start, end) * HPAGE_SIZE; 
+			if (len == 0) 
+				;
+			else if (!__is_hugepage_mem_enough(pol, len)) { 
+				PDprintk("not enough huge pages (%d) (%d,%lx)\n",
+					 len/HPAGE_SIZE, 
+					 pol ? pol->policy : 0, 
+					 pol ? pol->v.nodes : 0); 
+				return ERR_PTR(-ENOMEM);
+			}
+		} 
 		prev = vma;
 	}
 	return first;
@@ -368,7 +385,7 @@
 			mode,nodes[0]);
 
 	down_write(&mm->mmap_sem);
-	vma = check_range(mm, start, end, nodes, flags);
+	vma = check_range(mm, start, end, nodes, flags, new);
 	err = PTR_ERR(vma);
 	if (!IS_ERR(vma))
 		err = mbind_range(vma, start, end, new);
