Index: linux.t/Documentation/hook/HOWTO
===================================================================
--- linux.t.orig/Documentation/hook/HOWTO	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/Documentation/hook/HOWTO	2004-05-13 10:48:24.751308776 -0400
@@ -0,0 +1,393 @@
+How to use Kernel Hooks?
+
+Author: Richard J Moore, richardj_moore@uk.ibm.com, 
+	Vamsi Krishna S., vamsi_krishna@in.ibm.com,
+	Prasanna S Panchamukhi prasanna@in.ibm.com
+	Linux Technology Centre, IBM Corp.
+
+(C) Copyright 2000 IBM Corporation
+(C) Copyright 2000 IBM UK Ltd
+
+
+Introduction:
+------------
+
+The Kernel Hooks Interface is a generalised facility for placing hooks in 
+arbitrary kernel locations. A hook is a location in the kernel
+that calls out of the kernel to a kernel module routine - a hook exit routine.
+It enables many kernel enhancements, which are otherwise self-contained, to
+become loadable kernel modules and retain a substantial degree of independence
+from the kernel source. This affords advantages for maintenance and
+co-existence with other kernel enhancements. 
+
+Hooks are implemented as fast and slim-line insertions to kernel space code.
+When not active that have practically no overhead to the kernel. They are in
+essence a conditional jmp to the exit dispatching code. 
+
+There are two hook optimizations employed in gkhi, one of which is optional - the
+exclusive hook; the other - the arch-hook - is dependent on the IA32 architecture
+and always used in that environment.
+
+The exclusive hook eliminates some of the generalised processing associated with
+dispatching multiple exits. This can be used where it is known that only one 
+exit would ever register to use a hook. Exclusive hooks are coded as 
+EXCLUSIVE_HOOK, EXCLUSIVE_HOOK_RET etc. You have to use the macro
+DECLARE_EXCLUSIVE_HOOK to declare the exclusive hook.
+
+The arch-hook optimization uses architecturally dependent features. We have 
+provided an implementation for IA32, though could be ported to other 
+architectures without difficulty. The code for the IA32 implementation may 
+be found in include/asm-i386/hook.h. This optimization is always used under IA32. 
+It is implemented by:
+ 
+  1. moving the hook exit dispatching code to a separate section to minimise the
+     icache footprint of the hook code. (This should be applicable
+     to all architectures.)
+  2. changing the test for the conditional jmp to be dependent on a register variable
+     which set by moving a literal constant into the register.
+  3. modifying the literal value in the MOV instruction to activate and deactivate the
+     hook.
+ 
+These actions both minimise the cache hit and the number of instructions required to
+test for an inactive hook.
+
+There is another type of hooks: generic hooks. These are slower than the
+arch-optimized hooks, but they generate no symbols at hook locations and
+could be used to place hooks even in inline functions. Use the macros
+DECLARE_GENERIC_HOOK and GENERIC_HOOK etc. to define generic hooks.
+
+The hook interface allows multiple kernel modules to register their exits for
+a given hook, in order to receive control at that given hook location. Multiple
+hooks may be defined within the kernel and a single kernel module may register
+exits to use multiple hooks.
+
+When hook exits register they may specify co-existence criteria, that is
+whether they can co-exist with other exist for the same hook and their
+dispatching priority.
+
+Hooks may be placed in kernel modules as well as the kernel itself.
+
+A hook exit receives control as if called from the code in which the hook is
+placed. Parameters may be passed to a hook exit and may be modified by an
+exit (subject to being declared for that purpose). The exit may return a
+non-zero result to stop other exits from being dispatched.
+
+There are two type of hook:
+
+	normal.
+	conditional return.
+
+With normal hooks, control returns to the hooked code after any exits are
+dispatched.
+
+With conditional return hooks, an exit may optionally specify that the routine
+in which the hook is coded must return when the exit returns.
+
+Exits are made callable in a two-stage process:
+
+1) Registration - this is used to make the exit known to the hook interface
+and to perform some validation. 
+
+2) Arming - this is used to make a set of exits callable. The arming operation
+is atomic as far as kernel processing is concerned.
+
+These operations may be reversed using disarming and de-registration functions.
+
+Hook interface is implemented in kernel/hook.c which can be compiled into the
+kernel or as a module based on the kernel compilation option specified in
+the "Kernel Hacking" section of the build configuration.
+
+Hooks are defined by coding a DECLARE_HOOK macro to define a hook-head 
+structure. Modules defining hooks may load before or after hook.o when it is 
+compiled as a module, however they have to identify to the hook interface module 
+the existence of a hook before an exit can be register and arm itself.
+
+Hooks are identified by name, which should avoid problems of uniqueness. The
+name specified is used to generate labels for the hook-head structure and the
+hook location.
+
+
+Installation:
+-------------
+
+Apply this patch to the kernel source and say 'Y' or 'M' to "Kernel Hooks 
+Interface" in the "Kernel Hacking" section of the build configuration. Build 
+the kernel and boot with it. If you build the hook interface as a module,
+build and install the module.
+
+-------------------------------------------------------------------------------
+If you want to see a working example then compile khook.c and kexit.c using 
+the following command:
+
+echo "obj-m := khook.o kexit.o" > Makefile   
+make -C /usr/src/linux/ SUBDIRS=$PWD modules
+
+insmod khook.ko
+insmod kexit.ko
+
+khook.c shows how hooks are coded.
+kexit.c shows how hook exits register and arm themselves.
+
+The procedure for defining and using hooks involves the following steps:
+	- add hooks to the kernel/kernel module source
+	- register hook exits
+	- arm hook exits
+and when we are done using the hooks, undo the above:
+	- disarm hook exits
+	- deregister hook exits
+
+-------------------------------------------------------------------------------
+
+Adding Hooks to the Kernel
+--------------------------
+
+Let's say we want to place a hook named hook_trap1_entry in the beginning of the
+trap1 handler then edit arch/i386/traps.c, locate routine do_debug. This is the
+trap1 exception handler. The code begins as follows:
+
+asmlinkage void do_debug(struct pt_regs * regs, long error_code)
+{
+	unsigned int condition;
+	struct task_struct *tsk = current;
+
+	if (regs->eflags & VM_MASK)
+		goto debug_vm86;
+
+	__asm__ __volatile__("movl %%db6,%0" : "=r" (condition));
+
+Suppose we want a hook before the if statement. We add to traps.c:
+
+#include <linux/hook.h>
+#define HOOK_TRAP1_ENTRY hook_trap1_entry /* just a convenient define */
+DECLARE_HOOK(HOOK_TRAP1_ENTRY);
+
+then in do_debug we insert the hook definition:
+asmlinkage void do_debug(struct pt_regs * regs, long error_code)
+{
+	unsigned int condition;
+	struct task_struct *tsk = current;
+
+	HOOK(HOOK_TRAP1_ENTRY);
+
+	if (regs->eflags & VM_MASK)
+		goto debug_vm86;
+
+	__asm__ __volatile__("movl %%db6,%0" : "=r" (condition));
+
+Now recompile the kernel.
+
+For example to pass "condition" from do_debug to a hook exit:
+
+    HOOK(HOOK_TRAP1_ENTRY, condition);
+
+If you want to code a conditional-return hook the use for exmaple:
+
+    HOOK_RET(HOOK_TRAP1_ENTRY, condition);
+
+The kernel now has a dormant hook at the beginning of the trap1 exception
+handler.
+
+Adding Hooks to a Kernel Module
+-------------------------------
+Adding hooks to a kernel module is very similar to adding hooks to kernel.
+In the module that is to have a hook defined code the DECLARE_HOOK macro 
+before the first routine is defined - in other words where external static 
+variables would be defined. For example suppose we wish to define my_hook,
+then code:
+
+#include <linux/hook.h>
+DECLARE_HOOK(my_hook);
+
+Next you'll need to define the hook by coding a HOOK macro in the code path 
+where the hook is to be placed. In this example:
+
+	HOOK(my_hook);
+
+would be coded. This defines a public symbol for the hook location using the
+name my_hook.
+
+Using Hooks - registering and arming hook exits:
+------------------------------------------------
+
+To use this hook from your kernel module you need to perform 3 actions:
+
+1) If hook interface hook.o is built as a module, insert it using:
+	insmod hook.o
+you might need the -f switch if you've changed kernel  versions after
+compiling hook.o
+
+2) You need to register the entry point (the hook exit) in your kernel module
+that will receive control from hook.
+
+You do this by calling hook_exit_register passing a pointer to hook structure 
+(in this example hook_trap1_entry) and a pointer to a hook record structure 
+(defined in hook.h as struct hook_rec). You will need to include linux/hook.h
+into your module's source. Refer to this file for the definition of struct 
+hook_rec, struct hook  and the relavent flags.
+
+Allocate an instance of this structure for each hook exit you wish to
+register. The hook.o interface will use these structures for as long as your
+exits remain registered so allocate them from persistent memory e.g. the
+kernel heap or global memory in you module. Don't allocate them as local
+variables!
+
+You set up your hook record as follows:
+
+1) initialise the entire structure to NULLs.
+
+2) set hook_exit to the address of your hook routine.
+
+3) set the pointer hook_exit_name to the name of exit routine.
+
+4) optionally set hook_flags to one of the following:
+
+
+#define HOOK_PRIORITY_FIRST	0x00000004
+#define HOOK_PRIORITY_LAST	0x00000008
+#define HOOK_QUEUE_LIFO		0x00000010
+
+HOOK_PRIORITY_FIRST inserts your exit at the head of the queue of exits to be 
+dispatched for the particular hook. If another exit has already registered with
+HOOK_PRIORITY_FIRST, then your registration fails.
+
+HOOK_PRIORITY_LAST inserts your exit at the tail of the dispatching
+queue. If another exit has already registered with this priority, then your 
+registration fails.
+
+Set HOOK_QUEUE_LIFO if you want to be inserted at the head of those exits that
+can happily co-exist, but after a HOOK_PRIORITY_FIRST exit if one exists. 
+
+If you leave hook_flag to NULL you'll be inserted at the tail, but above a 
+HOOK_PRIORITY_LAST exit if it exists.
+
+You now call hook_exit_register. If you get a NO_ERROR result then your exit has
+been successfully registered. Note: registration does not cause your exit to be
+called - that only happens after arming you exit. The reason for making this
+distinction is to allow a group of exits to be simultaneously armed, once
+successfully registered.
+
+On successful registration you hook record will have hook_index indicating the
+current position of this exit in the list of all exits registered for this 
+hook, i.e., its dispatching priority (1 being first). Note that it will be 
+updated as more exits register or deregister.
+
+To get a group of exits callable from the hook you need to arm them. 
+Arming is done by calling hook_exit_arm.
+
+Once this is done your exits will be called whenever the kernel executes a
+HOOK statement - unless a higher priority exit set a non-zero return value.
+
+Hook Exit Parameters and Return Values.
+--------------------------------------
+A hook exit receives a variable length parameter list defined as follows:
+
+For normal (unconditional return) hooks:
+
+parm 0: pointer to the hook structure. This is useful if you have the
+	same exit routine registered for multiple hooks, in which case this
+	can be used to determine which hook has caused the exit routine to be
+	called. 
+parm 1 to (n+1): parameters coded on the HOOK macros.
+
+For conditional-return hooks:
+
+parm 0: pointer to the hook structure. This is useful if you have the
+	same exit routine registered for multiple hooks, in which case this
+	can be used to determine which hook has caused the exit routine to be
+	called. 
+parm 1: pointer to the return code (int *) to be set if a forced return of the
+	hooked routine is requested by the exit routine. 
+parm 2 to (n+2): parameters coded on the HOOK macros.
+
+If the exit function's prototype does not match the expected prototype, then
+the kernel could oops.
+
+A hook exit may itself return with the following return values:
+
+HOOK_CONTINUE - allows dispatching of other exits.
+HOOK_TERMINATE - stops further exit dispatching and returns to the hooked code.
+HOOK_RETURN - stops further exit dispatching and for conditional return hooks
+forces the hooked routine to return using parm2 as a return value.
+
+It is possible to write a hook exit function that takes variable number of
+arguments, see kexit.c for an example.
+
+Deregistering and disarming exits
+---------------------------------
+
+Exits may be disarmed and re-armed as often as like. Disarming may be done two
+ways:
+
+1) by calling hook_exit_disarm and passing a pointer to a hook record structure. 
+
+2) by turning off HOOK_ARMED in hook_flags (&=~HOOK_ARMED) from the hook exit.
+
+Exits may be de-registered by calling hook_exit_deregister and passing a 
+pointer to a hook record structure. De-registration will force disarming.
+
+WARNING!!! A kernel module must deregister its exits from its module_cleanup
+routine if that have not already been deregistered. 
+
+/proc interface
+---------------
+When Generalized Kernel Hooks is initialized, a /proc/hooks directory is 
+created. Whenever a hook exit is registered for new hook, a /proc/hooks/<hook_id> 
+subdirectory is created. Whenever a new hook exit is registered, a 
+/proc/hooks/<hook_id>/<hook_exit_name> file is created. This file is writable 
+if hook_exit_register is called with the proc_writable set to 1, otherwise, 
+it is read-only. The file name is taken from hook_exit_name if set in the 
+hook_rec_t structure. If not set, the file name is the exit's memory location. 
+This file contains a boolean value of '1' or '0' to indicate whether the exit 
+is armed or not. It may be written to independently of GKHI to arm or disarm 
+a hook exit, provided that proc_writable flag is set on registration.
+
+Reporting Problems and Discussing GKHI
+--------------------------------------
+email: dprobes@oss.software.ibm.com
+vist: http://oss.software.ibm.com/developerworks/linux
+
+For further information read the USENIX 2000 Annual Linux Showcase paper, and
+the UKUUG Linux2001 Generalised Kernel Hooks paper which may be found at
+http://oss.software.ibm.com/developerworks/linux
+
+License
+-------
+Copyright (C) 2001 IBM Corporation
+
+This program is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 2 of the License, or
+(at your option) any later version.
+
+This program is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; if not, write to the Free Software
+Foundation, Inc., 59 Temple Place - Suite 330, Boston,
+MA 02111-1307, USA.
+
+Change History
+--------------
+0.6	8th November 2000	First public drop
+1.0	14th February 2001	SMP Enablement. Slim-line hooks implemented
+				Thanks to Andrea Arcangeli for suggestions for
+				improvement.
+1.1	12th April 2001		Hooks initialised dynamically.
+				Named hooks supported.
+				Conditonal return hooks supported.
+				Support for hooks in kernel modules added.
+1.2 	3rd July 2001		Bug fixes.
+				Rewrite to confirm to kernel coding style.
+				Make it part of the kernel build process.
+				Seperate out arch-dependent and indepedent
+				parts. Arch-independent hooks and convenient
+				provision to allow arch-specific optimized
+				implementation of hooks. Updated documentation
+				and simplify the sample modules.
+1.3	20th Sept. 2001		/proc interface
+				exclusive hooks
+1.4	4th Oct. 2001		HOOK macros now take variable number of args
+				Bug fix in is_asm_hook()
Index: linux.t/Documentation/hook/Makefile
===================================================================
--- linux.t.orig/Documentation/hook/Makefile	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/Documentation/hook/Makefile	2004-05-13 10:48:24.752308624 -0400
@@ -0,0 +1 @@
+obj-m := khook.o kexit.o
Index: linux.t/Documentation/hook/kexit.c
===================================================================
--- linux.t.orig/Documentation/hook/kexit.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/Documentation/hook/kexit.c	2004-05-13 10:48:24.753308472 -0400
@@ -0,0 +1,267 @@
+/*****************************************************************************/
+/* Kernel Hooks Interface.                                                   */
+/* Author: Richard J Moore richardj_moore@uk.ibm.com                         */
+/* 	   Vamsi Krishna S. r1vamsi@in.ibm.com                               */
+/*	   Prasanna S P prasanna@in.ibm.com                                  */
+/*                                                                           */
+/* A sample kernel module registering exits for hooks defined in khook.o.    */
+/*                                                                           */
+/* Refer to Documentation/hook/HOWTO for details.                            */
+/* (C) Copyright IBM Corp. 2003                                              */
+/*****************************************************************************/
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/stddef.h>
+#include <linux/unistd.h>
+#include <linux/hook.h>
+
+extern struct hook  test_hook1;
+extern struct hook  test_hook2;
+extern struct hook  test_hook3;
+extern struct hook  test_hook4;
+extern struct hook  test_hook5;
+extern struct hook  ex_test_hook3;
+extern struct hook  ex_test_hook4;
+extern struct hook  ex_test_hook5;
+int exit1(struct hook *, int *);	/* first exit for test_hook1 */
+int exit2(struct hook *);		/* first exit for test_hook2 */
+int exit3(struct hook *, int *);	/* second exit for test_hook1 */
+int exit4(struct hook *);		/* second exit for test_hook2 */
+int exit_var0(struct hook *);
+int exit_var1(struct hook *, int);
+int exit_var2(struct hook *, int, int);
+int exit_var2_mismatch(struct hook *, int);
+
+int ex_exit_var0(struct hook *);
+int ex_exit_var1(struct hook *, int);
+int ex_exit_var2(struct hook *, int, int);
+int exit_var_args(struct hook * hook, ...);
+extern int testhook(void);
+
+struct hook_rec hook1;
+struct hook_rec hook2;
+struct hook_rec hook3;
+struct hook_rec hook4;
+struct hook_rec var0;
+struct hook_rec var1;
+struct hook_rec var2;
+struct hook_rec ex_var0;
+struct hook_rec ex_var1;
+struct hook_rec ex_var2;
+
+int init_module(void)
+{
+	int rc;
+
+	hook1.hook_exit = &exit1;
+	hook1.hook_exit_name = "exit1";
+	rc = hook_exit_register(&test_hook1, &hook1);
+	if (rc) {
+		printk("hook_exit_register exit1 for hook1 returned %u\n", rc);
+		goto err;
+	}
+
+	hook2.hook_exit = &exit2;
+	hook2.hook_exit_name = "exit2";
+	rc = hook_exit_register(&test_hook2, &hook2);
+	if (rc) { 
+		printk("hook_exit_register exit2 for hook2 returned %u\n", rc);
+		goto err1;
+	}
+
+	hook3.hook_exit = &exit3;
+	hook3.hook_exit_name = "exit3";
+	rc = hook_exit_register(&test_hook1, &hook3);
+	if (rc) {
+		goto err2;
+		printk("hook_exit_register exit3 for hook1 returned %u\n", rc);
+	}
+	hook4.hook_exit = &exit4;
+	hook4.hook_exit_name = "exit4";
+	rc = hook_exit_register(&test_hook2, &hook4);
+	if (rc) {
+		printk("hook_exit_register exit4 for hook2 returned %u\n", rc);
+	 	goto err3;
+	}
+
+	var0.hook_exit = &exit_var0;
+	rc = hook_exit_register(&test_hook3, &var0);
+	if (rc) goto err4;
+
+	var1.hook_exit = &exit_var1;
+	rc = hook_exit_register(&test_hook4, &var1);
+	if (rc) goto err5;
+
+	var2.hook_exit = &exit_var2_mismatch;
+	rc = hook_exit_register(&test_hook5, &var2);
+	if (rc) goto err6;
+	ex_var0.hook_exit = &ex_exit_var0;
+	rc = hook_exit_register(&ex_test_hook3, &ex_var0);
+	if (rc) goto err7;
+
+	ex_var1.hook_exit = &ex_exit_var1;
+	rc = hook_exit_register(&ex_test_hook4, &ex_var1);
+	if (rc) goto err8;
+
+	ex_var2.hook_exit = exit_var_args;
+	rc = hook_exit_register(&ex_test_hook5, &ex_var2);
+	if (rc) goto err9;
+	printk("hook exits are registered, but not yet armed.\n");
+
+	testhook();
+
+	hook_exit_arm(&hook1);
+	hook_exit_arm(&hook2);
+	hook_exit_arm(&hook3);
+	hook_exit_arm(&hook4);
+	hook_exit_arm(&var0);
+	hook_exit_arm(&var1);
+	hook_exit_arm(&var2);
+	hook_exit_arm(&ex_var0);
+	hook_exit_arm(&ex_var1);
+	hook_exit_arm(&ex_var2);
+
+	printk("hook exit are now armed.\n");
+
+	testhook();
+
+	printk("disarming exit1 only\n");
+	hook_exit_disarm(&hook1);
+
+	testhook();
+
+	printk("disarming exit2 only\n");
+	hook_exit_disarm(&hook2);
+
+	testhook();
+	return 0;
+	
+err9:	hook_exit_deregister(&ex_var1);
+err8:	hook_exit_deregister(&ex_var0);
+err7:	hook_exit_deregister(&var2);
+err6:	hook_exit_deregister(&var1);
+err5:	hook_exit_deregister(&var0);
+err4:	hook_exit_deregister(&hook4);
+err3:	hook_exit_deregister(&hook3);
+err2:	hook_exit_deregister(&hook2);
+err1:	hook_exit_deregister(&hook1);
+err: 	return rc;
+}
+
+void cleanup_module(void)
+{
+	/* deregister all hook exits*/
+	hook_exit_deregister(&ex_var2);
+	hook_exit_deregister(&ex_var1);
+	hook_exit_deregister(&ex_var0);
+	hook_exit_deregister(&var2);
+	hook_exit_deregister(&var1);
+	hook_exit_deregister(&var0);
+	hook_exit_deregister(&hook4);
+	hook_exit_deregister(&hook3);
+	hook_exit_deregister(&hook2);
+	hook_exit_deregister(&hook1);
+
+	printk("deregistered all hook exits.\n");
+
+	testhook();
+
+	return;
+}
+
+/* exit1 exit to test_hook1 */
+int exit1(struct hook * hook, int *rc)
+{
+	printk("exit1: hook exit1 entered, indicate for testhook to return immediately\n");
+	*rc = 0;
+	printk("exit1: hook exit1 exiting\n");
+	return HOOK_RETURN;
+}
+
+/* exit2 exit to test_hook2 */
+int exit2(struct hook * hook)
+{
+	printk("exit2: hook exit2 entered\n");
+	printk("exit2: hook exit2 exiting\n");
+	return HOOK_CONTINUE;
+}
+
+/* exit3 exit to test_hook1 */
+int exit3(struct hook * hook, int *rc)
+{
+	printk("exit3: hook exit3 entered, allow testhook to continue\n");
+	*rc = 0;
+	printk("exit3: hook exit3 exiting\n");
+	return HOOK_CONTINUE;
+}
+
+/* exit4 exit to test_hook2 */
+int exit4(struct hook * hook)
+{
+	printk("exit4: hook exit4 entered\n");
+	printk("exit4: hook exit4 exiting\n");
+	return HOOK_CONTINUE;
+}
+
+int exit_var0(struct hook *h)
+{
+	printk("exit_var0: entered\n");
+	printk("exit_var0: exiting\n");
+	return HOOK_CONTINUE;
+}
+int exit_var1(struct hook *h, int i)
+{
+	printk("exit_var1: entered, %x\n", i);
+	printk("exit_var1: exiting\n");
+	return HOOK_CONTINUE;
+}
+int exit_var2(struct hook *h, int i, int j)
+{
+	printk("exit_var2: entered %x, %x\n", i, j);
+	printk("exit_var2: exiting\n");
+	return HOOK_CONTINUE;
+}
+
+int exit_var2_mismatch(struct hook *h, int i)
+{
+	printk("exit_var2: entered using only the first arg: %x\n", i);
+	printk("exit_var2: exiting\n");
+	return HOOK_CONTINUE;
+}
+
+int ex_exit_var0(struct hook *h)
+{
+	printk("ex_exit_var0: entered %s\n", h->hook_id);
+	printk("ex_exit_var0: exiting\n");
+	return HOOK_CONTINUE;
+}
+int ex_exit_var1(struct hook *h, int i)
+{
+	printk("ex_exit_var1: entered, %x\n", i);
+	printk("ex_exit_var1: exiting\n");
+	return HOOK_CONTINUE;
+}
+int ex_exit_var2(struct hook *h, int i, int j)
+{
+	printk("ex_exit_var2: entered %x, %x\n", i, j);
+	printk("ex_exit_var2: exiting\n");
+	return HOOK_CONTINUE;
+}
+
+int exit_var_args(struct hook * hook, ...)
+{
+	va_list args;
+	char buf[80];
+	char *fmt;
+	printk("exit_var_args: entered\n");
+	va_start(args, hook);
+	fmt = va_arg(args, char *);
+	vsprintf(buf, fmt, args);
+	printk("vsprintf output=%s\n", buf);
+	va_end(args);
+	printk("exit_var_args: exiting\n");
+	return HOOK_CONTINUE;
+}
+MODULE_LICENSE("GPL");
Index: linux.t/Documentation/hook/khook.c
===================================================================
--- linux.t.orig/Documentation/hook/khook.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/Documentation/hook/khook.c	2004-05-13 10:48:24.754308320 -0400
@@ -0,0 +1,72 @@
+/****************************************************************************/
+/* Kernel Hooks Interface.                                    		    */
+/* Author: Richard J Moore richardj_moore@uk.ibm.com                        */
+/* 	   Vamsi Krishna S. r1vamsi@in.ibm.com 				    */
+/*	   Prasanna S P prasanna@in.ibm.com                                 */
+/*                                                                          */
+/* A sample kernel module with hooks in it (in the testhook function).      */
+/*                                                                          */
+/*  (C) Copyright IBM Corp. 2003                                            */
+/* Refer to Documentation/hook/HOWTO for details.                           */
+/****************************************************************************/
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/stddef.h>
+#include <linux/unistd.h>
+#include <linux/hook.h>
+
+#define TEST_HOOK1 test_hook1
+#define TEST_HOOK2 test_hook2
+#define TEST_HOOK3 test_hook3
+#define TEST_HOOK4 test_hook4
+#define TEST_HOOK5 test_hook5
+#define EX_TEST_HOOK3 ex_test_hook3
+#define EX_TEST_HOOK4 ex_test_hook4
+#define EX_TEST_HOOK5 ex_test_hook5
+
+DECLARE_HOOK(TEST_HOOK1);
+DECLARE_HOOK(TEST_HOOK2);
+DECLARE_HOOK(TEST_HOOK3);
+DECLARE_HOOK(TEST_HOOK4);
+DECLARE_HOOK(TEST_HOOK5);
+DECLARE_EXCLUSIVE_HOOK(EX_TEST_HOOK3);
+DECLARE_EXCLUSIVE_HOOK(EX_TEST_HOOK4);
+DECLARE_EXCLUSIVE_HOOK(EX_TEST_HOOK5);
+
+int init_module(void)
+{
+	printk("now load kexit.o to test the hook(s)\n");
+	return 0;
+}
+
+void cleanup_module(void)
+{
+
+	return;
+}
+
+/*
+ * this is an example of how the hooks would be coded in the kernel or a
+ * kernel module.
+ */
+int testhook(void)
+{
+	printk("testhook entered\n");
+	
+	HOOK_RET(TEST_HOOK1);
+	HOOK(TEST_HOOK2);
+
+	HOOK(TEST_HOOK3);
+	HOOK(TEST_HOOK4, 4);
+	HOOK(TEST_HOOK5, 5, 0);
+	EXCLUSIVE_HOOK(EX_TEST_HOOK3);
+	EXCLUSIVE_HOOK(EX_TEST_HOOK4, 4);
+	EXCLUSIVE_HOOK(EX_TEST_HOOK5, "%s, %d", "test_hook3", 1);
+	printk("testhook exited\n");
+	return 0;
+}
+
+EXPORT_SYMBOL_NOVERS(testhook);
+MODULE_LICENSE("GPL");
Index: linux.t/arch/alpha/Kconfig
===================================================================
--- linux.t.orig/arch/alpha/Kconfig	2004-05-13 10:44:58.220706200 -0400
+++ linux.t/arch/alpha/Kconfig	2004-05-13 10:48:24.756308016 -0400
@@ -691,6 +691,38 @@
 	  Say Y here only if you plan to use gdb to debug the kernel.
 	  If you don't debug the kernel, you can say N.
 
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/arm/Kconfig
===================================================================
--- linux.t.orig/arch/arm/Kconfig	2004-05-13 10:44:58.266699208 -0400
+++ linux.t/arch/arm/Kconfig	2004-05-13 10:48:24.758307712 -0400
@@ -736,6 +736,45 @@
 	  output to the second serial port on these devices.  Saying N will
 	  cause the debug messages to appear on the first serial port.
 
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
+config TRIGEVENT_SYSCALL_HOOK
+	bool " Enable syscall entry/exit hooks"
+	depends on TRIGEVENT_HOOKS
+	help 
+	RAS hooks to enable tracing of system call entry and exit points.
+	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/arm/kernel/entry-common.S
===================================================================
--- linux.t.orig/arch/arm/kernel/entry-common.S	2004-01-09 01:59:04.000000000 -0500
+++ linux.t/arch/arm/kernel/entry-common.S	2004-05-13 10:48:24.890287648 -0400
@@ -39,6 +39,11 @@
  */
 ret_fast_syscall:
 	disable_irq r1				@ disable interrupts
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	mov	r7, r0				@ save returned r0
+	bl	SYMBOL_NAME(post_syscall)
+	mov	r0, r7
+#endif
 	ldr	r1, [tsk, #TI_FLAGS]
 	tst	r1, #_TIF_WORK_MASK
 	bne	fast_work_pending
@@ -136,6 +141,15 @@
 #endif
 	enable_irq ip
 
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	/* zzz note that validity of scno is not yet checked.
+	 * zzz The visualizer checks it.
+	 */
+	add	r0, sp, #S_R0			@ pointer to regs
+	bl	SYMBOL_NAME(pre_syscall)
+	add	r0, sp, #S_R0			@ pointer to regs
+	ldmia	r1, {r0 - r3}			@ have to reload r0 - r3
+#endif
 	str	r4, [sp, #-S_OFF]!		@ push fifth arg
 
 	get_thread_info tsk
@@ -175,6 +189,9 @@
 
 __sys_trace_return:
 	str	r0, [sp, #S_R0 + S_OFF]!	@ save returned r0
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	bl	SYMBOL_NAME(post_syscall)
+#endif
 	mov	r1, sp
 	mov	r0, #1				@ trace exit [IP = 1]
 	bl	syscall_trace
Index: linux.t/arch/arm/kernel/irq.c
===================================================================
--- linux.t.orig/arch/arm/kernel/irq.c	2004-03-12 16:27:13.000000000 -0500
+++ linux.t/arch/arm/kernel/irq.c	2004-05-13 10:48:24.895286888 -0400
@@ -32,6 +32,7 @@
 #include <linux/errno.h>
 #include <linux/list.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/irq.h>
 #include <asm/system.h>
@@ -447,6 +448,7 @@
 {
 	struct irqdesc *desc = irq_desc + irq;
 
+	TRIG_EVENT(irq_entry_hook, irq, regs, !(user_mode(regs)));
 	/*
 	 * Some hardware gives randomly wrong interrupts.  Rather
 	 * than crashing, do something sensible.
@@ -466,6 +468,7 @@
 
 	spin_unlock(&irq_controller_lock);
 	irq_exit();
+	TRIG_EVENT(irq_exit_hook, irq, regs);
 }
 
 void __set_irq_handler(unsigned int irq, irq_handler_t handle, int is_chained)
Index: linux.t/arch/arm/kernel/process.c
===================================================================
--- linux.t.orig/arch/arm/kernel/process.c	2004-02-18 22:22:28.000000000 -0500
+++ linux.t/arch/arm/kernel/process.c	2004-05-13 10:48:24.896286736 -0400
@@ -399,6 +399,7 @@
 pid_t kernel_thread(int (*fn)(void *), void *arg, unsigned long flags)
 {
 	struct pt_regs regs;
+	int ret = 0;
 
 	memset(&regs, 0, sizeof(regs));
 
@@ -408,7 +409,13 @@
 	regs.ARM_pc = (unsigned long)kernel_thread_helper;
 	regs.ARM_cpsr = SVC_MODE;
 
-	return do_fork(flags|CLONE_VM|CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
+	ret = do_fork(flags|CLONE_VM|CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	if (ret > 0)
+		TRIG_EVENT(kthread_hook, ret, (int) fn);
+#endif
+
+	return  ret;
 }
 
 /*
Index: linux.t/arch/arm/kernel/sys_arm.c
===================================================================
--- linux.t.orig/arch/arm/kernel/sys_arm.c	2004-04-05 10:56:30.000000000 -0400
+++ linux.t/arch/arm/kernel/sys_arm.c	2004-05-13 10:48:24.899286280 -0400
@@ -25,6 +25,7 @@
 #include <linux/fs.h>
 #include <linux/file.h>
 #include <linux/utsname.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
@@ -166,6 +167,7 @@
 
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
+	TRIG_EVENT(ipc_call_hook, call, first);
 
 	switch (call) {
 	case SEMOP:
Index: linux.t/arch/arm/kernel/traps.c
===================================================================
--- linux.t.orig/arch/arm/kernel/traps.c	2004-04-05 10:56:30.000000000 -0400
+++ linux.t/arch/arm/kernel/traps.c	2004-05-13 10:48:24.903285672 -0400
@@ -26,6 +26,7 @@
 #include <linux/interrupt.h>
 #include <linux/kallsyms.h>
 #include <linux/init.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/atomic.h>
 #include <asm/io.h>
@@ -313,8 +314,10 @@
 	info.si_code  = ILL_ILLOPC;
 	info.si_addr  = pc;
 
+	TRIG_EVENT(trap_entry_hook, current->thread.trap_no, (uint32_t)pc);
 	force_sig_info(SIGILL, &info, current);
 
+	TRIG_EVENT(trap_exit_hook);
 	die_if_kernel("Oops - undefined instruction", regs, 0);
 }
 
@@ -427,7 +430,9 @@
 
 	case NR(breakpoint): /* SWI BREAK_POINT */
 		regs->ARM_pc -= thumb_mode(regs) ? 2 : 4;
+		TRIG_EVENT(trap_entry_hook, 1, (uint32_t)regs->ARM_pc);
 		ptrace_break(current, regs);
+		TRIG_EVENT(trap_exit_hook);
 		return regs->ARM_r0;
 
 	/*
@@ -526,7 +531,9 @@
 	info.si_code  = ILL_ILLOPC;
 	info.si_addr  = (void *)addr;
 
+	TRIG_EVENT(trap_entry_hook, 18, addr);	/* machine check */
 	force_sig_info(SIGILL, &info, current);
+	TRIG_EVENT(trap_exit_hook);
 	die_if_kernel("unknown data abort code", regs, instr);
 }
 
Index: linux.t/arch/arm/mm/fault-common.c
===================================================================
--- linux.t.orig/arch/arm/mm/fault-common.c	2004-04-05 10:56:30.000000000 -0400
+++ linux.t/arch/arm/mm/fault-common.c	2004-05-13 10:48:24.913284152 -0400
@@ -17,6 +17,7 @@
 #include <linux/mm.h>
 #include <linux/interrupt.h>
 #include <linux/init.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
 #include <asm/pgtable.h>
@@ -247,6 +248,7 @@
 	if (in_interrupt() || !mm)
 		goto no_context;
 
+	TRIG_EVENT(trap_entry_hook, 14, instruction_pointer(regs));
 	down_read(&mm->mmap_sem);
 	fault = __do_page_fault(mm, addr, fsr, tsk);
 	up_read(&mm->mmap_sem);
@@ -254,8 +256,10 @@
 	/*
 	 * Handle the "normal" case first
 	 */
-	if (fault > 0)
+	if (fault > 0) {
+		TRIG_EVENT(trap_exit_hook);
 		return 0;
+	}
 
 	/*
 	 * We had some memory, but were unable to
@@ -281,6 +285,7 @@
 	} else
 		__do_user_fault(tsk, addr, fsr, fault == -1 ?
 				SEGV_ACCERR : SEGV_MAPERR, regs);
+	TRIG_EVENT(trap_exit_hook);
 	return 0;
 
 
@@ -305,11 +310,14 @@
 #endif
 
 	/* Kernel mode? Handle exceptions or die */
-	if (user_mode(regs))
+	if (user_mode(regs)) {
+		TRIG_EVENT(trap_exit_hook);
 		return 0;
+	}
 
 no_context:
 	__do_kernel_fault(mm, addr, fsr, regs);
+	TRIG_EVENT(trap_exit_hook);
 	return 0;
 }
 
Index: linux.t/arch/cris/Kconfig
===================================================================
--- linux.t.orig/arch/cris/Kconfig	2004-05-13 10:44:58.333689024 -0400
+++ linux.t/arch/cris/Kconfig	2004-05-13 10:48:24.914284000 -0400
@@ -212,6 +212,37 @@
 	depends on PROFILE
 	default "2"
 
+config HOOK
+	tristate "Kernel Hook support"
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/i386/Kconfig
===================================================================
--- linux.t.orig/arch/i386/Kconfig	2004-05-13 10:45:17.603759528 -0400
+++ linux.t/arch/i386/Kconfig	2004-05-13 10:48:24.917283544 -0400
@@ -1459,6 +1459,78 @@
 	depends on X86_LOCAL_APIC && !X86_VISWS
 	default y
 
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config ASM_HOOK
+	bool
+	default y
+	depends on DEBUG_KERNEL && HOOK
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+	
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
+config TRIGEVENT_SYSCALL_HOOK
+	bool " Enable syscall entry/exit hooks"
+	depends on TRIGEVENT_HOOKS
+	help 
+	RAS hooks to enable tracing of system call entry and exit points.
+	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
+
+config LTT
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	select RELAYFS_FS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/i386/kernel/apic.c
===================================================================
--- linux.t.orig/arch/i386/kernel/apic.c	2004-05-13 10:45:11.833636720 -0400
+++ linux.t/arch/i386/kernel/apic.c	2004-05-13 10:48:24.919283240 -0400
@@ -26,6 +26,7 @@
 #include <linux/mc146818rtc.h>
 #include <linux/kernel_stat.h>
 #include <linux/sysdev.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/atomic.h>
 #include <asm/smp.h>
@@ -1072,6 +1073,7 @@
 		}
 
 #ifdef CONFIG_SMP
+		TRIG_EVENT(timer_hook, regs);
 		update_process_times(user_mode(regs));
 #endif
 	}
Index: linux.t/arch/i386/kernel/entry.S
===================================================================
--- linux.t.orig/arch/i386/kernel/entry.S	2004-05-13 10:44:19.384610184 -0400
+++ linux.t/arch/i386/kernel/entry.S	2004-05-13 10:48:24.921282936 -0400
@@ -302,9 +302,29 @@
 	testb $_TIF_SYSCALL_TRACE,TI_FLAGS(%ebp)
 	jnz syscall_trace_entry
 syscall_call:
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	movl pre_syscall_enabled, %eax
+	testl %eax, %eax
+	jz pre_syscall_done
+	movl %esp, %eax                 # copy the stack pointer
+	pushl %eax                      # pass the stack pointer copy
+	call pre_syscall
+	addl $4,%esp                    # return stack to state before pass
+pre_syscall_done:
+	movl ORIG_EAX(%esp),%eax	# restore eax to it's original content
+#endif
 	call *sys_call_table(,%eax,4)
 	movl %eax,EAX(%esp)		# store the return value
 syscall_exit:
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	pushl %ebx
+	movl post_syscall_enabled, %eax
+	testl %eax, %eax                   # are we tracing system call exits
+	jz post_syscall_done
+	call post_syscall
+post_syscall_done:
+	popl %ebx	
+#endif
 	cli				# make sure we don't miss an interrupt
 					# setting need_resched or sigpending
 					# between sampling and the iret
Index: linux.t/arch/i386/kernel/irq.c
===================================================================
--- linux.t.orig/arch/i386/kernel/irq.c	2004-03-12 16:27:13.000000000 -0500
+++ linux.t/arch/i386/kernel/irq.c	2004-05-13 10:48:24.931281416 -0400
@@ -34,6 +34,7 @@
 #include <linux/proc_fs.h>
 #include <linux/seq_file.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/atomic.h>
 #include <asm/io.h>
@@ -219,6 +220,7 @@
 	int status = 1;	/* Force the "do bottom halves" bit */
 	int retval = 0;
 
+	TRIG_EVENT(irq_entry_hook, irq, regs, !(user_mode(regs)));
 	if (!(action->flags & SA_INTERRUPT))
 		local_irq_enable();
 
@@ -230,6 +232,7 @@
 	if (status & SA_SAMPLE_RANDOM)
 		add_interrupt_randomness(irq);
 	local_irq_disable();
+	TRIG_EVENT(irq_exit_hook, irq, regs);
 	return retval;
 }
 
Index: linux.t/arch/i386/kernel/process.c
===================================================================
--- linux.t.orig/arch/i386/kernel/process.c	2004-05-13 10:44:06.346592264 -0400
+++ linux.t/arch/i386/kernel/process.c	2004-05-13 10:48:24.932281264 -0400
@@ -36,6 +36,7 @@
 #include <linux/module.h>
 #include <linux/kallsyms.h>
 #include <linux/ptrace.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/pgtable.h>
@@ -267,6 +268,7 @@
 int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags)
 {
 	struct pt_regs regs;
+	int ret = 0;
 
 	memset(&regs, 0, sizeof(regs));
 
@@ -281,7 +283,12 @@
 	regs.eflags = 0x286;
 
 	/* Ok, create the new process.. */
-	return do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
+	ret = do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	if (ret > 0)
+		TRIG_EVENT(kthread_hook, ret, (int) fn);
+#endif
+	return  ret;
 }
 
 /*
Index: linux.t/arch/i386/kernel/sys_i386.c
===================================================================
--- linux.t.orig/arch/i386/kernel/sys_i386.c	2004-05-13 10:45:18.500623184 -0400
+++ linux.t/arch/i386/kernel/sys_i386.c	2004-05-13 10:48:24.934280960 -0400
@@ -20,6 +20,7 @@
 #include <linux/file.h>
 #include <linux/utsname.h>
 #include <linux/fshooks.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
@@ -149,6 +150,7 @@
 
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
+	TRIG_EVENT(ipc_call_hook, call, first);
 
 	switch (call) {
 	case SEMOP:
Index: linux.t/arch/i386/kernel/traps.c
===================================================================
--- linux.t.orig/arch/i386/kernel/traps.c	2004-05-13 10:45:00.071424848 -0400
+++ linux.t/arch/i386/kernel/traps.c	2004-05-13 10:48:24.936280656 -0400
@@ -32,6 +32,7 @@
 #include <linux/ioport.h>
 #include <linux/eisa.h>
 #endif
+#include <linux/trigevent_hooks.h>
 
 #ifdef CONFIG_MCA
 #include <linux/mca.h>
@@ -327,6 +328,7 @@
 static inline void do_trap(int trapnr, int signr, char *str, int vm86,
 			   struct pt_regs * regs, long error_code, siginfo_t *info)
 {
+	TRIG_EVENT(trap_entry_hook, trapnr, regs->eip);
 	if (regs->eflags & VM_MASK) {
 		if (vm86)
 			goto vm86_trap;
@@ -344,20 +346,24 @@
 			force_sig_info(signr, info, tsk);
 		else
 			force_sig(signr, tsk);
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
 
 	kernel_trap: {
 		if (!fixup_exception(regs))
 			die(str, regs, error_code);
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
 
 	vm86_trap: {
 		int ret = handle_vm86_trap((struct kernel_vm86_regs *) regs, error_code, trapnr);
 		if (ret) goto trap_signal;
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
+	TRIG_EVENT(trap_exit_hook);
 }
 
 #define DO_ERROR(trapnr, signr, str, name) \
@@ -420,12 +426,16 @@
 
 	current->thread.error_code = error_code;
 	current->thread.trap_no = 13;
+	TRIG_EVENT(trap_entry_hook, 13, regs->eip);
 	force_sig(SIGSEGV, current);
+	TRIG_EVENT(trap_exit_hook);
 	return;
 
 gp_in_vm86:
 	local_irq_enable();
+	TRIG_EVENT(trap_entry_hook, 13, regs->eip);
 	handle_vm86_fault((struct kernel_vm86_regs *) regs, error_code);
+	TRIG_EVENT(trap_exit_hook);
 	return;
 
 gp_in_kernel:
@@ -535,6 +545,10 @@
 {
 	int cpu;
 
+#ifndef CONFIG_X86_LOCAL_APIC /* On an machine with APIC enabled NMIs are used to implement a
+				watchdog and will hang the machine if traced. */
+	TRIG_EVENT(trap_entry_hook, 2, regs->eip);
+#endif
 	nmi_enter();
 
 	cpu = smp_processor_id();
@@ -544,6 +558,7 @@
 		default_do_nmi(regs);
 
 	nmi_exit();
+	TRIG_EVENT(trap_exit_hook);
 }
 
 void set_nmi_callback(nmi_callback_t callback)
@@ -636,7 +651,9 @@
 	 */
 	info.si_addr = ((regs->xcs & 3) == 0) ? (void *)tsk->thread.eip : 
 	                                        (void *)regs->eip;
+        TRIG_EVENT(trap_entry_hook, 1, regs->eip);
 	force_sig_info(SIGTRAP, &info, tsk);
+        TRIG_EVENT(trap_exit_hook);
 
 	/* Disable additional traps. They'll be re-enabled when
 	 * the signal is delivered.
@@ -648,7 +665,9 @@
 	return;
 
 debug_vm86:
+        TRIG_EVENT(trap_entry_hook, 1, regs->eip);
 	handle_vm86_trap((struct kernel_vm86_regs *) regs, error_code, 1);
+        TRIG_EVENT(trap_exit_hook);
 	return;
 
 clear_TF_reenable:
@@ -810,10 +829,12 @@
 asmlinkage void do_spurious_interrupt_bug(struct pt_regs * regs,
 					  long error_code)
 {
+        TRIG_EVENT(trap_entry_hook, 16, regs->eip);
 #if 0
 	/* No need to warn about this any longer. */
 	printk("Ignoring P6 Local APIC Spurious Interrupt Bug...\n");
 #endif
+        TRIG_EVENT(trap_exit_hook);	
 }
 
 /*
@@ -844,8 +865,10 @@
 {
 	printk("math-emulation not enabled and no coprocessor found.\n");
 	printk("killing %s.\n",current->comm);
+        TRIG_EVENT(trap_entry_hook, 7, 0);
 	force_sig(SIGFPE,current);
 	schedule();
+        TRIG_EVENT(trap_exit_hook);
 }
 
 #endif /* CONFIG_MATH_EMULATION */
@@ -878,6 +901,7 @@
 } while (0)
 
 
+
 /*
  * This needs to use 'idt_table' rather than 'idt', and
  * thus use the _nonmapped_ version of the IDT, as the
Index: linux.t/arch/i386/mm/fault.c
===================================================================
--- linux.t.orig/arch/i386/mm/fault.c	2004-01-09 01:59:02.000000000 -0500
+++ linux.t/arch/i386/mm/fault.c	2004-05-13 10:48:24.942279744 -0400
@@ -21,6 +21,7 @@
 #include <linux/vt_kern.h>		/* For unblank_screen() */
 #include <linux/highmem.h>
 #include <linux/module.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
@@ -253,6 +254,7 @@
 		goto bad_area_nosemaphore;
 	} 
 
+	TRIG_EVENT(trap_entry_hook, 14, regs->eip);
 	mm = tsk->mm;
 
 	/*
@@ -339,6 +341,7 @@
 			tsk->thread.screen_bitmap |= 1 << bit;
 	}
 	up_read(&mm->mmap_sem);
+        TRIG_EVENT(trap_exit_hook);
 	return;
 
 /*
@@ -355,8 +358,10 @@
 		 * Valid to do another page fault here because this one came 
 		 * from user space.
 		 */
-		if (is_prefetch(regs, address))
+		if (is_prefetch(regs, address)) {
+			TRIG_EVENT(trap_exit_hook);
 			return;
+		}
 
 		tsk->thread.cr2 = address;
 		/* Kernel addresses are always protection faults */
@@ -367,6 +372,7 @@
 		/* info.si_code has been set above */
 		info.si_addr = (void *)address;
 		force_sig_info(SIGSEGV, &info, tsk);
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
 
@@ -381,6 +387,7 @@
 
 		if (nr == 6) {
 			do_invalid_op(regs, 0);
+			TRIG_EVENT(trap_exit_hook);
 			return;
 		}
 	}
@@ -388,17 +395,20 @@
 
 no_context:
 	/* Are we prepared to handle this kernel fault?  */
-	if (fixup_exception(regs))
+	if (fixup_exception(regs)) {
+		TRIG_EVENT(trap_exit_hook);
 		return;
+	}
 
 	/* 
 	 * Valid to do another page fault here, because if this fault
 	 * had been triggered by is_prefetch fixup_exception would have 
 	 * handled it.
 	 */
- 	if (is_prefetch(regs, address))
+ 	if (is_prefetch(regs, address)) {
+		TRIG_EVENT(trap_exit_hook);
  		return;
-
+	}
 /*
  * Oops. The kernel tried to access some bad page. We'll have to
  * terminate things with extreme prejudice.
@@ -458,8 +468,10 @@
 		goto no_context;
 
 	/* User space => ok to do another page fault */
-	if (is_prefetch(regs, address))
+	if (is_prefetch(regs, address)) {
+		TRIG_EVENT(trap_exit_hook);
 		return;
+	}
 
 	tsk->thread.cr2 = address;
 	tsk->thread.error_code = error_code;
@@ -469,6 +481,7 @@
 	info.si_code = BUS_ADRERR;
 	info.si_addr = (void *)address;
 	force_sig_info(SIGBUS, &info, tsk);
+	TRIG_EVENT(trap_exit_hook);
 	return;
 
 vmalloc_fault:
@@ -506,6 +519,9 @@
 		pte_k = pte_offset_kernel(pmd_k, address);
 		if (!pte_present(*pte_k))
 			goto no_context;
+		TRIG_EVENT(trap_entry_hook, 14, regs->eip);
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
+	TRIG_EVENT(trap_exit_hook);
 }
Index: linux.t/arch/ia64/Kconfig
===================================================================
--- linux.t.orig/arch/ia64/Kconfig	2004-05-13 10:44:58.343687504 -0400
+++ linux.t/arch/ia64/Kconfig	2004-05-13 10:48:24.944279440 -0400
@@ -614,6 +614,39 @@
 	bool
 	depends on COMPAT && SYSVIPC
 	default y
+
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/ia64/kernel/process.c
===================================================================
--- linux.t.orig/arch/ia64/kernel/process.c	2004-04-05 10:56:31.000000000 -0400
+++ linux.t/arch/ia64/kernel/process.c	2004-05-13 10:48:24.951278376 -0400
@@ -22,6 +22,7 @@
 #include <linux/thread_info.h>
 #include <linux/unistd.h>
 #include <linux/efi.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/delay.h>
 #include <asm/elf.h>
@@ -585,6 +586,7 @@
 {
 	extern void start_kernel_thread (void);
 	unsigned long *helper_fptr = (unsigned long *) &start_kernel_thread;
+	pid_t ret;
 	struct {
 		struct switch_stack sw;
 		struct pt_regs pt;
@@ -601,7 +603,13 @@
 	regs.sw.ar_fpsr = regs.pt.ar_fpsr = ia64_getreg(_IA64_REG_AR_FPSR);
 	regs.sw.ar_bspstore = (unsigned long) current + IA64_RBS_OFFSET;
 
-	return do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs.pt, 0, NULL, NULL);
+	ret = do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs.pt, 0, NULL, NULL);
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	if (ret > 0)
+		TRIG_EVENT(kthread_hook, ret, (unsigned long) fn);
+#endif
+
+	return  ret;
 }
 EXPORT_SYMBOL(kernel_thread);
 
Index: linux.t/arch/ia64/kernel/time.c
===================================================================
--- linux.t.orig/arch/ia64/kernel/time.c	2004-04-05 10:56:31.000000000 -0400
+++ linux.t/arch/ia64/kernel/time.c	2004-05-13 10:48:24.961276856 -0400
@@ -20,6 +20,7 @@
 #include <linux/efi.h>
 #include <linux/profile.h>
 #include <linux/timex.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/machvec.h>
 #include <asm/delay.h>
@@ -261,6 +262,7 @@
 		 * fixing that would require updates to all
 		 * platforms.
 		 */
+		TRIG_EVENT(timer_hook, regs);
 		update_process_times(user_mode(regs));
 #endif
 		new_itm += local_cpu_data->itm_delta;
Index: linux.t/arch/m68k/Kconfig
===================================================================
--- linux.t.orig/arch/m68k/Kconfig	2004-05-13 10:44:58.452670936 -0400
+++ linux.t/arch/m68k/Kconfig	2004-05-13 10:48:24.963276552 -0400
@@ -688,6 +688,38 @@
 	  Say Y here only if you plan to use gdb to debug the kernel.
 	  If you don't debug the kernel, you can say N.
 	  
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/mips/Kconfig
===================================================================
--- linux.t.orig/arch/mips/Kconfig	2004-04-05 10:56:31.000000000 -0400
+++ linux.t/arch/mips/Kconfig	2004-05-13 10:48:24.974274880 -0400
@@ -1531,6 +1531,45 @@
 	bool "Highmem debugging"
 	depends on DEBUG_KERNEL && HIGHMEM
 
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
+config TRIGEVENT_SYSCALL_HOOK
+	bool " Enable syscall entry/exit hooks"
+	depends on TRIGEVENT_HOOKS
+	help 
+	RAS hooks to enable tracing of system call entry and exit points.
+	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/mips/baget/irq.c
===================================================================
--- linux.t.orig/arch/mips/baget/irq.c	2004-01-09 01:59:45.000000000 -0500
+++ linux.t/arch/mips/baget/irq.c	2004-05-13 10:48:24.982273664 -0400
@@ -18,6 +18,7 @@
 #include <linux/slab.h>
 #include <linux/random.h>
 #include <linux/delay.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/bitops.h>
 #include <asm/bootinfo.h>
@@ -182,6 +183,7 @@
 	struct irqaction *action;
 	int do_random, cpu;
 
+	TRIG_EVENT(irq_entry_hook, irq, regs, !user_mode(regs));
 	cpu = smp_processor_id();
 	irq_enter();
 	kstat_cpus(cpu).irqs[irq]++;
@@ -207,6 +209,7 @@
 	unmask_irq(irq);
 	irq_exit();
 
+	TRIG_EVENT(irq_exit_hook, irq, regs);
 	/* unmasking and bottom half handling is done magically for us. */
 }
 
Index: linux.t/arch/mips/kernel/i8259.c
===================================================================
--- linux.t.orig/arch/mips/kernel/i8259.c	2004-03-12 16:27:15.000000000 -0500
+++ linux.t/arch/mips/kernel/i8259.c	2004-05-13 10:48:24.988272752 -0400
@@ -15,6 +15,7 @@
 #include <linux/kernel.h>
 #include <linux/spinlock.h>
 #include <linux/sysdev.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/i8259.h>
 #include <asm/io.h>
Index: linux.t/arch/mips/kernel/irq.c
===================================================================
--- linux.t.orig/arch/mips/kernel/irq.c	2004-03-12 16:27:15.000000000 -0500
+++ linux.t/arch/mips/kernel/irq.c	2004-05-13 10:48:24.999271080 -0400
@@ -22,6 +22,7 @@
 #include <linux/sched.h>
 #include <linux/seq_file.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/atomic.h>
 #include <asm/system.h>
@@ -352,6 +353,7 @@
 	struct irqaction * action;
 	unsigned int status;
 
+	TRIG_EVENT(irq_entry_hook, irq, regs, !user_mode(regs));
 	irq_enter();
 	kstat_this_cpu.irqs[irq]++;
 	spin_lock(&desc->lock);
@@ -417,6 +419,7 @@
 	spin_unlock(&desc->lock);
 
 	irq_exit();
+	TRIG_EVENT(irq_exit_hook, irq, regs);
 
 	return 1;
 }
Index: linux.t/arch/mips/kernel/process.c
===================================================================
--- linux.t.orig/arch/mips/kernel/process.c	2004-03-12 16:27:15.000000000 -0500
+++ linux.t/arch/mips/kernel/process.c	2004-05-13 10:48:25.006270016 -0400
@@ -23,6 +23,7 @@
 #include <linux/a.out.h>
 #include <linux/init.h>
 #include <linux/completion.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/bootinfo.h>
 #include <asm/cpu.h>
@@ -187,6 +188,10 @@
 		: "$2", "$3", "$4", "$5", "$6", "$7", "$8",
 		  "$9","$10","$11","$12","$13","$14","$15","$24","$25","$31");
 
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	if (retval > 0)
+		TRIG_EVENT(kthread_hook, retval, (int) fn);
+#endif
 	return retval;
 }
 
Index: linux.t/arch/mips/kernel/time.c
===================================================================
--- linux.t.orig/arch/mips/kernel/time.c	2004-03-12 16:27:15.000000000 -0500
+++ linux.t/arch/mips/kernel/time.c	2004-05-13 10:48:25.015268648 -0400
@@ -24,6 +24,7 @@
 #include <linux/spinlock.h>
 #include <linux/interrupt.h>
 #include <linux/module.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/bootinfo.h>
 #include <asm/cpu.h>
@@ -551,6 +552,7 @@
 
 asmlinkage void ll_timer_interrupt(int irq, struct pt_regs *regs)
 {
+	TRIG_EVENT(irq_entry_hook, irq, regs, CAUSE_EPC(regs));
 	irq_enter();
 	kstat_this_cpu.irqs[irq]++;
 
@@ -558,6 +560,7 @@
 	timer_interrupt(irq, NULL, regs);
 
 	irq_exit();
+	TRIG_EVENT(irq_exit_hook, irq, regs);	
 }
 
 asmlinkage void ll_local_timer_interrupt(int irq, struct pt_regs *regs)
Index: linux.t/arch/mips/kernel/traps.c
===================================================================
--- linux.t.orig/arch/mips/kernel/traps.c	2004-03-12 16:27:15.000000000 -0500
+++ linux.t/arch/mips/kernel/traps.c	2004-05-13 10:48:25.018268192 -0400
@@ -20,6 +20,7 @@
 #include <linux/smp_lock.h>
 #include <linux/spinlock.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/bootinfo.h>
 #include <asm/branch.h>
@@ -36,6 +37,7 @@
 #include <asm/mmu_context.h>
 #include <asm/watch.h>
 #include <asm/types.h>
+#include <asm/unistd.h>
 
 extern asmlinkage void handle_mod(void);
 extern asmlinkage void handle_tlbl(void);
@@ -340,6 +342,7 @@
 	int data = regs->cp0_cause & 4;
 	int action = MIPS_BE_FATAL;
 
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	/* XXX For now.  Fixme, this searches the wrong table ...  */
 	if (data && !user_mode(regs))
 		fixup = search_dbe_tables(exception_epc(regs));
@@ -352,10 +355,12 @@
 
 	switch (action) {
 	case MIPS_BE_DISCARD:
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	case MIPS_BE_FIXUP:
 		if (fixup) {
 			regs->cp0_epc = fixup->nextinsn;
+			TRIG_EVENT(trap_exit_hook);
 			return;
 		}
 		break;
@@ -371,6 +376,7 @@
 	       field, regs->cp0_epc, field, regs->regs[31]);
 	die_if_kernel("Oops", regs);
 	force_sig(SIGBUS, current);
+	TRIG_EVENT(trap_exit_hook);
 }
 
 static inline int get_insn_opcode(struct pt_regs *regs, unsigned int *opcode)
@@ -521,11 +527,13 @@
 {
 	siginfo_t info;
 
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	info.si_code = FPE_INTOVF;
 	info.si_signo = SIGFPE;
 	info.si_errno = 0;
 	info.si_addr = (void *)regs->cp0_epc;
 	force_sig_info(SIGFPE, &info, current);
+	TRIG_EVENT(trap_exit_hook);
 }
 
 /*
@@ -533,6 +541,7 @@
  */
 asmlinkage void do_fpe(struct pt_regs *regs, unsigned long fcr31)
 {
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	if (fcr31 & FPU_CSR_UNI_X) {
 		int sig;
 
@@ -565,10 +574,12 @@
 		if (sig)
 			force_sig(sig, current);
 
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
 
 	force_sig(SIGFPE, current);
+	TRIG_EVENT(trap_exit_hook);
 }
 
 asmlinkage void do_bp(struct pt_regs *regs)
@@ -578,9 +589,12 @@
 
 	die_if_kernel("Break instruction in kernel code", regs);
 
-	if (get_insn_opcode(regs, &opcode))
-		return;
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 
+	if (get_insn_opcode(regs, &opcode)) {
+		TRIG_EVENT(trap_exit_hook);
+		return;
+	}
 	/*
 	 * There is the ancient bug in the MIPS assemblers that the break
 	 * code starts left to bit 16 instead to bit 6 in the opcode.
@@ -609,6 +623,7 @@
 	default:
 		force_sig(SIGTRAP, current);
 	}
+	TRIG_EVENT(trap_exit_hook);
 }
 
 asmlinkage void do_tr(struct pt_regs *regs)
@@ -618,8 +633,12 @@
 
 	die_if_kernel("Trap instruction in kernel code", regs);
 
-	if (get_insn_opcode(regs, &opcode))
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
+
+	if (get_insn_opcode(regs, &opcode)) {
+		TRIG_EVENT(trap_exit_hook);
 		return;
+	}
 
 	/* Immediate versions don't provide a code.  */
 	if (!(opcode & OPCODE))
@@ -646,17 +665,22 @@
 	default:
 		force_sig(SIGTRAP, current);
 	}
+	TRIG_EVENT(trap_exit_hook);
 }
 
 asmlinkage void do_ri(struct pt_regs *regs)
 {
 	die_if_kernel("Reserved instruction in kernel code", regs);
 
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	if (!cpu_has_llsc)
-		if (!simulate_llsc(regs))
+		if (!simulate_llsc(regs)) {
+			TRIG_EVENT(trap_exit_hook);
 			return;
+		}
 
 	force_sig(SIGILL, current);
+	TRIG_EVENT(trap_exit_hook);
 }
 
 asmlinkage void do_cpu(struct pt_regs *regs)
@@ -665,6 +689,7 @@
 
 	die_if_kernel("do_cpu invoked from kernel context!", regs);
 
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	cpid = (regs->cp0_cause >> CAUSEB_CE) & 3;
 
 	switch (cpid) {
@@ -672,8 +697,10 @@
 		if (cpu_has_llsc)
 			break;
 
-		if (!simulate_llsc(regs))
+		if (!simulate_llsc(regs)) {
+			TRIG_EVENT(trap_exit_hook);
 			return;
+		}
 		break;
 
 	case 1:
@@ -692,6 +719,7 @@
 				force_sig(sig, current);
 		}
 
+		TRIG_EVENT(trap_exit_hook);
 		return;
 
 	case 2:
@@ -700,6 +728,7 @@
 	}
 
 	force_sig(SIGILL, current);
+	TRIG_EVENT(trap_exit_hook);
 }
 
 asmlinkage void do_mdmx(struct pt_regs *regs)
@@ -709,19 +738,23 @@
 
 asmlinkage void do_watch(struct pt_regs *regs)
 {
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	/*
 	 * We use the watch exception where available to detect stack
 	 * overflows.
 	 */
 	dump_tlb_all();
 	show_regs(regs);
+	TRIG_EVENT(trap_exit_hook);
 	panic("Caught WATCH exception - probably caused by stack overflow.");
 }
 
 asmlinkage void do_mcheck(struct pt_regs *regs)
 {
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	show_regs(regs);
 	dump_tlb_all();
+	TRIG_EVENT(trap_exit_hook);
 	/*
 	 * Some chips may have other causes of machine check (e.g. SB1
 	 * graduation timer)
@@ -759,6 +792,7 @@
 	default:
 		break;
 	}
+	TRIG_EVENT(trap_exit_hook);
 }
 
 asmlinkage void cache_parity_error(void)
Index: linux.t/arch/mips/kernel/unaligned.c
===================================================================
--- linux.t.orig/arch/mips/kernel/unaligned.c	2004-03-12 16:27:15.000000000 -0500
+++ linux.t/arch/mips/kernel/unaligned.c	2004-05-13 10:48:25.020267888 -0400
@@ -78,6 +78,7 @@
 #include <linux/signal.h>
 #include <linux/smp.h>
 #include <linux/smp_lock.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/asm.h>
 #include <asm/branch.h>
@@ -497,14 +498,17 @@
 	mm_segment_t seg;
 	unsigned long pc;
 
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	/*
 	 * Address errors may be deliberately induced by the FPU emulator to
 	 * retake control of the CPU after executing the instruction in the
 	 * delay slot of an emulated branch.
 	 */
 	/* Terminate if exception was recognized as a delay slot return */
-	if (do_dsemulret(regs))
+	if (do_dsemulret(regs)) {
+		TRIG_EVENT(trap_exit_hook);
 		return;
+	}
 
 	/* Otherwise handle as normal */
 
@@ -538,6 +542,7 @@
 	}
 	set_fs(seg);
 
+	TRIG_EVENT(trap_exit_hook);
 	return;
 
 sigbus:
@@ -547,4 +552,5 @@
 	/*
 	 * XXX On return from the signal handler we should advance the epc
 	 */
+	TRIG_EVENT(trap_exit_hook);
 }
Index: linux.t/arch/mips/mm/fault.c
===================================================================
--- linux.t.orig/arch/mips/mm/fault.c	2004-03-12 16:27:15.000000000 -0500
+++ linux.t/arch/mips/mm/fault.c	2004-05-13 10:48:25.029266520 -0400
@@ -19,6 +19,7 @@
 #include <linux/smp_lock.h>
 #include <linux/vt_kern.h>		/* For unblank_screen() */
 #include <linux/module.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/branch.h>
 #include <asm/hardirq.h>
@@ -27,6 +28,7 @@
 #include <asm/system.h>
 #include <asm/uaccess.h>
 #include <asm/ptrace.h>
+#include <asm/mipsregs.h>
 
 /*
  * This routine handles page faults.  It determines the address,
@@ -62,6 +64,7 @@
 	if (unlikely(address >= VMALLOC_START))
 		goto vmalloc_fault;
 
+	TRIG_EVENT(trap_entry_hook, CAUSE_EXCCODE(regs), CAUSE_EPC(regs));
 	/*
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
@@ -116,6 +119,7 @@
 	}
 
 	up_read(&mm->mmap_sem);
+	TRIG_EVENT(trap_exit_hook);
 	return;
 
 /*
@@ -144,6 +148,7 @@
 		/* info.si_code has been set above */
 		info.si_addr = (void *) address;
 		force_sig_info(SIGSEGV, &info, tsk);
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
 
@@ -151,6 +156,7 @@
 	/* Are we prepared to handle this kernel fault?  */
 	if (fixup_exception(regs)) {
 		current->thread.cp0_baduaddr = address;
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
 
@@ -201,6 +207,7 @@
 	info.si_addr = (void *) address;
 	force_sig_info(SIGBUS, &info, tsk);
 
+	TRIG_EVENT(trap_exit_hook);
 	return;
 
 vmalloc_fault:
@@ -235,4 +242,5 @@
 			goto no_context;
 		return;
 	}
+	TRIG_EVENT(trap_exit_hook);
 }
Index: linux.t/arch/parisc/Kconfig
===================================================================
--- linux.t.orig/arch/parisc/Kconfig	2004-05-13 10:44:58.471668048 -0400
+++ linux.t/arch/parisc/Kconfig	2004-05-13 10:48:25.031266216 -0400
@@ -222,6 +222,38 @@
 	  Say Y here only if you plan to use gdb to debug the kernel.
 	  If you don't debug the kernel, you can say N.
 	  
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/ppc/Kconfig
===================================================================
--- linux.t.orig/arch/ppc/Kconfig	2004-05-13 10:45:17.606759072 -0400
+++ linux.t/arch/ppc/Kconfig	2004-05-13 10:48:25.033265912 -0400
@@ -1225,6 +1225,50 @@
 	depends on IBM_OCP
 	default y
 
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config ASM_HOOK
+	bool
+	default y
+	depends on DEBUG_KERNEL && HOOK
+	
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
+config TRIGEVENT_SYSCALL_HOOK
+	bool " Enable syscall entry/exit hooks"
+	depends on TRIGEVENT_HOOKS
+	help 
+	RAS hooks to enable tracing of system call entry and exit points.
+	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/ppc/kernel/entry.S
===================================================================
--- linux.t.orig/arch/ppc/kernel/entry.S	2004-04-05 10:56:32.000000000 -0400
+++ linux.t/arch/ppc/kernel/entry.S	2004-05-13 10:48:25.046263936 -0400
@@ -35,6 +35,32 @@
 #undef SHOW_SYSCALLS
 #undef SHOW_SYSCALLS_TASK
 
+/* syscall hooks for LTT */
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+#define ASM_PRE_SYSCALL	\
+	addi	r3,r1,STACK_FRAME_OVERHEAD;  	/* Put pointer to registers into r3 */	\
+	mflr	r29;				/* Save LR */ \
+	bl	pre_syscall;			/* Call real trace function */ \
+	mtlr	r29;				/* Restore LR */ \
+	lwz	r0,GPR0(r1);			/* Restore original registers */ \
+	lwz	r3,GPR3(r1);	\
+	lwz	r4,GPR4(r1);	\
+	lwz	r5,GPR5(r1);	\
+	lwz	r6,GPR6(r1);	\
+	lwz	r7,GPR7(r1);	\
+	lwz	r8,GPR8(r1);
+#define ASM_POST_SYSCALL \
+	bl	post_syscall;			/* Call real trace function */ \
+	lwz	r0,GPR0(r1);			/* Restore original registers */ \
+	lwz	r3,RESULT(r1); \
+	lwz	r4,GPR4(r1); \
+	lwz	r5,GPR5(r1); \
+	lwz	r6,GPR6(r1); \
+	lwz	r7,GPR7(r1); \
+	lwz	r8,GPR8(r1); \
+	addi	r9,r1,STACK_FRAME_OVERHEAD;
+#endif
+
 /*
  * MSR_KERNEL is > 0x10000 on 4xx since it include MSR_CE.
  */
@@ -185,10 +211,16 @@
 	bge-	66f
 	lwzx	r10,r10,r0	/* Fetch system call handler [ptr] */
 	mtlr	r10
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	ASM_PRE_SYSCALL ;
+#endif
 	addi	r9,r1,STACK_FRAME_OVERHEAD
 	blrl			/* Call handler */
 	.globl	ret_from_syscall
 ret_from_syscall:
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	ASM_POST_SYSCALL ;
+#endif
 #ifdef SHOW_SYSCALLS
 	bl	do_show_syscall_exit
 #endif
Index: linux.t/arch/ppc/kernel/irq.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/irq.c	2004-03-12 16:27:16.000000000 -0500
+++ linux.t/arch/ppc/kernel/irq.c	2004-05-13 10:48:25.056262416 -0400
@@ -46,6 +46,7 @@
 #include <linux/random.h>
 #include <linux/seq_file.h>
 #include <linux/cpumask.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/bitops.h>
@@ -431,6 +432,7 @@
 	struct irqaction *action;
 	irq_desc_t *desc = irq_desc + irq;
 
+	TRIG_EVENT(irq_entry_hook, irq, regs, !(user_mode(regs)));
 	kstat_this_cpu.irqs[irq]++;
 	spin_lock(&desc->lock);
 	ack_irq(irq);
@@ -508,6 +510,7 @@
 			irq_desc[irq].handler->enable(irq);
 	}
 	spin_unlock(&desc->lock);
+	TRIG_EVENT(irq_exit_hook, irq, regs);
 }
 
 void do_IRQ(struct pt_regs *regs)
Index: linux.t/arch/ppc/kernel/misc.S
===================================================================
--- linux.t.orig/arch/ppc/kernel/misc.S	2004-04-05 10:56:32.000000000 -0400
+++ linux.t/arch/ppc/kernel/misc.S	2004-05-13 10:48:25.069260440 -0400
@@ -1066,7 +1066,11 @@
  * Create a kernel thread
  *   kernel_thread(fn, arg, flags)
  */
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK 
+_GLOBAL(original_kernel_thread)
+#else
 _GLOBAL(kernel_thread)
+#endif /* CONFIG_TRIGEVENT_SYSCALL_HOOK */
 	stwu	r1,-16(r1)
 	stw	r30,8(r1)
 	stw	r31,12(r1)
Index: linux.t/arch/ppc/kernel/process.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/process.c	2004-05-13 10:44:36.899947448 -0400
+++ linux.t/arch/ppc/kernel/process.c	2004-05-13 10:48:25.070260288 -0400
@@ -35,6 +35,7 @@
 #include <linux/init_task.h>
 #include <linux/module.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
@@ -306,6 +307,19 @@
 	show_stack(current, (unsigned long *) regs->gpr[1]);
 }
 
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK 
+long original_kernel_thread(int (*fn) (void *), void* arg, unsigned long flags);
+long kernel_thread(int (*fn) (void *), void* arg, unsigned long flags)
+{
+	long   retval;
+
+	retval = original_kernel_thread(fn, arg, flags);
+	if (retval > 0)
+		TRIG_EVENT(kthread_hook, retval, (int) fn);
+	return retval;
+}
+#endif /* CONFIG_TRIGEVENT_SYSCALL_HOOK */
+ 
 void exit_thread(void)
 {
 	if (last_task_used_math == current)
Index: linux.t/arch/ppc/kernel/syscalls.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/syscalls.c	2004-05-13 10:45:18.534618016 -0400
+++ linux.t/arch/ppc/kernel/syscalls.c	2004-05-13 10:48:25.072259984 -0400
@@ -37,6 +37,7 @@
 #include <linux/file.h>
 #include <linux/unistd.h>
 #include <linux/fshooks.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
@@ -60,6 +61,7 @@
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	TRIG_EVENT(ipc_call_hook, call, first);
 	ret = -ENOSYS;
 	switch (call) {
 	case SEMOP:
Index: linux.t/arch/ppc/kernel/time.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/time.c	2004-03-12 16:27:16.000000000 -0500
+++ linux.t/arch/ppc/kernel/time.c	2004-05-13 10:48:25.082258464 -0400
@@ -56,6 +56,7 @@
 #include <linux/mc146818rtc.h>
 #include <linux/time.h>
 #include <linux/init.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/segment.h>
 #include <asm/io.h>
@@ -152,6 +153,7 @@
 	if (atomic_read(&ppc_n_lost_interrupts) != 0)
 		do_IRQ(regs);
 
+	TRIG_EVENT(trap_entry_hook, regs->trap, instruction_pointer(regs));
 	irq_enter();
 
 	while ((next_dec = tb_ticks_per_jiffy - tb_delta(&jiffy_stamp)) < 0) {
@@ -199,6 +201,7 @@
 	last_jiffy_stamp(cpu) = jiffy_stamp;
 
 #ifdef CONFIG_SMP
+	TRIG_EVENT(timer_hook, regs);
 	smp_local_timer_interrupt(regs);
 #endif /* CONFIG_SMP */
 
@@ -206,6 +209,7 @@
 		ppc_md.heartbeat();
 
 	irq_exit();
+	TRIG_EVENT(trap_exit_hook);
 }
 
 /*
Index: linux.t/arch/ppc/kernel/traps.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/traps.c	2004-04-05 10:56:32.000000000 -0400
+++ linux.t/arch/ppc/kernel/traps.c	2004-05-13 10:48:25.084258160 -0400
@@ -30,6 +30,7 @@
 #include <linux/config.h>
 #include <linux/init.h>
 #include <linux/module.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
@@ -118,7 +119,9 @@
 	info.si_errno = 0;
 	info.si_code = code;
 	info.si_addr = (void *) addr;
+	TRIG_EVENT(trap_entry_hook, regs->trap, instruction_pointer(regs));
 	force_sig_info(signr, &info, current);
+	TRIG_EVENT(trap_exit_hook);
 }
 
 /*
Index: linux.t/arch/ppc/mm/fault.c
===================================================================
--- linux.t.orig/arch/ppc/mm/fault.c	2004-01-09 01:59:19.000000000 -0500
+++ linux.t/arch/ppc/mm/fault.c	2004-05-13 10:48:25.089257400 -0400
@@ -28,6 +28,7 @@
 #include <linux/interrupt.h>
 #include <linux/highmem.h>
 #include <linux/module.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/page.h>
 #include <asm/pgtable.h>
@@ -121,22 +122,28 @@ int do_page_fault(struct pt_regs *regs, 
 		is_write = error_code & 0x02000000;
 #endif /* CONFIG_4xx */
 
+	TRIG_EVENT(trap_entry_hook, regs->trap, instruction_pointer(regs));
 #if defined(CONFIG_XMON) || defined(CONFIG_KGDB)
 	if (debugger_fault_handler && TRAP(regs) == 0x300) {
 		debugger_fault_handler(regs);
+		TRIG_EVENT(trap_exit_hook);
 		return 0;
 	}
 #if !defined(CONFIG_4xx)
 	if (error_code & 0x00400000) {
 		/* DABR match */
-		if (debugger_dabr_match(regs))
+		if (debugger_dabr_match(regs)) {
+			TRIG_EVENT(trap_exit_hook);
 			return 0;
+		}
 	}
 #endif /* !CONFIG_4xx */
 #endif /* CONFIG_XMON || CONFIG_KGDB */
 
-	if (in_atomic() || mm == NULL)
+	if (in_atomic() || mm == NULL) {
+		TRIG_EVENT(trap_exit_hook);
 		return SIGSEGV;
+	}
 
 	down_read(&mm->mmap_sem);
 	vma = find_vma(mm, address);
@@ -276,6 +283,7 @@ good_area:
 	 * -- Cort
 	 */
 	pte_misses++;
+	TRIG_EVENT(trap_exit_hook);
 	return 0;
 
 bad_area:
@@ -289,9 +297,11 @@ bad_area:
 		info.si_code = code;
 		info.si_addr = (void *) address;
 		force_sig_info(SIGSEGV, &info, current);
+		TRIG_EVENT(trap_exit_hook);
 		return 0;
 	}
 
+	TRIG_EVENT(trap_exit_hook);
 	return SIGSEGV;
 
 /*
@@ -308,6 +318,7 @@ out_of_memory:
 	printk("VM: killing process %s\n", current->comm);
 	if (user_mode(regs))
 		do_exit(SIGKILL);
+	TRIG_EVENT(trap_exit_hook);
 	return SIGKILL;
 
 do_sigbus:
@@ -317,8 +328,12 @@ do_sigbus:
 	info.si_code = BUS_ADRERR;
 	info.si_addr = (void *)address;
 	force_sig_info (SIGBUS, &info, current);
-	if (!user_mode(regs))
+	if (!user_mode(regs)) {
+		TRIG_EVENT(trap_exit_hook);
 		return SIGBUS;
+	}
+
+	TRIG_EVENT(trap_exit_hook);
 	return 0;
 }
 
Index: linux.t/arch/ppc64/Kconfig
===================================================================
--- linux.t.orig/arch/ppc64/Kconfig	2004-05-13 10:45:20.862264160 -0400
+++ linux.t/arch/ppc64/Kconfig	2004-05-13 10:48:25.091257096 -0400
@@ -527,6 +527,44 @@
 
 	  If in doubt, say N.
 
+
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config ASM_HOOK
+	bool
+	default y
+	depends on DEBUG_KERNEL && HOOK
+	
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+	
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/ppc64/kernel/irq.c
===================================================================
--- linux.t.orig/arch/ppc64/kernel/irq.c	2004-05-13 10:44:16.273083208 -0400
+++ linux.t/arch/ppc64/kernel/irq.c	2004-05-13 10:48:25.093256792 -0400
@@ -41,6 +41,7 @@
 #include <linux/proc_fs.h>
 #include <linux/random.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/bitops.h>
@@ -485,6 +486,7 @@
 	struct thread_info *curtp, *irqtp;
 #endif
 
+	TRIG_EVENT(irq_entry_hook, irq, regs, !(user_mode(regs)));
 	kstat_cpu(cpu).irqs[irq]++;
 
 	if (desc->status & IRQ_PER_CPU) {
@@ -586,6 +588,7 @@
 			desc->handler->enable(irq);
 	}
 	spin_unlock(&desc->lock);
+	TRIG_EVENT(irq_exit_hook, irq, regs);
 }
 
 #ifdef CONFIG_PPC_ISERIES
Index: linux.t/arch/ppc64/kernel/time.c
===================================================================
--- linux.t.orig/arch/ppc64/kernel/time.c	2004-05-13 10:45:19.386488512 -0400
+++ linux.t/arch/ppc64/kernel/time.c	2004-05-13 10:48:25.095256488 -0400
@@ -49,6 +49,7 @@
 #include <linux/init.h>
 #include <linux/profile.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/segment.h>
 #include <asm/io.h>
@@ -281,6 +282,7 @@
 	while (lpaca->next_jiffy_update_tb <= (cur_tb = get_tb())) {
 
 #ifdef CONFIG_SMP
+		TRIG_EVENT(timer_hook, regs);
 		smp_local_timer_interrupt(regs);
 #endif
 		if (cpu == boot_cpuid) {
Index: linux.t/arch/s390/Kconfig
===================================================================
--- linux.t.orig/arch/s390/Kconfig	2004-05-13 10:45:20.152372080 -0400
+++ linux.t/arch/s390/Kconfig	2004-05-13 10:48:25.097256184 -0400
@@ -432,6 +432,50 @@
 	  If you say Y here, various routines which may sleep will become very
 	  noisy if they are called with a spinlock held.	
 
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config ASM_HOOK
+	bool
+	default y
+	depends on DEBUG_KERNEL && HOOK
+	
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
+config TRIGEVENT_SYSCALL_HOOK
+	bool " Enable syscall entry/exit hooks"
+	depends on TRIGEVENT_HOOKS
+	help 
+	RAS hooks to enable tracing of system call entry and exit points.
+	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/s390/kernel/entry.S
===================================================================
--- linux.t.orig/arch/s390/kernel/entry.S	2004-05-13 10:44:56.583955024 -0400
+++ linux.t/arch/s390/kernel/entry.S	2004-05-13 10:48:25.099255880 -0400
@@ -7,6 +7,7 @@
  *    Author(s): Martin Schwidefsky (schwidefsky@de.ibm.com),
  *               Hartmut Penner (hp@de.ibm.com),
  *               Denis Joseph Barrow (djbarrow@de.ibm.com,barrow_dj@yahoo.com),
+ *  Portions added by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
  */
 
 #include <linux/sys.h>
@@ -229,6 +230,14 @@
 	lh	%r7,0x8a	  # get svc number from lowcore
 sysc_enter:
         GET_THREAD_INFO           # load pointer to task_struct to R9
+/* call to ltt trace done here.  R8 has the syscall (svc) number to trace */
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK /* tjh - ltt port */              
+        /* add call to pre_syscall */                          
+	la      %r2,SP_PTREGS(%r15)   # load pt_regs as first parameter     
+	l       %r1,BASED(.Lpresyscall)                                    
+	basr    %r14,%r1                                                    
+	lm      %r0,%r6,SP_R0(%r15) /* restore call clobbered regs tjh */   
+#endif
 	sla	%r7,2             # *4 and test for svc 0
 	bnz	BASED(sysc_do_restart)  # svc number > 0
 	# svc 0: system call number in %r1
@@ -245,6 +254,13 @@
                                   # ATTENTION: check sys_execve_glue before
                                   # changing anything here !!
 
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK /* tjh - ltt port *            
+        /* add call to post_syscall */ 
+        la      %r2,SP_PTREGS(%r15)   # load pt_regs as first parameter  
+        l       %r1,BASED(.Lpostsyscall)                                 
+        basr    %r14,%r1                                                 
+        lm      %r0,%r6,SP_R0(%r15) /* restore call clobbered regs */
+#endif                                                                   
 sysc_return:
 	tm	SP_PSW+1(%r15),0x01	# returning to user ?
 	bno	BASED(sysc_leave)
@@ -790,6 +806,10 @@
 .Lsigaltstack: .long  sys_sigaltstack
 .Ltrace:       .long  syscall_trace
 .Lvfork:       .long  sys_vfork
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK            
+.Lpresyscall:  .long  pre_syscall
+.Lpostsyscall: .long  post_syscall 
+#endif
 .Lschedtail:   .long  schedule_tail
 
 .Lcritical_start:
Index: linux.t/arch/s390/kernel/process.c
===================================================================
--- linux.t.orig/arch/s390/kernel/process.c	2004-05-13 10:44:55.943052456 -0400
+++ linux.t/arch/s390/kernel/process.c	2004-05-13 10:48:25.101255576 -0400
@@ -33,6 +33,7 @@
 #include <linux/delay.h>
 #include <linux/reboot.h>
 #include <linux/init.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/pgtable.h>
@@ -179,6 +180,7 @@
 int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags)
 {
 	struct pt_regs regs;
+	int ret = 0;
 
 	memset(&regs, 0, sizeof(regs));
 	regs.psw.mask = PSW_KERNEL_BITS;
@@ -191,8 +193,14 @@
 	regs.orig_gpr2 = -1;
 
 	/* Ok, create the new process.. */
-	return do_fork(flags | CLONE_VM | CLONE_UNTRACED,
+	ret = do_fork(flags | CLONE_VM | CLONE_UNTRACED,
 		       0, &regs, 0, NULL, NULL);
+	
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	if (ret > 0)
+		TRIG_EVENT(kthread_hook, ret, (int) fn);
+#endif
+	return ret;
 }
 
 /*
Index: linux.t/arch/s390/kernel/sys_s390.c
===================================================================
--- linux.t.orig/arch/s390/kernel/sys_s390.c	2004-05-13 10:45:18.671597192 -0400
+++ linux.t/arch/s390/kernel/sys_s390.c	2004-05-13 10:48:25.102255424 -0400
@@ -30,6 +30,7 @@
 #include <linux/personality.h>
 #endif /* CONFIG_ARCH_S390X */
 #include <linux/fshooks.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
@@ -165,6 +166,7 @@
         struct ipc_kludge tmp;
 	int ret;
 
+        TRIG_EVENT(ipc_call_hook, call, first);
         switch (call) {
         case SEMOP:
 		return sys_semtimedop (first, (struct sembuf *) ptr, second,
Index: linux.t/arch/s390/kernel/time.c
===================================================================
--- linux.t.orig/arch/s390/kernel/time.c	2004-05-13 10:44:55.953050936 -0400
+++ linux.t/arch/s390/kernel/time.c	2004-05-13 10:48:25.104255120 -0400
@@ -26,6 +26,7 @@
 #include <linux/types.h>
 #include <linux/timex.h>
 #include <linux/config.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/delay.h>
@@ -300,6 +301,7 @@
 	 * Spread it over all cpus instead.
 	 */
 	write_seqlock(&xtime_lock);
+	TRIG_EVENT(timer_hook, regs);
 	if (S390_lowcore.jiffy_timer > xtime_cc) {
 		__u32 xticks;
 
Index: linux.t/arch/s390/kernel/traps.c
===================================================================
--- linux.t.orig/arch/s390/kernel/traps.c	2004-05-13 10:44:55.955050632 -0400
+++ linux.t/arch/s390/kernel/traps.c	2004-05-13 10:48:25.106254816 -0400
@@ -5,6 +5,7 @@
  *    Copyright (C) 1999,2000 IBM Deutschland Entwicklung GmbH, IBM Corporation
  *    Author(s): Martin Schwidefsky (schwidefsky@de.ibm.com),
  *               Denis Joseph Barrow (djbarrow@de.ibm.com,barrow_dj@yahoo.com),
+ *  Portions added by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
  *
  *  Derived from "arch/i386/kernel/traps.c"
  *    Copyright (C) 1991, 1992 Linus Torvalds
@@ -29,6 +30,7 @@
 #include <linux/delay.h>
 #include <linux/module.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
@@ -270,12 +272,17 @@
 static void inline do_trap(long interruption_code, int signr, char *str,
                            struct pt_regs *regs, siginfo_t *info)
 {
+	trapid_t ltt_interruption_code;
+	char * ic_ptr = (char *) &ltt_interruption_code;
 	/*
 	 * We got all needed information from the lowcore and can
 	 * now safely switch on interrupts.
 	 */
         if (regs->psw.mask & PSW_MASK_PSTATE)
 		local_irq_enable();
+	memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+	memcpy(ic_ptr+4,&interruption_code,sizeof(interruption_code));
+	TRIG_EVENT(trap_entry_hook, ltt_interruption_code, (regs->psw.addr & PSW_ADDR_INSN));
 
         if (regs->psw.mask & PSW_MASK_PSTATE) {
                 struct task_struct *tsk = current;
@@ -306,6 +313,7 @@
                 else
                         die(str, regs, interruption_code);
         }
+	TRIG_EVENT(trap_exit_hook);
 }
 
 static inline void *get_check_address(struct pt_regs *regs)
@@ -315,6 +323,11 @@
 
 int do_debugger_trap(struct pt_regs *regs)
 {
+	trapid_t ltt_interruption_code;
+	char * ic_ptr = (char *) &ltt_interruption_code;
+	memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+	memcpy(ic_ptr+6,&S390_lowcore.pgm_code,2); /* copy the interrupt code */
+
 	if ((regs->psw.mask & PSW_MASK_PSTATE) &&
 	    (current->ptrace & PT_PTRACED)) {
 		force_sig(SIGTRAP,current);
@@ -390,6 +403,8 @@
 {
         __u8 opcode[6];
 	__u16 *location;
+        trapid_t ltt_interruption_code;
+        char * ic_ptr = (char *) &ltt_interruption_code;
 	int signal = 0;
 
 	location = (__u16 *) get_check_address(regs);
@@ -401,6 +416,9 @@
 	if (regs->psw.mask & PSW_MASK_PSTATE)
 		local_irq_enable();
 
+	memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+	memcpy(ic_ptr+4,&interruption_code,sizeof(interruption_code));
+	TRIG_EVENT(trap_entry_hook, ltt_interruption_code, (regs->psw.addr & PSW_ADDR_INSN));
 	if (regs->psw.mask & PSW_MASK_PSTATE)
 		get_user(*((__u16 *) opcode), location);
 	else
@@ -441,6 +459,7 @@
         else if (signal)
 		do_trap(interruption_code, signal,
 			"illegal operation", regs, NULL);
+        TRIG_EVENT(trap_exit_hook);
 }
 
 
@@ -450,6 +469,8 @@
 {
         __u8 opcode[6];
 	__u16 *location = NULL;
+        trapid_t ltt_interruption_code;
+        char * ic_ptr = (char *) &ltt_interruption_code;
 	int signal = 0;
 
 	location = (__u16 *) get_check_address(regs);
@@ -461,6 +482,9 @@
 	if (regs->psw.mask & PSW_MASK_PSTATE)
 		local_irq_enable();
 		
+	memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+	memcpy(ic_ptr+4,&interruption_code,sizeof(interruption_code));
+	TRIG_EVENT(trap_entry_hook, ltt_interruption_code, (regs->psw.addr & PSW_ADDR_INSN));
         if (regs->psw.mask & PSW_MASK_PSTATE) {
 		get_user(*((__u16 *) opcode), location);
 		switch (opcode[0]) {
@@ -504,6 +528,7 @@
 		do_trap(interruption_code, signal, 
 			"specification exception", regs, &info);
 	}
+        TRIG_EVENT(trap_exit_hook);
 }
 #else
 DO_ERROR_INFO(SIGILL, "specification exception", specification_exception,
@@ -513,6 +538,8 @@
 asmlinkage void data_exception(struct pt_regs * regs, long interruption_code)
 {
 	__u16 *location;
+        trapid_t ltt_interruption_code;
+        char * ic_ptr = (char *) &ltt_interruption_code;
 	int signal = 0;
 
 	location = (__u16 *) get_check_address(regs);
@@ -524,6 +551,9 @@
 	if (regs->psw.mask & PSW_MASK_PSTATE)
 		local_irq_enable();
 
+	memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+	memcpy(ic_ptr+4,&interruption_code,sizeof(interruption_code));
+	TRIG_EVENT(trap_entry_hook, ltt_interruption_code, (regs->psw.addr & PSW_ADDR_INSN));
 	if (MACHINE_HAS_IEEE)
 		__asm__ volatile ("stfpc %0\n\t" 
 				  : "=m" (current->thread.fp_regs.fpc));
@@ -599,6 +629,7 @@
 		do_trap(interruption_code, signal, 
 			"data exception", regs, &info);
 	}
+        TRIG_EVENT(trap_exit_hook);
 }
 
 
Index: linux.t/arch/s390/mm/fault.c
===================================================================
--- linux.t.orig/arch/s390/mm/fault.c	2004-04-05 10:56:33.000000000 -0400
+++ linux.t/arch/s390/mm/fault.c	2004-05-13 10:48:25.113253752 -0400
@@ -5,6 +5,7 @@
  *    Copyright (C) 1999 IBM Deutschland Entwicklung GmbH, IBM Corporation
  *    Author(s): Hartmut Penner (hp@de.ibm.com)
  *               Ulrich Weigand (uweigand@de.ibm.com)
+ *  Portions added by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
  *
  *  Derived from "arch/i386/mm/fault.c"
  *    Copyright (C) 1995  Linus Torvalds
@@ -25,6 +26,7 @@
 #include <linux/init.h>
 #include <linux/console.h>
 #include <linux/module.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
@@ -168,6 +170,8 @@
 	int user_address;
 	const struct exception_table_entry *fixup;
 	int si_code = SEGV_MAPERR;
+        trapid_t ltt_interruption_code;                 
+        char * ic_ptr = (char *) &ltt_interruption_code; 
 
         tsk = current;
         mm = tsk->mm;
@@ -215,6 +219,9 @@
 	 */
 	local_irq_enable();
 
+        memset(&ltt_interruption_code,0,sizeof(ltt_interruption_code));
+        memcpy(ic_ptr+4,&error_code,sizeof(error_code));
+        TRIG_EVENT(trap_entry_hook, ltt_interruption_code,(regs->psw.addr & PSW_ADDR_INSN));
         down_read(&mm->mmap_sem);
 
         vma = find_vma(mm, address);
@@ -263,6 +270,7 @@
 	}
 
         up_read(&mm->mmap_sem);
+        TRIG_EVENT(trap_exit_hook);
         return;
 
 /*
@@ -277,6 +285,7 @@
                 tsk->thread.prot_addr = address;
                 tsk->thread.trap_no = error_code;
 		force_sigsegv(regs, error_code, si_code, address);
+                TRIG_EVENT(trap_exit_hook);
                 return;
 	}
 
@@ -285,6 +294,7 @@
 	fixup = search_exception_tables(regs->psw.addr & __FIXUP_MASK);
 	if (fixup) {
 		regs->psw.addr = fixup->fixup | PSW_ADDR_AMODE;
+		TRIG_EVENT(trap_exit_hook);
                 return;
         }
 
@@ -332,6 +342,7 @@
 	/* Kernel mode? Handle exceptions or die */
 	if (!(regs->psw.mask & PSW_MASK_PSTATE))
 		goto no_context;
+	TRIG_EVENT(trap_exit_hook);
 }
 
 void do_protection_exception(struct pt_regs *regs, unsigned long error_code)
Index: linux.t/arch/sh/Kconfig
===================================================================
--- linux.t.orig/arch/sh/Kconfig	2004-05-13 10:44:58.496664248 -0400
+++ linux.t/arch/sh/Kconfig	2004-05-13 10:48:25.115253448 -0400
@@ -790,6 +790,44 @@
 	  If you don't debug the kernel, you can say N, but we may not be able
 	  to solve problems without frame pointers.
 
+config HOOK
+	tristate "Kernel Hook support"
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+	
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
+config TRIGEVENT_SYSCALL_HOOK
+	bool " Enable syscall entry/exit hooks"
+	depends on TRIGEVENT_HOOKS
+	help 
+	RAS hooks to enable tracing of system call entry and exit points.
+	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/sh/kernel/entry.S
===================================================================
--- linux.t.orig/arch/sh/kernel/entry.S	2004-04-05 10:56:34.000000000 -0400
+++ linux.t/arch/sh/kernel/entry.S	2004-05-13 10:48:25.124252080 -0400
@@ -555,6 +555,19 @@
 	 nop
 	!
 good_system_call:		! Good syscall number
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	! TODO: for i386 this code only happens when not ptrace'd
+	mov 	r15, r4     	    	! pass pt_regs* as first arg
+	mov.l	__pre_syscall, r11 	! Call pre_syscall()
+	jsr	@r11	    	    	! (will chomp R[0-7])
+	 nop
+	!   	    	    	    	Reload R4-R7 from kernel stack
+	mov.l	@(OFF_R4,r15), r4   ! arg0
+	mov.l	@(OFF_R5,r15), r5
+	mov.l	@(OFF_R6,r15), r6
+	mov.l	@(OFF_R7,r15), r7   ! arg3
+	mov.l	@(OFF_R3,r15), r3   ! syscall_nr
+#endif
 	mov.l	@(TI_FLAGS,r8), r8
 	mov	#_TIF_SYSCALL_TRACE, r10
 	tst	r10, r8
@@ -570,6 +583,12 @@
 	mov.l	r0, @(OFF_R0,r15)		! save the return value
 	!
 syscall_exit:
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	! TODO: for i386 this code only happens when not ptrace'd
+	mov.l	__post_syscall, r1 	    	! Call post_syscall()
+	jsr	@r1
+	 nop
+#endif
 	CLI()
 	!
 	GET_THREAD_INFO(r8)
@@ -676,6 +695,12 @@
 5:	.long	0x00001000	! DSP
 7:	.long	0x30000000
 9:
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+__pre_syscall:
+	.long   SYMBOL_NAME(pre_syscall)
+__post_syscall:
+	.long   SYMBOL_NAME(post_syscall)
+#endif
 __INV_IMASK:
 	.long	0xffffff0f	! ~(IMASK)
 
Index: linux.t/arch/sh/kernel/irq.c
===================================================================
--- linux.t.orig/arch/sh/kernel/irq.c	2004-02-18 22:22:29.000000000 -0500
+++ linux.t/arch/sh/kernel/irq.c	2004-05-13 10:48:25.132250864 -0400
@@ -31,6 +31,7 @@
 #include <linux/init.h>
 #include <linux/seq_file.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
 #include <asm/io.h>
@@ -139,6 +140,11 @@
 	int status = 1;	/* Force the "do bottom halves" bit */
 	int retval = 0;
 
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	if (irq != TIMER_IRQ) { /* avoid double-reporting the timer IRQ */
+		TRIG_EVENT(irq_entry_hook, irq, regs, !(user_mode(regs)));
+	}
+#endif
 	if (!(action->flags & SA_INTERRUPT))
 		local_irq_enable();
 
@@ -152,6 +158,11 @@
 		add_interrupt_randomness(irq);
 
 	local_irq_disable();
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	if (irq != TIMER_IRQ) { /* avoid double-reporting the timer IRQ */
+		TRIG_EVENT(irq_exit_hook, irq, regs);
+	}
+#endif
 	return retval;
 }
 
Index: linux.t/arch/sh/kernel/process.c
===================================================================
--- linux.t.orig/arch/sh/kernel/process.c	2004-04-05 10:56:34.000000000 -0400
+++ linux.t/arch/sh/kernel/process.c	2004-05-13 10:48:25.145248888 -0400
@@ -20,6 +20,7 @@
 #include <linux/ptrace.h>
 #include <linux/platform.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/io.h>
 #include <asm/uaccess.h>
@@ -147,6 +148,7 @@
 int kernel_thread(int (*fn)(void *), void * arg, unsigned long flags)
 {	/* Don't use this in BL=1(cli).  Or else, CPU resets! */
 	struct pt_regs regs;
+	int ret = 0;
 
 	memset(&regs, 0, sizeof(regs));
 	regs.regs[4] = (unsigned long) arg;
@@ -156,7 +158,12 @@
 	regs.sr = (1 << 30);
 
 	/* Ok, create the new process.. */
-	return do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
+	ret = do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	if (ret > 0)
+		TRIG_EVENT(kthread_hook, ret, (int) fn);
+#endif
+	return  ret;
 }
 
 /*
Index: linux.t/arch/sh/kernel/sys_sh.c
===================================================================
--- linux.t.orig/arch/sh/kernel/sys_sh.c	2004-04-05 10:56:34.000000000 -0400
+++ linux.t/arch/sh/kernel/sys_sh.c	2004-05-13 10:48:25.156247216 -0400
@@ -21,6 +21,7 @@
 #include <linux/mman.h>
 #include <linux/file.h>
 #include <linux/utsname.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/ipc.h>
@@ -166,6 +167,7 @@
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
 
+	TRIG_EVENT(ipc_call_hook, call, first);
 	if (call <= SEMCTL)
 		switch (call) {
 		case SEMOP:
Index: linux.t/arch/sh/kernel/traps.c
===================================================================
--- linux.t.orig/arch/sh/kernel/traps.c	2004-04-05 10:56:34.000000000 -0400
+++ linux.t/arch/sh/kernel/traps.c	2004-05-13 10:48:25.170245088 -0400
@@ -27,6 +27,7 @@
 #include <linux/spinlock.h>
 #include <linux/module.h>
 #include <linux/kallsyms.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
 #include <asm/uaccess.h>
@@ -67,7 +68,9 @@
 	tsk->thread.error_code = error_code;				\
 	tsk->thread.trap_no = trapnr;					\
         CHK_REMOTE_DEBUG(&regs);					\
+	TRIG_EVENT(trap_entry_hook, trapnr, regs.pc);			\
 	force_sig(signr, tsk);						\
+	TRIG_EVENT(trap_exit_hook);					\
 	die_if_no_fixup(str,&regs,error_code);				\
 }
 
@@ -500,6 +503,7 @@
 
 	asm volatile("stc       r2_bank,%0": "=r" (error_code));
 
+	TRIG_EVENT(trap_entry_hook, error_code >> 5, regs->pc);
 	oldfs = get_fs();
 
 	if (user_mode(regs)) {
@@ -523,8 +527,10 @@
 		tmp = handle_unaligned_access(instruction, regs);
 		set_fs(oldfs);
 
-		if (tmp==0)
+		if (tmp==0) {
+			TRIG_EVENT(trap_exit_hook);
 			return; /* sorted */
+		}
 
 	uspace_segv:
 		printk(KERN_NOTICE "Killing process \"%s\" due to unaligned access\n", current->comm);
@@ -545,6 +551,7 @@
 		handle_unaligned_access(instruction, regs);
 		set_fs(oldfs);
 	}
+	TRIG_EVENT(trap_exit_hook);
 }
 
 #ifdef CONFIG_SH_DSP
Index: linux.t/arch/sh/mm/fault.c
===================================================================
--- linux.t.orig/arch/sh/mm/fault.c	2004-02-18 22:22:29.000000000 -0500
+++ linux.t/arch/sh/mm/fault.c	2004-05-13 10:48:25.181243416 -0400
@@ -21,6 +21,7 @@
 #include <linux/smp_lock.h>
 #include <linux/interrupt.h>
 #include <linux/module.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
 #include <asm/io.h>
@@ -54,6 +55,13 @@
 	tsk = current;
 	mm = tsk->mm;
 
+#if (CONFIG_TRIGEVENT_HOOKS)
+	{
+		unsigned long trapnr;
+		asm volatile("stc       r2_bank,%0": "=r" (trapnr));
+		TRIG_EVENT(trap_entry_hook, trapnr >> 5, regs->pc);  /* trap 4,5 or 6 */
+	}
+#endif
 	/*
 	 * If we're in an interrupt or have no user
 	 * context, we must not take the fault..
@@ -107,6 +115,7 @@
 	}
 
 	up_read(&mm->mmap_sem);
+	TRIG_EVENT(trap_exit_hook);
 	return;
 
 /*
@@ -120,13 +129,16 @@
 		tsk->thread.address = address;
 		tsk->thread.error_code = writeaccess;
 		force_sig(SIGSEGV, tsk);
+		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
 
 no_context:
 	/* Are we prepared to handle this kernel fault?  */
-	if (fixup_exception(regs))
+	if (fixup_exception(regs)) {
+		TRIG_EVENT(trap_exit_hook);
 		return;
+	}
 
 /*
  * Oops. The kernel tried to access some bad page. We'll have to
@@ -186,6 +198,7 @@
 	/* Kernel mode? Handle exceptions or die */
 	if (!user_mode(regs))
 		goto no_context;
+	TRIG_EVENT(trap_exit_hook);
 }
 
 /*
Index: linux.t/arch/sparc/Kconfig
===================================================================
--- linux.t.orig/arch/sparc/Kconfig	2004-05-13 10:44:58.503663184 -0400
+++ linux.t/arch/sparc/Kconfig	2004-05-13 10:48:25.183243112 -0400
@@ -448,6 +448,37 @@
 	  of the BUG call as well as the EIP and oops trace.  This aids
 	  debugging but costs about 70-100K of memory.
 
+config HOOK
+	tristate "Kernel Hook support"
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/sparc64/Kconfig
===================================================================
--- linux.t.orig/arch/sparc64/Kconfig	2004-05-13 10:44:58.512661816 -0400
+++ linux.t/arch/sparc64/Kconfig	2004-05-13 10:48:25.185242808 -0400
@@ -700,6 +700,38 @@
 	depends on STACK_DEBUG
 	default y
 
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/x86_64/Kconfig
===================================================================
--- linux.t.orig/arch/x86_64/Kconfig	2004-05-13 10:45:23.514860904 -0400
+++ linux.t/arch/x86_64/Kconfig	2004-05-13 10:48:25.187242504 -0400
@@ -569,6 +569,38 @@
 #config X86_REMOTE_DEBUG
 #       bool "kgdb debugging stub"
 
+config HOOK
+	tristate "Kernel Hook support"
+	depends on DEBUG_KERNEL 
+	help
+	 The Kernel Hooks Interface is a generalised facility for placing hooks in
+	 arbitrary kernel locations. A hook is a location in the kernel that
+	 calls out of the kernel to a kernel module routine - a hook exit routine.
+	 Read Documentation/hook/HOWTO for more details.
+
+config HOOK_PROCFS
+	bool "/proc interface for hooks" 
+	depends on DEBUG_KERNEL && HOOK
+
+config TRIGEVENT_HOOKS
+	bool "RAS Instrumentation Hooks"
+	depends on HOOK=y 
+	help 
+	RAS Instrumentation Hooks are kernel hooks to trace system calls and
+	 events used by Linux Trace Toolkit. These hooks may be used by other tools 
+	 also.
+
+	 RAS hooks trace Interprocess communication routines (sys_ipc, sys_msgget, 
+	 sys_semget, sys_shmget etc), IRQ's entry and exit points, Kernel timer 
+	 routines, Kernel threads create routine, Process Management routines (such as 
+	 fork, exec, exit, wait etc), Process Scheduling switch and dispatch routines, 
+	 Signals, Memory Management routines(such as __get_free_pages, __free_pages_ok, 
+	 do_swap_page, swap_writepage etc), Network packets transmit and receive 
+	 routines, Sockets  create, send, receive routines, tasklets, Trap 
+	 entry and exit routines etc.
+
+	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/x86_64/kernel/apic.c
===================================================================
--- linux.t.orig/arch/x86_64/kernel/apic.c	2004-05-13 10:45:11.850634136 -0400
+++ linux.t/arch/x86_64/kernel/apic.c	2004-05-13 10:48:25.189242200 -0400
@@ -26,6 +26,7 @@
 #include <linux/mc146818rtc.h>
 #include <linux/kernel_stat.h>
 #include <linux/sysdev.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/atomic.h>
 #include <asm/smp.h>
@@ -857,6 +858,7 @@
 		}
 
 #ifdef CONFIG_SMP
+		TRIG_EVENT(timer_hook, regs);
 		update_process_times(user_mode(regs));
 #endif
 	}
Index: linux.t/arch/x86_64/kernel/irq.c
===================================================================
--- linux.t.orig/arch/x86_64/kernel/irq.c	2004-05-13 10:45:23.548855736 -0400
+++ linux.t/arch/x86_64/kernel/irq.c	2004-05-13 10:48:25.191241896 -0400
@@ -33,6 +33,7 @@
 #include <linux/irq.h>
 #include <linux/proc_fs.h>
 #include <linux/seq_file.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/atomic.h>
 #include <asm/io.h>
@@ -214,6 +215,7 @@
 {
 	int status = 1; /* Force the "do bottom halves" bit */
 
+	TRIG_EVENT(irq_entry_hook, irq, regs, !(user_mode(regs)));
 	if (!(action->flags & SA_INTERRUPT))
 		local_irq_enable();
 
@@ -226,6 +228,7 @@
 		add_interrupt_randomness(irq);
 	local_irq_disable();
 
+	TRIG_EVENT(irq_exit_hook, irq, regs);
 	return status;
 }
 
Index: linux.t/drivers/dump/dump_setup.c
===================================================================
--- linux.t.orig/drivers/dump/dump_setup.c	2004-05-13 10:45:23.427874128 -0400
+++ linux.t/drivers/dump/dump_setup.c	2004-05-13 10:48:25.193241592 -0400
@@ -118,6 +118,7 @@
 #include <linux/sysctl.h>
 #include <linux/nmi.h>
 #include <linux/init.h>
+#include <linux/ltt.h>
 
 #include <asm/hardirq.h>
 #include <asm/uaccess.h>
@@ -325,6 +326,8 @@
 		return;
 	}
 
+	ltt_flight_pause();
+	
 	/* Bring system into the strictest level of quiescing for min drift 
 	 * dump drivers can soften this as required in dev->ops->silence() 
 	 */
@@ -342,6 +345,8 @@
 		printk("Dump Complete; %d dump pages saved.\n", 
 		       dump_header.dh_num_dump_pages);
 	}
+	
+	ltt_flight_unpause();
 }
 
 /*
Index: linux.t/drivers/s390/s390mach.c
===================================================================
--- linux.t.orig/drivers/s390/s390mach.c	2004-03-12 16:27:30.000000000 -0500
+++ linux.t/drivers/s390/s390mach.c	2004-05-13 10:48:25.206239616 -0400
@@ -6,12 +6,14 @@
  *    Copyright (C) 2000 IBM Deutschland Entwicklung GmbH, IBM Corporation
  *    Author(s): Ingo Adlung (adlung@de.ibm.com)
  *		 Martin Schwidefsky (schwidefsky@de.ibm.com)
+ *	Portions added by T. Halloran: (C) Copyright 2002 IBM Poughkeepsie, IBM Corporation
  */
 
 #include <linux/config.h>
 #include <linux/init.h>
 #include <linux/sched.h>
 #include <linux/errno.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/lowcore.h>
 
@@ -142,8 +144,18 @@
 s390_do_machine_check(void)
 {
 	struct mci *mci;
+	trapid_t ltt_interruption_code;
+	uint32_t ltt_old_psw;
 
 	mci = (struct mci *) &S390_lowcore.mcck_interruption_code;
+	memcpy( &ltt_interruption_code,
+		&S390_lowcore.mcck_interruption_code,
+		sizeof(__u64));
+	memcpy( &ltt_old_psw,
+		&S390_lowcore.mcck_old_psw,
+		sizeof(uint32_t));
+	ltt_old_psw &=  PSW_ADDR_INSN;
+	TRIG_EVENT(trap_entry_hook, ltt_interruption_code,ltt_old_psw);
 
 	if (mci->sd)		/* system damage */
 		s390_handle_damage("received system damage machine check\n");
Index: linux.t/fs/buffer.c
===================================================================
--- linux.t.orig/fs/buffer.c	2004-05-13 10:45:20.605303224 -0400
+++ linux.t/fs/buffer.c	2004-05-13 10:48:25.210239008 -0400
@@ -38,6 +38,7 @@
 #include <linux/bio.h>
 #include <linux/notifier.h>
 #include <linux/cpu.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/bitops.h>
 
 static void invalidate_bh_lrus(void);
@@ -130,6 +131,7 @@
 			(!bh->b_page || !PageLocked(bh->b_page)))
 		buffer_error();
 
+	TRIG_EVENT(buf_wait_start_hook, bh);
 	do {
 		prepare_to_wait(wqh, &wait, TASK_UNINTERRUPTIBLE);
 		if (buffer_locked(bh)) {
@@ -141,6 +143,7 @@
 			io_schedule();
 		}
 	} while (buffer_locked(bh));
+	TRIG_EVENT(buf_wait_end_hook, bh);
 	finish_wait(wqh, &wait);
 }
 
Index: linux.t/fs/exec.c
===================================================================
--- linux.t.orig/fs/exec.c	2004-05-13 10:45:19.571460392 -0400
+++ linux.t/fs/exec.c	2004-05-13 10:48:25.212238704 -0400
@@ -49,6 +49,7 @@
 #include <linux/objrmap.h>
 #include <linux/ckrm.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/pgalloc.h>
@@ -1180,6 +1181,9 @@
 
 	retval = search_binary_handler(&bprm,regs);
 	if (retval >= 0) {
+		TRIG_EVENT(exec_hook, file->f_dentry->d_name.len,
+			file->f_dentry->d_name.name, regs);
+
 		free_arg_pages(&bprm);
 
 		ckrm_cb_exec(filename);
Index: linux.t/fs/ioctl.c
===================================================================
--- linux.t.orig/fs/ioctl.c	2004-05-13 10:45:18.698593088 -0400
+++ linux.t/fs/ioctl.c	2004-05-13 10:48:25.213238552 -0400
@@ -10,6 +10,7 @@
 #include <linux/fs.h>
 #include <linux/fshooks.h>
 #include <linux/security.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/ioctls.h>
@@ -68,6 +69,7 @@
                 goto out;
         }
 
+	TRIG_EVENT(ioctl_hook, fd, cmd);
 	lock_kernel();
 	switch (cmd) {
 		case FIOCLEX:
Index: linux.t/fs/open.c
===================================================================
--- linux.t.orig/fs/open.c	2004-05-13 10:45:19.064537456 -0400
+++ linux.t/fs/open.c	2004-05-13 10:48:25.215238248 -0400
@@ -23,6 +23,7 @@
 #include <linux/fs.h>
 #include <linux/fshooks.h>
 #include <linux/pagemap.h>
+#include <linux/trigevent_hooks.h>
 
 int vfs_statfs(struct super_block *sb, struct kstatfs *buf)
 {
@@ -1010,9 +1011,12 @@
 		if (fd >= 0) {
 			struct file *f = filp_open(tmp, flags, mode);
 
-			if (!IS_ERR(f))
+			if (!IS_ERR(f)) {
+				TRIG_EVENT(open_hook, fd,
+					  f->f_dentry->d_name.len,
+					  f->f_dentry->d_name.name); 
 				fd_install(fd, f);
-			else {
+			} else {
 				put_unused_fd(fd);
 				fd = PTR_ERR(f);
 			}
@@ -1089,6 +1093,7 @@
 	if (fd < files->max_fds) {
 		filp = files->fd[fd];
 		if (filp) {
+			TRIG_EVENT(close_hook, fd);
 			files->fd[fd] = NULL;
 			FD_CLR(fd, files->close_on_exec);
 			__put_unused_fd(files, fd);
Index: linux.t/fs/read_write.c
===================================================================
--- linux.t.orig/fs/read_write.c	2004-05-13 10:45:19.067537000 -0400
+++ linux.t/fs/read_write.c	2004-05-13 10:48:25.217237944 -0400
@@ -14,6 +14,7 @@
 #include <linux/security.h>
 #include <linux/module.h>
 #include <linux/fshooks.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 
@@ -149,6 +150,7 @@
 			retval = -EOVERFLOW;	/* LFS: should only happen on 32 bit platforms */
 	}
 	fput_light(file, fput_needed);
+	TRIG_EVENT(lseek_hook, fd, offset);
 bad:
 	FSHOOK_END(lseek, retval >= 0 ? 0 : retval)
 
@@ -185,6 +187,7 @@
 	offset = llseek(file, ((loff_t) offset_high << 32) | offset_low,
 			origin);
 
+	TRIG_EVENT(llseek_hook, fd, offset);
 	retval = (int)offset;
 	if (offset >= 0) {
 		retval = -EFAULT;
@@ -299,6 +302,7 @@
 	ret = -EBADF;
 	file = fget_light(fd, &fput_needed);
 	if (file) {
+		TRIG_EVENT(read_hook, fd, count);
 		ret = vfs_read(file, buf, count, &file->f_pos);
 		fput_light(file, fput_needed);
 	}
@@ -320,6 +324,7 @@
 	ret = -EBADF;
 	file = fget_light(fd, &fput_needed);
 	if (file) {
+		TRIG_EVENT(write_hook, fd, count);
 		ret = vfs_write(file, buf, count, &file->f_pos);
 		fput_light(file, fput_needed);
 	}
@@ -346,6 +351,7 @@
 
 	file = fget_light(fd, &fput_needed);
 	if (file) {
+		TRIG_EVENT(read_hook, fd, count);
 		ret = vfs_read(file, buf, count, &pos);
 		fput_light(file, fput_needed);
 	}
@@ -373,6 +379,7 @@
 
 	file = fget_light(fd, &fput_needed);
 	if (file) {
+		TRIG_EVENT(write_hook, fd, count);
 		ret = vfs_write(file, buf, count, &pos);
 		fput_light(file, fput_needed);
 	}
@@ -563,6 +570,7 @@
 	ret = -EBADF;
 	file = fget_light(fd, &fput_needed);
 	if (file) {
+		TRIG_EVENT(read_hook, fd, vlen);
 		ret = vfs_readv(file, vec, vlen, &file->f_pos);
 		fput_light(file, fput_needed);
 	}
@@ -584,6 +592,7 @@
 	ret = -EBADF;
 	file = fget_light(fd, &fput_needed);
 	if (file) {
+		TRIG_EVENT(write_hook, fd, vlen);
 		ret = vfs_writev(file, vec, vlen, &file->f_pos);
 		fput_light(file, fput_needed);
 	}
Index: linux.t/fs/select.c
===================================================================
--- linux.t.orig/fs/select.c	2004-05-13 10:45:19.097532440 -0400
+++ linux.t/fs/select.c	2004-05-13 10:48:25.219237640 -0400
@@ -23,6 +23,7 @@
 #include <linux/fs.h>
 #include <linux/fshooks.h>
 #include <linux/aio.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 
@@ -257,6 +258,7 @@
 					continue;
 				file = fget(i);
 				if (file) {
+					TRIG_EVENT(select_hook, i, __timeout);
 					f_op = file->f_op;
 					mask = DEFAULT_POLLMASK;
 					if (f_op && f_op->poll)
@@ -447,6 +449,7 @@
 			struct file * file = fget(fd);
 			mask = POLLNVAL;
 			if (file != NULL) {
+				TRIG_EVENT(poll_hook, fd);
 				mask = DEFAULT_POLLMASK;
 				if (file->f_op && file->f_op->poll)
 					mask = file->f_op->poll(file, *pwait);
Index: linux.t/include/asm-generic/hook.h
===================================================================
--- linux.t.orig/include/asm-generic/hook.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/asm-generic/hook.h	2004-05-13 10:48:25.220237488 -0400
@@ -0,0 +1,25 @@
+#ifndef __ASM_GENERIC_HOOK_H
+#define __ASM_GENERIC_HOOK_H
+/*
+ * Kernel Hooks common code for many archs.
+ * 
+ * Authors: Vamsi Krishna S. <vamsi_krishna@in.ibm.com>
+ */
+#include <asm/cacheflush.h>
+
+static inline void deactivate_asm_hook(struct hook *hook)
+{
+	unsigned char *addr = (unsigned char *) (hook->hook_addr);
+	addr[2] = 0;
+	flush_icache_range((unsigned long) addr + 2, (unsigned long) addr + 2);
+	return;
+}
+
+static inline void activate_asm_hook(struct hook *hook)
+{
+	unsigned char *addr = (unsigned char *) (hook->hook_addr);
+	addr[2] = 1;
+	flush_icache_range((unsigned long) addr + 2, (unsigned long) addr + 2);
+	return;
+}
+#endif /* __ASM_GENERIC_HOOK_H */
Index: linux.t/include/asm-i386/hook.h
===================================================================
--- linux.t.orig/include/asm-i386/hook.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/asm-i386/hook.h	2004-05-13 10:48:25.221237336 -0400
@@ -0,0 +1,106 @@
+#ifndef __ASM_I386_HOOK_H
+#define __ASM_I386_HOOK_H
+/*
+ * Kernel Hooks optimized for ia32.
+ * 
+ * Authors: Richard J Moore <richardj_moore@uk.ibm.com>
+ *	    Vamsi Krishna S. <vamsi_krishna@in.ibm.com>
+ */
+#include <linux/smp.h>
+#include <asm/cacheflush.h>
+
+#if defined(CONFIG_HOOK) || defined(CONFIG_HOOK_MODULE)
+
+#define IF_HOOK_ENABLED(h, hk) _IF_HOOK_ENABLED(h, #hk)
+#define _IF_HOOK_ENABLED(h, hk) \
+	register int tmp; \
+	__asm__ __volatile__ (".global "hk"; "hk":movl $0, %0":"=r"(tmp)); \
+	if (unlikely(tmp))
+
+#endif /* CONFIG_HOOK || CONFIG_HOOK_MODULE */
+
+/*
+ * Sanity check the hook location for expected instructions at hook location.
+ * movl $0, %reg, testl %reg, %reg
+ * test doesn't have to follow movl, so don't test for that.
+ */
+#define OPCODE_MOV1			0xb0
+#define OPCODE_MOV1_MASK		0xf0
+#define OPCODE_MOV2_1			0xc6 /* first byte */
+#define OPCODE_MOV2_2			0xc0 /* second byte */
+#define OPCODE_MOV2_1_MASK		0xfe
+#define OPCODE_MOV2_2_MASK		0xf8
+		
+static inline int is_asm_hook(unsigned char *addr)
+{
+	if (!addr)
+		return 0;
+	if((addr[0] & OPCODE_MOV1_MASK) == OPCODE_MOV1) {
+		if (*((unsigned long *)(addr+1)) == 0)
+			return 1;
+	} else if (((addr[0] & OPCODE_MOV2_1_MASK) == OPCODE_MOV2_1) && 
+		    ((addr[1] & OPCODE_MOV2_2_MASK) == OPCODE_MOV2_2)) {
+		if (*((unsigned long *)(addr+2)) == 0)
+			return 1;
+	}
+	return 0;
+}
+ 
+#if defined(CONFIG_SMP)
+/*
+ * This routine loops around a memory flag and once it is set to one, syncronizes the
+ * instruction cache by executing CPUID instruction.
+ */ 
+static void wait_for_memory_flag(atomic_t *memory_flag) 
+{
+	while (!atomic_read(memory_flag))
+		;
+	__asm__ __volatile__ ("cpuid" : : : "ax", "bx", "cx", "dx");
+	return;
+}
+
+#endif
+static inline void deactivate_asm_hook(struct hook *hook)
+{
+	unsigned char *addr = (unsigned char *) (hook->hook_addr);
+/*
+ * Fix for Intel Pentium and P6 family processors E49 errata (Unsyncronized 
+ * cross modifying code). Send an IPI to all CPUs except self and then modify
+ * the contents of hook_addr before other CPUs return from IPI.
+ */
+#if defined(CONFIG_SMP)
+	atomic_set(&hook->hook_deactivate, 0); 
+	mb(); 
+	smp_call_function((void *)wait_for_memory_flag, &hook->hook_deactivate, 1, 0); 
+#endif
+	addr[2] = 0;
+	flush_icache_range(addr + 2, addr + 2);
+#if defined(CONFIG_SMP)
+	atomic_set(&hook->hook_deactivate, 1); 
+	mb(); 
+#endif
+	return;
+}
+
+static inline void activate_asm_hook(struct hook *hook)
+{
+	unsigned char *addr = (unsigned char *) (hook->hook_addr);
+/*
+ * Fix for Intel Pentium and P6 family processors E49 errata (Unsyncronized 
+ * cross modifying code). Send an IPI to all CPUs except self and then modify 
+ * the contents of hook_addr before other CPUs return from IPI.
+ */
+#if defined(CONFIG_SMP)
+	atomic_set(&hook->hook_activate, 0); 
+	mb(); 
+	smp_call_function((void *)wait_for_memory_flag, &hook->hook_activate, 1, 0); 
+#endif
+	addr[2] = 1;
+	flush_icache_range(addr + 2, addr + 2);
+#if defined(CONFIG_SMP)
+	atomic_set(&hook->hook_activate, 1); 
+	mb(); 
+#endif
+	return;
+}
+#endif /* __ASM_I386_HOOK_H */
Index: linux.t/include/asm-i386/ltt.h
===================================================================
--- linux.t.orig/include/asm-i386/ltt.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/asm-i386/ltt.h	2004-05-13 10:48:25.222237184 -0400
@@ -0,0 +1,15 @@
+/*
+ * linux/include/asm-i386/ltt.h
+ *
+ * Copyright (C) 2002, Karim Yaghmour
+ *
+ * i386 definitions for tracing system
+ */
+
+#include <linux/ltt.h>
+
+/* Current arch type */
+#define TRACE_ARCH_TYPE TRACE_ARCH_TYPE_I386
+
+/* Current variant type */
+#define TRACE_ARCH_VARIANT TRACE_ARCH_VARIANT_NONE
Index: linux.t/include/asm-mips/mipsregs.h
===================================================================
--- linux.t.orig/include/asm-mips/mipsregs.h	2004-03-12 16:27:36.000000000 -0500
+++ linux.t/include/asm-mips/mipsregs.h	2004-05-13 10:48:25.238234752 -0400
@@ -525,6 +525,9 @@
 
 #ifndef __ASSEMBLY__
 
+#define CAUSE_EXCCODE(x) ((CAUSEF_EXCCODE & (x->cp0_cause)) >> CAUSEB_EXCCODE)
+#define CAUSE_EPC(x) (x->cp0_epc + (((x->cp0_cause & CAUSEF_BD) >> CAUSEB_BD) << 2))
+
 /*
  * Functions to access the r10k performance counter and control registers
  */
Index: linux.t/include/asm-ppc/hook.h
===================================================================
--- linux.t.orig/include/asm-ppc/hook.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/asm-ppc/hook.h	2004-05-13 10:48:25.239234600 -0400
@@ -0,0 +1,47 @@
+#ifndef __ASM_PPC_HOOK_H
+#define __ASM_PPC_HOOK_H
+/*
+ * Kernel Hooks optimized for PPC.
+ * 
+ * Authors: Mike Grundy <grundym@us.ibm.com> s390x
+ */
+#include <asm-generic/hook.h>
+
+#if defined(CONFIG_HOOK) || defined(CONFIG_HOOK_MODULE)
+
+#define IF_HOOK_ENABLED(h, hk) _IF_HOOK_ENABLED(h, #hk)
+#define _IF_HOOK_ENABLED(h, hk) \
+	register int tmp; \
+	__asm__ __volatile__ (".global "hk"; "hk":li %0, 0x00":"=r"(tmp)); \
+	if (unlikely(tmp))
+
+#endif /* CONFIG_HOOK || CONFIG_HOOK_MODULE */
+
+
+/*
+ * Sanity check the hook location for valid instructions at hook location.
+ * At hook location, we should find these instructions:
+ *	38 00 00 00       	li    	r0,0
+ *	2c 00 00 00            	cmpwi	r0,0
+ *	
+ * We can check for li and cmpwi instructions. As these instructions encode
+ * the register name in the second byte and the register cannot be predicted, 
+ * we mask out the bits corresponding to registers in the opcode before comparing.
+ * PPC opcodes are six bits, hence mask of 0xFC
+ */
+#define OPCODE_MOV1			0x38 /* LI (really an extended mnemonic for addi */   
+#define OPCODE_MOV1_MASK		0xFC
+/* Compiler generates 2c 00 00 00     cmpwi   r0,0 */
+		
+static inline int is_asm_hook(unsigned char * addr)
+{
+	if (!addr)
+		return 0;
+	
+	if((addr[0] & OPCODE_MOV1_MASK) == OPCODE_MOV1) {
+		if (*((unsigned short *)(addr+1)) == 0)
+			return 1;
+	}
+	return 0;
+}
+#endif /* __ASM_PPC_HOOK_H */
Index: linux.t/include/asm-ppc64/hook.h
===================================================================
--- linux.t.orig/include/asm-ppc64/hook.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/asm-ppc64/hook.h	2004-05-13 10:48:25.240234448 -0400
@@ -0,0 +1,47 @@
+#ifndef __ASM_PPC_HOOK_H
+#define __ASM_PPC_HOOK_H
+/*
+ * Kernel Hooks optimized for PPC64.
+ * 
+ * Authors: Mike Grundy <grundym@us.ibm.com> PPC64
+ */
+#include <asm-generic/hook.h>
+
+#if defined(CONFIG_HOOK) || defined(CONFIG_HOOK_MODULE)
+
+#define IF_HOOK_ENABLED(h, hk) _IF_HOOK_ENABLED(h, #hk)
+#define _IF_HOOK_ENABLED(h, hk) \
+	register int tmp; \
+	__asm__ __volatile__ (".global "hk"; "hk":li %0, 0x00":"=r"(tmp)); \
+	if (unlikely(tmp))
+
+#endif /* CONFIG_HOOK || CONFIG_HOOK_MODULE */
+
+
+/*
+ * Sanity check the hook location for valid instructions at hook location.
+ * At hook location, we should find these instructions:
+ *	38 00 00 00       	li    	r0,0
+ *	2c 00 00 00            	cmpwi	r0,0
+ *	
+ * We can check for li and cmpwi instructions. As these instructions encode
+ * the register name in the second byte and the register cannot be predicted, 
+ * we mask out the bits corresponding to registers in the opcode before comparing.
+ * PPC opcodes are six bits, hence mask of 0xFC
+ */
+#define OPCODE_MOV1			0x38 /* LI (really an extended mnemonic for addi */   
+#define OPCODE_MOV1_MASK		0xFC
+/* Compiler generates 2c 00 00 00     cmpwi   r0,0 */
+		
+static inline int is_asm_hook(unsigned char * addr)
+{
+	if (!addr)
+		return 0;
+	
+	if((addr[0] & OPCODE_MOV1_MASK) == OPCODE_MOV1) {
+		if (*((unsigned short *)(addr+1)) == 0)
+			return 1;
+	}
+	return 0;
+}
+#endif /* __ASM_PPC_HOOK_H */
Index: linux.t/include/asm-s390/hook.h
===================================================================
--- linux.t.orig/include/asm-s390/hook.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/asm-s390/hook.h	2004-05-13 10:48:25.241234296 -0400
@@ -0,0 +1,49 @@
+#ifndef __ASM_S390_HOOK_H
+#define __ASM_S390_HOOK_H
+/*
+ * Kernel Hooks optimized for s390.
+ * 
+ * Authors: Mike Grundy <grundym@us.ibm.com> s390
+ */
+#include <asm-generic/hook.h>
+
+#if defined(CONFIG_HOOK) || defined(CONFIG_HOOK_MODULE)
+
+#define IF_HOOK_ENABLED(h, hk) _IF_HOOK_ENABLED(h, #hk)
+#define _IF_HOOK_ENABLED(h, hk) \
+	register int tmp; \
+	__asm__ __volatile__ (".global "hk"; "hk":lhi %0, 0x00":"=r"(tmp)); \
+	if (unlikely(tmp))
+
+#endif /* CONFIG_HOOK || CONFIG_HOOK_MODULE */
+
+/*
+ * Sanity check the hook location for valid instructions at hook location.
+ * At hook location, we should find these instructions:
+ *  a7 18 00 00             lhi     %r1,0
+ *  12 11                   ltr     %r1,%r1
+ * We can check for the lhi and ltr instructions. As the lhi instruction encodes
+ * the register name in it, and we can't guarantee which register will be used,
+ * we'll mask out the bits corresponding to the target register.
+ */
+#define OPCODE_MOV2_1			0xa7 /* LHI first byte */
+#define OPCODE_MOV2_2			0x08 /* LHI second byte */
+#define OPCODE_MOV2_1_MASK		0xff
+#define OPCODE_MOV2_2_MASK		0x0f
+/* Compiler generates LTR opcode 12, but second op not tested */
+		
+static inline int is_asm_hook(unsigned char * addr)
+{
+	if (!addr){
+		return 0;
+	}
+	if (((addr[0] & OPCODE_MOV2_1_MASK) == OPCODE_MOV2_1) && 
+		    ((addr[1] & OPCODE_MOV2_2_MASK) == OPCODE_MOV2_2)) {
+		/* was checking a 32bit val, need to check 16, cheated with 8+8 */
+		if (addr[2]== 0 && addr[3]== 0){
+			return 1;
+		}
+	}
+	return 0;
+}
+#endif /* __ASM_S390_HOOK_H */
Index: linux.t/include/asm-s390x/hook.h
===================================================================
--- linux.t.orig/include/asm-s390x/hook.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/asm-s390x/hook.h	2004-05-13 10:48:25.242234144 -0400
@@ -0,0 +1,49 @@
+#ifndef __ASM_S390X_HOOK_H
+#define __ASM_S390X_HOOK_H
+/*
+ * Kernel Hooks optimized for s390x(64bit).
+ * 
+ * Authors: Mike Grundy <grundym@us.ibm.com> s390x
+ */
+#include <asm-generic/hook.h>
+
+#if defined(CONFIG_HOOK) || defined(CONFIG_HOOK_MODULE)
+
+#define IF_HOOK_ENABLED(h, hk) _IF_HOOK_ENABLED(h, #hk)
+#define _IF_HOOK_ENABLED(h, hk) \
+	register int tmp; \
+	__asm__ __volatile__ (".global "hk"; "hk":lhi %0, 0x00":"=r"(tmp)); \
+	if (unlikely(tmp))
+
+#endif /* CONFIG_HOOK || CONFIG_HOOK_MODULE */
+
+/*
+ * Sanity check the hook location for valid instructions at hook location.
+ * At hook location, we should find these instructions:
+ *  a7 18 00 00             lhi     %r1,0
+ *  12 11                   ltr     %r1,%r1
+ * We can check for the lhi and ltr instructions. As the lhi instruction encodes
+ * the register name in it, and we can't guarantee which register will be used,
+ * we'll mask out the bits corresponding to the target register.
+ */
+#define OPCODE_MOV2_1			0xa7 /* LHI first byte */
+#define OPCODE_MOV2_2			0x08 /* LHI second byte */
+#define OPCODE_MOV2_1_MASK		0xff
+#define OPCODE_MOV2_2_MASK		0x0f
+/* Compiler generates LTR opcode 12, but second op not tested */
+		
+static inline int is_asm_hook(unsigned char * addr)
+{
+	if (!addr){
+		return 0;
+	}
+	if (((addr[0] & OPCODE_MOV2_1_MASK) == OPCODE_MOV2_1) && 
+		    ((addr[1] & OPCODE_MOV2_2_MASK) == OPCODE_MOV2_2)) {
+		/* was checking a 32bit val, need to check 16, cheated with 8+8 */
+		if (addr[2]== 0 && addr[3]== 0){
+			return 1;
+		}
+	}
+	return 0;
+}
+#endif /* __ASM_S390X_HOOK_H */
Index: linux.t/include/linux/hook.h
===================================================================
--- linux.t.orig/include/linux/hook.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/linux/hook.h	2004-05-13 10:48:25.243233992 -0400
@@ -0,0 +1,238 @@
+#ifndef __LINUX_HOOK_H
+#define __LINUX_HOOK_H
+/*
+ * Kernel Hooks Interface.
+ * 
+ * Authors: Richard J Moore <richardj_moore@uk.ibm.com>
+ *	    Vamsi Krishna S. <vamsi_krishna@in.ibm.com>
+ * (C) Copyright IBM Corp. 2002, 2003
+ */
+#include <linux/compiler.h>
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <linux/list.h>
+
+/* define the user (kernel module) hook structure */
+struct hook_rec;
+struct hook;
+
+struct hook_rec {
+	void *hook_exit;
+	struct list_head exit_list;
+	unsigned int hook_flags;
+	unsigned int hook_index;
+	struct hook *hook_head;
+/*fields required for adding proc entries */
+	char *hook_exit_name;
+	struct proc_dir_entry *proc_entry;
+	int proc_writable;
+};
+
+struct hook {
+	struct list_head exit_list;
+	unsigned int hook_flags;
+	unsigned int hook_index;
+	void *hook_addr;
+	void *hook_ex_exit;
+/*fields required for adding proc entries */
+	struct proc_dir_entry *proc_entry;
+	char *hook_id;
+	atomic_t hook_activate;
+	atomic_t hook_deactivate;
+};
+
+/* hook flags */
+#define HOOK_ARMED		0x00000001
+#define HOOK_PRIORITY_FIRST	0x00000004
+#define HOOK_PRIORITY_LAST	0x00000008
+#define HOOK_QUEUE_LIFO		0x00000010
+
+/* flag groupings */
+#define HOOK_PRIORITY		(HOOK_PRIORITY_FIRST | HOOK_PRIORITY_LAST)
+#define HOOK_QUEUE		HOOK_QUEUE_LIFO
+#define HOOK_VALID_USER_FLAGS	(HOOK_PRIORITY | HOOK_QUEUE)
+
+/*
+ * Use the DECLARE_HOOK macro to define the hook structure in global 
+ * memory of a kernel module that is implementing a hook.
+ */
+#if defined(CONFIG_HOOK) || defined(CONFIG_HOOK_MODULE)
+
+#define HOOK_SYM(h) _HOOK_SYM(h)
+#define _HOOK_SYM(h) h##_hook
+
+#define DECLARE_HOOK(name) _DECLARE_HOOK(name, HOOK_SYM(name))
+#define _DECLARE_HOOK(name, hk) \
+extern void hk; \
+struct hook name = { \
+	.hook_addr 	= &(hk), 			  \
+	.exit_list	= LIST_HEAD_INIT(name.exit_list), \
+	.hook_index	= 0,				  \
+	.hook_id	= #name,			  \
+}; \
+EXPORT_SYMBOL(name);
+
+#define DECLARE_EXCLUSIVE_HOOK(name) _DECLARE_EXCLUSIVE_HOOK(name, HOOK_SYM(name))
+#define _DECLARE_EXCLUSIVE_HOOK(name, hk) \
+extern void hk; \
+struct hook name = { \
+	.hook_addr 	= &(hk), 			  \
+	.exit_list	= LIST_HEAD_INIT(name.exit_list), \
+	.hook_flags	= HOOK_EXCLUSIVE,		  \
+	.hook_index	= 0,				  \
+	.hook_id	= #name,			  \
+}; \
+EXPORT_SYMBOL(name);
+
+/*
+ * Generic hooks are the same in all architectures and may be used to
+ * place hooks even in inline functions. They don't define a symbol at hook
+ * location.
+ */ 
+
+#define DECLARE_GENERIC_HOOK(name) _DECLARE_GENERIC_HOOK(name)
+#define _DECLARE_GENERIC_HOOK(name) \
+struct hook name = { \
+	.hook_addr 	= &(name), 			  \
+	.exit_list	= LIST_HEAD_INIT(name.exit_list), \
+	.hook_id	= #name,			  \
+}; \
+EXPORT_SYMBOL(name);
+
+#define USE_HOOK(name) _USE_HOOK(name)
+#define _USE_HOOK(name) extern struct hook name
+
+/* define head record only flags */
+#define HOOK_ACTIVE	0x80000000
+#define HOOK_ASM_HOOK	0x40000000
+#define HOOK_EXCLUSIVE	0x20000000
+
+/* global status flags */
+#define HOOK_INIT       1
+
+typedef int (*hook_fn_t)(struct hook *, ...);
+
+#ifdef CONFIG_ASM_HOOK
+#include <asm/hook.h>
+#else
+static inline int is_asm_hook(unsigned char *addr) {return 0;}
+static inline void activate_asm_hook(struct hook *hook) { }
+static inline void deactivate_asm_hook(struct hook *hook) { }
+#endif
+
+#ifndef IF_HOOK_ENABLED
+#define IF_HOOK_ENABLED(h, hk) _IF_HOOK_ENABLED(h, #hk)
+#define _IF_HOOK_ENABLED(h, hk) \
+	__asm__ __volatile__ (".global "hk"; "hk":"); \
+	if (unlikely(h.hook_flags & HOOK_ACTIVE))
+#endif
+
+#define HOOK_TEST(h) \
+	extern struct hook h; \
+	IF_HOOK_ENABLED(h, h##_hook)
+
+#define CALL_EXIT(fn, parm, args ...) (((hook_fn_t)(fn))(parm , ##args))
+
+#define DISPATCH_NORMAL(fn, parm, dsprc, args...) \
+	dsprc = CALL_EXIT(fn, parm , ##args);
+
+#define DISPATCH_RET(fn, parm, dsprc, args...) { \
+	int rc; \
+	dsprc = CALL_EXIT(fn, parm, &rc , ##args); \
+	if (dsprc == HOOK_RETURN) \
+		return rc; \
+}
+
+#define DISPATCH_RET_NORC(fn, parm, dsprc, args...) { \
+	dsprc = CALL_EXIT(fn, parm , ##args); \
+	if (dsprc == HOOK_RETURN) \
+		return; \
+}
+
+#define HOOK_DISP_LOOP(h, dispatch, args...) { \
+	register struct hook_rec *rec; \
+	list_for_each_entry(rec, &h.exit_list, exit_list) { \
+		register int dsprc; \
+		if (rec->hook_flags & HOOK_ARMED) { \
+			dispatch(rec->hook_exit, rec->hook_head, dsprc , ##args) \
+			if (dsprc == HOOK_TERMINATE) \
+				break; \
+		} \
+	} \
+}
+
+#define HOOK_DISP_EXCLUSIVE(h, dispatch, args...) { \
+	register int dsprc; \
+	if (h.hook_flags & HOOK_ACTIVE) { \
+		dispatch(h.hook_ex_exit, &h, dsprc , ##args) \
+	} \
+}
+
+#define HOOK(h, args...) { \
+	HOOK_TEST(h) \
+	HOOK_DISP_LOOP(h, DISPATCH_NORMAL , ##args); \
+}
+
+#define HOOK_RET(h, args...) { \
+	HOOK_TEST(h) \
+	HOOK_DISP_LOOP(h, DISPATCH_RET , ##args); \
+}
+
+#define HOOK_RET_NORC(h, args...) { \
+	HOOK_TEST(h) \
+	HOOK_DISP_LOOP(h, DISPATCH_RET_NORC , ##args); \
+}
+
+#define EXCLUSIVE_HOOK(h, args...) { \
+	HOOK_TEST(h) \
+	HOOK_DISP_EXCLUSIVE(h, DISPATCH_NORMAL , ##args); \
+}
+
+#define EXCLUSIVE_HOOK_RET(h, args...) { \
+	HOOK_TEST(h) \
+	HOOK_DISP_EXCLUSIVE(h, DISPATCH_RET , ##args); \
+}
+
+#define EXCLUSIVE_HOOK_RET_NORC(h, args...) { \
+	HOOK_TEST(h) \
+	HOOK_DISP_EXCLUSIVE(h, DISPATCH_RET_NORC , ##args); \
+}
+
+#define GENERIC_HOOK(h, args...) { \
+	extern struct hook h; \
+	if (unlikely(h.hook_flags & HOOK_ACTIVE)) { \
+		HOOK_DISP_LOOP(h, DISPATCH_NORMAL , ##args); \
+	} \
+}
+
+/* exported function prototypes */
+extern int hook_exit_register(struct hook *, struct hook_rec *);
+extern void hook_exit_deregister(struct hook_rec *);
+extern void hook_exit_arm(struct hook_rec *);
+extern void hook_exit_disarm(struct hook_rec *);
+
+/* exported functions error codes */
+#define EPRIORITY	1	/* reqd. priority not possible */
+#define ERROR_HIGHER_PRIORITY_HOOK 		-2
+#define ERROR_LOWER_PRIORITY_HOOK 		-4
+
+/* Return values from Hook Exit routines */
+#define HOOK_CONTINUE 	0
+#define HOOK_TERMINATE 	1
+#define HOOK_RETURN 	-1
+
+#else
+/* dummy macros when hooks are not compiled in */
+#define DECLARE_HOOK(x)
+#define DECLARE_GENERIC_HOOK(x)
+#define USE_HOOK(x)
+#define HOOK(h, args...)
+#define HOOK_RET(h, args...)
+#define HOOK_RET_NORC(h, args...)
+#define EXCLUSIVE_HOOK(h, args...)
+#define EXCLUSIVE_HOOK_RET(h, args...)
+#define EXCLUSIVE_HOOK_RET_NORC(h, args...)
+#define GENERIC_HOOK(h, args...)
+#endif /* !(CONFIG_HOOK || CONFIG_HOOK_MODULE) */
+
+#endif /* __LINUX_HOOK_H */
Index: linux.t/include/linux/ltt.h
===================================================================
--- linux.t.orig/include/linux/ltt.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/linux/ltt.h	2004-05-13 10:48:25.246233536 -0400
@@ -0,0 +1,777 @@
+/*
+ * linux/include/linux/ltt.h
+ *
+ * Copyright (C) 1999-2004 Karim Yaghmour (karim@opersys.com)
+ *
+ * This contains the necessary definitions for the Linux Trace Toolkit.
+ */
+
+#ifndef _LINUX_TRACE_H
+#define _LINUX_TRACE_H
+
+#include <linux/config.h>
+#include <linux/types.h>
+#include <linux/sched.h>
+
+#include <linux/relayfs_fs.h>
+
+/* Is kernel tracing enabled  */
+#if defined(CONFIG_LTT) 
+
+/* Don't set this to "1" unless you really know what you're doing */
+#define LTT_UNPACKED_STRUCTS	0
+
+/* Structure packing within the trace */
+#if LTT_UNPACKED_STRUCTS
+#define LTT_PACKED_STRUCT
+#else
+#define LTT_PACKED_STRUCT __attribute__ ((packed))
+#endif
+
+typedef u64 trace_event_mask;
+
+#define CUSTOM_EVENT_MAX_SIZE		8192
+#define CUSTOM_EVENT_TYPE_STR_LEN	20
+#define CUSTOM_EVENT_DESC_STR_LEN	100
+#define CUSTOM_EVENT_FORM_STR_LEN	256
+#define CUSTOM_EVENT_FINAL_STR_LEN	200
+
+#define CUSTOM_EVENT_FORMAT_TYPE_NONE	0
+#define CUSTOM_EVENT_FORMAT_TYPE_STR	1
+#define CUSTOM_EVENT_FORMAT_TYPE_HEX	2
+#define CUSTOM_EVENT_FORMAT_TYPE_XML	3
+#define CUSTOM_EVENT_FORMAT_TYPE_IBM	4
+
+#define TRACE_MAX_HANDLES		256
+
+/* In the ltt root directory lives the trace control file, used for
+   kernel-user communication. */
+#define TRACE_RELAYFS_ROOT		"ltt"
+#define TRACE_CONTROL_FILE		"control"
+
+/* We currently support 2 traces, normal trace and flight recorder */
+#define NR_TRACES			2
+#define TRACE_HANDLE			0
+#define FLIGHT_HANDLE			1
+
+/* Convenience accessors */
+#define waiting_for_cpu_async(trace_handle, cpu) (current_traces[trace_handle].relay_data[cpu].waiting_for_cpu_async)
+#define trace_channel_handle(trace_handle, cpu) (current_traces[trace_handle].relay_data[cpu].channel_handle)
+#define trace_channel_reader(trace_handle, cpu) (current_traces[trace_handle].relay_data[cpu].reader)
+#define trace_buffers_full(cpu) (daemon_relay_data[cpu].buffers_full)
+#define events_lost(trace_handle, cpu) (current_traces[trace_handle].relay_data[cpu].events_lost)
+
+/* System types */
+#define TRACE_SYS_TYPE_VANILLA_LINUX	1
+
+/* Architecture types */
+#define TRACE_ARCH_TYPE_I386			1
+#define TRACE_ARCH_TYPE_PPC			2
+#define TRACE_ARCH_TYPE_SH			3
+#define TRACE_ARCH_TYPE_S390			4
+#define TRACE_ARCH_TYPE_MIPS			5
+#define TRACE_ARCH_TYPE_ARM			6
+
+/* Standard definitions for variants */
+#define TRACE_ARCH_VARIANT_NONE             0   /* Main architecture implementation */
+
+/* The maximum number of CPUs the kernel might run on */
+#define MAX_NR_CPUS 32
+
+/* Per-CPU channel information */
+struct channel_data
+{
+	int channel_handle;
+	struct rchan_reader *reader;
+	atomic_t waiting_for_cpu_async;
+	u32 events_lost;
+};
+
+/* Per-trace status info */
+struct trace_info
+{
+	int			active;
+	unsigned int		trace_handle;
+	int			paused;
+	int			flight_recorder;
+	int			use_locking;
+	int			using_tsc;
+	u32			n_buffers;
+	u32			buf_size;
+	trace_event_mask	traced_events;
+	trace_event_mask	log_event_details_mask;
+	u32			buffers_produced[MAX_NR_CPUS];
+};
+
+/* Status info for all traces */
+struct tracer_status
+{
+	int num_cpus;
+	struct trace_info traces[NR_TRACES];
+};
+
+/* Per-trace information - each trace/flight recorder represented by one */
+struct trace_struct
+{
+	unsigned int		trace_handle;	/* For convenience */
+	struct trace_struct	*active;	/* 'this' if active, or NULL */
+	int			paused;		/* Not currently logging */
+	struct channel_data relay_data[NR_CPUS];/* Relayfs handles, by CPU */
+	int			flight_recorder;/* i.e. this is not a trace */
+	struct task_struct	*daemon_task_struct;/* Daemon associated with trace */
+	struct _trace_start	*trace_start_data; /* Trace start event data, for flight recorder */
+	int			tracer_started;
+	int			tracer_stopping;
+	struct proc_dir_entry *	proc_dir_entry;	/* proc/ltt/0..1 */
+	trace_event_mask	traced_events;
+	trace_event_mask	log_event_details_mask;
+	u32			n_buffers;	/* Number of sub-buffers */
+	u32			buf_size;	/* Size of sub-buffer */
+	int			use_locking;
+	int			using_tsc;
+	int			log_cpuid;
+	int			tracing_pid;
+	int			tracing_pgrp;
+	int			tracing_gid;
+	int			tracing_uid;
+	pid_t			traced_pid;
+	pid_t			traced_pgrp;
+	gid_t			traced_gid;
+	uid_t			traced_uid;
+	unsigned long		buffer_switches_pending;/* For trace */
+	struct work_struct	work;	/* stop work struct */
+
+};
+
+
+extern int ltt_set_trace_config(
+	int		do_syscall_depth,
+	int		do_syscall_bounds,
+	int		eip_depth,
+	void		*eip_lower_bound,
+	void		*eip_upper_bound);
+extern int ltt_get_trace_config(
+	int		*do_syscall_depth,
+	int		*do_syscall_bounds,
+	int		*eip_depth,
+	void		**eip_lower_bound,
+	void		**eip_upper_bound);
+extern int ltt_create_event(
+	char		*event_type,
+	char		*event_desc,
+	int		format_type,
+	char		*format_data);
+extern int ltt_create_owned_event(
+	char		*event_type,
+	char		*event_desc,
+	int		format_type,
+	char		*format_data,
+	pid_t		owner_pid);
+extern void ltt_destroy_event(
+	int		event_id);
+extern void ltt_destroy_owners_events(
+	pid_t		owner_pid);
+extern void ltt_reregister_custom_events(void);
+extern int ltt_log_std_formatted_event(
+	int		event_id,
+	...);
+extern int ltt_log_raw_event(
+	int		event_id,
+	int		event_size,
+	void		*event_data);
+extern int _ltt_log_event(
+	struct trace_struct *trace,
+	u8		event_id,
+	void		*event_struct,
+	u8		cpu_id);
+extern int ltt_log_event(
+	u8		event_id,
+	void		*event_struct);
+extern int ltt_valid_trace_handle(
+	unsigned int	tracer_handle);
+extern int ltt_alloc_trace_handle(
+	unsigned int	tracer_handle);
+extern int ltt_free_trace_handle(
+	unsigned int	tracer_handle);
+extern int ltt_free_daemon_handle(
+	struct trace_struct *trace);
+extern void ltt_free_all_handles(
+	struct task_struct*	task_ptr);
+extern int ltt_set_buffer_size(
+	struct trace_struct *trace,
+	int		buffers_size, 
+	char *		dirname);
+extern int ltt_set_n_buffers(
+	struct trace_struct *trace,
+	int		no_buffers);
+extern int ltt_set_default_config(
+	struct trace_struct *trace);
+extern void ltt_flight_pause(
+	void);
+extern void ltt_flight_unpause(
+	void);
+
+static inline void TRACE_EVENT(u8 event_id, void* data)
+{
+	ltt_log_event(event_id, data);
+}
+
+/* Traced events */
+enum {
+	TRACE_EV_START = 0,	/* This is to mark the trace's start */
+	TRACE_EV_SYSCALL_ENTRY,	/* Entry in a given system call */
+	TRACE_EV_SYSCALL_EXIT,	/* Exit from a given system call */
+	TRACE_EV_TRAP_ENTRY,	/* Entry in a trap */
+	TRACE_EV_TRAP_EXIT,	/* Exit from a trap */
+	TRACE_EV_IRQ_ENTRY,	/* Entry in an irq */
+	TRACE_EV_IRQ_EXIT,	/* Exit from an irq */
+	TRACE_EV_SCHEDCHANGE,	/* Scheduling change */
+	TRACE_EV_KERNEL_TIMER,	/* The kernel timer routine has been called */
+	TRACE_EV_SOFT_IRQ,	/* Hit key part of soft-irq management */
+	TRACE_EV_PROCESS,	/* Hit key part of process management */
+	TRACE_EV_FILE_SYSTEM,	/* Hit key part of file system */
+	TRACE_EV_TIMER,		/* Hit key part of timer management */
+	TRACE_EV_MEMORY,	/* Hit key part of memory management */
+	TRACE_EV_SOCKET,	/* Hit key part of socket communication */
+	TRACE_EV_IPC,		/* Hit key part of System V IPC */
+	TRACE_EV_NETWORK,	/* Hit key part of network communication */
+	TRACE_EV_BUFFER_START,	/* Mark the begining of a trace buffer */
+	TRACE_EV_BUFFER_END,	/* Mark the ending of a trace buffer */
+	TRACE_EV_NEW_EVENT,	/* New event type */
+	TRACE_EV_CUSTOM,	/* Custom event */
+	TRACE_EV_CHANGE_MASK,	/* Change in event mask */
+	TRACE_EV_HEARTBEAT	/* Heartbeat event */
+};
+
+/* Number of traced events */
+#define TRACE_EV_MAX           TRACE_EV_HEARTBEAT
+
+/* Information logged when a trace is started */
+#define TRACER_MAGIC_NUMBER     0x00D6B7ED
+#define TRACER_VERSION_MAJOR    2
+#define TRACER_VERSION_MINOR    2
+typedef struct _trace_start {
+	u32 magic_number;
+	u32 arch_type;
+	u32 arch_variant;
+	u32 system_type;
+	u8 major_version;
+	u8 minor_version;
+
+	u32 buffer_size;
+	trace_event_mask event_mask;
+	trace_event_mask details_mask;
+	u8 log_cpuid;
+	u8 use_tsc;
+	u8 flight_recorder;
+} LTT_PACKED_STRUCT trace_start;
+
+/*  TRACE_SYSCALL_ENTRY */
+typedef struct _trace_syscall_entry {
+	u8 syscall_id;		/* Syscall entry number in entry.S */
+	u32 address;		/* Address from which call was made */
+} LTT_PACKED_STRUCT trace_syscall_entry;
+
+/*  TRACE_TRAP_ENTRY */
+#ifndef __s390__
+typedef struct _trace_trap_entry {
+	u16 trap_id;		/* Trap number */
+	u32 address;		/* Address where trap occured */
+} LTT_PACKED_STRUCT trace_trap_entry;
+static inline void TRACE_TRAP_ENTRY(u16 trap_id, u32 address)
+#else
+typedef u64 trapid_t;
+typedef struct _trace_trap_entry {
+	trapid_t trap_id;	/* Trap number */
+	u32 address;		/* Address where trap occured */
+} LTT_PACKED_STRUCT trace_trap_entry;
+static inline void TRACE_TRAP_ENTRY(trapid_t trap_id, u32 address)
+#endif
+{
+	trace_trap_entry trap_event;
+
+	trap_event.trap_id = trap_id;
+	trap_event.address = address;
+
+	ltt_log_event(TRACE_EV_TRAP_ENTRY, &trap_event);
+}
+
+/*  TRACE_TRAP_EXIT */
+static inline void TRACE_TRAP_EXIT(void)
+{
+	ltt_log_event(TRACE_EV_TRAP_EXIT, NULL);
+}
+
+/*  TRACE_IRQ_ENTRY */
+typedef struct _trace_irq_entry {
+	u8 irq_id;		/* IRQ number */
+	u8 kernel;		/* Are we executing kernel code */
+} LTT_PACKED_STRUCT trace_irq_entry;
+static inline void TRACE_IRQ_ENTRY(u8 irq_id, u8 in_kernel)
+{
+	trace_irq_entry irq_entry;
+
+	irq_entry.irq_id = irq_id;
+	irq_entry.kernel = in_kernel;
+
+	ltt_log_event(TRACE_EV_IRQ_ENTRY, &irq_entry);
+}
+
+/*  TRACE_IRQ_EXIT */
+static inline void TRACE_IRQ_EXIT(void)
+{
+	ltt_log_event(TRACE_EV_IRQ_EXIT, NULL);
+}
+
+/*  TRACE_SCHEDCHANGE */
+typedef struct _trace_schedchange {
+	u32 out;		/* Outgoing process */
+	u32 in;			/* Incoming process */
+	u32 out_state;		/* Outgoing process' state */
+} LTT_PACKED_STRUCT trace_schedchange;
+static inline void TRACE_SCHEDCHANGE(task_t * task_out, task_t * task_in)
+{
+	trace_schedchange sched_event;
+
+	sched_event.out = (u32) task_out->pid;
+	sched_event.in = (u32) task_in;
+	sched_event.out_state = (u32) task_out->state;
+
+	ltt_log_event(TRACE_EV_SCHEDCHANGE, &sched_event);
+}
+
+/*  TRACE_SOFT_IRQ */
+enum {
+	TRACE_EV_SOFT_IRQ_BOTTOM_HALF = 1,	/* Conventional bottom-half */
+	TRACE_EV_SOFT_IRQ_SOFT_IRQ,		/* Real soft-irq */
+	TRACE_EV_SOFT_IRQ_TASKLET_ACTION,	/* Tasklet action */
+	TRACE_EV_SOFT_IRQ_TASKLET_HI_ACTION	/* Tasklet hi-action */
+};
+typedef struct _trace_soft_irq {
+	u8 event_sub_id;	/* Soft-irq event Id */
+	u32 event_data;
+} LTT_PACKED_STRUCT trace_soft_irq;
+static inline void TRACE_SOFT_IRQ(u8 ev_id, u32 data)
+{
+	trace_soft_irq soft_irq_event;
+
+	soft_irq_event.event_sub_id = ev_id;
+	soft_irq_event.event_data = data;
+
+	ltt_log_event(TRACE_EV_SOFT_IRQ, &soft_irq_event);
+}
+
+/*  TRACE_PROCESS */
+enum {
+	TRACE_EV_PROCESS_KTHREAD = 1,	/* Creation of a kernel thread */
+	TRACE_EV_PROCESS_FORK,		/* A fork or clone occured */
+	TRACE_EV_PROCESS_EXIT,		/* An exit occured */
+	TRACE_EV_PROCESS_WAIT,		/* A wait occured */
+	TRACE_EV_PROCESS_SIGNAL,	/* A signal has been sent */
+	TRACE_EV_PROCESS_WAKEUP		/* Wake up a process */
+};
+typedef struct _trace_process {
+	u8 event_sub_id;	/* Process event ID */
+	u32 event_data1;
+	u32 event_data2;
+} LTT_PACKED_STRUCT trace_process;
+static inline void TRACE_PROCESS(u8 ev_id, u32 data1, u32 data2)
+{
+	trace_process proc_event;
+
+	proc_event.event_sub_id = ev_id;
+	proc_event.event_data1 = data1;
+	proc_event.event_data2 = data2;
+
+	ltt_log_event(TRACE_EV_PROCESS, &proc_event);
+}
+static inline void TRACE_PROCESS_EXIT(u32 data1, u32 data2)
+{
+	trace_process proc_event;
+
+	proc_event.event_sub_id = TRACE_EV_PROCESS_EXIT;
+
+	/**** WARNING ****/
+	/* Regardless of whether this trace statement is active or not, these
+	two function must be called, otherwise there will be inconsistencies
+	in the kernel's structures. */
+/*
+	ltt_destroy_owners_events(current->pid);
+	ltt_free_all_handles(current);
+*/
+	ltt_log_event(TRACE_EV_PROCESS, &proc_event);
+}
+
+/*  TRACE_FILE_SYSTEM */
+enum {
+	TRACE_EV_FILE_SYSTEM_BUF_WAIT_START = 1,	/* Starting to wait for a data buffer */
+	TRACE_EV_FILE_SYSTEM_BUF_WAIT_END,		/* End to wait for a data buffer */
+	TRACE_EV_FILE_SYSTEM_EXEC,			/* An exec occured */
+	TRACE_EV_FILE_SYSTEM_OPEN,			/* An open occured */
+	TRACE_EV_FILE_SYSTEM_CLOSE,			/* A close occured */
+	TRACE_EV_FILE_SYSTEM_READ,			/* A read occured */
+	TRACE_EV_FILE_SYSTEM_WRITE,			/* A write occured */
+	TRACE_EV_FILE_SYSTEM_SEEK,			/* A seek occured */
+	TRACE_EV_FILE_SYSTEM_IOCTL,			/* An ioctl occured */
+	TRACE_EV_FILE_SYSTEM_SELECT,			/* A select occured */
+	TRACE_EV_FILE_SYSTEM_POLL			/* A poll occured */
+};
+typedef struct _trace_file_system {
+	u8 event_sub_id;	/* File system event ID */
+	u32 event_data1;
+	u32 event_data2;
+	char *file_name;	/* Name of file operated on */
+} LTT_PACKED_STRUCT trace_file_system;
+static inline void TRACE_FILE_SYSTEM(u8 ev_id, u32 data1, u32 data2, const unsigned char *file_name)
+{
+	trace_file_system fs_event;
+
+	fs_event.event_sub_id = ev_id;
+	fs_event.event_data1 = data1;
+	fs_event.event_data2 = data2;
+	fs_event.file_name = (char*) file_name;
+
+	ltt_log_event(TRACE_EV_FILE_SYSTEM, &fs_event);
+}
+
+/*  TRACE_TIMER */
+enum {
+	TRACE_EV_TIMER_EXPIRED = 1,	/* Timer expired */
+	TRACE_EV_TIMER_SETITIMER,	/* Setting itimer occurred */
+	TRACE_EV_TIMER_SETTIMEOUT	/* Setting sched timeout occurred */
+};
+typedef struct _trace_timer {
+	u8 event_sub_id;	/* Timer event ID */
+	u8 event_sdata;		/* Short data */
+	u32 event_data1;
+	u32 event_data2;
+} LTT_PACKED_STRUCT trace_timer;
+static inline void TRACE_TIMER(u8 ev_id, u8 sdata, u32 data1, u32 data2)
+{
+	trace_timer timer_event;
+
+	timer_event.event_sub_id = ev_id;
+	timer_event.event_sdata = sdata;
+	timer_event.event_data1 = data1;
+	timer_event.event_data2 = data2;
+
+	ltt_log_event(TRACE_EV_TIMER, &timer_event);
+}
+
+/*  TRACE_MEMORY */
+enum {
+	TRACE_EV_MEMORY_PAGE_ALLOC = 1,		/* Allocating pages */
+	TRACE_EV_MEMORY_PAGE_FREE,		/* Freing pages */
+	TRACE_EV_MEMORY_SWAP_IN,		/* Swaping pages in */
+	TRACE_EV_MEMORY_SWAP_OUT,		/* Swaping pages out */
+	TRACE_EV_MEMORY_PAGE_WAIT_START,	/* Start to wait for page */
+	TRACE_EV_MEMORY_PAGE_WAIT_END		/* End to wait for page */
+};
+typedef struct _trace_memory {
+	u8 event_sub_id;	/* Memory event ID */
+	u32 event_data;
+} LTT_PACKED_STRUCT trace_memory;
+static inline void TRACE_MEMORY(u8 ev_id, u32 data)
+{
+	trace_memory memory_event;
+
+	memory_event.event_sub_id = ev_id;
+	memory_event.event_data = data;
+
+	ltt_log_event(TRACE_EV_MEMORY, &memory_event);
+}
+
+/*  TRACE_SOCKET */
+enum {
+	TRACE_EV_SOCKET_CALL = 1,	/* A socket call occured */
+	TRACE_EV_SOCKET_CREATE,		/* A socket has been created */
+	TRACE_EV_SOCKET_SEND,		/* Data was sent to a socket */
+	TRACE_EV_SOCKET_RECEIVE		/* Data was read from a socket */
+};
+typedef struct _trace_socket {
+	u8 event_sub_id;	/* Socket event ID */
+	u32 event_data1;
+	u32 event_data2;
+} LTT_PACKED_STRUCT trace_socket;
+static inline void TRACE_SOCKET(u8 ev_id, u32 data1, u32 data2)
+{
+	trace_socket socket_event;
+
+	socket_event.event_sub_id = ev_id;
+	socket_event.event_data1 = data1;
+	socket_event.event_data2 = data2;
+
+	ltt_log_event(TRACE_EV_SOCKET, &socket_event);
+}
+
+/*  TRACE_IPC */
+enum {
+	TRACE_EV_IPC_CALL = 1,		/* A System V IPC call occured */
+	TRACE_EV_IPC_MSG_CREATE,	/* A message queue has been created */
+	TRACE_EV_IPC_SEM_CREATE,	/* A semaphore was created */
+	TRACE_EV_IPC_SHM_CREATE		/* A shared memory segment has been created */
+};
+typedef struct _trace_ipc {
+	u8 event_sub_id;	/* IPC event ID */
+	u32 event_data1;
+	u32 event_data2;
+} LTT_PACKED_STRUCT trace_ipc;
+static inline void TRACE_IPC(u8 ev_id, u32 data1, u32 data2)
+{
+	trace_ipc ipc_event;
+
+	ipc_event.event_sub_id = ev_id;
+	ipc_event.event_data1 = data1;
+	ipc_event.event_data2 = data2;
+
+	ltt_log_event(TRACE_EV_IPC, &ipc_event);
+}
+
+/*  TRACE_NETWORK */
+enum {
+	TRACE_EV_NETWORK_PACKET_IN = 1,	/* A packet came in */
+	TRACE_EV_NETWORK_PACKET_OUT	/* A packet was sent */
+};
+typedef struct _trace_network {
+	u8 event_sub_id;	/* Network event ID */
+	u32 event_data;
+} LTT_PACKED_STRUCT trace_network;
+static inline void TRACE_NETWORK(u8 ev_id, u32 data)
+{
+	trace_network net_event;
+
+	net_event.event_sub_id = ev_id;
+	net_event.event_data = data;
+
+	ltt_log_event(TRACE_EV_NETWORK, &net_event);
+}
+
+/* Start of trace buffer information */
+typedef struct _trace_buffer_start {
+	struct timeval time;	/* Time stamp of this buffer */
+	u32 tsc;   /* TSC of this buffer, if applicable */
+	u32 id;			/* Unique buffer ID */
+} LTT_PACKED_STRUCT trace_buffer_start;
+
+/* End of trace buffer information */
+typedef struct _trace_buffer_end {
+	struct timeval time;	/* Time stamp of this buffer */
+	u32 tsc;   /* TSC of this buffer, if applicable */
+} LTT_PACKED_STRUCT trace_buffer_end;
+
+/* Custom declared events */
+/* ***WARNING*** These structures should never be used as is, use the 
+   provided custom event creation and logging functions. */
+typedef struct _trace_new_event {
+	/* Basics */
+	u32 id;					/* Custom event ID */
+	char type[CUSTOM_EVENT_TYPE_STR_LEN];	/* Event type description */
+	char desc[CUSTOM_EVENT_DESC_STR_LEN];	/* Detailed event description */
+
+	/* Custom formatting */
+	u32 format_type;			/* Type of formatting */
+	char form[CUSTOM_EVENT_FORM_STR_LEN];	/* Data specific to format */
+} LTT_PACKED_STRUCT trace_new_event;
+typedef struct _trace_custom {
+	u32 id;			/* Event ID */
+	u32 data_size;		/* Size of data recorded by event */
+	void *data;		/* Data recorded by event */
+} LTT_PACKED_STRUCT trace_custom;
+
+/* TRACE_CHANGE_MASK */
+typedef struct _trace_change_mask {
+	trace_event_mask mask;	/* Event mask */
+} LTT_PACKED_STRUCT trace_change_mask;
+
+
+/*  TRACE_HEARTBEAT */
+static inline void TRACE_HEARTBEAT(void)
+{
+	ltt_log_event(TRACE_EV_HEARTBEAT, NULL);
+}
+
+/* Tracer properties */
+#define TRACER_DEFAULT_BUF_SIZE   50000
+#define TRACER_MIN_BUF_SIZE        1000
+#define TRACER_MAX_BUF_SIZE      500000
+#define TRACER_MIN_BUFFERS            2
+#define TRACER_MAX_BUFFERS          256
+
+#define TRACER_FIRST_EVENT_SIZE   (sizeof(u8) + sizeof(u32) + sizeof(trace_buffer_start) + sizeof(uint16_t))
+#define TRACER_START_TRACE_EVENT_SIZE   (sizeof(u8) + sizeof(u32) + sizeof(trace_start) + sizeof(uint16_t))
+#define TRACER_LAST_EVENT_SIZE   (sizeof(u8) \
+				  + sizeof(u8) \
+				  + sizeof(u32) \
+				  + sizeof(trace_buffer_end) \
+				  + sizeof(uint16_t) \
+				  + sizeof(u32))
+
+/* The configurations possible */
+enum {
+	TRACER_START = TRACER_MAGIC_NUMBER,	/* Start tracing events using the current configuration */
+	TRACER_STOP,				/* Stop tracing */
+	TRACER_CONFIG_DEFAULT,			/* Set the tracer to the default configuration */
+	TRACER_CONFIG_MEMORY_BUFFERS,		/* Set the memory buffers the daemon wants us to use */
+	TRACER_CONFIG_EVENTS,			/* Trace the given events */
+	TRACER_CONFIG_DETAILS,			/* Record the details of the event, or not */
+	TRACER_CONFIG_CPUID,			/* Record the CPUID associated with the event */
+	TRACER_CONFIG_PID,			/* Trace only one process */
+	TRACER_CONFIG_PGRP,			/* Trace only the given process group */
+	TRACER_CONFIG_GID,			/* Trace the processes of a given group of users */
+	TRACER_CONFIG_UID,			/* Trace the processes of a given user */
+	TRACER_CONFIG_SYSCALL_EIP_DEPTH,	/* Set the call depth at which the EIP should be fetched on syscall */
+	TRACER_CONFIG_SYSCALL_EIP_LOWER,	/* Set the lowerbound address from which EIP is recorded on syscall */
+	TRACER_CONFIG_SYSCALL_EIP_UPPER,	/* Set the upperbound address from which EIP is recorded on syscall */
+	TRACER_DATA_COMITTED,			/* The daemon has comitted the last trace */
+	TRACER_GET_EVENTS_LOST,			/* Get the number of events lost */
+	TRACER_CREATE_USER_EVENT,		/* Create a user tracable event */
+	TRACER_DESTROY_USER_EVENT,		/* Destroy a user tracable event */
+	TRACER_TRACE_USER_EVENT,		/* Trace a user event */
+	TRACER_SET_EVENT_MASK,			/* Set the trace event mask */
+	TRACER_GET_EVENT_MASK,			/* Get the trace event mask */
+	TRACER_GET_BUFFER_CONTROL,		/* Get the buffer control data for the lockless schem*/
+	TRACER_CONFIG_N_MEMORY_BUFFERS,		/* Set the number of memory buffers the daemon wants us to use */
+	TRACER_CONFIG_USE_LOCKING,		/* Set the locking scheme to use */
+	TRACER_CONFIG_TIMESTAMP,		/* Set the timestamping method to use */
+	TRACER_GET_ARCH_INFO,			/* Get information about the CPU configuration */
+	TRACER_ALLOC_HANDLE,			/* Allocate a tracer handle */
+	TRACER_FREE_HANDLE,			/* Free a single handle */
+	TRACER_FREE_DAEMON_HANDLE,		/* Free the daemon's handle */
+	TRACER_FREE_ALL_HANDLES,		/* Free all handles */
+	TRACER_MAP_BUFFER,			/* Map buffer to process-space */
+	TRACER_PAUSE,				/* Pause tracing */
+	TRACER_UNPAUSE,				/* Unpause tracing */
+	TRACER_GET_START_INFO,			/* trace start data */
+	TRACER_GET_STATUS			/* status of traces */
+};
+
+/* Lockless scheme definitions */
+#define TRACER_LOCKLESS_MIN_BUF_SIZE CUSTOM_EVENT_MAX_SIZE + 8192
+#define TRACER_LOCKLESS_MAX_BUF_SIZE 0x1000000
+
+/* Flags used for per-CPU tasks */
+#define LTT_NOTHING_TO_DO      0x00
+#define LTT_FINALIZE_TRACE     0x02
+#define LTT_TRACE_HEARTBEAT    0x08
+
+/* How often the LTT per-CPU timers fire */
+#define LTT_PERCPU_TIMER_FREQ  (HZ/10);
+
+/* Used for sharing per-buffer information between driver and daemon */
+struct buf_control_info
+{
+	s16 cpu_id;
+	u32 buffer_switches_pending;
+	u32 buffer_control_valid;
+
+	u32 buf_size;
+	u32 n_buffers;
+	u32 cur_idx;
+	u32 buffers_produced;
+	u32 buffers_consumed;
+	int buffer_complete[TRACER_MAX_BUFFERS];
+};
+
+/* Used for sharing buffer-commit information between driver and daemon */
+struct buffers_committed
+{
+	u8 cpu_id;
+	u32 buffers_consumed;
+};
+
+/* Used for specifying size/cpu id pair between driver and daemon */
+struct cpu_mmap_data
+{
+	u8 cpu_id;
+	unsigned long map_size;
+};
+
+/* Used for sharing architecture-specific info between driver and daemon */
+struct ltt_arch_info
+{
+	int n_cpus;
+	int page_shift;
+};
+
+extern __inline__ int ltt_set_bit(int nr, void *addr)
+{
+	unsigned char *p = addr;
+	unsigned char mask = 1 << (nr & 7);
+	unsigned char old;
+
+	p += nr >> 3;
+	old = *p;
+	*p |= mask;
+
+	return ((old & mask) != 0);
+}
+
+extern __inline__ int ltt_clear_bit(int nr, void *addr)
+{
+	unsigned char *p = addr;
+	unsigned char mask = 1 << (nr & 7);
+	unsigned char old;
+
+	p += nr >> 3;
+	old = *p;
+	*p &= ~mask;
+
+	return ((old & mask) != 0);
+}
+
+extern __inline__ int ltt_test_bit(int nr, void *addr)
+{
+	unsigned char *p = addr;
+	unsigned char mask = 1 << (nr & 7);
+
+	p += nr >> 3;
+
+	return ((*p & mask) != 0);
+}
+
+/**
+ *	switch_time_delta: - Utility function getting buffer switch time delta.
+ *	@time_delta: previously calculated or retrieved time delta 
+ *
+ *	Returns the time_delta passed in if we're using TSC or 0 otherwise.
+ */
+static inline u32 switch_time_delta(u32 time_delta,
+				    int using_tsc)
+{
+	if((using_tsc == 1) && cpu_has_tsc)
+		return time_delta;
+	else
+		return 0;
+}
+
+static inline void TRACE_CLEANUP(void) {
+	ltt_destroy_owners_events(current->pid);
+	ltt_free_all_handles(current);
+}
+
+extern void change_traced_events(trace_event_mask *);
+#else				/* Kernel is configured without tracing */
+#define TRACE_EVENT(ID, DATA)
+#define TRACE_TRAP_ENTRY(ID, EIP)
+#define TRACE_TRAP_EXIT()
+#define TRACE_IRQ_ENTRY(ID, KERNEL)
+#define TRACE_IRQ_EXIT()
+#define TRACE_SCHEDCHANGE(OUT, IN)
+#define TRACE_SOFT_IRQ(ID, DATA)
+#define TRACE_PROCESS(ID, DATA1, DATA2)
+#define TRACE_PROCESS_EXIT(DATA1, DATA2)
+#define TRACE_FILE_SYSTEM(ID, DATA1, DATA2, FILE_NAME)
+#define TRACE_TIMER(ID, SDATA, DATA1, DATA2)
+#define TRACE_MEMORY(ID, DATA)
+#define TRACE_SOCKET(ID, DATA1, DATA2)
+#define TRACE_IPC(ID, DATA1, DATA2)
+#define TRACE_NETWORK(ID, DATA)
+#define TRACE_HEARTBEAT()
+static inline void TRACE_CLEANUP(void)	{}
+static inline void ltt_flight_pause(void) {}
+static inline void ltt_flight_unpause(void) {}
+#endif				/* defined(CONFIG_LTT) */
+#endif				/* _LINUX_TRACE_H */
+
+
+
Index: linux.t/include/linux/trigevent_hooks.h
===================================================================
--- linux.t.orig/include/linux/trigevent_hooks.h	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/include/linux/trigevent_hooks.h	2004-05-13 10:48:25.247233384 -0400
@@ -0,0 +1,105 @@
+#ifndef __LINUX_TRIGEVENT_HOOKS_H
+#define __LINUX_TRIGEVENT_HOOKS_H
+/*
+ * Kernel Hooks Interface.
+ * 
+ * Authors: Richard J Moore <richardj_moore@uk.ibm.com>
+ *	    Vamsi Krishna S. <vamsi_krishna@in.ibm.com>
+ */
+#include <linux/hook.h>
+#include <linux/module.h>
+
+#ifdef CONFIG_TRIGEVENT_HOOKS
+#define TRIG_EVENT(name, args...) GENERIC_HOOK(name , ##args)
+#define DECLARE_TRIG_EVENT(name)	DECLARE_GENERIC_HOOK(name)
+
+USE_HOOK(ipc_call_hook);
+USE_HOOK(ipc_msg_create_hook);
+USE_HOOK(ipc_sem_create_hook);
+USE_HOOK(ipc_shm_create_hook);
+
+USE_HOOK(irq_entry_hook);
+USE_HOOK(irq_exit_hook);
+
+USE_HOOK(kernel_timer_hook);
+
+USE_HOOK(kthread_hook);
+USE_HOOK(exec_hook);
+USE_HOOK(fork_hook);
+USE_HOOK(process_exit_hook);
+USE_HOOK(process_wait_hook);
+USE_HOOK(process_wakeup_hook);
+USE_HOOK(sched_switch_hook);
+USE_HOOK(sched_dispatch_hook);
+USE_HOOK(signal_hook);
+
+USE_HOOK(open_hook);
+USE_HOOK(close_hook);
+USE_HOOK(llseek_hook);
+USE_HOOK(lseek_hook);
+USE_HOOK(ioctl_hook);
+USE_HOOK(poll_hook);
+USE_HOOK(select_hook);
+USE_HOOK(read_hook);
+USE_HOOK(write_hook);
+USE_HOOK(buf_wait_end_hook);
+USE_HOOK(buf_wait_start_hook);
+
+USE_HOOK(mmap_hook);
+USE_HOOK(mm_page_alloc_hook);
+USE_HOOK(mm_page_free_hook);
+USE_HOOK(mm_swap_in_hook);
+USE_HOOK(mm_swap_out_hook);
+USE_HOOK(page_wait_end_hook);
+USE_HOOK(page_wait_start_hook);
+
+USE_HOOK(net_pkt_in_hook);
+USE_HOOK(net_pkt_out_hook);
+
+USE_HOOK(sk_call_hook);
+USE_HOOK(sk_create_hook);
+USE_HOOK(sk_receive_hook);
+USE_HOOK(sk_send_hook);
+
+USE_HOOK(softirq_hook);
+USE_HOOK(tasklet_action_hook);
+USE_HOOK(tasklet_hi_action_hook);
+USE_HOOK(bh_hook);
+
+USE_HOOK(timer_expired_hook);
+USE_HOOK(setitimer_hook);
+USE_HOOK(settimeout_hook);
+
+USE_HOOK(trap_entry_hook);
+USE_HOOK(trap_exit_hook);
+
+USE_HOOK(timer_hook);
+
+#ifdef CONFIG_MODULES
+USE_HOOK(module_init_hook);
+USE_HOOK(module_init_failed_hook);
+USE_HOOK(free_module_hook);
+#endif
+
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+USE_HOOK(pre_syscall_hook);
+USE_HOOK(post_syscall_hook);
+
+extern int pre_syscall_enabled;
+extern int post_syscall_enabled;
+
+extern void enable_pre_syscall(void);
+extern void enable_post_syscall(void);
+extern void disable_pre_syscall(void);
+extern void disable_post_syscall(void);
+#endif /* CONFIG_TRIGEVENT_SYSCALL_HOOK */
+#else
+#define TRIG_EVENT(name, ...)
+#endif /* CONFIG_TRIGEVENT_HOOKS */
+
+/* this needs to be done properly */
+#ifdef __s390__
+typedef uint64_t trapid_t;
+#endif
+
+#endif /* __LINUX_TRIGEVENT_HOOKS_H */
Index: linux.t/init/kerntypes.c
===================================================================
--- linux.t.orig/init/kerntypes.c	2004-05-13 10:45:12.346558744 -0400
+++ linux.t/init/kerntypes.c	2004-05-13 10:48:25.248233232 -0400
@@ -21,6 +21,7 @@
 #include <linux/utsname.h>
 #include <linux/kernel_stat.h>
 #include <linux/dump.h>
+#include <linux/ltt.h>
 
 #include <asm/kerntypes.h>
 
Index: linux.t/ipc/msg.c
===================================================================
--- linux.t.orig/ipc/msg.c	2004-05-13 10:45:20.270354144 -0400
+++ linux.t/ipc/msg.c	2004-05-13 10:48:25.250232928 -0400
@@ -25,6 +25,7 @@
 #include <linux/security.h>
 #include <linux/sched.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/current.h>
 #include <asm/uaccess.h>
 #include "util.h"
@@ -334,6 +335,7 @@
 		msg_unlock(msq);
 	}
 	up(&msg_ids.sem);
+	TRIG_EVENT(ipc_msg_create_hook, ret, msgflg);
 	return audit_result(ret);
 }
 
Index: linux.t/ipc/sem.c
===================================================================
--- linux.t.orig/ipc/sem.c	2004-05-13 10:45:19.925406584 -0400
+++ linux.t/ipc/sem.c	2004-05-13 10:48:25.252232624 -0400
@@ -72,6 +72,7 @@
 #include <linux/smp_lock.h>
 #include <linux/security.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/uaccess.h>
 #include "util.h"
 
@@ -241,6 +242,7 @@
 	}
 
 	up(&sem_ids.sem);
+	TRIG_EVENT(ipc_sem_create_hook, err, semflg);
 	return audit_result(err);
 }
 
Index: linux.t/ipc/shm.c
===================================================================
--- linux.t.orig/ipc/shm.c	2004-05-13 10:45:20.783276168 -0400
+++ linux.t/ipc/shm.c	2004-05-13 10:48:25.254232320 -0400
@@ -27,6 +27,7 @@
 #include <linux/shmem_fs.h>
 #include <linux/security.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/uaccess.h>
 
 #include "util.h"
@@ -300,6 +301,7 @@
 	}
 	up(&shm_ids.sem);
 
+	TRIG_EVENT(ipc_shm_create_hook, err, shmflg);
 	return audit_result(err);
 }
 
Index: linux.t/kernel/Makefile
===================================================================
--- linux.t.orig/kernel/Makefile	2004-05-13 10:45:12.005610576 -0400
+++ linux.t/kernel/Makefile	2004-05-13 10:48:25.255232168 -0400
@@ -22,6 +22,9 @@
 obj-$(CONFIG_IKCONFIG_PROC) += configs.o
 obj-$(CONFIG_STOP_MACHINE) += stop_machine.o
 obj-$(CONFIG_EVLOG) += evlbuf.o evlapi.o evlposix.o
+obj-$(CONFIG_HOOK) += hook.o
+obj-$(CONFIG_TRIGEVENT_HOOKS) += trigevent_hooks.o
+obj-$(CONFIG_LTT) += ltt/
 
 ifneq ($(CONFIG_IA64),y)
 # According to Alan Modra <alan@linuxcare.com.au>, the -fno-omit-frame-pointer is
Index: linux.t/kernel/exit.c
===================================================================
--- linux.t.orig/kernel/exit.c	2004-05-13 10:45:23.857808768 -0400
+++ linux.t/kernel/exit.c	2004-05-13 10:48:25.257231864 -0400
@@ -28,6 +28,8 @@
 #include <linux/ckrm.h>
 #include <linux/ckrm_tsk.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
+#include <linux/ltt.h>
 
 #include <asm/uaccess.h>
 #include <asm/pgtable.h>
@@ -787,6 +789,8 @@
 #endif
 	__exit_mm(tsk);
 
+	TRACE_CLEANUP();  
+	TRIG_EVENT(process_exit_hook, tsk->pid);
 	exit_sem(tsk);
 	__exit_files(tsk);
 	__exit_fs(tsk);
@@ -1094,6 +1098,7 @@
 	if (options & ~(WNOHANG|WUNTRACED|__WNOTHREAD|__WCLONE|__WALL))
 		return -EINVAL;
 
+	TRIG_EVENT(process_wait_hook, pid);
 	add_wait_queue(&current->wait_chldexit,&wait);
 repeat:
 	flag = 0;
Index: linux.t/kernel/fork.c
===================================================================
--- linux.t.orig/kernel/fork.c	2004-05-13 10:45:23.859808464 -0400
+++ linux.t/kernel/fork.c	2004-05-13 10:48:25.259231560 -0400
@@ -33,6 +33,7 @@
 #include <linux/mount.h>
 #include <linux/objrmap.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 
 #include <linux/ckrm.h>
 #include <linux/ckrm_tsk.h>
@@ -1237,6 +1238,8 @@
         	      audit_fork(current, p);
 #endif
 
+		/* Trace the event  */
+		TRIG_EVENT(fork_hook, clone_flags, p, pid);
 		if (!(clone_flags & CLONE_STOPPED)) {
 			/*
 			 * Do the wakeup last. On SMP we treat fork() and
Index: linux.t/kernel/hook.c
===================================================================
--- linux.t.orig/kernel/hook.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/hook.c	2004-05-13 10:48:25.261231256 -0400
@@ -0,0 +1,328 @@
+/*
+ * Kernel Hooks Interface.
+ * 
+ * Authors: Richard J Moore <richardj_moore@uk.ibm.com>
+ *	    Vamsi Krishna S. <vamsi_krishna@in.ibm.com>
+ * 22 Aug 2003 : Added code for /proc entries and hook priority.
+ * 	  Prasanna S Panchamukhi < prasanna@in.ibm.com>
+ * (C) Copyright IBM Corp. 2002, 2003
+ */
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/spinlock.h>
+#include <linux/string.h>
+#include <linux/hook.h>
+#include <asm/system.h>
+#include <asm/uaccess.h>
+
+static spinlock_t hook_lock = SPIN_LOCK_UNLOCKED;
+static DECLARE_MUTEX(hook_proc_sem);
+
+static int hook_global_status = 0;
+
+static void calculate_indicies(struct hook *hook)
+{
+	struct hook_rec *rec, *rec_prev;
+	list_for_each_entry(rec, &hook->exit_list, exit_list) {
+		rec_prev = list_entry(rec->exit_list.prev, struct hook_rec, exit_list);
+		rec->hook_index = (rec_prev->hook_index) + 1;
+	}
+	return;
+}
+
+static inline void deactivate_hook(struct hook *hook)
+{
+	hook->hook_flags &= ~HOOK_ACTIVE;
+	if(hook->hook_flags & HOOK_ASM_HOOK)
+		deactivate_asm_hook(hook);
+}
+
+static inline void activate_hook(struct hook *hook)
+{
+	hook->hook_flags |= HOOK_ACTIVE;
+	if(hook->hook_flags & HOOK_ASM_HOOK)
+		activate_asm_hook(hook);
+}
+
+static void disarm_one_hook_exit(struct hook_rec *hook_rec)
+{
+	struct hook_rec *rec;
+	hook_rec->hook_flags &= ~HOOK_ARMED;
+	list_for_each_entry(rec, &hook_rec->hook_head->exit_list, exit_list) {
+		if(rec->hook_flags & HOOK_ARMED) {
+			return;
+		}
+	}
+	deactivate_hook(hook_rec->hook_head);
+}
+#ifdef CONFIG_HOOK_PROCFS
+static struct proc_dir_entry *proc_hooks_dir;
+#define PROC_HOOKS_ROOT "hooks"
+
+static int hook_read_proc(char *page, char **start, off_t off, int count, 
+		int *eof, void *data)
+{
+	int len;
+	struct hook_rec *hook_rec = (struct hook_rec *)data;
+	len = sprintf(page, "%d\n", (hook_rec->hook_flags & HOOK_ARMED));
+	return len;
+}
+
+static int hook_write_proc(struct file *file, const char *buffer, 
+		unsigned long count, void *data)
+{
+	struct hook_rec *hook_rec = (struct hook_rec *)data;
+	char input;
+	int armed;
+
+	if (copy_from_user(&input, buffer, 1)) {
+		return -EFAULT;
+	}
+	armed = input - '0';
+	if (armed && !(hook_rec->hook_flags & HOOK_ARMED)) {
+		hook_exit_arm(hook_rec);
+	} else if (!armed && (hook_rec->hook_flags & HOOK_ARMED)) {
+		hook_exit_disarm(hook_rec);
+	}
+	return count;
+}
+
+static void hook_create_proc(struct hook_rec *hook_rec)
+{
+	char *proc_entry_name;
+	struct hook *hook = (struct hook *) (hook_rec->hook_head);
+
+	if (hook->proc_entry) {
+		char tmp[32];
+		proc_entry_name = hook_rec->hook_exit_name;
+		if (!proc_entry_name) {
+			sprintf(tmp, "%p", hook_rec);
+			proc_entry_name = tmp;
+		}
+		
+		if (!hook_rec->proc_writable) {
+		
+			hook_rec->proc_entry = create_proc_read_entry(
+					proc_entry_name, 0444, 
+					hook->proc_entry, 
+					hook_read_proc,
+					hook_rec);
+		} else {
+			hook_rec->proc_entry = create_proc_entry(
+					proc_entry_name, 0644, 
+					hook->proc_entry);
+			if (hook_rec->proc_entry) {
+				hook_rec->proc_entry->data = hook_rec;
+				hook_rec->proc_entry->read_proc = hook_read_proc;
+				hook_rec->proc_entry->write_proc = hook_write_proc;
+			}
+		}
+	}
+}
+
+static inline void create_hook_exit_proc_entry(struct hook_rec *hook_rec)
+{
+	down(&hook_proc_sem);
+	if (hook_global_status & HOOK_INIT) {
+		hook_create_proc(hook_rec);
+	}
+	up(&hook_proc_sem);
+}
+
+static inline void remove_hook_exit_proc_entry(struct hook_rec *hook_rec)
+{
+	char tmp[32];
+	char *proc_entry_name;
+
+	down(&hook_proc_sem);
+	if (hook_rec->proc_entry) {
+		proc_entry_name = hook_rec->hook_exit_name;
+		if (!proc_entry_name) {
+			sprintf(tmp, "%p", hook_rec);
+			proc_entry_name = tmp;
+		}
+		hook_rec->proc_entry->data = NULL;
+		remove_proc_entry(proc_entry_name, hook_rec->hook_head->proc_entry);
+	}
+	up(&hook_proc_sem);
+}
+
+static inline void create_hook_proc_dir(struct hook *hook)
+{
+	down(&hook_proc_sem);
+	if (hook_global_status & HOOK_INIT) {
+		hook->proc_entry = proc_mkdir(hook->hook_id, proc_hooks_dir);
+	}
+	up(&hook_proc_sem);
+}
+
+static inline void remove_hook_proc_dir(struct hook *hook)
+{
+	down(&hook_proc_sem);
+	if (hook->proc_entry) {
+		remove_proc_entry(hook->hook_id, proc_hooks_dir);
+	}
+	up(&hook_proc_sem);
+}
+
+static void __init init_hook_procfs(void)
+{
+	down(&hook_proc_sem);
+	proc_hooks_dir = proc_mkdir(PROC_HOOKS_ROOT, NULL);
+	up(&hook_proc_sem);
+}
+
+static void __exit cleanup_hook_procfs(void)
+{
+	down(&hook_proc_sem);
+	remove_proc_entry(PROC_HOOKS_ROOT, NULL);
+	up(&hook_proc_sem);
+}
+#else
+static inline void hook_create_proc(struct hook_rec *hook_rec) {}
+static inline void create_hook_exit_proc_entry(struct hook_rec *hook_rec) {}
+static inline void remove_hook_exit_proc_entry(struct hook_rec *hook_rec) {}
+static inline void create_hook_proc_dir(struct hook *hook) {}
+static inline void remove_hook_proc_dir(struct hook *hook) {}
+static inline void init_hook_procfs(void) {}
+static inline void cleanup_hook_procfs(void) {}
+#endif /* CONFIG_HOOK_PROCFS */
+
+int hook_exit_register(struct hook *hook, struct hook_rec *hook_rec)
+{
+	unsigned long flags;
+	struct hook_rec *rec_next, *rec_prev, *rec;
+	struct list_head *hook_link;
+
+	/* During the registeration of hook exits, hook entries are also created
+	 * in the /proc. proc entries cannot be created with irq's disabled.
+	 */
+	if (list_empty(&hook->exit_list)) 
+		create_hook_proc_dir(hook);
+
+	spin_lock_irqsave(&hook_lock, flags);
+	if(hook->hook_flags & HOOK_EXCLUSIVE) {
+		if (!list_empty(&hook->exit_list)) {
+			spin_unlock_irqrestore(&hook_lock, flags);
+			return -EPRIORITY;
+		}
+		hook->hook_ex_exit = hook_rec->hook_exit;
+	}
+	hook_link = &hook->exit_list;
+	rec_next = list_entry(hook->exit_list.next, struct hook_rec, exit_list);
+	rec_prev = list_entry(hook->exit_list.prev, struct hook_rec, exit_list);
+	if ((hook_rec->hook_flags) & HOOK_PRIORITY_FIRST) {
+		if ((!list_empty(&hook->exit_list)) && ((rec_next->hook_flags) & HOOK_PRIORITY_FIRST)) {
+			spin_unlock_irqrestore(&hook_lock, flags);
+			return ERROR_HIGHER_PRIORITY_HOOK;
+		} 
+	}
+	
+	if ((hook_rec->hook_flags) & HOOK_PRIORITY_LAST) {
+		if (!list_empty(&hook->exit_list)) {
+			if ((rec_prev->hook_flags) & HOOK_PRIORITY_LAST) {
+				spin_unlock_irqrestore(&hook_lock, flags);
+				return ERROR_LOWER_PRIORITY_HOOK;
+			} else {
+				hook_link = &rec_prev->exit_list;
+			}
+		}
+	}
+
+	if (!((hook_rec->hook_flags) & HOOK_PRIORITY)) {
+		if ((hook_rec->hook_flags) & HOOK_QUEUE_LIFO) {
+			if ((!list_empty(&hook->exit_list)) && ((rec_next->hook_flags) & HOOK_PRIORITY_FIRST)) 
+				hook_link = &rec_next->exit_list;
+		} else if ((!list_empty(&hook->exit_list)) && ((rec_prev->hook_flags) & HOOK_PRIORITY_LAST)) {
+			rec = list_entry(rec_prev->exit_list.prev, struct hook_rec, exit_list);
+			hook_link = &rec->exit_list;
+		} else 
+			hook_link = &rec_prev->exit_list;
+	}
+	
+	list_add(&hook_rec->exit_list, hook_link);
+	hook_rec->hook_head = hook;
+
+	calculate_indicies(hook_rec->hook_head);
+
+	if(is_asm_hook(hook->hook_addr))
+		hook->hook_flags |= HOOK_ASM_HOOK;
+
+	try_module_get(THIS_MODULE);
+	spin_unlock_irqrestore(&hook_lock, flags);
+
+	/* Creates entries in /proc, for hook exits.*/
+	create_hook_exit_proc_entry(hook_rec);
+	return 0;
+}
+
+void hook_exit_deregister(struct hook_rec *rec)
+{
+	unsigned long flags;
+	struct hook *hook;
+
+	spin_lock_irqsave(&hook_lock, flags);
+	if(rec->hook_flags & HOOK_ARMED)
+		disarm_one_hook_exit(rec);
+	if(rec->hook_head->hook_flags & HOOK_EXCLUSIVE)
+		rec->hook_head->hook_ex_exit = NULL;
+	list_del(&rec->exit_list);
+	hook = rec->hook_head;
+	calculate_indicies(rec->hook_head);
+	module_put(THIS_MODULE);
+	spin_unlock_irqrestore(&hook_lock, flags);
+
+	/* Remove hook exit entries from /proc. */
+	remove_hook_exit_proc_entry(rec);
+
+	/* Remove hook entries from /proc. */
+	if (list_empty(&hook->exit_list))
+		remove_hook_proc_dir(hook);
+		 
+}
+
+void hook_exit_arm(struct hook_rec *rec)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&hook_lock, flags);
+	rec->hook_flags |= HOOK_ARMED;
+	if(!(rec->hook_head->hook_flags & HOOK_ACTIVE))
+		activate_hook(rec->hook_head);
+	spin_unlock_irqrestore(&hook_lock, flags);
+}
+
+void hook_exit_disarm(struct hook_rec *rec)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&hook_lock, flags);
+	disarm_one_hook_exit(rec);
+	spin_unlock_irqrestore(&hook_lock, flags);
+}
+
+static int __init hook_init_module(void)
+{
+	hook_global_status |= HOOK_INIT;
+	init_hook_procfs();
+	printk(KERN_INFO "Kernel Hooks Interface installed.\n");
+	return 0;
+}
+
+static void __exit hook_cleanup_module(void)
+{
+	cleanup_hook_procfs();
+	printk(KERN_INFO "Kernel Hooks Interface terminated.\n");
+}
+
+module_init(hook_init_module);
+module_exit(hook_cleanup_module);
+
+EXPORT_SYMBOL(hook_exit_deregister);
+EXPORT_SYMBOL(hook_exit_arm);
+EXPORT_SYMBOL(hook_exit_disarm);
+EXPORT_SYMBOL(hook_exit_register);
+
+MODULE_LICENSE("GPL");
Index: linux.t/kernel/itimer.c
===================================================================
--- linux.t.orig/kernel/itimer.c	2004-01-09 01:59:26.000000000 -0500
+++ linux.t/kernel/itimer.c	2004-05-13 10:48:25.262231104 -0400
@@ -10,6 +10,7 @@
 #include <linux/smp_lock.h>
 #include <linux/interrupt.h>
 #include <linux/time.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 
@@ -68,6 +69,7 @@
 	struct task_struct * p = (struct task_struct *) __data;
 	unsigned long interval;
 
+	TRIG_EVENT(timer_expired_hook, p);
 	send_group_sig_info(SIGALRM, SEND_SIG_PRIV, p);
 	interval = p->it_real_incr;
 	if (interval) {
@@ -87,6 +89,7 @@
 	j = timeval_to_jiffies(&value->it_value);
 	if (ovalue && (k = do_getitimer(which, ovalue)) < 0)
 		return k;
+	TRIG_EVENT(setitimer_hook, which, i, j);
 	switch (which) {
 		case ITIMER_REAL:
 			del_timer_sync(&current->real_timer);
Index: linux.t/kernel/ltt/Makefile
===================================================================
--- linux.t.orig/kernel/ltt/Makefile	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/Makefile	2004-05-13 10:48:25.263230952 -0400
@@ -0,0 +1,31 @@
+#
+# Makefile for the kernel tracing drivers.
+#
+
+# Multipart objects.
+
+ltt_driver-objs	:= ltt-core.o ltt-core_hooks.o
+
+
+# Optional parts of multipart objects.
+ifeq ($(CONFIG_ARM),y)
+ltt_driver-objs	+= arm_syscall.o
+endif
+ifeq ($(CONFIG_X86),y)
+ltt_driver-objs	+= i386_syscall.o
+endif
+ifeq ($(CONFIG_MIPS32),y)
+ltt_driver-objs	+= mips_syscall.o
+endif
+ifeq ($(CONFIG_PPC32),y)
+ltt_driver-objs	+= ppc_syscall.o
+endif
+ifeq ($(CONFIG_ARCH_S390),y)
+ltt_driver-objs	+= s390_syscall.o
+endif
+ifeq ($(CONFIG_SUPERH),y)
+ltt_driver-objs	+= sh_syscall.o
+endif
+
+obj-$(CONFIG_LTT)	+= ltt_driver.o
+
Index: linux.t/kernel/ltt/arm_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/arm_syscall.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/arm_syscall.c	2004-05-13 10:48:25.264230800 -0400
@@ -0,0 +1,74 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* arm */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+	int			scno = 0;
+	int			depth = 0;
+	unsigned long           end_code;
+	unsigned long		*fp;			/* frame pointer */
+	unsigned long		lower_bound;
+	unsigned long		lr;			/* link register */
+	unsigned long		*prev_fp;
+	int			seek_depth;
+	unsigned long           start_code;
+	unsigned long           *start_stack;
+	trace_syscall_entry	trace_syscall_event;
+	unsigned long		upper_bound;
+	int			use_bounds;
+	int			use_depth;
+
+	/* TODO: get_scno */
+	trace_syscall_event.syscall_id = (uint8_t)scno;
+	trace_syscall_event.address    = instruction_pointer(regs);
+	
+	if (! (user_mode(regs) ))
+		goto trace_syscall_end;
+
+	if (ltt_get_trace_config(&use_depth,
+			     &use_bounds,
+			     &seek_depth,
+			     (void*)&lower_bound,
+			     (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	if ((use_depth == 1) || (use_bounds == 1)) {
+		fp          = (unsigned long *)regs->ARM_fp;
+		end_code    = current->mm->end_code;
+		start_code  = current->mm->start_code;
+		start_stack = (unsigned long *)current->mm->start_stack;
+
+		while (!__get_user(lr, (unsigned long *)(fp - 1))) {
+			if ((lr > start_code) && (lr < end_code)) {
+				if (((use_depth == 1) && (depth >= seek_depth)) ||
+				    ((use_bounds == 1) && (lr > lower_bound) && (lr < upper_bound))) {
+					trace_syscall_event.address = lr;
+					goto trace_syscall_end;
+				} else {
+					depth++;
+				}
+			}
+
+			if ((__get_user((unsigned long)prev_fp, (fp - 3))) ||
+			    (prev_fp > start_stack) ||
+			    (prev_fp <= fp)) {
+				goto trace_syscall_end;
+			}
+			fp = prev_fp;
+		}
+	}
+
+trace_syscall_end:
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/i386_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/i386_syscall.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/i386_syscall.c	2004-05-13 10:48:25.265230648 -0400
@@ -0,0 +1,81 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <linux/ltt.h>
+#include <asm/uaccess.h>
+
+/* i386 */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+        int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+        int                 seek_depth;
+        unsigned long       lower_bound;
+        unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+        /* Set the syscall ID */
+        trace_syscall_event.syscall_id = (uint8_t) regs->orig_eax;
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = regs->eip;
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!(regs->xcs & 3))
+	  /* Don't go diging anywhere */
+	  goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(ltt_get_trace_config(&use_depth,
+			    &use_bounds,
+			    &seek_depth,
+			    (void*)&lower_bound,
+			    (void*)&upper_bound) < 0)
+	  goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	  {
+	  /* Start at the top of the stack (bottom address since stacks grow downward) */
+	  stack = (unsigned long*) regs->esp;
+
+	  /* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+	  while(!get_user(addr, stack))
+	    {
+	    /* Does this LOOK LIKE an address in the program */
+	    if((addr > current->mm->start_code)
+             &&(addr < current->mm->end_code))
+	      {
+	      /* Does this address fit the description */
+	      if(((use_depth == 1) && (depth == seek_depth))
+               ||((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound)))
+		{
+		/* Set the address */
+		trace_syscall_event.address = addr;
+
+		/* We're done */
+		goto trace_syscall_end;
+		}
+	      else
+		/* We're one depth more */
+		depth++;
+	      }
+	    /* Go on to the next address */
+	    stack++;
+	    }
+	  }
+
+trace_syscall_end:
+	/* Trace the event */
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/ltt-core.c
===================================================================
--- linux.t.orig/kernel/ltt/ltt-core.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/ltt-core.c	2004-05-13 10:48:25.271229736 -0400
@@ -0,0 +1,2566 @@
+/*
+ * ltt-core.c
+ *
+ * (C) Copyright, 1999, 2000, 2001, 2002, 2003, 2004 -
+ *              Karim Yaghmour (karim@opersys.com)
+ *
+ * Contains the kernel code for the Linux Trace Toolkit.
+ *
+ * Author:
+ *	Karim Yaghmour (karim@opersys.com)
+ *
+ * Changelog:
+ *	24/01/04, Revamped tracer to rely entirely on relayfs, no sys_trace.
+ *		Renamed all relevant files and functions from trace* to ltt*.
+ *	14/03/03, Modified to use relayfs (zanussi@us.ibm.com)
+ *	15/10/02, Changed tracer from device to kernel subsystem and added
+ *		custom trace system call (sys_trace).
+ *	01/10/02, Coding style change to fit with kernel coding style.
+ *	16/02/02, Added Tom Zanussi's implementation of K42's lockless logging.
+ *		K42 tracing guru Robert Wisniewski participated in the
+ *		discussions surrounding this implementation. A big thanks to
+ *		the IBM folks.
+ *	03/12/01, Added user event support.
+ *	05/01/01, Modified PPC bit manipulation functions for x86
+ *		compatibility (andy_lowe@mvista.com).
+ *	15/11/00, Finally fixed memory allocation and remapping method. Now
+ *		using BTTV-driver-inspired code.
+ *	13/03/00, Modified tracer so that the daemon mmaps the tracer's buffers
+ *		in it's address space rather than use "read".
+ *	26/01/00, Added support for standardized buffer sizes and extensibility
+ *		of events.
+ *	01/10/99, Modified tracer in order to used double-buffering.
+ *	28/09/99, Adding tracer configuration support.
+ *	09/09/99, Changing the format of an event record in order to reduce the
+ *		size of the traces.
+ *	04/03/99, Initial typing.
+ *
+ * Note:
+ *	The sizes of the variables used to store the details of an event are
+ *	planned for a system who gets at least one clock tick every 10 
+ *	milli-seconds. There has to be at least one event every 2^32-1
+ *	microseconds, otherwise the size of the variable holding the time
+ *	doesn't work anymore.
+ */
+
+#include <linux/init.h>
+#include <linux/ltt.h>
+#include <linux/errno.h>
+#include <linux/stddef.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/string.h>
+#include <linux/time.h>
+#include <linux/vmalloc.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/delay.h>
+#include <linux/proc_fs.h>
+
+#include <asm/io.h>
+#include <asm/current.h>
+#include <asm/uaccess.h>
+#include <asm/bitops.h>
+#include <asm/pgtable.h>
+#include <asm/relay.h>
+#include <asm/ltt.h>
+
+/* Tracer configuration */
+static int		num_cpus;
+
+/* System call tracing behavior */
+static int		use_syscall_eip_bounds;
+static int		lower_eip_bound_set;
+static int		upper_eip_bound_set;
+static void*		lower_eip_bound;
+static void*		upper_eip_bound;
+static int		syscall_eip_depth_set;
+static int		syscall_eip_depth;
+
+static int		fetch_syscall_eip_use_depth;
+static int		fetch_syscall_eip_use_bounds;
+static void*		syscall_lower_eip_bound;
+static void*		syscall_upper_eip_bound;
+
+/* Data buffer management */
+static struct trace_struct	current_traces[NR_TRACES];
+static u32			start_reserve = TRACER_FIRST_EVENT_SIZE;
+static u32			end_reserve = TRACER_LAST_EVENT_SIZE;
+static u32			trace_start_reserve = TRACER_START_TRACE_EVENT_SIZE;
+static struct rchan_callbacks	ltt_callbacks;		/* relayfs callbacks */
+static struct ltt_arch_info	ltt_arch_info;
+static struct buf_control_info	shared_buf_ctl;
+static char *			user_event_data = NULL;
+
+/* Timer management */
+static struct timer_list	heartbeat_timer;
+static struct timer_list	percpu_timer[NR_CPUS] __cacheline_aligned;
+
+/* /proc variables */
+static struct proc_dir_entry *	ltt_proc_root_entry; /* proc/ltt */
+static int			tmp_rchan_handles[NR_CPUS];
+static char			relayfs_path[PATH_MAX];	/* path to attribs */
+static char			relay_file_name[PATH_MAX]; /* scratch area */
+static int			control_channel; /* LTT control channel */
+
+/* Forward declarations */
+static struct proc_dir_entry *create_handle_proc_dir(unsigned trace_handle);
+static void remove_handle_proc_dir(struct proc_dir_entry *handle_dir,
+				   unsigned trace_handle);
+
+/* Size of statically defined events */
+int event_struct_size[TRACE_EV_MAX + 1] =
+{
+	sizeof(trace_start),
+	sizeof(trace_syscall_entry),
+	0,				/* TRACE_SYSCALL_EXIT */
+	sizeof(trace_trap_entry),
+	0,				/* TRACE_TRAP_EXIT */
+	sizeof(trace_irq_entry),
+	0,				/* TRACE_IRQ_EXIT */
+	sizeof(trace_schedchange),
+	0,				/* TRACE_KERNEL_TIMER */
+	sizeof(trace_soft_irq),
+	sizeof(trace_process),
+	sizeof(trace_file_system),
+	sizeof(trace_timer),
+	sizeof(trace_memory),
+	sizeof(trace_socket),
+	sizeof(trace_ipc),
+	sizeof(trace_network),
+	sizeof(trace_buffer_start),
+	sizeof(trace_buffer_end),
+	sizeof(trace_new_event),
+	sizeof(trace_custom),
+	sizeof(trace_change_mask),
+	0				/* TRACE_HEARTBEAT */
+};
+
+/* Custom event description */
+struct custom_event_desc {
+	trace_new_event event;
+
+	pid_t owner_pid;
+
+	struct custom_event_desc *next;
+	struct custom_event_desc *prev;
+};
+
+/* Custom event management */
+static int			next_event_id = TRACE_EV_MAX + 1;
+static rwlock_t			custom_list_lock = RW_LOCK_UNLOCKED;
+static rwlock_t			trace_handle_table_lock = RW_LOCK_UNLOCKED;
+static struct custom_event_desc	custom_events_head;
+static struct custom_event_desc	*custom_events = NULL;
+
+/* Handle management */
+struct trace_handle_struct{
+	struct task_struct	*owner;
+};
+static struct trace_handle_struct trace_handle_table[TRACE_MAX_HANDLES];
+
+/**
+ *	set_waiting_for_cpu_async: - Utility function for setting wait flags
+ *	@cpu_id: which CPU to set flag on
+ *	@bit: which bit to set
+ */
+static inline void set_waiting_for_cpu_async(unsigned int trace_handle, u8 cpu_id, int bit)
+{
+	atomic_set(&waiting_for_cpu_async(trace_handle, cpu_id), 
+		   atomic_read(&waiting_for_cpu_async(trace_handle, cpu_id)) | bit);
+}
+
+/**
+ *	clear_waiting_for_cpu_async: - Utility function for clearing wait flags
+ *	@cpu_id: which CPU to clear flag on
+ *	@bit: which bit to clear
+ */
+static inline void clear_waiting_for_cpu_async(unsigned int trace_handle, u8 cpu_id, int bit)
+{
+	atomic_set(&waiting_for_cpu_async(trace_handle, cpu_id), 
+		   atomic_read(&waiting_for_cpu_async(trace_handle, cpu_id)) & ~bit);
+}
+
+
+/**
+ *	init_trace: - Initialize a trace/flight recorder instance
+ *	@trace_struct: trace/flight recorder struct
+ *
+ *	Initialize a trace instance to default values.
+ */
+static void init_trace(struct trace_struct *trace)
+{
+	trace->trace_handle = 0;
+	
+	trace->active = NULL;
+	trace->paused = 0;
+	trace->flight_recorder = 1;
+	trace->daemon_task_struct = NULL;
+	trace->trace_start_data = NULL;
+	
+	trace->tracer_started = 0;
+	trace->tracer_stopping = 0;
+	trace->proc_dir_entry = NULL;
+	trace->traced_events = 0;
+	trace->log_event_details_mask = 0;
+	trace->log_cpuid = 0;
+	trace->tracing_pid = 0;
+	trace->tracing_pgrp = 0;
+	trace->tracing_gid = 0;
+	trace->tracing_uid = 0;
+	trace->traced_pid = 0;
+	trace->traced_pgrp = 0;
+	trace->traced_gid = 0;
+	trace->traced_uid = 0;
+	trace->use_locking = 1;
+	trace->n_buffers = 0;
+	trace->buf_size = 0;
+	trace->using_tsc = 0;
+
+	trace->buffer_switches_pending = 0;
+	INIT_WORK(&trace->work, NULL, NULL);
+}
+
+/*
+ * Trace heartbeat
+ */
+
+/**
+ *	write_heartbeat_event: - Timer function generating hearbeat event.
+ *	@data: unused
+ *
+ *	Guarantees at least 1 event is logged before low word of TSC wraps.
+ */
+static void write_heartbeat_event(unsigned long data)
+{
+	unsigned long int flags;
+	int i, j;
+	
+	local_irq_save(flags);
+	for (i = 0; i < NR_TRACES; i++) {
+		if (current_traces[i].active && current_traces[i].using_tsc) {
+			for (j =  0; j < num_cpus; j++)
+				set_waiting_for_cpu_async(i, j, LTT_TRACE_HEARTBEAT);
+		}
+	}
+	local_irq_restore(flags);
+
+	del_timer(&heartbeat_timer);
+	heartbeat_timer.expires = jiffies + 0xffffffffUL/loops_per_jiffy - 1;
+	add_timer(&heartbeat_timer);
+}
+
+/**
+ *	syscall_active: - If any active trace is logging syscalls, return 1
+ *	@syscall_type: either SYSCALL_ENTRY or SYSCALL_EXIT
+ *
+ *	Returns 1 if any channel is tracing syscalls, 0 otherwise
+ *
+ *	Needed for setting/clearing the global syscall...active variables
+ *	in order to reflect the needs of all traces.
+ */
+int syscall_active(int syscall_type)
+{
+	int i, retval = 0;
+	struct trace_struct *trace;
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		trace = &current_traces[i];
+		if (!trace->active)
+			continue;
+		if(ltt_test_bit(syscall_type, &trace->traced_events))
+			retval = 1;
+	}
+
+	return retval;
+}
+
+/**
+ *	need_heartbeat: - If any active trace uses TSC timestamping, return 1
+ *
+ *	Returns the number of active traces using TSC timestamping
+ *
+ *	Needed for starting/stopping the heartbeat timer depending on whether
+ *	any trace needs it or not.
+ */
+int need_heartbeat(void)
+{
+	int i, retval = 0;
+	struct trace_struct *trace;
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		trace = &current_traces[i];
+		if(trace->active && trace->using_tsc)
+			retval++;
+	}
+
+	return retval;
+}
+
+/**
+ *	init_heartbeat_timer: - Start timer generating hearbeat events.
+ */
+static void init_heartbeat_timer(void)
+{
+	if (loops_per_jiffy > 0) {
+		init_timer(&heartbeat_timer);
+		heartbeat_timer.function = write_heartbeat_event;
+		heartbeat_timer.expires = jiffies 
+			+ 0xffffffffUL/loops_per_jiffy - 1;
+		add_timer(&heartbeat_timer);
+	}
+	else
+		printk(KERN_ALERT "LTT: No TSC for heartbeat timer - continuing without one \n");
+}
+
+/*
+ * Tasks and timers for trace finalization
+ */
+
+/**
+ *	all_channels_finalized: - Verify that all channels have been finalized.
+ *	@trace_handle: the trace containing the channels to be tested
+ *
+ *	Returns 1 if channels on all CPUs are complete, 0 otherwise.
+ */
+static int all_channels_finalized(unsigned int trace_handle)
+{
+	int i;
+	
+	for (i = 0; i < num_cpus; i++)
+		if (atomic_read(&waiting_for_cpu_async(trace_handle, i)) & LTT_FINALIZE_TRACE)
+			return 0;
+
+	return 1;
+}
+
+/**
+ *	active_traces: - The number of currently active traces
+ *
+ *	Returns the number of active traces
+ */
+static inline int active_traces(void)
+{
+	int i, nr_active = 0;
+	
+	for (i = 0; i < NR_TRACES; i++)
+		if (current_traces[i].active)
+			nr_active++;
+		
+	return nr_active;
+}
+
+/**
+ *	del_percpu_timers: - Delete all per_cpu timers.
+ */
+static inline void del_percpu_timers(void)
+{
+	int i;
+
+	for (i =  0; i < num_cpus; i++)
+		del_timer_sync(&percpu_timer[i]);
+}
+
+ /**
+  *	remove_readers_async: - Remove all map readers asynchronously.
+  *	@private: the trace_handle containing the readers to be removed
+  */
+static void remove_readers_async(void *private)
+{
+	int i;
+	unsigned int trace_handle = (unsigned int)private;
+	
+	for (i = 0; i < num_cpus; i++) {
+		remove_map_reader(trace_channel_reader(trace_handle, i));
+		trace_channel_reader(trace_handle, i) = NULL;
+	}
+}
+
+/**
+ *	remove_readers: - Remove all map readers.
+ *	@trace_handle: the trace containing the readers to be removed
+ */
+static inline void remove_readers(unsigned int trace_handle)
+{
+	int i;
+	
+	for (i = 0; i < num_cpus; i++) {
+		remove_map_reader(trace_channel_reader(trace_handle, i));
+		trace_channel_reader(trace_handle, i) = NULL;
+	}
+}
+
+/**
+ *	do_waiting_async_tasks: - perform asynchronous per-CPU tasks.
+ *	@cpu_id: the CPU the tasks should be executed on
+ */
+static void do_waiting_async_tasks(unsigned int trace_handle, u8 cpu_id)
+{
+	unsigned long int flags;
+	int tasks;
+	struct trace_struct *trace;
+	
+	trace = &current_traces[trace_handle];
+
+	local_irq_save(flags);
+	tasks = atomic_read(&waiting_for_cpu_async(trace_handle, cpu_id));
+
+	if (tasks == 0) {
+		local_irq_restore(flags);
+		return;
+	}
+
+	if (trace->using_tsc && trace->tracer_started && (tasks & LTT_TRACE_HEARTBEAT)) {
+                clear_waiting_for_cpu_async(trace_handle, cpu_id, LTT_TRACE_HEARTBEAT);
+		TRACE_HEARTBEAT();
+	}
+
+	if (trace->tracer_stopping && (tasks & LTT_FINALIZE_TRACE)) {
+                clear_waiting_for_cpu_async(trace_handle, cpu_id, LTT_FINALIZE_TRACE);
+		if (relay_close(trace_channel_handle(trace_handle, cpu_id)) != 0)
+			printk(KERN_ALERT "LTT: Couldn't close trace channel %d\n", trace_channel_handle(trace_handle, cpu_id));
+
+		set_bit(cpu_id, &trace->buffer_switches_pending);
+
+		if (all_channels_finalized(trace_handle)) {
+			PREPARE_WORK(&trace->work, remove_readers_async, (void *)trace_handle);
+			schedule_work(&trace->work);
+			trace->tracer_stopping = 0;
+		}
+	}
+
+	local_irq_restore(flags);
+}
+
+/**
+ *	check_waiting_async_tasks: - Timer function checking for async tasks.
+ *	@data: unused
+ */
+static void check_waiting_async_tasks(unsigned long data)
+{
+	int i;
+	int cpu = smp_processor_id();
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		if (atomic_read(&waiting_for_cpu_async(i, cpu)) != 0)
+			do_waiting_async_tasks(i, cpu);
+	}
+
+	del_timer(&percpu_timer[cpu]);
+	percpu_timer[cpu].expires = jiffies + LTT_PERCPU_TIMER_FREQ;
+	add_timer(&percpu_timer[cpu]);
+}
+
+/**
+ *	_init_percpu_timer: - Start timer checking for async tasks.
+ */
+void _init_percpu_timer(void * dummy)
+{
+	int cpu = smp_processor_id();
+
+	init_timer(&percpu_timer[cpu]);
+	percpu_timer[cpu].function = check_waiting_async_tasks;
+	percpu_timer[cpu].expires = jiffies + LTT_PERCPU_TIMER_FREQ;
+	add_timer(&percpu_timer[cpu]);
+}
+
+static inline void init_percpu_timers(void)
+{
+	_init_percpu_timer(NULL);
+
+	if (smp_call_function(_init_percpu_timer, NULL, 1, 1) != 0)
+		printk(KERN_ALERT "LTT: Couldn't initialize all per-CPU timers\n");
+}
+
+/*
+ * User-kernel interface for tracer
+ */
+
+/**
+ *	update_shared_buffer_control: - prepare for GET_BUFFER_CONTROL ioctl
+ *	@cpu_id: the CPU associated with the ioctl
+ */
+static inline void update_shared_buffer_control(struct trace_struct *trace, u8 cpu_id)
+{
+	struct rchan_info channel_info;
+	int i;
+	int channel_handle = trace_channel_handle(trace->trace_handle, cpu_id);
+	
+	if (relay_info(channel_handle, &channel_info) == -1) {
+		shared_buf_ctl.buffer_control_valid = 0;
+		return;
+	}
+
+	shared_buf_ctl.cpu_id =				cpu_id;
+	shared_buf_ctl.buffer_switches_pending =	trace->buffer_switches_pending & ~(1UL << cpu_id);
+	shared_buf_ctl.buffer_control_valid =		1;
+	shared_buf_ctl.buf_size =			channel_info.buf_size;
+	shared_buf_ctl.n_buffers =			channel_info.n_bufs;
+	shared_buf_ctl.cur_idx =			channel_info.cur_idx;
+	shared_buf_ctl.buffers_produced =		channel_info.bufs_produced;
+	shared_buf_ctl.buffers_consumed =		channel_info.bufs_consumed;
+
+	if (channel_info.flags & RELAY_SCHEME_LOCKLESS) {
+		for (i = 0; i < channel_info.n_bufs; i++) {
+			shared_buf_ctl.buffer_complete[i] = 
+				channel_info.buffer_complete[i];
+		}
+	}
+}
+
+/**
+ *	ltt_set_flight_recorder_config: - set flight recorder defaults
+ *	@trace: the trace struct
+ */
+static void ltt_set_flight_recorder_config(struct trace_struct *trace)
+{
+	trace->traced_events = 0;
+	trace->log_event_details_mask = 0;
+	
+	ltt_set_bit(TRACE_EV_BUFFER_START, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_BUFFER_START, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_START, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_START, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->log_event_details_mask);
+
+	ltt_set_bit(TRACE_EV_SYSCALL_ENTRY, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_SYSCALL_ENTRY, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_SYSCALL_EXIT, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_SYSCALL_EXIT, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_TRAP_ENTRY, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_TRAP_ENTRY, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_TRAP_EXIT, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_TRAP_EXIT, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_IRQ_ENTRY, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_IRQ_ENTRY, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_IRQ_EXIT, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_IRQ_EXIT, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_SCHEDCHANGE, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_SCHEDCHANGE, &trace->log_event_details_mask);
+
+	ltt_set_bit(TRACE_EV_KERNEL_TIMER, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_KERNEL_TIMER, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_SOFT_IRQ, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_SOFT_IRQ, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_PROCESS, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_PROCESS, &trace->log_event_details_mask);
+}
+
+/**
+ *	tracer_get_status: - fill in a status struct covering all traces
+ *	@tracer_status: the tracer_status struct
+ */
+static int tracer_get_status(struct tracer_status *tracer_status)
+{
+	int i, j, rchan_handle, retval = 0;
+	struct trace_struct *trace;
+	struct trace_info *info;
+	struct rchan_info rchan_info;
+	
+	tracer_status->num_cpus = num_cpus;
+
+	for (i = 0; i < NR_TRACES; i++) {
+		trace = &current_traces[i];
+		info = &tracer_status->traces[i];
+		info->active = trace->active && trace->tracer_started ? 1 : 0;
+		if (!info->active)
+			continue;
+		info->trace_handle = trace->trace_handle;
+		info->paused = trace->paused;
+		info->flight_recorder = trace->flight_recorder;
+		info->use_locking = trace->use_locking;
+		info->using_tsc = trace->using_tsc;
+		info->n_buffers = trace->n_buffers;
+		info->buf_size = trace->buf_size;
+		info->traced_events = trace->traced_events;
+		info->log_event_details_mask = trace->log_event_details_mask;
+		for (j = 0; j < num_cpus; j++) {
+			rchan_handle = trace_channel_handle(trace->trace_handle, j);
+			retval = relay_info(rchan_handle, &rchan_info);
+			if (retval)
+				return retval;
+			info->buffers_produced[j] = rchan_info.bufs_produced;
+		}
+	}
+
+	return retval;
+}
+
+/**
+ *	ltt_flight_pause: - pause the flight recorder
+ *
+ *	Allows for external control of flight recorder e.g. for crashdump
+ */
+void ltt_flight_pause(void)
+{
+	struct trace_struct *trace;
+
+	trace = &current_traces[FLIGHT_HANDLE];
+	if (!trace->active)
+		return;
+	
+	trace->paused = 1;
+}
+
+/**
+ *	ltt_flight_unpause: - unpause the flight recorder
+ *
+ *	Allows for external control of flight recorder e.g. for crashdump
+ */
+void ltt_flight_unpause(void)
+{
+	struct trace_struct *trace;
+
+	trace = &current_traces[FLIGHT_HANDLE];
+	if (!trace->active)
+		return;
+	
+	trace->paused = 0;
+}
+
+/**
+ *      ltt_ioctl: - Tracing kernel-user control interface
+ *
+ *      @rchan_id: rchan id ioctl occurred on
+ *      @tracer_command: command given by the caller
+ *      @command_arg: argument to the command
+ *
+ *      Returns:
+ *      >0, In case the caller requested the number of events lost.
+ *      0, Everything went OK
+ *      -ENOSYS, no such command
+ *      -EINVAL, tracer not properly configured
+ *      -EBUSY, tracer can't be reconfigured while in operation
+ *      -ENOMEM, no more memory
+ *      -EFAULT, unable to access user space memory
+ *      -EACCES, invalid tracer handle
+ */
+static int ltt_ioctl(int rchan_id,
+		     unsigned int tracer_command,
+		     unsigned long arg)
+{
+	int retval;
+	int new_user_event_id;
+	unsigned long int flags;
+	u8 cpu_id;
+	u8 i;
+	u32 buffers_consumed;
+	trace_custom user_event;
+	trace_change_mask trace_mask;
+	trace_new_event new_user_event;
+	struct buffers_committed buffers_committed;
+	struct trace_struct *trace = NULL;
+	struct tracer_status tracer_status;
+	unsigned int tracer_handle;
+	unsigned long command_arg;
+
+	if (copy_from_user(&tracer_handle, (void *)arg, sizeof(unsigned int)))
+		return -EFAULT;
+
+	if (copy_from_user(&command_arg, (void*)(arg + sizeof(tracer_handle)), sizeof(unsigned long)))
+		return -EFAULT;
+
+	if (tracer_command == TRACER_ALLOC_HANDLE)
+		return ltt_alloc_trace_handle(tracer_handle);
+
+	if (!ltt_valid_trace_handle(tracer_handle))
+		return -EACCES;
+
+	if (tracer_handle < NR_TRACES)
+		trace = &current_traces[tracer_handle];
+	else if (tracer_handle >= NR_TRACES) {
+		if (current_traces[TRACE_HANDLE].active)
+			trace = &current_traces[TRACE_HANDLE];
+		if (trace == NULL && tracer_command != TRACER_GET_STATUS)
+			return -EACCES;
+	}
+
+	if ((tracer_handle < NR_TRACES)
+	    && (trace->tracer_started == 1)
+	    && (tracer_command != TRACER_STOP)
+	    && (tracer_command != TRACER_PAUSE)
+	    && (tracer_command != TRACER_UNPAUSE)
+	    && (tracer_command != TRACER_DATA_COMITTED)
+	    && (tracer_command != TRACER_GET_ARCH_INFO)
+	    && (tracer_command != TRACER_GET_BUFFER_CONTROL)
+	    && (tracer_command != TRACER_GET_START_INFO))
+		return -EBUSY;
+
+	if ((tracer_handle >= NR_TRACES)
+	    && (tracer_command != TRACER_CREATE_USER_EVENT)
+	    && (tracer_command != TRACER_DESTROY_USER_EVENT)
+	    && (tracer_command != TRACER_TRACE_USER_EVENT)
+	    && (tracer_command != TRACER_FREE_HANDLE)
+	    && (tracer_command != TRACER_GET_STATUS)
+	    && (tracer_command != TRACER_SET_EVENT_MASK)
+	    && (tracer_command != TRACER_GET_EVENT_MASK))
+		return -ENOSYS;
+
+	switch (tracer_command) {
+	case TRACER_START:
+		if (trace->using_tsc && (need_heartbeat() == 1))
+			init_heartbeat_timer();
+		if (active_traces() == 1)
+			init_percpu_timers();
+
+		if (((use_syscall_eip_bounds == 1)
+		     && (syscall_eip_depth_set == 1))
+		    || ((use_syscall_eip_bounds == 1)
+			&& ((lower_eip_bound_set != 1)
+			    || (upper_eip_bound_set != 1)))
+		    || ((trace->tracing_pid == 1)
+			&& (trace->tracing_pgrp == 1)))
+			return -EINVAL;
+
+		if (ltt_set_trace_config(syscall_eip_depth_set,
+					 use_syscall_eip_bounds,
+					 syscall_eip_depth,
+					 lower_eip_bound,
+					 upper_eip_bound) < 0)
+			return -EINVAL;
+
+		if (trace->flight_recorder)
+			ltt_set_flight_recorder_config(trace);
+		
+		ltt_set_bit(TRACE_EV_BUFFER_START, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_BUFFER_START, &trace->log_event_details_mask);
+		ltt_set_bit(TRACE_EV_START, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_START, &trace->log_event_details_mask);
+		ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->log_event_details_mask);
+
+		/* Enable hooks for the events we are interested in. */
+		change_traced_events(&trace->traced_events);
+
+		trace->tracer_stopping = 0;
+		trace->tracer_started = 1;
+
+		ltt_reregister_custom_events();
+		break;
+
+	case TRACER_STOP:
+		if (trace->flight_recorder) {
+			for (i = 0; i < num_cpus; i++)
+				tmp_rchan_handles[i] = trace_channel_handle(tracer_handle, i);
+			ltt_free_all_handles(NULL);
+		} else {
+			trace->tracer_stopping = 1;
+			trace->tracer_started = 0;
+		}
+
+		/* Disable hooks. */
+		change_traced_events(NULL);
+
+		if (trace->flight_recorder) {
+			for (i = 0; i < num_cpus; i++) {
+				if (relay_close(tmp_rchan_handles[i]) != 0)
+					printk(KERN_ALERT "LTT: Couldn't close trace channel %d\n", trace_channel_handle(tracer_handle, i));
+			}
+			remove_readers(tracer_handle);
+		} else {
+			for (i = 0; i < num_cpus; i++)
+				set_waiting_for_cpu_async(tracer_handle, i, LTT_FINALIZE_TRACE);
+		}
+		break;
+
+	case TRACER_PAUSE:
+		trace->paused = 1;
+		break;
+
+	case TRACER_UNPAUSE:
+		trace->paused = 0;
+		break;
+
+	case TRACER_CONFIG_DEFAULT:
+		ltt_set_default_config(trace);
+		break;
+
+	case TRACER_CONFIG_MEMORY_BUFFERS:
+		if (trace->use_locking == 1) {
+			if (command_arg < TRACER_MIN_BUF_SIZE)
+				return -EINVAL;
+		} else {
+			if ((command_arg < TRACER_LOCKLESS_MIN_BUF_SIZE) || 
+			    (command_arg > TRACER_LOCKLESS_MAX_BUF_SIZE))
+				return -EINVAL;
+		}
+		return ltt_set_buffer_size(trace, command_arg, relayfs_path);
+		break;
+
+	case TRACER_CONFIG_N_MEMORY_BUFFERS:
+		if (command_arg < TRACER_MIN_BUFFERS || 
+		    command_arg > TRACER_MAX_BUFFERS)
+			return -EINVAL;
+
+		return ltt_set_n_buffers(trace, command_arg);
+		break;
+
+	case TRACER_CONFIG_USE_LOCKING:
+		trace->use_locking = command_arg;
+
+		if ((trace->use_locking == 0) && (have_cmpxchg() == 0))
+			return -EINVAL;
+		break;
+
+	case TRACER_CONFIG_EVENTS:
+		if (copy_from_user(&trace->traced_events, (void *)command_arg, sizeof(trace->traced_events)))
+			return -EFAULT;
+		break;
+
+	case TRACER_CONFIG_TIMESTAMP:
+		trace->using_tsc = command_arg;
+
+		if ((trace->using_tsc == 1) && (have_tsc() == 0)) {
+			trace->using_tsc = 0;
+			return -EINVAL;
+		}
+		break;
+
+	case TRACER_CONFIG_DETAILS:
+		if (copy_from_user(&trace->log_event_details_mask, (void *)command_arg, sizeof(trace->log_event_details_mask)))
+			return -EFAULT;
+		 /* Enable hooks for the events we are interested in. */
+
+		if (trace->tracer_started) {
+			change_traced_events(&trace->traced_events);
+		}
+
+		break;
+
+	case TRACER_CONFIG_CPUID:
+		trace->log_cpuid = 0; /* disabled */
+		break;
+
+	case TRACER_CONFIG_PID:
+		trace->tracing_pid = 1;
+		trace->traced_pid = command_arg;
+		break;
+
+	case TRACER_CONFIG_PGRP:
+		trace->tracing_pgrp = 1;
+		trace->traced_pgrp = command_arg;
+		break;
+
+	case TRACER_CONFIG_GID:
+		trace->tracing_gid = 1;
+		trace->traced_gid = command_arg;
+		break;
+
+	case TRACER_CONFIG_UID:
+		trace->tracing_uid = 1;
+		trace->traced_uid = command_arg;
+		break;
+
+	case TRACER_CONFIG_SYSCALL_EIP_DEPTH:
+		syscall_eip_depth_set = 1;
+		syscall_eip_depth = command_arg;
+		break;
+
+	case TRACER_CONFIG_SYSCALL_EIP_LOWER:
+		use_syscall_eip_bounds = 1;
+		lower_eip_bound = (void *)command_arg;
+		lower_eip_bound_set = 1;
+		break;
+
+	case TRACER_CONFIG_SYSCALL_EIP_UPPER:
+		use_syscall_eip_bounds = 1;
+		upper_eip_bound = (void *)command_arg;
+		upper_eip_bound_set = 1;
+		break;
+
+	case TRACER_DATA_COMITTED:
+		if (copy_from_user(&buffers_committed, (void *)command_arg, 
+				   sizeof(buffers_committed)))
+			return -EFAULT;
+
+		cpu_id = buffers_committed.cpu_id;
+		buffers_consumed = buffers_committed.buffers_consumed;
+		clear_bit(cpu_id, &trace->buffer_switches_pending);
+
+		local_irq_save(flags);
+		relay_buffers_consumed(trace_channel_reader(tracer_handle, cpu_id), 
+				       buffers_consumed);
+		local_irq_restore(flags);
+
+		break;
+
+	case TRACER_GET_EVENTS_LOST:
+		return events_lost(tracer_handle, command_arg);
+		break;
+
+	case TRACER_CREATE_USER_EVENT:
+		if (copy_from_user(&new_user_event, (void *)command_arg, sizeof(new_user_event)))
+			return -EFAULT;
+
+		new_user_event_id = ltt_create_owned_event(new_user_event.type,
+							     new_user_event.desc,
+							     new_user_event.format_type,
+							     new_user_event.form,
+							     current->pid);
+		if (new_user_event_id >= 0) {
+			new_user_event.id = new_user_event_id;
+			if (copy_to_user((void *)command_arg, &new_user_event, sizeof(new_user_event))) {
+				ltt_destroy_event(new_user_event_id);
+				return -EFAULT;
+			}
+		} else
+			return new_user_event_id;
+		break;
+
+	case TRACER_DESTROY_USER_EVENT:
+		ltt_destroy_event((int)command_arg);
+		break;
+
+	case TRACER_TRACE_USER_EVENT:
+		if (copy_from_user(&user_event, (void *)command_arg, sizeof(user_event)))
+			return -EFAULT;
+		
+		if ((user_event_data == NULL) 
+		    && (user_event_data = vmalloc(CUSTOM_EVENT_MAX_SIZE)) < 0)
+			return -ENOMEM;
+
+		if (copy_from_user(user_event_data, user_event.data, user_event.data_size))
+			return -EFAULT;
+
+		retval = ltt_log_raw_event(user_event.id,
+					   user_event.data_size,
+					   user_event_data);
+		if (retval < 0)
+			return retval;
+		break;
+
+	case TRACER_SET_EVENT_MASK:
+		if (copy_from_user(&(trace_mask.mask), (void *)command_arg, sizeof(trace_mask.mask)))
+			return -EFAULT;
+
+		retval = _ltt_log_event(trace,
+					TRACE_EV_CHANGE_MASK,
+					&trace_mask,
+					smp_processor_id());
+
+		memcpy(&trace->traced_events, &(trace_mask.mask), sizeof(trace_mask.mask));
+
+		ltt_set_bit(TRACE_EV_BUFFER_START, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_START, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->traced_events);
+
+		/* Enable hooks for the events we are interested in. */
+		if (trace->tracer_started) {
+			change_traced_events(&trace->traced_events);
+		}
+
+		return retval;
+		break;
+
+	case TRACER_GET_EVENT_MASK:
+		if (copy_to_user((void *)command_arg, &trace->traced_events, sizeof(trace->traced_events)))
+			return -EFAULT;
+		break;
+
+	case TRACER_GET_ARCH_INFO:
+		ltt_arch_info.n_cpus = num_cpus;
+		ltt_arch_info.page_shift = PAGE_SHIFT;
+
+		if (copy_to_user((void *)command_arg,
+				 &ltt_arch_info,
+				 sizeof(ltt_arch_info))) {
+			return -EFAULT;
+		}
+		break;
+
+	case TRACER_GET_START_INFO:
+		if (trace->trace_start_data) {
+			if (copy_to_user((void *)command_arg,
+					 trace->trace_start_data,
+					 sizeof(trace_start)))
+				return -EFAULT;
+		} else
+			return -EINVAL;
+		break;
+
+	case TRACER_GET_STATUS:
+		if (tracer_get_status(&tracer_status))
+			return -EINVAL;
+		
+		if (copy_to_user((void *)command_arg, 
+				 &tracer_status,
+				 sizeof(struct tracer_status)))
+			return -EFAULT;
+		break;
+
+	case TRACER_GET_BUFFER_CONTROL:
+		if (copy_from_user(&shared_buf_ctl, (void *)command_arg, sizeof(shared_buf_ctl)))
+			return -EFAULT;
+
+		if (shared_buf_ctl.cpu_id == -1) {
+			for (i = 0; i < num_cpus; i++) {
+				if (trace->buffer_switches_pending & (1UL << i)) {
+					update_shared_buffer_control(trace, i);
+					if (copy_to_user((void *)command_arg,
+							 &shared_buf_ctl,
+							 sizeof(struct buf_control_info)))
+						return -EFAULT;
+					return 0;
+				}
+			}
+		} else {
+			update_shared_buffer_control(trace, (u8)shared_buf_ctl.cpu_id);
+			if (copy_to_user((void *)command_arg,
+					 &shared_buf_ctl,
+					 sizeof(struct buf_control_info)))
+				return -EFAULT;
+			return 0;
+		}
+
+		shared_buf_ctl.cpu_id = 0;
+		shared_buf_ctl.buffer_control_valid = 0;
+
+		if (copy_to_user((void *) command_arg,
+				&shared_buf_ctl,
+				sizeof(struct buf_control_info)))
+			return -EFAULT;
+		break;
+
+	case TRACER_FREE_HANDLE:
+		return ltt_free_trace_handle(tracer_handle);
+		break;
+
+	case TRACER_FREE_DAEMON_HANDLE:
+		return ltt_free_daemon_handle(trace);
+		break;
+
+	case TRACER_FREE_ALL_HANDLES:
+		ltt_free_all_handles(current);
+		break;
+
+	case TRACER_MAP_BUFFER:
+		return -EFAULT;
+		break;
+
+	default:
+		return -ENOSYS;
+		break;
+	}
+
+	return 0;
+}
+
+/*
+ * Trace Handles
+ */
+
+/**
+ *	ltt_valid_trace_handle: - Validate tracer handle.
+ *	@tracer_handle: handle to be validated
+ *
+ *	Returns:
+ *	1, if handle is valid
+ *	0, if handle is invalid
+ */
+int ltt_valid_trace_handle(unsigned int tracer_handle)
+{
+	int retval = 0;
+	struct trace_struct *trace;
+
+	if (tracer_handle < NR_TRACES) {
+		trace = &current_traces[tracer_handle];
+		if (!trace->active)
+			retval = 0;
+		else if (!trace->flight_recorder) {
+			if (trace->daemon_task_struct == current)
+				retval = 1;
+		} else
+			retval = 1;
+	} else {
+		read_lock(&trace_handle_table_lock);
+		if (trace_handle_table[tracer_handle - NR_TRACES].owner == current)
+			retval = 1;
+		else
+			retval = 0;
+		read_unlock(&trace_handle_table_lock);
+	}
+
+	return retval;
+}
+
+/**
+ *	ltt_alloc_trace_handle: - Allocate trace handle to caller.
+ *	@tracer_handle: handle requested by process
+ *
+ *	Returns:
+ *	Handle ID, everything went OK
+ *	-ENODEV, no more free handles.
+ *	-EBUSY, daemon handle already in use.
+ */
+int ltt_alloc_trace_handle(unsigned int tracer_handle)
+{
+	int i;
+	int retval;
+	struct trace_struct *trace = NULL;
+	
+	if (tracer_handle < NR_TRACES) {
+		trace = &current_traces[tracer_handle];
+		if (trace->active)
+			return -EBUSY;
+	}
+
+	if (tracer_handle == NR_TRACES) {
+		write_lock(&trace_handle_table_lock);
+		for (i = 0; i < TRACE_MAX_HANDLES; i++)
+			if (trace_handle_table[i].owner == NULL) {
+				trace_handle_table[i].owner = current;
+				break;
+			}
+		write_unlock(&trace_handle_table_lock);
+		if (i == TRACE_MAX_HANDLES)
+			retval = -ENODEV;
+		else
+			retval = (i + NR_TRACES);
+	} else {
+		trace->active = trace;
+		trace->tracer_started = 0;
+		trace->tracer_stopping = 0;
+		if (tracer_handle == TRACE_HANDLE) {
+			trace->flight_recorder = 0;
+			trace->daemon_task_struct = current;
+		} else {
+			if ((trace->trace_start_data = (struct _trace_start *) kmalloc(sizeof(struct _trace_start), GFP_ATOMIC)) == NULL)
+				return -ENOMEM;
+		}
+
+		trace->proc_dir_entry = create_handle_proc_dir(tracer_handle);
+		ltt_set_default_config(trace);
+		retval = trace->trace_handle = tracer_handle;
+	}
+	
+	return retval;
+}
+
+/**
+ *	ltt_free_trace_handle: - Free a single handle.
+ *	tracer_handle: handle to be freed.
+ *
+ *	Returns: 
+ *	0, everything went OK
+ *	-ENODEV, no such handle.
+ *	-EACCES, handle doesn't belong to caller.
+ */
+int ltt_free_trace_handle(unsigned int tracer_handle)
+{
+	int retval;
+
+	if ((tracer_handle < NR_TRACES) || (tracer_handle >= TRACE_MAX_HANDLES))
+		return -ENODEV;
+
+	write_lock(&trace_handle_table_lock);
+
+	if (trace_handle_table[tracer_handle - NR_TRACES].owner == current) {
+		trace_handle_table[tracer_handle - NR_TRACES].owner = NULL;
+		retval = 0;
+	}
+	else
+		retval = -EACCES;
+
+	write_unlock(&trace_handle_table_lock);
+
+	return retval;
+}
+
+/**
+ *	ltt_free_daemon_handle: - Free the daemon's handle.
+ *
+ *	Returns: 
+ *	0, everything went OK
+ *	-EACCES, handle doesn't belong to caller.
+ *	-EBUSY, there are still event writes in progress so the buffer can't
+ *	be released.
+ */
+int ltt_free_daemon_handle(struct trace_struct *trace)
+{
+	int i;
+
+	if (!trace->flight_recorder) {
+		if (trace->daemon_task_struct != current)
+			return -EACCES;
+
+		for (i = 0; i < num_cpus; i++) {
+			if (events_lost(trace->trace_handle, i) > 0)
+				printk(KERN_ALERT "LTT: Lost %d events on cpu %d\n",
+				       events_lost(trace->trace_handle, i), i);
+		}
+		trace->daemon_task_struct = NULL;
+	}
+	
+	trace->active = NULL;
+
+	if (!active_traces())
+		del_percpu_timers();
+
+	if(!need_heartbeat()) 
+		del_timer(&heartbeat_timer);
+
+	for (i = 0; i < num_cpus; i++) {
+		if (trace_channel_handle(trace->trace_handle, i) != -1) {
+				trace_channel_handle(trace->trace_handle, i) = -1;
+				trace_channel_reader(trace->trace_handle, i) = NULL;
+		}
+	}
+
+	remove_handle_proc_dir(trace->proc_dir_entry, 0);
+
+	trace->use_locking = 1;
+	ltt_set_default_config(trace);
+	trace->tracer_started = 0;
+	trace->tracer_stopping = 0;
+	if (trace->trace_start_data)
+		kfree(trace->trace_start_data);
+
+	return 0;
+}
+
+/**
+ *	ltt_free_all_handles: - Free all handles taken.
+ *	@task_ptr: pointer to exiting task.
+ *
+ *	Free all handles taken against a given channel.  If task_ptr is NULL,
+ *	it means there is no daemon, i.e. free all handles taken agains the
+ *	flight recorder channel, otherwise task_ptr refers to a trace daemon.
+ */
+void ltt_free_all_handles(struct task_struct* task_ptr)
+{
+	int i;
+	struct trace_struct *trace;
+
+	if (task_ptr == NULL) {
+		if (current_traces[FLIGHT_HANDLE].active) {
+			ltt_free_daemon_handle(&current_traces[FLIGHT_HANDLE]);
+			return;
+		}
+	} else {
+		trace = &current_traces[TRACE_HANDLE];
+		if (trace->active && trace->daemon_task_struct == task_ptr)
+			ltt_free_daemon_handle(trace);
+	}
+
+	write_lock(&trace_handle_table_lock);
+	for (i = 0; i < TRACE_MAX_HANDLES; i++)
+		if (trace_handle_table[i].owner == current)
+			trace_handle_table[i].owner = NULL;
+	write_unlock(&trace_handle_table_lock);
+} /* * Tracer Configuration
+ */
+
+/**
+ *	init_channel_data: - Init channel-associated data for new tracing run.
+ *	@buf_ctrl: buffer control struct to be initialized
+ *	@use_lockless: which tracing scheme to use, 1 for lockless
+ *	@buffer_number_bits: number of bits in index word for buffer number
+ *	@offset_bits: number of bits in index word to use for buffer offset
+ */
+static void init_channel_data(struct trace_struct *trace)
+{
+	unsigned i;
+	
+	trace->buffer_switches_pending = 0;
+
+	for (i = 0; i < num_cpus; i++) {
+		trace_channel_handle(trace->trace_handle, i) = -1;
+		trace_channel_reader(trace->trace_handle, i) = NULL;
+		atomic_set(&waiting_for_cpu_async(trace->trace_handle, i), LTT_NOTHING_TO_DO);
+		events_lost(trace->trace_handle, i) = 0;
+	}
+}
+
+/**
+ *	ltt_set_n_buffers: - Sets the number of buffers.
+ *	@no_buffers: number of buffers.
+ *
+ *	For lockless only, must be a power of 2.
+ *
+ *	Returns:
+ *
+ *	0, Size setting went OK
+ *	-EINVAL, not a power of 2
+ */
+int ltt_set_n_buffers(struct trace_struct *trace, int no_buffers)
+{
+	if (hweight32(no_buffers) != 1)
+		return -EINVAL;
+
+	trace->n_buffers = no_buffers;
+
+	return 0;
+}
+
+/**
+ *	ltt_set_buffer_size: - Sets size of and creates buffers.
+ *	@buf_size: Size of sub-buffers
+ *	@dirname: name of the relayfs directory to contain trace files
+ *
+ *	Note: dirname should be well-formed before it gets here e.g.
+ *	trailing slashes should be removed.
+ *
+ *	Returns:
+ *	0, Size setting went OK
+ *	-ENOMEM, unable to get a hold of memory for tracer
+ *	-EINVAL, tracer not properly configured
+ */
+int ltt_set_buffer_size(struct trace_struct *trace, int buffer_size, char * dirname)
+{
+	int i;
+	u32 flags;
+
+	if (trace->flight_recorder)
+		flags = RELAY_DELIVERY_BULK | RELAY_USAGE_SMP | RELAY_MODE_CONTINUOUS;
+	else
+		flags = RELAY_DELIVERY_BULK | RELAY_USAGE_SMP | RELAY_MODE_NO_OVERWRITE;
+
+	if ((dirname == NULL) || (strlen(dirname) == 0))
+		return  -EINVAL;
+
+	if (trace->using_tsc)
+		flags |= RELAY_TIMESTAMP_TSC;
+	else
+		flags |= RELAY_TIMESTAMP_GETTIMEOFDAY;
+	
+	if (trace->use_locking)
+		flags |= RELAY_SCHEME_LOCKING;
+	else
+		flags |= RELAY_SCHEME_LOCKLESS;
+	
+	num_cpus = num_online_cpus();
+
+	init_channel_data(trace);
+
+	trace->buf_size = buffer_size;
+
+	for (i = 0; i < num_cpus; i++) {
+		sprintf(relay_file_name, "%s/cpu%d", dirname, i);
+		trace_channel_handle(trace->trace_handle, i) = relay_open(relay_file_name,
+							  buffer_size,
+							  trace->n_buffers,
+							  flags,
+							  &ltt_callbacks,
+							  start_reserve,
+							  end_reserve,
+							  trace_start_reserve,
+							  0,
+							  0,
+							  0,
+							  NULL,
+							  0);
+		if (trace_channel_handle(trace->trace_handle, i) < 0)
+			return -ENOMEM;
+	}
+	
+	return 0;
+}
+
+/**
+ *	ltt_set_default_config: - Sets the tracer in its default config
+ *
+ *	Returns:
+ *	0, everything went OK
+ *	-ENOMEM, unable to get a hold of memory for tracer
+ */
+int ltt_set_default_config(struct trace_struct *trace)
+{
+	int i;
+	int retval = 0;
+
+	trace->traced_events = 0;
+
+	for (i = 0; i <= TRACE_EV_MAX; i++) {
+		ltt_set_bit(i, &trace->traced_events);
+		ltt_set_bit(i, &trace->log_event_details_mask);
+	}
+
+
+	trace->log_cpuid = 0;
+	trace->tracing_pid = 0;
+	trace->tracing_pgrp = 0;
+	trace->tracing_gid = 0;
+	trace->tracing_uid = 0;
+	trace->using_tsc = 0;
+
+	syscall_eip_depth_set = 0;
+	use_syscall_eip_bounds = 0;
+	lower_eip_bound_set = 0;
+	upper_eip_bound_set = 0;
+
+	ltt_set_trace_config(syscall_eip_depth_set,
+			 use_syscall_eip_bounds,
+			 0,
+			 0,
+			 0);
+
+	/* Enable hooks for the events we are interested in. */
+	if (trace->tracer_started) {
+		change_traced_events(&trace->traced_events);
+	}
+
+	return retval;
+}
+
+/**
+ *	ltt_set_trace_config: - Set the tracing configuration
+ *	@do_syscall_depth: Use depth to fetch eip
+ *	@do_syscall_bounds: Use bounds to fetch eip
+ *	@eip_depth: Detph to fetch eip
+ *	@eip_lower_bound: Lower bound eip address
+ *	@eip_upper_bound: Upper bound eip address
+ *
+ *	Returns: 
+ *	0, all is OK 
+ *	-ENOMEDIUM, there isn't a registered tracer
+ *	-ENXIO, wrong tracer
+ *	-EINVAL, invalid configuration
+ */
+int ltt_set_trace_config(int do_syscall_depth,
+		     int do_syscall_bounds,
+		     int eip_depth,
+		     void *eip_lower_bound,
+		     void *eip_upper_bound)
+{
+	if ((do_syscall_depth && do_syscall_bounds)
+	    || (eip_lower_bound > eip_upper_bound)
+	    || (eip_depth < 0))
+		return -EINVAL;
+
+	fetch_syscall_eip_use_depth = do_syscall_depth;
+	fetch_syscall_eip_use_bounds = do_syscall_bounds;
+
+	syscall_eip_depth = eip_depth;
+	syscall_lower_eip_bound = eip_lower_bound;
+	syscall_upper_eip_bound = eip_upper_bound;
+
+	return 0;
+}
+
+/**
+ *	ltt_get_trace_config: - Get the tracing configuration
+ *	@do_syscall_depth: Use depth to fetch eip
+ *	@do_syscall_bounds: Use bounds to fetch eip
+ *	@eip_depth: Detph to fetch eip
+ *	@eip_lower_bound: Lower bound eip address
+ *	@eip_upper_bound: Upper bound eip address
+ *
+ *	Returns:
+ *	0, all is OK 
+ *	-ENOMEDIUM, there isn't a registered tracer
+ */
+int ltt_get_trace_config(int *do_syscall_depth,
+		     int *do_syscall_bounds,
+		     int *eip_depth,
+		     void **eip_lower_bound,
+		     void **eip_upper_bound)
+{
+	*do_syscall_depth = fetch_syscall_eip_use_depth;
+	*do_syscall_bounds = fetch_syscall_eip_use_bounds;
+	*eip_depth = syscall_eip_depth;
+	*eip_lower_bound = syscall_lower_eip_bound;
+	*eip_upper_bound = syscall_upper_eip_bound;
+
+	return 0;
+}
+
+
+/*
+ * Custom Events
+ */
+
+/**
+ *	init_custom_events: - Initialize custom events
+ */
+static inline void init_custom_events(void)
+{
+	custom_events = &custom_events_head;
+	custom_events->next = custom_events;
+	custom_events->prev = custom_events;
+}
+
+/**
+ *	_ltt_create_event: - Create a new traceable event type
+ *	@event_type: string describing event type
+ *	@event_desc: string used for standard formatting
+ *	@format_type: type of formatting used to log event data
+ *	@format_data: data specific to format
+ *	@owner_pid: PID of event's owner (0 if none)
+ *
+ *	Returns:
+ *	New Event ID if all is OK
+ *	-ENOMEM, Unable to allocate new event
+ */
+int _ltt_create_event(char *event_type,
+			char *event_desc,
+			int format_type,
+			char *format_data,
+			pid_t owner_pid)
+{
+	trace_new_event *new_event;
+	struct custom_event_desc *new_event_desc;
+
+	if ((new_event_desc = (struct custom_event_desc *) kmalloc(sizeof(struct custom_event_desc), GFP_ATOMIC)) == NULL)
+		 return -ENOMEM;
+
+	new_event = &(new_event_desc->event);
+	new_event->type[0] = '\0';
+	new_event->desc[0] = '\0';
+	new_event->form[0] = '\0';
+
+	if (event_type != NULL)
+		strncpy(new_event->type, event_type, CUSTOM_EVENT_TYPE_STR_LEN);
+	if (event_desc != NULL)
+		strncpy(new_event->desc, event_desc, CUSTOM_EVENT_DESC_STR_LEN);
+	if (format_data != NULL)
+		strncpy(new_event->form, format_data, CUSTOM_EVENT_FORM_STR_LEN);
+
+	new_event->type[CUSTOM_EVENT_TYPE_STR_LEN - 1] = '\0';
+	new_event->desc[CUSTOM_EVENT_DESC_STR_LEN - 1] = '\0';
+	new_event->form[CUSTOM_EVENT_FORM_STR_LEN - 1] = '\0';
+
+	new_event->format_type = format_type;
+	new_event->id = next_event_id;
+
+	next_event_id++;
+
+	new_event_desc->owner_pid = owner_pid;
+
+	write_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	new_event_desc->next = custom_events;
+	new_event_desc->prev = custom_events->prev;
+	custom_events->prev->next = new_event_desc;
+	custom_events->prev = new_event_desc;
+	write_unlock(&custom_list_lock);
+
+	ltt_log_event(TRACE_EV_NEW_EVENT, &(new_event_desc->event));
+
+	return new_event->id;
+}
+
+int ltt_create_event(char *event_type,
+		       char *event_desc,
+		       int format_type,
+		       char *format_data)
+{
+	return _ltt_create_event(event_type, event_desc, format_type, format_data, 0);
+}
+
+int ltt_create_owned_event(char *event_type,
+			     char *event_desc,
+			     int format_type,
+			     char *format_data,
+			     pid_t owner_pid)
+{
+	return _ltt_create_event(event_type, event_desc, format_type, format_data, owner_pid);
+}
+
+/**
+ *	ltt_destroy_event: - Destroy a created event type
+ *	@event_id, the Id returned by ltt_create_event()
+ */
+void ltt_destroy_event(int event_id)
+{
+	struct custom_event_desc *event_desc;
+
+	write_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	for (event_desc = custom_events->next;
+	     event_desc != custom_events;
+	     event_desc = event_desc->next)
+		if (event_desc->event.id == event_id)
+			break;
+
+	if (event_desc != custom_events) {
+		event_desc->next->prev = event_desc->prev;
+		event_desc->prev->next = event_desc->next;
+		kfree(event_desc);
+	}
+
+	write_unlock(&custom_list_lock);
+}
+
+/**
+ *	ltt_destroy_owners_events: Destroy an owner's events
+ *	@owner_pid: the PID of the owner who's events are to be deleted.
+ */
+void ltt_destroy_owners_events(pid_t owner_pid)
+{
+	struct custom_event_desc *temp_event;
+	struct custom_event_desc *event_desc;
+
+	write_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	event_desc = custom_events->next;
+
+	while (event_desc != custom_events) {
+		temp_event = event_desc->next;
+		if (event_desc->owner_pid == owner_pid) {
+			event_desc->next->prev = event_desc->prev;
+			event_desc->prev->next = event_desc->next;
+			kfree(event_desc);
+		}
+		event_desc = temp_event;
+	}
+
+	write_unlock(&custom_list_lock);
+}
+
+/**
+ *	ltt_reregister_custom_events: - Relogs event creations.
+ */
+void ltt_reregister_custom_events(void)
+{
+	struct custom_event_desc *event_desc;
+
+	read_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	for (event_desc = custom_events->next;
+	     event_desc != custom_events;
+	     event_desc = event_desc->next)
+		ltt_log_event(TRACE_EV_NEW_EVENT, &(event_desc->event));
+
+	read_unlock(&custom_list_lock);
+}
+
+/*
+ * Event logging primitives
+ */
+
+/**
+ *	_ltt_log_event: - Tracing function per se.
+ *	@event_id: ID of event as defined in linux/ltt.h
+ *	@event_struct: struct describing the event
+ *	@cpu_id: the CPU associated with the event
+ *
+ *	Returns: 
+ *	0, if everything went OK (event got registered)
+ *	-ENODEV, no tracing daemon opened the driver.
+ *	-ENOMEM, no more memory to store events.
+ *	-EBUSY, tracer not started yet.
+ */
+int _ltt_log_event(struct trace_struct *trace,
+		   u8 event_id,
+		   void *event_struct,
+		   u8 cpu_id)
+{
+	int var_data_len = 0;
+	void *var_data_beg = NULL;
+	uint16_t data_size;
+	struct task_struct *incoming_process = NULL;
+	unsigned long flags;
+	char * reserved;
+	int bytes_written = 0;
+	int reserve_code, interrupting;
+	struct timeval time_stamp;
+	u32 time_delta;
+	int channel_handle;
+	struct rchan *rchan;
+	unsigned int tracer_handle;
+	
+	if (!trace)
+		return -ENOMEDIUM;
+
+	if (trace->paused)
+		return -EBUSY;
+
+	tracer_handle = trace->trace_handle;
+	
+	if (!trace->flight_recorder && (trace->daemon_task_struct == NULL))
+		return -ENODEV;
+
+	channel_handle = trace_channel_handle(tracer_handle, cpu_id);
+
+	if ((trace->tracer_started == 1) || (event_id == TRACE_EV_START) || (event_id == TRACE_EV_BUFFER_START))
+		goto trace_event;
+
+	return -EBUSY;
+
+trace_event:
+	if (!ltt_test_bit(event_id, &trace->traced_events))
+		return 0;
+
+	if ((event_id != TRACE_EV_START) && (event_id != TRACE_EV_BUFFER_START)) {
+		if (event_id == TRACE_EV_SCHEDCHANGE)
+			incoming_process = (struct task_struct *) (((trace_schedchange *) event_struct)->in);
+		if ((trace->tracing_pid == 1) && (current->pid != trace->traced_pid)) {
+			if (incoming_process == NULL)
+				return 0;
+			else if (incoming_process->pid != trace->traced_pid)
+				return 0;
+		}
+		if ((trace->tracing_pgrp == 1) && (process_group(current) != trace->traced_pgrp)) {
+			if (incoming_process == NULL)
+				return 0;
+			else if (process_group(incoming_process) != trace->traced_pgrp)
+				return 0;
+		}
+		if ((trace->tracing_gid == 1) && (current->egid != trace->traced_gid)) {
+			if (incoming_process == NULL)
+				return 0;
+			else if (incoming_process->egid != trace->traced_gid)
+				return 0;
+		}
+		if ((trace->tracing_uid == 1) && (current->euid != trace->traced_uid)) {
+			if (incoming_process == NULL)
+				return 0;
+			else if (incoming_process->euid != trace->traced_uid)
+				return 0;
+		}
+		if (event_id == TRACE_EV_SCHEDCHANGE)
+			(((trace_schedchange *) event_struct)->in) = incoming_process->pid;
+	}
+
+	data_size = sizeof(event_id) + sizeof(time_delta) + sizeof(data_size);
+
+	if (ltt_test_bit(event_id, &trace->log_event_details_mask)) {
+		data_size += event_struct_size[event_id];
+		switch (event_id) {
+		case TRACE_EV_FILE_SYSTEM:
+			if ((((trace_file_system *) event_struct)->event_sub_id == TRACE_EV_FILE_SYSTEM_EXEC)
+			    || (((trace_file_system *) event_struct)->event_sub_id == TRACE_EV_FILE_SYSTEM_OPEN)) {
+				var_data_beg = ((trace_file_system *) event_struct)->file_name;
+				var_data_len = ((trace_file_system *) event_struct)->event_data2 + 1;
+				data_size += (uint16_t) var_data_len;
+			}
+			break;
+		case TRACE_EV_CUSTOM:
+			var_data_beg = ((trace_custom *) event_struct)->data;
+			var_data_len = ((trace_custom *) event_struct)->data_size;
+			data_size += (uint16_t) var_data_len;
+			break;
+		}
+	}
+
+	if ((trace->log_cpuid == 1) && (event_id != TRACE_EV_START) && (event_id != TRACE_EV_BUFFER_START))
+		data_size += sizeof(cpu_id);
+
+	rchan = rchan_get(channel_handle);
+	if (rchan == NULL)
+		return -ENODEV;
+	relay_lock_channel(rchan, flags); /* nop for lockless */
+	reserved = relay_reserve(rchan, data_size, &time_stamp, &time_delta, &reserve_code, &interrupting);
+	
+	if (reserve_code & RELAY_WRITE_DISCARD) {
+		events_lost(trace->trace_handle, cpu_id)++;
+		bytes_written = 0;
+		goto check_buffer_switch;
+	}
+	if ((trace->log_cpuid == 1) && (event_id != TRACE_EV_START) 
+	    && (event_id != TRACE_EV_BUFFER_START))
+		relay_write_direct(reserved,
+				   &cpu_id,
+				   sizeof(cpu_id));
+
+	relay_write_direct(reserved,
+			   &event_id,
+			   sizeof(event_id));
+
+	relay_write_direct(reserved,
+			   &time_delta,
+			   sizeof(time_delta));
+
+	if (ltt_test_bit(event_id, &trace->log_event_details_mask)) {
+		relay_write_direct(reserved,
+				   event_struct,
+				   event_struct_size[event_id]);
+		if (var_data_len)
+			relay_write_direct(reserved,
+					   var_data_beg,
+					   var_data_len);
+	}
+
+	relay_write_direct(reserved,
+			   &data_size,
+			   sizeof(data_size));
+
+	bytes_written = data_size;
+
+check_buffer_switch:
+	if ((event_id == TRACE_EV_SCHEDCHANGE) && (tracer_handle == TRACE_HANDLE) && current_traces[FLIGHT_HANDLE].active)
+		(((trace_schedchange *) event_struct)->in) = (u32)incoming_process;
+	
+	/* We need to commit even if we didn't write anything because
+	   that's how the deliver callback is invoked. */
+	relay_commit(rchan, reserved, bytes_written, reserve_code, interrupting);
+
+	relay_unlock_channel(rchan, flags);
+	rchan_put(rchan);
+
+	return 0;
+}
+
+/**
+ *	ltt_log_event: - Trace an event
+ *	@event_id, the event's ID (check out ltt.h)
+ *	@event_struct, the structure describing the event
+ *
+ *	Returns:
+ *	Trace fct return code if OK.
+ *	-ENOMEDIUM, there is no registered tracer
+ *	-ENOMEM, couldn't access ltt_info
+ */
+int ltt_log_event(u8 event_id,
+		void *event_struct)
+{
+	int i;
+	static int err[NR_TRACES];
+	struct trace_struct *trace;
+	u32 cpu = smp_processor_id();
+
+	for (i = 0; i < NR_TRACES; i++) {
+		trace = current_traces[i].active;
+		err[i] = _ltt_log_event(trace,
+				     event_id,
+				     event_struct, 
+				     cpu);
+	}
+
+	return err[0] == -ENOMEDIUM ? err[1] : err[0];
+}
+
+/**
+ *	ltt_log_std_formatted_event: - Trace a formatted event
+ *	@event_id: the event Id provided upon creation
+ *	@...: printf-like data that will be used to fill the event string.
+ *
+ *	Returns:
+ *	Trace fct return code if OK.
+ *	-ENOMEDIUM, there is no registered tracer or event doesn't exist.
+ */
+int ltt_log_std_formatted_event(int event_id,...)
+{
+	int string_size;
+	char final_string[CUSTOM_EVENT_FINAL_STR_LEN];
+	va_list vararg_list;
+	trace_custom custom_event;
+	struct custom_event_desc *event_desc;
+
+	read_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	for (event_desc = custom_events->next;
+	     event_desc != custom_events;
+	     event_desc = event_desc->next)
+		if (event_desc->event.id == event_id)
+			break;
+
+	if (event_desc == custom_events) {
+		read_unlock(&custom_list_lock);
+		return -ENOMEDIUM;
+	}
+
+	custom_event.id = event_id;
+
+	va_start(vararg_list, event_id);
+	string_size = vsprintf(final_string, event_desc->event.desc, vararg_list);
+	read_unlock(&custom_list_lock);
+	va_end(vararg_list);
+
+	custom_event.data_size = (u32) (string_size + 1);
+	custom_event.data = final_string;
+
+	return ltt_log_event(TRACE_EV_CUSTOM, &custom_event);
+}
+
+/**
+ *	ltt_log_raw_event: - Trace a raw event
+ *	@event_id, the event Id provided upon creation
+ *	@event_size, the size of the data provided
+ *	@event_data, data buffer describing event
+ *
+ *	Returns:
+ *	Trace fct return code if OK.
+ *	-ENOMEDIUM, there is no registered tracer or event doesn't exist.
+ */
+int ltt_log_raw_event(int event_id, int event_size, void *event_data)
+{
+	trace_custom custom_event;
+	struct custom_event_desc *event_desc;
+
+	read_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	for (event_desc = custom_events->next;
+	     event_desc != custom_events;
+	     event_desc = event_desc->next)
+		if (event_desc->event.id == event_id)
+			break;
+
+	read_unlock(&custom_list_lock);
+
+	if (event_desc == custom_events)
+		return -ENOMEDIUM;
+
+	custom_event.id = event_id;
+
+	if (event_size <= CUSTOM_EVENT_MAX_SIZE)
+		custom_event.data_size = (u32) event_size;
+	else
+		custom_event.data_size = (u32) CUSTOM_EVENT_MAX_SIZE;
+
+	custom_event.data = event_data;
+
+	return ltt_log_event(TRACE_EV_CUSTOM, &custom_event);
+}
+
+/*
+ * Relayfs callback implementations.
+ */
+
+/**
+ *	_ltt_channel_cpuid: - Get CPU id given channel handle, for given trace.
+ *	@tracer_handle: trace handle.
+ *	@channel_handle: relay channel handle.
+ *
+ *	Returns:
+ *
+ *	CPU id
+ *	-1, channel_handle, thus CPU id, not found
+ */
+static int _ltt_channel_cpuid(int tracer_handle, int channel_handle)
+{
+	int i;
+	
+	for (i = 0; i < num_cpus; i++)
+		if (trace_channel_handle(tracer_handle, i) == channel_handle)
+			return i;
+	
+	return -1;
+}
+
+/**
+ *	ltt_channel_cpuid: - Get CPU id given channel handle.
+ *	@channel_handle: relay channel handle.
+ *
+ *	Returns:
+ *
+ *	CPU id
+ *	-1, channel_handle, thus CPU id, not found
+ */
+static int ltt_channel_cpuid(int channel_handle)
+{
+	int i, cpuid;
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		cpuid = _ltt_channel_cpuid(i, channel_handle);
+		if (cpuid != -1)
+			return cpuid;
+	}
+	
+	return -1;
+}
+
+/**
+ *	ltt_channel_trace: - Get trace struct given channel handle.
+ *	@channel_handle: relay channel handle.
+ *
+ *	Returns:
+ *
+ *	trace struct *
+ *	NULL, channel_handle, thus trace_struct *, not found
+ */
+static struct trace_struct *ltt_channel_trace(int channel_handle)
+{
+	int i;
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		if (_ltt_channel_cpuid(i, channel_handle) != -1)
+			return &current_traces[i];
+	}
+	
+	return NULL;
+}
+
+/**
+ *	ltt_channel_trace_handle: - Get trace handle given channel handle.
+ *	@channel_handle: relay channel handle.
+ *
+ *	Returns:
+ *
+ *	trace handle
+ *	-1, channel_handle, thus trace handle, not found
+ */
+static int ltt_channel_trace_handle(int channel_handle)
+{
+	unsigned int i;
+	
+	for (i = 0; i < NR_TRACES; i++)
+		if (_ltt_channel_cpuid(i, channel_handle) != -1)
+			return i;
+	
+	return -1;
+}
+
+/**
+ *	write_start_event: - Initialize a trace session for a given CPU.
+ *	@cpu_id: the CPU id to initialize a trace for
+ */
+static inline int write_start_event(struct trace_struct *trace,
+				    int channel, 
+				    char * current_write_pos,
+				    u32 start_tsc,
+				    int using_tsc)
+{
+	struct rchan_info channel_info;
+	u32 time_delta;
+	trace_start start_event;
+	u8 event_id;
+	uint16_t data_size;
+
+	relay_info(channel, &channel_info);
+
+	start_event.magic_number =	TRACER_MAGIC_NUMBER;
+	start_event.arch_type =		TRACE_ARCH_TYPE;
+	start_event.arch_variant =	TRACE_ARCH_VARIANT;
+	start_event.system_type =	TRACE_SYS_TYPE_VANILLA_LINUX;
+	start_event.major_version =	TRACER_VERSION_MAJOR;
+	start_event.minor_version =	TRACER_VERSION_MINOR;
+	start_event.buffer_size =	channel_info.buf_size;
+	start_event.event_mask = 	trace->traced_events;
+	start_event.details_mask =	trace->log_event_details_mask;
+	start_event.log_cpuid =		trace->log_cpuid;
+	start_event.use_tsc =		trace->using_tsc;
+	start_event.flight_recorder =	trace->flight_recorder;
+
+	event_id = TRACE_EV_START;
+	relay_write_direct(current_write_pos,
+			   &event_id,
+			   sizeof(event_id));
+
+	time_delta = switch_time_delta(start_tsc, using_tsc);
+	relay_write_direct(current_write_pos,
+			   &time_delta,
+			   sizeof(time_delta));
+
+	relay_write_direct(current_write_pos,
+			   &start_event,
+			   sizeof(trace_start));
+
+	data_size = sizeof(event_id)
+		+ sizeof(time_delta)
+		+ sizeof(trace_start)
+		+ sizeof(data_size);
+
+	relay_write_direct(current_write_pos,
+			   &data_size,
+			   sizeof(data_size));
+
+	if (trace->trace_start_data)
+		memcpy(trace->trace_start_data, &start_event, sizeof(start_event));
+
+	return (int)data_size;
+}
+
+/**
+ *	buffer_start_callback: - Write start-buffer event to start of buffer.
+ *	@channel_handle: the channel id
+ *	@current_write_pos: position in sub-buffer client should write to
+ *	@buffer_id: the id of the new sub-buffer
+ *	@start_time: the timestamp associated with the start of sub-buffer
+ *	@start_tsc: the TSC associated with the timestamp, if using_tsc
+ *	@using_tsc: boolean, indicates whether start_tsc is valid
+ *
+ *	This is the relayfs buffer_start() callback implementation for
+ *	the tracer.  We write the start event directly to the address
+ *	contained in the current_write_pos param.  If this is the first
+ *	sub-buffer, we also write the start event.  Of course we reserved
+ *	the number of bytes we're writing when we opened the channel, which
+ *	is the number we return.
+ */
+static int buffer_start_callback(int channel_handle,
+				 char * current_write_pos,
+				 u32 buffer_id,
+				 struct timeval start_time,
+				 u32 start_tsc,
+				 int using_tsc) 
+{
+	trace_buffer_start start_buffer_event;
+	u8 event_id;
+	u32 time_delta;
+	uint16_t data_size;
+	struct trace_struct *trace = ltt_channel_trace(channel_handle);
+
+	if (!trace)
+		return 0;
+	
+	start_buffer_event.id = buffer_id;
+	start_buffer_event.time = start_time;
+	start_buffer_event.tsc = start_tsc;
+
+	event_id = TRACE_EV_BUFFER_START;
+	relay_write_direct(current_write_pos,
+			   &event_id,
+			   sizeof(event_id));
+
+	time_delta = switch_time_delta(start_tsc, using_tsc);
+	relay_write_direct(current_write_pos,
+			   &time_delta,
+			   sizeof(time_delta));
+
+	relay_write_direct(current_write_pos,
+			   &start_buffer_event,
+			   sizeof(start_buffer_event));
+
+	data_size = sizeof(event_id)
+	    + sizeof(time_delta)
+	    + sizeof(start_buffer_event)
+	    + sizeof(data_size);
+
+	relay_write_direct(current_write_pos,
+			   &data_size,
+			   sizeof(data_size));
+
+	if (buffer_id == 0) /* first buffer */
+		data_size += write_start_event(trace, channel_handle, current_write_pos, start_tsc, using_tsc);
+	
+	return (int)data_size;
+}
+
+/**
+ *	buffer_end_callback - called at the end of a sub-buffer
+ *	@channel_handle: the channel id
+ *	@current_write_pos: position in sub-buffer of end of data
+ *	@end_of_buffer: the position of the end of the sub-buffer
+ *	@end_time: the timestamp associated with the end of the sub-buffer
+ *	@end_tsc: the TSC associated with the end_time, if using_tsc
+ *	@using_tsc: boolean, indicates whether end_tsc is valid
+ *
+ *	This is the relayfs buffer_end() callback implementation for
+ *	the tracer.  We write the end event directly to the address
+ *	contained in the current_write_pos param.  We also calculate
+ *	the 'size_lost' or unused bytes at the end of the sub-buffer
+ *	and write that value to the very end of the sub-buffer for
+ *	post-processing.  Of course we reserved	the number of bytes
+ *	we're writing when we opened the channel, which is the number
+ *	we return.
+ */
+static int buffer_end_callback(int channel_handle,
+			       char * current_write_pos,
+			       char * end_of_buffer,
+			       struct timeval end_time,
+			       u32 end_tsc,
+			       int using_tsc) 
+{
+ 	trace_buffer_end end_buffer_event;
+	u8 event_id;
+	u32 time_delta;
+	char* init_write_pos = current_write_pos;
+	uint16_t data_size;
+	u32 size_lost;
+	u8 cpu_id;
+	struct trace_struct *trace;
+
+	end_buffer_event.time = end_time;
+	end_buffer_event.tsc = end_tsc;
+
+	cpu_id = (u8)ltt_channel_cpuid(channel_handle);
+	trace = ltt_channel_trace(channel_handle);
+	if (!trace)
+		return 0;
+
+	if (trace->log_cpuid == 1)
+		relay_write_direct(current_write_pos,
+				   &cpu_id,
+				   sizeof(cpu_id));
+
+	event_id = TRACE_EV_BUFFER_END;
+	relay_write_direct(current_write_pos,
+			   &event_id,
+			   sizeof(event_id));
+
+	time_delta = switch_time_delta(end_tsc, using_tsc);
+	relay_write_direct(current_write_pos,
+			   &time_delta,
+			   sizeof(time_delta));
+
+	relay_write_direct(current_write_pos,
+			   &end_buffer_event,
+			   sizeof(end_buffer_event));
+
+	data_size = sizeof(event_id)
+		+ sizeof(time_delta)
+		+ sizeof(end_buffer_event)
+		+ sizeof(data_size);
+
+	relay_write_direct(current_write_pos,
+			   &data_size,
+			   sizeof(data_size));
+
+	/* size lost includes size of end buffer event */
+	size_lost = end_of_buffer - init_write_pos;
+	*((u32 *) (end_of_buffer - sizeof(size_lost))) = size_lost;
+
+	return (int)data_size;
+}
+
+/**
+ *	deliver_callback - called when data is ready for the tracer
+ *	@channel_handle: the channel id
+ *	@from: the start of the delivered data
+ *	@len: the length of the delivered data
+ *
+ *	This is the relayfs deliver() callback implementation for
+ *	the tracer.  We simply set the send_signal flag, which will
+ *	be checked when the current write is finished, at which 
+ *	point the daemon will be signaled to read the buffer.
+ */
+void deliver_callback(int channel_handle,
+		      char * from,
+		      u32 len)
+{
+	struct trace_struct *trace;
+	int cpu_id;
+
+	trace = ltt_channel_trace(channel_handle);
+	if (!trace)
+		return;
+	
+	cpu_id = ltt_channel_cpuid(channel_handle);
+	if (cpu_id == -1)
+		return;
+
+	set_bit(cpu_id, &trace->buffer_switches_pending);
+}
+
+/**
+ *	fileop_notify - called when change to trace file status 
+ *	@rchan_id: the rchan id
+ *	@filp: the file
+ *	@fileop: the file operation
+ *
+ *	This is the relayfs fileop_notify() callback implementation for
+ *	the tracer.  We use it to take care of trace file mapping and
+ *	unmapping tasks.
+ */
+static int fileop_notify(int rchan_id,
+			 struct file *filp,
+			 enum relay_fileop fileop)
+{
+	struct rchan_reader *map_reader;
+	struct rchan_reader *open_file_reader;
+	struct rchan *rchan;
+	u8 cpu_id;
+	int trace_handle;
+
+	trace_handle = ltt_channel_trace_handle(rchan_id);
+	if (trace_handle == -1)
+		return 0;
+	
+	if (fileop == RELAY_FILE_MAP) {
+		cpu_id = (u8)ltt_channel_cpuid(rchan_id);
+		open_file_reader = (struct rchan_reader *)filp->private_data;
+		rchan = open_file_reader->rchan;
+		if (atomic_read(&rchan->mapped))
+			return -EBUSY;
+		map_reader = add_map_reader(rchan_id);
+		trace_channel_reader(trace_handle, cpu_id) = map_reader;
+	} else if (fileop == RELAY_FILE_UNMAP) {
+		cpu_id = (u8)ltt_channel_cpuid(rchan_id);
+		remove_map_reader(trace_channel_reader(trace_handle, cpu_id));
+		trace_channel_reader(trace_handle, cpu_id) = NULL;
+	}
+
+	return 0;
+}
+
+static struct rchan_callbacks ltt_callbacks = {
+	.buffer_start = buffer_start_callback,
+	.buffer_end = buffer_end_callback,
+	.deliver = deliver_callback,
+	.fileop_notify = fileop_notify,
+	.ioctl = ltt_ioctl,
+};
+
+/*
+ * Procfs kernel-user interface
+ */
+
+/**
+ *	proc_read_relayfs_path - procfs read callback for relayfs_path attr 
+ */
+static int proc_read_relayfs_path(char *page, char **start, off_t off, 
+				  int count, int *eof, void *data)
+{
+	return sprintf(page, "%s", relayfs_path);
+}
+
+/**
+ *	proc_write_relayfs_path - procfs write callback for relayfs_path attr 
+ *
+ *	Sets the path to the trace files within relayfs for the current trace.
+ */
+static int proc_write_relayfs_path(struct file *filp, const char *buffer,
+				   unsigned long count, void *data)
+{
+	unsigned long len;
+
+	if (count > PATH_MAX)
+		len = PATH_MAX;
+	else
+		len = count;
+	
+	if (copy_from_user(relayfs_path, buffer, len))
+		return -EFAULT;
+
+	if (len != PATH_MAX)
+		relayfs_path[len] = '\0';
+
+	return len;
+}
+
+/**
+ *	populate_handle_proc_dir - populate proc dir with trace attributes
+ *	@trace_handle: the trace handle for this trace run
+ *	@handle_dir: the directory to populate
+ *
+ *	This function populates the handle dir with attribute files.
+ *
+ *	Returns 0 if successful, negative if not.
+ */
+static int populate_handle_proc_dir(unsigned int trace_handle,
+				    struct proc_dir_entry *handle_dir)
+{
+	struct proc_dir_entry * file_entry;
+	int err = 0;
+
+	file_entry = create_proc_entry("relayfs_path", 0666, handle_dir);
+
+	if (file_entry == NULL) {
+		err = -ENOMEM;
+		return err;
+	}
+
+	file_entry->read_proc = proc_read_relayfs_path;
+	file_entry->write_proc = proc_write_relayfs_path;
+	file_entry->data = (void *)trace_handle;
+	file_entry->owner = THIS_MODULE;
+
+	return err;
+}
+
+/**
+ *	create_handle_proc_dir - create proc dir for trace attributes
+ *	@trace_handle: the trace handle for this trace run
+ *
+ *	This function creates a proc dir to communicate trace attribute
+ *	values between the daemon and the tracer.  It also populates the
+ *	new dir with the attribute files.
+ *
+ *	Retruns the proc dir entry if successful, NULL otherwise.
+ */
+static struct proc_dir_entry *create_handle_proc_dir(unsigned int trace_handle)
+{
+	char handle_dir_name[22];
+	struct proc_dir_entry *handle_dir;
+
+	sprintf(handle_dir_name, "%u", trace_handle);
+
+	handle_dir = proc_mkdir(handle_dir_name, ltt_proc_root_entry);
+
+	if (handle_dir == NULL) {
+		return NULL;
+	}
+	else
+		handle_dir->owner = THIS_MODULE;
+	
+	if (populate_handle_proc_dir(trace_handle, handle_dir)) {
+		remove_proc_entry(handle_dir_name, ltt_proc_root_entry);
+		handle_dir = NULL;
+	}
+		
+	return handle_dir;
+}
+
+/**
+ *	depopulate_handle_proc_dir - remove proc dir entries for handle_dir
+ *	@handle_dir: the directory to depopulate
+ *
+ *	This function removes the attribute files from the handle dir.
+ */
+static void depopulate_handle_proc_dir(struct proc_dir_entry *handle_dir)
+{
+	remove_proc_entry("relayfs_path", handle_dir);
+}
+
+/**
+ *	remove_handle_proc_dir - remove proc dir for trace attributes
+ *	@handle_dir: the directory
+ *	@trace_handle: the trace handle for this trace run
+ *
+ *	This function removes a trace handle's proc dir.  It first
+ *	depopulates the dir of attribute files.
+ */
+static void remove_handle_proc_dir(struct proc_dir_entry *handle_dir, 
+				   unsigned int trace_handle)
+{
+	char handle_dir_name[22];
+
+	depopulate_handle_proc_dir(handle_dir);
+	
+	sprintf(handle_dir_name, "%u", trace_handle);
+	remove_proc_entry(handle_dir_name, ltt_proc_root_entry);
+}
+
+/*
+ * Initialization and finalization
+ */
+
+static struct rchan_callbacks control_callbacks = {
+	.ioctl = ltt_ioctl,
+};
+
+/**
+ *	create_control_channel - creates channel /mnt/relay/ltt/control
+ *
+ *	Returns channel id on success, negative otherwise.
+ */
+static int
+create_control_channel(void)
+{
+	u32 bufsize, nbufs;
+	u32 channel_flags;
+	int control;
+
+	sprintf(relay_file_name, "%s/%s", TRACE_RELAYFS_ROOT, TRACE_CONTROL_FILE);
+
+	channel_flags = RELAY_DELIVERY_PACKET | RELAY_USAGE_GLOBAL;
+	channel_flags |= RELAY_SCHEME_ANY | RELAY_TIMESTAMP_ANY;
+
+	bufsize = 4096;
+	nbufs = 4;
+
+	control = relay_open(relay_file_name,
+			     bufsize,
+			     nbufs,
+			     channel_flags,
+			     &control_callbacks,
+			     0,
+			     0,
+			     0,
+			     0,
+			     0,
+			     0,
+			     NULL,
+			     0);
+
+	return control;
+}
+
+/**
+ *	proc_read_init_ltt - procfs read callback for init attr 
+ */
+static int proc_read_init_ltt(char *page, char **start, off_t off, 
+			      int count, int *eof, void *data)
+{
+	return sprintf(page, "%d", control_channel == -1 ? 0 : 1);
+}
+
+/**
+ *	proc_write_init_ltt - procfs write callback for init attr 
+ */
+static int proc_write_init_ltt(struct file *filp, const char *buffer,
+			       unsigned long count, void *data)
+{
+	if (control_channel == -1) {
+		control_channel = create_control_channel();
+	
+		if (control_channel < 0)
+			printk("LTT control channel creation failed, errcode: %d\n", control_channel);
+		else
+			printk("LTT control channel created\n");
+	}
+
+	return 1;
+}
+
+/**
+ *	remove_control_channel - destroys channel /mnt/relay/ltt/control
+ *
+ *	Returns 0, negative otherwise.
+ */
+static int
+remove_control_channel(void)
+{
+	if (control_channel != -1)
+		return relay_close(control_channel);
+
+	return -ENODEV;
+}
+
+static int __init init_ltt(void)
+{
+	int i;
+	int err = 0;
+	struct proc_dir_entry *init_entry;
+
+	ltt_proc_root_entry = proc_mkdir("ltt", NULL);
+
+	if (ltt_proc_root_entry == NULL)
+		err = -ENOMEM;
+	else
+		ltt_proc_root_entry->owner = THIS_MODULE;
+
+	control_channel = -1;
+	
+	init_entry = create_proc_entry("init", 0666, ltt_proc_root_entry);
+	if (init_entry == NULL) {
+		err = -ENOMEM;
+		return err;
+	}
+
+	init_entry->read_proc = proc_read_init_ltt;
+	init_entry->write_proc = proc_write_init_ltt;
+	init_entry->owner = THIS_MODULE;
+
+	for (i = 0; i < NR_TRACES; i++)
+		init_trace(&current_traces[i]);
+		
+	return err;
+}
+
+static void __exit exit_ltt(void)
+{
+	remove_proc_entry("init", ltt_proc_root_entry);
+	remove_proc_entry("ltt", NULL);
+
+	remove_control_channel();
+}
+
+module_init(init_ltt)
+module_exit(exit_ltt)
+
+EXPORT_SYMBOL(ltt_set_trace_config);
+EXPORT_SYMBOL(ltt_get_trace_config);
+EXPORT_SYMBOL(ltt_create_event);
+EXPORT_SYMBOL(ltt_create_owned_event);
+EXPORT_SYMBOL(ltt_destroy_event);
+EXPORT_SYMBOL(ltt_destroy_owners_events);
+EXPORT_SYMBOL(ltt_log_std_formatted_event);
+EXPORT_SYMBOL(ltt_log_raw_event);
+EXPORT_SYMBOL(ltt_log_event);
+EXPORT_SYMBOL(ltt_flight_pause);
+EXPORT_SYMBOL(ltt_flight_unpause);
+
+MODULE_AUTHOR("Karim Yaghmour, Tom Zanussi, Bob Wisniewski")
+MODULE_DESCRIPTION("Linux Trace Toolkit kernel core") 
+MODULE_LICENSE("GPL");
Index: linux.t/kernel/ltt/ltt-core_hooks.c
===================================================================
--- linux.t.orig/kernel/ltt/ltt-core_hooks.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/ltt-core_hooks.c	2004-05-13 10:48:25.274229280 -0400
@@ -0,0 +1,932 @@
+/*
+ * drivers/trace/trace_hooks.c
+ *
+ * This file registers and arms all the instrumentation hooks that are
+ * required by Linux Trace Toolkit. It also contains the hook exit
+ * routines.
+ *
+ * Author: Vamsi Krishna S. (vamsi_krishna@in.ibm.com)
+ *         The hook exit routines are based on LTT sources.
+ */
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/fs.h>
+#include <linux/ptrace.h>
+#include <linux/bitops.h>
+#include <linux/trigevent_hooks.h>
+#include <linux/ltt.h>
+
+#include <asm/io.h>
+#include <asm/current.h>
+#include <asm/uaccess.h>
+#include <asm/bitops.h>
+#include <asm/pgtable.h>
+
+
+/*
+ * Register hook exits. LTT maintains a bit in sTracedEvents for
+ * the status of a set of similar events for eg: TRACE_IPC for
+ * a number of IPC events etc. We need to arm and disarm all
+ * the hooks that correspond to a given bit in sTracedEvents.
+ */
+
+/*
+ * Helper macro to declare hook record structs. It takes as an argument 
+ * name of the hook. If hook_name is passed in, it declares hook_rec
+ * ltt_hook_name_rec and initialises the exit routine to
+ * ltt_hook_name.
+ */
+#define DECLARE_HOOK_REC(name) \
+static struct hook_rec ltt_##name##_rec = { \
+	.hook_exit      = ltt_##name, \
+};
+
+/*
+ * Helper macros to register/unregister/arm/disarm hooks.
+ */
+#define ltt_hook_register(name) \
+	hook_exit_register(&name, &ltt_##name##_rec)
+#define ltt_hook_unregister(name) \
+	hook_exit_deregister(&ltt_##name##_rec)
+#define ltt_hook_arm(name) \
+	hook_exit_arm(&ltt_##name##_rec)
+#define ltt_hook_remove(name) \
+	hook_exit_disarm(&ltt_##name##_rec); \
+	hook_exit_deregister(&ltt_##name##_rec)
+
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+/* TRACE_SYSCALL_ENTRY */
+extern void ltt_pre_syscall(struct pt_regs *);
+static void ltt_pre_syscall_hook(struct hook *h, struct pt_regs *regs)
+{
+	ltt_pre_syscall(regs);
+}
+DECLARE_HOOK_REC(pre_syscall_hook);
+
+static int enable_pre_syscall_hooks(void)
+{
+	int rc;
+
+	ltt_pre_syscall_hook_rec.hook_exit_name = "pre_syscall";
+	if ((rc = ltt_hook_register(pre_syscall_hook)))
+		return rc;
+	
+	ltt_hook_arm(pre_syscall_hook);
+	enable_pre_syscall();
+	return rc;
+}
+
+static int disable_pre_syscall_hooks(void)
+{
+	disable_pre_syscall();
+	ltt_hook_remove(pre_syscall_hook);
+	return 0;
+}
+
+/* TRACE_SYSCALL_EXIT */
+static void ltt_post_syscall_hook(struct hook *h, struct pt_regs *regs)
+{
+	ltt_log_event(TRACE_EV_SYSCALL_EXIT, NULL);
+}
+DECLARE_HOOK_REC(post_syscall_hook);
+
+static int enable_post_syscall_hooks(void)
+{
+	int rc;
+
+	ltt_post_syscall_hook_rec.hook_exit_name = "post_syscall";
+	if ((rc = ltt_hook_register(post_syscall_hook)))
+		return rc;
+	
+	ltt_hook_arm(post_syscall_hook);
+	enable_post_syscall();
+	return rc;
+}
+
+static int disable_post_syscall_hooks(void)
+{
+	disable_post_syscall();
+	ltt_hook_remove(post_syscall_hook);
+	return 0;
+}
+#endif
+/* TRACE_TRAP_ENTRY */
+static void ltt_trap_entry_hook(struct hook *h, int trapnr, unsigned long eip, struct pt_regs *regs)
+{
+	TRACE_TRAP_ENTRY(trapnr, eip);
+}
+DECLARE_HOOK_REC(trap_entry_hook);
+
+static int enable_trap_entry_hooks(void)
+{
+	int rc;
+
+	ltt_trap_entry_hook_rec.hook_exit_name = "trap_entry";
+	if ((rc = ltt_hook_register(trap_entry_hook)))
+		return rc;
+	
+	ltt_hook_arm(trap_entry_hook);
+	return rc;
+}
+
+static int disable_trap_entry_hooks(void)
+{
+	ltt_hook_remove(trap_entry_hook);
+	return 0;
+}
+
+/* TRACE_TRAP_EXIT */
+static void ltt_trap_exit_hook(struct hook *h)
+{
+	TRACE_TRAP_EXIT();
+}
+
+DECLARE_HOOK_REC(trap_exit_hook);
+
+static int enable_trap_exit_hooks(void)
+{
+	int rc;
+	
+	ltt_trap_exit_hook_rec.hook_exit_name = "trap_exit";
+	if ((rc = ltt_hook_register(trap_exit_hook)))
+		return rc;
+	
+	ltt_hook_arm(trap_exit_hook);
+	return rc;
+}
+
+static int disable_trap_exit_hooks(void)
+{
+	ltt_hook_remove(trap_exit_hook);
+	return 0;
+}
+
+/* TRACE_IRQ_ENTRY */
+static void ltt_irq_entry_hook(struct hook *h, unsigned int irq, struct pt_regs *regs, int irq_in_kernel)
+{
+	TRACE_IRQ_ENTRY(irq, irq_in_kernel);
+}
+
+DECLARE_HOOK_REC(irq_entry_hook);
+
+static int enable_irq_entry_hooks(void)
+{
+	int rc;
+
+	ltt_irq_entry_hook_rec.hook_exit_name = "irq_entry";
+	if ((rc = ltt_hook_register(irq_entry_hook)))
+		return rc;
+	
+	ltt_hook_arm(irq_entry_hook);
+	return rc;
+}
+
+static int disable_irq_entry_hooks(void)
+{
+	ltt_hook_remove(irq_entry_hook);
+	return 0;
+}
+
+/* TRACE_IRQ_EXIT */
+static void ltt_irq_exit_hook(struct hook *h)
+{
+	TRACE_IRQ_EXIT();
+}
+
+DECLARE_HOOK_REC(irq_exit_hook);
+
+static int enable_irq_exit_hooks(void)
+{
+	int rc;
+
+	ltt_irq_exit_hook_rec.hook_exit_name = "irq_exit";
+	if ((rc = ltt_hook_register(irq_exit_hook)))
+		return rc;
+	
+	ltt_hook_arm(irq_exit_hook);
+	return rc;
+}
+
+static int disable_irq_exit_hooks(void)
+{
+	ltt_hook_remove(irq_exit_hook);
+	return 0;
+}
+
+/* TRACE_SCHEDCHANGE */
+static void ltt_sched_switch_hook(struct hook *h, struct task_struct *prev, struct task_struct *next)
+{
+	TRACE_SCHEDCHANGE(prev, next);
+}
+
+DECLARE_HOOK_REC(sched_switch_hook);
+
+static int enable_schedchange_hooks(void)
+{
+	int rc;
+	
+	ltt_sched_switch_hook_rec.hook_exit_name = "sched_switch";
+	if ((rc = ltt_hook_register(sched_switch_hook)))
+		return rc;
+	
+	ltt_hook_arm(sched_switch_hook);
+	return rc;
+}
+
+static int disable_schedchange_hooks(void)
+{
+	ltt_hook_remove(sched_switch_hook);
+	return 0;
+}
+
+
+/* TRACE_KERNEL_TIMER */
+static void ltt_kernel_timer_hook(struct hook *h, unsigned long nr)
+{
+	TRACE_EVENT(TRACE_EV_KERNEL_TIMER, NULL);
+}
+
+DECLARE_HOOK_REC(kernel_timer_hook);
+
+static int enable_kernel_timer_hooks(void)
+{
+	int rc;
+
+	ltt_kernel_timer_hook_rec.hook_exit_name = "kernel_timer";
+	if ((rc = ltt_hook_register(kernel_timer_hook)))
+		return rc;
+	
+	ltt_hook_arm(kernel_timer_hook);
+	return rc;
+}
+
+static int disable_kernel_timer_hooks(void)
+{
+	ltt_hook_remove(kernel_timer_hook);
+	return 0;
+}
+
+static void ltt_softirq_hook(struct hook *h, int index)
+{
+	TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_SOFT_IRQ, index);
+}
+static void ltt_tasklet_action_hook(struct hook *h, unsigned long fn)
+{
+	TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_TASKLET_ACTION, fn);
+}
+static void ltt_tasklet_hi_action_hook(struct hook *h, unsigned long fn)
+{
+	TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_TASKLET_HI_ACTION, fn);
+}
+
+DECLARE_HOOK_REC(softirq_hook);
+DECLARE_HOOK_REC(tasklet_action_hook);
+DECLARE_HOOK_REC(tasklet_hi_action_hook);
+
+static int enable_softirq_hooks(void)
+{
+	int rc;
+
+	
+	ltt_softirq_hook_rec.hook_exit_name = "ltt_softirq";
+	if ((rc = ltt_hook_register(softirq_hook)))
+		goto err;
+	ltt_tasklet_action_hook_rec.hook_exit_name = "tasklet_action";
+	if ((rc = ltt_hook_register(tasklet_action_hook)))
+		goto err1;
+	ltt_tasklet_hi_action_hook_rec.hook_exit_name = "tasklet_hi_action";
+	if ((rc = ltt_hook_register(tasklet_hi_action_hook)))
+		goto err2;
+	
+	ltt_hook_arm(softirq_hook);
+	ltt_hook_arm(tasklet_action_hook);
+	ltt_hook_arm(tasklet_hi_action_hook);
+	return rc;
+
+err2:	ltt_hook_unregister(tasklet_action_hook);
+err1:	ltt_hook_unregister(softirq_hook);
+err:	return rc;
+
+}
+
+static int disable_softirq_hooks(void)
+{
+	ltt_hook_remove(softirq_hook);
+	ltt_hook_remove(tasklet_action_hook);
+	ltt_hook_remove(tasklet_hi_action_hook);
+	return 0;
+}
+
+/* TRACE_PROCESS */
+static void ltt_kthread_hook(struct hook *h, unsigned int ret, unsigned int fn)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_KTHREAD, ret, fn);
+}
+static void ltt_process_exit_hook(struct hook *h, pid_t pid)
+{
+	TRACE_PROCESS_EXIT(0, 0);
+}
+static void ltt_process_wait_hook(struct hook *h, pid_t pid)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_WAIT, pid, 0);
+}
+static void ltt_fork_hook(struct hook *h, unsigned long clone_flags, struct task_struct *p, int ret)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_FORK, ret, 0);
+}
+static void ltt_process_wakeup_hook(struct hook *h, pid_t pid, unsigned long state)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_WAKEUP, pid, state);
+}
+static void ltt_signal_hook(struct hook *h, int sig, pid_t pid)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_SIGNAL, sig, pid);
+}
+
+DECLARE_HOOK_REC(kthread_hook);
+DECLARE_HOOK_REC(process_exit_hook);
+DECLARE_HOOK_REC(process_wait_hook);
+DECLARE_HOOK_REC(fork_hook);
+DECLARE_HOOK_REC(process_wakeup_hook);
+DECLARE_HOOK_REC(signal_hook);
+
+static int enable_process_hooks(void)
+{
+	int rc;
+
+	ltt_kthread_hook_rec.hook_exit_name = "ltt_kthread";
+	if ((rc = ltt_hook_register(kthread_hook)))
+		goto err;
+	ltt_process_exit_hook_rec.hook_exit_name = "ltt_process_exit";
+	if ((rc = ltt_hook_register(process_exit_hook)))
+		goto err1;
+	ltt_process_wait_hook_rec.hook_exit_name = "ltt_process_wait";
+	if ((rc = ltt_hook_register(process_wait_hook)))
+		goto err2;
+	ltt_fork_hook_rec.hook_exit_name = "ltt_fork";
+	if ((rc = ltt_hook_register(fork_hook)))
+		goto err3;
+	ltt_signal_hook_rec.hook_exit_name = "ltt_signal";
+	if ((rc = ltt_hook_register(signal_hook)))
+		goto err4;
+	ltt_process_wakeup_hook_rec.hook_exit_name = "ltt_process_wakeup";
+	if ((rc = ltt_hook_register(process_wakeup_hook)))
+		goto err5;
+	
+	ltt_hook_arm(kthread_hook);
+	ltt_hook_arm(process_exit_hook);
+	ltt_hook_arm(process_wait_hook);
+	ltt_hook_arm(fork_hook);
+	ltt_hook_arm(signal_hook);
+	ltt_hook_arm(process_wakeup_hook);
+	return rc;
+
+err5:	ltt_hook_unregister(signal_hook);
+err4:	ltt_hook_unregister(fork_hook);
+err3:	ltt_hook_unregister(process_wait_hook);
+err2:	ltt_hook_unregister(process_exit_hook);
+err1:	ltt_hook_unregister(kthread_hook);
+err:	return rc;
+
+}
+
+static int disable_process_hooks(void)
+{
+	ltt_hook_remove(kthread_hook);
+	ltt_hook_remove(process_exit_hook);
+	ltt_hook_remove(process_wait_hook);
+	ltt_hook_remove(fork_hook);
+	ltt_hook_remove(signal_hook);
+	ltt_hook_remove(process_wakeup_hook);
+	return 0;
+}
+
+/* TRACE_FILE_SYSTEM */
+static void ltt_buf_wait_start_hook(struct hook *h, struct buffer_head *bh)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_BUF_WAIT_START, 0, 0, NULL);
+}
+static void ltt_buf_wait_end_hook(struct hook *h, struct buffer_head *bh)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_BUF_WAIT_END, 0, 0, NULL);
+}
+static void ltt_exec_hook(struct hook *h, int len, char *name, struct pt_regs *regs)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_EXEC, 0, len, name);
+}
+static void ltt_ioctl_hook(struct hook *h, unsigned int fd, unsigned int cmd)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_IOCTL, fd, cmd, NULL);
+}
+static void ltt_open_hook(struct hook *h, unsigned int fd, unsigned int len, char *name)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_OPEN, fd, len, name);
+}
+static void ltt_close_hook(struct hook *h, unsigned int fd)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_CLOSE, fd, 0, NULL);
+}
+static void ltt_lseek_hook(struct hook *h, unsigned int fd, off_t offset)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SEEK, fd, offset, NULL);
+}
+static void ltt_llseek_hook(struct hook *h, unsigned int fd, loff_t offset)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SEEK, fd, offset, NULL);
+}
+static void ltt_read_hook(struct hook *h, unsigned int fd, size_t count)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_READ, fd, count, NULL);
+}
+static void ltt_write_hook(struct hook *h, unsigned int fd, size_t count)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_WRITE, fd, count, NULL);
+}
+static void ltt_select_hook(struct hook *h, unsigned int fd, long timeout)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SELECT, fd, timeout, NULL);
+}
+static void ltt_poll_hook(struct hook *h, unsigned int fd)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_POLL, fd, 0, NULL);
+}
+
+DECLARE_HOOK_REC(buf_wait_start_hook);
+DECLARE_HOOK_REC(buf_wait_end_hook);
+DECLARE_HOOK_REC(exec_hook);
+DECLARE_HOOK_REC(ioctl_hook);
+DECLARE_HOOK_REC(open_hook);
+DECLARE_HOOK_REC(close_hook);
+DECLARE_HOOK_REC(lseek_hook);
+DECLARE_HOOK_REC(llseek_hook);
+DECLARE_HOOK_REC(read_hook);
+DECLARE_HOOK_REC(write_hook);
+DECLARE_HOOK_REC(select_hook);
+DECLARE_HOOK_REC(poll_hook);
+
+static int enable_fs_hooks(void)
+{
+	int rc;
+
+	ltt_buf_wait_start_hook_rec.hook_exit_name = "ltt_buf_wait_start";
+	if ((rc = ltt_hook_register(buf_wait_start_hook)))
+		goto err;
+	ltt_buf_wait_end_hook_rec.hook_exit_name = "ltt_buf_wait_end";
+	if ((rc = ltt_hook_register(buf_wait_end_hook)))
+		goto err1;
+	ltt_exec_hook_rec.hook_exit_name = "ltt_exec";
+	if ((rc = ltt_hook_register(exec_hook)))
+		goto err2;
+	ltt_ioctl_hook_rec.hook_exit_name = "ltt_ioctl";
+	if ((rc = ltt_hook_register(ioctl_hook)))
+		goto err3;
+	ltt_open_hook_rec.hook_exit_name = "ltt_open";
+	if ((rc = ltt_hook_register(open_hook)))
+		goto err4;
+	ltt_close_hook_rec.hook_exit_name = "ltt_close";
+	if ((rc = ltt_hook_register(close_hook)))
+		goto err5;
+	ltt_lseek_hook_rec.hook_exit_name = "ltt_lseek";
+	if ((rc = ltt_hook_register(lseek_hook)))
+		goto err6;
+	ltt_llseek_hook_rec.hook_exit_name = "ltt_llseek";
+	if ((rc = ltt_hook_register(llseek_hook)))
+		goto err7;
+	ltt_read_hook_rec.hook_exit_name = "ltt_read";
+	if ((rc = ltt_hook_register(read_hook)))
+		goto err8;
+	ltt_write_hook_rec.hook_exit_name = "ltt_write";
+	if ((rc = ltt_hook_register(write_hook)))
+		goto err9;
+	ltt_select_hook_rec.hook_exit_name = "ltt_select";
+	if ((rc = ltt_hook_register(select_hook)))
+		goto err10;
+	ltt_poll_hook_rec.hook_exit_name = "ltt_poll";
+	if ((rc = ltt_hook_register(poll_hook)))
+		goto err11;
+	
+	ltt_hook_arm(buf_wait_start_hook);
+	ltt_hook_arm(buf_wait_end_hook);
+	ltt_hook_arm(exec_hook);
+	ltt_hook_arm(ioctl_hook);
+	ltt_hook_arm(open_hook);
+	ltt_hook_arm(close_hook);
+	ltt_hook_arm(lseek_hook);
+	ltt_hook_arm(llseek_hook);
+	ltt_hook_arm(read_hook);
+	ltt_hook_arm(write_hook);
+	ltt_hook_arm(select_hook);
+	ltt_hook_arm(poll_hook);
+	return rc;
+
+err11:	ltt_hook_unregister(select_hook);
+err10:	ltt_hook_unregister(write_hook);
+err9:	ltt_hook_unregister(read_hook);
+err8:	ltt_hook_unregister(llseek_hook);
+err7:	ltt_hook_unregister(lseek_hook);
+err6:	ltt_hook_unregister(close_hook);
+err5:	ltt_hook_unregister(open_hook);
+err4:	ltt_hook_unregister(ioctl_hook);
+err3:	ltt_hook_unregister(exec_hook);
+err2:	ltt_hook_unregister(buf_wait_end_hook);
+err1:	ltt_hook_unregister(buf_wait_start_hook);
+err:	return rc;
+
+}
+
+static int disable_fs_hooks(void)
+{
+	ltt_hook_remove(buf_wait_start_hook);
+	ltt_hook_remove(buf_wait_end_hook);
+	ltt_hook_remove(exec_hook);
+	ltt_hook_remove(ioctl_hook);
+	ltt_hook_remove(open_hook);
+	ltt_hook_remove(close_hook);
+	ltt_hook_remove(lseek_hook);
+	ltt_hook_remove(llseek_hook);
+	ltt_hook_remove(read_hook);
+	ltt_hook_remove(write_hook);
+	ltt_hook_remove(select_hook);
+	ltt_hook_remove(poll_hook);
+	return 0;
+}
+
+/* TRACE_TIMER */
+static void ltt_timer_expired_hook(struct hook *h, struct task_struct *p)
+{
+	TRACE_TIMER(TRACE_EV_TIMER_EXPIRED, 0, 0, 0);
+}
+static void ltt_setitimer_hook(struct hook *h, int which, unsigned long interval, unsigned long value)
+{
+	TRACE_TIMER(TRACE_EV_TIMER_SETITIMER, which, interval, value);
+}
+static void ltt_settimeout_hook(struct hook *h, unsigned long timeout)
+{
+	TRACE_TIMER(TRACE_EV_TIMER_SETTIMEOUT, 0, timeout, 0);
+}
+
+DECLARE_HOOK_REC(setitimer_hook);
+DECLARE_HOOK_REC(timer_expired_hook);
+DECLARE_HOOK_REC(settimeout_hook);
+
+static int enable_timer_hooks(void)
+{
+	int rc;
+
+	ltt_setitimer_hook_rec.hook_exit_name = "ltt_setitimer";
+	if ((rc = ltt_hook_register(setitimer_hook)))
+		goto err;
+	ltt_timer_expired_hook_rec.hook_exit_name = "ltt_timer_expired";
+	if ((rc = ltt_hook_register(timer_expired_hook)))
+		goto err1;
+	ltt_settimeout_hook_rec.hook_exit_name = "ltt_settimeout";
+	if ((rc = ltt_hook_register(settimeout_hook)))
+		goto err2;
+	
+	ltt_hook_arm(setitimer_hook);
+	ltt_hook_arm(timer_expired_hook);
+	ltt_hook_arm(settimeout_hook);
+	return rc;
+
+err2:	ltt_hook_unregister(timer_expired_hook);
+err1:	ltt_hook_unregister(setitimer_hook);
+err:	return rc;
+
+}
+
+static int disable_timer_hooks(void)
+{
+	ltt_hook_remove(setitimer_hook);
+	ltt_hook_remove(timer_expired_hook);
+	ltt_hook_remove(settimeout_hook);
+	return 0;
+}
+
+
+/* TRACE_MEMORY */
+static void ltt_mm_page_alloc_hook(struct hook *h, unsigned int order)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_ALLOC, order);
+}
+static void ltt_mm_page_free_hook(struct hook *h, unsigned int order)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_FREE, order);
+}
+static void ltt_mm_swap_in_hook(struct hook *h, unsigned long address)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_SWAP_IN, address);
+}
+static void ltt_mm_swap_out_hook(struct hook *h, struct page *page)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_SWAP_OUT, ((unsigned long) page));
+}
+static void ltt_page_wait_start_hook(struct hook *h, struct page *page)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_WAIT_START, 0);
+}
+static void ltt_page_wait_end_hook(struct hook *h, struct page *page)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_WAIT_END, 0);
+}
+
+DECLARE_HOOK_REC(page_wait_start_hook);
+DECLARE_HOOK_REC(page_wait_end_hook);
+DECLARE_HOOK_REC(mm_page_free_hook);
+DECLARE_HOOK_REC(mm_page_alloc_hook);
+DECLARE_HOOK_REC(mm_swap_in_hook);
+DECLARE_HOOK_REC(mm_swap_out_hook);
+
+static int enable_mm_hooks(void)
+{
+	int rc;
+
+	ltt_page_wait_start_hook_rec.hook_exit_name = "ltt_page_wait_start";
+	if ((rc = ltt_hook_register(page_wait_start_hook)))
+		goto err;
+	ltt_page_wait_end_hook_rec.hook_exit_name = "ltt_page_wait_end";
+	if ((rc = ltt_hook_register(page_wait_end_hook)))
+		goto err1;
+	ltt_mm_page_free_hook_rec.hook_exit_name = "ltt_mm_page_free";
+	if ((rc = ltt_hook_register(mm_page_free_hook)))
+		goto err2;
+	ltt_mm_page_alloc_hook_rec.hook_exit_name = "ltt_mm_page_alloc";
+	if ((rc = ltt_hook_register(mm_page_alloc_hook)))
+		goto err3;
+	ltt_mm_swap_in_hook_rec.hook_exit_name = "ltt_mm_swap_in";
+	if ((rc = ltt_hook_register(mm_swap_in_hook)))
+		goto err4;
+	ltt_mm_swap_out_hook_rec.hook_exit_name = "ltt_mm_swap_out";
+	if ((rc = ltt_hook_register(mm_swap_out_hook)))
+		goto err5;
+	
+	ltt_hook_arm(page_wait_start_hook);
+	ltt_hook_arm(page_wait_end_hook);
+	ltt_hook_arm(mm_page_free_hook);
+	ltt_hook_arm(mm_page_alloc_hook);
+	ltt_hook_arm(mm_swap_in_hook);
+	ltt_hook_arm(mm_swap_out_hook);
+	return rc;
+
+err5:	ltt_hook_unregister(mm_swap_in_hook);
+err4:	ltt_hook_unregister(mm_page_alloc_hook);
+err3:	ltt_hook_unregister(mm_page_free_hook);
+err2:	ltt_hook_unregister(page_wait_end_hook);
+err1:	ltt_hook_unregister(page_wait_start_hook);
+err:	return rc;
+
+}
+
+static int disable_mm_hooks(void)
+{
+	ltt_hook_remove(page_wait_start_hook);
+	ltt_hook_remove(page_wait_end_hook);
+	ltt_hook_remove(mm_page_free_hook);
+	ltt_hook_remove(mm_page_alloc_hook);
+	ltt_hook_remove(mm_swap_in_hook);
+	ltt_hook_remove(mm_swap_out_hook);
+	return 0;
+}
+/* TRACE_SOCKET */
+static void ltt_sk_send_hook(struct hook *h, int type, int size)
+{
+	TRACE_SOCKET(TRACE_EV_SOCKET_SEND, type, size);
+}
+
+static void ltt_sk_receive_hook(struct hook *h, int type, int size)
+{
+	TRACE_SOCKET(TRACE_EV_SOCKET_RECEIVE, type, size);
+}
+
+static void ltt_sk_create_hook(struct hook *h, int retval, int type)
+{
+	TRACE_SOCKET(TRACE_EV_SOCKET_CREATE, retval, type);
+}
+
+static void ltt_sk_call_hook(struct hook *h, int call, unsigned long a0)
+{
+	TRACE_SOCKET(TRACE_EV_SOCKET_CALL, call, a0);
+}
+
+DECLARE_HOOK_REC(sk_send_hook);
+DECLARE_HOOK_REC(sk_receive_hook);
+DECLARE_HOOK_REC(sk_create_hook);
+DECLARE_HOOK_REC(sk_call_hook);
+
+static int enable_socket_hooks(void)
+{
+	int rc;
+
+	ltt_sk_send_hook_rec.hook_exit_name = "ltt_sk_send";
+	if ((rc = ltt_hook_register(sk_send_hook)))
+		goto err;
+	ltt_sk_receive_hook_rec.hook_exit_name = "ltt_sk_receive";
+	if ((rc = ltt_hook_register(sk_receive_hook)))
+		goto err1;
+	ltt_sk_create_hook_rec.hook_exit_name = "ltt_sk_create";
+	if ((rc = ltt_hook_register(sk_create_hook)))
+		goto err2;
+	ltt_sk_call_hook_rec.hook_exit_name = "ltt_sk_call";
+	if ((rc = ltt_hook_register(sk_call_hook)))
+		goto err3;
+	
+	ltt_hook_arm(sk_send_hook);
+	ltt_hook_arm(sk_receive_hook);
+	ltt_hook_arm(sk_create_hook);
+	ltt_hook_arm(sk_call_hook);
+	return rc;
+
+err3:	ltt_hook_unregister(sk_create_hook);
+err2:	ltt_hook_unregister(sk_receive_hook);
+err1:	ltt_hook_unregister(sk_send_hook);
+err:	return rc;
+
+}
+
+static int disable_socket_hooks(void)
+{
+	ltt_hook_remove(sk_send_hook);
+	ltt_hook_remove(sk_receive_hook);
+	ltt_hook_remove(sk_create_hook);
+	ltt_hook_remove(sk_call_hook);
+	return 0;
+}
+
+/* TRACE_IPC */
+static void ltt_ipc_call_hook(struct hook *h, unsigned int call, int first)
+{
+	TRACE_IPC(TRACE_EV_IPC_CALL, call, first);
+}
+static void ltt_ipc_msg_create_hook(struct hook *h, int err, int flag)
+{
+	TRACE_IPC(TRACE_EV_IPC_MSG_CREATE, err, flag);
+}
+static void ltt_ipc_sem_create_hook(struct hook *h, int err, int flag)
+{
+	TRACE_IPC(TRACE_EV_IPC_SEM_CREATE, err, flag);
+}
+static void ltt_ipc_shm_create_hook(struct hook *h, int err, int flag)
+{
+	TRACE_IPC(TRACE_EV_IPC_SHM_CREATE, err, flag);
+}
+
+DECLARE_HOOK_REC(ipc_call_hook);
+DECLARE_HOOK_REC(ipc_msg_create_hook);
+DECLARE_HOOK_REC(ipc_sem_create_hook);
+DECLARE_HOOK_REC(ipc_shm_create_hook);
+
+static int enable_ipc_hooks(void)
+{
+	int rc;
+
+	ltt_ipc_call_hook_rec.hook_exit_name = "ltt_ipc_call";
+	if ((rc = ltt_hook_register(ipc_call_hook)))
+		goto err;
+	ltt_ipc_msg_create_hook_rec.hook_exit_name = "ltt_ipc_msg_create";
+	if ((rc = ltt_hook_register(ipc_msg_create_hook)))
+		goto err1;
+	ltt_ipc_sem_create_hook_rec.hook_exit_name = "ltt_ipc_sem_create";
+	if ((rc = ltt_hook_register(ipc_sem_create_hook)))
+		goto err2;
+	ltt_ipc_shm_create_hook_rec.hook_exit_name = "ltt_ipc_shm_create";
+	if ((rc = ltt_hook_register(ipc_shm_create_hook)))
+		goto err3;
+	
+	ltt_hook_arm(ipc_call_hook);
+	ltt_hook_arm(ipc_msg_create_hook);
+	ltt_hook_arm(ipc_sem_create_hook);
+	ltt_hook_arm(ipc_shm_create_hook);
+	return rc;
+
+err3:	ltt_hook_unregister(ipc_sem_create_hook);
+err2:	ltt_hook_unregister(ipc_msg_create_hook);
+err1:	ltt_hook_unregister(ipc_call_hook);
+err:	return rc;
+
+}
+
+static int disable_ipc_hooks(void)
+{
+	ltt_hook_remove(ipc_call_hook);
+	ltt_hook_remove(ipc_msg_create_hook);
+	ltt_hook_remove(ipc_sem_create_hook);
+	ltt_hook_remove(ipc_shm_create_hook);
+	return 0;
+}
+
+/* TRACE_NETWORK */
+static void ltt_net_pkt_out_hook(struct hook *h, unsigned short protocol)
+{
+	TRACE_NETWORK(TRACE_EV_NETWORK_PACKET_OUT, protocol);
+}
+
+static void ltt_net_pkt_in_hook(struct hook *h, unsigned short protocol)
+{
+	TRACE_NETWORK(TRACE_EV_NETWORK_PACKET_IN, protocol);
+}
+
+DECLARE_HOOK_REC(net_pkt_out_hook);
+DECLARE_HOOK_REC(net_pkt_in_hook);
+
+static int enable_net_hooks(void)
+{
+	int rc;
+
+	ltt_net_pkt_out_hook_rec.hook_exit_name = "ltt_net_pkt_out";
+	if ((rc = ltt_hook_register(net_pkt_out_hook)))
+		goto err;
+	ltt_net_pkt_in_hook_rec.hook_exit_name = "ltt_net_pkt_in";
+	if ((rc = ltt_hook_register(net_pkt_in_hook)))
+		goto err1;
+	
+	ltt_hook_arm(net_pkt_out_hook);
+	ltt_hook_arm(net_pkt_in_hook);
+	return rc;
+
+err1:	ltt_hook_unregister(net_pkt_out_hook);
+err:	return rc;
+
+}
+
+static int disable_net_hooks(void)
+{
+	ltt_hook_remove(net_pkt_out_hook);
+	ltt_hook_remove(net_pkt_in_hook);
+	return 0;
+}
+
+typedef int (*enable_fn_t)(void);
+
+static enable_fn_t enable[TRACE_EV_MAX + 1][2] =
+{
+	{ NULL, NULL},							/* TRACE_START */
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+	{ disable_pre_syscall_hooks, enable_pre_syscall_hooks},		/* TRACE_SYSCALL_ENTRY */
+	{ disable_post_syscall_hooks, enable_post_syscall_hooks},	/* TRACE_SYSCALL_EXIT */
+#endif
+	{ disable_trap_entry_hooks, enable_trap_entry_hooks},		/* TRACE_TRAP_ENTRY */
+	{ disable_trap_exit_hooks, enable_trap_exit_hooks},		/* TRACE_TRAP_EXIT */
+	{ disable_irq_entry_hooks, enable_irq_entry_hooks},		/* TRACE_IRQ_ENTRY */
+	{ disable_irq_exit_hooks, enable_irq_exit_hooks},		/* TRACE_IRQ_EXIT */
+	{ disable_schedchange_hooks, enable_schedchange_hooks},		/* TRACE_SCHEDCHANGE */
+	{ disable_kernel_timer_hooks, enable_kernel_timer_hooks},	/* TRACE_KERNEL_TIMER */
+	{ disable_softirq_hooks, enable_softirq_hooks},			/* TRACE_SOFT_IRQ */
+	{ disable_process_hooks, enable_process_hooks},			/* TRACE_PROCESS */
+	{ disable_fs_hooks, enable_fs_hooks},				/* TRACE_FILE_SYSTEM */
+	{ disable_timer_hooks, enable_timer_hooks},			/* TRACE_MEMORY */
+	{ disable_mm_hooks, enable_mm_hooks},				/* TRACE_MEMORY */
+	{ disable_socket_hooks, enable_socket_hooks},			/* TRACE_SOCKET */
+	{ disable_ipc_hooks, enable_ipc_hooks},				/* TRACE_IPC */
+	{ disable_net_hooks, enable_net_hooks},				/* TRACE_NETWORK */
+	{ NULL, NULL},							/* TRACE_BUFFER_START */
+	{ NULL, NULL},							/* TRACE_BUFFER_END */
+	{ NULL, NULL},							/* TRACE_NEW_EVENT */
+	{ NULL, NULL},							/* TRACE_CUSTOM */
+	{ NULL, NULL}							/* TRACE_CHANGE_MASK */
+};
+
+static trace_event_mask prev_mask;
+void change_traced_events(trace_event_mask *mask)
+{
+	int i = 0;
+	enable_fn_t fn;
+	
+	trace_event_mask changes;	/* zero bit indicates change */
+
+	if (!mask) {
+		/* disable all existing hooks, tracing is being stopped */
+		changes = ~prev_mask;
+		memset(&prev_mask, 0, sizeof(prev_mask));
+		mask = &prev_mask;
+	} else {
+		changes = ~(prev_mask ^ (*mask));
+		memcpy(&prev_mask, mask, sizeof(*mask));
+	}
+
+repeat:
+	i = find_next_zero_bit((const unsigned long *)&changes, sizeof(changes), i);
+	if (i <= TRACE_EV_MAX) {
+		if (test_bit(i, (const unsigned long *)mask)) {
+			fn = enable[i][1];
+		} else {
+			fn = enable[i][0];
+		}
+		if (fn) {
+			fn();
+		}
+		i++;
+		goto repeat;
+	}
+
+#if defined(CONFIG_SMP) || defined(CONFIG_PREEMPT)
+	/*
+	 * Wait to ensure that no other processor (or process, for
+	 * CONFIG_PREEMPT) could possibly be inside any of our hook
+	 * exit functions.
+	 *
+	 * sychornize_kernel is available on UL kernels. We need an
+	 * equivalent on other 2.4 kernels.
+	 */
+	synchronize_kernel();
+#endif
+	return;
+}
Index: linux.t/kernel/ltt/mips_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/mips_syscall.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/mips_syscall.c	2004-05-13 10:48:25.275229128 -0400
@@ -0,0 +1,77 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* mips */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+	unsigned long       addr;
+	int                 depth = 0;
+	unsigned long       end_code;
+	unsigned long       lower_bound;
+	int                 seek_depth;
+	unsigned long       *stack;
+	unsigned long       start_code;
+	unsigned long       *start_stack;
+	trace_syscall_entry trace_syscall_event;
+	unsigned long       upper_bound;
+	int                 use_bounds;
+	int                 use_depth;
+
+	/* syscall_id will be negative for SVR4, IRIX5, BSD43, and POSIX
+	 * syscalls -- these are not supported at this point by LTT
+	 */
+	trace_syscall_event.syscall_id = (uint8_t) (regs->regs[2] - __NR_Linux);
+
+	trace_syscall_event.address  = regs->cp0_epc;
+
+	if (!user_mode(regs))
+		goto trace_syscall_end;
+
+	if (ltt_get_trace_config(&use_depth,
+			     &use_bounds,
+			     &seek_depth,
+			     (void*)&lower_bound,
+			     (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	/* Heuristic that might work:
+	 * (BUT DOESN'T WORK for any of the cases I tested...) zzz
+	 * Search through stack until a value is found that is within the
+	 * range start_code .. end_code.  (This is looking for a return
+	 * pointer to where a shared library was called from.)  If a stack
+	 * variable contains a valid code address then an incorrect
+	 * result will be generated.
+	 */
+	if ((use_depth == 1) || (use_bounds == 1)) {
+		stack       = (unsigned long*) regs->regs[29];
+		end_code    = current->mm->end_code;
+		start_code  = current->mm->start_code;
+		start_stack = (unsigned long *)current->mm->start_stack;
+
+		while ((stack <= start_stack) && (!__get_user(addr, stack))) {
+			if ((addr > start_code) && (addr < end_code)) {
+				if (((use_depth  == 1) && (depth == seek_depth)) ||
+				    ((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound))) {
+					trace_syscall_event.address = addr;
+					goto trace_syscall_end;
+				} else {
+					depth++;
+				}
+			}
+		stack++;
+		}
+	}
+
+trace_syscall_end:
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/ppc_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/ppc_syscall.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/ppc_syscall.c	2004-05-13 10:48:25.276228976 -0400
@@ -0,0 +1,88 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* ppc */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+        int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+        int                 seek_depth;
+        unsigned long       lower_bound;
+        unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+        /* Set the syscall ID */
+	trace_syscall_event.syscall_id = (uint8_t) regs->gpr[0];
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = instruction_pointer(regs);
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!user_mode(regs))
+	  /* Don't go digining anywhere */
+	  goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(ltt_get_trace_config(&use_depth,
+			    &use_bounds,
+			    &seek_depth,
+			    (void*)&lower_bound,
+			    (void*)&upper_bound) < 0)
+	  goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	  {
+	  /* Start at the top of the stack (bottom address since stacks grow downward) */
+	  stack = (unsigned long*) regs->gpr[1];
+
+	  /* Skip over first stack frame as the return address isn't valid */
+	  if(get_user(addr, stack))
+	    goto trace_syscall_end;
+	  stack = (unsigned long*) addr;
+
+	  /* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+	  while(!get_user(addr, stack + 1)) /* "stack + 1", since this is where the IP is */
+	    {
+	    /* Does this LOOK LIKE an address in the program */
+	    if((addr > current->mm->start_code)
+             &&(addr < current->mm->end_code))
+	      {
+	      /* Does this address fit the description */
+	      if(((use_depth == 1) && (depth == seek_depth))
+               ||((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound)))
+		{
+		/* Set the address */
+		trace_syscall_event.address = addr;
+
+		/* We're done */
+		goto trace_syscall_end;
+		}
+	      else
+		/* We're one depth more */
+		depth++;
+	      }
+	    /* Go on to the next address */
+	    if(get_user(addr, stack))
+	      goto trace_syscall_end;
+	    stack = (unsigned long*) addr;
+	    }
+	  }
+
+trace_syscall_end:
+	/* Trace the event */
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/s390_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/s390_syscall.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/s390_syscall.c	2004-05-13 10:48:25.278228672 -0400
@@ -0,0 +1,92 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* s390 */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{                                                              
+	int		    use_depth;	                 
+        int                 use_bounds;                        
+        int                 depth = 0;                         
+        int                 seek_depth;                        
+        unsigned long       lower_bound;                       
+        unsigned long       upper_bound;                       
+        unsigned long       addr;                              
+        unsigned long*      stack;
+        unsigned long       temp_stack;
+        trace_syscall_entry trace_syscall_event;               
+        /* Set the syscall ID                               */ 
+        /* Register 8 is setup just prior to the call       */ 
+        /* This instruction is just following linkage       */ 
+        /* so it's ok.  If moved and chance of R8 being     */ 
+        /* clobbered, would need to dig it out of the stack */ 
+        __asm__ volatile(                                      
+        "  stc  8,%0\n\t"                                      
+        : "=m" (trace_syscall_event.syscall_id));              
+        /* get the psw address */                              
+        trace_syscall_event.address  = regs->psw.addr;         
+        /* and off the hi-order bit */                                          
+        trace_syscall_event.address &= PSW_ADDR_INSN;                           
+        if(!(user_mode(regs))) /* if kernel mode, return */                     
+           goto trace_syscall_end;                                              
+        /* Get the trace configuration - if none, return */                     
+        if(ltt_get_trace_config(&use_depth,                                         
+                            &use_bounds,                                        
+                            &seek_depth,                                        
+                            (void*)&lower_bound,                                
+                            (void*)&upper_bound) < 0)                           
+          goto trace_syscall_end;                                               
+        /* Do we have to search for an instruction pointer address range */     
+        if((use_depth == 1) || (use_bounds == 1))                               
+        {                                                                       
+          /* Start at the top of the stack */                                   
+          /* stack pointer is register 15 */                                    
+          stack = (unsigned long*) regs->gprs[15]; /* stack pointer */      
+          /* Keep on going until we reach the end of the process' stack limit */
+          do
+          {
+            get_user(addr,stack+14);  /* get the program address +0x38 */ 
+            /* and off the hi-order bit */
+            addr &= PSW_ADDR_INSN;                                
+            /* Does this LOOK LIKE an address in the program */
+            if ((addr > current->mm->start_code)               
+               &&(addr < current->mm->end_code))               
+            { 
+              /* Does this address fit the description */      
+              if(((use_depth == 1) && (depth == seek_depth))   
+                ||((use_bounds == 1) && (addr > lower_bound)   
+                && (addr < upper_bound)))
+                {
+                  /* Set the address */   
+                  trace_syscall_event.address = addr; 
+                  /* We're done */                             
+                  goto trace_syscall_end;                      
+                }                                              
+              else                                             
+                /* We're one depth more */                     
+                depth++; 
+            }
+            /* Go on to the next address */
+            get_user(temp_stack,stack); /* get contents of stack */
+            temp_stack &= PSW_ADDR_INSN; /* and off hi order bit */
+            stack = (unsigned long *)temp_stack; /* move into stack */
+            /* stack may or may not go to zero when end hit               */
+            /* using 0x7fffffff-_STK_LIM to validate that the address is  */
+            /* within the range of a valid stack address                  */
+            /* If outside that range, exit the loop, stack end must have  */
+            /* been hit.                                                  */
+          } while (stack >= (unsigned long *)(0x7fffffff-_STK_LIM));
+        }                                                         
+trace_syscall_end:                                                
+        /* Trace the event */                                     
+        ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}                                                                 
Index: linux.t/kernel/ltt/sh_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/sh_syscall.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/ltt/sh_syscall.c	2004-05-13 10:48:25.278228672 -0400
@@ -0,0 +1,79 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* sh */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+	int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+	int                 seek_depth;
+	unsigned long       lower_bound;
+	unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+	/* Set the syscall ID */
+	trace_syscall_event.syscall_id = (uint8_t) regs->regs[REG_REG0+3];
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = regs->pc;
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!user_mode(regs))
+		/* Don't go digining anywhere */
+		goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(ltt_get_trace_config(&use_depth, &use_bounds, &seek_depth,
+	   (void*)&lower_bound, (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	{
+		/* Start at the top of the stack (bottom address since stacks grow downward) */
+		stack = (unsigned long*) regs->regs[REG_REG15];
+
+		/* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+		while(!get_user(addr, stack))
+		{
+			/* Does this LOOK LIKE an address in the program */
+			/* TODO: does this work with shared libraries?? - Greg Banks */
+			if((addr > current->mm->start_code) &&(addr < current->mm->end_code))
+			{
+				/* Does this address fit the description */
+				if(((use_depth == 1) && (depth == seek_depth))
+				   ||((use_bounds == 1) && (addr > lower_bound)
+				   && (addr < upper_bound)))
+				{
+					/* Set the address */
+					trace_syscall_event.address = addr;
+
+					/* We're done */
+					goto trace_syscall_end;
+				}
+				else
+					/* We're one depth more */
+					depth++;
+			}
+			/* Go on to the next address */
+			stack++;
+		}
+	}
+
+trace_syscall_end:
+	/* Trace the event */
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/module.c
===================================================================
--- linux.t.orig/kernel/module.c	2004-05-13 10:45:19.940404304 -0400
+++ linux.t/kernel/module.c	2004-05-13 10:48:25.282228064 -0400
@@ -35,6 +35,7 @@
 #include <linux/notifier.h>
 #include <linux/stop_machine.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/uaccess.h>
 #include <asm/semaphore.h>
 #include <asm/pgalloc.h>
@@ -951,6 +952,7 @@
 /* Free a module, remove from lists, etc (must hold module mutex). */
 static void free_module(struct module *mod)
 {
+	TRIG_EVENT(free_module_hook, mod);
 	/* Delete from various lists */
 	spin_lock_irq(&modlist_lock);
 	list_del(&mod->list);
@@ -1646,6 +1648,7 @@
 	notifier_call_chain(&module_notify_list, MODULE_STATE_COMING, mod);
 	up(&notify_mutex);
 
+	TRIG_EVENT(module_init_hook, mod);
 	/* Start the module */
 	ret = mod->init();
 	if (ret < 0) {
@@ -1662,6 +1665,7 @@
 			free_module(mod);
 			up(&module_mutex);
 		}
+		TRIG_EVENT(module_init_failed_hook, mod);
 		return audit_result(ret);
 	}
 
Index: linux.t/kernel/sched.c
===================================================================
--- linux.t.orig/kernel/sched.c	2004-05-13 10:45:26.392423448 -0400
+++ linux.t/kernel/sched.c	2004-05-13 10:48:25.286227456 -0400
@@ -41,6 +41,7 @@
 #include <linux/percpu.h>
 #include <linux/kthread.h>
 #include <linux/stop_machine.h>
+#include <linux/trigevent_hooks.h>
 
 #ifdef CONFIG_NUMA_SCHED
 #define cpu_to_node_mask(cpu) node_to_cpumask(cpu_to_node(cpu))
@@ -407,6 +408,7 @@
 
 	recalc_task_prio(p, now);
 
+	TRIG_EVENT(process_wakeup_hook, p->pid, p->state);
 	/*
 	 * This checks to make sure it's not an uninterruptible task
 	 * that is now waking up.
@@ -2248,6 +2250,7 @@
 		++*switch_count;
 
 		prepare_arch_switch(rq, next);
+		TRIG_EVENT(sched_switch_hook, prev, next);
 		prev = context_switch(rq, prev, next);
 		barrier();
 
@@ -2257,6 +2260,7 @@
 
 	reacquire_kernel_lock(current);
 	preempt_enable_no_resched();
+	TRIG_EVENT(sched_dispatch_hook, prev, next);
 	if (test_thread_flag(TIF_NEED_RESCHED))
 		goto need_resched;
 
Index: linux.t/kernel/signal.c
===================================================================
--- linux.t.orig/kernel/signal.c	2004-05-13 10:45:19.946403392 -0400
+++ linux.t/kernel/signal.c	2004-05-13 10:48:25.289227000 -0400
@@ -22,6 +22,7 @@
 #include <linux/security.h>
 #include <linux/ptrace.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/param.h>
 #include <asm/uaccess.h>
 #include <asm/siginfo.h>
@@ -1205,6 +1206,7 @@
 	 */
 	read_lock(&tasklist_lock);  
 	spin_lock_irqsave(&p->sighand->siglock, flags);
+	TRIG_EVENT(signal_hook, sig, p->pid);
 	ret = specific_send_sig_info(sig, info, p);
 	spin_unlock_irqrestore(&p->sighand->siglock, flags);
 	read_unlock(&tasklist_lock);
Index: linux.t/kernel/softirq.c
===================================================================
--- linux.t.orig/kernel/softirq.c	2004-05-13 10:44:16.234089136 -0400
+++ linux.t/kernel/softirq.c	2004-05-13 10:48:25.291226696 -0400
@@ -15,6 +15,7 @@
 #include <linux/percpu.h>
 #include <linux/cpu.h>
 #include <linux/kthread.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/irq.h>
 /*
@@ -88,8 +89,10 @@
 	h = softirq_vec;
 
 	do {
-		if (pending & 1)
+		if (pending & 1) {
+			TRIG_EVENT(softirq_hook, (h - softirq_vec));
 			h->action(h);
+		}
 		h++;
 		pending >>= 1;
 	} while (pending);
@@ -237,6 +240,7 @@
 			if (!atomic_read(&t->count)) {
 				if (!test_and_clear_bit(TASKLET_STATE_SCHED, &t->state))
 					BUG();
+				TRIG_EVENT(tasklet_action_hook, (unsigned long) (t->func));
 				t->func(t->data);
 				tasklet_unlock(t);
 				continue;
@@ -270,6 +274,7 @@
 			if (!atomic_read(&t->count)) {
 				if (!test_and_clear_bit(TASKLET_STATE_SCHED, &t->state))
 					BUG();
+				TRIG_EVENT(tasklet_hi_action_hook, (unsigned long) (t->func));
 				t->func(t->data);
 				tasklet_unlock(t);
 				continue;
Index: linux.t/kernel/timer.c
===================================================================
--- linux.t.orig/kernel/timer.c	2004-05-13 10:44:56.011042120 -0400
+++ linux.t/kernel/timer.c	2004-05-13 10:48:25.293226392 -0400
@@ -31,6 +31,7 @@
 #include <linux/time.h>
 #include <linux/jiffies.h>
 #include <linux/cpu.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/div64.h>
@@ -870,8 +871,9 @@
  */
 static void run_timer_softirq(struct softirq_action *h)
 {
-	tvec_base_t *base = &__get_cpu_var(tvec_bases);
+	TRIG_EVENT(kernel_timer_hook, NULL);
 
+	tvec_base_t *base = &__get_cpu_var(tvec_bases);
 	if (time_after_eq(jiffies, base->timer_jiffies))
 		__run_timers(base);
 }
@@ -912,6 +914,7 @@
 #ifndef CONFIG_SMP
 	/* SMP process accounting uses the local APIC timer */
 
+	TRIG_EVENT(timer_hook, regs);
 	update_process_times(user_mode(regs));
 #endif
 	update_times();
@@ -1035,6 +1038,7 @@
 
 static void process_timeout(unsigned long __data)
 {
+	TRIG_EVENT(timer_expired_hook, (task_t *)__data);
 	wake_up_process((task_t *)__data);
 }
 
@@ -1099,6 +1103,7 @@
 		}
 	}
 
+	TRIG_EVENT(settimeout_hook, timeout);
 	expire = timeout + jiffies;
 
 	init_timer(&timer);
Index: linux.t/kernel/trigevent_hooks.c
===================================================================
--- linux.t.orig/kernel/trigevent_hooks.c	2004-04-06 09:27:52.000000000 -0400
+++ linux.t/kernel/trigevent_hooks.c	2004-05-13 10:48:25.294226240 -0400
@@ -0,0 +1,130 @@
+/*
+ * RAS Instrumentation hooks.
+ *
+ * Most of these hooks are for Linux Trace Toolkit. They may also be
+ * used by any other tool.
+ * 
+ * Author: Vamsi Krishna S. <vamsi_krishna@in.ibm.com>
+ */
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/hook.h>
+#include <linux/trigevent_hooks.h>
+#include <linux/ptrace.h>
+
+DECLARE_TRIG_EVENT(ipc_call_hook);
+DECLARE_TRIG_EVENT(ipc_msg_create_hook);
+DECLARE_TRIG_EVENT(ipc_sem_create_hook);
+DECLARE_TRIG_EVENT(ipc_shm_create_hook);
+
+DECLARE_TRIG_EVENT(irq_entry_hook);
+DECLARE_TRIG_EVENT(irq_exit_hook);
+
+DECLARE_TRIG_EVENT(kernel_timer_hook);
+
+DECLARE_TRIG_EVENT(kthread_hook);
+DECLARE_TRIG_EVENT(exec_hook);
+DECLARE_TRIG_EVENT(fork_hook);
+DECLARE_TRIG_EVENT(process_exit_hook);
+DECLARE_TRIG_EVENT(process_wait_hook);
+DECLARE_TRIG_EVENT(process_wakeup_hook);
+DECLARE_TRIG_EVENT(sched_switch_hook);
+DECLARE_TRIG_EVENT(sched_dispatch_hook);
+DECLARE_TRIG_EVENT(signal_hook);
+
+DECLARE_TRIG_EVENT(open_hook);
+DECLARE_TRIG_EVENT(close_hook);
+DECLARE_TRIG_EVENT(llseek_hook);
+DECLARE_TRIG_EVENT(lseek_hook);
+DECLARE_TRIG_EVENT(ioctl_hook);
+DECLARE_TRIG_EVENT(poll_hook);
+DECLARE_TRIG_EVENT(select_hook);
+DECLARE_TRIG_EVENT(read_hook);
+DECLARE_TRIG_EVENT(write_hook);
+DECLARE_TRIG_EVENT(buf_wait_end_hook);
+DECLARE_TRIG_EVENT(buf_wait_start_hook);
+
+
+DECLARE_TRIG_EVENT(mmap_hook);
+DECLARE_TRIG_EVENT(mm_page_alloc_hook);
+DECLARE_TRIG_EVENT(mm_page_free_hook);
+DECLARE_TRIG_EVENT(mm_swap_in_hook);
+DECLARE_TRIG_EVENT(mm_swap_out_hook);
+DECLARE_TRIG_EVENT(page_wait_end_hook);
+DECLARE_TRIG_EVENT(page_wait_start_hook);
+
+DECLARE_TRIG_EVENT(net_pkt_in_hook);
+DECLARE_TRIG_EVENT(net_pkt_out_hook);
+
+DECLARE_TRIG_EVENT(sk_call_hook);
+DECLARE_TRIG_EVENT(sk_create_hook);
+DECLARE_TRIG_EVENT(sk_receive_hook);
+DECLARE_TRIG_EVENT(sk_send_hook);
+
+DECLARE_TRIG_EVENT(softirq_hook);
+DECLARE_TRIG_EVENT(tasklet_action_hook);
+DECLARE_TRIG_EVENT(tasklet_hi_action_hook);
+DECLARE_TRIG_EVENT(bh_hook);
+
+DECLARE_TRIG_EVENT(timer_expired_hook);
+DECLARE_TRIG_EVENT(setitimer_hook);
+DECLARE_TRIG_EVENT(settimeout_hook);
+
+DECLARE_TRIG_EVENT(trap_entry_hook);
+DECLARE_TRIG_EVENT(trap_exit_hook);
+
+DECLARE_TRIG_EVENT(timer_hook);
+
+#ifdef CONFIG_MODULES
+DECLARE_TRIG_EVENT(module_init_hook);
+DECLARE_TRIG_EVENT(module_init_failed_hook);
+DECLARE_TRIG_EVENT(free_module_hook);
+#endif
+
+#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
+DECLARE_TRIG_EVENT(pre_syscall_hook);
+DECLARE_TRIG_EVENT(post_syscall_hook);
+/* 
+ * as syscalls are very sensitive, we have extra steps to enable 
+ * pre/post syscall hooks. Besides registering and arming hooks
+ * one has to call enable/disable_pre/post_syscall_hook().
+ */
+int pre_syscall_enabled;
+int post_syscall_enabled;
+
+void enable_pre_syscall(void)
+{
+	pre_syscall_enabled = 1;
+}
+EXPORT_SYMBOL(enable_pre_syscall);
+
+void enable_post_syscall(void)
+{
+	post_syscall_enabled = 1;
+}
+EXPORT_SYMBOL(enable_post_syscall);
+
+void disable_pre_syscall(void)
+{
+	pre_syscall_enabled = 0;
+}
+EXPORT_SYMBOL(disable_pre_syscall);
+
+void disable_post_syscall(void)
+{
+	post_syscall_enabled = 0;
+}
+EXPORT_SYMBOL(disable_post_syscall);
+
+asmlinkage void pre_syscall(struct pt_regs * regs)
+{
+	TRIG_EVENT(pre_syscall_hook, regs);
+}
+
+asmlinkage void post_syscall(void)
+{
+	TRIG_EVENT(post_syscall_hook);
+}
+#endif /* CONFIG_TRIGEVENT_SYSCALL_HOOK */
Index: linux.t/mm/filemap.c
===================================================================
--- linux.t.orig/mm/filemap.c	2004-05-13 10:45:19.178520128 -0400
+++ linux.t/mm/filemap.c	2004-05-13 10:48:25.298225632 -0400
@@ -28,6 +28,8 @@
 #include <linux/pagevec.h>
 #include <linux/blkdev.h>
 #include <linux/security.h>
+#include <linux/trigevent_hooks.h>
+
 /*
  * This is needed for the following functions:
  *  - try_to_release_page
@@ -469,6 +471,7 @@
 	if (!wait)
 		wait = &local_wait; /* default to a sync wait entry */
 
+	TRIG_EVENT(page_wait_start_hook, page);
 	do {
 		prepare_to_wait(waitqueue, wait, TASK_UNINTERRUPTIBLE);
 		if (test_bit(bit_nr, &page->flags)) {
@@ -485,6 +488,7 @@
 			io_schedule();
 		}
 	} while (test_bit(bit_nr, &page->flags));
+	TRIG_EVENT(page_wait_end_hook, page);
 	finish_wait(waitqueue, wait);
 
 	return 0;
Index: linux.t/mm/memory.c
===================================================================
--- linux.t.orig/mm/memory.c	2004-05-13 10:45:12.072600392 -0400
+++ linux.t/mm/memory.c	2004-05-13 10:48:25.301225176 -0400
@@ -46,6 +46,7 @@
 #include <linux/objrmap.h>
 #include <linux/module.h>
 #include <linux/init.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/pgalloc.h>
 #include <asm/uaccess.h>
@@ -1298,6 +1299,7 @@
 	ret = VM_FAULT_MINOR;
 	page = lookup_swap_cache(entry);
 	if (!page) {
+	        TRIG_EVENT(mm_swap_in_hook, address);
  		swapin_readahead(entry, address, vma);
  		page = read_swap_cache_async(entry, vma, address);
 		if (!page) {
Index: linux.t/mm/mmap.c
===================================================================
--- linux.t.orig/mm/mmap.c	2004-05-13 10:45:23.346886440 -0400
+++ linux.t/mm/mmap.c	2004-05-13 10:48:25.303224872 -0400
@@ -34,14 +34,14 @@
 #include <linux/objrmap.h>
 #include <linux/audit.h>
 #include <linux/err.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
 #include <asm/pgalloc.h>
 #include <asm/tlb.h>
 
 /*
- * WARNING: the debugging will use recursive algorithms so never enable this
- * unless you know what you are doing.
+ * WARNING: the debugging will use recursive algorithms so never enable this * unless you know what you are doing.
  */
 #undef DEBUG_MM_RB
 
@@ -307,6 +307,7 @@
 	__vma_link_rb(mm, vma, rb_link, rb_parent);
 	__vma_link_file(vma);
 	__anon_vma_link(vma);
+	TRIG_EVENT(mmap_hook, vma);
 }
 
 static void vma_link(struct mm_struct *mm, struct vm_area_struct *vma,
Index: linux.t/mm/page_alloc.c
===================================================================
--- linux.t.orig/mm/page_alloc.c	2004-05-13 10:45:11.157739472 -0400
+++ linux.t/mm/page_alloc.c	2004-05-13 10:48:25.306224416 -0400
@@ -31,6 +31,7 @@
 #include <linux/topology.h>
 #include <linux/sysctl.h>
 #include <linux/cpu.h>
+#include <linux/trigevent_hooks.h>
 
 #include <asm/tlbflush.h>
 
@@ -277,6 +278,7 @@
 	LIST_HEAD(list);
 	int i;
 
+	TRIG_EVENT(mm_page_free_hook, order);
 	arch_free_page(page, order);
 
 	mod_page_state(pgfree, 1 << order);
@@ -789,6 +791,7 @@
 	page = alloc_pages(gfp_mask, order);
 	if (!page)
 		return 0;
+	TRIG_EVENT(mm_page_alloc_hook, order);
 	return (unsigned long) page_address(page);
 }
 
Index: linux.t/mm/page_io.c
===================================================================
--- linux.t.orig/mm/page_io.c	2004-05-13 10:45:10.291871104 -0400
+++ linux.t/mm/page_io.c	2004-05-13 10:48:25.307224264 -0400
@@ -19,6 +19,7 @@
 #include <linux/buffer_head.h>	/* for block_sync_page() */
 #include <linux/mpage.h>
 #include <linux/writeback.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/pgtable.h>
 
 static struct bio *
@@ -103,6 +104,7 @@
 		ret = -ENOMEM;
 		goto out;
 	}
+	TRIG_EVENT(mm_swap_out_hook, page);
 	inc_page_state(pswpout);
 	set_page_writeback(page);
 	unlock_page(page);
Index: linux.t/net/core/dev.c
===================================================================
--- linux.t.orig/net/core/dev.c	2004-05-13 10:45:03.330929328 -0400
+++ linux.t/net/core/dev.c	2004-05-13 10:48:25.312223504 -0400
@@ -111,6 +111,7 @@
 #include <linux/wireless.h>		/* Note : will define WIRELESS_EXT */
 #include <net/iw_handler.h>
 #endif	/* CONFIG_NET_RADIO */
+#include <linux/trigevent_hooks.h>
 #include <asm/current.h>
 
 /* This define, if set, will randomly drop a packet when congestion
@@ -1385,6 +1386,7 @@
 			goto out;
 	}
 
+	TRIG_EVENT(net_pkt_out_hook, skb->protocol);
 	/* Grab device queue */
 	spin_lock_bh(&dev->queue_lock);
 	q = dev->qdisc;
@@ -1786,6 +1788,7 @@
 
 	skb_bond(skb);
 
+	TRIG_EVENT(net_pkt_in_hook, skb->protocol);
 	__get_cpu_var(netdev_rx_stat).total++;
 
 #ifdef CONFIG_NET_FASTROUTE
Index: linux.t/net/socket.c
===================================================================
--- linux.t.orig/net/socket.c	2004-05-13 10:45:20.094380896 -0400
+++ linux.t/net/socket.c	2004-05-13 10:48:25.315223048 -0400
@@ -82,6 +82,7 @@
 #include <linux/compat.h>
 #include <linux/kmod.h>
 #include <linux/audit.h>
+#include <linux/trigevent_hooks.h>
 
 #ifdef CONFIG_NET_RADIO
 #include <linux/wireless.h>		/* Note : will define WIRELESS_EXT */
@@ -550,6 +551,7 @@
 	int ret;
 
 	init_sync_kiocb(&iocb, NULL);
+	TRIG_EVENT(sk_send_hook, sock->type, size);
 	ret = __sock_sendmsg(&iocb, sock, msg, size);
 	if (-EIOCBQUEUED == ret)
 		ret = wait_on_sync_kiocb(&iocb);
@@ -583,6 +585,7 @@
 	int ret;
 
         init_sync_kiocb(&iocb, NULL);
+	TRIG_EVENT(sk_receive_hook, sock->type, size);
 	ret = __sock_recvmsg(&iocb, sock, msg, size, flags);
 	if (-EIOCBQUEUED == ret)
 		ret = wait_on_sync_kiocb(&iocb);
@@ -1103,6 +1106,7 @@
 	if (retval < 0)
 		goto out_release;
 
+	TRIG_EVENT(sk_create_hook, retval, type);
 out:
 	/* It may be already another descriptor 8) Not kernel problem. */
 	return audit_result(retval);
@@ -1826,6 +1830,7 @@
 	a0=a[0];
 	a1=a[1];
 	
+	TRIG_EVENT(sk_call_hook, call, a0);	
 	switch(call) 
 	{
 		case SYS_SOCKET:
