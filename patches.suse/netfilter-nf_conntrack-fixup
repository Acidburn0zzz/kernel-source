From: okir@suse.de
Subject: Adapt nf_conntrack patch to 2.6.13-rc4


Index: linux-2.6.12/include/linux/netfilter/nf_conntrack_core.h
===================================================================
--- linux-2.6.12.orig/include/linux/netfilter/nf_conntrack_core.h
+++ linux-2.6.12/include/linux/netfilter/nf_conntrack_core.h
@@ -13,7 +13,6 @@
 #define _NF_CONNTRACK_CORE_H
 
 #include <linux/netfilter.h>
-#include <linux/netfilter_ipv4/lockhelp.h>
 
 /* This header is used to share core functionality between the
    standalone connection tracking module, and the compatibility layer's use
@@ -68,5 +67,5 @@ extern void __nf_conntrack_attach(struct
 
 extern struct list_head *nf_conntrack_hash;
 extern struct list_head nf_conntrack_expect_list;
-DECLARE_RWLOCK_EXTERN(nf_conntrack_lock);
+extern rwlock_t nf_conntrack_lock;
 #endif /* _NF_CONNTRACK_CORE_H */
Index: linux-2.6.12/net/netfilter/nf_conntrack_core.c
===================================================================
--- linux-2.6.12.orig/net/netfilter/nf_conntrack_core.c
+++ linux-2.6.12/net/netfilter/nf_conntrack_core.c
@@ -44,8 +44,8 @@
 
 /* This rwlock protects the main hash table, protocol/helper/expected
    registrations, conntrack timers*/
-#define ASSERT_READ_LOCK(x) MUST_BE_READ_LOCKED(&nf_conntrack_lock)
-#define ASSERT_WRITE_LOCK(x) MUST_BE_WRITE_LOCKED(&nf_conntrack_lock)
+#define ASSERT_READ_LOCK(x)  /* */
+#define ASSERT_WRITE_LOCK(x) /* */
 
 #include <linux/netfilter/nf_conntrack.h>
 #include <linux/netfilter/nf_conntrack_l3proto.h>
@@ -62,7 +62,7 @@
 #define DEBUGP(format, args...)
 #endif
 
-DECLARE_RWLOCK(nf_conntrack_lock);
+rwlock_t nf_conntrack_lock;
 
 /* nf_conntrack_standalone needs this */
 atomic_t nf_conntrack_count = ATOMIC_INIT(0);
@@ -109,7 +109,7 @@ static struct {
 } nf_ct_cache[NF_CT_F_NUM];
 
 /* protect members of nf_ct_cache except of "use" */
-DECLARE_RWLOCK(nf_ct_cache_lock);
+rwlock_t nf_ct_cache_lock;
 
 /* This avoids calling kmem_cache_create() with same name simultaneously */
 DECLARE_MUTEX(nf_ct_cache_mutex);
@@ -154,7 +154,7 @@ alloc_conntrack(u_int32_t features)
 
 	DEBUGP("alloc_conntrack: features=0x%x\n", features);
 
-	READ_LOCK(&nf_ct_cache_lock);
+	read_lock_bh(&nf_ct_cache_lock);
 
 	if (!nf_ct_cache[features].use) {
 		DEBUGP("alloc_conntrack: not supported features = 0x%x\n",
@@ -178,7 +178,7 @@ alloc_conntrack(u_int32_t features)
 	}
 
 out:
-	READ_UNLOCK(&nf_ct_cache_lock);
+	read_unlock_bh(&nf_ct_cache_lock);
 	return conntrack;
 }
 
@@ -223,7 +223,7 @@ int nf_conntrack_register_cache(u_int32_
 
 	down(&nf_ct_cache_mutex);
 
-	WRITE_LOCK(&nf_ct_cache_lock);
+	write_lock_bh(&nf_ct_cache_lock);
 	/* e.g: multiple helpers are loaded */
 	if (nf_ct_cache[features].use > 0) {
 		DEBUGP("nf_conntrack_register_cache: already resisterd.\n");
@@ -237,11 +237,11 @@ int nf_conntrack_register_cache(u_int32_
 		} else
 			ret = -EBUSY;
 
-		WRITE_UNLOCK(&nf_ct_cache_lock);
+		write_unlock_bh(&nf_ct_cache_lock);
 		up(&nf_ct_cache_mutex);
 		return ret;
 	}
-	WRITE_UNLOCK(&nf_ct_cache_lock);
+	write_unlock_bh(&nf_ct_cache_lock);
 
 	/*
 	 * The memory space for name of slab cache must be alive until
@@ -270,13 +270,13 @@ int nf_conntrack_register_cache(u_int32_
 		goto out_free_name;
 	}
 
-	WRITE_LOCK(&nf_ct_cache_lock);
+	write_lock_bh(&nf_ct_cache_lock);
 	nf_ct_cache[features].use = 1;
 	nf_ct_cache[features].size = size;
 	nf_ct_cache[features].init_conntrack = init;
 	nf_ct_cache[features].cachep = cachep;
 	nf_ct_cache[features].name = cache_name;
-	WRITE_UNLOCK(&nf_ct_cache_lock);
+	write_unlock_bh(&nf_ct_cache_lock);
 
 	goto out_up_mutex;
 
@@ -300,9 +300,9 @@ void nf_conntrack_unregister_cache(u_int
 	DEBUGP("nf_conntrack_unregister_cache: 0x%04x\n", features);
 	down(&nf_ct_cache_mutex);
 
-	WRITE_LOCK(&nf_ct_cache_lock);
+	write_lock_bh(&nf_ct_cache_lock);
 	if (--nf_ct_cache[features].use > 0) {
-		WRITE_UNLOCK(&nf_ct_cache_lock);
+		write_unlock_bh(&nf_ct_cache_lock);
 		up(&nf_ct_cache_mutex);
 		return;
 	}
@@ -312,7 +312,7 @@ void nf_conntrack_unregister_cache(u_int
 	nf_ct_cache[features].name = NULL;
 	nf_ct_cache[features].init_conntrack = NULL;
 	nf_ct_cache[features].size = 0;
-	WRITE_UNLOCK(&nf_ct_cache_lock);
+	write_unlock_bh(&nf_ct_cache_lock);
 
 	synchronize_net();
 
@@ -373,7 +373,6 @@ static void destroy_expect(struct nf_con
 
 static void unlink_expect(struct nf_conntrack_expect *exp)
 {
-	MUST_BE_WRITE_LOCKED(&nf_conntrack_lock);
 	list_del(&exp->list);
 	/* Logically in destroy_expect, but we hold the lock here. */
 	exp->master->expecting--;
@@ -383,9 +382,9 @@ static void expectation_timed_out(unsign
 {
 	struct nf_conntrack_expect *exp = (void *)ul_expect;
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	unlink_expect(exp);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 	destroy_expect(exp);
 }
 
@@ -435,7 +434,6 @@ clean_from_lists(struct nf_conn *ct)
 	unsigned int ho, hr;
 	
 	DEBUGP("clean_from_lists(%p)\n", ct);
-	MUST_BE_WRITE_LOCKED(&nf_conntrack_lock);
 
 	ho = hash_conntrack(&ct->tuplehash[IP_CT_DIR_ORIGINAL].tuple);
 	hr = hash_conntrack(&ct->tuplehash[IP_CT_DIR_REPLY].tuple);
@@ -472,7 +470,7 @@ destroy_conntrack(struct nf_conntrack *n
 	if (nf_conntrack_destroyed)
 		nf_conntrack_destroyed(ct);
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	/* Expectations will have been removed in clean_from_lists,
 	 * except TFTP can create an expectation on the first packet,
 	 * before connection is in the list, so we need to clean here,
@@ -486,7 +484,7 @@ destroy_conntrack(struct nf_conntrack *n
 	}
 
 	NF_CT_STAT_INC(delete);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 
 	if (ct->master)
 		nf_ct_put(ct->master);
@@ -500,12 +498,12 @@ static void death_by_timeout(unsigned lo
 {
 	struct nf_conn *ct = (void *)ul_conntrack;
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	/* Inside lock so preempt is disabled on module removal path.
 	 * Otherwise we can get spurious warnings. */
 	NF_CT_STAT_INC(delete_list);
 	clean_from_lists(ct);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 	nf_ct_put(ct);
 }
 
@@ -514,7 +512,6 @@ conntrack_tuple_cmp(const struct nf_conn
 		    const struct nf_conntrack_tuple *tuple,
 		    const struct nf_conn *ignored_conntrack)
 {
-	MUST_BE_READ_LOCKED(&nf_conntrack_lock);
 	return nf_ct_tuplehash_to_ctrack(i) != ignored_conntrack
 		&& nf_ct_tuple_equal(tuple, &i->tuple);
 }
@@ -526,7 +523,6 @@ __nf_conntrack_find(const struct nf_conn
 	struct nf_conntrack_tuple_hash *h;
 	unsigned int hash = hash_conntrack(tuple);
 
-	MUST_BE_READ_LOCKED(&nf_conntrack_lock);
 	list_for_each_entry(h, &nf_conntrack_hash[hash], list) {
 		if (conntrack_tuple_cmp(h, tuple, ignored_conntrack)) {
 			NF_CT_STAT_INC(found);
@@ -545,11 +541,11 @@ nf_conntrack_find_get(const struct nf_co
 {
 	struct nf_conntrack_tuple_hash *h;
 
-	READ_LOCK(&nf_conntrack_lock);
+	read_lock_bh(&nf_conntrack_lock);
 	h = __nf_conntrack_find(tuple, ignored_conntrack);
 	if (h)
 		atomic_inc(&nf_ct_tuplehash_to_ctrack(h)->ct_general.use);
-	READ_UNLOCK(&nf_conntrack_lock);
+	read_unlock_bh(&nf_conntrack_lock);
 
 	return h;
 }
@@ -584,7 +580,7 @@ __nf_conntrack_confirm(struct sk_buff **
 	NF_CT_ASSERT(!nf_ct_is_confirmed(ct));
 	DEBUGP("Confirming conntrack %p\n", ct);
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 
 	/* See if there's one in the list already, including reverse:
 	   NAT could have grabbed it without realizing, since we're
@@ -612,12 +608,12 @@ __nf_conntrack_confirm(struct sk_buff **
 		atomic_inc(&ct->ct_general.use);
 		set_bit(IPS_CONFIRMED_BIT, &ct->status);
 		NF_CT_STAT_INC(insert);
-		WRITE_UNLOCK(&nf_conntrack_lock);
+		write_unlock_bh(&nf_conntrack_lock);
 		return NF_ACCEPT;
 	}
 
 	NF_CT_STAT_INC(insert_failed);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 	return NF_DROP;
 }
 
@@ -629,9 +625,9 @@ nf_conntrack_tuple_taken(const struct nf
 {
 	struct nf_conntrack_tuple_hash *h;
 
-	READ_LOCK(&nf_conntrack_lock);
+	read_lock_bh(&nf_conntrack_lock);
 	h = __nf_conntrack_find(tuple, ignored_conntrack);
-	READ_UNLOCK(&nf_conntrack_lock);
+	read_unlock_bh(&nf_conntrack_lock);
 
 	return h != NULL;
 }
@@ -651,13 +647,13 @@ static int early_drop(struct list_head *
 	struct nf_conn *ct = NULL;
 	int dropped = 0;
 
-	READ_LOCK(&nf_conntrack_lock);
+	read_lock_bh(&nf_conntrack_lock);
 	h = LIST_FIND_B(chain, unreplied, struct nf_conntrack_tuple_hash *);
 	if (h) {
 		ct = nf_ct_tuplehash_to_ctrack(h);
 		atomic_inc(&ct->ct_general.use);
 	}
-	READ_UNLOCK(&nf_conntrack_lock);
+	read_unlock_bh(&nf_conntrack_lock);
 
 	if (!ct)
 		return dropped;
@@ -727,12 +723,12 @@ init_conntrack(const struct nf_conntrack
 
 	/*  find features needed by this conntrack. */
 	features = l3proto->get_features(tuple);
-	READ_LOCK(&nf_conntrack_lock);
+	read_lock_bh(&nf_conntrack_lock);
 	if (nf_ct_find_helper(&repl_tuple) != NULL) {
 		features |= NF_CT_F_HELP;
 		helper_used = 1;
 	}
-	READ_UNLOCK(&nf_conntrack_lock);
+	read_unlock_bh(&nf_conntrack_lock);
 
 	conntrack = alloc_conntrack(features);
 	if (!conntrack) {
@@ -754,7 +750,7 @@ init_conntrack(const struct nf_conntrack
 	conntrack->timeout.data = (unsigned long)conntrack;
 	conntrack->timeout.function = death_by_timeout;
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	exp = find_expectation(tuple);
 
 	if (exp) {
@@ -778,7 +774,7 @@ init_conntrack(const struct nf_conntrack
 	list_add(&conntrack->tuplehash[IP_CT_DIR_ORIGINAL].list, &unconfirmed);
 
 	atomic_inc(&nf_conntrack_count);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 
 	if (exp) {
 		if (exp->expectfn)
@@ -965,17 +961,17 @@ void nf_conntrack_unexpect_related(struc
 {
 	struct nf_conntrack_expect *i;
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	/* choose the the oldest expectation to evict */
 	list_for_each_entry_reverse(i, &nf_conntrack_expect_list, list) {
 		if (expect_matches(i, exp) && del_timer(&i->timeout)) {
 			unlink_expect(i);
-			WRITE_UNLOCK(&nf_conntrack_lock);
+			write_unlock_bh(&nf_conntrack_lock);
 			destroy_expect(i);
 			return;
 		}
 	}
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 }
 
 struct nf_conntrack_expect *nf_conntrack_expect_alloc(void)
@@ -1050,7 +1046,7 @@ int nf_conntrack_expect_related(struct n
 	DEBUGP("tuple: "); NF_CT_DUMP_TUPLE(&expect->tuple);
 	DEBUGP("mask:  "); NF_CT_DUMP_TUPLE(&expect->mask);
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	list_for_each_entry(i, &nf_conntrack_expect_list, list) {
 		if (expect_matches(i, expect)) {
 			/* Refresh timer: if it's dying, ignore.. */
@@ -1073,7 +1069,7 @@ int nf_conntrack_expect_related(struct n
 	nf_conntrack_expect_insert(expect);
 	ret = 0;
 out:
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 	return ret;
 }
 
@@ -1082,7 +1078,7 @@ out:
 void nf_conntrack_alter_reply(struct nf_conn *conntrack,
 			      const struct nf_conntrack_tuple *newreply)
 {
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	/* Should be unconfirmed, so not in hash table yet */
 	NF_CT_ASSERT(!nf_ct_is_confirmed(conntrack));
 
@@ -1092,7 +1088,7 @@ void nf_conntrack_alter_reply(struct nf_
 	conntrack->tuplehash[IP_CT_DIR_REPLY].tuple = *newreply;
 	if (!conntrack->master && conntrack->expecting == 0)
 		conntrack->helper = nf_ct_find_helper(newreply);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 }
 
 int nf_conntrack_helper_register(struct nf_conntrack_helper *me)
@@ -1109,9 +1105,9 @@ int nf_conntrack_helper_register(struct 
 		printk(KERN_ERR "nf_conntrack_helper_reigster: Unable to create slab cache for conntracks\n");
 		return ret;
 	}
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	list_prepend(&helpers, me);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 
 	return 0;
 }
@@ -1130,7 +1126,7 @@ void nf_conntrack_helper_unregister(stru
 	struct nf_conntrack_expect *exp, *tmp;
 
 	/* Need write lock here, to delete helper. */
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	LIST_DELETE(&helpers, me);
 
 	/* Get rid of expectations */
@@ -1146,7 +1142,7 @@ void nf_conntrack_helper_unregister(stru
 	for (i = 0; i < nf_conntrack_htable_size; i++)
 		LIST_FIND_W(&nf_conntrack_hash[i], unhelp,
 			    struct nf_conntrack_tuple_hash *, me);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 
 	/* Someone could be still looking at the helper in a bh. */
 	synchronize_net();
@@ -1180,14 +1176,14 @@ void nf_ct_refresh_acct(struct nf_conn *
 		ct->timeout.expires = extra_jiffies;
 		ct_add_counters(ct, ctinfo, skb);
 	} else {
-		WRITE_LOCK(&nf_conntrack_lock);
+		write_lock_bh(&nf_conntrack_lock);
 		/* Need del_timer for race avoidance (may already be dying). */
 		if (del_timer(&ct->timeout)) {
 			ct->timeout.expires = jiffies + extra_jiffies;
 			add_timer(&ct->timeout);
 		}
 		ct_add_counters(ct, ctinfo, skb);
-		WRITE_UNLOCK(&nf_conntrack_lock);
+		write_unlock_bh(&nf_conntrack_lock);
 	}
 }
 
@@ -1225,7 +1221,7 @@ get_next_corpse(int (*iter)(struct nf_co
 {
 	struct nf_conntrack_tuple_hash *h = NULL;
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	for (; *bucket < nf_conntrack_htable_size; (*bucket)++) {
 		h = LIST_FIND_W(&nf_conntrack_hash[*bucket], do_iter,
 				struct nf_conntrack_tuple_hash *, iter, data);
@@ -1237,7 +1233,7 @@ get_next_corpse(int (*iter)(struct nf_co
 				struct nf_conntrack_tuple_hash *, iter, data);
 	if (h)
 		atomic_inc(&nf_ct_tuplehash_to_ctrack(h)->ct_general.use);
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 
 	return h;
 }
@@ -1366,10 +1362,10 @@ int __init nf_conntrack_init(void)
 	}
 
 	/* Don't NEED lock here, but good form anyway. */
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
         for (i = 0; i < PF_MAX; i++)
 		nf_ct_l3protos[i] = &nf_conntrack_generic_l3proto;
-        WRITE_UNLOCK(&nf_conntrack_lock);
+        write_unlock_bh(&nf_conntrack_lock);
 
 	for (i = 0; i < nf_conntrack_htable_size; i++)
 		INIT_LIST_HEAD(&nf_conntrack_hash[i]);
Index: linux-2.6.12/net/netfilter/nf_conntrack_ftp.c
===================================================================
--- linux-2.6.12.orig/net/netfilter/nf_conntrack_ftp.c
+++ linux-2.6.12/net/netfilter/nf_conntrack_ftp.c
@@ -26,7 +26,6 @@
 #include <net/tcp.h>
 
 #include <linux/netfilter/nf_conntrack.h>
-#include <linux/netfilter_ipv4/lockhelp.h>
 #include <linux/netfilter/nf_conntrack_helper.h>
 #include <linux/netfilter/nf_conntrack_ftp.h>
 
@@ -37,7 +36,7 @@ MODULE_DESCRIPTION("ftp connection track
 /* This is slow, but it's simple. --RR */
 static char ftp_buffer[65536];
 
-static DECLARE_LOCK(nf_ftp_lock);
+static spinlock_t nf_ftp_lock;
 
 #define MAX_PORTS 8
 static int ports[MAX_PORTS];
@@ -464,7 +463,7 @@ static int help(struct sk_buff **pskb,
 	}
 	datalen = (*pskb)->len - dataoff;
 
-	LOCK_BH(&nf_ftp_lock);
+	spin_lock_bh(&nf_ftp_lock);
 	fb_ptr = skb_header_pointer(*pskb, dataoff, datalen, ftp_buffer);
 	BUG_ON(fb_ptr == NULL);
 
@@ -611,7 +610,7 @@ out_update_nl:
 	if (ends_in_nl)
 		update_nl_seq(seq, ct_ftp_info,dir);
  out:
-	UNLOCK_BH(&nf_ftp_lock);
+	spin_unlock_bh(&nf_ftp_lock);
 	return ret;
 }
 
Index: linux-2.6.12/net/netfilter/nf_conntrack_proto_sctp.c
===================================================================
--- linux-2.6.12.orig/net/netfilter/nf_conntrack_proto_sctp.c
+++ linux-2.6.12/net/netfilter/nf_conntrack_proto_sctp.c
@@ -31,7 +31,6 @@
 
 #include <linux/netfilter/nf_conntrack.h>
 #include <linux/netfilter/nf_conntrack_protocol.h>
-#include <linux/netfilter_ipv4/lockhelp.h>
 
 #if 0
 #define DEBUGP(format, ...) printk(format, ## __VA_ARGS__)
@@ -40,7 +39,7 @@
 #endif
 
 /* Protects conntrack->proto.sctp */
-static DECLARE_RWLOCK(sctp_lock);
+static rwlock_t sctp_lock;
 
 /* FIXME: Examine ipfilter's timeouts and conntrack transitions more
    closely.  They're more complex. --RR 
@@ -204,9 +203,9 @@ static int sctp_print_conntrack(struct s
 	DEBUGP(__FUNCTION__);
 	DEBUGP("\n");
 
-	READ_LOCK(&sctp_lock);
+	read_lock_bh(&sctp_lock);
 	state = conntrack->proto.sctp.state;
-	READ_UNLOCK(&sctp_lock);
+	read_unlock_bh(&sctp_lock);
 
 	return seq_printf(s, "%s ", sctp_conntrack_names[state]);
 }
@@ -351,13 +350,13 @@ static int sctp_packet(struct nf_conn *c
 
 	oldsctpstate = newconntrack = SCTP_CONNTRACK_MAX;
 	for_each_sctp_chunk (skb, sch, _sch, offset, dataoff, count) {
-		WRITE_LOCK(&sctp_lock);
+		write_lock_bh(&sctp_lock);
 
 		/* Special cases of Verification tag check (Sec 8.5.1) */
 		if (sch->type == SCTP_CID_INIT) {
 			/* Sec 8.5.1 (A) */
 			if (sh->vtag != 0) {
-				WRITE_UNLOCK(&sctp_lock);
+				write_unlock_bh(&sctp_lock);
 				return -1;
 			}
 		} else if (sch->type == SCTP_CID_ABORT) {
@@ -365,7 +364,7 @@ static int sctp_packet(struct nf_conn *c
 			if (!(sh->vtag == conntrack->proto.sctp.vtag[CTINFO2DIR(ctinfo)])
 				&& !(sh->vtag == conntrack->proto.sctp.vtag
 							[1 - CTINFO2DIR(ctinfo)])) {
-				WRITE_UNLOCK(&sctp_lock);
+				write_unlock_bh(&sctp_lock);
 				return -1;
 			}
 		} else if (sch->type == SCTP_CID_SHUTDOWN_COMPLETE) {
@@ -374,13 +373,13 @@ static int sctp_packet(struct nf_conn *c
 				&& !(sh->vtag == conntrack->proto.sctp.vtag
 							[1 - CTINFO2DIR(ctinfo)] 
 					&& (sch->flags & 1))) {
-				WRITE_UNLOCK(&sctp_lock);
+				write_unlock_bh(&sctp_lock);
 				return -1;
 			}
 		} else if (sch->type == SCTP_CID_COOKIE_ECHO) {
 			/* Sec 8.5.1 (D) */
 			if (!(sh->vtag == conntrack->proto.sctp.vtag[CTINFO2DIR(ctinfo)])) {
-				WRITE_UNLOCK(&sctp_lock);
+				write_unlock_bh(&sctp_lock);
 				return -1;
 			}
 		}
@@ -392,7 +391,7 @@ static int sctp_packet(struct nf_conn *c
 		if (newconntrack == SCTP_CONNTRACK_MAX) {
 			DEBUGP("nf_conntrack_sctp: Invalid dir=%i ctype=%u conntrack=%u\n",
 			       CTINFO2DIR(ctinfo), sch->type, oldsctpstate);
-			WRITE_UNLOCK(&sctp_lock);
+			write_unlock_bh(&sctp_lock);
 			return -1;
 		}
 
@@ -404,7 +403,7 @@ static int sctp_packet(struct nf_conn *c
 			ih = skb_header_pointer(skb, offset + sizeof(sctp_chunkhdr_t),
 			                        sizeof(_inithdr), &_inithdr);
 			if (ih == NULL) {
-					WRITE_UNLOCK(&sctp_lock);
+					write_unlock_bh(&sctp_lock);
 					return -1;
 			}
 			DEBUGP("Setting vtag %x for dir %d\n", 
@@ -413,7 +412,7 @@ static int sctp_packet(struct nf_conn *c
 		}
 
 		conntrack->proto.sctp.state = newconntrack;
-		WRITE_UNLOCK(&sctp_lock);
+		write_unlock_bh(&sctp_lock);
 	}
 
 	nf_ct_refresh_acct(conntrack, ctinfo, skb, *sctp_timeouts[newconntrack]);
Index: linux-2.6.12/net/netfilter/nf_conntrack_proto_tcp.c
===================================================================
--- linux-2.6.12.orig/net/netfilter/nf_conntrack_proto_tcp.c
+++ linux-2.6.12/net/netfilter/nf_conntrack_proto_tcp.c
@@ -43,7 +43,6 @@
 #include <linux/netfilter_ipv6.h>
 #include <linux/netfilter/nf_conntrack.h>
 #include <linux/netfilter/nf_conntrack_protocol.h>
-#include <linux/netfilter_ipv4/lockhelp.h>
 
 #if 0
 #define DEBUGP printk
@@ -53,7 +52,7 @@
 #endif
 
 /* Protects conntrack->proto.tcp */
-static DECLARE_RWLOCK(tcp_lock);
+static rwlock_t tcp_lock;
 
 /* "Be conservative in what you do, 
     be liberal in what you accept from others." 
@@ -337,9 +336,9 @@ static int tcp_print_conntrack(struct se
 {
 	enum tcp_conntrack state;
 
-	READ_LOCK(&tcp_lock);
+	read_lock_bh(&tcp_lock);
 	state = conntrack->proto.tcp.state;
-	READ_UNLOCK(&tcp_lock);
+	read_unlock_bh(&tcp_lock);
 
 	return seq_printf(s, "%s ", tcp_conntrack_names[state]);
 }
@@ -747,14 +746,14 @@ void nf_conntrack_tcp_update(struct sk_b
 
 	end = segment_seq_plus_len(ntohl(tcph->seq), skb->len, dataoff, tcph);
 
-	WRITE_LOCK(&tcp_lock);
+	write_lock_bh(&tcp_lock);
 	/*
 	 * We have to worry for the ack in the reply packet only...
 	 */
 	if (after(end, conntrack->proto.tcp.seen[dir].td_end))
 		conntrack->proto.tcp.seen[dir].td_end = end;
 	conntrack->proto.tcp.last_end = end;
-	WRITE_UNLOCK(&tcp_lock);
+	write_unlock_bh(&tcp_lock);
 	DEBUGP("tcp_update: sender end=%u maxend=%u maxwin=%u scale=%i "
 	       "receiver end=%u maxend=%u maxwin=%u scale=%i\n",
 		sender->td_end, sender->td_maxend, sender->td_maxwin,
@@ -903,7 +902,7 @@ static int tcp_packet(struct nf_conn *co
 	th = skb_header_pointer(skb, dataoff, sizeof(_tcph), &_tcph);
 	BUG_ON(th == NULL);
 
-	WRITE_LOCK(&tcp_lock);
+	write_lock_bh(&tcp_lock);
 	old_state = conntrack->proto.tcp.state;
 	dir = CTINFO2DIR(ctinfo);
 	index = get_conntrack_index(th);
@@ -925,7 +924,7 @@ static int tcp_packet(struct nf_conn *co
 			 * that the client cannot but retransmit its SYN and 
 			 * thus initiate a clean new session.
 			 */
-		    	WRITE_UNLOCK(&tcp_lock);
+		    	write_unlock_bh(&tcp_lock);
 			if (LOG_INVALID(IPPROTO_TCP))
 				nf_log_packet(pf, 0, skb, NULL, NULL, 
 					  "nf_ct_tcp: killing out of sync session ");
@@ -940,7 +939,7 @@ static int tcp_packet(struct nf_conn *co
 		conntrack->proto.tcp.last_end =
 		    segment_seq_plus_len(ntohl(th->seq), skb->len, dataoff, th);
 
-		WRITE_UNLOCK(&tcp_lock);
+		write_unlock_bh(&tcp_lock);
 		if (LOG_INVALID(IPPROTO_TCP))
 			nf_log_packet(pf, 0, skb, NULL, NULL, 
 				  "nf_ct_tcp: invalid packed ignored ");
@@ -950,7 +949,7 @@ static int tcp_packet(struct nf_conn *co
 		DEBUGP("nf_ct_tcp: Invalid dir=%i index=%u ostate=%u\n",
 		       dir, get_conntrack_index(th),
 		       old_state);
-		WRITE_UNLOCK(&tcp_lock);
+		write_unlock_bh(&tcp_lock);
 		if (LOG_INVALID(IPPROTO_TCP))
 			nf_log_packet(pf, 0, skb, NULL, NULL, 
 				  "nf_ct_tcp: invalid state ");
@@ -964,7 +963,7 @@ static int tcp_packet(struct nf_conn *co
 			     conntrack->proto.tcp.seen[dir].td_end)) {
 		    	/* Attempt to reopen a closed connection.
 		    	* Delete this connection and look up again. */
-		    	WRITE_UNLOCK(&tcp_lock);
+		    	write_unlock_bh(&tcp_lock);
 		    	if (del_timer(&conntrack->timeout))
 		    		conntrack->timeout.function((unsigned long)
 		    					    conntrack);
@@ -989,7 +988,7 @@ static int tcp_packet(struct nf_conn *co
 
 	if (!tcp_in_window(&conntrack->proto.tcp, dir, index,
 			   skb, dataoff, th, pf)) {
-		WRITE_UNLOCK(&tcp_lock);
+		write_unlock_bh(&tcp_lock);
 		return -NF_ACCEPT;
 	}
      in_window:
@@ -1012,7 +1011,7 @@ static int tcp_packet(struct nf_conn *co
 	timeout = conntrack->proto.tcp.retrans >= nf_ct_tcp_max_retrans
 		  && *tcp_timeouts[new_state] > nf_ct_tcp_timeout_max_retrans
 		  ? nf_ct_tcp_timeout_max_retrans : *tcp_timeouts[new_state];
-	WRITE_UNLOCK(&tcp_lock);
+	write_unlock_bh(&tcp_lock);
 
 	if (!test_bit(IPS_SEEN_REPLY_BIT, &conntrack->status)) {
 		/* If only reply is a RST, we can consider ourselves not to
Index: linux-2.6.12/net/netfilter/nf_conntrack_standalone.c
===================================================================
--- linux-2.6.12.orig/net/netfilter/nf_conntrack_standalone.c
+++ linux-2.6.12/net/netfilter/nf_conntrack_standalone.c
@@ -30,8 +30,8 @@
 #include <linux/sysctl.h>
 #endif
 
-#define ASSERT_READ_LOCK(x) MUST_BE_READ_LOCKED(&nf_conntrack_lock)
-#define ASSERT_WRITE_LOCK(x) MUST_BE_WRITE_LOCKED(&nf_conntrack_lock)
+#define ASSERT_READ_LOCK(x)  /* */
+#define ASSERT_WRITE_LOCK(x) /* */
 
 #include <linux/netfilter/nf_conntrack.h>
 #include <linux/netfilter/nf_conntrack_l3proto.h>
@@ -131,7 +131,7 @@ static struct list_head *ct_get_idx(stru
 
 static void *ct_seq_start(struct seq_file *seq, loff_t *pos)
 {
-	READ_LOCK(&nf_conntrack_lock);
+	read_lock_bh(&nf_conntrack_lock);
 	return ct_get_idx(seq, *pos);
 }
 
@@ -143,7 +143,7 @@ static void *ct_seq_next(struct seq_file
 
 static void ct_seq_stop(struct seq_file *s, void *v)
 {
-	READ_UNLOCK(&nf_conntrack_lock);
+	read_unlock_bh(&nf_conntrack_lock);
 }
 
 /* return 0 on success, 1 in case of error */
@@ -154,7 +154,6 @@ static int ct_seq_show(struct seq_file *
 	struct nf_conntrack_l3proto *l3proto;
 	struct nf_conntrack_protocol *proto;
 
-	MUST_BE_READ_LOCKED(&nf_conntrack_lock);
 	NF_CT_ASSERT(conntrack);
 
 	/* we only want to print DIR_ORIGINAL */
@@ -263,7 +262,7 @@ static void *exp_seq_start(struct seq_fi
 
 	/* strange seq_file api calls stop even if we fail,
 	 * thus we need to grab lock since stop unlocks */
-	READ_LOCK(&nf_conntrack_lock);
+	read_lock_bh(&nf_conntrack_lock);
 
 	if (list_empty(e))
 		return NULL;
@@ -290,7 +289,7 @@ static void *exp_seq_next(struct seq_fil
 
 static void exp_seq_stop(struct seq_file *s, void *v)
 {
-	READ_UNLOCK(&nf_conntrack_lock);
+	read_unlock_bh(&nf_conntrack_lock);
 }
 
 static int exp_seq_show(struct seq_file *s, void *v)
@@ -709,23 +708,23 @@ int nf_conntrack_l3proto_register(struct
 {
 	int ret = 0;
 
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	if (nf_ct_l3protos[proto->l3proto] != &nf_conntrack_generic_l3proto) {
 		ret = -EBUSY;
 		goto out;
 	}
 	nf_ct_l3protos[proto->l3proto] = proto;
 out:
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 
 	return ret;
 }
 
 void nf_conntrack_l3proto_unregister(struct nf_conntrack_l3proto *proto)
 {
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	nf_ct_l3protos[proto->l3proto] = &nf_conntrack_generic_l3proto;
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 	
 	/* Somebody could be still looking at the proto in bh. */
 	synchronize_net();
@@ -741,7 +740,7 @@ int nf_conntrack_protocol_register(struc
 	int ret = 0;
 
 retry:
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	if (nf_ct_protos[proto->l3proto]) {
 		if (nf_ct_protos[proto->l3proto][proto->proto]
 				!= &nf_conntrack_generic_protocol) {
@@ -753,7 +752,7 @@ retry:
 		struct nf_conntrack_protocol **proto_array;
 		int i;
 
-		WRITE_UNLOCK(&nf_conntrack_lock);
+		write_unlock_bh(&nf_conntrack_lock);
 
 		proto_array = (struct nf_conntrack_protocol **)
 				kmalloc(MAX_NF_CT_PROTO *
@@ -766,14 +765,14 @@ retry:
 		for (i = 0; i < MAX_NF_CT_PROTO; i++)
 			proto_array[i] = &nf_conntrack_generic_protocol;
 
-		WRITE_LOCK(&nf_conntrack_lock);
+		write_lock_bh(&nf_conntrack_lock);
 		if (nf_ct_protos[proto->l3proto]) {
 			/* bad timing, but no problem */
-			WRITE_UNLOCK(&nf_conntrack_lock);
+			write_unlock_bh(&nf_conntrack_lock);
 			kfree(proto_array);
 		} else {
 			nf_ct_protos[proto->l3proto] = proto_array;
-			WRITE_UNLOCK(&nf_conntrack_lock);
+			write_unlock_bh(&nf_conntrack_lock);
 		}
 
 		/*
@@ -786,17 +785,17 @@ retry:
 	nf_ct_protos[proto->l3proto][proto->proto] = proto;
 
 out_unlock:
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 out:
 	return ret;
 }
 
 void nf_conntrack_protocol_unregister(struct nf_conntrack_protocol *proto)
 {
-	WRITE_LOCK(&nf_conntrack_lock);
+	write_lock_bh(&nf_conntrack_lock);
 	nf_ct_protos[proto->l3proto][proto->proto]
 		= &nf_conntrack_generic_protocol;
-	WRITE_UNLOCK(&nf_conntrack_lock);
+	write_unlock_bh(&nf_conntrack_lock);
 	
 	/* Somebody could be still looking at the proto in bh. */
 	synchronize_net();
