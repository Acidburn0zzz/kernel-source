
From: Hans Reiser <reiser@namesys.com>

This patch is by Dipankar Sarma <dipankar@in.ibm.com>. His description:

  This patch introduces a new interface - rcu_barrier() which waits until
  all the RCUs queued until this call have been completed.

Reiser4 needs this patch, because we do more than just freeing memory object
in our RCU callback: we also remove it from the list hanging off super-block. 
This means, that before freeing reiser4-specific portion of super-block
(during umount) we have to wait until all pending RCU callbacks are executed.

The only change of reiser4 made to the original patch, is exporting of
rcu_barrier().

Signed-off-by: Andrew Morton <akpm@osdl.org>
Index: linux.t/include/linux/rcupdate.h
===================================================================
--- linux.t.orig/include/linux/rcupdate.h	2004-08-18 09:39:00.000000000 -0400
+++ linux.t/include/linux/rcupdate.h	2004-08-23 11:32:30.840952312 -0400
@@ -98,6 +98,7 @@ struct rcu_data {
         struct rcu_head *nxtlist;
 	struct rcu_head **nxttail;
         struct rcu_head *curlist;
+	struct rcu_head barrier;
 };
 
 DECLARE_PER_CPU(struct rcu_data, rcu_data);
@@ -144,6 +145,7 @@ extern void rcu_restart_cpu(int cpu);
 extern void FASTCALL(call_rcu(struct rcu_head *head, 
 				void (*func)(struct rcu_head *head)));
 extern void synchronize_kernel(void);
+extern void rcu_barrier(void);
 
 #endif /* __KERNEL__ */
 #endif /* __LINUX_RCUPDATE_H */
Index: linux.t/kernel/rcupdate.c
===================================================================
--- linux.t.orig/kernel/rcupdate.c	2004-08-18 09:39:01.000000000 -0400
+++ linux.t/kernel/rcupdate.c	2004-08-23 11:30:44.545111736 -0400
@@ -64,6 +64,10 @@ DEFINE_PER_CPU(struct rcu_data, rcu_data
 static DEFINE_PER_CPU(struct tasklet_struct, rcu_tasklet) = {NULL};
 #define RCU_tasklet(cpu) (per_cpu(rcu_tasklet, cpu))
 
+static atomic_t rcu_barrier_cpu_count;
+static struct semaphore rcu_barrier_sema;
+static struct completion rcu_barrier_completion;
+
 /**
  * call_rcu - Queue an RCU update request.
  * @head: structure to be used for queueing the RCU updates.
@@ -89,6 +93,41 @@ void fastcall call_rcu(struct rcu_head *
 	local_irq_restore(flags);
 }
 
+static void rcu_barrier_callback(struct rcu_head *notused)
+{
+	if (atomic_dec_and_test(&rcu_barrier_cpu_count))
+		complete(&rcu_barrier_completion);
+}
+
+static void rcu_barrier_func(void *notused)
+{
+	int cpu = get_cpu();
+	struct rcu_data *rdp = &per_cpu(rcu_data, cpu);
+	struct rcu_head *head;
+
+	head = &rdp->barrier;
+	atomic_inc(&rcu_barrier_cpu_count);
+	call_rcu(head, rcu_barrier_callback);
+	put_cpu_no_resched();
+}
+
+/**
+ * rcu_barrier - Wait until all the in-flight RCUs are complete.
+ */
+void rcu_barrier(void)
+{
+	BUG_ON(in_interrupt());
+	/* Take cpucontrol semaphore to protect against CPU hotplug */
+	down(&rcu_barrier_sema);
+	init_completion(&rcu_barrier_completion);
+	atomic_set(&rcu_barrier_cpu_count, 0);
+	rcu_barrier_func(NULL);
+	smp_call_function(rcu_barrier_func, NULL, 0, 1);
+	wait_for_completion(&rcu_barrier_completion);
+	up(&rcu_barrier_sema);
+}
+EXPORT_SYMBOL(rcu_barrier);
+
 /*
  * Invoke the completed RCU callbacks. They are expected to be in
  * a per-cpu list.
@@ -349,6 +388,7 @@ static struct notifier_block __devinitda
  */
 void __init rcu_init(void)
 {
+	sema_init(&rcu_barrier_sema, 1);
 	rcu_cpu_notify(&rcu_nb, CPU_UP_PREPARE,
 			(void *)(long)smp_processor_id());
 	/* Register notifier for non-boot CPUs */
