Index: linux.t/ipc/msg.c
===================================================================
--- linux.t.orig/ipc/msg.c	2004-03-22 20:23:56.958935256 -0500
+++ linux.t/ipc/msg.c	2004-03-22 20:25:22.618684349 -0500
@@ -24,12 +24,11 @@
 #include <linux/list.h>
 #include <linux/security.h>
 #include <linux/sched.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/current.h>
 #include <asm/uaccess.h>
 #include "util.h"
 
-#include <linux/trigevent_hooks.h>
-
 /* sysctl: */
 int msg_ctlmax = MSGMAX;
 int msg_ctlmnb = MSGMNB;
Index: linux.t/ipc/sem.c
===================================================================
--- linux.t.orig/ipc/sem.c	2004-03-22 20:23:56.960934667 -0500
+++ linux.t/ipc/sem.c	2004-03-22 20:25:22.619684055 -0500
@@ -71,11 +71,10 @@
 #include <linux/time.h>
 #include <linux/smp_lock.h>
 #include <linux/security.h>
+#include <linux/trigevent_hooks.h>
 #include <asm/uaccess.h>
 #include "util.h"
 
-#include <linux/trigevent_hooks.h>
-
 #define sem_lock(id)	((struct sem_array*)ipc_lock(&sem_ids,id))
 #define sem_unlock(sma)	ipc_unlock(&(sma)->sem_perm)
 #define sem_rmid(id)	((struct sem_array*)ipc_rmid(&sem_ids,id))
Index: linux.t/arch/sh/mm/fault.c
===================================================================
--- linux.t.orig/arch/sh/mm/fault.c	2004-03-22 20:23:56.937941443 -0500
+++ linux.t/arch/sh/mm/fault.c	2004-03-22 20:25:22.610686707 -0500
@@ -21,7 +21,6 @@
 #include <linux/smp_lock.h>
 #include <linux/interrupt.h>
 #include <linux/module.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
@@ -141,7 +140,6 @@ no_context:
 		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
-
 /*
  * Oops. The kernel tried to access some bad page. We'll have to
  * terminate things with extreme prejudice.
Index: linux.t/arch/sh/Kconfig
===================================================================
--- linux.t.orig/arch/sh/Kconfig	2004-03-22 20:23:56.931943211 -0500
+++ linux.t/arch/sh/Kconfig	2004-03-22 20:25:22.607687592 -0500
@@ -1144,6 +1144,34 @@ config TRIGEVENT_SYSCALL_HOOK
 	RAS hooks to enable tracing of system call entry and exit points.
 	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
 
+config LTT
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	select RELAYFS_FS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/sh/kernel/irq.c
===================================================================
--- linux.t.orig/arch/sh/kernel/irq.c	2004-03-22 20:23:56.933942622 -0500
+++ linux.t/arch/sh/kernel/irq.c	2004-03-22 20:25:22.608687297 -0500
@@ -31,7 +31,6 @@
 #include <linux/init.h>
 #include <linux/seq_file.h>
 #include <linux/kallsyms.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
@@ -160,13 +159,11 @@ int handle_IRQ_event(unsigned int irq, s
 		add_interrupt_randomness(irq);
 
 	local_irq_disable();
-
 #ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
 	if (irq != TIMER_IRQ) { /* avoid double-reporting the timer IRQ */
 		TRIG_EVENT(irq_exit_hook, irq, regs);
 	}
 #endif
-
 	return retval;
 }
 
Index: linux.t/arch/sh/kernel/traps.c
===================================================================
--- linux.t.orig/arch/sh/kernel/traps.c	2004-03-22 20:23:56.936941738 -0500
+++ linux.t/arch/sh/kernel/traps.c	2004-03-22 20:25:22.610686707 -0500
@@ -27,7 +27,6 @@
 #include <linux/spinlock.h>
 #include <linux/module.h>
 #include <linux/kallsyms.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
@@ -69,12 +68,12 @@ asmlinkage void do_##name(unsigned long 
 	tsk->thread.error_code = error_code;				\
 	tsk->thread.trap_no = trapnr;					\
         CHK_REMOTE_DEBUG(&regs);					\
-	TRIG_EVENT(trap_entry_hook, trapnr, regs.pc);			\
+	TRIG_EVENT(trap_entry_hook, trapnr, regs.pc); 			\
 	force_sig(signr, tsk);						\
-	TRIG_EVENT(trap_exit_hook);					\
+	TRIG_EVENT(trap_exit_hook); 					\	
 	die_if_no_fixup(str,&regs,error_code);				\
 }
-  
+
 #ifdef CONFIG_CPU_SH2
 #define TRAP_RESERVED_INST	4
 #define TRAP_ILLEGAL_SLOT_INST	6
@@ -719,5 +718,76 @@ void dump_stack(void)
 {
 	show_stack(NULL, NULL);
 }
+/* Trace related code */
+#if (CONFIG_TRACE)
+asmlinkage void trace_real_syscall_entry(struct pt_regs *regs)
+{
+	int use_depth;
+	int use_bounds;
+	int depth = 0;
+	int seek_depth;
+	unsigned long lower_bound;
+	unsigned long upper_bound;
+	unsigned long addr;
+	unsigned long *stack;
+	trace_syscall_entry trace_syscall_event;
+
+	/* Set the syscall ID */
+	trace_syscall_event.syscall_id = (uint8_t) regs->regs[REG_REG0 + 3];
+
+	/* Set the address in any case */
+	trace_syscall_event.address = regs->pc;
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if (!user_mode(regs))
+		/* Don't go digining anywhere */
+		goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if (ltt_get_trace_config(&use_depth,
+				 &use_bounds,
+				 &seek_depth,
+				 (void *) &lower_bound,
+				 (void *) &upper_bound) < 0)
+		goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if ((use_depth == 1) || (use_bounds == 1)) {
+		/* Start at the top of the stack (bottom address since stacks grow downward) */
+		stack = (unsigned long *) regs->regs[REG_REG15];
+
+		/* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+		while (!get_user(addr, stack)) {
+			/* Does this LOOK LIKE an address in the program */
+			/* TODO: does this work with shared libraries?? - Greg Banks */
+			if ((addr > current->mm->start_code) && (addr < current->mm->end_code)) {
+				/* Does this address fit the description */
+				if (((use_depth == 1) && (depth == seek_depth))
+				    || ((use_bounds == 1) && (addr > lower_bound)
+					&& (addr < upper_bound))) {
+					/* Set the address */
+					trace_syscall_event.address = addr;
+
+					/* We're done */
+					goto trace_syscall_end;
+				} else
+					/* We're one depth more */
+					depth++;
+			}
+			/* Go on to the next address */
+			stack++;
+		}
+	}
+trace_syscall_end:
+	/* Trace the event */
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
+
+asmlinkage void trace_real_syscall_exit(void)
+{
+	ltt_log_event(TRACE_EV_SYSCALL_EXIT, NULL);
+}
+
+#endif				/* (CONFIG_LTT) */
 
 EXPORT_SYMBOL(dump_stack);
Index: linux.t/arch/sh/kernel/sys_sh.c
===================================================================
--- linux.t.orig/arch/sh/kernel/sys_sh.c	2004-03-22 20:23:56.935942033 -0500
+++ linux.t/arch/sh/kernel/sys_sh.c	2004-03-22 20:25:22.609687002 -0500
@@ -21,7 +21,6 @@
 #include <linux/mman.h>
 #include <linux/file.h>
 #include <linux/utsname.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
Index: linux.t/arch/arm/mm/fault-common.c
===================================================================
--- linux.t.orig/arch/arm/mm/fault-common.c	2004-03-22 20:23:56.882957649 -0500
+++ linux.t/arch/arm/mm/fault-common.c	2004-03-22 20:25:22.584694371 -0500
@@ -249,6 +249,7 @@ int do_page_fault(unsigned long addr, un
 		goto no_context;
 
 	TRIG_EVENT(trap_entry_hook, 14, instruction_pointer(regs));
+
 	down_read(&mm->mmap_sem);
 	fault = __do_page_fault(mm, addr, fsr, tsk);
 	up_read(&mm->mmap_sem);
Index: linux.t/arch/arm/Kconfig
===================================================================
--- linux.t.orig/arch/arm/Kconfig	2004-03-22 20:23:56.877959122 -0500
+++ linux.t/arch/arm/Kconfig	2004-03-22 20:25:22.579695845 -0500
@@ -801,6 +801,34 @@ config TRIGEVENT_SYSCALL_HOOK
 	RAS hooks to enable tracing of system call entry and exit points.
 	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
 
+config LTT
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	select RELAYFS_FS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/arm/kernel/sys_arm.c
===================================================================
--- linux.t.orig/arch/arm/kernel/sys_arm.c	2004-03-22 20:23:56.881957944 -0500
+++ linux.t/arch/arm/kernel/sys_arm.c	2004-03-22 20:25:22.582694960 -0500
@@ -167,6 +167,7 @@ asmlinkage int sys_ipc (uint call, int f
 
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
+
 	TRIG_EVENT(ipc_call_hook, call, first);
 
 	switch (call) {
Index: linux.t/arch/arm/kernel/irq.c
===================================================================
--- linux.t.orig/arch/arm/kernel/irq.c	2004-03-22 20:23:56.879958533 -0500
+++ linux.t/arch/arm/kernel/irq.c	2004-03-22 20:25:22.581695255 -0500
@@ -449,6 +449,7 @@ asmlinkage void asm_do_IRQ(int irq, stru
 	struct irqdesc *desc = irq_desc + irq;
 
 	TRIG_EVENT(irq_entry_hook, irq, regs, !(user_mode(regs)));
+
 	/*
 	 * Some hardware gives randomly wrong interrupts.  Rather
 	 * than crashing, do something sensible.
@@ -468,6 +469,7 @@ asmlinkage void asm_do_IRQ(int irq, stru
 
 	spin_unlock(&irq_controller_lock);
 	irq_exit();
+
 	TRIG_EVENT(irq_exit_hook, irq, regs);
 }
 
Index: linux.t/arch/arm/kernel/traps.c
===================================================================
--- linux.t.orig/arch/arm/kernel/traps.c	2004-03-22 20:23:56.881957944 -0500
+++ linux.t/arch/arm/kernel/traps.c	2004-03-22 20:25:22.583694666 -0500
@@ -315,9 +315,11 @@ asmlinkage void do_undefinstr(struct pt_
 	info.si_addr  = pc;
 
 	TRIG_EVENT(trap_entry_hook, current->thread.trap_no, (uint32_t)pc);
+
 	force_sig_info(SIGILL, &info, current);
 
 	TRIG_EVENT(trap_exit_hook);
+
 	die_if_kernel("Oops - undefined instruction", regs, 0);
 }
 
@@ -532,8 +534,11 @@ baddataabort(int code, unsigned long ins
 	info.si_addr  = (void *)addr;
 
 	TRIG_EVENT(trap_entry_hook, 18, addr);	/* machine check */
+
 	force_sig_info(SIGILL, &info, current);
+
 	TRIG_EVENT(trap_exit_hook);
+
 	die_if_kernel("unknown data abort code", regs, instr);
 }
 
Index: linux.t/arch/arm/kernel/entry-common.S
===================================================================
--- linux.t.orig/arch/arm/kernel/entry-common.S	2004-03-22 20:23:56.878958828 -0500
+++ linux.t/arch/arm/kernel/entry-common.S	2004-03-22 20:25:22.580695550 -0500
@@ -150,6 +150,7 @@ ENTRY(vector_swi)
 	add	r0, sp, #S_R0			@ pointer to regs
 	ldmia	r1, {r0 - r3}			@ have to reload r0 - r3
 #endif
+  
 	str	r4, [sp, #-S_OFF]!		@ push fifth arg
 
 	get_thread_info tsk
Index: linux.t/arch/ppc/mm/fault.c
===================================================================
--- linux.t.orig/arch/ppc/mm/fault.c	2004-03-22 20:23:56.917947336 -0500
+++ linux.t/arch/ppc/mm/fault.c	2004-03-22 20:25:22.603688771 -0500
@@ -28,7 +28,6 @@
 #include <linux/interrupt.h>
 #include <linux/highmem.h>
 #include <linux/module.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/page.h>
Index: linux.t/arch/ppc/Kconfig
===================================================================
--- linux.t.orig/arch/ppc/Kconfig	2004-03-22 20:23:56.909949694 -0500
+++ linux.t/arch/ppc/Kconfig	2004-03-22 20:25:22.599689950 -0500
@@ -1273,6 +1273,34 @@ config TRIGEVENT_SYSCALL_HOOK
 	RAS hooks to enable tracing of system call entry and exit points.
 	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
 
+config LTT
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	select RELAYFS_FS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/ppc/kernel/irq.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/irq.c	2004-03-22 20:23:56.911949104 -0500
+++ linux.t/arch/ppc/kernel/irq.c	2004-03-22 20:25:22.600689655 -0500
@@ -46,7 +46,6 @@
 #include <linux/random.h>
 #include <linux/seq_file.h>
 #include <linux/cpumask.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
Index: linux.t/arch/ppc/kernel/traps.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/traps.c	2004-03-22 20:23:56.916947631 -0500
+++ linux.t/arch/ppc/kernel/traps.c	2004-03-22 20:25:22.602689065 -0500
@@ -30,7 +30,6 @@
 #include <linux/config.h>
 #include <linux/init.h>
 #include <linux/module.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/pgtable.h>
Index: linux.t/arch/ppc/kernel/process.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/process.c	2004-03-22 20:23:56.914948220 -0500
+++ linux.t/arch/ppc/kernel/process.c	2004-03-22 20:25:22.601689360 -0500
@@ -300,19 +300,19 @@ void show_regs(struct pt_regs * regs)
 	show_stack(current, (unsigned long *) regs->gpr[1]);
 }
 
-#ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK 
+#if CONFIG_TRIGEVENT_SYSCALL_HOOK
 long original_kernel_thread(int (*fn) (void *), void* arg, unsigned long flags);
 long kernel_thread(int (*fn) (void *), void* arg, unsigned long flags)
 {
-	long   retval;
+        long   retval;
 
 	retval = original_kernel_thread(fn, arg, flags);
 	if (retval > 0)
 		TRIG_EVENT(kthread_hook, retval, (int) fn);
 	return retval;
 }
-#endif /* CONFIG_TRIGEVENT_SYSCALL_HOOK */
- 
+#endif /* (CONFIG_TRIGEVENT_SYSCALL_HOOK) */
+
 void exit_thread(void)
 {
 	if (last_task_used_math == current)
Index: linux.t/arch/ppc/kernel/syscalls.c
===================================================================
--- linux.t.orig/arch/ppc/kernel/syscalls.c	2004-03-22 20:23:56.915947926 -0500
+++ linux.t/arch/ppc/kernel/syscalls.c	2004-03-22 20:25:22.601689360 -0500
@@ -36,7 +36,6 @@
 #include <linux/utsname.h>
 #include <linux/file.h>
 #include <linux/unistd.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/uaccess.h>
Index: linux.t/arch/i386/mm/fault.c
===================================================================
--- linux.t.orig/arch/i386/mm/fault.c	2004-03-22 20:23:56.894954113 -0500
+++ linux.t/arch/i386/mm/fault.c	2004-03-22 20:25:22.591692308 -0500
@@ -231,7 +231,6 @@ asmlinkage void do_page_fault(struct pt_
 
 	info.si_code = SEGV_MAPERR;
 
-	TRIG_EVENT(trap_entry_hook, 14, regs->eip);
 	/*
 	 * We fault-in kernel-space virtual memory on-demand. The
 	 * 'reference' page table is init_mm.pgd.
@@ -255,6 +254,8 @@ asmlinkage void do_page_fault(struct pt_
 		goto bad_area_nosemaphore;
 	} 
 
+	TRIG_EVENT(trap_entry_hook, 14, regs->eip);
+
 	mm = tsk->mm;
 
 	/*
@@ -358,8 +359,10 @@ bad_area_nosemaphore:
 		 * Valid to do another page fault here because this one came 
 		 * from user space.
 		 */
-		if (is_prefetch(regs, address))
+		if (is_prefetch(regs, address)) {
+			TRIG_EVENT(trap_exit_hook);
 			return;
+		}
 
 		tsk->thread.cr2 = address;
 		/* Kernel addresses are always protection faults */
@@ -407,12 +410,10 @@ no_context:
 		TRIG_EVENT(trap_exit_hook);
  		return;
 	}
-
 /*
  * Oops. The kernel tried to access some bad page. We'll have to
  * terminate things with extreme prejudice.
  */
-
 	bust_spinlocks(1);
 
 	if (address < PAGE_SIZE)
@@ -518,8 +519,10 @@ vmalloc_fault:
 		pte_k = pte_offset_kernel(pmd_k, address);
 		if (!pte_present(*pte_k))
 			goto no_context;
+		TRIG_EVENT(trap_entry_hook, 14, regs->eip);
 		TRIG_EVENT(trap_exit_hook);
 		return;
 	}
 	TRIG_EVENT(trap_exit_hook);
 }
+
Index: linux.t/arch/i386/Kconfig
===================================================================
--- linux.t.orig/arch/i386/Kconfig	2004-03-22 20:23:56.885956765 -0500
+++ linux.t/arch/i386/Kconfig	2004-03-22 20:25:22.586693781 -0500
@@ -1489,6 +1489,34 @@ config TRIGEVENT_SYSCALL_HOOK
 	RAS hooks to enable tracing of system call entry and exit points.
 	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
 
+config LTT
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	select RELAYFS_FS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/i386/kernel/irq.c
===================================================================
--- linux.t.orig/arch/i386/kernel/irq.c	2004-03-22 20:23:56.889955587 -0500
+++ linux.t/arch/i386/kernel/irq.c	2004-03-22 20:25:22.587693487 -0500
@@ -233,6 +233,7 @@ int handle_IRQ_event(unsigned int irq,
 		add_interrupt_randomness(irq);
 	local_irq_disable();
 	TRIG_EVENT(irq_exit_hook, irq, regs);
+
 	return retval;
 }
 
Index: linux.t/arch/i386/kernel/sys_i386.c
===================================================================
--- linux.t.orig/arch/i386/kernel/sys_i386.c	2004-03-22 20:23:56.891954997 -0500
+++ linux.t/arch/i386/kernel/sys_i386.c	2004-03-22 20:25:22.589692897 -0500
@@ -136,6 +136,7 @@ asmlinkage int sys_ipc (uint call, int f
 
 	version = call >> 16; /* hack for backward compatibility */
 	call &= 0xffff;
+
 	TRIG_EVENT(ipc_call_hook, call, first);
 
 	switch (call) {
Index: linux.t/arch/i386/kernel/traps.c
===================================================================
--- linux.t.orig/arch/i386/kernel/traps.c	2004-03-22 20:23:56.893954408 -0500
+++ linux.t/arch/i386/kernel/traps.c	2004-03-22 20:25:22.590692602 -0500
@@ -27,12 +27,12 @@
 #include <linux/ptrace.h>
 #include <linux/version.h>
 #include <linux/dump.h>
+#include <linux/trigevent_hooks.h>
 
 #ifdef CONFIG_EISA
 #include <linux/ioport.h>
 #include <linux/eisa.h>
 #endif
-#include <linux/trigevent_hooks.h>
 
 #ifdef CONFIG_MCA
 #include <linux/mca.h>
@@ -329,6 +329,7 @@ static inline void do_trap(int trapnr, i
 			   struct pt_regs * regs, long error_code, siginfo_t *info)
 {
 	TRIG_EVENT(trap_entry_hook, trapnr, regs->eip);
+
 	if (regs->eflags & VM_MASK) {
 		if (vm86)
 			goto vm86_trap;
Index: linux.t/arch/i386/kernel/process.c
===================================================================
--- linux.t.orig/arch/i386/kernel/process.c	2004-03-22 20:23:56.890955292 -0500
+++ linux.t/arch/i386/kernel/process.c	2004-03-22 20:25:22.588693192 -0500
@@ -284,6 +284,7 @@ int kernel_thread(int (*fn)(void *), voi
 
 	/* Ok, create the new process.. */
 	ret = do_fork(flags | CLONE_VM | CLONE_UNTRACED, 0, &regs, 0, NULL, NULL);
+
 #ifdef CONFIG_TRIGEVENT_SYSCALL_HOOK
 	if (ret > 0)
 		TRIG_EVENT(kthread_hook, ret, (int) fn);
Index: linux.t/arch/mips/baget/irq.c
===================================================================
--- linux.t.orig/arch/mips/baget/irq.c	2004-03-22 20:23:56.898952935 -0500
+++ linux.t/arch/mips/baget/irq.c	2004-03-22 20:25:22.594691423 -0500
@@ -184,6 +184,7 @@ static void do_IRQ(int irq, struct pt_re
 	int do_random, cpu;
 
 	TRIG_EVENT(irq_entry_hook, irq, regs, !user_mode(regs));
+
 	cpu = smp_processor_id();
 	irq_enter();
 	kstat_cpus(cpu).irqs[irq]++;
@@ -210,6 +211,7 @@ static void do_IRQ(int irq, struct pt_re
 	irq_exit();
 
 	TRIG_EVENT(irq_exit_hook, irq, regs);
+
 	/* unmasking and bottom half handling is done magically for us. */
 }
 
Index: linux.t/arch/mips/Kconfig
===================================================================
--- linux.t.orig/arch/mips/Kconfig	2004-03-22 20:23:56.897953229 -0500
+++ linux.t/arch/mips/Kconfig	2004-03-22 20:25:22.593691718 -0500
@@ -1570,6 +1570,34 @@ config TRIGEVENT_SYSCALL_HOOK
 	RAS hooks to enable tracing of system call entry and exit points.
 	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
 
+config LTT
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	select RELAYFS_FS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/mips/kernel/i8259.c
===================================================================
--- linux.t.orig/arch/mips/kernel/i8259.c	2004-03-22 20:23:56.899952640 -0500
+++ linux.t/arch/mips/kernel/i8259.c	2004-03-22 20:25:22.594691423 -0500
@@ -146,6 +146,7 @@ static inline int i8259A_irq_real(unsign
 	outb(0x0B,0xA0);		/* ISR register */
 	value = inb(0xA0) & (irqmask >> 8);
 	outb(0x0A,0xA0);		/* back to the IRR register */
+
 	TRIG_EVENT(irq_entry_hook, irq, regs, !user_mode(regs));
 	TRIG_EVENT(irq_exit_hook, irq, regs);
 	return value;
Index: linux.t/arch/mips/kernel/irq.c
===================================================================
--- linux.t.orig/arch/mips/kernel/irq.c	2004-03-22 20:23:56.900952345 -0500
+++ linux.t/arch/mips/kernel/irq.c	2004-03-22 20:25:22.595691129 -0500
@@ -354,6 +354,7 @@ asmlinkage unsigned int do_IRQ(int irq, 
 	unsigned int status;
 
 	TRIG_EVENT(irq_entry_hook, irq, regs, !user_mode(regs));
+
 	irq_enter();
 	kstat_this_cpu.irqs[irq]++;
 	spin_lock(&desc->lock);
@@ -419,6 +420,7 @@ out:
 	spin_unlock(&desc->lock);
 
 	irq_exit();
+
 	TRIG_EVENT(irq_exit_hook, irq, regs);
 
 	return 1;
Index: linux.t/arch/mips/kernel/time.c
===================================================================
--- linux.t.orig/arch/mips/kernel/time.c	2004-03-22 20:23:56.902951756 -0500
+++ linux.t/arch/mips/kernel/time.c	2004-03-22 20:25:22.596690834 -0500
@@ -553,6 +553,7 @@ irqreturn_t timer_interrupt(int irq, voi
 asmlinkage void ll_timer_interrupt(int irq, struct pt_regs *regs)
 {
 	TRIG_EVENT(irq_entry_hook, irq, regs, CAUSE_EPC(regs));
+
 	irq_enter();
 	kstat_this_cpu.irqs[irq]++;
 
@@ -560,6 +561,7 @@ asmlinkage void ll_timer_interrupt(int i
 	timer_interrupt(irq, NULL, regs);
 
 	irq_exit();
+
 	TRIG_EVENT(irq_exit_hook, irq, regs);	
 }
 
Index: linux.t/arch/s390/Kconfig
===================================================================
--- linux.t.orig/arch/s390/Kconfig	2004-03-22 20:23:56.921946158 -0500
+++ linux.t/arch/s390/Kconfig	2004-03-22 20:25:22.604688476 -0500
@@ -474,6 +474,34 @@ config TRIGEVENT_SYSCALL_HOOK
 	RAS hooks to enable tracing of system call entry and exit points.
 	 To enable RAS Syscall Hooks, say Y. If in doubt, Say N.	
 
+config LTT
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	select RELAYFS_FS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/s390/kernel/traps.c
===================================================================
--- linux.t.orig/arch/s390/kernel/traps.c	2004-03-22 20:23:56.927944390 -0500
+++ linux.t/arch/s390/kernel/traps.c	2004-03-22 20:25:22.605688181 -0500
@@ -30,7 +30,6 @@
 #include <linux/delay.h>
 #include <linux/module.h>
 #include <linux/kallsyms.h>
-
 #include <linux/trigevent_hooks.h>
 
 #include <asm/system.h>
Index: linux.t/arch/alpha/Kconfig
===================================================================
--- linux.t.orig/arch/alpha/Kconfig	2004-03-22 20:23:56.875959712 -0500
+++ linux.t/arch/alpha/Kconfig	2004-03-22 20:25:22.578696139 -0500
@@ -723,6 +723,33 @@ config TRIGEVENT_HOOKS
 
 	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
 
+config TRACE
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/sparc/Kconfig
===================================================================
--- linux.t.orig/arch/sparc/Kconfig	2004-03-22 20:23:56.938941149 -0500
+++ linux.t/arch/sparc/Kconfig	2004-03-22 20:25:22.611686413 -0500
@@ -479,6 +479,33 @@ config TRIGEVENT_HOOKS
 
 	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
 
+config TRACE
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/sparc64/Kconfig
===================================================================
--- linux.t.orig/arch/sparc64/Kconfig	2004-03-22 20:23:56.939940854 -0500
+++ linux.t/arch/sparc64/Kconfig	2004-03-22 20:25:22.613685823 -0500
@@ -732,6 +732,33 @@ config TRIGEVENT_HOOKS
 
 	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
 
+config TRACE
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/parisc/Kconfig
===================================================================
--- linux.t.orig/arch/parisc/Kconfig	2004-03-22 20:23:56.907950283 -0500
+++ linux.t/arch/parisc/Kconfig	2004-03-22 20:25:22.597690539 -0500
@@ -254,6 +254,33 @@ config TRIGEVENT_HOOKS
 
 	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
 
+config TRACE
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/arch/x86_64/Kconfig
===================================================================
--- linux.t.orig/arch/x86_64/Kconfig	2004-03-22 20:23:56.940940560 -0500
+++ linux.t/arch/x86_64/Kconfig	2004-03-22 20:25:22.614685528 -0500
@@ -529,6 +529,33 @@ config TRIGEVENT_HOOKS
 
 	 To enable RAS Instrumentation Hooks, say Y. If in doubt, Say N.	
 
+config TRACE
+	bool "Tracing support"
+	depends on TRIGEVENT_HOOKS
+	---help---
+	  It is possible for the kernel to log important events to a trace
+	  facility. Doing so, enables the use of the generated traces in order
+	  to reconstruct the dynamic behavior of the kernel, and hence the
+	  whole system.
+
+	  The tracing process contains 4 parts :
+	      1) The logging of events by key parts of the kernel.
+	      2) The tracer that keeps the events in a data buffer.
+	      3) A trace daemon that interacts with the tracer and is
+	         notified every time there is a certain quantity of data to
+	         read from the tracer.
+	      4) A trace event data decoder that reads the accumulated data
+	         and formats it in a human-readable format.
+
+	  If you say Y, the first two components will be built into the kernel.
+	  Critical parts of the kernel will call upon the kernel tracing
+	  function. The data is then recorded by the tracer if a trace daemon
+	  is running in user-space and has issued a "start" command.
+
+	  For more information on kernel tracing, the trace daemon or the event
+	  decoder, please check the following address :
+	       http://www.opersys.com/LTT
+
 endmenu
 
 source "security/Kconfig"
Index: linux.t/kernel/ltt/ltt-core_hooks.c
===================================================================
--- linux.t.orig/kernel/ltt/ltt-core_hooks.c	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/ltt-core_hooks.c	2004-03-22 20:25:22.630680813 -0500
@@ -0,0 +1,927 @@
+/*
+ * drivers/trace/trace_hooks.c
+ *
+ * This file registers and arms all the instrumentation hooks that are
+ * required by Linux Trace Toolkit. It also contains the hook exit
+ * routines.
+ *
+ * Author: Vamsi Krishna S. (vamsi_krishna@in.ibm.com)
+ *         The hook exit routines are based on LTT sources.
+ */
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/fs.h>
+#include <linux/ptrace.h>
+#include <linux/bitops.h>
+#include <linux/trigevent_hooks.h>
+#include <linux/ltt.h>
+
+#include <asm/io.h>
+#include <asm/current.h>
+#include <asm/uaccess.h>
+#include <asm/bitops.h>
+#include <asm/pgtable.h>
+
+
+/*
+ * Register hook exits. LTT maintains a bit in sTracedEvents for
+ * the status of a set of similar events for eg: TRACE_IPC for
+ * a number of IPC events etc. We need to arm and disarm all
+ * the hooks that correspond to a given bit in sTracedEvents.
+ */
+
+/*
+ * Helper macro to declare hook record structs. It takes as an argument 
+ * name of the hook. If hook_name is passed in, it declares hook_rec
+ * ltt_hook_name_rec and initialises the exit routine to
+ * ltt_hook_name.
+ */
+#define DECLARE_HOOK_REC(name) \
+static struct hook_rec ltt_##name##_rec = { \
+	.hook_exit      = ltt_##name, \
+};
+
+/*
+ * Helper macros to register/unregister/arm/disarm hooks.
+ */
+#define ltt_hook_register(name) \
+	hook_exit_register(&name, &ltt_##name##_rec)
+#define ltt_hook_unregister(name) \
+	hook_exit_deregister(&ltt_##name##_rec)
+#define ltt_hook_arm(name) \
+	hook_exit_arm(&ltt_##name##_rec)
+#define ltt_hook_remove(name) \
+	hook_exit_disarm(&ltt_##name##_rec); \
+	hook_exit_deregister(&ltt_##name##_rec)
+
+/* TRACE_SYSCALL_ENTRY */
+extern void ltt_pre_syscall(struct pt_regs *);
+static void ltt_pre_syscall_hook(struct hook *h, struct pt_regs *regs)
+{
+	ltt_pre_syscall(regs);
+}
+DECLARE_HOOK_REC(pre_syscall_hook);
+
+static int enable_pre_syscall_hooks(void)
+{
+	int rc;
+
+	ltt_pre_syscall_hook_rec.hook_exit_name = "pre_syscall";
+	if ((rc = ltt_hook_register(pre_syscall_hook)))
+		return rc;
+	
+	ltt_hook_arm(pre_syscall_hook);
+	enable_pre_syscall();
+	return rc;
+}
+
+static int disable_pre_syscall_hooks(void)
+{
+	disable_pre_syscall();
+	ltt_hook_remove(pre_syscall_hook);
+	return 0;
+}
+
+/* TRACE_SYSCALL_EXIT */
+static void ltt_post_syscall_hook(struct hook *h, struct pt_regs *regs)
+{
+	ltt_log_event(TRACE_EV_SYSCALL_EXIT, NULL);
+}
+DECLARE_HOOK_REC(post_syscall_hook);
+
+static int enable_post_syscall_hooks(void)
+{
+	int rc;
+
+	ltt_post_syscall_hook_rec.hook_exit_name = "post_syscall";
+	if ((rc = ltt_hook_register(post_syscall_hook)))
+		return rc;
+	
+	ltt_hook_arm(post_syscall_hook);
+	enable_post_syscall();
+	return rc;
+}
+
+static int disable_post_syscall_hooks(void)
+{
+	disable_post_syscall();
+	ltt_hook_remove(post_syscall_hook);
+	return 0;
+}
+/* TRACE_TRAP_ENTRY */
+static void ltt_trap_entry_hook(struct hook *h, int trapnr, unsigned long eip, struct pt_regs *regs)
+{
+	TRACE_TRAP_ENTRY(trapnr, eip);
+}
+DECLARE_HOOK_REC(trap_entry_hook);
+
+static int enable_trap_entry_hooks(void)
+{
+	int rc;
+
+	ltt_trap_entry_hook_rec.hook_exit_name = "trap_entry";
+	if ((rc = ltt_hook_register(trap_entry_hook)))
+		return rc;
+	
+	ltt_hook_arm(trap_entry_hook);
+	return rc;
+}
+
+static int disable_trap_entry_hooks(void)
+{
+	ltt_hook_remove(trap_entry_hook);
+	return 0;
+}
+
+/* TRACE_TRAP_EXIT */
+static void ltt_trap_exit_hook(struct hook *h)
+{
+	TRACE_TRAP_EXIT();
+}
+
+DECLARE_HOOK_REC(trap_exit_hook);
+
+static int enable_trap_exit_hooks(void)
+{
+	int rc;
+	
+	ltt_trap_exit_hook_rec.hook_exit_name = "trap_exit";
+	if ((rc = ltt_hook_register(trap_exit_hook)))
+		return rc;
+	
+	ltt_hook_arm(trap_exit_hook);
+	return rc;
+}
+
+static int disable_trap_exit_hooks(void)
+{
+	ltt_hook_remove(trap_exit_hook);
+	return 0;
+}
+
+/* TRACE_IRQ_ENTRY */
+static void ltt_irq_entry_hook(struct hook *h, unsigned int irq, struct pt_regs *regs, int irq_in_kernel)
+{
+	TRACE_IRQ_ENTRY(irq, irq_in_kernel);
+}
+
+DECLARE_HOOK_REC(irq_entry_hook);
+
+static int enable_irq_entry_hooks(void)
+{
+	int rc;
+
+	ltt_irq_entry_hook_rec.hook_exit_name = "irq_entry";
+	if ((rc = ltt_hook_register(irq_entry_hook)))
+		return rc;
+	
+	ltt_hook_arm(irq_entry_hook);
+	return rc;
+}
+
+static int disable_irq_entry_hooks(void)
+{
+	ltt_hook_remove(irq_entry_hook);
+	return 0;
+}
+
+/* TRACE_IRQ_EXIT */
+static void ltt_irq_exit_hook(struct hook *h)
+{
+	TRACE_IRQ_EXIT();
+}
+
+DECLARE_HOOK_REC(irq_exit_hook);
+
+static int enable_irq_exit_hooks(void)
+{
+	int rc;
+
+	ltt_irq_exit_hook_rec.hook_exit_name = "irq_exit";
+	if ((rc = ltt_hook_register(irq_exit_hook)))
+		return rc;
+	
+	ltt_hook_arm(irq_exit_hook);
+	return rc;
+}
+
+static int disable_irq_exit_hooks(void)
+{
+	ltt_hook_remove(irq_exit_hook);
+	return 0;
+}
+
+/* TRACE_SCHEDCHANGE */
+static void ltt_sched_switch_hook(struct hook *h, struct task_struct *prev, struct task_struct *next)
+{
+	TRACE_SCHEDCHANGE(prev, next);
+}
+
+DECLARE_HOOK_REC(sched_switch_hook);
+
+static int enable_schedchange_hooks(void)
+{
+	int rc;
+	
+	ltt_sched_switch_hook_rec.hook_exit_name = "sched_switch";
+	if ((rc = ltt_hook_register(sched_switch_hook)))
+		return rc;
+	
+	ltt_hook_arm(sched_switch_hook);
+	return rc;
+}
+
+static int disable_schedchange_hooks(void)
+{
+	ltt_hook_remove(sched_switch_hook);
+	return 0;
+}
+
+
+/* TRACE_KERNEL_TIMER */
+static void ltt_kernel_timer_hook(struct hook *h, unsigned long nr)
+{
+	TRACE_EVENT(TRACE_EV_KERNEL_TIMER, NULL);
+}
+
+DECLARE_HOOK_REC(kernel_timer_hook);
+
+static int enable_kernel_timer_hooks(void)
+{
+	int rc;
+
+	ltt_kernel_timer_hook_rec.hook_exit_name = "kernel_timer";
+	if ((rc = ltt_hook_register(kernel_timer_hook)))
+		return rc;
+	
+	ltt_hook_arm(kernel_timer_hook);
+	return rc;
+}
+
+static int disable_kernel_timer_hooks(void)
+{
+	ltt_hook_remove(kernel_timer_hook);
+	return 0;
+}
+
+static void ltt_softirq_hook(struct hook *h, int index)
+{
+	TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_SOFT_IRQ, index);
+}
+static void ltt_tasklet_action_hook(struct hook *h, unsigned long fn)
+{
+	TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_TASKLET_ACTION, fn);
+}
+static void ltt_tasklet_hi_action_hook(struct hook *h, unsigned long fn)
+{
+	TRACE_SOFT_IRQ(TRACE_EV_SOFT_IRQ_TASKLET_HI_ACTION, fn);
+}
+
+DECLARE_HOOK_REC(softirq_hook);
+DECLARE_HOOK_REC(tasklet_action_hook);
+DECLARE_HOOK_REC(tasklet_hi_action_hook);
+
+static int enable_softirq_hooks(void)
+{
+	int rc;
+
+	
+	ltt_softirq_hook_rec.hook_exit_name = "ltt_softirq";
+	if ((rc = ltt_hook_register(softirq_hook)))
+		goto err;
+	ltt_tasklet_action_hook_rec.hook_exit_name = "tasklet_action";
+	if ((rc = ltt_hook_register(tasklet_action_hook)))
+		goto err1;
+	ltt_tasklet_hi_action_hook_rec.hook_exit_name = "tasklet_hi_action";
+	if ((rc = ltt_hook_register(tasklet_hi_action_hook)))
+		goto err2;
+	
+	ltt_hook_arm(softirq_hook);
+	ltt_hook_arm(tasklet_action_hook);
+	ltt_hook_arm(tasklet_hi_action_hook);
+	return rc;
+
+err2:	ltt_hook_unregister(tasklet_action_hook);
+err1:	ltt_hook_unregister(softirq_hook);
+err:	return rc;
+
+}
+
+static int disable_softirq_hooks(void)
+{
+	ltt_hook_remove(softirq_hook);
+	ltt_hook_remove(tasklet_action_hook);
+	ltt_hook_remove(tasklet_hi_action_hook);
+	return 0;
+}
+
+/* TRACE_PROCESS */
+static void ltt_kthread_hook(struct hook *h, unsigned int ret, unsigned int fn)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_KTHREAD, ret, fn);
+}
+static void ltt_process_exit_hook(struct hook *h, pid_t pid)
+{
+	TRACE_PROCESS_EXIT(0, 0);
+}
+static void ltt_process_wait_hook(struct hook *h, pid_t pid)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_WAIT, pid, 0);
+}
+static void ltt_fork_hook(struct hook *h, unsigned long clone_flags, struct task_struct *p, int ret)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_FORK, ret, 0);
+}
+static void ltt_process_wakeup_hook(struct hook *h, pid_t pid, unsigned long state)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_WAKEUP, pid, state);
+}
+static void ltt_signal_hook(struct hook *h, int sig, pid_t pid)
+{
+	TRACE_PROCESS(TRACE_EV_PROCESS_SIGNAL, sig, pid);
+}
+
+DECLARE_HOOK_REC(kthread_hook);
+DECLARE_HOOK_REC(process_exit_hook);
+DECLARE_HOOK_REC(process_wait_hook);
+DECLARE_HOOK_REC(fork_hook);
+DECLARE_HOOK_REC(process_wakeup_hook);
+DECLARE_HOOK_REC(signal_hook);
+
+static int enable_process_hooks(void)
+{
+	int rc;
+
+	ltt_kthread_hook_rec.hook_exit_name = "ltt_kthread";
+	if ((rc = ltt_hook_register(kthread_hook)))
+		goto err;
+	ltt_process_exit_hook_rec.hook_exit_name = "ltt_process_exit";
+	if ((rc = ltt_hook_register(process_exit_hook)))
+		goto err1;
+	ltt_process_wait_hook_rec.hook_exit_name = "ltt_process_wait";
+	if ((rc = ltt_hook_register(process_wait_hook)))
+		goto err2;
+	ltt_fork_hook_rec.hook_exit_name = "ltt_fork";
+	if ((rc = ltt_hook_register(fork_hook)))
+		goto err3;
+	ltt_signal_hook_rec.hook_exit_name = "ltt_signal";
+	if ((rc = ltt_hook_register(signal_hook)))
+		goto err4;
+	ltt_process_wakeup_hook_rec.hook_exit_name = "ltt_process_wakeup";
+	if ((rc = ltt_hook_register(process_wakeup_hook)))
+		goto err5;
+	
+	ltt_hook_arm(kthread_hook);
+	ltt_hook_arm(process_exit_hook);
+	ltt_hook_arm(process_wait_hook);
+	ltt_hook_arm(fork_hook);
+	ltt_hook_arm(signal_hook);
+	ltt_hook_arm(process_wakeup_hook);
+	return rc;
+
+err5:	ltt_hook_unregister(signal_hook);
+err4:	ltt_hook_unregister(fork_hook);
+err3:	ltt_hook_unregister(process_wait_hook);
+err2:	ltt_hook_unregister(process_exit_hook);
+err1:	ltt_hook_unregister(kthread_hook);
+err:	return rc;
+
+}
+
+static int disable_process_hooks(void)
+{
+	ltt_hook_remove(kthread_hook);
+	ltt_hook_remove(process_exit_hook);
+	ltt_hook_remove(process_wait_hook);
+	ltt_hook_remove(fork_hook);
+	ltt_hook_remove(signal_hook);
+	ltt_hook_remove(process_wakeup_hook);
+	return 0;
+}
+
+/* TRACE_FILE_SYSTEM */
+static void ltt_buf_wait_start_hook(struct hook *h, struct buffer_head *bh)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_BUF_WAIT_START, 0, 0, NULL);
+}
+static void ltt_buf_wait_end_hook(struct hook *h, struct buffer_head *bh)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_BUF_WAIT_END, 0, 0, NULL);
+}
+static void ltt_exec_hook(struct hook *h, int len, char *name, struct pt_regs *regs)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_EXEC, 0, len, name);
+}
+static void ltt_ioctl_hook(struct hook *h, unsigned int fd, unsigned int cmd)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_IOCTL, fd, cmd, NULL);
+}
+static void ltt_open_hook(struct hook *h, unsigned int fd, unsigned int len, char *name)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_OPEN, fd, len, name);
+}
+static void ltt_close_hook(struct hook *h, unsigned int fd)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_CLOSE, fd, 0, NULL);
+}
+static void ltt_lseek_hook(struct hook *h, unsigned int fd, off_t offset)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SEEK, fd, offset, NULL);
+}
+static void ltt_llseek_hook(struct hook *h, unsigned int fd, loff_t offset)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SEEK, fd, offset, NULL);
+}
+static void ltt_read_hook(struct hook *h, unsigned int fd, size_t count)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_READ, fd, count, NULL);
+}
+static void ltt_write_hook(struct hook *h, unsigned int fd, size_t count)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_WRITE, fd, count, NULL);
+}
+static void ltt_select_hook(struct hook *h, unsigned int fd, long timeout)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_SELECT, fd, timeout, NULL);
+}
+static void ltt_poll_hook(struct hook *h, unsigned int fd)
+{
+	TRACE_FILE_SYSTEM(TRACE_EV_FILE_SYSTEM_POLL, fd, 0, NULL);
+}
+
+DECLARE_HOOK_REC(buf_wait_start_hook);
+DECLARE_HOOK_REC(buf_wait_end_hook);
+DECLARE_HOOK_REC(exec_hook);
+DECLARE_HOOK_REC(ioctl_hook);
+DECLARE_HOOK_REC(open_hook);
+DECLARE_HOOK_REC(close_hook);
+DECLARE_HOOK_REC(lseek_hook);
+DECLARE_HOOK_REC(llseek_hook);
+DECLARE_HOOK_REC(read_hook);
+DECLARE_HOOK_REC(write_hook);
+DECLARE_HOOK_REC(select_hook);
+DECLARE_HOOK_REC(poll_hook);
+
+static int enable_fs_hooks(void)
+{
+	int rc;
+
+	ltt_buf_wait_start_hook_rec.hook_exit_name = "ltt_buf_wait_start";
+	if ((rc = ltt_hook_register(buf_wait_start_hook)))
+		goto err;
+	ltt_buf_wait_end_hook_rec.hook_exit_name = "ltt_buf_wait_end";
+	if ((rc = ltt_hook_register(buf_wait_end_hook)))
+		goto err1;
+	ltt_exec_hook_rec.hook_exit_name = "ltt_exec";
+	if ((rc = ltt_hook_register(exec_hook)))
+		goto err2;
+	ltt_ioctl_hook_rec.hook_exit_name = "ltt_ioctl";
+	if ((rc = ltt_hook_register(ioctl_hook)))
+		goto err3;
+	ltt_open_hook_rec.hook_exit_name = "ltt_open";
+	if ((rc = ltt_hook_register(open_hook)))
+		goto err4;
+	ltt_close_hook_rec.hook_exit_name = "ltt_close";
+	if ((rc = ltt_hook_register(close_hook)))
+		goto err5;
+	ltt_lseek_hook_rec.hook_exit_name = "ltt_lseek";
+	if ((rc = ltt_hook_register(lseek_hook)))
+		goto err6;
+	ltt_llseek_hook_rec.hook_exit_name = "ltt_llseek";
+	if ((rc = ltt_hook_register(llseek_hook)))
+		goto err7;
+	ltt_read_hook_rec.hook_exit_name = "ltt_read";
+	if ((rc = ltt_hook_register(read_hook)))
+		goto err8;
+	ltt_write_hook_rec.hook_exit_name = "ltt_write";
+	if ((rc = ltt_hook_register(write_hook)))
+		goto err9;
+	ltt_select_hook_rec.hook_exit_name = "ltt_select";
+	if ((rc = ltt_hook_register(select_hook)))
+		goto err10;
+	ltt_poll_hook_rec.hook_exit_name = "ltt_poll";
+	if ((rc = ltt_hook_register(poll_hook)))
+		goto err11;
+	
+	ltt_hook_arm(buf_wait_start_hook);
+	ltt_hook_arm(buf_wait_end_hook);
+	ltt_hook_arm(exec_hook);
+	ltt_hook_arm(ioctl_hook);
+	ltt_hook_arm(open_hook);
+	ltt_hook_arm(close_hook);
+	ltt_hook_arm(lseek_hook);
+	ltt_hook_arm(llseek_hook);
+	ltt_hook_arm(read_hook);
+	ltt_hook_arm(write_hook);
+	ltt_hook_arm(select_hook);
+	ltt_hook_arm(poll_hook);
+	return rc;
+
+err11:	ltt_hook_unregister(select_hook);
+err10:	ltt_hook_unregister(write_hook);
+err9:	ltt_hook_unregister(read_hook);
+err8:	ltt_hook_unregister(llseek_hook);
+err7:	ltt_hook_unregister(lseek_hook);
+err6:	ltt_hook_unregister(close_hook);
+err5:	ltt_hook_unregister(open_hook);
+err4:	ltt_hook_unregister(ioctl_hook);
+err3:	ltt_hook_unregister(exec_hook);
+err2:	ltt_hook_unregister(buf_wait_end_hook);
+err1:	ltt_hook_unregister(buf_wait_start_hook);
+err:	return rc;
+
+}
+
+static int disable_fs_hooks(void)
+{
+	ltt_hook_remove(buf_wait_start_hook);
+	ltt_hook_remove(buf_wait_end_hook);
+	ltt_hook_remove(exec_hook);
+	ltt_hook_remove(ioctl_hook);
+	ltt_hook_remove(open_hook);
+	ltt_hook_remove(close_hook);
+	ltt_hook_remove(lseek_hook);
+	ltt_hook_remove(llseek_hook);
+	ltt_hook_remove(read_hook);
+	ltt_hook_remove(write_hook);
+	ltt_hook_remove(select_hook);
+	ltt_hook_remove(poll_hook);
+	return 0;
+}
+
+/* TRACE_TIMER */
+static void ltt_timer_expired_hook(struct hook *h, struct task_struct *p)
+{
+	TRACE_TIMER(TRACE_EV_TIMER_EXPIRED, 0, 0, 0);
+}
+static void ltt_setitimer_hook(struct hook *h, int which, unsigned long interval, unsigned long value)
+{
+	TRACE_TIMER(TRACE_EV_TIMER_SETITIMER, which, interval, value);
+}
+static void ltt_settimeout_hook(struct hook *h, unsigned long timeout)
+{
+	TRACE_TIMER(TRACE_EV_TIMER_SETTIMEOUT, 0, timeout, 0);
+}
+
+DECLARE_HOOK_REC(setitimer_hook);
+DECLARE_HOOK_REC(timer_expired_hook);
+DECLARE_HOOK_REC(settimeout_hook);
+
+static int enable_timer_hooks(void)
+{
+	int rc;
+
+	ltt_setitimer_hook_rec.hook_exit_name = "ltt_setitimer";
+	if ((rc = ltt_hook_register(setitimer_hook)))
+		goto err;
+	ltt_timer_expired_hook_rec.hook_exit_name = "ltt_timer_expired";
+	if ((rc = ltt_hook_register(timer_expired_hook)))
+		goto err1;
+	ltt_settimeout_hook_rec.hook_exit_name = "ltt_settimeout";
+	if ((rc = ltt_hook_register(settimeout_hook)))
+		goto err2;
+	
+	ltt_hook_arm(setitimer_hook);
+	ltt_hook_arm(timer_expired_hook);
+	ltt_hook_arm(settimeout_hook);
+	return rc;
+
+err2:	ltt_hook_unregister(timer_expired_hook);
+err1:	ltt_hook_unregister(setitimer_hook);
+err:	return rc;
+
+}
+
+static int disable_timer_hooks(void)
+{
+	ltt_hook_remove(setitimer_hook);
+	ltt_hook_remove(timer_expired_hook);
+	ltt_hook_remove(settimeout_hook);
+	return 0;
+}
+
+
+/* TRACE_MEMORY */
+static void ltt_mm_page_alloc_hook(struct hook *h, unsigned int order)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_ALLOC, order);
+}
+static void ltt_mm_page_free_hook(struct hook *h, unsigned int order)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_FREE, order);
+}
+static void ltt_mm_swap_in_hook(struct hook *h, unsigned long address)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_SWAP_IN, address);
+}
+static void ltt_mm_swap_out_hook(struct hook *h, struct page *page)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_SWAP_OUT, ((unsigned long) page));
+}
+static void ltt_page_wait_start_hook(struct hook *h, struct page *page)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_WAIT_START, 0);
+}
+static void ltt_page_wait_end_hook(struct hook *h, struct page *page)
+{
+	TRACE_MEMORY(TRACE_EV_MEMORY_PAGE_WAIT_END, 0);
+}
+
+DECLARE_HOOK_REC(page_wait_start_hook);
+DECLARE_HOOK_REC(page_wait_end_hook);
+DECLARE_HOOK_REC(mm_page_free_hook);
+DECLARE_HOOK_REC(mm_page_alloc_hook);
+DECLARE_HOOK_REC(mm_swap_in_hook);
+DECLARE_HOOK_REC(mm_swap_out_hook);
+
+static int enable_mm_hooks(void)
+{
+	int rc;
+
+	ltt_page_wait_start_hook_rec.hook_exit_name = "ltt_page_wait_start";
+	if ((rc = ltt_hook_register(page_wait_start_hook)))
+		goto err;
+	ltt_page_wait_end_hook_rec.hook_exit_name = "ltt_page_wait_end";
+	if ((rc = ltt_hook_register(page_wait_end_hook)))
+		goto err1;
+	ltt_mm_page_free_hook_rec.hook_exit_name = "ltt_mm_page_free";
+	if ((rc = ltt_hook_register(mm_page_free_hook)))
+		goto err2;
+	ltt_mm_page_alloc_hook_rec.hook_exit_name = "ltt_mm_page_alloc";
+	if ((rc = ltt_hook_register(mm_page_alloc_hook)))
+		goto err3;
+	ltt_mm_swap_in_hook_rec.hook_exit_name = "ltt_mm_swap_in";
+	if ((rc = ltt_hook_register(mm_swap_in_hook)))
+		goto err4;
+	ltt_mm_swap_out_hook_rec.hook_exit_name = "ltt_mm_swap_out";
+	if ((rc = ltt_hook_register(mm_swap_out_hook)))
+		goto err5;
+	
+	ltt_hook_arm(page_wait_start_hook);
+	ltt_hook_arm(page_wait_end_hook);
+	ltt_hook_arm(mm_page_free_hook);
+	ltt_hook_arm(mm_page_alloc_hook);
+	ltt_hook_arm(mm_swap_in_hook);
+	ltt_hook_arm(mm_swap_out_hook);
+	return rc;
+
+err5:	ltt_hook_unregister(mm_swap_in_hook);
+err4:	ltt_hook_unregister(mm_page_alloc_hook);
+err3:	ltt_hook_unregister(mm_page_free_hook);
+err2:	ltt_hook_unregister(page_wait_end_hook);
+err1:	ltt_hook_unregister(page_wait_start_hook);
+err:	return rc;
+
+}
+
+static int disable_mm_hooks(void)
+{
+	ltt_hook_remove(page_wait_start_hook);
+	ltt_hook_remove(page_wait_end_hook);
+	ltt_hook_remove(mm_page_free_hook);
+	ltt_hook_remove(mm_page_alloc_hook);
+	ltt_hook_remove(mm_swap_in_hook);
+	ltt_hook_remove(mm_swap_out_hook);
+	return 0;
+}
+/* TRACE_SOCKET */
+static void ltt_sk_send_hook(struct hook *h, int type, int size)
+{
+	TRACE_SOCKET(TRACE_EV_SOCKET_SEND, type, size);
+}
+
+static void ltt_sk_receive_hook(struct hook *h, int type, int size)
+{
+	TRACE_SOCKET(TRACE_EV_SOCKET_RECEIVE, type, size);
+}
+
+static void ltt_sk_create_hook(struct hook *h, int retval, int type)
+{
+	TRACE_SOCKET(TRACE_EV_SOCKET_CREATE, retval, type);
+}
+
+static void ltt_sk_call_hook(struct hook *h, int call, unsigned long a0)
+{
+	TRACE_SOCKET(TRACE_EV_SOCKET_CALL, call, a0);
+}
+
+DECLARE_HOOK_REC(sk_send_hook);
+DECLARE_HOOK_REC(sk_receive_hook);
+DECLARE_HOOK_REC(sk_create_hook);
+DECLARE_HOOK_REC(sk_call_hook);
+
+static int enable_socket_hooks(void)
+{
+	int rc;
+
+	ltt_sk_send_hook_rec.hook_exit_name = "ltt_sk_send";
+	if ((rc = ltt_hook_register(sk_send_hook)))
+		goto err;
+	ltt_sk_receive_hook_rec.hook_exit_name = "ltt_sk_receive";
+	if ((rc = ltt_hook_register(sk_receive_hook)))
+		goto err1;
+	ltt_sk_create_hook_rec.hook_exit_name = "ltt_sk_create";
+	if ((rc = ltt_hook_register(sk_create_hook)))
+		goto err2;
+	ltt_sk_call_hook_rec.hook_exit_name = "ltt_sk_call";
+	if ((rc = ltt_hook_register(sk_call_hook)))
+		goto err3;
+	
+	ltt_hook_arm(sk_send_hook);
+	ltt_hook_arm(sk_receive_hook);
+	ltt_hook_arm(sk_create_hook);
+	ltt_hook_arm(sk_call_hook);
+	return rc;
+
+err3:	ltt_hook_unregister(sk_create_hook);
+err2:	ltt_hook_unregister(sk_receive_hook);
+err1:	ltt_hook_unregister(sk_send_hook);
+err:	return rc;
+
+}
+
+static int disable_socket_hooks(void)
+{
+	ltt_hook_remove(sk_send_hook);
+	ltt_hook_remove(sk_receive_hook);
+	ltt_hook_remove(sk_create_hook);
+	ltt_hook_remove(sk_call_hook);
+	return 0;
+}
+
+/* TRACE_IPC */
+static void ltt_ipc_call_hook(struct hook *h, unsigned int call, int first)
+{
+	TRACE_IPC(TRACE_EV_IPC_CALL, call, first);
+}
+static void ltt_ipc_msg_create_hook(struct hook *h, int err, int flag)
+{
+	TRACE_IPC(TRACE_EV_IPC_MSG_CREATE, err, flag);
+}
+static void ltt_ipc_sem_create_hook(struct hook *h, int err, int flag)
+{
+	TRACE_IPC(TRACE_EV_IPC_SEM_CREATE, err, flag);
+}
+static void ltt_ipc_shm_create_hook(struct hook *h, int err, int flag)
+{
+	TRACE_IPC(TRACE_EV_IPC_SHM_CREATE, err, flag);
+}
+
+DECLARE_HOOK_REC(ipc_call_hook);
+DECLARE_HOOK_REC(ipc_msg_create_hook);
+DECLARE_HOOK_REC(ipc_sem_create_hook);
+DECLARE_HOOK_REC(ipc_shm_create_hook);
+
+static int enable_ipc_hooks(void)
+{
+	int rc;
+
+	ltt_ipc_call_hook_rec.hook_exit_name = "ltt_ipc_call";
+	if ((rc = ltt_hook_register(ipc_call_hook)))
+		goto err;
+	ltt_ipc_msg_create_hook_rec.hook_exit_name = "ltt_ipc_msg_create";
+	if ((rc = ltt_hook_register(ipc_msg_create_hook)))
+		goto err1;
+	ltt_ipc_sem_create_hook_rec.hook_exit_name = "ltt_ipc_sem_create";
+	if ((rc = ltt_hook_register(ipc_sem_create_hook)))
+		goto err2;
+	ltt_ipc_shm_create_hook_rec.hook_exit_name = "ltt_ipc_shm_create";
+	if ((rc = ltt_hook_register(ipc_shm_create_hook)))
+		goto err3;
+	
+	ltt_hook_arm(ipc_call_hook);
+	ltt_hook_arm(ipc_msg_create_hook);
+	ltt_hook_arm(ipc_sem_create_hook);
+	ltt_hook_arm(ipc_shm_create_hook);
+	return rc;
+
+err3:	ltt_hook_unregister(ipc_sem_create_hook);
+err2:	ltt_hook_unregister(ipc_msg_create_hook);
+err1:	ltt_hook_unregister(ipc_call_hook);
+err:	return rc;
+
+}
+
+static int disable_ipc_hooks(void)
+{
+	ltt_hook_remove(ipc_call_hook);
+	ltt_hook_remove(ipc_msg_create_hook);
+	ltt_hook_remove(ipc_sem_create_hook);
+	ltt_hook_remove(ipc_shm_create_hook);
+	return 0;
+}
+
+/* TRACE_NETWORK */
+static void ltt_net_pkt_out_hook(struct hook *h, unsigned short protocol)
+{
+	TRACE_NETWORK(TRACE_EV_NETWORK_PACKET_OUT, protocol);
+}
+
+static void ltt_net_pkt_in_hook(struct hook *h, unsigned short protocol)
+{
+	TRACE_NETWORK(TRACE_EV_NETWORK_PACKET_IN, protocol);
+}
+
+DECLARE_HOOK_REC(net_pkt_out_hook);
+DECLARE_HOOK_REC(net_pkt_in_hook);
+
+static int enable_net_hooks(void)
+{
+	int rc;
+
+	ltt_net_pkt_out_hook_rec.hook_exit_name = "ltt_net_pkt_out";
+	if ((rc = ltt_hook_register(net_pkt_out_hook)))
+		goto err;
+	ltt_net_pkt_in_hook_rec.hook_exit_name = "ltt_net_pkt_in";
+	if ((rc = ltt_hook_register(net_pkt_in_hook)))
+		goto err1;
+	
+	ltt_hook_arm(net_pkt_out_hook);
+	ltt_hook_arm(net_pkt_in_hook);
+	return rc;
+
+err1:	ltt_hook_unregister(net_pkt_out_hook);
+err:	return rc;
+
+}
+
+static int disable_net_hooks(void)
+{
+	ltt_hook_remove(net_pkt_out_hook);
+	ltt_hook_remove(net_pkt_in_hook);
+	return 0;
+}
+
+typedef int (*enable_fn_t)(void);
+
+static enable_fn_t enable[TRACE_EV_MAX + 1][2] =
+{
+	{ NULL, NULL},							/* TRACE_START */
+	{ disable_pre_syscall_hooks, enable_pre_syscall_hooks},		/* TRACE_SYSCALL_ENTRY */
+	{ disable_post_syscall_hooks, enable_post_syscall_hooks},	/* TRACE_SYSCALL_EXIT */
+	{ disable_trap_entry_hooks, enable_trap_entry_hooks},		/* TRACE_TRAP_ENTRY */
+	{ disable_trap_exit_hooks, enable_trap_exit_hooks},		/* TRACE_TRAP_EXIT */
+	{ disable_irq_entry_hooks, enable_irq_entry_hooks},		/* TRACE_IRQ_ENTRY */
+	{ disable_irq_exit_hooks, enable_irq_exit_hooks},		/* TRACE_IRQ_EXIT */
+	{ disable_schedchange_hooks, enable_schedchange_hooks},		/* TRACE_SCHEDCHANGE */
+	{ disable_kernel_timer_hooks, enable_kernel_timer_hooks},	/* TRACE_KERNEL_TIMER */
+	{ disable_softirq_hooks, enable_softirq_hooks},			/* TRACE_SOFT_IRQ */
+	{ disable_process_hooks, enable_process_hooks},			/* TRACE_PROCESS */
+	{ disable_fs_hooks, enable_fs_hooks},				/* TRACE_FILE_SYSTEM */
+	{ disable_timer_hooks, enable_timer_hooks},			/* TRACE_MEMORY */
+	{ disable_mm_hooks, enable_mm_hooks},				/* TRACE_MEMORY */
+	{ disable_socket_hooks, enable_socket_hooks},			/* TRACE_SOCKET */
+	{ disable_ipc_hooks, enable_ipc_hooks},				/* TRACE_IPC */
+	{ disable_net_hooks, enable_net_hooks},				/* TRACE_NETWORK */
+	{ NULL, NULL},							/* TRACE_BUFFER_START */
+	{ NULL, NULL},							/* TRACE_BUFFER_END */
+	{ NULL, NULL},							/* TRACE_NEW_EVENT */
+	{ NULL, NULL},							/* TRACE_CUSTOM */
+	{ NULL, NULL}							/* TRACE_CHANGE_MASK */
+};
+
+static trace_event_mask prev_mask;
+void change_traced_events(trace_event_mask *mask)
+{
+	int i = 0;
+	enable_fn_t fn;
+	
+	trace_event_mask changes;	/* zero bit indicates change */
+
+	if (!mask) {
+		/* disable all existing hooks, tracing is being stopped */
+		changes = ~prev_mask;
+		memset(&prev_mask, 0, sizeof(prev_mask));
+		mask = &prev_mask;
+	} else {
+		changes = ~(prev_mask ^ (*mask));
+		memcpy(&prev_mask, mask, sizeof(*mask));
+	}
+
+repeat:
+	i = find_next_zero_bit((const unsigned long *)&changes, sizeof(changes), i);
+	if (i <= TRACE_EV_MAX) {
+		if (test_bit(i, (const unsigned long *)mask)) {
+			fn = enable[i][1];
+		} else {
+			fn = enable[i][0];
+		}
+		if (fn) {
+			fn();
+		}
+		i++;
+		goto repeat;
+	}
+
+#ifdef CONFIG_SMP
+	/*
+	 * Wait to ensure that no other processor could possibly be
+	 * inside any of our hook exit functions.
+	 *
+	 * sychornize_kernel is available on UL kernels. We need an
+	 * equivalent on other 2.4 kernels.
+	 */
+	synchronize_kernel();
+#endif
+	return;
+}
Index: linux.t/kernel/ltt/mips_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/mips_syscall.c	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/mips_syscall.c	2004-03-22 20:25:22.631680518 -0500
@@ -0,0 +1,77 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* mips */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+	unsigned long       addr;
+	int                 depth = 0;
+	unsigned long       end_code;
+	unsigned long       lower_bound;
+	int                 seek_depth;
+	unsigned long       *stack;
+	unsigned long       start_code;
+	unsigned long       *start_stack;
+	trace_syscall_entry trace_syscall_event;
+	unsigned long       upper_bound;
+	int                 use_bounds;
+	int                 use_depth;
+
+	/* syscall_id will be negative for SVR4, IRIX5, BSD43, and POSIX
+	 * syscalls -- these are not supported at this point by LTT
+	 */
+	trace_syscall_event.syscall_id = (uint8_t) (regs->regs[2] - __NR_Linux);
+
+	trace_syscall_event.address  = regs->cp0_epc;
+
+	if (!user_mode(regs))
+		goto trace_syscall_end;
+
+	if (ltt_get_trace_config(&use_depth,
+			     &use_bounds,
+			     &seek_depth,
+			     (void*)&lower_bound,
+			     (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	/* Heuristic that might work:
+	 * (BUT DOESN'T WORK for any of the cases I tested...) zzz
+	 * Search through stack until a value is found that is within the
+	 * range start_code .. end_code.  (This is looking for a return
+	 * pointer to where a shared library was called from.)  If a stack
+	 * variable contains a valid code address then an incorrect
+	 * result will be generated.
+	 */
+	if ((use_depth == 1) || (use_bounds == 1)) {
+		stack       = (unsigned long*) regs->regs[29];
+		end_code    = current->mm->end_code;
+		start_code  = current->mm->start_code;
+		start_stack = (unsigned long *)current->mm->start_stack;
+
+		while ((stack <= start_stack) && (!__get_user(addr, stack))) {
+			if ((addr > start_code) && (addr < end_code)) {
+				if (((use_depth  == 1) && (depth == seek_depth)) ||
+				    ((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound))) {
+					trace_syscall_event.address = addr;
+					goto trace_syscall_end;
+				} else {
+					depth++;
+				}
+			}
+		stack++;
+		}
+	}
+
+trace_syscall_end:
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/Makefile
===================================================================
--- linux.t.orig/kernel/ltt/Makefile	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/Makefile	2004-03-22 20:25:22.623682876 -0500
@@ -0,0 +1,31 @@
+#
+# Makefile for the kernel tracing drivers.
+#
+
+# Multipart objects.
+
+ltt_driver-objs	:= ltt-core.o ltt-core_hooks.o
+
+
+# Optional parts of multipart objects.
+ifeq ($(CONFIG_ARM),y)
+ltt_driver-objs	+= arm_syscall.o
+endif
+ifeq ($(CONFIG_X86),y)
+ltt_driver-objs	+= i386_syscall.o
+endif
+ifeq ($(CONFIG_MIPS32),y)
+ltt_driver-objs	+= mips_syscall.o
+endif
+ifeq ($(CONFIG_PPC32),y)
+ltt_driver-objs	+= ppc_syscall.o
+endif
+ifeq ($(CONFIG_ARCH_S390),y)
+ltt_driver-objs	+= s390_syscall.o
+endif
+ifeq ($(CONFIG_SUPERH),y)
+ltt_driver-objs	+= sh_syscall.o
+endif
+
+obj-$(CONFIG_LTT)	+= ltt_driver.o
+
Index: linux.t/kernel/ltt/sh_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/sh_syscall.c	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/sh_syscall.c	2004-03-22 20:25:22.633679928 -0500
@@ -0,0 +1,79 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* sh */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+	int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+	int                 seek_depth;
+	unsigned long       lower_bound;
+	unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+	/* Set the syscall ID */
+	trace_syscall_event.syscall_id = (uint8_t) regs->regs[REG_REG0+3];
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = regs->pc;
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!user_mode(regs))
+		/* Don't go digining anywhere */
+		goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(ltt_get_trace_config(&use_depth, &use_bounds, &seek_depth,
+	   (void*)&lower_bound, (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	{
+		/* Start at the top of the stack (bottom address since stacks grow downward) */
+		stack = (unsigned long*) regs->regs[REG_REG15];
+
+		/* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+		while(!get_user(addr, stack))
+		{
+			/* Does this LOOK LIKE an address in the program */
+			/* TODO: does this work with shared libraries?? - Greg Banks */
+			if((addr > current->mm->start_code) &&(addr < current->mm->end_code))
+			{
+				/* Does this address fit the description */
+				if(((use_depth == 1) && (depth == seek_depth))
+				   ||((use_bounds == 1) && (addr > lower_bound)
+				   && (addr < upper_bound)))
+				{
+					/* Set the address */
+					trace_syscall_event.address = addr;
+
+					/* We're done */
+					goto trace_syscall_end;
+				}
+				else
+					/* We're one depth more */
+					depth++;
+			}
+			/* Go on to the next address */
+			stack++;
+		}
+	}
+
+trace_syscall_end:
+	/* Trace the event */
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/s390_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/s390_syscall.c	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/s390_syscall.c	2004-03-22 20:25:22.633679928 -0500
@@ -0,0 +1,92 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* s390 */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{                                                              
+	int		    use_depth;	                 
+        int                 use_bounds;                        
+        int                 depth = 0;                         
+        int                 seek_depth;                        
+        unsigned long       lower_bound;                       
+        unsigned long       upper_bound;                       
+        unsigned long       addr;                              
+        unsigned long*      stack;
+        unsigned long       temp_stack;
+        trace_syscall_entry trace_syscall_event;               
+        /* Set the syscall ID                               */ 
+        /* Register 8 is setup just prior to the call       */ 
+        /* This instruction is just following linkage       */ 
+        /* so it's ok.  If moved and chance of R8 being     */ 
+        /* clobbered, would need to dig it out of the stack */ 
+        __asm__ volatile(                                      
+        "  stc  8,%0\n\t"                                      
+        : "=m" (trace_syscall_event.syscall_id));              
+        /* get the psw address */                              
+        trace_syscall_event.address  = regs->psw.addr;         
+        /* and off the hi-order bit */                                          
+        trace_syscall_event.address &= PSW_ADDR_MASK;                           
+        if(!(user_mode(regs))) /* if kernel mode, return */                     
+           goto trace_syscall_end;                                              
+        /* Get the trace configuration - if none, return */                     
+        if(ltt_get_trace_config(&use_depth,                                         
+                            &use_bounds,                                        
+                            &seek_depth,                                        
+                            (void*)&lower_bound,                                
+                            (void*)&upper_bound) < 0)                           
+          goto trace_syscall_end;                                               
+        /* Do we have to search for an instruction pointer address range */     
+        if((use_depth == 1) || (use_bounds == 1))                               
+        {                                                                       
+          /* Start at the top of the stack */                                   
+          /* stack pointer is register 15 */                                    
+          stack = (unsigned long*) regs->gprs[15]; /* stack pointer */      
+          /* Keep on going until we reach the end of the process' stack limit */
+          do
+          {
+            get_user(addr,stack+14);  /* get the program address +0x38 */ 
+            /* and off the hi-order bit */
+            addr &= PSW_ADDR_MASK;                                
+            /* Does this LOOK LIKE an address in the program */
+            if ((addr > current->mm->start_code)               
+               &&(addr < current->mm->end_code))               
+            { 
+              /* Does this address fit the description */      
+              if(((use_depth == 1) && (depth == seek_depth))   
+                ||((use_bounds == 1) && (addr > lower_bound)   
+                && (addr < upper_bound)))
+                {
+                  /* Set the address */   
+                  trace_syscall_event.address = addr; 
+                  /* We're done */                             
+                  goto trace_syscall_end;                      
+                }                                              
+              else                                             
+                /* We're one depth more */                     
+                depth++; 
+            }
+            /* Go on to the next address */
+            get_user(temp_stack,stack); /* get contents of stack */
+            temp_stack &= PSW_ADDR_MASK; /* and off hi order bit */
+            stack = (unsigned long *)temp_stack; /* move into stack */
+            /* stack may or may not go to zero when end hit               */
+            /* using 0x7fffffff-_STK_LIM to validate that the address is  */
+            /* within the range of a valid stack address                  */
+            /* If outside that range, exit the loop, stack end must have  */
+            /* been hit.                                                  */
+          } while (stack >= (unsigned long *)(0x7fffffff-_STK_LIM));
+        }                                                         
+trace_syscall_end:                                                
+        /* Trace the event */                                     
+        ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}                                                                 
Index: linux.t/kernel/ltt/arm_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/arm_syscall.c	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/arm_syscall.c	2004-03-22 20:25:22.623682876 -0500
@@ -0,0 +1,74 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* arm */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+	int			scno = 0;
+	int			depth = 0;
+	unsigned long           end_code;
+	unsigned long		*fp;			/* frame pointer */
+	unsigned long		lower_bound;
+	unsigned long		lr;			/* link register */
+	unsigned long		*prev_fp;
+	int			seek_depth;
+	unsigned long           start_code;
+	unsigned long           *start_stack;
+	trace_syscall_entry	trace_syscall_event;
+	unsigned long		upper_bound;
+	int			use_bounds;
+	int			use_depth;
+
+	/* TODO: get_scno */
+	trace_syscall_event.syscall_id = (uint8_t)scno;
+	trace_syscall_event.address    = instruction_pointer(regs);
+	
+	if (! (user_mode(regs) ))
+		goto trace_syscall_end;
+
+	if (ltt_get_trace_config(&use_depth,
+			     &use_bounds,
+			     &seek_depth,
+			     (void*)&lower_bound,
+			     (void*)&upper_bound) < 0)
+		goto trace_syscall_end;
+
+	if ((use_depth == 1) || (use_bounds == 1)) {
+		fp          = (unsigned long *)regs->ARM_fp;
+		end_code    = current->mm->end_code;
+		start_code  = current->mm->start_code;
+		start_stack = (unsigned long *)current->mm->start_stack;
+
+		while (!__get_user(lr, (unsigned long *)(fp - 1))) {
+			if ((lr > start_code) && (lr < end_code)) {
+				if (((use_depth == 1) && (depth >= seek_depth)) ||
+				    ((use_bounds == 1) && (lr > lower_bound) && (lr < upper_bound))) {
+					trace_syscall_event.address = lr;
+					goto trace_syscall_end;
+				} else {
+					depth++;
+				}
+			}
+
+			if ((__get_user((unsigned long)prev_fp, (fp - 3))) ||
+			    (prev_fp > start_stack) ||
+			    (prev_fp <= fp)) {
+				goto trace_syscall_end;
+			}
+			fp = prev_fp;
+		}
+	}
+
+trace_syscall_end:
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/i386_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/i386_syscall.c	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/i386_syscall.c	2004-03-22 20:25:22.624682581 -0500
@@ -0,0 +1,81 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <linux/ltt.h>
+#include <asm/uaccess.h>
+
+/* i386 */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+        int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+        int                 seek_depth;
+        unsigned long       lower_bound;
+        unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+        /* Set the syscall ID */
+        trace_syscall_event.syscall_id = (uint8_t) regs->orig_eax;
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = regs->eip;
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!(regs->xcs & 3))
+	  /* Don't go diging anywhere */
+	  goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(ltt_get_trace_config(&use_depth,
+			    &use_bounds,
+			    &seek_depth,
+			    (void*)&lower_bound,
+			    (void*)&upper_bound) < 0)
+	  goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	  {
+	  /* Start at the top of the stack (bottom address since stacks grow downward) */
+	  stack = (unsigned long*) regs->esp;
+
+	  /* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+	  while(!get_user(addr, stack))
+	    {
+	    /* Does this LOOK LIKE an address in the program */
+	    if((addr > current->mm->start_code)
+             &&(addr < current->mm->end_code))
+	      {
+	      /* Does this address fit the description */
+	      if(((use_depth == 1) && (depth == seek_depth))
+               ||((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound)))
+		{
+		/* Set the address */
+		trace_syscall_event.address = addr;
+
+		/* We're done */
+		goto trace_syscall_end;
+		}
+	      else
+		/* We're one depth more */
+		depth++;
+	      }
+	    /* Go on to the next address */
+	    stack++;
+	    }
+	  }
+
+trace_syscall_end:
+	/* Trace the event */
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/ppc_syscall.c
===================================================================
--- linux.t.orig/kernel/ltt/ppc_syscall.c	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/ppc_syscall.c	2004-03-22 20:25:22.632680223 -0500
@@ -0,0 +1,88 @@
+/*
+ * drivers/trace/xxx_syscall.c
+ *
+ * This code is distributed under the GPL license
+ *
+ * System call tracing.
+ */
+#include <linux/kernel.h>
+#include <linux/ptrace.h>
+#include <linux/sched.h>
+#include <asm/uaccess.h>
+#include <linux/ltt.h>
+
+/* ppc */
+asmlinkage void ltt_pre_syscall(struct pt_regs * regs)
+{
+        int                 use_depth;
+	int                 use_bounds;
+	int                 depth = 0;
+        int                 seek_depth;
+        unsigned long       lower_bound;
+        unsigned long       upper_bound;
+	unsigned long       addr;
+	unsigned long*      stack;
+	trace_syscall_entry trace_syscall_event;
+
+        /* Set the syscall ID */
+	trace_syscall_event.syscall_id = (uint8_t) regs->gpr[0];
+
+	/* Set the address in any case */
+	trace_syscall_event.address  = instruction_pointer(regs);
+
+	/* Are we in the kernel (This is a kernel thread)? */
+	if(!user_mode(regs))
+	  /* Don't go digining anywhere */
+	  goto trace_syscall_end;
+
+	/* Get the trace configuration */
+	if(ltt_get_trace_config(&use_depth,
+			    &use_bounds,
+			    &seek_depth,
+			    (void*)&lower_bound,
+			    (void*)&upper_bound) < 0)
+	  goto trace_syscall_end;
+
+	/* Do we have to search for an eip address range */
+	if((use_depth == 1) || (use_bounds == 1))
+	  {
+	  /* Start at the top of the stack (bottom address since stacks grow downward) */
+	  stack = (unsigned long*) regs->gpr[1];
+
+	  /* Skip over first stack frame as the return address isn't valid */
+	  if(get_user(addr, stack))
+	    goto trace_syscall_end;
+	  stack = (unsigned long*) addr;
+
+	  /* Keep on going until we reach the end of the process' stack limit (wherever it may be) */
+	  while(!get_user(addr, stack + 1)) /* "stack + 1", since this is where the IP is */
+	    {
+	    /* Does this LOOK LIKE an address in the program */
+	    if((addr > current->mm->start_code)
+             &&(addr < current->mm->end_code))
+	      {
+	      /* Does this address fit the description */
+	      if(((use_depth == 1) && (depth == seek_depth))
+               ||((use_bounds == 1) && (addr > lower_bound) && (addr < upper_bound)))
+		{
+		/* Set the address */
+		trace_syscall_event.address = addr;
+
+		/* We're done */
+		goto trace_syscall_end;
+		}
+	      else
+		/* We're one depth more */
+		depth++;
+	      }
+	    /* Go on to the next address */
+	    if(get_user(addr, stack))
+	      goto trace_syscall_end;
+	    stack = (unsigned long*) addr;
+	    }
+	  }
+
+trace_syscall_end:
+	/* Trace the event */
+	ltt_log_event(TRACE_EV_SYSCALL_ENTRY, &trace_syscall_event);
+}
Index: linux.t/kernel/ltt/ltt-core.c
===================================================================
--- linux.t.orig/kernel/ltt/ltt-core.c	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/kernel/ltt/ltt-core.c	2004-03-22 20:25:22.628681402 -0500
@@ -0,0 +1,2404 @@
+/*
+ * ltt-core.c
+ *
+ * (C) Copyright, 1999, 2000, 2001, 2002, 2003, 2004 -
+ *              Karim Yaghmour (karim@opersys.com)
+ *
+ * Contains the kernel code for the Linux Trace Toolkit.
+ *
+ * Author:
+ *	Karim Yaghmour (karim@opersys.com)
+ *
+ * Changelog:
+ *	24/01/04, Revamped tracer to rely entirely on relayfs, no sys_trace.
+ *		Renamed all relevant files and functions from trace* to ltt*.
+ *	14/03/03, Modified to use relayfs (zanussi@us.ibm.com)
+ *	15/10/02, Changed tracer from device to kernel subsystem and added
+ *		custom trace system call (sys_trace).
+ *	01/10/02, Coding style change to fit with kernel coding style.
+ *	16/02/02, Added Tom Zanussi's implementation of K42's lockless logging.
+ *		K42 tracing guru Robert Wisniewski participated in the
+ *		discussions surrounding this implementation. A big thanks to
+ *		the IBM folks.
+ *	03/12/01, Added user event support.
+ *	05/01/01, Modified PPC bit manipulation functions for x86
+ *		compatibility (andy_lowe@mvista.com).
+ *	15/11/00, Finally fixed memory allocation and remapping method. Now
+ *		using BTTV-driver-inspired code.
+ *	13/03/00, Modified tracer so that the daemon mmaps the tracer's buffers
+ *		in it's address space rather than use "read".
+ *	26/01/00, Added support for standardized buffer sizes and extensibility
+ *		of events.
+ *	01/10/99, Modified tracer in order to used double-buffering.
+ *	28/09/99, Adding tracer configuration support.
+ *	09/09/99, Changing the format of an event record in order to reduce the
+ *		size of the traces.
+ *	04/03/99, Initial typing.
+ *
+ * Note:
+ *	The sizes of the variables used to store the details of an event are
+ *	planned for a system who gets at least one clock tick every 10 
+ *	milli-seconds. There has to be at least one event every 2^32-1
+ *	microseconds, otherwise the size of the variable holding the time
+ *	doesn't work anymore.
+ */
+
+#include <linux/init.h>
+#include <linux/ltt.h>
+#include <linux/errno.h>
+#include <linux/stddef.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/sched.h>
+#include <linux/string.h>
+#include <linux/time.h>
+#include <linux/vmalloc.h>
+#include <linux/mm.h>
+#include <linux/mman.h>
+#include <linux/delay.h>
+#include <linux/proc_fs.h>
+
+#include <asm/io.h>
+#include <asm/current.h>
+#include <asm/uaccess.h>
+#include <asm/bitops.h>
+#include <asm/pgtable.h>
+#include <asm/relay.h>
+#include <asm/ltt.h>
+
+/* Tracer configuration */
+static int		num_cpus;
+
+/* System call tracing behavior */
+static int		use_syscall_eip_bounds;
+static int		lower_eip_bound_set;
+static int		upper_eip_bound_set;
+static void*		lower_eip_bound;
+static void*		upper_eip_bound;
+static int		syscall_eip_depth_set;
+static int		syscall_eip_depth;
+
+static int		fetch_syscall_eip_use_depth;
+static int		fetch_syscall_eip_use_bounds;
+static void*		syscall_lower_eip_bound;
+static void*		syscall_upper_eip_bound;
+
+/* Data buffer management */
+static struct trace_struct	current_traces[NR_TRACES];
+static u32			start_reserve = TRACER_FIRST_EVENT_SIZE;
+static u32			end_reserve = TRACER_LAST_EVENT_SIZE;
+static u32			trace_start_reserve = TRACER_START_TRACE_EVENT_SIZE;
+static struct rchan_callbacks	ltt_callbacks;		/* relayfs callbacks */
+static struct ltt_arch_info	ltt_arch_info;
+static struct buf_control_info	shared_buf_ctl;
+static char *			user_event_data = NULL;
+
+/* Timer management */
+static struct timer_list	heartbeat_timer;
+static struct timer_list	percpu_timer[NR_CPUS] __cacheline_aligned;
+
+/* /proc variables */
+static struct proc_dir_entry *	ltt_proc_root_entry; /* proc/trace */
+static int			tmp_rchan_handles[NR_CPUS];
+static char			relayfs_path[PATH_MAX];	/* path to attribs */
+static char			relay_file_name[PATH_MAX];/* scratch area */
+
+/* Forward declarations */
+static struct proc_dir_entry *create_handle_proc_dir(unsigned trace_handle);
+static void remove_handle_proc_dir(struct proc_dir_entry *handle_dir,
+				   unsigned trace_handle);
+
+/* Size of statically defined events */
+int event_struct_size[TRACE_EV_MAX + 1] =
+{
+	sizeof(trace_start),
+	sizeof(trace_syscall_entry),
+	0,				/* TRACE_SYSCALL_EXIT */
+	sizeof(trace_trap_entry),
+	0,				/* TRACE_TRAP_EXIT */
+	sizeof(trace_irq_entry),
+	0,				/* TRACE_IRQ_EXIT */
+	sizeof(trace_schedchange),
+	0,				/* TRACE_KERNEL_TIMER */
+	sizeof(trace_soft_irq),
+	sizeof(trace_process),
+	sizeof(trace_file_system),
+	sizeof(trace_timer),
+	sizeof(trace_memory),
+	sizeof(trace_socket),
+	sizeof(trace_ipc),
+	sizeof(trace_network),
+	sizeof(trace_buffer_start),
+	sizeof(trace_buffer_end),
+	sizeof(trace_new_event),
+	sizeof(trace_custom),
+	sizeof(trace_change_mask),
+	0				/* TRACE_HEARTBEAT */
+};
+
+/* Custom event description */
+struct custom_event_desc {
+	trace_new_event event;
+
+	pid_t owner_pid;
+
+	struct custom_event_desc *next;
+	struct custom_event_desc *prev;
+};
+
+/* Custom event management */
+static int			next_event_id = TRACE_EV_MAX + 1;
+static rwlock_t			custom_list_lock = RW_LOCK_UNLOCKED;
+static rwlock_t			trace_handle_table_lock = RW_LOCK_UNLOCKED;
+static struct custom_event_desc	custom_events_head;
+static struct custom_event_desc	*custom_events = NULL;
+
+/* Handle management */
+struct trace_handle_struct{
+	struct task_struct	*owner;
+};
+static struct trace_handle_struct trace_handle_table[TRACE_MAX_HANDLES];
+
+/**
+ *	set_waiting_for_cpu_async: - Utility function for setting wait flags
+ *	@cpu_id: which CPU to set flag on
+ *	@bit: which bit to set
+ */
+static inline void set_waiting_for_cpu_async(unsigned int trace_handle, u8 cpu_id, int bit)
+{
+	atomic_set(&waiting_for_cpu_async(trace_handle, cpu_id), 
+		   atomic_read(&waiting_for_cpu_async(trace_handle, cpu_id)) | bit);
+}
+
+/**
+ *	clear_waiting_for_cpu_async: - Utility function for clearing wait flags
+ *	@cpu_id: which CPU to clear flag on
+ *	@bit: which bit to clear
+ */
+static inline void clear_waiting_for_cpu_async(unsigned int trace_handle, u8 cpu_id, int bit)
+{
+	atomic_set(&waiting_for_cpu_async(trace_handle, cpu_id), 
+		   atomic_read(&waiting_for_cpu_async(trace_handle, cpu_id)) & ~bit);
+}
+
+
+/**
+ *	init_trace: - Initialize a trace/flight recorder instance
+ *	@trace_struct: trace/flight recorder struct
+ *
+ *	Initialize a trace instance to default values.
+ */
+static void init_trace(struct trace_struct *trace)
+{
+	trace->trace_handle = 0;
+	
+	trace->active = NULL;
+	trace->paused = 0;
+	trace->flight_recorder = 1;
+	trace->daemon_task_struct = NULL;
+	trace->trace_start_data = NULL;
+	
+	trace->tracer_started = 0;
+	trace->tracer_stopping = 0;
+	trace->proc_dir_entry = NULL;
+	trace->traced_events = 0;
+	trace->log_event_details_mask = 0;
+	trace->log_cpuid = 0;
+	trace->tracing_pid = 0;
+	trace->tracing_pgrp = 0;
+	trace->tracing_gid = 0;
+	trace->tracing_uid = 0;
+	trace->traced_pid = 0;
+	trace->traced_pgrp = 0;
+	trace->traced_gid = 0;
+	trace->traced_uid = 0;
+	trace->use_locking = 1;
+	trace->n_buffers = 0;
+	trace->buf_size = 0;
+	trace->using_tsc = 0;
+
+	trace->buffer_switches_pending = 0;
+}
+
+/*
+ * Trace heartbeat
+ */
+
+/**
+ *	write_heartbeat_event: - Timer function generating hearbeat event.
+ *	@data: unused
+ *
+ *	Guarantees at least 1 event is logged before low word of TSC wraps.
+ */
+static void write_heartbeat_event(unsigned long data)
+{
+	unsigned long int flags;
+	int i, j;
+	
+	local_irq_save(flags);
+	for (i = 0; i < NR_TRACES; i++) {
+		if (current_traces[i].active && current_traces[i].using_tsc) {
+			for (j =  0; j < num_cpus; j++)
+				set_waiting_for_cpu_async(i, j, LTT_TRACE_HEARTBEAT);
+		}
+	}
+	local_irq_restore(flags);
+
+	del_timer(&heartbeat_timer);
+	heartbeat_timer.expires = jiffies + 0xffffffffUL/loops_per_jiffy - 1;
+	add_timer(&heartbeat_timer);
+}
+
+/**
+ *	syscall_active: - If any active trace is logging syscalls, return 1
+ *	@syscall_type: either SYSCALL_ENTRY or SYSCALL_EXIT
+ *
+ *	Returns 1 if any channel is tracing syscalls, 0 otherwise
+ *
+ *	Needed for setting/clearing the global syscall...active variables
+ *	in order to reflect the needs of all traces.
+ */
+int syscall_active(int syscall_type)
+{
+	int i, retval = 0;
+	struct trace_struct *trace;
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		trace = &current_traces[i];
+		if (!trace->active)
+			continue;
+		if(ltt_test_bit(syscall_type, &trace->traced_events))
+			retval = 1;
+	}
+
+	return retval;
+}
+
+/**
+ *	need_heartbeat: - If any active trace uses TSC timestamping, return 1
+ *
+ *	Returns the number of active traces using TSC timestamping
+ *
+ *	Needed for starting/stopping the heartbeat timer depending on whether
+ *	any trace needs it or not.
+ */
+int need_heartbeat(void)
+{
+	int i, retval = 0;
+	struct trace_struct *trace;
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		trace = &current_traces[i];
+		if(trace->active && trace->using_tsc)
+			retval++;
+	}
+
+	return retval;
+}
+
+/**
+ *	init_heartbeat_timer: - Start timer generating hearbeat events.
+ */
+static void init_heartbeat_timer(void)
+{
+	if (loops_per_jiffy > 0) {
+		init_timer(&heartbeat_timer);
+		heartbeat_timer.function = write_heartbeat_event;
+		heartbeat_timer.expires = jiffies 
+			+ 0xffffffffUL/loops_per_jiffy - 1;
+		add_timer(&heartbeat_timer);
+	}
+	else
+		printk(KERN_ALERT "LTT: No TSC for heartbeat timer - continuing without one \n");
+}
+
+/*
+ * Tasks and timers for trace finalization
+ */
+
+/**
+ *	all_channels_finalized: - Verify that all channels have been finalized.
+ *	@trace_handle: the trace containing the channels to be tested
+ *
+ *	Returns 1 if channels on all CPUs are complete, 0 otherwise.
+ */
+static int all_channels_finalized(unsigned int trace_handle)
+{
+	int i;
+	
+	for (i = 0; i < num_cpus; i++)
+		if (atomic_read(&waiting_for_cpu_async(trace_handle, i)) & LTT_FINALIZE_TRACE)
+			return 0;
+
+	return 1;
+}
+
+/**
+ *	active_traces: - The number of currently active traces
+ *
+ *	Returns the number of active traces
+ */
+static inline int active_traces(void)
+{
+	int i, nr_active = 0;
+	
+	for (i = 0; i < NR_TRACES; i++)
+		if (current_traces[i].active)
+			nr_active++;
+		
+	return nr_active;
+}
+
+/**
+ *	del_percpu_timers: - Delete all per_cpu timers.
+ */
+static inline void del_percpu_timers(void)
+{
+	int i;
+
+	for (i =  0; i < num_cpus; i++)
+		del_timer_sync(&percpu_timer[i]);
+}
+
+/**
+ *	remove_readers: - Remove all map readers.
+ *	@trace_handle: the trace containing the readers to be removed
+ */
+static inline void remove_readers(unsigned int trace_handle)
+{
+	int i;
+	
+	for (i = 0; i < num_cpus; i++) {
+		remove_map_reader(trace_channel_reader(trace_handle, i));
+		trace_channel_reader(trace_handle, i) = NULL;
+	}
+}
+
+/**
+ *	do_waiting_async_tasks: - perform asynchronous per-CPU tasks.
+ *	@cpu_id: the CPU the tasks should be executed on
+ */
+static void do_waiting_async_tasks(unsigned int trace_handle, u8 cpu_id)
+{
+	unsigned long int flags;
+	int tasks;
+	struct trace_struct *trace;
+	
+	trace = &current_traces[trace_handle];
+
+	local_irq_save(flags);
+	tasks = atomic_read(&waiting_for_cpu_async(trace_handle, cpu_id));
+
+	if (tasks == 0) {
+		local_irq_restore(flags);
+		return;
+	}
+
+	if (trace->using_tsc && trace->tracer_started && (tasks & LTT_TRACE_HEARTBEAT)) {
+                clear_waiting_for_cpu_async(trace_handle, cpu_id, LTT_TRACE_HEARTBEAT);
+		TRACE_HEARTBEAT();
+	}
+
+	if (trace->tracer_stopping && (tasks & LTT_FINALIZE_TRACE)) {
+                clear_waiting_for_cpu_async(trace_handle, cpu_id, LTT_FINALIZE_TRACE);
+
+		if (relay_close(trace_channel_handle(trace_handle, cpu_id)) != 0)
+			printk(KERN_ALERT "LTT: Couldn't close trace channel %d\n", trace_channel_handle(trace_handle, cpu_id));
+
+		set_bit(cpu_id, &trace->buffer_switches_pending);
+
+		if (all_channels_finalized(trace_handle)) {
+			remove_readers(trace_handle);
+			trace->tracer_stopping = 0;
+		}
+	}
+
+	local_irq_restore(flags);
+}
+
+/**
+ *	check_waiting_async_tasks: - Timer function checking for async tasks.
+ *	@data: unused
+ */
+static void check_waiting_async_tasks(unsigned long data)
+{
+	int i;
+	int cpu = smp_processor_id();
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		if (atomic_read(&waiting_for_cpu_async(i, cpu)) != 0)
+			do_waiting_async_tasks(i, cpu);
+	}
+
+	del_timer(&percpu_timer[cpu]);
+	percpu_timer[cpu].expires = jiffies + LTT_PERCPU_TIMER_FREQ;
+	add_timer(&percpu_timer[cpu]);
+}
+
+/**
+ *	_init_percpu_timer: - Start timer checking for async tasks.
+ */
+void _init_percpu_timer(void * dummy)
+{
+	int cpu = smp_processor_id();
+
+	init_timer(&percpu_timer[cpu]);
+	percpu_timer[cpu].function = check_waiting_async_tasks;
+	percpu_timer[cpu].expires = jiffies + LTT_PERCPU_TIMER_FREQ;
+	add_timer(&percpu_timer[cpu]);
+}
+
+static inline void init_percpu_timers(void)
+{
+	_init_percpu_timer(NULL);
+
+	if (smp_call_function(_init_percpu_timer, NULL, 1, 1) != 0)
+		printk(KERN_ALERT "LTT: Couldn't initialize all per-CPU timers\n");
+}
+
+/*
+ * User-kernel interface for tracer
+ */
+
+/**
+ *	update_shared_buffer_control: - prepare for GET_BUFFER_CONTROL ioctl
+ *	@cpu_id: the CPU associated with the ioctl
+ */
+static inline void update_shared_buffer_control(struct trace_struct *trace, u8 cpu_id)
+{
+	struct rchan_info channel_info;
+	int i;
+	int channel_handle = trace_channel_handle(trace->trace_handle, cpu_id);
+	
+	if (relay_info(channel_handle, &channel_info) == -1) {
+		shared_buf_ctl.buffer_control_valid = 0;
+		return;
+	}
+
+	shared_buf_ctl.cpu_id =				cpu_id;
+	shared_buf_ctl.buffer_switches_pending =	trace->buffer_switches_pending & ~(1UL << cpu_id);
+	shared_buf_ctl.buffer_control_valid =		1;
+	shared_buf_ctl.buf_size =			channel_info.buf_size;
+	shared_buf_ctl.n_buffers =			channel_info.n_bufs;
+	shared_buf_ctl.cur_idx =			channel_info.cur_idx;
+	shared_buf_ctl.buffers_produced =		channel_info.bufs_produced;
+	shared_buf_ctl.buffers_consumed =		channel_info.bufs_consumed;
+
+	if (channel_info.flags & RELAY_SCHEME_LOCKLESS) {
+		for (i = 0; i < channel_info.n_bufs; i++) {
+			shared_buf_ctl.buffer_complete[i] = 
+				channel_info.buffer_complete[i];
+		}
+	}
+}
+
+/**
+ *	ltt_set_flight_recorder_config: - set flight recorder defaults
+ *	@trace: the trace struct
+ */
+static void ltt_set_flight_recorder_config(struct trace_struct *trace)
+{
+	trace->traced_events = 0;
+	trace->log_event_details_mask = 0;
+	
+	ltt_set_bit(TRACE_EV_BUFFER_START, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_BUFFER_START, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_START, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_START, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->log_event_details_mask);
+
+	ltt_set_bit(TRACE_EV_SYSCALL_ENTRY, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_SYSCALL_ENTRY, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_SYSCALL_EXIT, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_SYSCALL_EXIT, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_TRAP_ENTRY, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_TRAP_ENTRY, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_TRAP_EXIT, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_TRAP_EXIT, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_IRQ_ENTRY, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_IRQ_ENTRY, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_IRQ_EXIT, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_IRQ_EXIT, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_SCHEDCHANGE, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_SCHEDCHANGE, &trace->log_event_details_mask);
+
+	ltt_set_bit(TRACE_EV_KERNEL_TIMER, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_KERNEL_TIMER, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_SOFT_IRQ, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_SOFT_IRQ, &trace->log_event_details_mask);
+	ltt_set_bit(TRACE_EV_PROCESS, &trace->traced_events);
+	ltt_set_bit(TRACE_EV_PROCESS, &trace->log_event_details_mask);
+}
+
+/**
+ *	tracer_get_status: - fill in a status struct covering all traces
+ *	@tracer_status: the tracer_status struct
+ */
+static int tracer_get_status(struct tracer_status *tracer_status)
+{
+	int i, j, rchan_handle, retval = 0;
+	struct trace_struct *trace;
+	struct trace_info *info;
+	struct rchan_info rchan_info;
+	
+	tracer_status->num_cpus = num_cpus;
+
+	for (i = 0; i < NR_TRACES; i++) {
+		trace = &current_traces[i];
+		info = &tracer_status->traces[i];
+		info->active = trace->active && trace->tracer_started ? 1 : 0;
+		if (!info->active)
+			continue;
+		info->trace_handle = trace->trace_handle;
+		info->paused = trace->paused;
+		info->flight_recorder = trace->flight_recorder;
+		info->use_locking = trace->use_locking;
+		info->using_tsc = trace->using_tsc;
+		info->n_buffers = trace->n_buffers;
+		info->buf_size = trace->buf_size;
+		info->traced_events = trace->traced_events;
+		info->log_event_details_mask = trace->log_event_details_mask;
+		for (j = 0; j < num_cpus; j++) {
+			rchan_handle = trace_channel_handle(trace->trace_handle, j);
+			retval = relay_info(rchan_handle, &rchan_info);
+			if (retval)
+				return retval;
+			info->buffers_produced[j] = rchan_info.bufs_produced;
+		}
+	}
+
+	return retval;
+}
+
+/**
+ *	sys_trace: - Tracing system call
+ *
+ *	@tracer_handle: tracing mechanism handle
+ *	@tracer_command: command given by the caller
+ *	@command_arg1: argument "1" to the command
+ *	@command_arg2: argument "2" to the command
+ *
+ *	Returns:
+ *	>0, In case the caller requested the number of events lost.
+ *	0, Everything went OK
+ *	-ENOSYS, no such command
+ *	-EINVAL, tracer not properly configured
+ *	-EBUSY, tracer can't be reconfigured while in operation
+ *	-ENOMEM, no more memory
+ *	-EFAULT, unable to access user space memory
+ *	-EACCES, invalid tracer handle
+ */
+asmlinkage int sys_trace(unsigned int tracer_handle,
+			 unsigned int tracer_command,
+			 unsigned long command_arg1,
+			 unsigned long command_arg2)
+{
+	int retval;
+	int new_user_event_id;
+	unsigned long int flags;
+	u8 cpu_id;
+	u8 i;
+	u32 buffers_consumed;
+	trace_custom user_event;
+	trace_change_mask trace_mask;
+	trace_new_event new_user_event;
+	struct buffers_committed buffers_committed;
+	struct trace_struct *trace = NULL;
+	struct tracer_status tracer_status;
+
+	if (tracer_command == TRACER_ALLOC_HANDLE)
+		return ltt_alloc_trace_handle(tracer_handle);
+
+	if (!ltt_valid_trace_handle(tracer_handle))
+		return -EACCES;
+
+	if (tracer_handle < NR_TRACES)
+		trace = &current_traces[tracer_handle];
+	else if (tracer_handle >= NR_TRACES) {
+		if (current_traces[TRACE_HANDLE].active)
+			trace = &current_traces[TRACE_HANDLE];
+		if (trace == NULL && tracer_command != TRACER_GET_STATUS)
+			return -EACCES;
+	}
+
+	if ((tracer_handle < NR_TRACES)
+	    && (trace->tracer_started == 1)
+	    && (tracer_command != TRACER_STOP)
+	    && (tracer_command != TRACER_PAUSE)
+	    && (tracer_command != TRACER_UNPAUSE)
+	    && (tracer_command != TRACER_DATA_COMITTED)
+	    && (tracer_command != TRACER_GET_ARCH_INFO)
+	    && (tracer_command != TRACER_GET_BUFFER_CONTROL)
+	    && (tracer_command != TRACER_GET_START_INFO))
+		return -EBUSY;
+
+	if ((tracer_handle >= NR_TRACES)
+	    && (tracer_command != TRACER_CREATE_USER_EVENT)
+	    && (tracer_command != TRACER_DESTROY_USER_EVENT)
+	    && (tracer_command != TRACER_TRACE_USER_EVENT)
+	    && (tracer_command != TRACER_GET_STATUS)
+	    && (tracer_command != TRACER_SET_EVENT_MASK)
+	    && (tracer_command != TRACER_GET_EVENT_MASK))
+		return -ENOSYS;
+
+	switch (tracer_command) {
+	case TRACER_START:
+		if (trace->using_tsc && (need_heartbeat() == 1))
+			init_heartbeat_timer();
+		if (active_traces() == 1)
+			init_percpu_timers();
+
+		if (((use_syscall_eip_bounds == 1)
+		     && (syscall_eip_depth_set == 1))
+		    || ((use_syscall_eip_bounds == 1)
+			&& ((lower_eip_bound_set != 1)
+			    || (upper_eip_bound_set != 1)))
+		    || ((trace->tracing_pid == 1)
+			&& (trace->tracing_pgrp == 1)))
+			return -EINVAL;
+
+		if (ltt_set_trace_config(syscall_eip_depth_set,
+					 use_syscall_eip_bounds,
+					 syscall_eip_depth,
+					 lower_eip_bound,
+					 upper_eip_bound) < 0)
+			return -EINVAL;
+
+		if (trace->flight_recorder)
+			ltt_set_flight_recorder_config(trace);
+		
+		ltt_set_bit(TRACE_EV_BUFFER_START, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_BUFFER_START, &trace->log_event_details_mask);
+		ltt_set_bit(TRACE_EV_START, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_START, &trace->log_event_details_mask);
+		ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->log_event_details_mask);
+
+		/* Enable hooks for the events we are interested in. */
+		change_traced_events(&trace->traced_events);
+
+		trace->tracer_stopping = 0;
+		trace->tracer_started = 1;
+
+		ltt_reregister_custom_events();
+		break;
+
+	case TRACER_STOP:
+		if (trace->flight_recorder) {
+			for (i = 0; i < num_cpus; i++)
+				tmp_rchan_handles[i] = trace_channel_handle(tracer_handle, i);
+			ltt_free_all_handles(NULL);
+		} else {
+			trace->tracer_stopping = 1;
+			trace->tracer_started = 0;
+		}
+
+		/* Disable hooks. */
+		change_traced_events(NULL);
+
+		if (trace->flight_recorder) {
+			for (i = 0; i < num_cpus; i++) {
+				if (relay_close(tmp_rchan_handles[i]) != 0)
+					printk(KERN_ALERT "LTT: Couldn't close trace channel %d\n", trace_channel_handle(tracer_handle, i));
+			}
+			remove_readers(tracer_handle);
+		} else {
+			for (i = 0; i < num_cpus; i++)
+				set_waiting_for_cpu_async(tracer_handle, i, LTT_FINALIZE_TRACE);
+		}
+		break;
+
+	case TRACER_PAUSE:
+		trace->paused = 1;
+		break;
+
+	case TRACER_UNPAUSE:
+		trace->paused = 0;
+		break;
+
+	case TRACER_CONFIG_DEFAULT:
+		ltt_set_default_config(trace);
+		break;
+
+	case TRACER_CONFIG_MEMORY_BUFFERS:
+		if (trace->use_locking == 1) {
+			if (command_arg1 < TRACER_MIN_BUF_SIZE)
+				return -EINVAL;
+		} else {
+			if ((command_arg1 < TRACER_LOCKLESS_MIN_BUF_SIZE) || 
+			    (command_arg1 > TRACER_LOCKLESS_MAX_BUF_SIZE))
+				return -EINVAL;
+		}
+
+		return ltt_set_buffer_size(trace, command_arg1, relayfs_path);
+		break;
+
+	case TRACER_CONFIG_N_MEMORY_BUFFERS:
+		if (command_arg1 < TRACER_MIN_BUFFERS || 
+		    command_arg1 > TRACER_MAX_BUFFERS)
+			return -EINVAL;
+
+		return ltt_set_n_buffers(trace, command_arg1);
+		break;
+
+	case TRACER_CONFIG_USE_LOCKING:
+		trace->use_locking = command_arg1;
+
+		if ((trace->use_locking == 0) && (have_cmpxchg() == 0))
+			return -EINVAL;
+		break;
+
+	case TRACER_CONFIG_EVENTS:
+		if (copy_from_user(&trace->traced_events, (void *) command_arg1, sizeof(trace->traced_events)))
+			return -EFAULT;
+		break;
+
+	case TRACER_CONFIG_TIMESTAMP:
+		trace->using_tsc = command_arg1;
+
+		if ((trace->using_tsc == 1) && (have_tsc() == 0)) {
+			trace->using_tsc = 0;
+			return -EINVAL;
+		}
+
+		break;
+
+	case TRACER_CONFIG_DETAILS:
+		if (copy_from_user(&trace->log_event_details_mask, (void *) command_arg1, sizeof(trace->log_event_details_mask)))
+			return -EFAULT;
+		 /* Enable hooks for the events we are interested in. */
+
+		if (trace->tracer_started) {
+			change_traced_events(&trace->traced_events);
+		}
+
+		break;
+
+	case TRACER_CONFIG_CPUID:
+		trace->log_cpuid = 1;
+		break;
+
+	case TRACER_CONFIG_PID:
+		trace->tracing_pid = 1;
+		trace->traced_pid = command_arg1;
+		break;
+
+	case TRACER_CONFIG_PGRP:
+		trace->tracing_pgrp = 1;
+		trace->traced_pgrp = command_arg1;
+		break;
+
+	case TRACER_CONFIG_GID:
+		trace->tracing_gid = 1;
+		trace->traced_gid = command_arg1;
+		break;
+
+	case TRACER_CONFIG_UID:
+		trace->tracing_uid = 1;
+		trace->traced_uid = command_arg1;
+		break;
+
+	case TRACER_CONFIG_SYSCALL_EIP_DEPTH:
+		syscall_eip_depth_set = 1;
+		syscall_eip_depth = command_arg1;
+		break;
+
+	case TRACER_CONFIG_SYSCALL_EIP_LOWER:
+		use_syscall_eip_bounds = 1;
+		lower_eip_bound = (void *) command_arg1;
+		lower_eip_bound_set = 1;
+		break;
+
+	case TRACER_CONFIG_SYSCALL_EIP_UPPER:
+		use_syscall_eip_bounds = 1;
+		upper_eip_bound = (void *) command_arg1;
+		upper_eip_bound_set = 1;
+		break;
+
+	case TRACER_DATA_COMITTED:
+		if (copy_from_user(&buffers_committed, (void *)command_arg1, 
+				   sizeof(buffers_committed)))
+			return -EFAULT;
+
+		cpu_id = buffers_committed.cpu_id;
+		buffers_consumed = buffers_committed.buffers_consumed;
+		clear_bit(cpu_id, &trace->buffer_switches_pending);
+
+		local_irq_save(flags);
+		relay_buffers_consumed(trace_channel_reader(tracer_handle, cpu_id), 
+				       buffers_consumed);
+		local_irq_restore(flags);
+
+		break;
+
+	case TRACER_GET_EVENTS_LOST:
+		return events_lost(tracer_handle, command_arg1);
+		break;
+
+	case TRACER_CREATE_USER_EVENT:
+		if (copy_from_user(&new_user_event, (void *) command_arg1, sizeof(new_user_event)))
+			return -EFAULT;
+
+		new_user_event_id = ltt_create_owned_event(new_user_event.type,
+							     new_user_event.desc,
+							     new_user_event.format_type,
+							     new_user_event.form,
+							     current->pid);
+		if (new_user_event_id >= 0) {
+			new_user_event.id = new_user_event_id;
+			if (copy_to_user((void *) command_arg1, &new_user_event, sizeof(new_user_event))) {
+				ltt_destroy_event(new_user_event_id);
+				return -EFAULT;
+			}
+		}
+		else
+			return new_user_event_id;
+		break;
+
+	case TRACER_DESTROY_USER_EVENT:
+		ltt_destroy_event((int) command_arg1);
+		break;
+
+	case TRACER_TRACE_USER_EVENT:
+		if (copy_from_user(&user_event, (void *) command_arg1, sizeof(user_event)))
+			return -EFAULT;
+
+		if ((user_event_data == NULL) 
+		    && (user_event_data = vmalloc(CUSTOM_EVENT_MAX_SIZE)) < 0)
+			return -ENOMEM;
+
+		if (copy_from_user(user_event_data, user_event.data, user_event.data_size))
+			return -EFAULT;
+
+		retval = ltt_log_raw_event(user_event.id,
+					   user_event.data_size,
+					   user_event_data);
+
+		if (retval < 0)
+			return retval;
+		break;
+
+	case TRACER_SET_EVENT_MASK:
+		if (copy_from_user(&(trace_mask.mask), (void *) command_arg1, sizeof(trace_mask.mask)))
+			return -EFAULT;
+
+		retval = _ltt_log_event(trace,
+					TRACE_EV_CHANGE_MASK,
+					&trace_mask,
+					smp_processor_id());
+
+		memcpy(&trace->traced_events, &(trace_mask.mask), sizeof(trace_mask.mask));
+
+		ltt_set_bit(TRACE_EV_BUFFER_START, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_START, &trace->traced_events);
+		ltt_set_bit(TRACE_EV_CHANGE_MASK, &trace->traced_events);
+
+		/* Enable hooks for the events we are interested in. */
+		if (trace->tracer_started) {
+			change_traced_events(&trace->traced_events);
+		}
+
+		return retval;
+		break;
+
+	case TRACER_GET_EVENT_MASK:
+		if (copy_to_user((void *) command_arg1, &trace->traced_events, sizeof(trace->traced_events)))
+			return -EFAULT;
+		break;
+
+	case TRACER_GET_ARCH_INFO:
+		ltt_arch_info.n_cpus = num_cpus;
+		ltt_arch_info.page_shift = PAGE_SHIFT;
+
+		if (copy_to_user((void *) command_arg1, 
+				 &ltt_arch_info, 
+				 sizeof(ltt_arch_info))) {
+			return -EFAULT;
+		}
+		break;
+
+	case TRACER_GET_START_INFO:
+		if (trace->trace_start_data) {
+			if (copy_to_user((void *) command_arg1, 
+					 trace->trace_start_data, 
+					 sizeof(trace_start)))
+				return -EFAULT;
+		} else
+			return -EINVAL;
+		break;
+
+	case TRACER_GET_STATUS:
+		if (tracer_get_status(&tracer_status))
+			return -EINVAL;
+		
+		if (copy_to_user((void *) command_arg1, 
+				 &tracer_status, 
+				 sizeof(struct tracer_status)))
+			return -EFAULT;
+		break;
+
+	case TRACER_GET_BUFFER_CONTROL:
+		if (copy_from_user(&shared_buf_ctl, (void *) command_arg1, sizeof(shared_buf_ctl)))
+			return -EFAULT;
+
+		if (shared_buf_ctl.cpu_id == -1) {
+			for (i = 0; i < num_cpus; i++) {
+				if (trace->buffer_switches_pending & (1UL << i)) {
+					update_shared_buffer_control(trace, i);
+					
+					if (copy_to_user((void *) command_arg1, 
+							 &shared_buf_ctl, 
+							 sizeof(struct buf_control_info)))
+						return -EFAULT;
+
+					return 0;
+				}
+			}
+		} else {
+			update_shared_buffer_control(trace, (u8)shared_buf_ctl.cpu_id);
+			if (copy_to_user((void *) command_arg1, 
+					 &shared_buf_ctl, 
+					 sizeof(struct buf_control_info)))
+				return -EFAULT;
+
+			return 0;
+		}
+
+		shared_buf_ctl.cpu_id = 0;
+		shared_buf_ctl.buffer_control_valid = 0;
+
+		if (copy_to_user((void *) command_arg1,
+				&shared_buf_ctl,
+				sizeof(struct buf_control_info)))
+			return -EFAULT;
+		break;
+
+	case TRACER_FREE_HANDLE:
+		return ltt_free_trace_handle(tracer_handle);
+		break;
+
+	case TRACER_FREE_DAEMON_HANDLE:
+		return ltt_free_daemon_handle(trace);
+		break;
+
+	case TRACER_FREE_ALL_HANDLES:
+		ltt_free_all_handles(current);
+		break;
+
+	case TRACER_MAP_BUFFER:
+		return -EFAULT;
+		break;
+
+	default:
+		return -ENOSYS;
+	}
+	return 0;
+}
+
+/*
+ * Trace Handles
+ */
+
+/**
+ *	ltt_valid_trace_handle: - Validate tracer handle.
+ *	@tracer_handle: handle to be validated
+ *
+ *	Returns:
+ *	1, if handle is valid
+ *	0, if handle is invalid
+ */
+int ltt_valid_trace_handle(unsigned int tracer_handle)
+{
+	int retval = 0;
+	struct trace_struct *trace;
+
+	if (tracer_handle < NR_TRACES) {
+		trace = &current_traces[tracer_handle];
+		if (!trace->active)
+			retval = 0;
+		else if (!trace->flight_recorder) {
+			if (trace->daemon_task_struct == current)
+				retval = 1;
+		} else
+			retval = 1;
+	} else {
+		read_lock(&trace_handle_table_lock);
+		if (trace_handle_table[tracer_handle - NR_TRACES].owner == current)
+			retval = 1;
+		else
+			retval = 0;
+		read_unlock(&trace_handle_table_lock);
+	}
+
+	return retval;
+}
+
+/**
+ *	ltt_alloc_trace_handle: - Allocate trace handle to caller.
+ *	@tracer_handle: handle requested by process
+ *
+ *	Returns:
+ *	Handle ID, everything went OK
+ *	-ENODEV, no more free handles.
+ *	-EBUSY, daemon handle already in use.
+ */
+int ltt_alloc_trace_handle(unsigned int tracer_handle)
+{
+	int i;
+	int retval;
+	struct trace_struct *trace = NULL;
+	
+	if (tracer_handle < NR_TRACES) {
+		trace = &current_traces[tracer_handle];
+		if (trace->active)
+			return -EBUSY;
+	}
+
+	if (tracer_handle == NR_TRACES) {
+		write_lock(&trace_handle_table_lock);
+		for (i = 0; i < TRACE_MAX_HANDLES; i++)
+			if (trace_handle_table[i].owner == NULL) {
+				trace_handle_table[i].owner = current;
+				break;
+			}
+		write_unlock(&trace_handle_table_lock);
+		if (i == TRACE_MAX_HANDLES)
+			retval = -ENODEV;
+		else
+			retval = (i + NR_TRACES);
+	} else {
+		trace->active = trace;
+		trace->tracer_started = 0;
+		trace->tracer_stopping = 0;
+		if (tracer_handle == TRACE_HANDLE) {
+			trace->flight_recorder = 0;
+			trace->daemon_task_struct = current;
+		} else {
+			if ((trace->trace_start_data = (struct _trace_start *) kmalloc(sizeof(struct _trace_start), GFP_ATOMIC)) == NULL)
+				return -ENOMEM;
+		}
+
+		trace->proc_dir_entry = create_handle_proc_dir(tracer_handle);
+		ltt_set_default_config(trace);
+		retval = trace->trace_handle = tracer_handle;
+	}
+	
+	return retval;
+}
+
+/**
+ *	ltt_free_trace_handle: - Free a single handle.
+ *	tracer_handle: handle to be freed.
+ *
+ *	Returns: 
+ *	0, everything went OK
+ *	-ENODEV, no such handle.
+ *	-EACCES, handle doesn't belong to caller.
+ */
+int ltt_free_trace_handle(unsigned int tracer_handle)
+{
+	int retval;
+
+	if ((tracer_handle < NR_TRACES) || (tracer_handle >= TRACE_MAX_HANDLES))
+		return -ENODEV;
+
+	write_lock(&trace_handle_table_lock);
+
+	if (trace_handle_table[tracer_handle - NR_TRACES].owner == current) {
+		trace_handle_table[tracer_handle - NR_TRACES].owner = NULL;
+		retval = 0;
+	}
+	else
+		retval = -EACCES;
+
+	write_unlock(&trace_handle_table_lock);
+
+	return retval;
+}
+
+/**
+ *	ltt_free_daemon_handle: - Free the daemon's handle.
+ *
+ *	Returns: 
+ *	0, everything went OK
+ *	-EACCES, handle doesn't belong to caller.
+ *	-EBUSY, there are still event writes in progress so the buffer can't
+ *	be released.
+ */
+int ltt_free_daemon_handle(struct trace_struct *trace)
+{
+	int i;
+
+	if (!trace->flight_recorder) {
+		if (trace->daemon_task_struct != current)
+			return -EACCES;
+
+		for (i = 0; i < num_cpus; i++) {
+			if (events_lost(trace->trace_handle, i) > 0)
+				printk(KERN_ALERT "LTT: Lost %d events on cpu %d\n",
+				       events_lost(trace->trace_handle, i), i);
+		}
+		trace->daemon_task_struct = NULL;
+	}
+	
+	trace->active = NULL;
+
+	if (!active_traces())
+		del_percpu_timers();
+
+	if(!need_heartbeat()) 
+		del_timer(&heartbeat_timer);
+
+	for (i = 0; i < num_cpus; i++) {
+		if (trace_channel_handle(trace->trace_handle, i) != -1) {
+				trace_channel_handle(trace->trace_handle, i) = -1;
+				trace_channel_reader(trace->trace_handle, i) = NULL;
+		}
+	}
+
+	remove_handle_proc_dir(trace->proc_dir_entry, 0);
+
+	trace->use_locking = 1;
+	ltt_set_default_config(trace);
+	trace->tracer_started = 0;
+	trace->tracer_stopping = 0;
+	if (trace->trace_start_data)
+		kfree(trace->trace_start_data);
+
+	return 0;
+}
+
+/**
+ *	ltt_free_all_handles: - Free all handles taken.
+ *	@task_ptr: pointer to exiting task.
+ *
+ *	Free all handles taken against a given channel.  If task_ptr is NULL,
+ *	it means there is no daemon, i.e. free all handles taken agains the
+ *	flight recorder channel, otherwise task_ptr refers to a trace daemon.
+ */
+void ltt_free_all_handles(struct task_struct* task_ptr)
+{
+	int i;
+	struct trace_struct *trace;
+
+	if (task_ptr == NULL) {
+		if (current_traces[FLIGHT_HANDLE].active) {
+			ltt_free_daemon_handle(&current_traces[FLIGHT_HANDLE]);
+			return;
+		}
+	} else {
+		trace = &current_traces[TRACE_HANDLE];
+		if (trace->active && trace->daemon_task_struct == task_ptr)
+			ltt_free_daemon_handle(trace);
+	}
+
+	write_lock(&trace_handle_table_lock);
+	for (i = 0; i < TRACE_MAX_HANDLES; i++)
+		if (trace_handle_table[i].owner == current)
+			trace_handle_table[i].owner = NULL;
+	write_unlock(&trace_handle_table_lock);
+} /* * Tracer Configuration
+ */
+
+/**
+ *	init_channel_data: - Init channel-associated data for new tracing run.
+ *	@buf_ctrl: buffer control struct to be initialized
+ *	@use_lockless: which tracing scheme to use, 1 for lockless
+ *	@buffer_number_bits: number of bits in index word for buffer number
+ *	@offset_bits: number of bits in index word to use for buffer offset
+ */
+static void init_channel_data(struct trace_struct *trace)
+{
+	unsigned i;
+	
+	trace->buffer_switches_pending = 0;
+
+	for (i = 0; i < num_cpus; i++) {
+		trace_channel_handle(trace->trace_handle, i) = -1;
+		trace_channel_reader(trace->trace_handle, i) = NULL;
+		atomic_set(&waiting_for_cpu_async(trace->trace_handle, i), LTT_NOTHING_TO_DO);
+		events_lost(trace->trace_handle, i) = 0;
+	}
+}
+
+/**
+ *	ltt_set_n_buffers: - Sets the number of buffers.
+ *	@no_buffers: number of buffers.
+ *
+ *	For lockless only, must be a power of 2.
+ *
+ *	Returns:
+ *
+ *	0, Size setting went OK
+ *	-EINVAL, not a power of 2
+ */
+int ltt_set_n_buffers(struct trace_struct *trace, int no_buffers)
+{
+	if (hweight32(no_buffers) != 1)
+		return -EINVAL;
+
+	trace->n_buffers = no_buffers;
+
+	return 0;
+}
+
+/**
+ *	ltt_set_buffer_size: - Sets size of and creates buffers.
+ *	@buf_size: Size of sub-buffers
+ *	@dirname: name of the relayfs directory to contain trace files
+ *
+ *	Note: dirname should be well-formed before it gets here e.g.
+ *	trailing slashes should be removed.
+ *
+ *	Returns:
+ *	0, Size setting went OK
+ *	-ENOMEM, unable to get a hold of memory for tracer
+ *	-EINVAL, tracer not properly configured
+ */
+int ltt_set_buffer_size(struct trace_struct *trace, int buffer_size, char * dirname)
+{
+	int i;
+	u32 flags;
+
+	if (trace->flight_recorder)
+		flags = RELAY_DELIVERY_BULK | RELAY_USAGE_SMP | RELAY_MODE_CONTINUOUS;
+	else
+		flags = RELAY_DELIVERY_BULK | RELAY_USAGE_SMP | RELAY_MODE_NO_OVERWRITE;
+
+	if ((dirname == NULL) || (strlen(dirname) == 0))
+		return  -EINVAL;
+
+	if (trace->using_tsc)
+		flags |= RELAY_TIMESTAMP_TSC;
+	else
+		flags |= RELAY_TIMESTAMP_GETTIMEOFDAY;
+	
+	if (trace->use_locking)
+		flags |= RELAY_SCHEME_LOCKING;
+	else
+		flags |= RELAY_SCHEME_LOCKLESS;
+	
+	num_cpus = num_online_cpus();
+
+	init_channel_data(trace);
+
+	trace->buf_size = buffer_size;
+
+	for (i = 0; i < num_cpus; i++) {
+		sprintf(relay_file_name, "%s/cpu%d", dirname, i);
+		trace_channel_handle(trace->trace_handle, i) = relay_open(relay_file_name,
+							  buffer_size,
+							  trace->n_buffers,
+							  flags,
+							  &ltt_callbacks,
+							  start_reserve,
+							  end_reserve,
+							  trace_start_reserve,
+							  0,
+							  0,
+							  0,
+							  NULL,
+							  0);
+
+		if (trace_channel_handle(trace->trace_handle, i) < 0)
+			return -ENOMEM;
+	}
+	
+	return 0;
+}
+
+/**
+ *	ltt_set_default_config: - Sets the tracer in its default config
+ *
+ *	Returns:
+ *	0, everything went OK
+ *	-ENOMEM, unable to get a hold of memory for tracer
+ */
+int ltt_set_default_config(struct trace_struct *trace)
+{
+	int i;
+	int retval = 0;
+
+	trace->traced_events = 0;
+
+	for (i = 0; i <= TRACE_EV_MAX; i++) {
+		ltt_set_bit(i, &trace->traced_events);
+		ltt_set_bit(i, &trace->log_event_details_mask);
+	}
+
+
+	trace->log_cpuid = 0;
+	trace->tracing_pid = 0;
+	trace->tracing_pgrp = 0;
+	trace->tracing_gid = 0;
+	trace->tracing_uid = 0;
+	trace->using_tsc = 0;
+
+	syscall_eip_depth_set = 0;
+	use_syscall_eip_bounds = 0;
+	lower_eip_bound_set = 0;
+	upper_eip_bound_set = 0;
+
+	ltt_set_trace_config(syscall_eip_depth_set,
+			 use_syscall_eip_bounds,
+			 0,
+			 0,
+			 0);
+
+	/* Enable hooks for the events we are interested in. */
+	if (trace->tracer_started) {
+		change_traced_events(&trace->traced_events);
+	}
+
+	return retval;
+}
+
+/**
+ *	ltt_set_trace_config: - Set the tracing configuration
+ *	@do_syscall_depth: Use depth to fetch eip
+ *	@do_syscall_bounds: Use bounds to fetch eip
+ *	@eip_depth: Detph to fetch eip
+ *	@eip_lower_bound: Lower bound eip address
+ *	@eip_upper_bound: Upper bound eip address
+ *
+ *	Returns: 
+ *	0, all is OK 
+ *	-ENOMEDIUM, there isn't a registered tracer
+ *	-ENXIO, wrong tracer
+ *	-EINVAL, invalid configuration
+ */
+int ltt_set_trace_config(int do_syscall_depth,
+		     int do_syscall_bounds,
+		     int eip_depth,
+		     void *eip_lower_bound,
+		     void *eip_upper_bound)
+{
+	if ((do_syscall_depth && do_syscall_bounds)
+	    || (eip_lower_bound > eip_upper_bound)
+	    || (eip_depth < 0))
+		return -EINVAL;
+
+	fetch_syscall_eip_use_depth = do_syscall_depth;
+	fetch_syscall_eip_use_bounds = do_syscall_bounds;
+
+	syscall_eip_depth = eip_depth;
+	syscall_lower_eip_bound = eip_lower_bound;
+	syscall_upper_eip_bound = eip_upper_bound;
+
+	return 0;
+}
+
+/**
+ *	ltt_get_trace_config: - Get the tracing configuration
+ *	@do_syscall_depth: Use depth to fetch eip
+ *	@do_syscall_bounds: Use bounds to fetch eip
+ *	@eip_depth: Detph to fetch eip
+ *	@eip_lower_bound: Lower bound eip address
+ *	@eip_upper_bound: Upper bound eip address
+ *
+ *	Returns:
+ *	0, all is OK 
+ *	-ENOMEDIUM, there isn't a registered tracer
+ */
+int ltt_get_trace_config(int *do_syscall_depth,
+		     int *do_syscall_bounds,
+		     int *eip_depth,
+		     void **eip_lower_bound,
+		     void **eip_upper_bound)
+{
+	*do_syscall_depth = fetch_syscall_eip_use_depth;
+	*do_syscall_bounds = fetch_syscall_eip_use_bounds;
+	*eip_depth = syscall_eip_depth;
+	*eip_lower_bound = syscall_lower_eip_bound;
+	*eip_upper_bound = syscall_upper_eip_bound;
+
+	return 0;
+}
+
+
+/*
+ * Custom Events
+ */
+
+/**
+ *	init_custom_events: - Initialize custom events
+ */
+static inline void init_custom_events(void)
+{
+	custom_events = &custom_events_head;
+	custom_events->next = custom_events;
+	custom_events->prev = custom_events;
+}
+
+/**
+ *	_ltt_create_event: - Create a new traceable event type
+ *	@event_type: string describing event type
+ *	@event_desc: string used for standard formatting
+ *	@format_type: type of formatting used to log event data
+ *	@format_data: data specific to format
+ *	@owner_pid: PID of event's owner (0 if none)
+ *
+ *	Returns:
+ *	New Event ID if all is OK
+ *	-ENOMEM, Unable to allocate new event
+ */
+int _ltt_create_event(char *event_type,
+			char *event_desc,
+			int format_type,
+			char *format_data,
+			pid_t owner_pid)
+{
+	trace_new_event *new_event;
+	struct custom_event_desc *new_event_desc;
+
+	if ((new_event_desc = (struct custom_event_desc *) kmalloc(sizeof(struct custom_event_desc), GFP_ATOMIC)) == NULL)
+		 return -ENOMEM;
+
+	new_event = &(new_event_desc->event);
+	new_event->type[0] = '\0';
+	new_event->desc[0] = '\0';
+	new_event->form[0] = '\0';
+
+	if (event_type != NULL)
+		strncpy(new_event->type, event_type, CUSTOM_EVENT_TYPE_STR_LEN);
+	if (event_desc != NULL)
+		strncpy(new_event->desc, event_desc, CUSTOM_EVENT_DESC_STR_LEN);
+	if (format_data != NULL)
+		strncpy(new_event->form, format_data, CUSTOM_EVENT_FORM_STR_LEN);
+
+	new_event->type[CUSTOM_EVENT_TYPE_STR_LEN - 1] = '\0';
+	new_event->desc[CUSTOM_EVENT_DESC_STR_LEN - 1] = '\0';
+	new_event->form[CUSTOM_EVENT_FORM_STR_LEN - 1] = '\0';
+
+	new_event->format_type = format_type;
+	new_event->id = next_event_id;
+
+	next_event_id++;
+
+	new_event_desc->owner_pid = owner_pid;
+
+	write_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	new_event_desc->next = custom_events;
+	new_event_desc->prev = custom_events->prev;
+	custom_events->prev->next = new_event_desc;
+	custom_events->prev = new_event_desc;
+	write_unlock(&custom_list_lock);
+
+	ltt_log_event(TRACE_EV_NEW_EVENT, &(new_event_desc->event));
+
+	return new_event->id;
+}
+
+int ltt_create_event(char *event_type,
+		       char *event_desc,
+		       int format_type,
+		       char *format_data)
+{
+	return _ltt_create_event(event_type, event_desc, format_type, format_data, 0);
+}
+
+int ltt_create_owned_event(char *event_type,
+			     char *event_desc,
+			     int format_type,
+			     char *format_data,
+			     pid_t owner_pid)
+{
+	return _ltt_create_event(event_type, event_desc, format_type, format_data, owner_pid);
+}
+
+/**
+ *	ltt_destroy_event: - Destroy a created event type
+ *	@event_id, the Id returned by ltt_create_event()
+ */
+void ltt_destroy_event(int event_id)
+{
+	struct custom_event_desc *event_desc;
+
+	write_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	for (event_desc = custom_events->next;
+	     event_desc != custom_events;
+	     event_desc = event_desc->next)
+		if (event_desc->event.id == event_id)
+			break;
+
+	if (event_desc != custom_events) {
+		event_desc->next->prev = event_desc->prev;
+		event_desc->prev->next = event_desc->next;
+		kfree(event_desc);
+	}
+
+	write_unlock(&custom_list_lock);
+}
+
+/**
+ *	ltt_destroy_owners_events: Destroy an owner's events
+ *	@owner_pid: the PID of the owner who's events are to be deleted.
+ */
+void ltt_destroy_owners_events(pid_t owner_pid)
+{
+	struct custom_event_desc *temp_event;
+	struct custom_event_desc *event_desc;
+
+	write_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	event_desc = custom_events->next;
+
+	while (event_desc != custom_events) {
+		temp_event = event_desc->next;
+		if (event_desc->owner_pid == owner_pid) {
+			event_desc->next->prev = event_desc->prev;
+			event_desc->prev->next = event_desc->next;
+			kfree(event_desc);
+		}
+		event_desc = temp_event;
+	}
+
+	write_unlock(&custom_list_lock);
+}
+
+/**
+ *	ltt_reregister_custom_events: - Relogs event creations.
+ */
+void ltt_reregister_custom_events(void)
+{
+	struct custom_event_desc *event_desc;
+
+	read_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	for (event_desc = custom_events->next;
+	     event_desc != custom_events;
+	     event_desc = event_desc->next)
+		ltt_log_event(TRACE_EV_NEW_EVENT, &(event_desc->event));
+
+	read_unlock(&custom_list_lock);
+}
+
+/*
+ * Event logging primitives
+ */
+
+/**
+ *	_ltt_log_event: - Tracing function per se.
+ *	@event_id: ID of event as defined in linux/ltt.h
+ *	@event_struct: struct describing the event
+ *	@cpu_id: the CPU associated with the event
+ *
+ *	Returns: 
+ *	0, if everything went OK (event got registered)
+ *	-ENODEV, no tracing daemon opened the driver.
+ *	-ENOMEM, no more memory to store events.
+ *	-EBUSY, tracer not started yet.
+ */
+int _ltt_log_event(struct trace_struct *trace,
+		   u8 event_id,
+		   void *event_struct,
+		   u8 cpu_id)
+{
+	int var_data_len = 0;
+	void *var_data_beg = NULL;
+	uint16_t data_size;
+	struct task_struct *incoming_process = NULL;
+	unsigned long flags;
+	char * reserved;
+	int bytes_written = 0;
+	int reserve_code, interrupting;
+	struct timeval time_stamp;
+	u32 time_delta;
+	int channel_handle;
+	struct rchan *rchan;
+	unsigned int tracer_handle;
+	
+	if (!trace)
+		return -ENOMEDIUM;
+
+	if (trace->paused)
+		return -EBUSY;
+
+	tracer_handle = trace->trace_handle;
+	
+	if (!trace->flight_recorder && (trace->daemon_task_struct == NULL))
+		return -ENODEV;
+
+	channel_handle = trace_channel_handle(tracer_handle, cpu_id);
+
+	if ((trace->tracer_started == 1) || (event_id == TRACE_EV_START) || (event_id == TRACE_EV_BUFFER_START))
+		goto trace_event;
+
+	return -EBUSY;
+
+trace_event:
+	if (!ltt_test_bit(event_id, &trace->traced_events))
+		return 0;
+
+	if ((event_id != TRACE_EV_START) && (event_id != TRACE_EV_BUFFER_START)) {
+		if (event_id == TRACE_EV_SCHEDCHANGE)
+			incoming_process = (struct task_struct *) (((trace_schedchange *) event_struct)->in);
+		if ((trace->tracing_pid == 1) && (current->pid != trace->traced_pid)) {
+			if (incoming_process == NULL)
+				return 0;
+			else if (incoming_process->pid != trace->traced_pid)
+				return 0;
+		}
+		if ((trace->tracing_pgrp == 1) && (process_group(current) != trace->traced_pgrp)) {
+			if (incoming_process == NULL)
+				return 0;
+			else if (process_group(incoming_process) != trace->traced_pgrp)
+				return 0;
+		}
+		if ((trace->tracing_gid == 1) && (current->egid != trace->traced_gid)) {
+			if (incoming_process == NULL)
+				return 0;
+			else if (incoming_process->egid != trace->traced_gid)
+				return 0;
+		}
+		if ((trace->tracing_uid == 1) && (current->euid != trace->traced_uid)) {
+			if (incoming_process == NULL)
+				return 0;
+			else if (incoming_process->euid != trace->traced_uid)
+				return 0;
+		}
+		if (event_id == TRACE_EV_SCHEDCHANGE)
+			(((trace_schedchange *) event_struct)->in) = incoming_process->pid;
+	}
+
+	data_size = sizeof(event_id) + sizeof(time_delta) + sizeof(data_size);
+
+	if (ltt_test_bit(event_id, &trace->log_event_details_mask)) {
+		data_size += event_struct_size[event_id];
+		switch (event_id) {
+		case TRACE_EV_FILE_SYSTEM:
+			if ((((trace_file_system *) event_struct)->event_sub_id == TRACE_EV_FILE_SYSTEM_EXEC)
+			    || (((trace_file_system *) event_struct)->event_sub_id == TRACE_EV_FILE_SYSTEM_OPEN)) {
+				var_data_beg = ((trace_file_system *) event_struct)->file_name;
+				var_data_len = ((trace_file_system *) event_struct)->event_data2 + 1;
+				data_size += (uint16_t) var_data_len;
+			}
+			break;
+		case TRACE_EV_CUSTOM:
+			var_data_beg = ((trace_custom *) event_struct)->data;
+			var_data_len = ((trace_custom *) event_struct)->data_size;
+			data_size += (uint16_t) var_data_len;
+			break;
+		}
+	}
+
+	if ((trace->log_cpuid == 1) && (event_id != TRACE_EV_START) && (event_id != TRACE_EV_BUFFER_START))
+		data_size += sizeof(cpu_id);
+
+	rchan = rchan_get(channel_handle);
+	if (rchan == NULL)
+		return -ENODEV;
+	relay_lock_channel(rchan, flags); /* nop for lockless */
+	reserved = relay_reserve(rchan, data_size, &time_stamp, &time_delta, &reserve_code, &interrupting);
+	
+	if (reserve_code & RELAY_WRITE_DISCARD) {
+		events_lost(trace->trace_handle, cpu_id)++;
+		bytes_written = 0;
+		goto check_buffer_switch;
+	}
+	if ((trace->log_cpuid == 1) && (event_id != TRACE_EV_START) 
+	    && (event_id != TRACE_EV_BUFFER_START))
+		relay_write_direct(reserved,
+				   &cpu_id,
+				   sizeof(cpu_id));
+
+	relay_write_direct(reserved,
+			   &event_id,
+			   sizeof(event_id));
+
+	relay_write_direct(reserved,
+			   &time_delta,
+			   sizeof(time_delta));
+
+	if (ltt_test_bit(event_id, &trace->log_event_details_mask)) {
+		relay_write_direct(reserved,
+				   event_struct,
+				   event_struct_size[event_id]);
+		if (var_data_len)
+			relay_write_direct(reserved,
+					   var_data_beg,
+					   var_data_len);
+	}
+
+	relay_write_direct(reserved,
+			   &data_size,
+			   sizeof(data_size));
+
+	bytes_written = data_size;
+
+check_buffer_switch:
+	if ((event_id == TRACE_EV_SCHEDCHANGE) && (tracer_handle == TRACE_HANDLE) && current_traces[FLIGHT_HANDLE].active)
+		(((trace_schedchange *) event_struct)->in) = (u32)incoming_process;
+	
+	/* We need to commit even if we didn't write anything because
+	   that's how the deliver callback is invoked. */
+	relay_commit(rchan, reserved, bytes_written, reserve_code, interrupting);
+
+	relay_unlock_channel(rchan, flags);
+	rchan_put(rchan);
+
+	return 0;
+}
+
+/**
+ *	ltt_log_event: - Trace an event
+ *	@event_id, the event's ID (check out ltt.h)
+ *	@event_struct, the structure describing the event
+ *
+ *	Returns:
+ *	Trace fct return code if OK.
+ *	-ENOMEDIUM, there is no registered tracer
+ *	-ENOMEM, couldn't access ltt_info
+ */
+int ltt_log_event(u8 event_id,
+		void *event_struct)
+{
+	int i;
+	static int err[NR_TRACES];
+	struct trace_struct *trace;
+	u32 cpu = smp_processor_id();
+
+	for (i = 0; i < NR_TRACES; i++) {
+		trace = current_traces[i].active;
+		err[i] = _ltt_log_event(trace,
+				     event_id,
+				     event_struct, 
+				     cpu);
+	}
+
+	return err[0] == -ENOMEDIUM ? err[1] : err[0];
+}
+
+/**
+ *	ltt_log_std_formatted_event: - Trace a formatted event
+ *	@event_id: the event Id provided upon creation
+ *	@...: printf-like data that will be used to fill the event string.
+ *
+ *	Returns:
+ *	Trace fct return code if OK.
+ *	-ENOMEDIUM, there is no registered tracer or event doesn't exist.
+ */
+int ltt_log_std_formatted_event(int event_id,...)
+{
+	int string_size;
+	char final_string[CUSTOM_EVENT_FINAL_STR_LEN];
+	va_list vararg_list;
+	trace_custom custom_event;
+	struct custom_event_desc *event_desc;
+
+	read_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	for (event_desc = custom_events->next;
+	     event_desc != custom_events;
+	     event_desc = event_desc->next)
+		if (event_desc->event.id == event_id)
+			break;
+
+	if (event_desc == custom_events) {
+		read_unlock(&custom_list_lock);
+		return -ENOMEDIUM;
+	}
+
+	custom_event.id = event_id;
+
+	va_start(vararg_list, event_id);
+	string_size = vsprintf(final_string, event_desc->event.desc, vararg_list);
+	read_unlock(&custom_list_lock);
+	va_end(vararg_list);
+
+	custom_event.data_size = (u32) (string_size + 1);
+	custom_event.data = final_string;
+
+	return ltt_log_event(TRACE_EV_CUSTOM, &custom_event);
+}
+
+/**
+ *	ltt_log_raw_event: - Trace a raw event
+ *	@event_id, the event Id provided upon creation
+ *	@event_size, the size of the data provided
+ *	@event_data, data buffer describing event
+ *
+ *	Returns:
+ *	Trace fct return code if OK.
+ *	-ENOMEDIUM, there is no registered tracer or event doesn't exist.
+ */
+int ltt_log_raw_event(int event_id, int event_size, void *event_data)
+{
+	trace_custom custom_event;
+	struct custom_event_desc *event_desc;
+
+	read_lock(&custom_list_lock);
+
+	if (custom_events == NULL)
+		init_custom_events();
+
+	for (event_desc = custom_events->next;
+	     event_desc != custom_events;
+	     event_desc = event_desc->next)
+		if (event_desc->event.id == event_id)
+			break;
+
+	read_unlock(&custom_list_lock);
+
+	if (event_desc == custom_events)
+		return -ENOMEDIUM;
+
+	custom_event.id = event_id;
+
+	if (event_size <= CUSTOM_EVENT_MAX_SIZE)
+		custom_event.data_size = (u32) event_size;
+	else
+		custom_event.data_size = (u32) CUSTOM_EVENT_MAX_SIZE;
+
+	custom_event.data = event_data;
+
+	return ltt_log_event(TRACE_EV_CUSTOM, &custom_event);
+}
+
+/*
+ * Relayfs callback implementations.
+ */
+
+/**
+ *	_ltt_channel_cpuid: - Get CPU id given channel handle, for given trace.
+ *	@tracer_handle: trace handle.
+ *	@channel_handle: relay channel handle.
+ *
+ *	Returns:
+ *
+ *	CPU id
+ *	-1, channel_handle, thus CPU id, not found
+ */
+static int _ltt_channel_cpuid(int tracer_handle, int channel_handle)
+{
+	int i;
+	
+	for (i = 0; i < num_cpus; i++)
+		if (trace_channel_handle(tracer_handle, i) == channel_handle)
+			return i;
+	
+	return -1;
+}
+
+/**
+ *	ltt_channel_cpuid: - Get CPU id given channel handle.
+ *	@channel_handle: relay channel handle.
+ *
+ *	Returns:
+ *
+ *	CPU id
+ *	-1, channel_handle, thus CPU id, not found
+ */
+static int ltt_channel_cpuid(int channel_handle)
+{
+	int i, cpuid;
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		cpuid = _ltt_channel_cpuid(i, channel_handle);
+		if (cpuid != -1)
+			return cpuid;
+	}
+	
+	return -1;
+}
+
+/**
+ *	ltt_channel_trace: - Get trace struct given channel handle.
+ *	@channel_handle: relay channel handle.
+ *
+ *	Returns:
+ *
+ *	trace struct *
+ *	NULL, channel_handle, thus trace_struct *, not found
+ */
+static struct trace_struct *ltt_channel_trace(int channel_handle)
+{
+	int i;
+	
+	for (i = 0; i < NR_TRACES; i++) {
+		if (_ltt_channel_cpuid(i, channel_handle) != -1)
+			return &current_traces[i];
+	}
+	
+	return NULL;
+}
+
+/**
+ *	ltt_channel_trace_handle: - Get trace handle given channel handle.
+ *	@channel_handle: relay channel handle.
+ *
+ *	Returns:
+ *
+ *	trace handle
+ *	-1, channel_handle, thus trace handle, not found
+ */
+static unsigned int ltt_channel_trace_handle(int channel_handle)
+{
+	unsigned int i;
+	
+	for (i = 0; i < NR_TRACES; i++)
+		if (_ltt_channel_cpuid(i, channel_handle) != -1)
+			return i;
+	
+	return -1;
+}
+
+/**
+ *	write_start_event: - Initialize a trace session for a given CPU.
+ *	@cpu_id: the CPU id to initialize a trace for
+ */
+static inline int write_start_event(struct trace_struct *trace,
+				    int channel, 
+				    char * current_write_pos,
+				    u32 start_tsc,
+				    int using_tsc)
+{
+	struct rchan_info channel_info;
+	u32 time_delta;
+	trace_start start_event;
+	u8 event_id;
+	uint16_t data_size;
+
+	relay_info(channel, &channel_info);
+
+	start_event.magic_number =	TRACER_MAGIC_NUMBER;
+	start_event.arch_type =		TRACE_ARCH_TYPE;
+	start_event.arch_variant =	TRACE_ARCH_VARIANT;
+	start_event.system_type =	TRACE_SYS_TYPE_VANILLA_LINUX;
+	start_event.major_version =	TRACER_VERSION_MAJOR;
+	start_event.minor_version =	TRACER_VERSION_MINOR;
+	start_event.buffer_size =	channel_info.buf_size;
+	start_event.event_mask = 	trace->traced_events;
+	start_event.details_mask =	trace->log_event_details_mask;
+	start_event.log_cpuid =		trace->log_cpuid;
+	start_event.use_tsc =		trace->using_tsc;
+	start_event.flight_recorder =	trace->flight_recorder;
+
+	event_id = TRACE_EV_START;
+	relay_write_direct(current_write_pos,
+			   &event_id,
+			   sizeof(event_id));
+
+	time_delta = switch_time_delta(start_tsc, using_tsc);
+	relay_write_direct(current_write_pos,
+			   &time_delta,
+			   sizeof(time_delta));
+
+	relay_write_direct(current_write_pos,
+			   &start_event,
+			   sizeof(trace_start));
+
+	data_size = sizeof(event_id)
+		+ sizeof(time_delta)
+		+ sizeof(trace_start)
+		+ sizeof(data_size);
+
+	relay_write_direct(current_write_pos,
+			   &data_size,
+			   sizeof(data_size));
+
+	if (trace->trace_start_data)
+		memcpy(trace->trace_start_data, &start_event, sizeof(start_event));
+
+	return (int)data_size;
+}
+
+/**
+ *	buffer_start_callback: - Write start-buffer event to start of buffer.
+ *	@channel_handle: the channel id
+ *	@current_write_pos: position in sub-buffer client should write to
+ *	@buffer_id: the id of the new sub-buffer
+ *	@start_time: the timestamp associated with the start of sub-buffer
+ *	@start_tsc: the TSC associated with the timestamp, if using_tsc
+ *	@using_tsc: boolean, indicates whether start_tsc is valid
+ *
+ *	This is the relayfs buffer_start() callback implementation for
+ *	the tracer.  We write the start event directly to the address
+ *	contained in the current_write_pos param.  If this is the first
+ *	sub-buffer, we also write the start event.  Of course we reserved
+ *	the number of bytes we're writing when we opened the channel, which
+ *	is the number we return.
+ */
+static int buffer_start_callback(int channel_handle,
+				 char * current_write_pos,
+				 u32 buffer_id,
+				 struct timeval start_time,
+				 u32 start_tsc,
+				 int using_tsc) 
+{
+	trace_buffer_start start_buffer_event;
+	u8 event_id;
+	u32 time_delta;
+	uint16_t data_size;
+	struct trace_struct *trace = ltt_channel_trace(channel_handle);
+
+	if (!trace)
+		return 0;
+	
+	start_buffer_event.id = buffer_id;
+	start_buffer_event.time = start_time;
+	start_buffer_event.tsc = start_tsc;
+
+	event_id = TRACE_EV_BUFFER_START;
+	relay_write_direct(current_write_pos,
+			   &event_id,
+			   sizeof(event_id));
+
+	time_delta = switch_time_delta(start_tsc, using_tsc);
+	relay_write_direct(current_write_pos,
+			   &time_delta,
+			   sizeof(time_delta));
+
+	relay_write_direct(current_write_pos,
+			   &start_buffer_event,
+			   sizeof(start_buffer_event));
+
+	data_size = sizeof(event_id)
+	    + sizeof(time_delta)
+	    + sizeof(start_buffer_event)
+	    + sizeof(data_size);
+
+	relay_write_direct(current_write_pos,
+			   &data_size,
+			   sizeof(data_size));
+
+	if (buffer_id == 0) /* first buffer */
+		data_size += write_start_event(trace, channel_handle, current_write_pos, start_tsc, using_tsc);
+	
+	return (int)data_size;
+}
+
+/**
+ *	buffer_end_callback - called at the end of a sub-buffer
+ *	@channel_handle: the channel id
+ *	@current_write_pos: position in sub-buffer of end of data
+ *	@end_of_buffer: the position of the end of the sub-buffer
+ *	@end_time: the timestamp associated with the end of the sub-buffer
+ *	@end_tsc: the TSC associated with the end_time, if using_tsc
+ *	@using_tsc: boolean, indicates whether end_tsc is valid
+ *
+ *	This is the relayfs buffer_end() callback implementation for
+ *	the tracer.  We write the end event directly to the address
+ *	contained in the current_write_pos param.  We also calculate
+ *	the 'size_lost' or unused bytes at the end of the sub-buffer
+ *	and write that value to the very end of the sub-buffer for
+ *	post-processing.  Of course we reserved	the number of bytes
+ *	we're writing when we opened the channel, which is the number
+ *	we return.
+ */
+static int buffer_end_callback(int channel_handle,
+			       char * current_write_pos,
+			       char * end_of_buffer,
+			       struct timeval end_time,
+			       u32 end_tsc,
+			       int using_tsc) 
+{
+ 	trace_buffer_end end_buffer_event;
+	u8 event_id;
+	u32 time_delta;
+	char* init_write_pos = current_write_pos;
+	uint16_t data_size;
+	u32 size_lost;
+	u8 cpu_id;
+	struct trace_struct *trace;
+
+	end_buffer_event.time = end_time;
+	end_buffer_event.tsc = end_tsc;
+
+	cpu_id = (u8)ltt_channel_cpuid(channel_handle);
+	trace = ltt_channel_trace(channel_handle);
+	if (!trace)
+		return 0;
+
+	if (trace->log_cpuid == 1)
+		relay_write_direct(current_write_pos,
+				   &cpu_id,
+				   sizeof(cpu_id));
+
+	event_id = TRACE_EV_BUFFER_END;
+	relay_write_direct(current_write_pos,
+			   &event_id,
+			   sizeof(event_id));
+
+	time_delta = switch_time_delta(end_tsc, using_tsc);
+	relay_write_direct(current_write_pos,
+			   &time_delta,
+			   sizeof(time_delta));
+
+	relay_write_direct(current_write_pos,
+			   &end_buffer_event,
+			   sizeof(end_buffer_event));
+
+	data_size = sizeof(event_id)
+		+ sizeof(time_delta)
+		+ sizeof(end_buffer_event)
+		+ sizeof(data_size);
+
+	relay_write_direct(current_write_pos,
+			   &data_size,
+			   sizeof(data_size));
+
+	/* size lost includes size of end buffer event */
+	size_lost = end_of_buffer - init_write_pos;
+	*((u32 *) (end_of_buffer - sizeof(size_lost))) = size_lost;
+
+	return (int)data_size;
+}
+
+/**
+ *	deliver_callback - called when data is ready for the tracer
+ *	@channel_handle: the channel id
+ *	@from: the start of the delivered data
+ *	@len: the length of the delivered data
+ *
+ *	This is the relayfs deliver() callback implementation for
+ *	the tracer.  We simply set the send_signal flag, which will
+ *	be checked when the current write is finished, at which 
+ *	point the daemon will be signaled to read the buffer.
+ */
+void deliver_callback(int channel_handle,
+		      char * from,
+		      u32 len)
+{
+	struct trace_struct *trace;
+	int cpu_id;
+	
+	trace = ltt_channel_trace(channel_handle);
+	if (!trace)
+		return;
+	
+	cpu_id = ltt_channel_cpuid(channel_handle);
+	if (cpu_id == -1)
+		return;
+
+	set_bit(cpu_id, &trace->buffer_switches_pending);
+}
+
+static int fileop_notify(int rchan_id,
+			 struct file *filp,
+			 enum relay_fileop fileop)
+{
+	struct rchan_reader *map_reader;
+	struct rchan_reader *open_file_reader;
+	struct rchan *rchan;
+	u8 cpu_id;
+	unsigned int trace_handle;
+
+	trace_handle = ltt_channel_trace_handle(rchan_id);
+	if (trace_handle == -1)
+		return 0;
+	
+	if (fileop == RELAY_FILE_MAP) {
+		cpu_id = (u8)ltt_channel_cpuid(rchan_id);
+		open_file_reader = (struct rchan_reader *)filp->private_data;
+		rchan = open_file_reader->rchan;
+		if (atomic_read(&rchan->mapped))
+			return -EBUSY;
+		map_reader = add_map_reader(rchan_id);
+		trace_channel_reader(trace_handle, cpu_id) = map_reader;
+	} else if (fileop == RELAY_FILE_UNMAP) {
+		cpu_id = (u8)ltt_channel_cpuid(rchan_id);
+		remove_map_reader(trace_channel_reader(trace_handle, cpu_id));
+		trace_channel_reader(trace_handle, cpu_id) = NULL;
+	}
+
+	return 0;
+}
+
+static struct rchan_callbacks ltt_callbacks = {
+	.buffer_start = buffer_start_callback,
+	.buffer_end = buffer_end_callback,
+	.deliver = deliver_callback,
+	.fileop_notify = fileop_notify,
+};
+
+/*
+ * Procfs kernel-user interface
+ */
+
+/**
+ *	proc_read_relayfs_path - procfs read callback for relayfs_path attr 
+ */
+static int proc_read_relayfs_path(char *page, char **start, off_t off, 
+				  int count, int *eof, void *data)
+{
+	return sprintf(page, "%s", relayfs_path);
+}
+
+/**
+ *	proc_write_relayfs_path - procfs write callback for relayfs_path attr 
+ *
+ *	Sets the path to the trace files within relayfs for the current trace.
+ */
+static int proc_write_relayfs_path(struct file *filp, const char *buffer,
+				   unsigned long count, void *data)
+{
+	unsigned long len;
+
+	if (count > PATH_MAX)
+		len = PATH_MAX;
+	else
+		len = count;
+	
+	if (copy_from_user(relayfs_path, buffer, len))
+		return -EFAULT;
+
+	if (len != PATH_MAX)
+		relayfs_path[len] = '\0';
+
+	return len;
+}
+
+/**
+ *	populate_handle_proc_dir - populate proc dir with trace attributes
+ *	@trace_handle: the trace handle for this trace run
+ *	@handle_dir: the directory to populate
+ *
+ *	This function populates the handle dir with attribute files.
+ *
+ *	Returns 0 if successful, negative if not.
+ */
+static int populate_handle_proc_dir(unsigned int trace_handle,
+				    struct proc_dir_entry *handle_dir)
+{
+	struct proc_dir_entry * file_entry;
+	int err = 0;
+
+	file_entry = create_proc_entry("relayfs_path", 0666, handle_dir);
+
+	if (file_entry == NULL) {
+		err = -ENOMEM;
+		return err;
+	}
+
+	file_entry->read_proc = proc_read_relayfs_path;
+	file_entry->write_proc = proc_write_relayfs_path;
+	file_entry->data = (void *)trace_handle;
+	file_entry->owner = THIS_MODULE;
+
+	return err;
+}
+
+/**
+ *	create_handle_proc_dir - create proc dir for trace attributes
+ *	@trace_handle: the trace handle for this trace run
+ *
+ *	This function creates a proc dir to communicate trace attribute
+ *	values between the daemon and the tracer.  It also populates the
+ *	new dir with the attribute files.
+ *
+ *	Retruns the proc dir entry if successful, NULL otherwise.
+ */
+static struct proc_dir_entry *create_handle_proc_dir(unsigned int trace_handle)
+{
+	char handle_dir_name[22];
+	struct proc_dir_entry *handle_dir;
+
+	sprintf(handle_dir_name, "%u", trace_handle);
+
+	handle_dir = proc_mkdir(handle_dir_name, ltt_proc_root_entry);
+
+	if (handle_dir == NULL) {
+		return NULL;
+	}
+	else
+		handle_dir->owner = THIS_MODULE;
+	
+	if (populate_handle_proc_dir(trace_handle, handle_dir)) {
+		remove_proc_entry(handle_dir_name, ltt_proc_root_entry);
+		handle_dir = NULL;
+	}
+		
+	return handle_dir;
+}
+
+/**
+ *	depopulate_handle_proc_dir - remove proc dir entries for handle_dir
+ *	@handle_dir: the directory to depopulate
+ *
+ *	This function removes the attribute files from the handle dir.
+ */
+static void depopulate_handle_proc_dir(struct proc_dir_entry *handle_dir)
+{
+	remove_proc_entry("relayfs_path", handle_dir);
+}
+
+/**
+ *	remove_handle_proc_dir - remove proc dir for trace attributes
+ *	@handle_dir: the directory
+ *	@trace_handle: the trace handle for this trace run
+ *
+ *	This function removes a trace handle's proc dir.  It first
+ *	depopulates the dir of attribute files.
+ */
+static void remove_handle_proc_dir(struct proc_dir_entry *handle_dir, 
+				   unsigned int trace_handle)
+{
+	char handle_dir_name[22];
+
+	depopulate_handle_proc_dir(handle_dir);
+	
+	sprintf(handle_dir_name, "%u", trace_handle);
+	remove_proc_entry(handle_dir_name, ltt_proc_root_entry);
+}
+
+/*
+ * Initialization and finalization
+ */
+
+static int __init init_ltt(void)
+{
+	int i;
+	int err = 0;
+
+	ltt_proc_root_entry = proc_mkdir("ltt", NULL);
+
+	if (ltt_proc_root_entry == NULL)
+		err = -ENOMEM;
+	else
+		ltt_proc_root_entry->owner = THIS_MODULE;
+	
+	for (i = 0; i < NR_TRACES; i++)
+		init_trace(&current_traces[i]);
+		
+	return err;
+}
+
+static void __exit exit_ltt(void)
+{
+}
+
+module_init(init_ltt)
+module_exit(exit_ltt)
+
+EXPORT_SYMBOL(ltt_set_trace_config);
+EXPORT_SYMBOL(ltt_get_trace_config);
+EXPORT_SYMBOL(ltt_create_event);
+EXPORT_SYMBOL(ltt_create_owned_event);
+EXPORT_SYMBOL(ltt_destroy_event);
+EXPORT_SYMBOL(ltt_destroy_owners_events);
+EXPORT_SYMBOL(ltt_log_std_formatted_event);
+EXPORT_SYMBOL(ltt_log_raw_event);
+EXPORT_SYMBOL(ltt_log_event);
+
+MODULE_AUTHOR("Karim Yaghmour, Tom Zanussi, Bob Wisniewski")
+MODULE_DESCRIPTION("Linux Trace Toolkit kernel core") 
+MODULE_LICENSE("GPL");
Index: linux.t/kernel/Makefile
===================================================================
--- linux.t.orig/kernel/Makefile	2004-03-22 20:23:56.962934077 -0500
+++ linux.t/kernel/Makefile	2004-03-22 20:25:22.620683760 -0500
@@ -24,6 +24,8 @@ obj-$(CONFIG_STOP_MACHINE) += stop_machi
 obj-$(CONFIG_EVLOG) += evlbuf.o evlapi.o evlposix.o
 obj-$(CONFIG_HOOK) += hook.o
 obj-$(CONFIG_TRIGEVENT_HOOKS) += trigevent_hooks.o
+obj-$(CONFIG_LTT) += ltt/
+
 
 ifneq ($(CONFIG_IA64),y)
 # According to Alan Modra <alan@linuxcare.com.au>, the -fno-omit-frame-pointer is
Index: linux.t/kernel/exit.c
===================================================================
--- linux.t.orig/kernel/exit.c	2004-03-22 20:23:56.964933488 -0500
+++ linux.t/kernel/exit.c	2004-03-22 20:25:28.301008931 -0500
@@ -26,8 +26,8 @@
 #include <linux/kdb.h>
 #endif
 #include <linux/ckrm.h>
-
 #include <linux/trigevent_hooks.h>
+#include <linux/ltt.h>
 
 #include <asm/uaccess.h>
 #include <asm/pgtable.h>
@@ -783,6 +783,7 @@ asmlinkage NORET_TYPE void do_exit(long 
 	acct_process(code);
 	__exit_mm(tsk);
 
+	TRACE_CLEANUP();  
 	TRIG_EVENT(process_exit_hook, tsk->pid);
 
 	exit_sem(tsk);
Index: linux.t/Documentation/hook/Makefile
===================================================================
--- linux.t.orig/Documentation/hook/Makefile	2004-03-22 20:23:56.778988292 -0500
+++ linux.t/Documentation/hook/Makefile	2003-09-23 18:19:32.000000000 -0400
@@ -1 +0,0 @@
-obj-m := khook.o kexit.o
Index: linux.t/include/linux/ltt.h
===================================================================
--- linux.t.orig/include/linux/ltt.h	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/include/linux/ltt.h	2004-03-22 20:25:22.617684644 -0500
@@ -0,0 +1,763 @@
+/*
+ * linux/include/linux/ltt.h
+ *
+ * Copyright (C) 1999-2004 Karim Yaghmour (karim@opersys.com)
+ *
+ * This contains the necessary definitions for the Linux Trace Toolkit.
+ */
+
+#ifndef _LINUX_TRACE_H
+#define _LINUX_TRACE_H
+
+#include <linux/config.h>
+#include <linux/types.h>
+#include <linux/sched.h>
+
+#include <linux/relayfs_fs.h>
+
+/* Is kernel tracing enabled  */
+#if defined(CONFIG_LTT) 
+/* Don't set this to "1" unless you really know what you're doing */
+#define LTT_UNPACKED_STRUCTS	0
+
+/* Structure packing within the trace */
+#if LTT_UNPACKED_STRUCTS
+#define LTT_PACKED_STRUCT
+#else
+#define LTT_PACKED_STRUCT __attribute__ ((packed))
+#endif
+
+typedef u64 trace_event_mask;
+
+#define CUSTOM_EVENT_MAX_SIZE		8192
+#define CUSTOM_EVENT_TYPE_STR_LEN	20
+#define CUSTOM_EVENT_DESC_STR_LEN	100
+#define CUSTOM_EVENT_FORM_STR_LEN	256
+#define CUSTOM_EVENT_FINAL_STR_LEN	200
+
+#define CUSTOM_EVENT_FORMAT_TYPE_NONE	0
+#define CUSTOM_EVENT_FORMAT_TYPE_STR	1
+#define CUSTOM_EVENT_FORMAT_TYPE_HEX	2
+#define CUSTOM_EVENT_FORMAT_TYPE_XML	3
+#define CUSTOM_EVENT_FORMAT_TYPE_IBM	4
+
+#define TRACE_MAX_HANDLES		256
+
+/* We currently support 2 traces, normal trace and flight recorder */
+#define NR_TRACES			2
+#define TRACE_HANDLE			0
+#define FLIGHT_HANDLE			1
+
+/* Convenience accessors */
+#define waiting_for_cpu_async(trace_handle, cpu) (current_traces[trace_handle].relay_data[cpu].waiting_for_cpu_async)
+#define trace_channel_handle(trace_handle, cpu) (current_traces[trace_handle].relay_data[cpu].channel_handle)
+#define trace_channel_reader(trace_handle, cpu) (current_traces[trace_handle].relay_data[cpu].reader)
+#define trace_buffers_full(cpu) (daemon_relay_data[cpu].buffers_full)
+#define events_lost(trace_handle, cpu) (current_traces[trace_handle].relay_data[cpu].events_lost)
+
+/* System types */
+#define TRACE_SYS_TYPE_VANILLA_LINUX	1
+
+/* Architecture types */
+#define TRACE_ARCH_TYPE_I386			1
+#define TRACE_ARCH_TYPE_PPC			2
+#define TRACE_ARCH_TYPE_SH			3
+#define TRACE_ARCH_TYPE_S390			4
+#define TRACE_ARCH_TYPE_MIPS			5
+#define TRACE_ARCH_TYPE_ARM			6
+
+/* Standard definitions for variants */
+#define TRACE_ARCH_VARIANT_NONE             0   /* Main architecture implementation */
+
+/* The maximum number of CPUs the kernel might run on */
+#define MAX_NR_CPUS 32
+
+/* Per-CPU channel information */
+struct channel_data
+{
+	int channel_handle;
+	struct rchan_reader *reader;
+	atomic_t waiting_for_cpu_async;
+	u32 events_lost;
+};
+
+/* Per-trace status info */
+struct trace_info
+{
+	int			active;
+	unsigned int		trace_handle;
+	int			paused;
+	int			flight_recorder;
+	int			use_locking;
+	int			using_tsc;
+	u32			n_buffers;
+	u32			buf_size;
+	trace_event_mask	traced_events;
+	trace_event_mask	log_event_details_mask;
+	u32			buffers_produced[MAX_NR_CPUS];
+};
+
+/* Status info for all traces */
+struct tracer_status
+{
+	int num_cpus;
+	struct trace_info traces[NR_TRACES];
+};
+
+/* Per-trace information - each trace/flight recorder represented by one */
+struct trace_struct
+{
+	unsigned int		trace_handle;	/* For convenience */
+	struct trace_struct	*active;	/* 'this' if active, or NULL */
+	int			paused;		/* Not currently logging */
+	struct channel_data relay_data[NR_CPUS];/* Relayfs handles, by CPU */
+	int			flight_recorder;/* i.e. this is not a trace */
+	struct task_struct	*daemon_task_struct;/* Daemon associated with trace */
+	struct _trace_start	*trace_start_data; /* Trace start event data, for flight recorder */
+	int			tracer_started;
+	int			tracer_stopping;
+	struct proc_dir_entry *	proc_dir_entry;	/* proc/ltt/0..1 */
+	trace_event_mask	traced_events;
+	trace_event_mask	log_event_details_mask;
+	u32			n_buffers;	/* Number of sub-buffers */
+	u32			buf_size;	/* Size of sub-buffer */
+	int			use_locking;
+	int			using_tsc;
+	int			log_cpuid;
+	int			tracing_pid;
+	int			tracing_pgrp;
+	int			tracing_gid;
+	int			tracing_uid;
+	pid_t			traced_pid;
+	pid_t			traced_pgrp;
+	gid_t			traced_gid;
+	uid_t			traced_uid;
+	unsigned long		buffer_switches_pending;/* For trace */  
+};
+
+
+extern int ltt_set_trace_config(
+	int		do_syscall_depth,
+	int		do_syscall_bounds,
+	int		eip_depth,
+	void		*eip_lower_bound,
+	void		*eip_upper_bound);
+extern int ltt_get_trace_config(
+	int		*do_syscall_depth,
+	int		*do_syscall_bounds,
+	int		*eip_depth,
+	void		**eip_lower_bound,
+	void		**eip_upper_bound);
+extern int ltt_create_event(
+	char		*event_type,
+	char		*event_desc,
+	int		format_type,
+	char		*format_data);
+extern int ltt_create_owned_event(
+	char		*event_type,
+	char		*event_desc,
+	int		format_type,
+	char		*format_data,
+	pid_t		owner_pid);
+extern void ltt_destroy_event(
+	int		event_id);
+extern void ltt_destroy_owners_events(
+	pid_t		owner_pid);
+extern void ltt_reregister_custom_events(void);
+extern int ltt_log_std_formatted_event(
+	int		event_id,
+	...);
+extern int ltt_log_raw_event(
+	int		event_id,
+	int		event_size,
+	void		*event_data);
+extern int _ltt_log_event(
+	struct trace_struct *trace,
+	u8		event_id,
+	void		*event_struct,
+	u8		cpu_id);
+extern int ltt_log_event(
+	u8		event_id,
+	void		*event_struct);
+extern int ltt_valid_trace_handle(
+	unsigned int	tracer_handle);
+extern int ltt_alloc_trace_handle(
+	unsigned int	tracer_handle);
+extern int ltt_free_trace_handle(
+	unsigned int	tracer_handle);
+extern int ltt_free_daemon_handle(
+	struct trace_struct *trace);
+extern void ltt_free_all_handles(
+	struct task_struct*	task_ptr);
+extern int ltt_set_buffer_size(
+	struct trace_struct *trace,
+	int		buffers_size, 
+	char *		dirname);
+extern int ltt_set_n_buffers(
+	struct trace_struct *trace,
+	int		no_buffers);
+extern int ltt_set_default_config(
+	struct trace_struct *trace);
+
+static inline void TRACE_EVENT(u8 event_id, void* data)
+{
+	ltt_log_event(event_id, data);
+}
+
+/* Traced events */
+enum {
+	TRACE_EV_START = 0,	/* This is to mark the trace's start */
+	TRACE_EV_SYSCALL_ENTRY,	/* Entry in a given system call */
+	TRACE_EV_SYSCALL_EXIT,	/* Exit from a given system call */
+	TRACE_EV_TRAP_ENTRY,	/* Entry in a trap */
+	TRACE_EV_TRAP_EXIT,	/* Exit from a trap */
+	TRACE_EV_IRQ_ENTRY,	/* Entry in an irq */
+	TRACE_EV_IRQ_EXIT,	/* Exit from an irq */
+	TRACE_EV_SCHEDCHANGE,	/* Scheduling change */
+	TRACE_EV_KERNEL_TIMER,	/* The kernel timer routine has been called */
+	TRACE_EV_SOFT_IRQ,	/* Hit key part of soft-irq management */
+	TRACE_EV_PROCESS,	/* Hit key part of process management */
+	TRACE_EV_FILE_SYSTEM,	/* Hit key part of file system */
+	TRACE_EV_TIMER,		/* Hit key part of timer management */
+	TRACE_EV_MEMORY,	/* Hit key part of memory management */
+	TRACE_EV_SOCKET,	/* Hit key part of socket communication */
+	TRACE_EV_IPC,		/* Hit key part of System V IPC */
+	TRACE_EV_NETWORK,	/* Hit key part of network communication */
+	TRACE_EV_BUFFER_START,	/* Mark the begining of a trace buffer */
+	TRACE_EV_BUFFER_END,	/* Mark the ending of a trace buffer */
+	TRACE_EV_NEW_EVENT,	/* New event type */
+	TRACE_EV_CUSTOM,	/* Custom event */
+	TRACE_EV_CHANGE_MASK,	/* Change in event mask */
+	TRACE_EV_HEARTBEAT	/* Heartbeat event */
+};
+
+/* Number of traced events */
+#define TRACE_EV_MAX           TRACE_EV_HEARTBEAT
+
+/* Information logged when a trace is started */
+#define TRACER_MAGIC_NUMBER     0x00D6B7ED
+#define TRACER_VERSION_MAJOR    2
+#define TRACER_VERSION_MINOR    2
+typedef struct _trace_start {
+	u32 magic_number;
+	u32 arch_type;
+	u32 arch_variant;
+	u32 system_type;
+	u8 major_version;
+	u8 minor_version;
+
+	u32 buffer_size;
+	trace_event_mask event_mask;
+	trace_event_mask details_mask;
+	u8 log_cpuid;
+	u8 use_tsc;
+	u8 flight_recorder;
+} LTT_PACKED_STRUCT trace_start;
+
+/*  TRACE_SYSCALL_ENTRY */
+typedef struct _trace_syscall_entry {
+	u8 syscall_id;		/* Syscall entry number in entry.S */
+	u32 address;		/* Address from which call was made */
+} LTT_PACKED_STRUCT trace_syscall_entry;
+
+/*  TRACE_TRAP_ENTRY */
+#ifndef __s390__
+typedef struct _trace_trap_entry {
+	u16 trap_id;		/* Trap number */
+	u32 address;		/* Address where trap occured */
+} LTT_PACKED_STRUCT trace_trap_entry;
+static inline void TRACE_TRAP_ENTRY(u16 trap_id, u32 address)
+#else
+typedef u64 trapid_t;
+typedef struct _trace_trap_entry {
+	trapid_t trap_id;	/* Trap number */
+	u32 address;		/* Address where trap occured */
+} LTT_PACKED_STRUCT trace_trap_entry;
+static inline void TRACE_TRAP_ENTRY(trapid_t trap_id, u32 address)
+#endif
+{
+	trace_trap_entry trap_event;
+
+	trap_event.trap_id = trap_id;
+	trap_event.address = address;
+
+	ltt_log_event(TRACE_EV_TRAP_ENTRY, &trap_event);
+}
+
+/*  TRACE_TRAP_EXIT */
+static inline void TRACE_TRAP_EXIT(void)
+{
+	ltt_log_event(TRACE_EV_TRAP_EXIT, NULL);
+}
+
+/*  TRACE_IRQ_ENTRY */
+typedef struct _trace_irq_entry {
+	u8 irq_id;		/* IRQ number */
+	u8 kernel;		/* Are we executing kernel code */
+} LTT_PACKED_STRUCT trace_irq_entry;
+static inline void TRACE_IRQ_ENTRY(u8 irq_id, u8 in_kernel)
+{
+	trace_irq_entry irq_entry;
+
+	irq_entry.irq_id = irq_id;
+	irq_entry.kernel = in_kernel;
+
+	ltt_log_event(TRACE_EV_IRQ_ENTRY, &irq_entry);
+}
+
+/*  TRACE_IRQ_EXIT */
+static inline void TRACE_IRQ_EXIT(void)
+{
+	ltt_log_event(TRACE_EV_IRQ_EXIT, NULL);
+}
+
+/*  TRACE_SCHEDCHANGE */
+typedef struct _trace_schedchange {
+	u32 out;		/* Outgoing process */
+	u32 in;			/* Incoming process */
+	u32 out_state;		/* Outgoing process' state */
+} LTT_PACKED_STRUCT trace_schedchange;
+static inline void TRACE_SCHEDCHANGE(task_t * task_out, task_t * task_in)
+{
+	trace_schedchange sched_event;
+
+	sched_event.out = (u32) task_out->pid;
+	sched_event.in = (u32) task_in;
+	sched_event.out_state = (u32) task_out->state;
+
+	ltt_log_event(TRACE_EV_SCHEDCHANGE, &sched_event);
+}
+
+/*  TRACE_SOFT_IRQ */
+enum {
+	TRACE_EV_SOFT_IRQ_BOTTOM_HALF = 1,	/* Conventional bottom-half */
+	TRACE_EV_SOFT_IRQ_SOFT_IRQ,		/* Real soft-irq */
+	TRACE_EV_SOFT_IRQ_TASKLET_ACTION,	/* Tasklet action */
+	TRACE_EV_SOFT_IRQ_TASKLET_HI_ACTION	/* Tasklet hi-action */
+};
+typedef struct _trace_soft_irq {
+	u8 event_sub_id;	/* Soft-irq event Id */
+	u32 event_data;
+} LTT_PACKED_STRUCT trace_soft_irq;
+static inline void TRACE_SOFT_IRQ(u8 ev_id, u32 data)
+{
+	trace_soft_irq soft_irq_event;
+
+	soft_irq_event.event_sub_id = ev_id;
+	soft_irq_event.event_data = data;
+
+	ltt_log_event(TRACE_EV_SOFT_IRQ, &soft_irq_event);
+}
+
+/*  TRACE_PROCESS */
+enum {
+	TRACE_EV_PROCESS_KTHREAD = 1,	/* Creation of a kernel thread */
+	TRACE_EV_PROCESS_FORK,		/* A fork or clone occured */
+	TRACE_EV_PROCESS_EXIT,		/* An exit occured */
+	TRACE_EV_PROCESS_WAIT,		/* A wait occured */
+	TRACE_EV_PROCESS_SIGNAL,	/* A signal has been sent */
+	TRACE_EV_PROCESS_WAKEUP		/* Wake up a process */
+};
+typedef struct _trace_process {
+	u8 event_sub_id;	/* Process event ID */
+	u32 event_data1;
+	u32 event_data2;
+} LTT_PACKED_STRUCT trace_process;
+static inline void TRACE_PROCESS(u8 ev_id, u32 data1, u32 data2)
+{
+	trace_process proc_event;
+
+	proc_event.event_sub_id = ev_id;
+	proc_event.event_data1 = data1;
+	proc_event.event_data2 = data2;
+
+	ltt_log_event(TRACE_EV_PROCESS, &proc_event);
+}
+static inline void TRACE_PROCESS_EXIT(u32 data1, u32 data2)
+{
+	trace_process proc_event;
+
+	proc_event.event_sub_id = TRACE_EV_PROCESS_EXIT;
+
+	/**** WARNING ****/
+	/* Regardless of whether this trace statement is active or not, these
+	two function must be called, otherwise there will be inconsistencies
+	in the kernel's structures. */
+/*
+	ltt_destroy_owners_events(current->pid);
+	ltt_free_all_handles(current);
+*/
+	ltt_log_event(TRACE_EV_PROCESS, &proc_event);
+}
+
+/*  TRACE_FILE_SYSTEM */
+enum {
+	TRACE_EV_FILE_SYSTEM_BUF_WAIT_START = 1,	/* Starting to wait for a data buffer */
+	TRACE_EV_FILE_SYSTEM_BUF_WAIT_END,		/* End to wait for a data buffer */
+	TRACE_EV_FILE_SYSTEM_EXEC,			/* An exec occured */
+	TRACE_EV_FILE_SYSTEM_OPEN,			/* An open occured */
+	TRACE_EV_FILE_SYSTEM_CLOSE,			/* A close occured */
+	TRACE_EV_FILE_SYSTEM_READ,			/* A read occured */
+	TRACE_EV_FILE_SYSTEM_WRITE,			/* A write occured */
+	TRACE_EV_FILE_SYSTEM_SEEK,			/* A seek occured */
+	TRACE_EV_FILE_SYSTEM_IOCTL,			/* An ioctl occured */
+	TRACE_EV_FILE_SYSTEM_SELECT,			/* A select occured */
+	TRACE_EV_FILE_SYSTEM_POLL			/* A poll occured */
+};
+typedef struct _trace_file_system {
+	u8 event_sub_id;	/* File system event ID */
+	u32 event_data1;
+	u32 event_data2;
+	char *file_name;	/* Name of file operated on */
+} LTT_PACKED_STRUCT trace_file_system;
+static inline void TRACE_FILE_SYSTEM(u8 ev_id, u32 data1, u32 data2, const unsigned char *file_name)
+{
+	trace_file_system fs_event;
+
+	fs_event.event_sub_id = ev_id;
+	fs_event.event_data1 = data1;
+	fs_event.event_data2 = data2;
+	fs_event.file_name = (char*) file_name;
+
+	ltt_log_event(TRACE_EV_FILE_SYSTEM, &fs_event);
+}
+
+/*  TRACE_TIMER */
+enum {
+	TRACE_EV_TIMER_EXPIRED = 1,	/* Timer expired */
+	TRACE_EV_TIMER_SETITIMER,	/* Setting itimer occurred */
+	TRACE_EV_TIMER_SETTIMEOUT	/* Setting sched timeout occurred */
+};
+typedef struct _trace_timer {
+	u8 event_sub_id;	/* Timer event ID */
+	u8 event_sdata;		/* Short data */
+	u32 event_data1;
+	u32 event_data2;
+} LTT_PACKED_STRUCT trace_timer;
+static inline void TRACE_TIMER(u8 ev_id, u8 sdata, u32 data1, u32 data2)
+{
+	trace_timer timer_event;
+
+	timer_event.event_sub_id = ev_id;
+	timer_event.event_sdata = sdata;
+	timer_event.event_data1 = data1;
+	timer_event.event_data2 = data2;
+
+	ltt_log_event(TRACE_EV_TIMER, &timer_event);
+}
+
+/*  TRACE_MEMORY */
+enum {
+	TRACE_EV_MEMORY_PAGE_ALLOC = 1,		/* Allocating pages */
+	TRACE_EV_MEMORY_PAGE_FREE,		/* Freing pages */
+	TRACE_EV_MEMORY_SWAP_IN,		/* Swaping pages in */
+	TRACE_EV_MEMORY_SWAP_OUT,		/* Swaping pages out */
+	TRACE_EV_MEMORY_PAGE_WAIT_START,	/* Start to wait for page */
+	TRACE_EV_MEMORY_PAGE_WAIT_END		/* End to wait for page */
+};
+typedef struct _trace_memory {
+	u8 event_sub_id;	/* Memory event ID */
+	u32 event_data;
+} LTT_PACKED_STRUCT trace_memory;
+static inline void TRACE_MEMORY(u8 ev_id, u32 data)
+{
+	trace_memory memory_event;
+
+	memory_event.event_sub_id = ev_id;
+	memory_event.event_data = data;
+
+	ltt_log_event(TRACE_EV_MEMORY, &memory_event);
+}
+
+/*  TRACE_SOCKET */
+enum {
+	TRACE_EV_SOCKET_CALL = 1,	/* A socket call occured */
+	TRACE_EV_SOCKET_CREATE,		/* A socket has been created */
+	TRACE_EV_SOCKET_SEND,		/* Data was sent to a socket */
+	TRACE_EV_SOCKET_RECEIVE		/* Data was read from a socket */
+};
+typedef struct _trace_socket {
+	u8 event_sub_id;	/* Socket event ID */
+	u32 event_data1;
+	u32 event_data2;
+} LTT_PACKED_STRUCT trace_socket;
+static inline void TRACE_SOCKET(u8 ev_id, u32 data1, u32 data2)
+{
+	trace_socket socket_event;
+
+	socket_event.event_sub_id = ev_id;
+	socket_event.event_data1 = data1;
+	socket_event.event_data2 = data2;
+
+	ltt_log_event(TRACE_EV_SOCKET, &socket_event);
+}
+
+/*  TRACE_IPC */
+enum {
+	TRACE_EV_IPC_CALL = 1,		/* A System V IPC call occured */
+	TRACE_EV_IPC_MSG_CREATE,	/* A message queue has been created */
+	TRACE_EV_IPC_SEM_CREATE,	/* A semaphore was created */
+	TRACE_EV_IPC_SHM_CREATE		/* A shared memory segment has been created */
+};
+typedef struct _trace_ipc {
+	u8 event_sub_id;	/* IPC event ID */
+	u32 event_data1;
+	u32 event_data2;
+} LTT_PACKED_STRUCT trace_ipc;
+static inline void TRACE_IPC(u8 ev_id, u32 data1, u32 data2)
+{
+	trace_ipc ipc_event;
+
+	ipc_event.event_sub_id = ev_id;
+	ipc_event.event_data1 = data1;
+	ipc_event.event_data2 = data2;
+
+	ltt_log_event(TRACE_EV_IPC, &ipc_event);
+}
+
+/*  TRACE_NETWORK */
+enum {
+	TRACE_EV_NETWORK_PACKET_IN = 1,	/* A packet came in */
+	TRACE_EV_NETWORK_PACKET_OUT	/* A packet was sent */
+};
+typedef struct _trace_network {
+	u8 event_sub_id;	/* Network event ID */
+	u32 event_data;
+} LTT_PACKED_STRUCT trace_network;
+static inline void TRACE_NETWORK(u8 ev_id, u32 data)
+{
+	trace_network net_event;
+
+	net_event.event_sub_id = ev_id;
+	net_event.event_data = data;
+
+	ltt_log_event(TRACE_EV_NETWORK, &net_event);
+}
+
+/* Start of trace buffer information */
+typedef struct _trace_buffer_start {
+	struct timeval time;	/* Time stamp of this buffer */
+	u32 tsc;   /* TSC of this buffer, if applicable */
+	u32 id;			/* Unique buffer ID */
+} LTT_PACKED_STRUCT trace_buffer_start;
+
+/* End of trace buffer information */
+typedef struct _trace_buffer_end {
+	struct timeval time;	/* Time stamp of this buffer */
+	u32 tsc;   /* TSC of this buffer, if applicable */
+} LTT_PACKED_STRUCT trace_buffer_end;
+
+/* Custom declared events */
+/* ***WARNING*** These structures should never be used as is, use the 
+   provided custom event creation and logging functions. */
+typedef struct _trace_new_event {
+	/* Basics */
+	u32 id;					/* Custom event ID */
+	char type[CUSTOM_EVENT_TYPE_STR_LEN];	/* Event type description */
+	char desc[CUSTOM_EVENT_DESC_STR_LEN];	/* Detailed event description */
+
+	/* Custom formatting */
+	u32 format_type;			/* Type of formatting */
+	char form[CUSTOM_EVENT_FORM_STR_LEN];	/* Data specific to format */
+} LTT_PACKED_STRUCT trace_new_event;
+typedef struct _trace_custom {
+	u32 id;			/* Event ID */
+	u32 data_size;		/* Size of data recorded by event */
+	void *data;		/* Data recorded by event */
+} LTT_PACKED_STRUCT trace_custom;
+
+/* TRACE_CHANGE_MASK */
+typedef struct _trace_change_mask {
+	trace_event_mask mask;	/* Event mask */
+} LTT_PACKED_STRUCT trace_change_mask;
+
+
+/*  TRACE_HEARTBEAT */
+static inline void TRACE_HEARTBEAT(void)
+{
+	ltt_log_event(TRACE_EV_HEARTBEAT, NULL);
+}
+
+/* Tracer properties */
+#define TRACER_DEFAULT_BUF_SIZE   50000
+#define TRACER_MIN_BUF_SIZE        1000
+#define TRACER_MAX_BUF_SIZE      500000
+#define TRACER_MIN_BUFFERS            2
+#define TRACER_MAX_BUFFERS          256
+
+#define TRACER_FIRST_EVENT_SIZE   (sizeof(u8) + sizeof(u32) + sizeof(trace_buffer_start) + sizeof(uint16_t))
+#define TRACER_START_TRACE_EVENT_SIZE   (sizeof(u8) + sizeof(u32) + sizeof(trace_start) + sizeof(uint16_t))
+#define TRACER_LAST_EVENT_SIZE   (sizeof(u8) \
+				  + sizeof(u8) \
+				  + sizeof(u32) \
+				  + sizeof(trace_buffer_end) \
+				  + sizeof(uint16_t) \
+				  + sizeof(u32))
+
+/* The configurations possible */
+enum {
+	TRACER_START = TRACER_MAGIC_NUMBER,	/* Start tracing events using the current configuration */
+	TRACER_STOP,				/* Stop tracing */
+	TRACER_CONFIG_DEFAULT,			/* Set the tracer to the default configuration */
+	TRACER_CONFIG_MEMORY_BUFFERS,		/* Set the memory buffers the daemon wants us to use */
+	TRACER_CONFIG_EVENTS,			/* Trace the given events */
+	TRACER_CONFIG_DETAILS,			/* Record the details of the event, or not */
+	TRACER_CONFIG_CPUID,			/* Record the CPUID associated with the event */
+	TRACER_CONFIG_PID,			/* Trace only one process */
+	TRACER_CONFIG_PGRP,			/* Trace only the given process group */
+	TRACER_CONFIG_GID,			/* Trace the processes of a given group of users */
+	TRACER_CONFIG_UID,			/* Trace the processes of a given user */
+	TRACER_CONFIG_SYSCALL_EIP_DEPTH,	/* Set the call depth at which the EIP should be fetched on syscall */
+	TRACER_CONFIG_SYSCALL_EIP_LOWER,	/* Set the lowerbound address from which EIP is recorded on syscall */
+	TRACER_CONFIG_SYSCALL_EIP_UPPER,	/* Set the upperbound address from which EIP is recorded on syscall */
+	TRACER_DATA_COMITTED,			/* The daemon has comitted the last trace */
+	TRACER_GET_EVENTS_LOST,			/* Get the number of events lost */
+	TRACER_CREATE_USER_EVENT,		/* Create a user tracable event */
+	TRACER_DESTROY_USER_EVENT,		/* Destroy a user tracable event */
+	TRACER_TRACE_USER_EVENT,		/* Trace a user event */
+	TRACER_SET_EVENT_MASK,			/* Set the trace event mask */
+	TRACER_GET_EVENT_MASK,			/* Get the trace event mask */
+	TRACER_GET_BUFFER_CONTROL,		/* Get the buffer control data for the lockless schem*/
+	TRACER_CONFIG_N_MEMORY_BUFFERS,		/* Set the number of memory buffers the daemon wants us to use */
+	TRACER_CONFIG_USE_LOCKING,		/* Set the locking scheme to use */
+	TRACER_CONFIG_TIMESTAMP,		/* Set the timestamping method to use */
+	TRACER_GET_ARCH_INFO,			/* Get information about the CPU configuration */
+	TRACER_ALLOC_HANDLE,			/* Allocate a tracer handle */
+	TRACER_FREE_HANDLE,			/* Free a single handle */
+	TRACER_FREE_DAEMON_HANDLE,		/* Free the daemon's handle */
+	TRACER_FREE_ALL_HANDLES,		/* Free all handles */
+	TRACER_MAP_BUFFER,			/* Map buffer to process-space */
+	TRACER_PAUSE,				/* Pause tracing */
+	TRACER_UNPAUSE,				/* Unpause tracing */
+	TRACER_GET_START_INFO,			/* trace start data */
+	TRACER_GET_STATUS			/* status of traces */
+};
+
+/* Lockless scheme definitions */
+#define TRACER_LOCKLESS_MIN_BUF_SIZE CUSTOM_EVENT_MAX_SIZE + 8192
+#define TRACER_LOCKLESS_MAX_BUF_SIZE 0x1000000
+
+/* Flags used for per-CPU tasks */
+#define LTT_NOTHING_TO_DO      0x00
+#define LTT_FINALIZE_TRACE     0x02
+#define LTT_TRACE_HEARTBEAT    0x08
+
+/* How often the LTT per-CPU timers fire */
+#define LTT_PERCPU_TIMER_FREQ  (HZ/10);
+
+/* Used for sharing per-buffer information between driver and daemon */
+struct buf_control_info
+{
+	s16 cpu_id;
+	u32 buffer_switches_pending;
+	u32 buffer_control_valid;
+
+	u32 buf_size;
+	u32 n_buffers;
+	u32 cur_idx;
+	u32 buffers_produced;
+	u32 buffers_consumed;
+	int buffer_complete[TRACER_MAX_BUFFERS];
+};
+
+/* Used for sharing buffer-commit information between driver and daemon */
+struct buffers_committed
+{
+	u8 cpu_id;
+	u32 buffers_consumed;
+};
+
+/* Used for specifying size/cpu id pair between driver and daemon */
+struct cpu_mmap_data
+{
+	u8 cpu_id;
+	unsigned long map_size;
+};
+
+/* Used for sharing architecture-specific info between driver and daemon */
+struct ltt_arch_info
+{
+	int n_cpus;
+	int page_shift;
+};
+
+extern __inline__ int ltt_set_bit(int nr, void *addr)
+{
+	unsigned char *p = addr;
+	unsigned char mask = 1 << (nr & 7);
+	unsigned char old;
+
+	p += nr >> 3;
+	old = *p;
+	*p |= mask;
+
+	return ((old & mask) != 0);
+}
+
+extern __inline__ int ltt_clear_bit(int nr, void *addr)
+{
+	unsigned char *p = addr;
+	unsigned char mask = 1 << (nr & 7);
+	unsigned char old;
+
+	p += nr >> 3;
+	old = *p;
+	*p &= ~mask;
+
+	return ((old & mask) != 0);
+}
+
+extern __inline__ int ltt_test_bit(int nr, void *addr)
+{
+	unsigned char *p = addr;
+	unsigned char mask = 1 << (nr & 7);
+
+	p += nr >> 3;
+
+	return ((*p & mask) != 0);
+}
+
+/**
+ *	switch_time_delta: - Utility function getting buffer switch time delta.
+ *	@time_delta: previously calculated or retrieved time delta 
+ *
+ *	Returns the time_delta passed in if we're using TSC or 0 otherwise.
+ */
+static inline u32 switch_time_delta(u32 time_delta,
+				    int using_tsc)
+{
+	if((using_tsc == 1) && cpu_has_tsc)
+		return time_delta;
+	else
+		return 0;
+}
+
+static inline void TRACE_CLEANUP(void) {
+	ltt_destroy_owners_events(current->pid);
+	ltt_free_all_handles(current);
+}
+
+extern void change_traced_events(trace_event_mask *);
+#else				/* Kernel is configured without tracing */
+#define TRACE_EVENT(ID, DATA)
+#define TRACE_TRAP_ENTRY(ID, EIP)
+#define TRACE_TRAP_EXIT()
+#define TRACE_IRQ_ENTRY(ID, KERNEL)
+#define TRACE_IRQ_EXIT()
+#define TRACE_SCHEDCHANGE(OUT, IN)
+#define TRACE_SOFT_IRQ(ID, DATA)
+#define TRACE_PROCESS(ID, DATA1, DATA2)
+#define TRACE_PROCESS_EXIT(DATA1, DATA2)
+#define TRACE_FILE_SYSTEM(ID, DATA1, DATA2, FILE_NAME)
+#define TRACE_TIMER(ID, SDATA, DATA1, DATA2)
+#define TRACE_MEMORY(ID, DATA)
+#define TRACE_SOCKET(ID, DATA1, DATA2)
+#define TRACE_IPC(ID, DATA1, DATA2)
+#define TRACE_NETWORK(ID, DATA)
+#define TRACE_HEARTBEAT()
+static inline void TRACE_CLEANUP(void)	{}
+#endif				/* defined(CONFIG_LTT) */
+#endif				/* _LINUX_TRACE_H */
+
+
+
Index: linux.t/include/asm-i386/ltt.h
===================================================================
--- linux.t.orig/include/asm-i386/ltt.h	2003-09-23 18:19:32.000000000 -0400
+++ linux.t/include/asm-i386/ltt.h	2004-03-22 20:25:22.615685234 -0500
@@ -0,0 +1,15 @@
+/*
+ * linux/include/asm-i386/ltt.h
+ *
+ * Copyright (C) 2002, Karim Yaghmour
+ *
+ * i386 definitions for tracing system
+ */
+
+#include <linux/ltt.h>
+
+/* Current arch type */
+#define TRACE_ARCH_TYPE TRACE_ARCH_TYPE_I386
+
+/* Current variant type */
+#define TRACE_ARCH_VARIANT TRACE_ARCH_VARIANT_NONE
