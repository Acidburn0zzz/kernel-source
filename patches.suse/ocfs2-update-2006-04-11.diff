From: Mark Fasheh <mark.fasheh@oracle.com>
Subject: [oracle-dev] OCFS2 Code Update for SLES 10 - 2006-04-11
Patch-mainline: never - Oracle certification is separate from mainline

This patch is against kernel-source-2.6.16-20060408024659. It includes the
following patches from svn:

r2778: added source addr to bind() in o2net_start_connect()
r2779: mlog_errno() in extent_map.c
r2780: respond to on-disk corruption in the extent map code.
r2781: orphan recovery deadlock fix
r2782: dlm mastery fixes
r2783: dlm mastery fixes
r2784: remove all instances of MLFu64 in dlm
r2785: use hlists for lockres hash
r2787: multi node truncate fix
r2799: userdlm fixes

--
Mark Fasheh
Senior Software Developer, Oracle
mark.fasheh@oracle.com

Acked-by: Jeff Mahoney <jeffm@suse.com>

diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/cluster/tcp.c linux-2.6.16-20060408024659/fs/ocfs2/cluster/tcp.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/cluster/tcp.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/cluster/tcp.c	2006-04-10 18:13:59.000000000 -0700
@@ -1342,7 +1342,7 @@ static void o2net_start_connect(void *ar
 {
 	struct o2net_node *nn = arg;
 	struct o2net_sock_container *sc = NULL;
-	struct o2nm_node *node = NULL;
+	struct o2nm_node *node = NULL, *mynode = NULL;
 	struct socket *sock = NULL;
 	struct sockaddr_in myaddr = {0, }, remoteaddr = {0, };
 	int ret = 0;
@@ -1358,6 +1358,12 @@ static void o2net_start_connect(void *ar
 		goto out;
 	}
 
+	mynode = o2nm_get_node_by_num(o2nm_this_node());
+	if (mynode == NULL) {
+		ret = 0;
+		goto out;
+	}
+
 	spin_lock(&nn->nn_lock);
 	/* see if we already have one pending or have given up */
 	if (nn->nn_sc || nn->nn_persistent_error)
@@ -1385,12 +1391,14 @@ static void o2net_start_connect(void *ar
 	sock->sk->sk_allocation = GFP_ATOMIC;
 
 	myaddr.sin_family = AF_INET;
+	myaddr.sin_addr.s_addr = (__force u32)mynode->nd_ipv4_address;
 	myaddr.sin_port = (__force u16)htons(0); /* any port */
 
 	ret = sock->ops->bind(sock, (struct sockaddr *)&myaddr,
 			      sizeof(myaddr));
 	if (ret) {
-		mlog(0, "bind failed: %d\n", ret);
+		mlog(ML_ERROR, "bind failed with %d at address %u.%u.%u.%u\n",
+		     ret, NIPQUAD(mynode->nd_ipv4_address));
 		goto out;
 	}
 
@@ -1431,6 +1439,8 @@ out:
 		sc_put(sc);
 	if (node)
 		o2nm_node_put(node);
+	if (mynode)
+		o2nm_node_put(mynode);
 
 	return;
 }
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/cluster/ver.c linux-2.6.16-20060408024659/fs/ocfs2/cluster/ver.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/cluster/ver.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/cluster/ver.c	2006-04-11 14:45:48.000000000 -0700
@@ -28,8 +28,8 @@
 
 #include "ver.h"
 
-#define CLUSTER_BUILD_VERSION	"1.2.0-SLES"
-#define CLUSTER_BUILD_DATE	"Tue Feb 21 14:36:13 PST 2006"
+#define CLUSTER_BUILD_VERSION	"1.2.1-SLES"
+#define CLUSTER_BUILD_DATE	"Tue Apr 11 14:45:04 PDT 2006"
 #define CLUSTER_BUILD_MD5	"sles"
 
 #define VERSION_STR "OCFS2 Node Manager " \
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmast.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmast.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmast.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmast.c	2006-04-10 18:19:33.000000000 -0700
@@ -307,8 +307,11 @@ int dlm_proxy_ast_handler(struct o2net_m
 
 	if (past->type != DLM_AST &&
 	    past->type != DLM_BAST) {
-		mlog(ML_ERROR, "Unknown ast type! %d, cookie=%"MLFu64", "
-		     "name=%.*s\n", past->type, cookie, locklen, name);
+		mlog(ML_ERROR, "Unknown ast type! %d, cookie=%u:%llu"
+		     "name=%.*s\n", past->type, 
+		     dlm_get_lock_cookie_node(cookie),
+		     dlm_get_lock_cookie_seq(cookie),
+		     locklen, name);
 		ret = DLM_IVLOCKID;
 		goto leave;
 	}
@@ -316,9 +319,11 @@ int dlm_proxy_ast_handler(struct o2net_m
 	res = dlm_lookup_lockres(dlm, name, locklen);
 	if (!res) {
 		mlog(ML_ERROR, "got %sast for unknown lockres! "
-			       "cookie=%"MLFu64", name=%.*s, namelen=%u\n",
+			       "cookie=%u:%llu, name=%.*s, namelen=%u\n",
 		     past->type == DLM_AST ? "" : "b",
-		     cookie, locklen, name, locklen);
+		     dlm_get_lock_cookie_node(cookie),
+		     dlm_get_lock_cookie_seq(cookie),
+		     locklen, name, locklen);
 		ret = DLM_IVLOCKID;
 		goto leave;
 	}
@@ -360,9 +365,12 @@ int dlm_proxy_ast_handler(struct o2net_m
 			goto do_ast;
 	}
 
-	mlog(ML_ERROR, "got %sast for unknown lock!  cookie=%"MLFu64", "
-		       "name=%.*s, namelen=%u\n",
-             past->type == DLM_AST ? "" : "b", cookie, locklen, name, locklen);
+	mlog(ML_ERROR, "got %sast for unknown lock!  cookie=%u:%llu, "
+		       "name=%.*s, namelen=%u\n", 
+		       past->type == DLM_AST ? "" : "b", 
+		       dlm_get_lock_cookie_node(cookie),
+		       dlm_get_lock_cookie_seq(cookie),
+		       locklen, name, locklen);
 
 	ret = DLM_NORMAL;
 unlock_out:
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmcommon.h linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmcommon.h
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmcommon.h	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmcommon.h	2006-04-10 18:20:21.000000000 -0700
@@ -37,9 +37,7 @@
 #define DLM_THREAD_SHUFFLE_INTERVAL    5     // flush everything every 5 passes
 #define DLM_THREAD_MS                  200   // flush at least every 200 ms
 
-#define DLM_HASH_BITS     7
-#define DLM_HASH_SIZE     (1 << DLM_HASH_BITS)
-#define DLM_HASH_MASK     (DLM_HASH_SIZE - 1)
+#define DLM_HASH_BUCKETS     (PAGE_SIZE / sizeof(struct hlist_head))
 
 enum dlm_ast_type {
 	DLM_AST = 0,
@@ -87,7 +85,7 @@ enum dlm_ctxt_state {
 struct dlm_ctxt
 {
 	struct list_head list;
-	struct list_head *resources;
+	struct hlist_head *lockres_hash;
 	struct list_head dirty_list;
 	struct list_head purge_list;
 	struct list_head pending_asts;
@@ -217,7 +215,7 @@ struct dlm_lock_resource
 {
 	/* WARNING: Please see the comment in dlm_init_lockres before
 	 * adding fields here. */
-	struct list_head list;
+	struct hlist_node hash_node;
 	struct kref      refs;
 
 	/* please keep these next 3 in this order
@@ -632,6 +630,21 @@ __dlm_lockres_state_to_status(struct dlm
 	return status;
 }
 
+static inline u8 dlm_get_lock_cookie_node(u64 cookie)
+{
+	u8 ret;
+	cookie >>= 56;
+	ret = (u8)(cookie & 0xffULL);
+	return ret;
+}
+
+static inline unsigned long long dlm_get_lock_cookie_seq(u64 cookie)
+{
+	unsigned long long ret;
+	ret = ((unsigned long long)cookie) & 0x00ffffffffffffffULL;
+	return ret;
+}
+
 struct dlm_lock * dlm_new_lock(int type, u8 node, u64 cookie,
 			       struct dlm_lockstatus *lksb);
 void dlm_lock_get(struct dlm_lock *lock);
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmconvert.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmconvert.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmconvert.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmconvert.c	2006-04-10 18:19:33.000000000 -0700
@@ -284,8 +284,10 @@ enum dlm_status dlmconvert_remote(struct
 	if (lock->ml.convert_type != LKM_IVMODE) {
 		__dlm_print_one_lock_resource(res);
 		mlog(ML_ERROR, "converting a remote lock that is already "
-		     "converting! (cookie=%"MLFu64", conv=%d)\n",
-		     lock->ml.cookie, lock->ml.convert_type);
+		     "converting! (cookie=%u:%llu, conv=%d)\n",
+		     dlm_get_lock_cookie_node(lock->ml.cookie),
+		     dlm_get_lock_cookie_seq(lock->ml.cookie),
+		     lock->ml.convert_type);
 		status = DLM_DENIED;
 		goto bail;
 	}
@@ -513,8 +515,9 @@ int dlm_convert_lock_handler(struct o2ne
 leave:
 	if (!lock)
 		mlog(ML_ERROR, "did not find lock to convert on grant queue! "
-			       "cookie=%"MLFu64"\n",
-		     cnv->cookie);
+			       "cookie=%u:%llu\n",
+			       dlm_get_lock_cookie_node(cnv->cookie),
+			       dlm_get_lock_cookie_seq(cnv->cookie));
 	else
 		dlm_lock_put(lock);
 
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmdebug.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmdebug.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmdebug.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmdebug.c	2006-04-10 18:20:21.000000000 -0700
@@ -243,8 +243,10 @@ void __dlm_print_one_lock_resource(struc
 		lock = list_entry(iter2, struct dlm_lock, list);
 		spin_lock(&lock->spinlock);
 		mlog(ML_NOTICE, "    type=%d, conv=%d, node=%u, "
-		       "cookie=%"MLFu64", ast=(empty=%c,pend=%c), bast=(empty=%c,pend=%c)\n", 
-		       lock->ml.type, lock->ml.convert_type, lock->ml.node, lock->ml.cookie, 
+		       "cookie=%u:%llu, ast=(empty=%c,pend=%c), bast=(empty=%c,pend=%c)\n", 
+		       lock->ml.type, lock->ml.convert_type, lock->ml.node, 
+		       dlm_get_lock_cookie_node(lock->ml.cookie), 
+		       dlm_get_lock_cookie_seq(lock->ml.cookie), 
 		       list_empty(&lock->ast_list) ? 'y' : 'n',
 		       lock->ast_pending ? 'y' : 'n',
 		       list_empty(&lock->bast_list) ? 'y' : 'n',
@@ -256,8 +258,10 @@ void __dlm_print_one_lock_resource(struc
 		lock = list_entry(iter2, struct dlm_lock, list);
 		spin_lock(&lock->spinlock);
 		mlog(ML_NOTICE, "    type=%d, conv=%d, node=%u, "
-		       "cookie=%"MLFu64", ast=(empty=%c,pend=%c), bast=(empty=%c,pend=%c)\n", 
-		       lock->ml.type, lock->ml.convert_type, lock->ml.node, lock->ml.cookie, 
+		       "cookie=%u:%llu, ast=(empty=%c,pend=%c), bast=(empty=%c,pend=%c)\n", 
+		       lock->ml.type, lock->ml.convert_type, lock->ml.node, 
+		       dlm_get_lock_cookie_node(lock->ml.cookie), 
+		       dlm_get_lock_cookie_seq(lock->ml.cookie), 
 		       list_empty(&lock->ast_list) ? 'y' : 'n',
 		       lock->ast_pending ? 'y' : 'n',
 		       list_empty(&lock->bast_list) ? 'y' : 'n',
@@ -269,8 +273,10 @@ void __dlm_print_one_lock_resource(struc
 		lock = list_entry(iter2, struct dlm_lock, list);
 		spin_lock(&lock->spinlock);
 		mlog(ML_NOTICE, "    type=%d, conv=%d, node=%u, "
-		       "cookie=%"MLFu64", ast=(empty=%c,pend=%c), bast=(empty=%c,pend=%c)\n", 
-		       lock->ml.type, lock->ml.convert_type, lock->ml.node, lock->ml.cookie, 
+		       "cookie=%u:%llu, ast=(empty=%c,pend=%c), bast=(empty=%c,pend=%c)\n", 
+		       lock->ml.type, lock->ml.convert_type, lock->ml.node, 
+		       dlm_get_lock_cookie_node(lock->ml.cookie), 
+		       dlm_get_lock_cookie_seq(lock->ml.cookie), 
 		       list_empty(&lock->ast_list) ? 'y' : 'n',
 		       lock->ast_pending ? 'y' : 'n',
 		       list_empty(&lock->bast_list) ? 'y' : 'n',
@@ -289,8 +295,8 @@ EXPORT_SYMBOL_GPL(dlm_print_one_lock);
 void dlm_dump_lock_resources(struct dlm_ctxt *dlm)
 {
 	struct dlm_lock_resource *res;
-	struct list_head *iter;
-	struct list_head *bucket;
+	struct hlist_node *iter;
+	struct hlist_head *bucket;
 	int i;
 
 	mlog(ML_NOTICE, "struct dlm_ctxt: %s, node=%u, key=%u\n",
@@ -301,12 +307,10 @@ void dlm_dump_lock_resources(struct dlm_
 	}
 
 	spin_lock(&dlm->spinlock);
-	for (i=0; i<DLM_HASH_SIZE; i++) {
-		bucket = &(dlm->resources[i]);
-		list_for_each(iter, bucket) {
-			res = list_entry(iter, struct dlm_lock_resource, list);
+	for (i=0; i<DLM_HASH_BUCKETS; i++) {
+		bucket = &(dlm->lockres_hash[i]);
+		hlist_for_each_entry(res, iter, bucket, hash_node)
 			dlm_print_one_lock_resource(res);
-		}
 	}
 	spin_unlock(&dlm->spinlock);
 }
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmdomain.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmdomain.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmdomain.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmdomain.c	2006-04-10 18:20:21.000000000 -0700
@@ -77,26 +77,26 @@ static void dlm_unregister_domain_handle
 
 void __dlm_unhash_lockres(struct dlm_lock_resource *lockres)
 {
-	list_del_init(&lockres->list);
+	hlist_del_init(&lockres->hash_node);
 	dlm_lockres_put(lockres);
 }
 
 void __dlm_insert_lockres(struct dlm_ctxt *dlm,
 		       struct dlm_lock_resource *res)
 {
-	struct list_head *bucket;
+	struct hlist_head *bucket;
 	struct qstr *q;
 
 	assert_spin_locked(&dlm->spinlock);
 
 	q = &res->lockname;
 	q->hash = full_name_hash(q->name, q->len);
-	bucket = &(dlm->resources[q->hash & DLM_HASH_MASK]);
+	bucket = &(dlm->lockres_hash[q->hash % DLM_HASH_BUCKETS]);
 
 	/* get a reference for our hashtable */
 	dlm_lockres_get(res);
 
-	list_add_tail(&res->list, bucket);
+	hlist_add_head(&res->hash_node, bucket);
 }
 
 struct dlm_lock_resource * __dlm_lookup_lockres(struct dlm_ctxt *dlm,
@@ -104,9 +104,9 @@ struct dlm_lock_resource * __dlm_lookup_
 					 unsigned int len)
 {
 	unsigned int hash;
-	struct list_head *iter;
+	struct hlist_node *iter;
 	struct dlm_lock_resource *tmpres=NULL;
-	struct list_head *bucket;
+	struct hlist_head *bucket;
 
 	mlog_entry("%.*s\n", len, name);
 
@@ -114,11 +114,11 @@ struct dlm_lock_resource * __dlm_lookup_
 
 	hash = full_name_hash(name, len);
 
-	bucket = &(dlm->resources[hash & DLM_HASH_MASK]);
+	bucket = &(dlm->lockres_hash[hash % DLM_HASH_BUCKETS]);
 
 	/* check for pre-existing lock */
-	list_for_each(iter, bucket) {
-		tmpres = list_entry(iter, struct dlm_lock_resource, list);
+	hlist_for_each(iter, bucket) {
+		tmpres = hlist_entry(iter, struct dlm_lock_resource, hash_node);
 		if (tmpres->lockname.len == len &&
 		    memcmp(tmpres->lockname.name, name, len) == 0) {
 			dlm_lockres_get(tmpres);
@@ -193,8 +193,8 @@ static int dlm_wait_on_domain_helper(con
 
 static void dlm_free_ctxt_mem(struct dlm_ctxt *dlm)
 {
-	if (dlm->resources)
-		free_page((unsigned long) dlm->resources);
+	if (dlm->lockres_hash)
+		free_page((unsigned long) dlm->lockres_hash);
 
 	if (dlm->name)
 		kfree(dlm->name);
@@ -310,10 +310,10 @@ static void dlm_migrate_all_locks(struct
 	mlog(0, "Migrating locks from domain %s\n", dlm->name);
 restart:
 	spin_lock(&dlm->spinlock);
-	for (i=0; i<DLM_HASH_SIZE; i++) {
-		while (!list_empty(&dlm->resources[i])) {
-			res = list_entry(dlm->resources[i].next,
-				     struct dlm_lock_resource, list);
+	for (i = 0; i < DLM_HASH_BUCKETS; i++) {
+		while (!hlist_empty(&dlm->lockres_hash[i])) {
+			res = hlist_entry(dlm->lockres_hash[i].first,
+					  struct dlm_lock_resource, hash_node);
 			/* need reference when manually grabbing lockres */
 			dlm_lockres_get(res);
 			/* this should unhash the lockres
@@ -1200,18 +1200,17 @@ static struct dlm_ctxt *dlm_alloc_ctxt(c
 		goto leave;
 	}
 
-	dlm->resources = (struct list_head *) __get_free_page(GFP_KERNEL);
-	if (!dlm->resources) {
+	dlm->lockres_hash = (struct hlist_head *) __get_free_page(GFP_KERNEL);
+	if (!dlm->lockres_hash) {
 		mlog_errno(-ENOMEM);
 		kfree(dlm->name);
 		kfree(dlm);
 		dlm = NULL;
 		goto leave;
 	}
-	memset(dlm->resources, 0, PAGE_SIZE);
 
-	for (i=0; i<DLM_HASH_SIZE; i++)
-		INIT_LIST_HEAD(&dlm->resources[i]);
+	for (i=0; i<DLM_HASH_BUCKETS; i++)
+		INIT_HLIST_HEAD(&dlm->lockres_hash[i]);
 
 	strcpy(dlm->name, domain);
 	dlm->key = key;
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmfsver.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmfsver.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmfsver.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmfsver.c	2006-04-11 14:46:12.000000000 -0700
@@ -28,8 +28,8 @@
 
 #include "dlmfsver.h"
 
-#define DLM_BUILD_VERSION	"1.2.0-SLES"
-#define DLM_BUILD_DATE	"Tue Feb 21 14:36:13 PST 2006"
+#define DLM_BUILD_VERSION	"1.2.1-SLES"
+#define DLM_BUILD_DATE	"Tue Apr 11 14:45:04 PDT 2006"
 #define DLM_BUILD_MD5	"sles"
 
 #define VERSION_STR "OCFS2 DLMFS " \
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmmaster.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmmaster.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmmaster.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmmaster.c	2006-04-10 18:20:21.000000000 -0700
@@ -561,7 +561,7 @@ static void dlm_lockres_release(struct k
 
 	/* By the time we're ready to blow this guy away, we shouldn't
 	 * be on any lists. */
-	BUG_ON(!list_empty(&res->list));
+	BUG_ON(!hlist_unhashed(&res->hash_node));
 	BUG_ON(!list_empty(&res->granted));
 	BUG_ON(!list_empty(&res->converting));
 	BUG_ON(!list_empty(&res->blocked));
@@ -601,7 +601,7 @@ void dlm_init_lockres(struct dlm_ctxt *d
 
 	init_waitqueue_head(&res->wq);
 	spin_lock_init(&res->spinlock);
-	INIT_LIST_HEAD(&res->list);
+	INIT_HLIST_NODE(&res->hash_node);
 	INIT_LIST_HEAD(&res->granted);
 	INIT_LIST_HEAD(&res->converting);
 	INIT_LIST_HEAD(&res->blocked);
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmrecovery.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmrecovery.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmrecovery.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmrecovery.c	2006-04-10 18:20:21.000000000 -0700
@@ -743,10 +743,12 @@ static void dlm_request_all_locks_worker
 		     dlm->name, dlm->reco.dead_node, dlm->reco.new_master,
 		     dead_node, reco_master);
 		mlog(ML_ERROR, "%s: name=%.*s master=%u locks=%u/%u flags=%u "
-		     "entry[0]={c=%"MLFu64",l=%u,f=%u,t=%d,ct=%d,hb=%d,n=%u}\n",
+		     "entry[0]={c=%u:%llu,l=%u,f=%u,t=%d,ct=%d,hb=%d,n=%u}\n",
 		     dlm->name, mres->lockname_len, mres->lockname, mres->master,
 		     mres->num_locks, mres->total_locks, mres->flags,
-		     mres->ml[0].cookie, mres->ml[0].list, mres->ml[0].flags,
+		     dlm_get_lock_cookie_node(mres->ml[0].cookie),
+		     dlm_get_lock_cookie_seq(mres->ml[0].cookie),
+		     mres->ml[0].list, mres->ml[0].flags,
 		     mres->ml[0].type, mres->ml[0].convert_type,
 		     mres->ml[0].highest_blocked, mres->ml[0].node);
 		BUG();
@@ -1512,9 +1514,11 @@ static int dlm_process_recovery_data(str
 			/* lock is always created locally first, and
 			 * destroyed locally last.  it must be on the list */
 			if (!lock) {
+				u64 c = ml->cookie;
 				mlog(ML_ERROR, "could not find local lock "
-					       "with cookie %"MLFu64"!\n",
-				     ml->cookie);
+					       "with cookie %u:%llu!\n",
+					       dlm_get_lock_cookie_node(c),
+					       dlm_get_lock_cookie_seq(c));
 				BUG();
 			}
 			BUG_ON(lock->ml.node != ml->node);
@@ -1686,7 +1690,10 @@ static void dlm_finish_local_lockres_rec
 					      u8 dead_node, u8 new_master)
 {
 	int i;
-	struct list_head *iter, *iter2, *bucket;
+	struct list_head *iter, *iter2;
+	struct hlist_node *hash_iter;
+	struct hlist_head *bucket;
+
 	struct dlm_lock_resource *res;
 
 	mlog_entry_void();
@@ -1710,10 +1717,9 @@ static void dlm_finish_local_lockres_rec
 	 * for now we need to run the whole hash, clear
 	 * the RECOVERING state and set the owner
 	 * if necessary */
-	for (i=0; i<DLM_HASH_SIZE; i++) {
-		bucket = &(dlm->resources[i]);
-		list_for_each(iter, bucket) {
-			res = list_entry (iter, struct dlm_lock_resource, list);
+	for (i = 0; i < DLM_HASH_BUCKETS; i++) {
+		bucket = &(dlm->lockres_hash[i]);
+		hlist_for_each_entry(res, hash_iter, bucket, hash_node) {
 			if (res->state & DLM_LOCK_RES_RECOVERING) {
 				if (res->owner == dead_node) {
 					mlog(0, "(this=%u) res %.*s owner=%u "
@@ -1852,10 +1858,10 @@ static void dlm_free_dead_locks(struct d
 
 static void dlm_do_local_recovery_cleanup(struct dlm_ctxt *dlm, u8 dead_node)
 {
-	struct list_head *iter;
+	struct hlist_node *iter;
 	struct dlm_lock_resource *res;
 	int i;
-	struct list_head *bucket;
+	struct hlist_head *bucket;
 	struct dlm_lock *lock;
 
 
@@ -1876,10 +1882,9 @@ static void dlm_do_local_recovery_cleanu
 	 *    can be kicked again to see if any ASTs or BASTs
 	 *    need to be fired as a result.
 	 */
-	for (i=0; i<DLM_HASH_SIZE; i++) {
-		bucket = &(dlm->resources[i]);
-		list_for_each(iter, bucket) {
-			res = list_entry (iter, struct dlm_lock_resource, list);
+ 	for (i = 0; i < DLM_HASH_BUCKETS; i++) {
+ 		bucket = &(dlm->lockres_hash[i]);
+ 		hlist_for_each_entry(res, iter, bucket, hash_node) {
 			/* always prune any $RECOVERY entries for dead nodes,
 			 * otherwise hangs can occur during later recovery */
 			if (dlm_is_recovery_lock(res->lockname.name,
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmunlock.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmunlock.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmunlock.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmunlock.c	2006-04-10 18:19:33.000000000 -0700
@@ -244,8 +244,10 @@ leave:
 	if (actions & DLM_UNLOCK_FREE_LOCK) {
 		/* this should always be coupled with list removal */
 		BUG_ON(!(actions & DLM_UNLOCK_REMOVE_LOCK));
-		mlog(0, "lock %"MLFu64" should be gone now! refs=%d\n",
-		     lock->ml.cookie, atomic_read(&lock->lock_refs.refcount)-1);
+		mlog(0, "lock %u:%llu should be gone now! refs=%d\n",
+		     dlm_get_lock_cookie_node(lock->ml.cookie),
+		     dlm_get_lock_cookie_seq(lock->ml.cookie),
+		     atomic_read(&lock->lock_refs.refcount)-1);
 		dlm_lock_put(lock);
 	}
 	if (actions & DLM_UNLOCK_CALL_AST)
@@ -493,8 +495,9 @@ int dlm_unlock_lock_handler(struct o2net
 not_found:
 	if (!found)
 		mlog(ML_ERROR, "failed to find lock to unlock! "
-			       "cookie=%"MLFu64"\n",
-		     unlock->cookie);
+			       "cookie=%u:%llu\n",
+			       dlm_get_lock_cookie_node(unlock->cookie),
+			       dlm_get_lock_cookie_seq(unlock->cookie));
 	else {
 		/* send the lksb->status back to the other node */
 		status = lksb->status;
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmver.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmver.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/dlmver.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/dlmver.c	2006-04-11 14:46:26.000000000 -0700
@@ -28,8 +28,8 @@
 
 #include "dlmver.h"
 
-#define DLM_BUILD_VERSION	"1.2.0-SLES"
-#define DLM_BUILD_DATE	"Tue Feb 21 14:36:13 PST 2006"
+#define DLM_BUILD_VERSION	"1.2.1-SLES"
+#define DLM_BUILD_DATE	"Tue Apr 11 14:45:04 PDT 2006"
 #define DLM_BUILD_MD5	"sles"
 
 #define VERSION_STR "OCFS2 DLM " \
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/userdlm.c linux-2.6.16-20060408024659/fs/ocfs2/dlm/userdlm.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/dlm/userdlm.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/dlm/userdlm.c	2006-04-10 18:21:31.000000000 -0700
@@ -139,6 +139,10 @@ static void user_ast(void *opaque)
 		return;
 	}
 
+	mlog_bug_on_msg(lockres->l_requested == LKM_IVMODE,
+			"Lockres %s, requested ivmode. flags 0x%x\n",
+			lockres->l_name, lockres->l_flags);
+
 	/* we're downconverting. */
 	if (lockres->l_requested < lockres->l_level) {
 		if (lockres->l_requested <=
@@ -229,23 +233,42 @@ static void user_unlock_ast(void *opaque
 
 	mlog(0, "UNLOCK AST called on lock %s\n", lockres->l_name);
 
-	if (status != DLM_NORMAL)
+	if (status != DLM_NORMAL && status != DLM_CANCELGRANT)
 		mlog(ML_ERROR, "Dlm returns status %d\n", status);
 
 	spin_lock(&lockres->l_lock);
-	if (lockres->l_flags & USER_LOCK_IN_TEARDOWN)
+	/* The teardown flag gets set early during the unlock process,
+	 * so test the cancel flag to make sure that this ast isn't
+	 * for a concurrent cancel. */
+	if (lockres->l_flags & USER_LOCK_IN_TEARDOWN
+	    && !(lockres->l_flags & USER_LOCK_IN_CANCEL)) {
 		lockres->l_level = LKM_IVMODE;
-	else {
+	} else if (status == DLM_CANCELGRANT) {
+		mlog(0, "Lock %s, cancel fails, flags 0x%x\n",
+		     lockres->l_name, lockres->l_flags);
+		/* We tried to cancel a convert request, but it was
+		 * already granted. Don't clear the busy flag - the
+		 * ast should've done this already. */
+		BUG_ON(!(lockres->l_flags & USER_LOCK_IN_CANCEL));
+		lockres->l_flags &= ~USER_LOCK_IN_CANCEL;
+		goto out_noclear;
+	} else {
+		BUG_ON(!(lockres->l_flags & USER_LOCK_IN_CANCEL));
+		/* Cancel succeeded, we want to re-queue */
+		mlog(0, "Lock %s, cancel succeeds, flags 0x%x\n",
+		     lockres->l_name, lockres->l_flags);
 		lockres->l_requested = LKM_IVMODE; /* cancel an
 						    * upconvert
 						    * request. */
 		lockres->l_flags &= ~USER_LOCK_IN_CANCEL;
 		/* we want the unblock thread to look at it again
 		 * now. */
-		__user_dlm_queue_lockres(lockres);
+		if (lockres->l_flags & USER_LOCK_BLOCKED)
+			__user_dlm_queue_lockres(lockres);
 	}
 
 	lockres->l_flags &= ~USER_LOCK_BUSY;
+out_noclear:
 	spin_unlock(&lockres->l_lock);
 
 	wake_up(&lockres->l_event);
@@ -268,13 +291,26 @@ static void user_dlm_unblock_lock(void *
 
 	spin_lock(&lockres->l_lock);
 
-	BUG_ON(!(lockres->l_flags & USER_LOCK_BLOCKED));
-	BUG_ON(!(lockres->l_flags & USER_LOCK_QUEUED));
+	mlog_bug_on_msg(!(lockres->l_flags & USER_LOCK_QUEUED),
+			"Lockres %s, flags 0x%x\n",
+			lockres->l_name, lockres->l_flags);
 
-	/* notice that we don't clear USER_LOCK_BLOCKED here. That's
-	 * for user_ast to do. */
+	/* notice that we don't clear USER_LOCK_BLOCKED here. If it's
+	 * set, we want user_ast clear it. */
 	lockres->l_flags &= ~USER_LOCK_QUEUED;
 
+	/* It's valid to get here and no longer be blocked - if we get
+	 * several basts in a row, we might be queued by the first
+	 * one, the unblock thread might run and clear the queued
+	 * flag, and finally we might get another bast which re-queues
+	 * us before our ast for the downconvert is called. */
+	if (!(lockres->l_flags & USER_LOCK_BLOCKED)) {
+		mlog(0, "Lockres %s, flags 0x%x: queued but not blocking\n",
+			lockres->l_name, lockres->l_flags);
+		spin_unlock(&lockres->l_lock);
+		goto drop_ref;
+	}
+
 	if (lockres->l_flags & USER_LOCK_IN_TEARDOWN) {
 		mlog(0, "lock is in teardown so we do nothing\n");
 		spin_unlock(&lockres->l_lock);
@@ -282,7 +318,9 @@ static void user_dlm_unblock_lock(void *
 	}
 
 	if (lockres->l_flags & USER_LOCK_BUSY) {
-		mlog(0, "BUSY flag detected...\n");
+		mlog(0, "Cancel lock %s, flags 0x%x\n",
+		     lockres->l_name, lockres->l_flags);
+
 		if (lockres->l_flags & USER_LOCK_IN_CANCEL) {
 			spin_unlock(&lockres->l_lock);
 			goto drop_ref;
@@ -296,14 +334,7 @@ static void user_dlm_unblock_lock(void *
 				   LKM_CANCEL,
 				   user_unlock_ast,
 				   lockres);
-		if (status == DLM_CANCELGRANT) {
-			/* If we got this, then the ast was fired
-			 * before we could cancel. We cleanup our
-			 * state, and restart the function. */
-			spin_lock(&lockres->l_lock);
-			lockres->l_flags &= ~USER_LOCK_IN_CANCEL;
-			spin_unlock(&lockres->l_lock);
-		} else if (status != DLM_NORMAL)
+		if (status != DLM_NORMAL)
 			user_log_dlm_error("dlmunlock", status, lockres);
 		goto drop_ref;
 	}
@@ -581,6 +612,14 @@ int user_dlm_destroy_lock(struct user_lo
 	mlog(0, "asked to destroy %s\n", lockres->l_name);
 
 	spin_lock(&lockres->l_lock);
+	if (lockres->l_flags & USER_LOCK_IN_TEARDOWN) {
+		mlog(0, "Lock is already torn down\n");
+		spin_unlock(&lockres->l_lock);
+		return 0;
+	}
+
+	lockres->l_flags |= USER_LOCK_IN_TEARDOWN;
+
 	while (lockres->l_flags & USER_LOCK_BUSY) {
 		spin_unlock(&lockres->l_lock);
 
@@ -606,7 +645,6 @@ int user_dlm_destroy_lock(struct user_lo
 
 	lockres->l_flags &= ~USER_LOCK_ATTACHED;
 	lockres->l_flags |= USER_LOCK_BUSY;
-	lockres->l_flags |= USER_LOCK_IN_TEARDOWN;
 	spin_unlock(&lockres->l_lock);
 
 	mlog(0, "unlocking lockres %s\n", lockres->l_name);
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/extent_map.c linux-2.6.16-20060408024659/fs/ocfs2/extent_map.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/extent_map.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/extent_map.c	2006-04-10 18:15:35.000000000 -0700
@@ -176,21 +176,33 @@ static int ocfs2_extent_map_find_leaf(st
 				   le32_to_cpu(rec->e_clusters));
 
 			ret = -EBADR;
-			if (rec_end > OCFS2_I(inode)->ip_clusters)
+			if (rec_end > OCFS2_I(inode)->ip_clusters) {
+				mlog_errno(ret);
+				ocfs2_error(inode->i_sb,
+					    "Extent %d at e_blkno %"MLFu64" of inode %"MLFu64" goes past ip_clusters of %u\n",
+					    i,
+					    le64_to_cpu(rec->e_blkno),
+					    OCFS2_I(inode)->ip_blkno,
+					    OCFS2_I(inode)->ip_clusters);
 				goto out_free;
+			}
 
 			if (rec_end <= cpos) {
 				ret = ocfs2_extent_map_insert(inode, rec,
 						le16_to_cpu(el->l_tree_depth));
-				if (ret && (ret != -EEXIST))
+				if (ret && (ret != -EEXIST)) {
+					mlog_errno(ret);
 					goto out_free;
+				}
 				continue;
 			}
 			if ((cpos + clusters) <= le32_to_cpu(rec->e_cpos)) {
 				ret = ocfs2_extent_map_insert(inode, rec,
 						le16_to_cpu(el->l_tree_depth));
-				if (ret && (ret != -EEXIST))
+				if (ret && (ret != -EEXIST)) {
+					mlog_errno(ret);
 					goto out_free;
+				}
 				continue;
 			}
 
@@ -204,8 +216,10 @@ static int ocfs2_extent_map_find_leaf(st
 			ret = -ESRCH;
 			if (!ocfs2_extent_rec_contains_clusters(rec,
 							        cpos,
-								clusters))
+								clusters)) {
+				mlog_errno(ret);
 				goto out_free;
+			}
 
 			/*
 			 * If we've already found a record, the el has
@@ -213,8 +227,16 @@ static int ocfs2_extent_map_find_leaf(st
 			 * EEEK!
 			 */
 			ret = -EBADR;
-			if (blkno)
+			if (blkno) {
+				mlog_errno(ret);
+				ocfs2_error(inode->i_sb,
+					    "Multiple extents for (cpos = %u, clusters = %u) on inode %"MLFu64"; e_blkno %"MLFu64" and rec %d at e_blkno %"MLFu64"\n",
+					    cpos, clusters,
+					    OCFS2_I(inode)->ip_blkno,
+					    blkno, i,
+					    le64_to_cpu(rec->e_blkno));
 				goto out_free;
+			}
 
 			blkno = le64_to_cpu(rec->e_blkno);
 		}
@@ -224,8 +246,14 @@ static int ocfs2_extent_map_find_leaf(st
 		 * in the branches, so we'd better have found someone
 		 */
 		ret = -EBADR;
-		if (!blkno)
+		if (!blkno) {
+			ocfs2_error(inode->i_sb,
+				    "No record found for (cpos = %u, clusters = %u) on inode %"MLFu64"\n",
+				    cpos, clusters,
+				    OCFS2_I(inode)->ip_blkno);
+			mlog_errno(ret);
 			goto out_free;
+		}
 
 		if (eb_bh) {
 			brelse(eb_bh);
@@ -234,8 +262,10 @@ static int ocfs2_extent_map_find_leaf(st
 		ret = ocfs2_read_block(OCFS2_SB(inode->i_sb),
 				       blkno, &eb_bh, OCFS2_BH_CACHED,
 				       inode);
-		if (ret)
+		if (ret) {
+			mlog_errno(ret);
 			goto out_free;
+		}
 		eb = (struct ocfs2_extent_block *)eb_bh->b_data;
 		if (!OCFS2_IS_VALID_EXTENT_BLOCK(eb)) {
 			OCFS2_RO_ON_INVALID_EXTENT_BLOCK(inode->i_sb, eb);
@@ -250,10 +280,26 @@ static int ocfs2_extent_map_find_leaf(st
 
 	for (i = 0; i < le16_to_cpu(el->l_next_free_rec); i++) {
 		rec = &el->l_recs[i];
+
+		if ((le32_to_cpu(rec->e_cpos) + le32_to_cpu(rec->e_clusters)) >
+		    OCFS2_I(inode)->ip_clusters) {
+			ret = -EBADR;
+			mlog_errno(ret);
+			ocfs2_error(inode->i_sb,
+				    "Extent %d at e_blkno %"MLFu64" of inode %"MLFu64" goes past ip_clusters of %u\n",
+				    i,
+				    le64_to_cpu(rec->e_blkno),
+				    OCFS2_I(inode)->ip_blkno,
+				    OCFS2_I(inode)->ip_clusters);
+			return ret;
+		}
+
 		ret = ocfs2_extent_map_insert(inode, rec,
 					      le16_to_cpu(el->l_tree_depth));
-		if (ret)
+		if (ret) {
+			mlog_errno(ret);
 			goto out_free;
+		}
 	}
 
 	ret = 0;
@@ -298,6 +344,7 @@ static int ocfs2_extent_map_lookup_read(
 		ret = ocfs2_read_block(OCFS2_SB(inode->i_sb), blkno, &bh,
 				       OCFS2_BH_CACHED, inode);
 		if (ret) {
+			mlog_errno(ret);
 			if (bh)
 				brelse(bh);
 			return ret;
@@ -316,6 +363,7 @@ static int ocfs2_extent_map_lookup_read(
 				       OCFS2_I(inode)->ip_blkno, &bh,
 				       OCFS2_BH_CACHED, inode);
 		if (ret) {
+			mlog_errno(ret);
 			if (bh)
 				brelse(bh);
 			return ret;
@@ -331,12 +379,17 @@ static int ocfs2_extent_map_lookup_read(
 
 	ret = ocfs2_extent_map_find_leaf(inode, cpos, clusters, el);
 	brelse(bh);
-	if (ret)
+	if (ret) {
+		mlog_errno(ret);
 		return ret;
+	}
 
 	ent = ocfs2_extent_map_lookup(em, cpos, clusters, NULL, NULL);
-	if (!ent)
-		return -ESRCH;
+	if (!ent) {
+		ret = -ESRCH;
+		mlog_errno(ret);
+		return ret;
+	}
 
 	if (ent->e_tree_depth)
 		BUG();  /* FIXME: Make sure this isn't a corruption */
@@ -489,14 +542,24 @@ int ocfs2_extent_map_insert(struct inode
 	struct ocfs2_em_insert_context ctxt = {0, };
 
 	if ((le32_to_cpu(rec->e_cpos) + le32_to_cpu(rec->e_clusters)) >
-	    OCFS2_I(inode)->ip_map.em_clusters)
-		return -EBADR;
+	    OCFS2_I(inode)->ip_map.em_clusters) {
+		ret = -EBADR;
+		mlog_errno(ret);
+		return ret;
+	}
 
 	/* Zero e_clusters means a truncated tail record.  It better be EOF */
 	if (!rec->e_clusters) {
 		if ((le32_to_cpu(rec->e_cpos) + le32_to_cpu(rec->e_clusters)) !=
-		    OCFS2_I(inode)->ip_map.em_clusters)
-			return -EBADR;
+		    OCFS2_I(inode)->ip_map.em_clusters) {
+			ret = -EBADR;
+			mlog_errno(ret);
+			ocfs2_error(inode->i_sb,
+				    "Zero e_clusters on non-tail extent record at e_blkno %"MLFu64" on inode %"MLFu64"\n",
+				    le64_to_cpu(rec->e_blkno),
+				    OCFS2_I(inode)->ip_blkno);
+			return ret;
+		}
 
 		/* Ignore the truncated tail */
 		return 0;
@@ -505,8 +568,10 @@ int ocfs2_extent_map_insert(struct inode
 	ret = -ENOMEM;
 	ctxt.new_ent = kmem_cache_alloc(ocfs2_em_ent_cachep,
 					GFP_KERNEL);
-	if (!ctxt.new_ent)
+	if (!ctxt.new_ent) {
+		mlog_errno(ret);
 		return ret;
+	}
 
 	ctxt.new_ent->e_rec = *rec;
 	ctxt.new_ent->e_tree_depth = tree_depth;
@@ -532,6 +597,9 @@ int ocfs2_extent_map_insert(struct inode
 						  tree_depth, &ctxt);
 	} while (ret == -EAGAIN);
 
+	if (ret < 0)
+		mlog_errno(ret);
+
 	if (ctxt.left_ent)
 		kmem_cache_free(ocfs2_em_ent_cachep, ctxt.left_ent);
 	if (ctxt.right_ent)
@@ -552,12 +620,12 @@ int ocfs2_extent_map_insert(struct inode
  * Existing record in the extent map:
  *
  *	cpos = 10, len = 10
- * 	|---------|
+ *	|---------|
  *
  * New Record:
  *
  *	cpos = 10, len = 20
- * 	|------------------|
+ *	|------------------|
  *
  * The passed record is the new on-disk record.  The new_clusters value
  * is how many clusters were added to the file.  If the append is a
@@ -630,7 +698,8 @@ int ocfs2_extent_map_append(struct inode
 
 	if (ret == -ENOENT)
 		ret = ocfs2_extent_map_insert(inode, rec, 0);
-
+	if (ret < 0)
+		mlog_errno(ret);
 	return ret;
 }
 
@@ -754,8 +823,11 @@ int ocfs2_extent_map_get_blocks(struct i
 	cpos = ocfs2_blocks_to_clusters(inode->i_sb, v_blkno);
 	clusters = ocfs2_blocks_to_clusters(inode->i_sb,
 					    (u64)count + bpc - 1);
-	if ((cpos + clusters) > OCFS2_I(inode)->ip_clusters)
-		return -EINVAL;
+	if ((cpos + clusters) > OCFS2_I(inode)->ip_clusters) {
+		ret = -EINVAL;
+		mlog_errno(ret);
+		return ret;
+	}
 
 	if ((cpos + clusters) > em->em_clusters) {
 		/*
@@ -768,16 +840,21 @@ int ocfs2_extent_map_get_blocks(struct i
 	}
 
 	ret = ocfs2_extent_map_lookup_read(inode, cpos, clusters, &ent);
-	if (ret)
+	if (ret) {
+		mlog_errno(ret);
 		return ret;
+	}
 
 	if (ent)
 	{
 		rec = &ent->e_rec;
 
 		/* We should never find ourselves straddling an interval */
-		if (!ocfs2_extent_rec_contains_clusters(rec, cpos, clusters))
-			return -ESRCH;
+		if (!ocfs2_extent_rec_contains_clusters(rec, cpos, clusters)) {
+			ret = -ESRCH;
+			mlog_errno(ret);
+			return ret;
+		}
 
 		boff = ocfs2_clusters_to_blocks(inode->i_sb, cpos -
 						le32_to_cpu(rec->e_cpos));
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/file.c linux-2.6.16-20060408024659/fs/ocfs2/file.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/file.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/file.c	2006-04-10 18:21:08.000000000 -0700
@@ -510,6 +510,17 @@ static int ocfs2_truncate_file(struct oc
 	if (new_i_size == le64_to_cpu(fe->i_size))
 		goto bail;
 
+	/* This forces other nodes to sync and drop their pages. Do
+	 * this even if we have a truncate without allocation change -
+	 * ocfs2 cluster sizes can be much greater than page size, so
+	 * we have to truncate them anyway.  */
+	status = ocfs2_data_lock(inode, 1);
+	if (status < 0) {
+		mlog_errno(status);
+		goto bail;
+	}
+	ocfs2_data_unlock(inode, 1);
+
 	if (le32_to_cpu(fe->i_clusters) ==
 	    ocfs2_clusters_for_bytes(osb->sb, new_i_size)) {
 		mlog(0, "fe->i_clusters = %u, so we do a simple truncate\n",
@@ -532,14 +543,6 @@ static int ocfs2_truncate_file(struct oc
 		goto bail;
 	}
 
-	/* This forces other nodes to sync and drop their pages */
-	status = ocfs2_data_lock(inode, 1);
-	if (status < 0) {
-		mlog_errno(status);
-		goto bail;
-	}
-	ocfs2_data_unlock(inode, 1);
-
 	/* alright, we're going to need to do a full blown alloc size
 	 * change. Orphan the inode so that recovery can complete the
 	 * truncate if necessary. This does the task of marking
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/heartbeat.c linux-2.6.16-20060408024659/fs/ocfs2/heartbeat.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/heartbeat.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/heartbeat.c	2006-04-10 18:17:22.000000000 -0700
@@ -67,6 +67,7 @@ void ocfs2_init_node_maps(struct ocfs2_s
 	ocfs2_node_map_init(&osb->mounted_map);
 	ocfs2_node_map_init(&osb->recovery_map);
 	ocfs2_node_map_init(&osb->umount_map);
+	ocfs2_node_map_init(&osb->osb_recovering_orphan_dirs);
 }
 
 static void ocfs2_do_node_down(int node_num,
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/inode.c linux-2.6.16-20060408024659/fs/ocfs2/inode.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/inode.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/inode.c	2006-04-10 18:17:22.000000000 -0700
@@ -41,6 +41,7 @@
 #include "dlmglue.h"
 #include "extent_map.h"
 #include "file.h"
+#include  "heartbeat.h"
 #include "inode.h"
 #include "journal.h"
 #include "namei.h"
@@ -543,6 +544,42 @@ bail:
 	return status;
 }
 
+/* 
+ * Serialize with orphan dir recovery. If the process doing
+ * recovery on this orphan dir does an iget() with the dir
+ * i_mutex held, we'll deadlock here. Instead we detect this
+ * and exit early - recovery will wipe this inode for us.
+ */
+static int ocfs2_check_orphan_recovery_state(struct ocfs2_super *osb,
+					     int slot)
+{
+	int ret = 0;
+
+	spin_lock(&osb->osb_lock);
+	if (ocfs2_node_map_test_bit(osb, &osb->osb_recovering_orphan_dirs, slot)) {
+		mlog(0, "Recovery is happening on orphan dir %d, will skip "
+		     "this inode\n", slot);
+		ret = -EDEADLK;
+		goto out;
+	}
+	/* This signals to the orphan recovery process that is should
+	 * wait for us to handle the wipe. */
+	osb->osb_orphan_wipes[slot]++;
+out:
+	spin_unlock(&osb->osb_lock);
+	return ret;
+}
+
+static void ocfs2_signal_wipe_completion(struct ocfs2_super *osb,
+					 int slot)
+{
+	spin_lock(&osb->osb_lock);
+	osb->osb_orphan_wipes[slot]--;
+	spin_unlock(&osb->osb_lock);
+
+	wake_up(&osb->osb_wipe_event);
+}
+
 static int ocfs2_wipe_inode(struct inode *inode,
 			    struct buffer_head *di_bh)
 {
@@ -554,6 +591,11 @@ static int ocfs2_wipe_inode(struct inode
 	/* We've already voted on this so it should be readonly - no
 	 * spinlock needed. */
 	orphaned_slot = OCFS2_I(inode)->ip_orphaned_slot;
+
+	status = ocfs2_check_orphan_recovery_state(osb, orphaned_slot);
+	if (status)
+		return status;
+
 	orphan_dir_inode = ocfs2_get_system_file_inode(osb,
 						       ORPHAN_DIR_SYSTEM_INODE,
 						       orphaned_slot);
@@ -596,6 +638,7 @@ bail_unlock_dir:
 	brelse(orphan_dir_bh);
 bail:
 	iput(orphan_dir_inode);
+	ocfs2_signal_wipe_completion(osb, orphaned_slot);
 
 	return status;
 }
@@ -818,7 +861,8 @@ void ocfs2_delete_inode(struct inode *in
 
 	status = ocfs2_wipe_inode(inode, di_bh);
 	if (status < 0) {
-		mlog_errno(status);
+		if (status != -EDEADLK)
+			mlog_errno(status);
 		goto bail_unlock_inode;
 	}
 
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/journal.c linux-2.6.16-20060408024659/fs/ocfs2/journal.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/journal.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/journal.c	2006-04-10 18:17:22.000000000 -0700
@@ -1400,21 +1400,17 @@ bail:
 	return status;
 }
 
-static int ocfs2_recover_orphans(struct ocfs2_super *osb,
-				 int slot)
+static int ocfs2_queue_orphans(struct ocfs2_super *osb,
+			       int slot,
+			       struct inode **head)
 {
-	int status = 0;
-	int have_disk_lock = 0;
-	struct inode *inode = NULL;
-	struct inode *iter;
+	int status;
 	struct inode *orphan_dir_inode = NULL;
+	struct inode *iter;
 	unsigned long offset, blk, local;
 	struct buffer_head *bh = NULL;
 	struct ocfs2_dir_entry *de;
 	struct super_block *sb = osb->sb;
-	struct ocfs2_inode_info *oi;
-
-	mlog(0, "Recover inodes from orphan dir in slot %d\n", slot);
 
 	orphan_dir_inode = ocfs2_get_system_file_inode(osb,
 						       ORPHAN_DIR_SYSTEM_INODE,
@@ -1422,17 +1418,15 @@ static int ocfs2_recover_orphans(struct 
 	if  (!orphan_dir_inode) {
 		status = -ENOENT;
 		mlog_errno(status);
-		goto out;
-	}
+		return status;
+	}	
 
 	mutex_lock(&orphan_dir_inode->i_mutex);
 	status = ocfs2_meta_lock(orphan_dir_inode, NULL, NULL, 0);
 	if (status < 0) {
-		mutex_unlock(&orphan_dir_inode->i_mutex);
 		mlog_errno(status);
 		goto out;
 	}
-	have_disk_lock = 1;
 
 	offset = 0;
 	iter = NULL;
@@ -1443,11 +1437,10 @@ static int ocfs2_recover_orphans(struct 
 		if (!bh)
 			status = -EINVAL;
 		if (status < 0) {
-			mutex_unlock(&orphan_dir_inode->i_mutex);
 			if (bh)
 				brelse(bh);
 			mlog_errno(status);
-			goto out;
+			goto out_unlock;
 		}
 
 		local = 0;
@@ -1457,11 +1450,10 @@ static int ocfs2_recover_orphans(struct 
 
 			if (!ocfs2_check_dir_entry(orphan_dir_inode,
 						  de, bh, local)) {
-				mutex_unlock(&orphan_dir_inode->i_mutex);
 				status = -EINVAL;
 				mlog_errno(status);
 				brelse(bh);
-				goto out;
+				goto out_unlock;
 			}
 
 			local += le16_to_cpu(de->rec_len);
@@ -1496,18 +1488,97 @@ static int ocfs2_recover_orphans(struct 
 
 			mlog(0, "queue orphan %"MLFu64"\n",
 			     OCFS2_I(iter)->ip_blkno);
-			OCFS2_I(iter)->ip_next_orphan = inode;
-			inode = iter;
+			/* No locking is required for the next_orphan
+			 * queue as there is only ever a single
+			 * process doing orphan recovery. */
+			OCFS2_I(iter)->ip_next_orphan = *head;
+			*head = iter;
 		}
 		brelse(bh);
 	}
-	mutex_unlock(&orphan_dir_inode->i_mutex);
 
+out_unlock:
 	ocfs2_meta_unlock(orphan_dir_inode, 0);
-	have_disk_lock = 0;
-
+out:
+	mutex_unlock(&orphan_dir_inode->i_mutex);
 	iput(orphan_dir_inode);
-	orphan_dir_inode = NULL;
+	return status;
+}
+
+static int ocfs2_orphan_recovery_can_continue(struct ocfs2_super *osb,
+					      int slot)
+{
+	int ret;
+
+	spin_lock(&osb->osb_lock);
+	ret = !osb->osb_orphan_wipes[slot];
+	spin_unlock(&osb->osb_lock);
+	return ret;
+}
+
+static void ocfs2_mark_recovering_orphan_dir(struct ocfs2_super *osb,
+					     int slot)
+{
+	spin_lock(&osb->osb_lock);
+	/* Mark ourselves such that new processes in delete_inode()
+	 * know to quit early. */
+	ocfs2_node_map_set_bit(osb, &osb->osb_recovering_orphan_dirs, slot);
+	while (osb->osb_orphan_wipes[slot]) {
+		mlog(0, "%u threads in iput from orphan dir %d, will wait\n",
+		     osb->osb_orphan_wipes[slot], slot);
+		/* If any processes are already in the middle of an
+		 * orphan wipe on this dir, then we need to wait for
+		 * them. */
+		spin_unlock(&osb->osb_lock);
+		wait_event_interruptible(osb->osb_wipe_event,
+					 ocfs2_orphan_recovery_can_continue(osb, slot));
+		spin_lock(&osb->osb_lock);
+	}
+	spin_unlock(&osb->osb_lock);
+}
+
+static void ocfs2_clear_recovering_orphan_dir(struct ocfs2_super *osb,
+					      int slot)
+{
+	ocfs2_node_map_clear_bit(osb, &osb->osb_recovering_orphan_dirs, slot);
+}
+
+/*
+ * Orphan recovery. Each mounted node has its own orphan dir which we
+ * must run during recovery. Our strategy here is to build a list of
+ * the inodes in the orphan dir and iget/iput them. The VFS does
+ * (most) of the rest of the work.
+ *
+ * Orphan recovery can happen at any time, not just mount so we have a
+ * couple of extra considerations.
+ *
+ * - We grab as many inodes as we can under the orphan dir lock -
+ *   doing iget() outside the orphan dir risks getting a reference on
+ *   an invalid inode.
+ * - We must be sure not to deadlock with other processes on the
+ *   system wanting to run delete_inode(). This can happen when they go
+ *   to lock the orphan dir and the orphan recovery process attempts to
+ *   iget() inside the orphan dir lock. This can be avoided by
+ *   advertising our state to ocfs2_delete_inode().
+ */
+static int ocfs2_recover_orphans(struct ocfs2_super *osb,
+				 int slot)
+{
+	int ret = 0;
+	struct inode *inode = NULL;
+	struct inode *iter;
+	struct ocfs2_inode_info *oi;
+
+	mlog(0, "Recover inodes from orphan dir in slot %d\n", slot);
+
+	ocfs2_mark_recovering_orphan_dir(osb, slot);
+	ret = ocfs2_queue_orphans(osb, slot, &inode);
+	ocfs2_clear_recovering_orphan_dir(osb, slot);
+
+	/* Error here should be noted, but we want to continue with as
+	 * many queued inodes as we've got. */
+	if (ret)
+		mlog_errno(ret);
 
 	while (inode) {
 		oi = OCFS2_I(inode);
@@ -1533,14 +1604,7 @@ static int ocfs2_recover_orphans(struct 
 		inode = iter;
 	}
 
-out:
-	if (have_disk_lock)
-		ocfs2_meta_unlock(orphan_dir_inode, 0);
-
-	if (orphan_dir_inode)
-		iput(orphan_dir_inode);
-
-	return status;
+	return ret;
 }
 
 static int ocfs2_wait_on_mount(struct ocfs2_super *osb)
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/ocfs2.h linux-2.6.16-20060408024659/fs/ocfs2/ocfs2.h
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/ocfs2.h	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/ocfs2.h	2006-04-10 18:17:22.000000000 -0700
@@ -306,6 +306,10 @@ struct ocfs2_super
 	struct inode			*osb_tl_inode;
 	struct buffer_head		*osb_tl_bh;
 	struct work_struct		osb_truncate_log_wq;
+
+	struct ocfs2_node_map		osb_recovering_orphan_dirs;
+	unsigned int			*osb_orphan_wipes;
+	wait_queue_head_t		osb_wipe_event;
 };
 
 #define OCFS2_SB(sb)	    ((struct ocfs2_super *)(sb)->s_fs_info)
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/super.c linux-2.6.16-20060408024659/fs/ocfs2/super.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/super.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/super.c	2006-04-10 18:17:22.000000000 -0700
@@ -1394,6 +1394,16 @@ static int ocfs2_initialize_super(struct
 	}
 	mlog(ML_NOTICE, "max_slots for this device: %u\n", osb->max_slots);
 
+	init_waitqueue_head(&osb->osb_wipe_event);
+	osb->osb_orphan_wipes = kcalloc(osb->max_slots,
+					sizeof(*osb->osb_orphan_wipes),
+					GFP_KERNEL);
+	if (!osb->osb_orphan_wipes) {
+		status = -ENOMEM;
+		mlog_errno(status);
+		goto bail;
+	}
+
 	osb->s_feature_compat =
 		le32_to_cpu(OCFS2_RAW_SB(di)->s_feature_compat);
 	osb->s_feature_ro_compat =
@@ -1700,6 +1710,7 @@ static void ocfs2_delete_osb(struct ocfs
 	if (osb->slot_info)
 		ocfs2_free_slot_info(osb->slot_info);
 
+	kfree(osb->osb_orphan_wipes);
 	/* FIXME
 	 * This belongs in journal shutdown, but because we have to
 	 * allocate osb->journal at the start of ocfs2_initalize_osb(),
diff --exclude='*.orig' --exclude='*~' -pruN linux-2.6.16-20060408024659.orig/fs/ocfs2/ver.c linux-2.6.16-20060408024659/fs/ocfs2/ver.c
--- linux-2.6.16-20060408024659.orig/fs/ocfs2/ver.c	2006-04-10 18:23:52.000000000 -0700
+++ linux-2.6.16-20060408024659/fs/ocfs2/ver.c	2006-04-11 14:45:19.000000000 -0700
@@ -29,8 +29,8 @@
 
 #include "ver.h"
 
-#define OCFS2_BUILD_VERSION	"1.2.0-SLES"
-#define OCFS2_BUILD_DATE	"Tue Feb 21 14:36:13 PST 2006"
+#define OCFS2_BUILD_VERSION	"1.2.1-SLES"
+#define OCFS2_BUILD_DATE	"Tue Apr 11 14:45:04 PDT 2006"
 #define OCFS2_BUILD_MD5	"sles"
 
 #define VERSION_STR "OCFS2 " \


