diff -urNp linux-2.6.8/drivers/scsi/aacraid/aachba.c linux-2.6.8.SUSE/drivers/scsi/aacraid/aachba.c
--- linux-2.6.8/drivers/scsi/aacraid/aachba.c	2004-08-14 07:36:56.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/aachba.c	2004-07-30 19:42:15.000000000 +0200
@@ -39,9 +39,12 @@
 #include <scsi/scsi_cmnd.h>
 #include <scsi/scsi_device.h>
 #include <scsi/scsi_host.h>
+#include <scsi/scsi_eh.h>
+#include <scsi/scsi_tcq.h>
 
 #include "aacraid.h"
 
+
 /* values for inqd_pdt: Peripheral device type in plain English */
 #define	INQD_PDT_DA	0x00	/* Direct-access (DISK) device */
 #define	INQD_PDT_PROC	0x03	/* Processor device */
@@ -53,10 +56,6 @@
 #define	INQD_PDT_DMASK	0x1F	/* Peripheral Device Type Mask */
 #define	INQD_PDT_QMASK	0xE0	/* Peripheral Device Qualifer Mask */
 
-#define MAX_FIB_DATA (sizeof(struct hw_fib) - sizeof(FIB_HEADER))
-
-#define MAX_DRIVER_SG_SEGMENT_COUNT 17
-
 /*
  *	Sense codes
  */
@@ -131,54 +130,118 @@ struct inquiry_data {
 	u8 inqd_prl[4];	/* Product Revision Level */
 };
 
-struct sense_data {
-	u8 error_code;		/* 70h (current errors), 71h(deferred errors) */
-	u8 valid:1;		/* A valid bit of one indicates that the information  */
-				/* field contains valid information as defined in the
-				 * SCSI-2 Standard.
-				 */
-	u8 segment_number;	/* Only used for COPY, COMPARE, or COPY AND VERIFY Commands */
-	u8 sense_key:4;		/* Sense Key */
-	u8 reserved:1;
-	u8 ILI:1;		/* Incorrect Length Indicator */
-	u8 EOM:1;		/* End Of Medium - reserved for random access devices */
-	u8 filemark:1;		/* Filemark - reserved for random access devices */
-
-	u8 information[4];	/* for direct-access devices, contains the unsigned 
-				 * logical block address or residue associated with 
-				 * the sense key 
-				 */
-	u8 add_sense_len;	/* number of additional sense bytes to follow this field */
-	u8 cmnd_info[4];	/* not used */
-	u8 ASC;			/* Additional Sense Code */
-	u8 ASCQ;		/* Additional Sense Code Qualifier */
-	u8 FRUC;		/* Field Replaceable Unit Code - not used */
-	u8 bit_ptr:3;		/* indicates which byte of the CDB or parameter data
-				 * was in error
-				 */
-	u8 BPV:1;		/* bit pointer valid (BPV): 1- indicates that 
-				 * the bit_ptr field has valid value
-				 */
-	u8 reserved2:2;
-	u8 CD:1;		/* command data bit: 1- illegal parameter in CDB.
-				 * 0- illegal parameter in data.
-				 */
-	u8 SKSV:1;
-	u8 field_ptr[2];	/* byte of the CDB or parameter data in error */
-};
-
 /*
  *              M O D U L E   G L O B A L S
  */
  
-static struct sense_data sense_data[MAXIMUM_NUM_CONTAINERS];
 static unsigned long aac_build_sg(struct scsi_cmnd* scsicmd, struct sgmap* sgmap);
 static unsigned long aac_build_sg64(struct scsi_cmnd* scsicmd, struct sgmap64* psg);
+static unsigned long aac_build_sgraw(struct scsi_cmnd* scsicmd, struct sgmapraw* psg);
 static int aac_send_srb_fib(struct scsi_cmnd* scsicmd);
 #ifdef AAC_DETAILED_STATUS_INFO
 static char *aac_get_status_string(u32 status);
 #endif
 
+/*
+ *	Non dasd selection is handled entirely in aachba now
+ */	
+ 
+MODULE_PARM(nondasd, "i");
+MODULE_PARM_DESC(nondasd, "Control scanning of hba for nondasd devices. 0=off, 1=on");
+MODULE_PARM(dacmode, "i");
+MODULE_PARM_DESC(dacmode, "Control whether dma addressing is using 64 bit DAC. 0=off, 1=on");
+MODULE_PARM(commit, "i");
+MODULE_PARM_DESC(commit, "Control whether a COMMIT_CONFIG is issued to the adapter for foreign arrays.\nThis is typically needed in systems that do not have a BIOS. 0=off, 1=on");
+MODULE_PARM(coalescethreshold, "i");
+MODULE_PARM_DESC(coalescethreshold, "Control the maximum block size of sequential requests that are fed back to the\nscsi_merge layer for coalescing. 0=off, 16 block (8KB) default.");
+MODULE_PARM(acbsize, "i");
+MODULE_PARM_DESC(acbsize, "Request a specific adapter control block (FIB) size. Valid values are 512,\n2048, 4096 and 8192. Default is to use suggestion from Firmware.");
+MODULE_PARM(overridetimeout, "i");
+MODULE_PARM_DESC(overridetimeout, "Request a specific timeout to override I/O requests issed to the adapter.");
+
+static int nondasd = -1;
+static int dacmode = -1;
+#ifdef __arm__
+static int commit = 1;
+#else
+static int commit = -1;
+#endif
+static int coalescethreshold = 16; /* 8KB coalesce knee */
+int acbsize = -1;
+static int overridetimeout = -1;
+
+/**
+ *	aac_get_config_status	-	check the adapter configuration
+ *	@common: adapter to query
+ *
+ *	Query config status, and commit the configuration if needed.
+ */
+int aac_get_config_status(struct aac_dev *dev)
+{
+	int status = 0;
+	struct fib * fibptr;
+
+	if (!(fibptr = fib_alloc(dev)))
+		return -ENOMEM;
+
+	fib_init(fibptr);
+	{
+		struct aac_get_config_status *dinfo;
+		dinfo = (struct aac_get_config_status *) fib_data(fibptr);
+
+		dinfo->command = cpu_to_le32(VM_ContainerConfig);
+		dinfo->type = cpu_to_le32(CT_GET_CONFIG_STATUS);
+		dinfo->count = cpu_to_le32(sizeof(((struct aac_get_config_status_resp *)NULL)->data));
+	}
+
+	status = fib_send(ContainerCommand,
+			    fibptr,
+			    sizeof (struct aac_get_config_status),
+			    FsaNormal,
+			    1, 1,
+			    NULL, NULL);
+	if (status < 0 ) {
+		printk(KERN_WARNING "aac_get_config_status: SendFIB failed.\n");
+	} else {
+		struct aac_get_config_status_resp *reply
+		  = (struct aac_get_config_status_resp *) fib_data(fibptr);
+		dprintk((KERN_WARNING
+		  "aac_get_config_status: response=%d status=%d action=%d\n",
+		  reply->response, reply->status, reply->data.action));
+		if ((reply->response != ST_OK)
+		 || (reply->status != CT_OK)
+		 || (reply->data.action > CFACT_PAUSE)) {
+			printk(KERN_WARNING "aac_get_config_status: Will not issue the Commit Configuration\n");
+			status = -EINVAL;
+		}
+	}
+	fib_complete(fibptr);
+	/* Send a CT_COMMIT_CONFIG to enable discovery of devices */
+	if (status >= 0) {
+		if (commit == 1) {
+			struct aac_commit_config * dinfo;
+			fib_init(fibptr);
+			dinfo = (struct aac_commit_config *) fib_data(fibptr);
+	
+			dinfo->command = cpu_to_le32(VM_ContainerConfig);
+			dinfo->type = cpu_to_le32(CT_COMMIT_CONFIG);
+	
+			status = fib_send(ContainerCommand,
+				    fibptr,
+				    sizeof (struct aac_commit_config),
+				    FsaNormal,
+				    1, 1,
+				    NULL, NULL);
+			fib_complete(fibptr);
+		} else if (commit == 0) {
+			printk(KERN_WARNING
+			  "aac_get_config_status: Foreign device configurations are being ignored\n");
+		}
+	}
+	fib_free(fibptr);
+	return status;
+}
+
 /**
  *	aac_get_containers	-	list containers
  *	@common: adapter to probe
@@ -187,21 +250,62 @@ static char *aac_get_status_string(u32 s
  */
 int aac_get_containers(struct aac_dev *dev)
 {
-	struct fsa_scsi_hba *fsa_dev_ptr;
+	struct fsa_dev_info *fsa_dev_ptr;
 	u32 index; 
 	int status = 0;
-	struct aac_query_mount *dinfo;
-	struct aac_mount *dresp;
 	struct fib * fibptr;
 	unsigned instance;
 
-	fsa_dev_ptr = &(dev->fsa_dev);
 	instance = dev->scsi_host_ptr->unique_id;
 
 	if (!(fibptr = fib_alloc(dev)))
 		return -ENOMEM;
 
-	for (index = 0; index < MAXIMUM_NUM_CONTAINERS; index++) {
+	{
+		struct aac_get_container_count *dinfo;
+		struct aac_get_container_count_resp *dresp;
+		int maximum_num_containers = MAXIMUM_NUM_CONTAINERS;
+
+		fib_init(fibptr);
+		dinfo = (struct aac_get_container_count *) fib_data(fibptr);
+	
+		dinfo->command = cpu_to_le32(VM_ContainerConfig);
+		dinfo->type = cpu_to_le32(CT_GET_CONTAINER_COUNT);
+	
+		status = fib_send(ContainerCommand,
+			    fibptr,
+			    sizeof (struct aac_get_container_count),
+			    FsaNormal,
+			    1, 1,
+			    NULL, NULL);
+		if (status >= 0) {
+			dresp = (struct aac_get_container_count_resp *) fib_data(fibptr);
+			maximum_num_containers = dresp->ContainerSwitchEntries;
+//DEBUG
+//printk(KERN_INFO "maximum_num_containers=%d\n", maximum_num_containers);
+			fib_complete(fibptr);
+		}
+
+		if (maximum_num_containers < MAXIMUM_NUM_CONTAINERS)
+			maximum_num_containers = MAXIMUM_NUM_CONTAINERS;
+		fsa_dev_ptr = (struct fsa_dev_info *) kmalloc(
+		  sizeof(*fsa_dev_ptr) * maximum_num_containers, GFP_KERNEL);
+		if (!fsa_dev_ptr) {
+			fib_free(fibptr);
+			return -ENOMEM;
+		}
+		memset(fsa_dev_ptr, 0, sizeof(*fsa_dev_ptr) * maximum_num_containers);
+
+		dev->fsa_dev = fsa_dev_ptr;
+		dev->maximum_num_containers = maximum_num_containers;
+	}
+
+	for (index = 0; index < dev->maximum_num_containers; index++) {
+		struct aac_query_mount *dinfo;
+		struct aac_mount *dresp;
+
+		fsa_dev_ptr[index].devname[0] = '\0';
+
 		fib_init(fibptr);
 		dinfo = (struct aac_query_mount *) fib_data(fibptr);
 
@@ -221,14 +325,20 @@ int aac_get_containers(struct aac_dev *d
 		}
 		dresp = (struct aac_mount *)fib_data(fibptr);
 
+		dprintk ((KERN_DEBUG
+		  "VM_NameServe cid=%d status=%d vol=%d state=%d cap=%u\n",
+		  (int)index, (int)le32_to_cpu(dresp->status),
+		  (int)le32_to_cpu(dresp->mnt[0].vol),
+		  (int)le32_to_cpu(dresp->mnt[0].state),
+		  (unsigned)le32_to_cpu(dresp->mnt[0].capacity)));
 		if ((le32_to_cpu(dresp->status) == ST_OK) &&
 		    (le32_to_cpu(dresp->mnt[0].vol) != CT_NONE) &&
 		    (le32_to_cpu(dresp->mnt[0].state) != FSCS_HIDDEN)) {
-			fsa_dev_ptr->valid[index] = 1;
-			fsa_dev_ptr->type[index] = le32_to_cpu(dresp->mnt[0].vol);
-			fsa_dev_ptr->size[index] = le32_to_cpu(dresp->mnt[0].capacity);
+			fsa_dev_ptr[index].valid = 1;
+			fsa_dev_ptr[index].type = le32_to_cpu(dresp->mnt[0].vol);
+			fsa_dev_ptr[index].size = le32_to_cpu(dresp->mnt[0].capacity);
 			if (le32_to_cpu(dresp->mnt[0].state) & FSCS_READONLY)
-				    fsa_dev_ptr->ro[index] = 1;
+				    fsa_dev_ptr[index].ro = 1;
 		}
 		fib_complete(fibptr);
 		/*
@@ -242,25 +352,140 @@ int aac_get_containers(struct aac_dev *d
 	return status;
 }
 
+//DEBUG
+//static void aacraid_timeout_dummy_fn(struct scsi_cmnd * scsicmd)
+//{
+//	return;
+//}
+
+static void aac_io_done(struct scsi_cmnd * scsicmd)
+{
+	unsigned long cpu_flags;
+	struct Scsi_Host *host = scsicmd->device->host;
+
+	if (scsicmd->scsi_done == (void (*)(struct scsi_cmnd*))NULL) {
+		printk(KERN_WARNING "aac_io_done: scsi_done NULL\n");
+		return;
+	}
+	spin_lock_irqsave(host->host_lock, cpu_flags);
+	/*
+	 * Tell system to perform scsi_done functionality even despite
+	 * being in the error recovery code. Leave a `timer' to delete
+	 * so that completion can progress.
+	 */
+//DEBUG
+//	scsi_add_timer(scsicmd, 60*HZ, aacraid_timeout_dummy_fn);
+	scsicmd->scsi_done(scsicmd);
+//DEBUG
+//	if (scsicmd->serial_number) {
+//		scsi_add_timer(scsicmd, 60*HZ, aacraid_timeout_dummy_fn);
+//		scsicmd->scsi_done(scsicmd);
+//	}
+	spin_unlock_irqrestore(host->host_lock, cpu_flags);
+}
+
+static inline void __aac_io_done(struct scsi_cmnd * scsicmd)
+{
+	scsicmd->scsi_done(scsicmd);
+}
+
+static void get_container_name_callback(void *context, struct fib * fibptr)
+{
+	struct aac_get_name_resp * get_name_reply;
+	struct scsi_cmnd * scsicmd;
+
+	scsicmd = (struct scsi_cmnd *) context;
+
+	dprintk((KERN_DEBUG "get_container_name_callback[cpu %d]: t = %ld.\n", smp_processor_id(), jiffies));
+	if (fibptr == NULL)
+		BUG();
+
+	get_name_reply = (struct aac_get_name_resp *) fib_data(fibptr);
+	/* Failure is irrelevant, using default value instead */
+	if ((le32_to_cpu(get_name_reply->status) == CT_OK)
+	 && (get_name_reply->data[0] != '\0')) {
+		char * sp = get_name_reply->data;
+		char * dp = ((struct inquiry_data *)scsicmd->request_buffer)->inqd_pid;
+		int    count = sizeof(((struct aac_get_name_resp *)NULL)->data);
+		do {
+			if ((*sp == '\0') || (count <= 0)) {
+				*dp++ = ' ';
+			} else {
+				*dp++ = *sp++;
+			}
+		} while (--count
+		  > (sizeof(((struct aac_get_name_resp *)NULL)->data)
+		   - sizeof(((struct inquiry_data *)NULL)->inqd_pid)));
+	}
+	scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+
+	fib_complete(fibptr);
+	fib_free(fibptr);
+	aac_io_done(scsicmd);
+}
+
+/**
+ *	aac_get_container_name	-	get container name, none blocking.
+ */
+static int aac_get_container_name(struct scsi_cmnd * scsicmd, int cid)
+{
+	int status;
+	struct aac_get_name *dinfo;
+	struct fib * cmd_fibcontext;
+	struct aac_dev * dev;
+
+	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
+
+	if (!(cmd_fibcontext = fib_alloc(dev)))
+		return -ENOMEM;
+
+	fib_init(cmd_fibcontext);
+	dinfo = (struct aac_get_name *) fib_data(cmd_fibcontext);
+
+	dinfo->command = cpu_to_le32(VM_ContainerConfig);
+	dinfo->type = cpu_to_le32(CT_READ_NAME);
+	dinfo->cid = cpu_to_le32(cid);
+	dinfo->count = cpu_to_le32(sizeof(((struct aac_get_name_resp *)NULL)->data));
+
+	status = fib_send(ContainerCommand, 
+		  cmd_fibcontext, 
+		  sizeof (struct aac_get_name),
+		  FsaNormal, 
+		  0, 1, 
+		  (fib_callback) get_container_name_callback, 
+		  (void *) scsicmd);
+	
+	/*
+	 *	Check that the command queued to the controller
+	 */
+	if (status == -EINPROGRESS) 
+		return 0;
+		
+	printk(KERN_WARNING "aac_get_container_name: fib_send failed with status: %d.\n", status);
+	fib_complete(cmd_fibcontext);
+	fib_free(cmd_fibcontext);
+	return -1;
+}
+
 /**
  *	probe_container		-	query a logical volume
  *	@dev: device to query
  *	@cid: container identifier
  *
  *	Queries the controller about the given volume. The volume information
- *	is updated in the struct fsa_scsi_hba structure rather than returned.
+ *	is updated in the struct fsa_dev_info structure rather than returned.
  */
  
 static int probe_container(struct aac_dev *dev, int cid)
 {
-	struct fsa_scsi_hba *fsa_dev_ptr;
+	struct fsa_dev_info *fsa_dev_ptr;
 	int status;
 	struct aac_query_mount *dinfo;
 	struct aac_mount *dresp;
 	struct fib * fibptr;
 	unsigned instance;
 
-	fsa_dev_ptr = &(dev->fsa_dev);
+	fsa_dev_ptr = dev->fsa_dev;
 	instance = dev->scsi_host_ptr->unique_id;
 
 	if (!(fibptr = fib_alloc(dev)))
@@ -281,7 +506,7 @@ static int probe_container(struct aac_de
 			    1, 1,
 			    NULL, NULL);
 	if (status < 0) {
-		printk(KERN_WARNING "aacraid: probe_containers query failed.\n");
+		printk(KERN_WARNING "aacraid: probe_container query failed.\n");
 		goto error;
 	}
 
@@ -290,11 +515,11 @@ static int probe_container(struct aac_de
 	if ((le32_to_cpu(dresp->status) == ST_OK) &&
 	    (le32_to_cpu(dresp->mnt[0].vol) != CT_NONE) &&
 	    (le32_to_cpu(dresp->mnt[0].state) != FSCS_HIDDEN)) {
-		fsa_dev_ptr->valid[cid] = 1;
-		fsa_dev_ptr->type[cid] = le32_to_cpu(dresp->mnt[0].vol);
-		fsa_dev_ptr->size[cid] = le32_to_cpu(dresp->mnt[0].capacity);
+		fsa_dev_ptr[cid].valid = 1;
+		fsa_dev_ptr[cid].type = le32_to_cpu(dresp->mnt[0].vol);
+		fsa_dev_ptr[cid].size = le32_to_cpu(dresp->mnt[0].capacity);
 		if (le32_to_cpu(dresp->mnt[0].state) & FSCS_READONLY)
-			fsa_dev_ptr->ro[cid] = 1;
+			fsa_dev_ptr[cid].ro = 1;
 	}
 
 error:
@@ -353,14 +578,13 @@ static char *container_types[] = {
  * Arguments: [1] pointer to void [1] int
  *
  * Purpose: Sets SCSI inquiry data strings for vendor, product
- * and revision level. Allows strings to be set in platform dependent
- * files instead of in OS dependent driver source.
+ * and revision level. Allows strings to be set in platform dependant
+ * files instead of in OS dependant driver source.
  */
 
 static void setinqstr(int devtype, void *data, int tindex)
 {
 	struct scsi_inq *str;
-	char *findit;
 	struct aac_driver_ident *mp;
 
 	mp = aac_get_driver_ident(devtype);
@@ -370,13 +594,14 @@ static void setinqstr(int devtype, void 
 	inqstrcpy (mp->vname, str->vid); 
 	inqstrcpy (mp->model, str->pid); /* last six chars reserved for vol type */
 
-	findit = str->pid;
-
-	for ( ; *findit != ' '; findit++); /* walk till we find a space then incr by 1 */
-		findit++;
-	
 	if (tindex < (sizeof(container_types)/sizeof(char *))){
-		inqstrcpy (container_types[tindex], findit);
+		char *findit = str->pid;
+
+		for ( ; *findit != ' '; findit++); /* walk till we find a space */
+		/* RAID is superfluous in the context of a RAID device */
+		if (memcmp(findit-4, "RAID", 4) == 0)
+			*(findit -= 4) = ' ';
+		inqstrcpy (container_types[tindex], findit + 1);
 	}
 	inqstrcpy ("V1.0", str->prl);
 }
@@ -421,20 +646,6 @@ void set_sense(u8 *sense_buf, u8 sense_k
 	}
 }
 
-static void aac_io_done(struct scsi_cmnd * scsicmd)
-{
-	unsigned long cpu_flags;
-	struct Scsi_Host *host = scsicmd->device->host;
-	spin_lock_irqsave(host->host_lock, cpu_flags);
-	scsicmd->scsi_done(scsicmd);
-	spin_unlock_irqrestore(host->host_lock, cpu_flags);
-}
-
-static void __aac_io_done(struct scsi_cmnd * scsicmd)
-{
-	scsicmd->scsi_done(scsicmd);
-}
-
 int aac_get_adapter_info(struct aac_dev* dev)
 {
 	struct fib* fibptr;
@@ -460,49 +671,115 @@ int aac_get_adapter_info(struct aac_dev*
 	memcpy(&dev->adapter_info, info, sizeof(struct aac_adapter_info));
 
 	tmp = dev->adapter_info.kernelrev;
-	printk(KERN_INFO"%s%d: kernel %d.%d.%d build %d\n", 
+	printk(KERN_INFO "%s%d: kernel %d.%d-%d build %d\n", 
 			dev->name, dev->id,
-			tmp>>24,(tmp>>16)&0xff,(tmp>>8)&0xff,
+			tmp>>24,(tmp>>16)&0xff,tmp&0xff,
 			dev->adapter_info.kernelbuild);
 	tmp = dev->adapter_info.monitorrev;
-	printk(KERN_INFO"%s%d: monitor %d.%d.%d build %d\n", 
+	printk(KERN_INFO "%s%d: monitor %d.%d-%d build %d\n", 
 			dev->name, dev->id,
-			tmp>>24,(tmp>>16)&0xff,(tmp>>8)&0xff,
+			tmp>>24,(tmp>>16)&0xff,tmp&0xff,
 			dev->adapter_info.monitorbuild);
 	tmp = dev->adapter_info.biosrev;
-	printk(KERN_INFO"%s%d: bios %d.%d.%d build %d\n", 
+	printk(KERN_INFO "%s%d: bios %d.%d-%d build %d\n", 
 			dev->name, dev->id,
-			tmp>>24,(tmp>>16)&0xff,(tmp>>8)&0xff,
+			tmp>>24,(tmp>>16)&0xff,tmp&0xff,
 			dev->adapter_info.biosbuild);
-	printk(KERN_INFO"%s%d: serial %x%x\n",
+	if (dev->adapter_info.serial[0] != 0xBAD0)
+		printk(KERN_INFO "%s%d: serial %x\n",
 			dev->name, dev->id,
-			dev->adapter_info.serial[0],
-			dev->adapter_info.serial[1]);
+			dev->adapter_info.serial[0]);
 
 	dev->nondasd_support = 0;
+	dev->raid_scsi_mode = 0;
 	if(dev->adapter_info.options & AAC_OPT_NONDASD){
-//		dev->nondasd_support = 1;
-// dmb - temporarily disable nondasd
+		dev->nondasd_support = 1;
 	}
+
+	/*
+	 * If the firmware supports ROMB RAID/SCSI mode and we are currently
+	 * in RAID/SCSI mode, set the flag. For now if in this mode we will
+	 * force nondasd support on. If we decide to allow the non-dasd flag
+	 * additional changes changes will have to be made to support
+	 * RAID/SCSI.  the function aac_scsi_cmd in this module will have to be
+	 * changed to support the new dev->raid_scsi_mode flag instead of
+	 * leaching off of the dev->nondasd_support flag. Also in linit.c the
+	 * function aac_detect will have to be modified where it sets up the
+	 * max number of channels based on the aac->nondasd_support flag only.
+	 */
+	if ((dev->adapter_info.options & AAC_OPT_SCSI_MANAGED)
+		&& (dev->adapter_info.options & AAC_OPT_RAID_SCSI_MODE))
+	{
+		dev->nondasd_support = 1;
+		dev->raid_scsi_mode = 1;
+	}
+	if (dev->raid_scsi_mode != 0)
+		printk(KERN_INFO "%s%d: ROMB RAID/SCSI mode enabled\n",dev->name, dev->id);
+		
 	if(nondasd != -1) {  
 		dev->nondasd_support = (nondasd!=0);
 	}
-	if(dev->nondasd_support != 0){
-		printk(KERN_INFO "%s%d: Non-DASD support enabled.\n",dev->name, dev->id);
-	}
+	if(dev->nondasd_support != 0)
+		printk(KERN_INFO"%s%d: Non-DASD support enabled\n",dev->name, dev->id);
 
-	dev->pae_support = 0;
-	if( (sizeof(dma_addr_t) > 4) && (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64)){
-		printk(KERN_INFO "%s%d: 64bit support enabled.\n", dev->name, dev->id);
-		dev->pae_support = 1;
+	dev->dac_support = 0;
+	/*
+	 *	Only enable DAC mode if the dma_addr_t is larger than 32
+	 * bit addressing, and we have more than 32 bit addressing worth of
+	 * memory and if the controller supports 64 bit scatter gather elements.
+	 */
+	if( (sizeof(dma_addr_t) > 4) && (num_physpages > (0xFFFFFFFFULL >> PAGE_SHIFT)) && (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64)){
+		dev->dac_support = 1;
 	}
 
-	if(paemode != -1){
-		dev->pae_support = (paemode!=0);
+	if(dacmode != -1){
+		dev->dac_support = (dacmode!=0);
 	}
-	if(dev->pae_support != 0) {
-		printk(KERN_INFO"%s%d: 64 Bit PAE enabled\n", dev->name, dev->id);
-		pci_set_dma_mask(dev->pdev, (dma_addr_t)0xFFFFFFFFFFFFFFFFULL);
+	if(dev->dac_support != 0) {
+		if (!pci_set_dma_mask(dev->pdev, (dma_addr_t)0xFFFFFFFFFFFFFFFFULL) &&
+			!pci_set_consistent_dma_mask(dev->pdev, (dma_addr_t)0xFFFFFFFFFFFFFFFFULL)) {
+			printk(KERN_INFO"%s%d: 64 Bit DAC enabled\n",
+				dev->name, dev->id);
+		} else if (!pci_set_dma_mask(dev->pdev, (dma_addr_t)0xFFFFFFFFULL) &&
+			!pci_set_consistent_dma_mask(dev->pdev, (dma_addr_t)0xFFFFFFFFULL)) {
+			printk(KERN_INFO"%s%d: DMA mask set failed, 64 Bit DAC disabled\n",
+				dev->name, dev->id);
+			dev->dac_support = 0;
+		} else {
+			printk(KERN_WARNING"%s%d: No suitable DMA available.\n",
+				dev->name, dev->id);
+			rcode = -ENOMEM;
+		}
+	}
+	/* 57 scatter gather elements */
+	if (!(dev->raw_io_interface)) {
+		dev->scsi_host_ptr->sg_tablesize = (dev->max_fib_size
+			- sizeof(struct aac_fibhdr)
+			- sizeof(struct aac_write) + sizeof(struct sgmap))
+				/ sizeof(struct sgmap);
+		if( (sizeof(dma_addr_t) <= 4) || (num_physpages < (0xFFFFFFFFULL >> PAGE_SHIFT)) || (dev->adapter_info.options & AAC_OPT_SGMAP_HOST64) || (dev->dac_support != 0) ){
+			/* 38 scatter gather elements */
+			dev->scsi_host_ptr->sg_tablesize
+				= (dev->max_fib_size
+				- sizeof(struct aac_fibhdr)
+				- sizeof(struct aac_write64)
+				+ sizeof(struct sgmap64))
+					/ sizeof(struct sgmap64);
+		}
+		dev->scsi_host_ptr->max_sectors = AAC_MAX_32BIT_SGBCOUNT;
+		if(!(dev->adapter_info.options & AAC_OPT_NEW_COMM)) {
+			/*
+			 * Worst case size that could cause sg overflow when
+			 * we break up SG elements that are larger than 64KB.
+			 * Would be nice if we could tell the SCSI layer what
+			 * the maximum SG element size can be. Worst case is
+			 * (sg_tablesize-1) 4KB elements with one 64KB
+			 * element.
+			 *	32bit -> 468 or 238KB	64bit -> 424 or 212KB
+			 */
+			dev->scsi_host_ptr->max_sectors
+			  = (dev->scsi_host_ptr->sg_tablesize * 8) + 120;
+		}
 	}
 
 	fib_complete(fibptr);
@@ -511,13 +788,11 @@ int aac_get_adapter_info(struct aac_dev*
 	return rcode;
 }
 
-
-static void read_callback(void *context, struct fib * fibptr)
+static void io_callback(void *context, struct fib * fibptr)
 {
 	struct aac_dev *dev;
 	struct aac_read_reply *readreply;
 	struct scsi_cmnd *scsicmd;
-	u32 lba;
 	u32 cid;
 
 	scsicmd = (struct scsi_cmnd *) context;
@@ -525,8 +800,36 @@ static void read_callback(void *context,
 	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
 	cid = ID_LUN_TO_CONTAINER(scsicmd->device->id, scsicmd->device->lun);
 
-	lba = ((scsicmd->cmnd[1] & 0x1F) << 16) | (scsicmd->cmnd[2] << 8) | scsicmd->cmnd[3];
-	dprintk((KERN_DEBUG "read_callback[cpu %d]: lba = %u, t = %ld.\n", smp_processor_id(), lba, jiffies));
+	if (nblank(dprintk(x))) {
+		u64 lba;
+		if ((scsicmd->cmnd[0] == WRITE_6)	/* 6 byte command */
+		 || (scsicmd->cmnd[0] == READ_6))
+			lba = ((scsicmd->cmnd[1] & 0x1F) << 16)
+			    | (scsicmd->cmnd[2] << 8) | scsicmd->cmnd[3];
+#ifdef WRITE_16
+		else if ((scsicmd->cmnd[0] == WRITE_16)	/* 16 byte command */
+		 || (scsicmd->cmnd[0] == READ_16))
+			lba = ((u64)scsicmd->cmnd[2] << 56)
+			    | ((u64)scsicmd->cmnd[3] << 48)
+			    | ((u64)scsicmd->cmnd[4] << 40)
+			    | ((u64)scsicmd->cmnd[9] << 32)
+			    | ((u64)scsicmd->cmnd[6] << 24)
+			    | (scsicmd->cmnd[7] << 16)
+			    | (scsicmd->cmnd[8] << 8) | scsicmd->cmnd[9];
+#endif
+		else if ((scsicmd->cmnd[0] == WRITE_12)	/* 12 byte command */
+		 || (scsicmd->cmnd[0] == READ_12))
+			lba = ((u64)scsicmd->cmnd[2] << 24)
+			    | (scsicmd->cmnd[3] << 16)
+			    | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
+		else
+			lba = ((u64)scsicmd->cmnd[2] << 24)
+			    | (scsicmd->cmnd[3] << 16)
+			    | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
+		printk(KERN_DEBUG
+		  "io_callback[cpu %d]: lba = %llu, t = %ld.\n",
+		  smp_processor_id(), (unsigned long long)lba, jiffies);
+	}
 
 	if (fibptr == NULL)
 		BUG();
@@ -537,21 +840,24 @@ static void read_callback(void *context,
 			scsicmd->use_sg,
 			scsicmd->sc_data_direction);
 	else if(scsicmd->request_bufflen)
-		pci_unmap_single(dev->pdev, (dma_addr_t)(ulong)scsicmd->SCp.ptr,
+		pci_unmap_single(dev->pdev, scsicmd->SCp.dma_handle,
 				 scsicmd->request_bufflen,
 				 scsicmd->sc_data_direction);
 	readreply = (struct aac_read_reply *)fib_data(fibptr);
 	if (le32_to_cpu(readreply->status) == ST_OK)
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
 	else {
-		printk(KERN_WARNING "read_callback: read failed, status = %d\n", readreply->status);
+		printk(KERN_WARNING "io_callback: io failed, status = %d\n", le32_to_cpu(readreply->status));
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
-		set_sense((u8 *) &sense_data[cid],
+		set_sense((u8 *) &dev->fsa_dev[cid].sense_data,
 				    HARDWARE_ERROR,
 				    SENCODE_INTERNAL_TARGET_FAILURE,
 				    ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0,
 				    0, 0);
-		memcpy(scsicmd->sense_buffer, &sense_data[cid], sizeof(struct sense_data));
+		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
+		  (sizeof(dev->fsa_dev[cid].sense_data) > sizeof(scsicmd->sense_buffer))
+		    ? sizeof(scsicmd->sense_buffer)
+		    : sizeof(dev->fsa_dev[cid].sense_data));
 	}
 	fib_complete(fibptr);
 	fib_free(fibptr);
@@ -559,55 +865,43 @@ static void read_callback(void *context,
 	aac_io_done(scsicmd);
 }
 
-static void write_callback(void *context, struct fib * fibptr)
+static inline void aac_select_queue_depth(
+	struct scsi_cmnd * scsicmd,
+	int cid,
+	u64 lba,
+	u32 count)
 {
+	struct scsi_device *device = scsicmd->device;
 	struct aac_dev *dev;
-	struct aac_write_reply *writereply;
-	struct scsi_cmnd *scsicmd;
-	u32 lba;
-	u32 cid;
-
-	scsicmd = (struct scsi_cmnd *) context;
-	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
-	cid = ID_LUN_TO_CONTAINER(scsicmd->device->id, scsicmd->device->lun);
-
-	lba = ((scsicmd->cmnd[1] & 0x1F) << 16) | (scsicmd->cmnd[2] << 8) | scsicmd->cmnd[3];
-	dprintk((KERN_DEBUG "write_callback[cpu %d]: lba = %u, t = %ld.\n", smp_processor_id(), lba, jiffies));
-	if (fibptr == NULL)
-		BUG();
+	unsigned depth;
 
-	if(scsicmd->use_sg)
-		pci_unmap_sg(dev->pdev, 
-			(struct scatterlist *)scsicmd->buffer,
-			scsicmd->use_sg,
-			scsicmd->sc_data_direction);
-	else if(scsicmd->request_bufflen)
-		pci_unmap_single(dev->pdev, (dma_addr_t)(ulong)scsicmd->SCp.ptr,
-				 scsicmd->request_bufflen,
-				 scsicmd->sc_data_direction);
-
-	writereply = (struct aac_write_reply *) fib_data(fibptr);
-	if (le32_to_cpu(writereply->status) == ST_OK)
-		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
-	else {
-		printk(KERN_WARNING "write_callback: write failed, status = %d\n", writereply->status);
-		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
-		set_sense((u8 *) &sense_data[cid],
-				    HARDWARE_ERROR,
-				    SENCODE_INTERNAL_TARGET_FAILURE,
-				    ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0,
-				    0, 0);
-		memcpy(scsicmd->sense_buffer, &sense_data[cid], sizeof(struct sense_data));
+	if (!device->tagged_supported)
+		return;
+	dev = (struct aac_dev *)device->host->hostdata;
+	if (dev->fsa_dev[cid].queue_depth <= 2)
+		dev->fsa_dev[cid].queue_depth = device->queue_depth;
+	if (lba == dev->fsa_dev[cid].last) {
+		/*
+		 * If larger than coalescethreshold in size, coalescing has
+		 * less effect on overall performance.  Also, if we are
+		 * coalescing right now, leave it alone if above the threshold.
+		 */
+		if (count > coalescethreshold)
+			return;
+		depth = 2;
+	} else {
+		depth = dev->fsa_dev[cid].queue_depth;
 	}
-
-	fib_complete(fibptr);
-	fib_free(fibptr);
-	aac_io_done(scsicmd);
+	scsi_adjust_queue_depth(device, MSG_ORDERED_TAG, depth);
+	dprintk((KERN_DEBUG "l=%llu %llu[%u] q=%u %lu\n",
+	  dev->fsa_dev[cid].last, lba, count, device->queue_depth,
+	  dev->queues->queue[AdapNormCmdQueue].numpending));
+	dev->fsa_dev[cid].last = lba + count;
 }
 
 int aac_read(struct scsi_cmnd * scsicmd, int cid)
 {
-	u32 lba;
+	u64 lba;
 	u32 count;
 	int status;
 
@@ -619,6 +913,13 @@ int aac_read(struct scsi_cmnd * scsicmd,
 	/*
 	 *	Get block address and transfer length
 	 */
+	dprintk((KERN_DEBUG "aac_read: %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+	  scsicmd->cmnd[0],  scsicmd->cmnd[1],  scsicmd->cmnd[2],
+	  scsicmd->cmnd[3],  scsicmd->cmnd[4],  scsicmd->cmnd[5],
+	  scsicmd->cmnd[6],  scsicmd->cmnd[7],  scsicmd->cmnd[8],
+	  scsicmd->cmnd[9],  scsicmd->cmnd[10], scsicmd->cmnd[11],
+	  scsicmd->cmnd[12], scsicmd->cmnd[13], scsicmd->cmnd[14],
+	  scsicmd->cmnd[15]));
 	if (scsicmd->cmnd[0] == READ_6)	/* 6 byte command */
 	{
 		dprintk((KERN_DEBUG "aachba: received a read(6) command on id %d.\n", cid));
@@ -628,13 +929,54 @@ int aac_read(struct scsi_cmnd * scsicmd,
 
 		if (count == 0)
 			count = 256;
+#ifdef READ_16
+	} else if (scsicmd->cmnd[0] == READ_16) { /* 16 byte command */
+		dprintk((KERN_DEBUG "aachba: received a read(16) command on id %d.\n", cid));
+
+		lba = ((u64)scsicmd->cmnd[2] << 56)
+		    | ((u64)scsicmd->cmnd[3] << 48)
+		    | ((u64)scsicmd->cmnd[4] << 40)
+		    | ((u64)scsicmd->cmnd[9] << 32)
+		    | ((u64)scsicmd->cmnd[6] << 24) | (scsicmd->cmnd[7] << 16)
+		    | (scsicmd->cmnd[8] << 8) | scsicmd->cmnd[9];
+		count = (scsicmd->cmnd[10] << 24) | (scsicmd->cmnd[11] << 16)
+		      | (scsicmd->cmnd[12] << 8) | scsicmd->cmnd[13];
+#endif
+	} else if (scsicmd->cmnd[0] == READ_12) { /* 12 byte command */
+		dprintk((KERN_DEBUG "aachba: received a read(12) command on id %d.\n", cid));
+
+		lba = ((u64)scsicmd->cmnd[2] << 24) | (scsicmd->cmnd[3] << 16)
+		    | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
+		count = (scsicmd->cmnd[6] << 24) | (scsicmd->cmnd[7] << 16)
+		      | (scsicmd->cmnd[8] << 8) | scsicmd->cmnd[9];
 	} else {
 		dprintk((KERN_DEBUG "aachba: received a read(10) command on id %d.\n", cid));
 
-		lba = (scsicmd->cmnd[2] << 24) | (scsicmd->cmnd[3] << 16) | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
+		lba = ((u64)scsicmd->cmnd[2] << 24) | (scsicmd->cmnd[3] << 16) | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
 		count = (scsicmd->cmnd[7] << 8) | scsicmd->cmnd[8];
 	}
-	dprintk((KERN_DEBUG "aac_read[cpu %d]: lba = %u, t = %ld.\n", smp_processor_id(), lba, jiffies));
+	dprintk((KERN_DEBUG "aac_read[cpu %d]: lba = %llu, t = %ld.\n",
+	  smp_processor_id(), (unsigned long long)lba, jiffies));
+	if ((!(dev->raw_io_interface) || !(dev->raw_io_64))
+	 && (lba & 0xffffffff00000000LL)) {
+		dprintk((KERN_DEBUG "aac_read: Illegal lba\n"));
+		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
+		set_sense((u8 *) &dev->fsa_dev[cid].sense_data,
+			    HARDWARE_ERROR,
+			    SENCODE_INTERNAL_TARGET_FAILURE,
+			    ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0,
+			    0, 0);
+		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
+		  (sizeof(dev->fsa_dev[cid].sense_data) > sizeof(scsicmd->sense_buffer))
+		    ? sizeof(scsicmd->sense_buffer)
+		    : sizeof(dev->fsa_dev[cid].sense_data));
+		__aac_io_done(scsicmd);
+		return 0;
+	}
+	/*
+	 *	Are we in a sequential mode?
+	 */
+	aac_select_queue_depth(scsicmd, cid, lba, count);
 	/*
 	 *	Alocate and initialize a Fib
 	 */
@@ -644,20 +986,45 @@ int aac_read(struct scsi_cmnd * scsicmd,
 
 	fib_init(cmd_fibcontext);
 
-	if(dev->pae_support == 1){
+	if (dev->raw_io_interface) {
+		struct aac_raw_io *readcmd;
+		readcmd = (struct aac_raw_io *) fib_data(cmd_fibcontext);
+		readcmd->block[0] = cpu_to_le32((u32)(lba&0xffffffff));
+		readcmd->block[1] = cpu_to_le32((u32)((lba&0xffffffff00000000LL)>>32));
+		readcmd->count = cpu_to_le32(count<<9);
+		readcmd->cid = cpu_to_le16(cid);
+		readcmd->flags = 1; 
+		readcmd->bpTotal = 0;
+		readcmd->bpComplete = 0;
+		
+		aac_build_sgraw(scsicmd, &readcmd->sg);
+		fibsize = sizeof(struct aac_raw_io) + ((readcmd->sg.count - 1) * sizeof (struct sgentryraw));
+		if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))
+			BUG();
+		/*
+		 *	Now send the Fib to the adapter
+		 */
+		status = fib_send(ContainerRawIo,
+			  cmd_fibcontext, 
+			  fibsize, 
+			  FsaNormal, 
+			  0, 1, 
+			  (fib_callback) io_callback, 
+			  (void *) scsicmd);
+	} else if (dev->dac_support == 1) {
 		struct aac_read64 *readcmd;
 		readcmd = (struct aac_read64 *) fib_data(cmd_fibcontext);
 		readcmd->command = cpu_to_le32(VM_CtHostRead64);
 		readcmd->cid = cpu_to_le16(cid);
 		readcmd->sector_count = cpu_to_le16(count);
-		readcmd->block = cpu_to_le32(lba);
-		readcmd->pad   = cpu_to_le16(0);
-		readcmd->flags = cpu_to_le16(0); 
-
+		readcmd->block = cpu_to_le32((u32)(lba&0xffffffff));
+		readcmd->pad   = 0;
+		readcmd->flags = 0; 
+		
 		aac_build_sg64(scsicmd, &readcmd->sg);
-		if(readcmd->sg.count > MAX_DRIVER_SG_SEGMENT_COUNT)
-			BUG();
 		fibsize = sizeof(struct aac_read64) + ((readcmd->sg.count - 1) * sizeof (struct sgentry64));
+		if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))
+			BUG();
 		/*
 		 *	Now send the Fib to the adapter
 		 */
@@ -666,23 +1033,20 @@ int aac_read(struct scsi_cmnd * scsicmd,
 			  fibsize, 
 			  FsaNormal, 
 			  0, 1, 
-			  (fib_callback) read_callback, 
+			  (fib_callback) io_callback, 
 			  (void *) scsicmd);
 	} else {
 		struct aac_read *readcmd;
 		readcmd = (struct aac_read *) fib_data(cmd_fibcontext);
 		readcmd->command = cpu_to_le32(VM_CtBlockRead);
 		readcmd->cid = cpu_to_le32(cid);
-		readcmd->block = cpu_to_le32(lba);
+		readcmd->block = cpu_to_le32((u32)(lba&0xffffffff));
 		readcmd->count = cpu_to_le32(count * 512);
 
-		if (count * 512 > (64 * 1024))
-			BUG();
-
 		aac_build_sg(scsicmd, &readcmd->sg);
-		if(readcmd->sg.count > MAX_DRIVER_SG_SEGMENT_COUNT)
-			BUG();
 		fibsize = sizeof(struct aac_read) + ((readcmd->sg.count - 1) * sizeof (struct sgentry));
+		if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))
+			BUG();
 		/*
 		 *	Now send the Fib to the adapter
 		 */
@@ -691,7 +1055,7 @@ int aac_read(struct scsi_cmnd * scsicmd,
 			  fibsize, 
 			  FsaNormal, 
 			  0, 1, 
-			  (fib_callback) read_callback, 
+			  (fib_callback) io_callback, 
 			  (void *) scsicmd);
 	}
 
@@ -701,17 +1065,9 @@ int aac_read(struct scsi_cmnd * scsicmd,
 	 *	Check that the command queued to the controller
 	 */
 	if (status == -EINPROGRESS) 
-	{
-		dprintk("read queued.\n");
 		return 0;
-	}
 		
 	printk(KERN_WARNING "aac_read: fib_send failed with status: %d.\n", status);
-	/*
-	 *	For some reason, the Fib didn't queue, return QUEUE_FULL
-	 */
-	scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_TASK_SET_FULL;
-	aac_io_done(scsicmd);
 	fib_complete(cmd_fibcontext);
 	fib_free(cmd_fibcontext);
 	return -1;
@@ -719,7 +1075,7 @@ int aac_read(struct scsi_cmnd * scsicmd,
 
 static int aac_write(struct scsi_cmnd * scsicmd, int cid)
 {
-	u32 lba;
+	u64 lba;
 	u32 count;
 	int status;
 	u16 fibsize;
@@ -730,42 +1086,113 @@ static int aac_write(struct scsi_cmnd * 
 	/*
 	 *	Get block address and transfer length
 	 */
+	dprintk((KERN_DEBUG "aac_write: %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+	  scsicmd->cmnd[0],  scsicmd->cmnd[1],  scsicmd->cmnd[2],
+	  scsicmd->cmnd[3],  scsicmd->cmnd[4],  scsicmd->cmnd[5],
+	  scsicmd->cmnd[6],  scsicmd->cmnd[7],  scsicmd->cmnd[8],
+	  scsicmd->cmnd[9],  scsicmd->cmnd[10], scsicmd->cmnd[11],
+	  scsicmd->cmnd[12], scsicmd->cmnd[13], scsicmd->cmnd[14],
+	  scsicmd->cmnd[15]));
 	if (scsicmd->cmnd[0] == WRITE_6)	/* 6 byte command */
 	{
 		lba = ((scsicmd->cmnd[1] & 0x1F) << 16) | (scsicmd->cmnd[2] << 8) | scsicmd->cmnd[3];
 		count = scsicmd->cmnd[4];
 		if (count == 0)
 			count = 256;
+#ifdef WRITE_16
+	} else if (scsicmd->cmnd[0] == WRITE_16) { /* 16 byte command */
+		dprintk((KERN_DEBUG "aachba: received a write(16) command on id %d.\n", cid));
+
+		lba = ((u64)scsicmd->cmnd[2] << 56)
+		    | ((u64)scsicmd->cmnd[3] << 48)
+		    | ((u64)scsicmd->cmnd[4] << 40)
+		    | ((u64)scsicmd->cmnd[9] << 32)
+		    | ((u64)scsicmd->cmnd[6] << 24) | (scsicmd->cmnd[7] << 16)
+		    | (scsicmd->cmnd[8] << 8) | scsicmd->cmnd[9];
+		count = (scsicmd->cmnd[10] << 24) | (scsicmd->cmnd[11] << 16)
+		      | (scsicmd->cmnd[12] << 8) | scsicmd->cmnd[13];
+#endif
+	} else if (scsicmd->cmnd[0] == WRITE_12) { /* 12 byte command */
+		dprintk((KERN_DEBUG "aachba: received a write(12) command on id %d.\n", cid));
+
+		lba = ((u64)scsicmd->cmnd[2] << 24) | (scsicmd->cmnd[3] << 16)
+		    | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
+		count = (scsicmd->cmnd[6] << 24) | (scsicmd->cmnd[7] << 16)
+		      | (scsicmd->cmnd[8] << 8) | scsicmd->cmnd[9];
 	} else {
 		dprintk((KERN_DEBUG "aachba: received a write(10) command on id %d.\n", cid));
-		lba = (scsicmd->cmnd[2] << 24) | (scsicmd->cmnd[3] << 16) | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
+		lba = ((u64)scsicmd->cmnd[2] << 24) | (scsicmd->cmnd[3] << 16) | (scsicmd->cmnd[4] << 8) | scsicmd->cmnd[5];
 		count = (scsicmd->cmnd[7] << 8) | scsicmd->cmnd[8];
 	}
-	dprintk((KERN_DEBUG "aac_write[cpu %d]: lba = %u, t = %ld.\n", smp_processor_id(), lba, jiffies));
+	dprintk((KERN_DEBUG "aac_write[cpu %d]: lba = %llu, t = %ld.\n",
+	  smp_processor_id(), (unsigned long long)lba, jiffies));
+	if ((!(dev->raw_io_interface) || !(dev->raw_io_64))
+	 && (lba & 0xffffffff00000000LL)) {
+		dprintk((KERN_DEBUG "aac_write: Illegal lba\n"));
+		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
+		set_sense((u8 *) &dev->fsa_dev[cid].sense_data,
+			    HARDWARE_ERROR,
+			    SENCODE_INTERNAL_TARGET_FAILURE,
+			    ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0,
+			    0, 0);
+		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
+		  (sizeof(dev->fsa_dev[cid].sense_data) > sizeof(scsicmd->sense_buffer))
+		    ? sizeof(scsicmd->sense_buffer)
+		    : sizeof(dev->fsa_dev[cid].sense_data));
+		__aac_io_done(scsicmd);
+		return 0;
+	}
+	/*
+	 *	Are we in a sequential mode?
+	 */
+	aac_select_queue_depth(scsicmd, cid, lba, count);
 	/*
 	 *	Allocate and initialize a Fib then setup a BlockWrite command
 	 */
 	if (!(cmd_fibcontext = fib_alloc(dev))) {
-		scsicmd->result = DID_ERROR << 16;
-		aac_io_done(scsicmd);
 		return -1;
 	}
 	fib_init(cmd_fibcontext);
 
-	if(dev->pae_support == 1){
+	if (dev->raw_io_interface) {
+		struct aac_raw_io *writecmd;
+		writecmd = (struct aac_raw_io *) fib_data(cmd_fibcontext);
+		writecmd->block[0] = cpu_to_le32((u32)(lba&0xffffffff));
+		writecmd->block[1] = cpu_to_le32((u32)((lba&0xffffffff00000000LL)>>32));
+		writecmd->count = cpu_to_le32(count<<9);
+		writecmd->cid = cpu_to_le16(cid);
+		writecmd->flags = 0; 
+		writecmd->bpTotal = 0;
+		writecmd->bpComplete = 0;
+		
+		aac_build_sgraw(scsicmd, &writecmd->sg);
+		fibsize = sizeof(struct aac_raw_io) + ((writecmd->sg.count - 1) * sizeof (struct sgentryraw));
+		if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))
+			BUG();
+		/*
+		 *	Now send the Fib to the adapter
+		 */
+		status = fib_send(ContainerRawIo,
+			  cmd_fibcontext, 
+			  fibsize, 
+			  FsaNormal, 
+			  0, 1, 
+			  (fib_callback) io_callback, 
+			  (void *) scsicmd);
+	} else if (dev->dac_support == 1) {
 		struct aac_write64 *writecmd;
 		writecmd = (struct aac_write64 *) fib_data(cmd_fibcontext);
 		writecmd->command = cpu_to_le32(VM_CtHostWrite64);
 		writecmd->cid = cpu_to_le16(cid);
 		writecmd->sector_count = cpu_to_le16(count); 
-		writecmd->block = cpu_to_le32(lba);
-		writecmd->pad	= cpu_to_le16(0);
-		writecmd->flags	= cpu_to_le16(0);
+		writecmd->block = cpu_to_le32((u32)(lba&0xffffffff));
+		writecmd->pad	= 0;
+		writecmd->flags	= 0;
 
 		aac_build_sg64(scsicmd, &writecmd->sg);
-		if(writecmd->sg.count > MAX_DRIVER_SG_SEGMENT_COUNT)
-			BUG();
 		fibsize = sizeof(struct aac_write64) + ((writecmd->sg.count - 1) * sizeof (struct sgentry64));
+		if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))
+			BUG();
 		/*
 		 *	Now send the Fib to the adapter
 		 */
@@ -774,26 +1201,22 @@ static int aac_write(struct scsi_cmnd * 
 			  fibsize, 
 			  FsaNormal, 
 			  0, 1, 
-			  (fib_callback) write_callback, 
+			  (fib_callback) io_callback, 
 			  (void *) scsicmd);
 	} else {
 		struct aac_write *writecmd;
 		writecmd = (struct aac_write *) fib_data(cmd_fibcontext);
 		writecmd->command = cpu_to_le32(VM_CtBlockWrite);
 		writecmd->cid = cpu_to_le32(cid);
-		writecmd->block = cpu_to_le32(lba);
+		writecmd->block = cpu_to_le32((u32)(lba&0xffffffff));
 		writecmd->count = cpu_to_le32(count * 512);
 		writecmd->sg.count = cpu_to_le32(1);
 		/* ->stable is not used - it did mean which type of write */
 
-		if (count * 512 > (64 * 1024)) {
-			BUG();
-		}
-
 		aac_build_sg(scsicmd, &writecmd->sg);
-		if(writecmd->sg.count > MAX_DRIVER_SG_SEGMENT_COUNT)
-			BUG();
 		fibsize = sizeof(struct aac_write) + ((writecmd->sg.count - 1) * sizeof (struct sgentry));
+		if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))
+			BUG();
 		/*
 		 *	Now send the Fib to the adapter
 		 */
@@ -802,7 +1225,7 @@ static int aac_write(struct scsi_cmnd * 
 			  fibsize, 
 			  FsaNormal, 
 			  0, 1, 
-			  (fib_callback) write_callback, 
+			  (fib_callback) io_callback, 
 			  (void *) scsicmd);
 	}
 
@@ -810,18 +1233,116 @@ static int aac_write(struct scsi_cmnd * 
 	 *	Check that the command queued to the controller
 	 */
 	if (status == -EINPROGRESS)
-	{
-		dprintk("write queued.\n");
 		return 0;
-	}
 
 	printk(KERN_WARNING "aac_write: fib_send failed with status: %d\n", status);
+
+	fib_complete(cmd_fibcontext);
+	fib_free(cmd_fibcontext);
+	return -1;
+}
+
+static void synchronize_callback(void *context, struct fib * fibptr)
+{
+	struct aac_synchronize_reply * synchronizereply;
+	struct scsi_cmnd * scsicmd;
+
+	scsicmd = (struct scsi_cmnd *) context;
+
+	dprintk((KERN_DEBUG "synchronize_callback[cpu %d]: t = %ld.\n", smp_processor_id(), jiffies));
+	if (fibptr == NULL)
+		BUG();
+
+
+	synchronizereply = (struct aac_synchronize_reply *) fib_data(fibptr);
+	if (le32_to_cpu(synchronizereply->status) == CT_OK) {
+		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+	} else {
+		struct scsi_device * device = scsicmd->device;
+		struct aac_dev *dev = (struct aac_dev *)device->host->hostdata;
+		u32 cid = ID_LUN_TO_CONTAINER(device->id, device->lun);
+		printk(KERN_WARNING "synchronize_callback: synchronize failed, status = %d\n", synchronizereply->status);
+		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
+		set_sense((u8 *) &dev->fsa_dev[cid].sense_data,
+				    HARDWARE_ERROR,
+				    SENCODE_INTERNAL_TARGET_FAILURE,
+				    ASENCODE_INTERNAL_TARGET_FAILURE, 0, 0,
+				    0, 0);
+		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
+		  (sizeof(dev->fsa_dev[cid].sense_data) > sizeof(scsicmd->sense_buffer))
+		    ? sizeof(scsicmd->sense_buffer)
+		    : sizeof(dev->fsa_dev[cid].sense_data));
+	}
+
+	fib_complete(fibptr);
+	fib_free(fibptr);
+	aac_io_done(scsicmd);
+}
+
+static int aac_synchronize(struct scsi_cmnd * scsicmd, int cid)
+{
+	int status;
+	struct fib * cmd_fibcontext;
+	struct aac_synchronize * synchronizecmd;
+
 	/*
-	 *	For some reason, the Fib didn't queue, return QUEUE_FULL
+	 * Wait for all commands to complete to this specific
+	 * target (block).
 	 */
-	scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_TASK_SET_FULL;
-	aac_io_done(scsicmd);
+	struct scsi_cmnd * cmd;
+	struct scsi_device * device = scsicmd->device;
+	int active = 0;
+	unsigned long flags;
+	spin_lock_irqsave(&device->list_lock, flags);
+	list_for_each_entry(cmd, &device->cmd_list, list) {
+		if ((cmd != scsicmd) && (cmd->serial_number != 0)) {
+			++active;
+			break;
+		}
+	}
+	spin_unlock_irqrestore(&device->list_lock, flags);
+	if (active) {
+		/*
+		 *	Yield the processor (requeue for later)
+		 */
+		return -1;
+	}
 
+	dprintk((KERN_DEBUG "aac_synchronize[cpu %d]: t = %ld.\n", smp_processor_id(), jiffies));
+	/*
+	 *	Alocate and initialize a Fib
+	 */
+	if (!(cmd_fibcontext = fib_alloc((struct aac_dev *)scsicmd->device->host->hostdata))) {
+		return -1;
+	}
+
+	fib_init(cmd_fibcontext);
+
+	synchronizecmd = (struct aac_synchronize *) fib_data(cmd_fibcontext);
+	synchronizecmd->command = cpu_to_le32(VM_ContainerConfig);
+	synchronizecmd->type = cpu_to_le32(CT_FLUSH_CACHE);
+	synchronizecmd->cid = cpu_to_le32(cid);
+	synchronizecmd->count = cpu_to_le32(sizeof(((struct aac_synchronize_reply *)NULL)->data));
+
+	/*
+	 *	Now send the Fib to the adapter
+	 */
+	status = fib_send(ContainerCommand,
+		  cmd_fibcontext,
+		  sizeof(struct aac_synchronize),
+		  FsaNormal,
+		  0, 1,
+		  (fib_callback) synchronize_callback,
+		  (void *) scsicmd);
+
+	/*
+	 *	Check that the command queued to the controller
+	 */
+	if (status == -EINPROGRESS) {
+		return 0;
+	}
+
+	printk(KERN_WARNING "aac_synchronize: fib_send failed with status: %d.\n", status);
 	fib_complete(cmd_fibcontext);
 	fib_free(cmd_fibcontext);
 	return -1;
@@ -839,12 +1360,11 @@ static int aac_write(struct scsi_cmnd * 
 int aac_scsi_cmd(struct scsi_cmnd * scsicmd)
 {
 	u32 cid = 0;
-	int ret;
 	struct Scsi_Host *host = scsicmd->device->host;
 	struct aac_dev *dev = (struct aac_dev *)host->hostdata;
-	struct fsa_scsi_hba *fsa_dev_ptr = &dev->fsa_dev;
+	struct fsa_dev_info *fsa_dev_ptr = dev->fsa_dev;
 	int cardtype = dev->cardtype;
-	
+
 	/*
 	 *	If the bus, id or lun is out of range, return fail
 	 *	Test does not apply to ID 16, the pseudo id for the controller
@@ -852,7 +1372,7 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 	 */
 	if (scsicmd->device->id != host->this_id) {
 		if ((scsicmd->device->channel == 0) ){
-			if( (scsicmd->device->id >= MAXIMUM_NUM_CONTAINERS) || (scsicmd->device->lun != 0)){ 
+			if( (scsicmd->device->id >= dev->maximum_num_containers) || (scsicmd->device->lun != 0)){ 
 				scsicmd->result = DID_NO_CONNECT << 16;
 				__aac_io_done(scsicmd);
 				return 0;
@@ -863,15 +1383,20 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 			 *	If the target container doesn't exist, it may have
 			 *	been newly created
 			 */
-			if (fsa_dev_ptr->valid[cid] == 0) {
+			if ((fsa_dev_ptr[cid].valid & 1) == 0) {
 				switch (scsicmd->cmnd[0]) {
+#ifdef SERVICE_ACTION_IN
+				case SERVICE_ACTION_IN:
+					if ((scsicmd->cmnd[1] & 0x1f) != SAI_READ_CAPACITY_16)
+						break;
+#endif
 				case INQUIRY:
 				case READ_CAPACITY:
 				case TEST_UNIT_READY:
 					spin_unlock_irq(host->host_lock);
 					probe_container(dev, cid);
 					spin_lock_irq(host->host_lock);
-					if (fsa_dev_ptr->valid[cid] == 0) {
+					if (fsa_dev_ptr[cid].valid == 0) {
 						scsicmd->result = DID_NO_CONNECT << 16;
 						__aac_io_done(scsicmd);
 						return 0;
@@ -884,7 +1409,7 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 			 *	If the target container still doesn't exist, 
 			 *	return failure
 			 */
-			if (fsa_dev_ptr->valid[cid] == 0) {
+			if (fsa_dev_ptr[cid].valid == 0) {
 				scsicmd->result = DID_BAD_TARGET << 16;
 				__aac_io_done(scsicmd);
 				return 0;
@@ -907,12 +1432,15 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 	{
 		dprintk((KERN_WARNING "Only INQUIRY & TUR command supported for controller, rcvd = 0x%x.\n", scsicmd->cmnd[0]));
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
-		set_sense((u8 *) &sense_data[cid],
+		set_sense((u8 *) &dev->fsa_dev[cid].sense_data,
 			    ILLEGAL_REQUEST,
 			    SENCODE_INVALID_COMMAND,
 			    ASENCODE_INVALID_COMMAND, 0, 0, 0, 0);
+		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
+		  (sizeof(dev->fsa_dev[cid].sense_data) > sizeof(scsicmd->sense_buffer))
+		    ? sizeof(scsicmd->sense_buffer)
+		    : sizeof(dev->fsa_dev[cid].sense_data));
 		__aac_io_done(scsicmd);
-		memcpy(scsicmd->sense_buffer, &sense_data[cid], sizeof(struct sense_data));
 		return 0;
 	}
 
@@ -928,7 +1456,6 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 		memset(inq_data_ptr, 0, sizeof (struct inquiry_data));
 
 		inq_data_ptr->inqd_ver = 2;	/* claim compliance to SCSI-2 */
-		inq_data_ptr->inqd_dtq = 0x80;	/* set RMB bit to one indicating that the medium is removable */
 		inq_data_ptr->inqd_rdf = 2;	/* A response data format value of two indicates that the data shall be in the format specified in SCSI-2 */
 		inq_data_ptr->inqd_len = 31;
 		/*Format for "pad2" is  RelAdr | WBus32 | WBus16 |  Sync  | Linked |Reserved| CmdQue | SftRe */
@@ -937,22 +1464,59 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 		 *	Set the Vendor, Product, and Revision Level
 		 *	see: <vendor>.c i.e. aac.c
 		 */
-		setinqstr(cardtype, (void *) (inq_data_ptr->inqd_vid), fsa_dev_ptr->type[cid]);
-		if (scsicmd->device->id == host->this_id)
+		if (scsicmd->device->id == host->this_id) {
+			setinqstr(cardtype, (void *) (inq_data_ptr->inqd_vid), (sizeof(container_types)/sizeof(char *)));
 			inq_data_ptr->inqd_pdt = INQD_PDT_PROC;	/* Processor device */
-		else
-			inq_data_ptr->inqd_pdt = INQD_PDT_DA;	/* Direct/random access device */
+			scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
+			__aac_io_done(scsicmd);
+			return 0;
+		}
+		setinqstr(cardtype, (void *) (inq_data_ptr->inqd_vid), fsa_dev_ptr[cid].type);
+		inq_data_ptr->inqd_pdt = INQD_PDT_DA;	/* Direct/random access device */
+		return aac_get_container_name(scsicmd, cid);
+	}
+#ifdef SERVICE_ACTION_IN
+	case SERVICE_ACTION_IN:
+		if ((scsicmd->cmnd[1] & 0x1f) != SAI_READ_CAPACITY_16)
+			break;
+	{
+		u64 capacity;
+		char *cp;
+
+		dprintk((KERN_DEBUG "READ CAPACITY_16 command.\n"));
+		capacity = fsa_dev_ptr[cid].size - 1;
+		cp = scsicmd->request_buffer;
+		cp[0] = 0;
+		cp[1] = 0;
+		cp[2] = (capacity >> 56) & 0xff;
+		cp[3] = (capacity >> 48) & 0xff;
+		cp[4] = (capacity >> 40) & 0xff;
+		cp[5] = (capacity >> 32) & 0xff;
+		cp[6] = (capacity >> 24) & 0xff;
+		cp[7] = (capacity >> 16) & 0xff;
+		cp[8] = (capacity >> 8) & 0xff;
+		cp[9] = (capacity >> 0) & 0xff;
+		cp[10] = 0;
+		cp[11] = 0;
+		cp[12] = 2;
+		cp[13] = 0;
+
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
 		__aac_io_done(scsicmd);
+
 		return 0;
 	}
+#endif
 	case READ_CAPACITY:
 	{
-		int capacity;
+		u32 capacity;
 		char *cp;
 
 		dprintk((KERN_DEBUG "READ CAPACITY command.\n"));
-		capacity = fsa_dev_ptr->size[cid] - 1;
+		if (fsa_dev_ptr[cid].size <= 0x100000000)
+			capacity = fsa_dev_ptr[cid].size - 1;
+		else
+			capacity = (u32)-1;
 		cp = scsicmd->request_buffer;
 		cp[0] = (capacity >> 24) & 0xff;
 		cp[1] = (capacity >> 16) & 0xff;
@@ -1007,8 +1571,8 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 	}
 	case REQUEST_SENSE:
 		dprintk((KERN_DEBUG "REQUEST SENSE command.\n"));
-		memcpy(scsicmd->sense_buffer, &sense_data[cid], sizeof (struct sense_data));
-		memset(&sense_data[cid], 0, sizeof (struct sense_data));
+		memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data, sizeof (struct sense_data));
+		memset(&dev->fsa_dev[cid].sense_data, 0, sizeof (struct sense_data));
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
 		__aac_io_done(scsicmd);
 		return 0;
@@ -1016,9 +1580,9 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 	case ALLOW_MEDIUM_REMOVAL:
 		dprintk((KERN_DEBUG "LOCK command.\n"));
 		if (scsicmd->cmnd[4])
-			fsa_dev_ptr->locked[cid] = 1;
+			fsa_dev_ptr[cid].locked = 1;
 		else
-			fsa_dev_ptr->locked[cid] = 0;
+			fsa_dev_ptr[cid].locked = 0;
 
 		scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_GOOD;
 		__aac_io_done(scsicmd);
@@ -1042,57 +1606,95 @@ int aac_scsi_cmd(struct scsi_cmnd * scsi
 	{
 		case READ_6:
 		case READ_10:
+		case READ_12:
+#ifdef READ_16
+		case READ_16:
+#endif
 			/*
 			 *	Hack to keep track of ordinal number of the device that
 			 *	corresponds to a container. Needed to convert
 			 *	containers to /dev/sd device names
 			 */
-			 
-			spin_unlock_irq(host->host_lock);
-			if  (scsicmd->request->rq_disk)
-				memcpy(fsa_dev_ptr->devname[cid],
-					scsicmd->request->rq_disk->disk_name,
-					8);
-
-			ret = aac_read(scsicmd, cid);
-			spin_lock_irq(host->host_lock);
-			return ret;
+			if ((scsicmd->eh_state != SCSI_STATE_QUEUED)
+			 && (overridetimeout > 0)) {
+				mod_timer(&scsicmd->eh_timeout, jiffies + (overridetimeout * HZ));
+			}
+			if (scsicmd->request->rq_disk)
+				strlcpy(fsa_dev_ptr[cid].devname,
+				  scsicmd->request->rq_disk->disk_name,
+				  min(
+				    sizeof(fsa_dev_ptr[cid].devname),
+				    sizeof(scsicmd->request->rq_disk->disk_name) + 1));
+
+			return aac_read(scsicmd, cid);
 
 		case WRITE_6:
 		case WRITE_10:
-			spin_unlock_irq(host->host_lock);
-			ret = aac_write(scsicmd, cid);
-			spin_lock_irq(host->host_lock);
-			return ret;
+		case WRITE_12:
+#ifdef WRITE_16
+		case WRITE_16:
+#endif
+			if ((scsicmd->eh_state != SCSI_STATE_QUEUED)
+			 && (overridetimeout > 0)) {
+				mod_timer(&scsicmd->eh_timeout, jiffies + (overridetimeout * HZ));
+			}
+			return aac_write(scsicmd, cid);
+
+		case SYNCHRONIZE_CACHE:
+			/* Issue FIB to tell Firmware to flush it's cache */
+			return aac_synchronize(scsicmd, cid);
+			
 		default:
 			/*
 			 *	Unhandled commands
 			 */
-			printk(KERN_WARNING "Unhandled SCSI Command: 0x%x.\n", scsicmd->cmnd[0]);
+			dprintk((KERN_WARNING "Unhandled SCSI Command: 0x%x.\n", scsicmd->cmnd[0]));
 			scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8 | SAM_STAT_CHECK_CONDITION;
-			set_sense((u8 *) &sense_data[cid],
+			set_sense((u8 *) &dev->fsa_dev[cid].sense_data,
 				ILLEGAL_REQUEST, SENCODE_INVALID_COMMAND,
-			ASENCODE_INVALID_COMMAND, 0, 0, 0, 0);
-			memcpy(scsicmd->sense_buffer, &sense_data[cid],
-				sizeof(struct sense_data));
+				ASENCODE_INVALID_COMMAND, 0, 0, 0, 0);
+			memcpy(scsicmd->sense_buffer, &dev->fsa_dev[cid].sense_data,
+			  (sizeof(dev->fsa_dev[cid].sense_data) > sizeof(scsicmd->sense_buffer))
+			    ? sizeof(scsicmd->sense_buffer)
+			    : sizeof(dev->fsa_dev[cid].sense_data));
 			__aac_io_done(scsicmd);
 			return 0;
 	}
 }
 
-static int query_disk(struct aac_dev *dev, void __user *arg)
+static int busy_disk(struct aac_dev * dev, int cid)
+{
+	if ((dev != (struct aac_dev *)NULL)
+	 && (dev->scsi_host_ptr != (struct Scsi_Host *)NULL)) {
+		struct scsi_device *device;
+		shost_for_each_device(device, dev->scsi_host_ptr)
+		{
+			if ((device->channel == CONTAINER_TO_CHANNEL(cid))
+			 && (device->id == CONTAINER_TO_ID(cid))
+			 && (device->lun == CONTAINER_TO_LUN(cid))
+			&& (device->device_busy
+			  || test_bit(SHOST_RECOVERY, &dev->scsi_host_ptr->shost_state))) {
+				scsi_device_put(device);
+				return 1;
+			}
+		}
+	}
+	return 0;
+}
+
+static int query_disk(struct aac_dev *dev, void *arg)
 {
 	struct aac_query_disk qd;
-	struct fsa_scsi_hba *fsa_dev_ptr;
+	struct fsa_dev_info *fsa_dev_ptr;
 
-	fsa_dev_ptr = &(dev->fsa_dev);
+	fsa_dev_ptr = dev->fsa_dev;
 	if (copy_from_user(&qd, arg, sizeof (struct aac_query_disk)))
 		return -EFAULT;
 	if (qd.cnum == -1)
 		qd.cnum = ID_LUN_TO_CONTAINER(qd.id, qd.lun);
 	else if ((qd.bus == -1) && (qd.id == -1) && (qd.lun == -1)) 
 	{
-		if (qd.cnum < 0 || qd.cnum >= MAXIMUM_NUM_CONTAINERS)
+		if (qd.cnum < 0 || qd.cnum >= dev->maximum_num_containers)
 			return -EINVAL;
 		qd.instance = dev->scsi_host_ptr->host_no;
 		qd.bus = 0;
@@ -1101,73 +1703,74 @@ static int query_disk(struct aac_dev *de
 	}
 	else return -EINVAL;
 
-	qd.valid = fsa_dev_ptr->valid[qd.cnum];
-	qd.locked = fsa_dev_ptr->locked[qd.cnum];
-	qd.deleted = fsa_dev_ptr->deleted[qd.cnum];
+	qd.valid = fsa_dev_ptr[qd.cnum].valid;
+	qd.locked = fsa_dev_ptr[qd.cnum].locked || busy_disk(dev, qd.cnum);
+	qd.deleted = fsa_dev_ptr[qd.cnum].deleted;
 
-	if (fsa_dev_ptr->devname[qd.cnum][0] == '\0')
+	if (fsa_dev_ptr[qd.cnum].devname[0] == '\0')
 		qd.unmapped = 1;
 	else
 		qd.unmapped = 0;
 
-	strlcpy(qd.name, fsa_dev_ptr->devname[qd.cnum], sizeof(qd.name));
+	strlcpy(qd.name, fsa_dev_ptr[qd.cnum].devname,
+	  min(sizeof(qd.name), sizeof(fsa_dev_ptr[qd.cnum].devname) + 1));
 
 	if (copy_to_user(arg, &qd, sizeof (struct aac_query_disk)))
 		return -EFAULT;
 	return 0;
 }
 
-static int force_delete_disk(struct aac_dev *dev, void __user *arg)
+static int force_delete_disk(struct aac_dev *dev, void *arg)
 {
 	struct aac_delete_disk dd;
-	struct fsa_scsi_hba *fsa_dev_ptr;
+	struct fsa_dev_info *fsa_dev_ptr;
 
-	fsa_dev_ptr = &(dev->fsa_dev);
+	fsa_dev_ptr = dev->fsa_dev;
 
 	if (copy_from_user(&dd, arg, sizeof (struct aac_delete_disk)))
 		return -EFAULT;
 
-	if (dd.cnum >= MAXIMUM_NUM_CONTAINERS)
+	if (dd.cnum >= dev->maximum_num_containers)
 		return -EINVAL;
 	/*
 	 *	Mark this container as being deleted.
 	 */
-	fsa_dev_ptr->deleted[dd.cnum] = 1;
+	fsa_dev_ptr[dd.cnum].deleted = 1;
 	/*
 	 *	Mark the container as no longer valid
 	 */
-	fsa_dev_ptr->valid[dd.cnum] = 0;
+	fsa_dev_ptr[dd.cnum].valid = 0;
 	return 0;
 }
 
-static int delete_disk(struct aac_dev *dev, void __user *arg)
+static int delete_disk(struct aac_dev *dev, void *arg)
 {
 	struct aac_delete_disk dd;
-	struct fsa_scsi_hba *fsa_dev_ptr;
+	struct fsa_dev_info *fsa_dev_ptr;
 
-	fsa_dev_ptr = &(dev->fsa_dev);
+	fsa_dev_ptr = dev->fsa_dev;
 
 	if (copy_from_user(&dd, arg, sizeof (struct aac_delete_disk)))
 		return -EFAULT;
 
-	if (dd.cnum >= MAXIMUM_NUM_CONTAINERS)
+	if (dd.cnum >= dev->maximum_num_containers)
 		return -EINVAL;
 	/*
 	 *	If the container is locked, it can not be deleted by the API.
 	 */
-	if (fsa_dev_ptr->locked[dd.cnum])
+	if (fsa_dev_ptr[dd.cnum].locked || busy_disk(dev, dd.cnum))
 		return -EBUSY;
 	else {
 		/*
 		 *	Mark the container as no longer being valid.
 		 */
-		fsa_dev_ptr->valid[dd.cnum] = 0;
-		fsa_dev_ptr->devname[dd.cnum][0] = '\0';
+		fsa_dev_ptr[dd.cnum].valid = 0;
+		fsa_dev_ptr[dd.cnum].devname[0] = '\0';
 		return 0;
 	}
 }
 
-int aac_dev_ioctl(struct aac_dev *dev, int cmd, void __user *arg)
+int aac_dev_ioctl(struct aac_dev *dev, int cmd, void *arg)
 {
 	switch (cmd) {
 	case FSACTL_QUERY_DISK:
@@ -1207,11 +1810,8 @@ static void aac_srb_callback(void *conte
 
 	srbreply = (struct aac_srb_reply *) fib_data(fibptr);
 
-	scsicmd->sense_buffer[0] = '\0';  /* Initialize sense valid flag to false */
-	/*
-	 *	Calculate resid for sg 
-	 */
-	 
+	scsicmd->sense_buffer[0] = '\0';  // initialize sense valid flag to false
+	// calculate resid for sg 
 	scsicmd->resid = scsicmd->request_bufflen - srbreply->data_xfer_length;
 
 	if(scsicmd->use_sg)
@@ -1220,7 +1820,8 @@ static void aac_srb_callback(void *conte
 			scsicmd->use_sg,
 			scsicmd->sc_data_direction);
 	else if(scsicmd->request_bufflen)
-		pci_unmap_single(dev->pdev, (ulong)scsicmd->SCp.ptr, scsicmd->request_bufflen,
+		pci_unmap_single(dev->pdev, scsicmd->SCp.dma_handle,
+			scsicmd->request_bufflen,
 			scsicmd->sc_data_direction);
 
 	/*
@@ -1255,6 +1856,12 @@ static void aac_srb_callback(void *conte
 			if( b==TYPE_TAPE || b==TYPE_WORM || b==TYPE_ROM || b==TYPE_MOD|| b==TYPE_MEDIUM_CHANGER 
 					|| (b==TYPE_DISK && (b1&0x80)) ){
 				scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+			/*
+			 * We will allow disk devices if in RAID/SCSI mode and
+			 * the channel is 2
+			 */
+			} else if((dev->raid_scsi_mode)&&(scsicmd->device->channel == 2)){
+				scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
 			} else {
 				scsicmd->result = DID_NO_CONNECT << 16 | COMMAND_COMPLETE << 8;
 			}
@@ -1270,6 +1877,12 @@ static void aac_srb_callback(void *conte
 		case  WRITE_10:
 		case  READ_12:
 		case  WRITE_12:
+#ifdef READ_16
+		case  READ_16:
+#endif
+#ifdef WRITE_16
+		case  WRITE_16:
+#endif
 			if(le32_to_cpu(srbreply->data_xfer_length) < scsicmd->underflow ) {
 				printk(KERN_WARNING"aacraid: SCSI CMD underflow\n");
 			} else {
@@ -1288,6 +1901,12 @@ static void aac_srb_callback(void *conte
 			if( b==TYPE_TAPE || b==TYPE_WORM || b==TYPE_ROM || b==TYPE_MOD|| b==TYPE_MEDIUM_CHANGER
 					|| (b==TYPE_DISK && (b1&0x80)) ){
 				scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
+			/*
+			 * We will allow disk devices if in RAID/SCSI mode and
+			 * the channel is 2
+			 */
+			} else if((dev->raid_scsi_mode)&&(scsicmd->device->channel == 2)){
+				scsicmd->result = DID_OK << 16 | COMMAND_COMPLETE << 8;
 			} else {
 				scsicmd->result = DID_NO_CONNECT << 16 | COMMAND_COMPLETE << 8;
 			}
@@ -1348,7 +1967,7 @@ static void aac_srb_callback(void *conte
 	case SRB_STATUS_DOMAIN_VALIDATION_FAIL:
 	default:
 #ifdef AAC_DETAILED_STATUS_INFO
-		printk("aacraid: SRB ERROR(%u) %s scsi cmd 0x%x - scsi status 0x%x\n",le32_to_cpu(srbreply->srb_status&0x3f),aac_get_status_string(le32_to_cpu(srbreply->srb_status)), scsicmd->cmnd[0], le32_to_cpu(srbreply->scsi_status) );
+		printk("aacraid: SRB ERROR(%u) %s scsi cmd 0x%x - scsi status 0x%x\n",le32_to_cpu(srbreply->srb_status)&0x3f,aac_get_status_string(le32_to_cpu(srbreply->srb_status)&0x3F), scsicmd->cmnd[0], le32_to_cpu(srbreply->scsi_status) );
 #endif
 		scsicmd->result = DID_ERROR << 16 | COMMAND_COMPLETE << 8;
 		break;
@@ -1358,9 +1977,10 @@ static void aac_srb_callback(void *conte
 		scsicmd->result |= SAM_STAT_CHECK_CONDITION;
 		len = (srbreply->sense_data_size > sizeof(scsicmd->sense_buffer))?
 				sizeof(scsicmd->sense_buffer):srbreply->sense_data_size;
-		dprintk((KERN_WARNING "aac_srb_callback: check condition, status = %d len=%d\n", le32_to_cpu(srbreply->status), len));
+#ifdef AAC_DETAILED_STATUS_INFO
+		printk(KERN_WARNING "aac_srb_callback: check condition, status = %d len=%d\n", le32_to_cpu(srbreply->status), len);
+#endif
 		memcpy(scsicmd->sense_buffer, srbreply->sense_data, len);
-		
 	}
 	/*
 	 * OR in the scsi status (already shifted up a bit)
@@ -1426,7 +2046,7 @@ static int aac_send_srb_fib(struct scsi_
 	srbcmd = (struct aac_srb*) fib_data(cmd_fibcontext);
 	srbcmd->function = cpu_to_le32(SRBF_ExecuteScsi);
 	srbcmd->channel  = cpu_to_le32(aac_logical_to_phys(scsicmd->device->channel));
-	srbcmd->id   = cpu_to_le32(scsicmd->device->id);
+	srbcmd->id       = cpu_to_le32(scsicmd->device->id);
 	srbcmd->lun      = cpu_to_le32(scsicmd->device->lun);
 	srbcmd->flags    = cpu_to_le32(flag);
 	timeout = (scsicmd->timeout-jiffies)/HZ;
@@ -1434,10 +2054,10 @@ static int aac_send_srb_fib(struct scsi_
 		timeout = 1;
 	}
 	srbcmd->timeout  = cpu_to_le32(timeout);  // timeout in seconds
-	srbcmd->retry_limit =cpu_to_le32(0); // Obsolete parameter
+	srbcmd->retry_limit = 0; // Obsolete parameter
 	srbcmd->cdb_size = cpu_to_le32(scsicmd->cmd_len);
 	
-	if( dev->pae_support ==1 ) {
+	if (dev->dac_support == 1) {
 		aac_build_sg64(scsicmd, (struct sgmap64*) &srbcmd->sg);
 		srbcmd->count = cpu_to_le32(scsicmd->request_bufflen);
 
@@ -1446,7 +2066,10 @@ static int aac_send_srb_fib(struct scsi_
 		/*
 		 *	Build Scatter/Gather list
 		 */
-		fibsize = sizeof (struct aac_srb) + (((srbcmd->sg.count & 0xff) - 1) * sizeof (struct sgentry64));
+		fibsize = sizeof (struct aac_srb) - sizeof (struct sgentry) +
+			((srbcmd->sg.count & 0xff) * sizeof (struct sgentry64));
+		if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))
+			BUG();
 
 		/*
 		 *	Now send the Fib to the adapter
@@ -1463,6 +2086,8 @@ static int aac_send_srb_fib(struct scsi_
 		 *	Build Scatter/Gather list
 		 */
 		fibsize = sizeof (struct aac_srb) + (((srbcmd->sg.count & 0xff) - 1) * sizeof (struct sgentry));
+		if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr)))
+			BUG();
 
 		/*
 		 *	Now send the Fib to the adapter
@@ -1478,6 +2103,7 @@ static int aac_send_srb_fib(struct scsi_
 	}
 
 	printk(KERN_WARNING "aac_srb: fib_send failed with status: %d\n", status);
+
 	fib_complete(cmd_fibcontext);
 	fib_free(cmd_fibcontext);
 
@@ -1486,14 +2112,14 @@ static int aac_send_srb_fib(struct scsi_
 
 static unsigned long aac_build_sg(struct scsi_cmnd* scsicmd, struct sgmap* psg)
 {
-	struct aac_dev *dev;
+	struct Scsi_Host *host = scsicmd->device->host;
+	struct aac_dev *dev = (struct aac_dev *)host->hostdata;
 	unsigned long byte_count = 0;
 
-	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
 	// Get rid of old data
-	psg->count = cpu_to_le32(0);
-	psg->sg[0].addr = cpu_to_le32(0);
-	psg->sg[0].count = cpu_to_le32(0);  
+	psg->count = 0;
+	psg->sg[0].addr = 0;
+	psg->sg[0].count = 0;  
 	if (scsicmd->use_sg) {
 		struct scatterlist *sg;
 		int i;
@@ -1502,16 +2128,28 @@ static unsigned long aac_build_sg(struct
 
 		sg_count = pci_map_sg(dev->pdev, sg, scsicmd->use_sg,
 			scsicmd->sc_data_direction);
-		psg->count = cpu_to_le32(sg_count);
-
-		byte_count = 0;
 
 		for (i = 0; i < sg_count; i++) {
-			psg->sg[i].addr = cpu_to_le32(sg_dma_address(sg));
-			psg->sg[i].count = cpu_to_le32(sg_dma_len(sg));
-			byte_count += sg_dma_len(sg);
+			int count = sg_dma_len(sg);
+			u32 addr = sg_dma_address(sg);
+			if (host->max_sectors < AAC_MAX_32BIT_SGBCOUNT)
+			while (count > 65536) {
+				psg->sg[i].addr = cpu_to_le32(addr);
+				psg->sg[i].count = cpu_to_le32(65536);
+				++i;
+				if (++sg_count > host->sg_tablesize)
+					BUG();
+				byte_count += 65536;
+				addr += 65536;
+				count -= 65536;
+			}
+
+			psg->sg[i].addr = cpu_to_le32(addr);
+			psg->sg[i].count = cpu_to_le32(count);
+			byte_count += count;
 			sg++;
 		}
+		psg->count = cpu_to_le32(sg_count);
 		/* hba wants the size to be exact */
 		if(byte_count > scsicmd->request_bufflen){
 			psg->sg[i-1].count -= (byte_count - scsicmd->request_bufflen);
@@ -1524,15 +2162,27 @@ static unsigned long aac_build_sg(struct
 		}
 	}
 	else if(scsicmd->request_bufflen) {
-		dma_addr_t addr; 
-		addr = pci_map_single(dev->pdev,
+		int i, count;
+		u32 addr;
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
 				scsicmd->request_buffer,
 				scsicmd->request_bufflen,
 				scsicmd->sc_data_direction);
-		psg->count = cpu_to_le32(1);
-		psg->sg[0].addr = cpu_to_le32(addr);
-		psg->sg[0].count = cpu_to_le32(scsicmd->request_bufflen);  
-		scsicmd->SCp.ptr = (char *)(ulong)addr;
+		addr = scsicmd->SCp.dma_handle;
+		count = scsicmd->request_bufflen;  
+		i = 0;
+		if (host->max_sectors < AAC_MAX_32BIT_SGBCOUNT)
+		while (count > 65536) {
+			psg->sg[i].addr = cpu_to_le32(addr);
+			psg->sg[i].count = cpu_to_le32(65536);
+			if (++i >= host->sg_tablesize)
+				BUG();
+			addr += 65536;
+			count -= 65536;
+		}
+		psg->count = cpu_to_le32(1+i);
+		psg->sg[i].addr = cpu_to_le32(addr);
+		psg->sg[i].count = cpu_to_le32(count);
 		byte_count = scsicmd->request_bufflen;
 	}
 	return byte_count;
@@ -1541,16 +2191,15 @@ static unsigned long aac_build_sg(struct
 
 static unsigned long aac_build_sg64(struct scsi_cmnd* scsicmd, struct sgmap64* psg)
 {
-	struct aac_dev *dev;
+	struct Scsi_Host *host = scsicmd->device->host;
+	struct aac_dev *dev = (struct aac_dev *)host->hostdata;
 	unsigned long byte_count = 0;
-	u64 le_addr;
 
-	dev = (struct aac_dev *)scsicmd->device->host->hostdata;
 	// Get rid of old data
-	psg->count = cpu_to_le32(0);
-	psg->sg[0].addr[0] = cpu_to_le32(0);
-	psg->sg[0].addr[1] = cpu_to_le32(0);
-	psg->sg[0].count = cpu_to_le32(0);  
+	psg->count = 0;
+	psg->sg[0].addr[0] = 0;
+	psg->sg[0].addr[1] = 0;
+	psg->sg[0].count = 0;  
 	if (scsicmd->use_sg) {
 		struct scatterlist *sg;
 		int i;
@@ -1559,18 +2208,105 @@ static unsigned long aac_build_sg64(stru
 
 		sg_count = pci_map_sg(dev->pdev, sg, scsicmd->use_sg,
 			scsicmd->sc_data_direction);
+
+		for (i = 0; i < sg_count; i++) {
+			int count = sg_dma_len(sg);
+			u64 addr = sg_dma_address(sg);
+			if (host->max_sectors < AAC_MAX_32BIT_SGBCOUNT)
+			while (count > 65536) {
+				psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+				psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+				psg->sg[i].count = cpu_to_le32(65536);
+				++i;
+				if (++sg_count > host->sg_tablesize)
+					BUG();
+				byte_count += 65536;
+				addr += 65536;
+				count -= 65536;
+			}
+			psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+			psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+			psg->sg[i].count = cpu_to_le32(count);
+			byte_count += count;
+			sg++;
+		}
 		psg->count = cpu_to_le32(sg_count);
+		/* hba wants the size to be exact */
+		if(byte_count > scsicmd->request_bufflen){
+			psg->sg[i-1].count -= (byte_count - scsicmd->request_bufflen);
+			byte_count = scsicmd->request_bufflen;
+		}
+		/* Check for command underflow */
+		if(scsicmd->underflow && (byte_count < scsicmd->underflow)){
+			printk(KERN_WARNING"aacraid: cmd len %08lX cmd underflow %08X\n",
+					byte_count, scsicmd->underflow);
+		}
+	}
+	else if(scsicmd->request_bufflen) {
+		int i, count;
+		u64 addr;
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
+				scsicmd->request_buffer,
+				scsicmd->request_bufflen,
+				scsicmd->sc_data_direction);
+		addr = scsicmd->SCp.dma_handle;
+		count = scsicmd->request_bufflen;  
+		i = 0;
+		if (host->max_sectors < AAC_MAX_32BIT_SGBCOUNT)
+		while (count > 65536) {
+			psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+			psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+			psg->sg[i].count = cpu_to_le32(65536);
+			if (++i >= host->sg_tablesize)
+				BUG();
+			addr += 65536;
+			count -= 65536;
+		}
+		psg->count = cpu_to_le32(1+i);
+		psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+		psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+		psg->sg[i].count = cpu_to_le32(count);
+		byte_count = scsicmd->request_bufflen;
+	}
+	return byte_count;
+}
 
-		byte_count = 0;
+static unsigned long aac_build_sgraw(struct scsi_cmnd* scsicmd, struct sgmapraw* psg)
+{
+	struct Scsi_Host *host = scsicmd->device->host;
+	struct aac_dev *dev = (struct aac_dev *)host->hostdata;
+	unsigned long byte_count = 0;
+
+	// Get rid of old data
+	psg->count = 0;
+	psg->sg[0].next = 0;
+	psg->sg[0].prev = 0;
+	psg->sg[0].addr[0] = 0;
+	psg->sg[0].addr[1] = 0;
+	psg->sg[0].count = 0;
+	psg->sg[0].flags = 0;
+	if (scsicmd->use_sg) {
+		struct scatterlist *sg;
+		int i;
+		int sg_count;
+		sg = (struct scatterlist *) scsicmd->request_buffer;
+
+		sg_count = pci_map_sg(dev->pdev, sg, scsicmd->use_sg,
+			scsicmd->sc_data_direction);
 
 		for (i = 0; i < sg_count; i++) {
-			le_addr = cpu_to_le64(sg_dma_address(sg));
-			psg->sg[i].addr[1] = (u32)(le_addr>>32);
-			psg->sg[i].addr[0] = (u32)(le_addr & 0xffffffff);
-			psg->sg[i].count = cpu_to_le32(sg_dma_len(sg));
-			byte_count += sg_dma_len(sg);
+			int count = sg_dma_len(sg);
+			u64 addr = sg_dma_address(sg);
+			psg->sg[i].next = 0;
+			psg->sg[i].prev = 0;
+			psg->sg[i].addr[1] = cpu_to_le32((u32)(addr>>32));
+			psg->sg[i].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+			psg->sg[i].count = cpu_to_le32(count);
+			psg->sg[i].flags = 0;
+			byte_count += count;
 			sg++;
 		}
+		psg->count = cpu_to_le32(sg_count);
 		/* hba wants the size to be exact */
 		if(byte_count > scsicmd->request_bufflen){
 			psg->sg[i-1].count -= (byte_count - scsicmd->request_bufflen);
@@ -1583,17 +2319,21 @@ static unsigned long aac_build_sg64(stru
 		}
 	}
 	else if(scsicmd->request_bufflen) {
-		dma_addr_t addr; 
-		addr = pci_map_single(dev->pdev,
+		int count;
+		u64 addr;
+		scsicmd->SCp.dma_handle = pci_map_single(dev->pdev,
 				scsicmd->request_buffer,
 				scsicmd->request_bufflen,
 				scsicmd->sc_data_direction);
+		addr = scsicmd->SCp.dma_handle;
+		count = scsicmd->request_bufflen;
 		psg->count = cpu_to_le32(1);
-		le_addr = cpu_to_le64(addr);
-		psg->sg[0].addr[1] = (u32)(le_addr>>32);
-		psg->sg[0].addr[0] = (u32)(le_addr & 0xffffffff);
-		psg->sg[0].count = cpu_to_le32(scsicmd->request_bufflen);  
-		scsicmd->SCp.ptr = (char *)(ulong)addr;
+		psg->sg[0].next = 0;
+		psg->sg[0].prev = 0;
+		psg->sg[0].addr[1] = cpu_to_le32((u32)(addr>>32));
+		psg->sg[0].addr[0] = cpu_to_le32((u32)(addr & 0xffffffff));
+		psg->sg[0].count = cpu_to_le32(count);
+		psg->sg[0].flags = 0;
 		byte_count = scsicmd->request_bufflen;
 	}
 	return byte_count;
diff -urNp linux-2.6.8/drivers/scsi/aacraid/aacraid.h linux-2.6.8.SUSE/drivers/scsi/aacraid/aacraid.h
--- linux-2.6.8/drivers/scsi/aacraid/aacraid.h	2004-09-06 17:02:22.894098719 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/aacraid.h	2004-07-30 19:42:15.000000000 +0200
@@ -1,37 +1,52 @@
+//#define dprintk(x) printk x
 #if (!defined(dprintk))
 # define dprintk(x)
 #endif
+//#define AAC_DEBUG_INSTRUMENT_TIMING
 
+/* if (nblank(dprintk(x))) */
+#define _nblank(x) #x
+#define nblank(x) _nblank(x)[0]
+
+#include "compat.h"
 /*------------------------------------------------------------------------------
  *              D E F I N E S
  *----------------------------------------------------------------------------*/
 
+//#define AAC_EXTENDED_TIMEOUT	120
+
+#ifndef AAC_DRIVER_BUILD
+# define AAC_DRIVER_BUILD 2358
+#endif
 #define MAXIMUM_NUM_CONTAINERS	32
-#define MAXIMUM_NUM_ADAPTERS	8
+#define MAXIMUM_NUM_ADAPTERS	32
 
-#define AAC_NUM_FIB		(256 + 64)
-#define AAC_NUM_IO_FIB		100
+#define AAC_NUM_MGT_FIB		8
+#define AAC_NUM_IO_FIB		(512-AAC_NUM_MGT_FIB)
+#define AAC_NUM_FIB		(AAC_NUM_IO_FIB+AAC_NUM_MGT_FIB)
 
 #define AAC_MAX_LUN		(8)
 
 #define AAC_MAX_HOSTPHYSMEMPAGES (0xfffff)
+/*
+ *  max_sectors is an unsigned short, otherwise limit is 0x100000000 / 512
+ * Linux has starvation problems if we permit larger than 4MB I/O ...
+ */
+#define AAC_MAX_32BIT_SGBCOUNT	((unsigned short)8192)
 
 /*
  * These macros convert from physical channels to virtual channels
  */
-#define CONTAINER_CHANNEL		(0)
-#define ID_LUN_TO_CONTAINER(id, lun)	(id)
+#define CONTAINER_CHANNEL	(0)
+#define	ID_LUN_TO_CONTAINER(id, lun)	(id)
 #define CONTAINER_TO_CHANNEL(cont)	(CONTAINER_CHANNEL)
-#define CONTAINER_TO_ID(cont)		(cont)
+#define CONTAINER_TO_ID(cont)		((cont))
 #define CONTAINER_TO_LUN(cont)		(0)
-
 #define aac_phys_to_logical(x)  (x+1)
 #define aac_logical_to_phys(x)  (x?x-1:0)
 
-#define AAC_DETAILED_STATUS_INFO
-
-extern int nondasd;
-extern int paemode;
+/* #define AAC_DETAILED_STATUS_INFO */
+#define AAC_LM_SENSOR
 
 struct diskparm
 {
@@ -101,6 +116,14 @@ struct sgentry64 {
 	u32	count;	/* Length. */
 };
 
+struct sgentryraw {
+	u32		next;	/* reserved for F/W use */
+	u32		prev;	/* reserved for F/W use */
+	u32		addr[2];
+	u32		count;
+	u32		flags;	/* reserved for F/W use */
+};
+
 /*
  *	SGMAP
  *
@@ -118,6 +141,11 @@ struct sgmap64 {
 	struct sgentry64 sg[1];
 };
 
+struct sgmapraw {
+	u32		  count;
+	struct sgentryraw sg[1];
+};
+
 struct creation_info
 {
 	u8 		buildnum;		/* e.g., 588 */
@@ -258,11 +286,11 @@ enum aac_queue_types {
 #define		FsaNormal	1
 #define		FsaHigh		2
 
+
 /*
  * Define the FIB. The FIB is the where all the requested data and
  * command information are put to the application on the FSA adapter.
  */
-
 struct aac_fibhdr {
 	u32 XferState;			// Current transfer state for this CCB
 	u16 Command;			// Routing information for the destination
@@ -281,12 +309,9 @@ struct aac_fibhdr {
 	} _u;
 };
 
-#define FIB_DATA_SIZE_IN_BYTES (512 - sizeof(struct aac_fibhdr))
-
-
 struct hw_fib {
 	struct aac_fibhdr header;
-	u8 data[FIB_DATA_SIZE_IN_BYTES];		// Command specific data
+	u8 data[512-sizeof(struct aac_fibhdr)];	// Command specific data
 };
 
 /*
@@ -330,6 +355,7 @@ struct hw_fib {
  */
 #define		ContainerCommand		500
 #define		ContainerCommand64		501
+#define		ContainerRawIo			502
 /*
  *	Cluster Commands
  */
@@ -350,9 +376,9 @@ struct hw_fib {
 #define		SendHostTime			705
 #define		LastMiscCommand			706
 
-//
-// Commands that will target the failover level on the FSA adapter
-//
+/*
+ * Commands that will target the failover level on the FSA adapter
+ */
 
 enum fib_xfer_state {
 	HostOwned 			= (1<<0),
@@ -385,6 +411,7 @@ enum fib_xfer_state {
  */
 
 #define ADAPTER_INIT_STRUCT_REVISION		3
+#define ADAPTER_INIT_STRUCT_REVISION_4		4 // rocket science
 
 struct aac_init
 {
@@ -401,33 +428,39 @@ struct aac_init
 	u32	printfbufsiz;
 	u32	HostPhysMemPages;		// number of 4k pages of host physical memory
 	u32	HostElapsedSeconds;		// number of seconds since 1970.
+	// ADAPTER_INIT_STRUCT_REVISION_4 begins here
+	u32	InitFlags;			// flags for supported features
+#	define INITFLAGS_NEW_COMM_SUPPORTED	0x00000001
+	u32	MaxIoCommands;			// max outstanding commands
+	u32	MaxIoSize;			// largest I/O command
+	u32	MaxFibSize;			// largest FIB to adapter
 };
 
 enum aac_log_level {
-	LOG_AAC_INIT			= 10,
-	LOG_AAC_INFORMATIONAL		= 20,
-	LOG_AAC_WARNING			= 30,
-	LOG_AAC_LOW_ERROR		= 40,
-	LOG_AAC_MEDIUM_ERROR		= 50,
-	LOG_AAC_HIGH_ERROR		= 60,
-	LOG_AAC_PANIC			= 70,
-	LOG_AAC_DEBUG			= 80,
-	LOG_AAC_WINDBG_PRINT		= 90
+	AAC_LOG_INIT			= 10,
+	AAC_LOG_INFORMATIONAL		= 20,
+	AAC_LOG_WARNING			= 30,
+	AAC_LOG_LOW_ERROR		= 40,
+	AAC_LOG_MEDIUM_ERROR		= 50,
+	AAC_LOG_HIGH_ERROR		= 60,
+	AAC_LOG_PANIC			= 70,
+	AAC_LOG_DEBUG			= 80,
+	AAC_LOG_WINDBG_PRINT		= 90
 };
 
 #define FSAFS_NTC_GET_ADAPTER_FIB_CONTEXT	0x030b
 #define FSAFS_NTC_FIB_CONTEXT			0x030c
 
 struct aac_dev;
+struct fib;
 
 struct adapter_ops
 {
 	void (*adapter_interrupt)(struct aac_dev *dev);
 	void (*adapter_notify)(struct aac_dev *dev, u32 event);
-	void (*adapter_enable_int)(struct aac_dev *dev, u32 event);
-	void (*adapter_disable_int)(struct aac_dev *dev, u32 event);
-	int  (*adapter_sync_cmd)(struct aac_dev *dev, u32 command, u32 p1, u32 *status);
+	int  (*adapter_sync_cmd)(struct aac_dev *dev, u32 command, u32 p1, u32 p2, u32 p3, u32 p4, u32 p5, u32 p6, u32 p7, u32 *status, u32 *r1, u32 *r2, u32 *r3, u32 *r4);
 	int  (*adapter_check_health)(struct aac_dev *dev);
+	int  (*adapter_send)(struct fib * fib);
 };
 
 /*
@@ -462,22 +495,20 @@ struct aac_driver_ident
  */
  
 struct aac_queue {
-	u64		 	logical;	/*address we give the adapter */
-	struct aac_entry	*base;		/*system virtual address */
-	struct aac_qhdr 	headers;       	/*producer,consumer q headers*/
-	u32	 		entries;	/*Number of queue entries */
-	wait_queue_head_t	qfull;		/*Event to wait on if q full */
-	wait_queue_head_t	cmdready;	/*Cmd ready from the adapter */
-                  /* This is only valid for adapter to host command queues. */ 
-	spinlock_t	 	*lock;		/* Spinlock for this queue must take this lock before accessing the lock */
-	spinlock_t		lockdata;	/* Actual lock (used only on one side of the lock) */
-	unsigned long		SavedIrql;     	/* Previous IRQL when the spin lock is taken */
-	u32			padding;	/* Padding - FIXME - can remove I believe */
-	struct list_head 	cmdq;	   	/* A queue of FIBs which need to be prcessed by the FS thread. This is */
-                                		/* only valid for command queues which receive entries from the adapter. */
-	struct list_head	pendingq;	/* A queue of outstanding fib's to the adapter. */
-	u32			numpending;	/* Number of entries on outstanding queue. */
-	struct aac_dev *	dev;		/* Back pointer to adapter structure */
+	u64		 	logical;		/* This is the address we give the adapter */
+	struct aac_entry	*base;		   	/* This is the system virtual address */
+	struct aac_qhdr 	headers;       		/* A pointer to the producer and consumer queue headers for this queue */
+	u32	 		entries;	   	/* Number of queue entries on this queue */
+	wait_queue_head_t	qfull;		      	/* Event to wait on if the queue is full */
+	wait_queue_head_t	cmdready;	  	/* Indicates there is a Command ready from the adapter on this queue. */
+                                        		/* This is only valid for adapter to host command queues. */                      
+	spinlock_t	 	*lock;		     	/* Spinlock for this queue must take this lock before accessing the lock */
+	spinlock_t		lockdata;		/* Actual lock (used only on one side of the lock) */
+	struct list_head 	cmdq;		   	/* A queue of FIBs which need to be processed by the FS thread. This is */
+                                		        /* only valid for command queues which receive entries from the adapter. */
+	struct list_head	pendingq;		/* A queue of outstanding fib's to the adapter. */
+	unsigned long		numpending;		/* Number of entries on outstanding queue. */
+	struct aac_dev *	dev;			/* Back pointer to adapter structure */
 };
 
 /*
@@ -537,6 +568,7 @@ struct sa_drawbridge_CSR {
 #define Mailbox3	SaDbCSR.MAILBOX3
 #define Mailbox4	SaDbCSR.MAILBOX4
 #define Mailbox5	SaDbCSR.MAILBOX5
+#define Mailbox6	SaDbCSR.MAILBOX6
 #define Mailbox7	SaDbCSR.MAILBOX7
 	
 #define DoorbellReg_p SaDbCSR.PRISETIRQ
@@ -587,6 +619,10 @@ struct rx_mu_registers {
 	u32	ODR;				//	132Ch	|	2Ch	|	Outbound Doorbell Register
 	u32	OISR;				//	1330h	|	30h	|	Outbound Interrupt Status Register
 	u32	OIMR;				//	1334h	|	34h	|	Outbound Interrupt Mask Register
+	u32	reserved2;			//	1338h	|	38h	|	Reserved
+	u32	reserved3;			//	133Ch	|	3Ch	|	Reserved
+	u32	InboundQueue;			//	1340h	|	40h	|	Inbound Queue Port relative to firmware
+	u32	OutboundQueue;			//	1344h	|	44h	|	Outbound Queue Port relative to firmware
 						// * Must access through ATU Inbound Translation Window
 };
 
@@ -599,9 +635,11 @@ struct rx_inbound {
 #define	InboundMailbox2		IndexRegs.Mailbox[2]
 #define	InboundMailbox3		IndexRegs.Mailbox[3]
 #define	InboundMailbox4		IndexRegs.Mailbox[4]
+#ifdef AAC_LM_SENSOR
 #define	InboundMailbox5		IndexRegs.Mailbox[5]
 #define	InboundMailbox6		IndexRegs.Mailbox[6]
 #define	InboundMailbox7		IndexRegs.Mailbox[7]
+#endif
 
 #define	INBOUNDDOORBELL_0	cpu_to_le32(0x00000001)
 #define INBOUNDDOORBELL_1	cpu_to_le32(0x00000002)
@@ -621,8 +659,8 @@ struct rx_inbound {
 #define OutboundDoorbellReg	MUnit.ODR
 
 struct rx_registers {
-	struct rx_mu_registers		MUnit;		// 1300h - 1334h
-	u32				reserved1[6];	// 1338h - 134ch
+	struct rx_mu_registers		MUnit;		// 1300h - 1344h
+	u32				reserved1[2];	// 1348h - 134ch
 	struct rx_inbound		IndexRegs;
 };
 
@@ -639,8 +677,8 @@ struct rx_registers {
 #define rkt_inbound rx_inbound
 
 struct rkt_registers {
-	struct rkt_mu_registers		MUnit;		 /* 1300h - 1334h */
-	u32				reserved1[1010]; /* 1338h - 22fch */
+	struct rkt_mu_registers		MUnit;		 /* 1300h - 1344h */
+	u32				reserved1[1006]; /* 1348h - 22fch */
 	struct rkt_inbound		IndexRegs;	 /* 2300h - */
 };
 
@@ -649,8 +687,6 @@ struct rkt_registers {
 #define rkt_writeb(AEP, CSR, value)	writeb(value, &((AEP)->regs.rkt->CSR))
 #define rkt_writel(AEP, CSR, value)	writel(value, &((AEP)->regs.rkt->CSR))
 
-struct fib;
-
 typedef void (*fib_callback)(void *ctxt, struct fib *fibctx);
 
 struct aac_fib_context {
@@ -662,17 +698,56 @@ struct aac_fib_context {
 	struct semaphore 	wait_sem;	// this is used to wait for the next fib to arrive.
 	int			wait;		// Set to true when thread is in WaitForSingleObject
 	unsigned long		count;		// total number of FIBs on FibList
-	struct list_head	fib_list;	// this holds fibs and their attachd hw_fibs
+	struct list_head	fib_list;	// this holds fibs which should be 32 bit addresses
 };
 
-struct fsa_scsi_hba {
-	u32		size[MAXIMUM_NUM_CONTAINERS];
-	u32		type[MAXIMUM_NUM_CONTAINERS];
-	u8		valid[MAXIMUM_NUM_CONTAINERS];
-	u8		ro[MAXIMUM_NUM_CONTAINERS];
-	u8		locked[MAXIMUM_NUM_CONTAINERS];
-	u8		deleted[MAXIMUM_NUM_CONTAINERS];
-	char		devname[MAXIMUM_NUM_CONTAINERS][8];
+struct sense_data {
+	u8 error_code;		/* 70h (current errors), 71h(deferred errors) */
+	u8 valid:1;		/* A valid bit of one indicates that the information  */
+				/* field contains valid information as defined in the
+				 * SCSI-2 Standard.
+				 */
+	u8 segment_number;	/* Only used for COPY, COMPARE, or COPY AND VERIFY Commands */
+	u8 sense_key:4;		/* Sense Key */
+	u8 reserved:1;
+	u8 ILI:1;		/* Incorrect Length Indicator */
+	u8 EOM:1;		/* End Of Medium - reserved for random access devices */
+	u8 filemark:1;		/* Filemark - reserved for random access devices */
+
+	u8 information[4];	/* for direct-access devices, contains the unsigned 
+				 * logical block address or residue associated with 
+				 * the sense key 
+				 */
+	u8 add_sense_len;	/* number of additional sense bytes to follow this field */
+	u8 cmnd_info[4];	/* not used */
+	u8 ASC;			/* Additional Sense Code */
+	u8 ASCQ;		/* Additional Sense Code Qualifier */
+	u8 FRUC;		/* Field Replaceable Unit Code - not used */
+	u8 bit_ptr:3;		/* indicates which byte of the CDB or parameter data
+				 * was in error
+				 */
+	u8 BPV:1;		/* bit pointer valid (BPV): 1- indicates that 
+				 * the bit_ptr field has valid value
+				 */
+	u8 reserved2:2;
+	u8 CD:1;		/* command data bit: 1- illegal parameter in CDB.
+				 * 0- illegal parameter in data.
+				 */
+	u8 SKSV:1;
+	u8 field_ptr[2];	/* byte of the CDB or parameter data in error */
+};
+
+struct fsa_dev_info {
+	u64		last;
+	u64		size;
+	u32		type;
+	u16		queue_depth;
+	u8		valid;
+	u8		ro;
+	u8		locked;
+	u8		deleted;
+	char		devname[8];
+	struct sense_data sense_data;
 };
 
 struct fib {
@@ -699,6 +774,7 @@ struct fib {
 	 *	Outstanding I/O queue.
 	 */
 	struct list_head	queue;
+
 	/*
 	 *	And for the internal issue/reply queues (we may be able
 	 *	to merge these two)
@@ -758,19 +834,24 @@ struct aac_adapter_info
 /*
  * Supported Options
  */
-#define AAC_OPT_SNAPSHOT		cpu_to_le32(1)
-#define AAC_OPT_CLUSTERS		cpu_to_le32(1<<1)
-#define AAC_OPT_WRITE_CACHE		cpu_to_le32(1<<2)
-#define AAC_OPT_64BIT_DATA		cpu_to_le32(1<<3)
-#define AAC_OPT_HOST_TIME_FIB		cpu_to_le32(1<<4)
-#define AAC_OPT_RAID50			cpu_to_le32(1<<5)
-#define AAC_OPT_4GB_WINDOW		cpu_to_le32(1<<6)
-#define AAC_OPT_SCSI_UPGRADEABLE 	cpu_to_le32(1<<7)
-#define AAC_OPT_SOFT_ERR_REPORT		cpu_to_le32(1<<8)
-#define AAC_OPT_SUPPORTED_RECONDITION 	cpu_to_le32(1<<9)
-#define AAC_OPT_SGMAP_HOST64		cpu_to_le32(1<<10)
-#define AAC_OPT_ALARM			cpu_to_le32(1<<11)
-#define AAC_OPT_NONDASD			cpu_to_le32(1<<12)
+#define AAC_OPT_SNAPSHOT	cpu_to_le32(1)
+#define AAC_OPT_CLUSTERS	cpu_to_le32(1<<1)
+#define AAC_OPT_WRITE_CACHE	cpu_to_le32(1<<2)
+#define AAC_OPT_64BIT_DATA	cpu_to_le32(1<<3)
+#define AAC_OPT_HOST_TIME_FIB	cpu_to_le32(1<<4)
+#define AAC_OPT_RAID50		cpu_to_le32(1<<5)
+#define AAC_OPT_4GB_WINDOW	cpu_to_le32(1<<6)
+#define AAC_OPT_SCSI_UPGRADEABLE cpu_to_le32(1<<7)
+#define AAC_OPT_SOFT_ERR_REPORT	cpu_to_le32(1<<8)
+#define AAC_OPT_SUPPORTED_RECONDITION cpu_to_le32(1<<9)
+#define AAC_OPT_SGMAP_HOST64	cpu_to_le32(1<<10)
+#define AAC_OPT_ALARM		cpu_to_le32(1<<11)
+#define AAC_OPT_NONDASD		cpu_to_le32(1<<12)
+#define AAC_OPT_SCSI_MANAGED    cpu_to_le32(1<<13)
+#define AAC_OPT_RAID_SCSI_MODE	cpu_to_le32(1<<14)
+#define AAC_OPT_SUPPLEMENT_ADAPTER_INFO	cpu_to_le32(1<<16)
+#define AAC_OPT_NEW_COMM	cpu_to_le32(1<<17)
+#define AAC_OPT_NEW_COMM_64	cpu_to_le32(1<<18)
 
 struct aac_dev
 {
@@ -778,7 +859,12 @@ struct aac_dev
 	const char		*name;
 	int			id;
 
-	u16			irq_mask;
+	/*
+	 *	negotiated FIB settings
+	 */
+	unsigned		max_fib_size;
+	unsigned		sg_tablesize;
+
 	/*
 	 *	Map for 128 fib objects (64k)
 	 */	
@@ -817,13 +903,17 @@ struct aac_dev
 	size_t			comm_size;
 
 	struct Scsi_Host	*scsi_host_ptr;
-	struct fsa_scsi_hba	fsa_dev;
+	int			maximum_num_containers;
+	struct fsa_dev_info	*fsa_dev;
 	pid_t			thread_pid;
 	int			cardtype;
 	
 	/*
 	 *	The following is the device specific extension.
 	 */
+#if (!defined(AAC_MIN_FOOTPRINT_SIZE))
+#	define AAC_MIN_FOOTPRINT_SIZE 8192
+#endif
 	union
 	{
 		struct sa_registers *sa;
@@ -832,39 +922,41 @@ struct aac_dev
 	} regs;
 	u32			OIMR; /* Mask Register Cache */
 	/*
-	 *	AIF thread states
+	 *	AIF thread states.
 	 */
 	u32			aif_thread;
 	struct completion	aif_completion;
 	struct aac_adapter_info adapter_info;
+	u32			DeviceContainerID;
+	u32			DeviceConfigWaitingOn;
+	int			DeviceConfigNeeded;
 	/* These are in adapter info but they are in the io flow so
 	 * lets break them out so we don't have to do an AND to check them
 	 */
 	u8			nondasd_support; 
-	u8			pae_support;
+	u8			dac_support;
+	u8			raid_scsi_mode;
+	u8			new_comm_interface;
+	/* macro side-effects BEWARE */
+#	define			raw_io_interface \
+	  init->InitStructRevision==cpu_to_le32(ADAPTER_INIT_STRUCT_REVISION_4)
+	u8			raw_io_64;
 };
 
-#define AllocateAndMapFibSpace(dev, MapFibContext) \
-	(dev)->a_ops.AllocateAndMapFibSpace(dev, MapFibContext)
-
-#define UnmapAndFreeFibSpace(dev, MapFibContext) \
-	(dev)->a_ops.UnmapAndFreeFibSpace(dev, MapFibContext)
-
 #define aac_adapter_interrupt(dev) \
 	(dev)->a_ops.adapter_interrupt(dev)
 
 #define aac_adapter_notify(dev, event) \
 	(dev)->a_ops.adapter_notify(dev, event)
 
-#define aac_adapter_enable_int(dev, event) \
-	(dev)->a_ops.adapter_enable_int(dev, event)
-
-#define aac_adapter_disable_int(dev, event) \
-	dev->a_ops.adapter_disable_int(dev, event)
+#define aac_adapter_sync_cmd(dev, command, p1, p2, p3, p4, p5, p6, p7, status, r1, r2, r3, r4) \
+	(dev)->a_ops.adapter_sync_cmd(dev, command, p1, p2, p3, p4, p5, p6, p7, status, r1, r2, r3, r4)
 
 #define aac_adapter_check_health(dev) \
 	(dev)->a_ops.adapter_check_health(dev)
 
+#define aac_adapter_send(fib) \
+	((fib)->dev)->a_ops.adapter_send(fib)
 
 #define FIB_CONTEXT_FLAG_TIMED_OUT		(0x00000001)
 
@@ -1018,6 +1110,7 @@ struct aac_write64
 	u16		flags;
 	struct sgmap64	sg;	// Must be last in struct because it is variable
 };
+
 struct aac_write_reply
 {
 	u32		status;
@@ -1025,6 +1118,41 @@ struct aac_write_reply
 	u32		committed;
 };
 
+struct aac_raw_io
+{
+	u32		block[2];
+	u32		count;
+	u16		cid;
+	u16		flags;		/* 00 W, 01 R */
+	u16		bpTotal;	/* reserved for F/W use */
+	u16		bpComplete;	/* reserved for F/W use */
+	struct sgmapraw	sg;
+};
+	
+#define CT_FLUSH_CACHE 129
+struct aac_synchronize {
+	u32		command;	/* VM_ContainerConfig */
+	u32		type;		/* CT_FLUSH_CACHE */
+	u32		cid;
+	u32		parm1;
+	u32		parm2;
+	u32		parm3;
+	u32		parm4;
+	u32		count;	/* sizeof(((struct aac_synchronize_reply *)NULL)->data) */
+};
+
+struct aac_synchronize_reply {
+	u32		dummy0;
+	u32		dummy1;
+	u32		status;	/* CT_OK */
+	u32		parm1;
+	u32		parm2;
+	u32		parm3;
+	u32		parm4;
+	u32		parm5;
+	u8		data[16];
+};
+
 struct aac_srb
 {
 	u32		function;
@@ -1172,6 +1300,70 @@ union aac_contentinfo {
 };
 
 /*
+ *	Query for Container Configuration Status
+ */
+
+#define CT_GET_CONFIG_STATUS 147
+struct aac_get_config_status {
+	u32		command;	/* VM_ContainerConfig */
+	u32		type;		/* CT_GET_CONFIG_STATUS */
+	u32		parm1;
+	u32		parm2;
+	u32		parm3;
+	u32		parm4;
+	u32		parm5;
+	u32		count;	/* sizeof(((struct aac_get_config_status_resp *)NULL)->data) */
+};
+
+#define CFACT_CONTINUE 0
+#define CFACT_PAUSE    1
+#define CFACT_ABORT    2
+struct aac_get_config_status_resp {
+	u32		response; /* ST_OK */
+	u32		dummy0;
+	u32		status;	/* CT_OK */
+	u32		parm1;
+	u32		parm2;
+	u32		parm3;
+	u32		parm4;
+	u32		parm5;
+	struct {
+		u32	action; /* CFACT_CONTINUE, CFACT_PAUSE or CFACT_ABORT */
+		u16	flags;
+		s16	count;
+	}		data;
+};
+
+/*
+ *	Accept the configuration as-is
+ */
+
+#define CT_COMMIT_CONFIG 152
+
+struct aac_commit_config {
+	u32		command;	/* VM_ContainerConfig */
+	u32		type;		/* CT_COMMIT_CONFIG */
+};
+
+/*
+ *	Query for Container Configuration Status
+ */
+
+#define CT_GET_CONTAINER_COUNT 4
+struct aac_get_container_count {
+	u32		command;	/* VM_ContainerConfig */
+	u32		type;		/* CT_GET_CONTAINER_COUNT */
+};
+
+struct aac_get_container_count_resp {
+	u32		response; /* ST_OK */
+	u32		dummy0;
+	u32		MaxContainers;
+	u32		ContainerSwitchEntries;
+	u32		MaxPartitions;
+};
+
+/*
  *	Query for "mountable" objects, ie, objects that are typically
  *	associated with a drive letter on the client (host) side.
  */
@@ -1205,6 +1397,31 @@ struct aac_mount {
 	struct aac_mntent mnt[1];
 };
 
+#define CT_READ_NAME 130
+struct aac_get_name {
+	u32		command;	/* VM_ContainerConfig */
+	u32		type;		/* CT_READ_NAME */
+	u32		cid;
+	u32		parm1;
+	u32		parm2;
+	u32		parm3;
+	u32		parm4;
+	u32		count;	/* sizeof(((struct aac_get_name_resp *)NULL)->data) */
+};
+
+#define CT_OK        218
+struct aac_get_name_resp {
+	u32		dummy0;
+	u32		dummy1;
+	u32		status;	/* CT_OK */
+	u32		parm1;
+	u32		parm2;
+	u32		parm3;
+	u32		parm4;
+	u32		parm5;
+	u8		data[16];
+};
+
 /*
  * The following command is sent to shut down each container.
  */
@@ -1232,12 +1449,12 @@ struct aac_delete_disk {
 	u32	disknum;
 	u32	cnum;
 };
- 
+
 struct fib_ioctl
 {
 	u32	fibctx;
 	s32	wait;
-	char	__user *fib;
+	char *	fib;
 };
 
 struct revision
@@ -1277,6 +1494,7 @@ struct revision
 #define FSACTL_MINIPORT_REV_CHECK               CTL_CODE(2107, METHOD_BUFFERED)
 #define FSACTL_GET_PCI_INFO               	CTL_CODE(2119, METHOD_BUFFERED)
 #define FSACTL_FORCE_DELETE_DISK		CTL_CODE(2120, METHOD_NEITHER)
+#define FSACTL_REGISTER_FIB_SEND		CTL_CODE(2136, METHOD_BUFFERED)
 #define FSACTL_GET_CONTAINERS			2131
 
 
@@ -1313,7 +1531,7 @@ extern struct aac_common aac_config;
  *	only used for debugging.
  */
  
-#ifdef DBG
+#if DBG
 #define	FIB_COUNTER_INCREMENT(counter)		(counter)++
 #else
 #define	FIB_COUNTER_INCREMENT(counter)		
@@ -1330,8 +1548,10 @@ extern struct aac_common aac_config;
 #define WRITE_PERMANENT_PARAMETERS	cpu_to_le32(0x0000000b)
 #define HOST_CRASHING			cpu_to_le32(0x0000000d)
 #define	SEND_SYNCHRONOUS_FIB		cpu_to_le32(0x0000000c)
-#define	COMMAND_POST_RESULTS		cpu_to_le32(0x00000014)
+#define COMMAND_POST_RESULTS		cpu_to_le32(0x00000014)
 #define GET_ADAPTER_PROPERTIES		cpu_to_le32(0x00000019)
+#define RCV_TEMP_READINGS		cpu_to_le32(0x00000025)
+#define GET_COMM_PREFERRED_SETTINGS	cpu_to_le32(0x00000026)
 #define RE_INIT_ADAPTER			cpu_to_le32(0x000000ee)
 
 /*
@@ -1355,10 +1575,10 @@ extern struct aac_common aac_config;
  *	Phases are bit oriented.  It is NOT valid  to have multiple bits set						
  */					
 
-#define	SELF_TEST_FAILED		(cpu_to_le32(0x00000004))
-#define MONITOR_PANIC			(cpu_to_le32(0x00000020))
-#define	KERNEL_UP_AND_RUNNING		(cpu_to_le32(0x00000080))
-#define	KERNEL_PANIC			(cpu_to_le32(0x00000100))
+#define	SELF_TEST_FAILED		cpu_to_le32(0x00000004)
+#define	MONITOR_PANIC			cpu_to_le32(0x00000020)
+#define	KERNEL_UP_AND_RUNNING		cpu_to_le32(0x00000080)
+#define	KERNEL_PANIC			cpu_to_le32(0x00000100)
 
 /*
  *	Doorbell bit defines
@@ -1378,22 +1598,21 @@ extern struct aac_common aac_config;
  */
  
 #define 	AifCmdEventNotify	1	/* Notify of event */
-#define			AifEnConfigChange	3	/* Adapter configuration change */
-#define			AifEnContainerChange	4	/* Container configuration change */
-#define			AifEnDeviceFailure	5	/* SCSI device failed */
-#define			AifEnAddContainer	15	/* A new array was created */
-#define			AifEnDeleteContainer	16	/* A container was deleted */
-#define			AifEnExpEvent		23	/* Firmware Event Log */
-#define			AifExeFirmwarePanic	3	/* Firmware Event Panic */
-#define			AifHighPriority		3	/* Highest Priority Event */
-
+#define		AifEnConfigChange	3	/* Adapter configuration change */
+#define		AifEnContainerChange	4	/* Container configuration change */
+#define		AifEnDeviceFailure	5	/* SCSI device failed */
+#define		AifEnAddContainer	15	/* A new array was created. */
+#define		AifEnDeleteContainer	16	/* A container was deleted. */
+#define		AifEnExpEvent		23	/* Firmware Event Log */
+#define		AifExeFirmwarePanic	3	/* Firmware Event Panic */
+#define		AifHighPriority		3	/* Highest Priority Event */
 #define		AifCmdJobProgress	2	/* Progress report */
-#define			AifJobCtrZero	101	/* Array Zero progress */
-#define			AifJobStsSuccess 1	/* Job completes */
+#define		AifJobCtrZero		101	/* Array Zero progress */
+#define		AifJobStsSuccess	1	/* Job completes successfully */
 #define		AifCmdAPIReport		3	/* Report from other user of API */
 #define		AifCmdDriverNotify	4	/* Notify host driver of event */
-#define			AifDenMorphComplete 200	/* A morph operation completed */
-#define			AifDenVolumeExtendComplete 201 /* A volume extend completed */
+#define		AifDenMorphComplete	200	/* A morph operation completed */
+#define		AifDenVolumeExtendComplete 201  /* A volume expand operation completed */
 #define		AifReqJobList		100	/* Gets back complete job list */
 #define		AifReqJobsForCtr	101	/* Gets back jobs for specific container */
 #define		AifReqJobsForScsi	102	/* Gets back jobs for specific SCSI device */ 
@@ -1439,22 +1658,25 @@ void fib_free(struct fib * context);
 void fib_init(struct fib * context);
 void fib_dealloc(struct fib * context);
 void aac_printf(struct aac_dev *dev, u32 val);
-int fib_send(u16 command, struct fib * context, unsigned long size, int priority, int wait, int reply, fib_callback callback, void *ctxt);
+#define aac_fib_send fib_send
+int aac_fib_send(u16 command, struct fib * context, unsigned long size, int priority, int wait, int reply, fib_callback callback, void *ctxt);
 int aac_consumer_get(struct aac_dev * dev, struct aac_queue * q, struct aac_entry **entry);
 int aac_consumer_avail(struct aac_dev * dev, struct aac_queue * q);
 void aac_consumer_free(struct aac_dev * dev, struct aac_queue * q, u32 qnum);
 int fib_complete(struct fib * context);
 #define fib_data(fibctx) ((void *)(fibctx)->hw_fib->data)
 struct aac_dev *aac_init_adapter(struct aac_dev *dev);
+int aac_get_config_status(struct aac_dev *dev);
 int aac_get_containers(struct aac_dev *dev);
 int aac_scsi_cmd(struct scsi_cmnd *cmd);
-int aac_dev_ioctl(struct aac_dev *dev, int cmd, void __user *arg);
-int aac_do_ioctl(struct aac_dev * dev, int cmd, void __user *arg);
+int aac_dev_ioctl(struct aac_dev *dev, int cmd, void *arg);
+int aac_do_ioctl(struct aac_dev * dev, int cmd, void *arg);
 int aac_rx_init(struct aac_dev *dev);
 int aac_rkt_init(struct aac_dev *dev);
 int aac_sa_init(struct aac_dev *dev);
 unsigned int aac_response_normal(struct aac_queue * q);
 unsigned int aac_command_normal(struct aac_queue * q);
+unsigned int aac_intr_normal(struct aac_dev * dev, u32 Index);
 int aac_command_thread(struct aac_dev * dev);
 int aac_close_fib_context(struct aac_dev * dev, struct aac_fib_context *fibctx);
 int fib_adapter_complete(struct fib * fibptr, unsigned short size);
diff -urNp linux-2.6.8/drivers/scsi/aacraid/CHANGELOG linux-2.6.8.SUSE/drivers/scsi/aacraid/CHANGELOG
--- linux-2.6.8/drivers/scsi/aacraid/CHANGELOG	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/CHANGELOG	2004-07-30 19:42:13.000000000 +0200
@@ -0,0 +1,1176 @@
+Version: 0.9.10
+
+Version: 1.1.2
+
+2003-05-15	Mark_Salyzyn@adaptec.com
+
+Differences between 2.4.21-rc2-ac2 kernel and our 1.1.2 versioned driver,
+changes as performed by Deanna Bonds, Bob Pasteur and Mark Salyzyn.
+
+aachba.c:
+	- If the state of a logical unit is hidden, then do not report. This
+	  state is typically entered when a device is being cleared.
+	- Added support for the Tallahassee project, where one channel is
+	  dedicated to SCSI, and the other channel is dedicated to RAID.
+	- Resolved some issues surrounding PAE support and IA64.
+	- If the driver is a not a boot disk driver, then set the Removable
+	  bit on the inquiry strings returned by the logical units to ensure
+	  that any changes in the arrays will be acquired when the device is
+	  re-attached.
+	- mask the SRB status with 0x3F to deal with misbehaving devices.
+	- Do not report DISKs to inquiry requests on the SCSI bus except if
+	  the channel is designated as a SCSI only bus.
+	- Propagate check conditions to the SCSI command result.
+	- Add support for programmable timeouts to propagate down toe the
+	  requests.
+	- If we have pae mode enabled, right after we get the adapter
+	  information and determine the pae mode capability, we enable the
+	  system to issue 64 bit requests.
+aacraid.h:
+	- Had to drop from 512 commands to 100 commands because some versions
+	  of the firmware would starve commands causing a timeout reaction
+	  which lead to lost commands.
+	- Added a global control variable for nondasd and paemode support.
+	- Dealt with some 64 bit / 32 bit issues in list_head structures and
+	  helper Macros, replacing them with our own more sensitive variants.
+	- Differentiated virtual and physical references to the shared fib
+	  allocations.
+	- information structure not synchronized to firmware, needed to add
+	  a clusterchannelmask.
+	- Added definitions in support of the new configuration information
+	  page bits in support of Tallahassee.
+	- Changed to an allocated fib pool, rather than an array in the hba
+	  structure as this affected the SCSI memory pool.
+	- Added some AIF definitions to permit us to sniff for container
+	  changes to permit a rescan to pick up new information or targets.
+commctrl.c:
+	- The fib reference was changed to a physical and a virtual address,
+	  absorb the name changes.
+	- The list_head structure handlers have been replaced with our own,
+	  absorb the name changes.
+	- The fib address reported in an AIF is a physical (32 bit) reference,
+	  and not a virtual (possibly 64 bit) reference.
+	- added the ioctl handling for sending a raw srb (FSACTL_SEND_RAW_SRB).
+comminit.c:
+	- Deal with IA64 issues.
+	- Change to using the physical address (32 bit) for the AIF references.
+	- The list_head structure handlers have been replaced with our own,
+	  absorb the name changes.
+	- Observed a memory leak, free up the queue resources should we fail
+	  to initialize the adapter.
+commsup.c:
+	- The fib reference was changed to a physical and a virtual address,
+	  absorb the name changes.
+	- Instead of panicking the kernel when a fib allocation was available,
+	  sleep until it is available.
+	- Submitted fib pointers are physical (32 bit) rather than virtual
+	  (possibly 64 bit) values.
+	- producer and consumer indexes should be converted over to local
+	  cpu endian before comparison.
+	- aac_handle_aif now sniffs AIF events and takes plug and play action
+	  for container changes.
+	- The aif thread is set up to be a kernel thread, and not a user
+	  thread. This permits us the ability to make plug and play calls
+	  without prejudice.
+	- Added instrumentation to the aif thread to confirm the plug and
+	  play activity and as an aid to several other debug sessions.
+	- Do not age an aif context based on the last received aif, but rather
+	  the last poll.
+dpcsup.c:
+	- The fib reference was changed to a physical and a virtual address,
+	  absorb the name changes.
+	- Submitted fib pointers are physical (32 bit) rather than virtual
+	  (possibly 64 bit) values.
+linit.c:
+	- Added paemode control.
+	- Added various upcoming board products, and documented better the
+	  existing board product ids. This includes SATA RAID products.
+	- needed to take the io_request_lock during portions of initialization.
+	- allocate the fib resource separately, rather than part of adapter
+	  structure to aid in the precious SCSI resources.
+	- cleanup of none dasd support options.
+	- Added more details about the build date of the driver to the proc
+	  information.
+	- dropped a change that permitted 64 bit DMA resources to be generated
+	  instead of through a 32 bit bounce buffer. (it was moved to aachba.c
+	  where it can be turned on after we determine the adapter's
+	  capabilities).
+	- max_id, max_lun and max_channel parameters are set after the
+	  adapter information has been picked up (the number of channels is
+	  based on the product id table now).
+sa.c:
+	- Context of timeout handling was incorrect, only noticed in IA64
+	  bit machines (due to lack of BIOS initialization).
+
+Differences that need further investigation and could be viewed as regressions
+and added after submission:
+
+rx.c:
+	- Dropped detection of failure to generate kernel command thread.
+sa.c:
+	- Dropped detection of failure to generate kernel command thread.
+
+Version: 1.1.3
+
+2003-07-01	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Added aac_get_container_name to permit override of array inquiry
+	  string with the set name.
+
+2003-07-08	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Return 0 (success) for unsupported commands, the check condition
+	  should perform the necessary action of error handling.
+
+2003-07-10	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- The pass-through SCSI SCB command in PAE mode was getting the fib
+	  size count wrong, by using the 32 bit command, then doing an (n-1)
+	  times the size of the 64 bit scatter gather. Resolution was to
+	  subtract the 32 bit scatter gather, then do an n times the 64 scatter
+	  gather size.
+	- Only go into PAE mode if more than 4MB of memory in the system.
+
+2003-07-10	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Added `Family' product codes and reordered the product discovery code
+	  to produce devices in PCI order rather than in product order.
+	  Dell, Legend and Adaptec Families were produced with the assumption
+	  of 2 available busses.
+
+2003-07-24	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Added Bearcat (6 ch SATA) and a commented entry for Lancer where
+	  future workarounds may be necessary due to hardware constraints.
+	- Set highmem_io (for kernels of 2.4.18 and above).
+
+aachba.c:
+	- Set highmem_io (for kernels of 2.4.18 and above; and when the
+	  adapter is guaranteed to handle the possible address ranges it
+	  will be provided).
+
+Version: 1.1.4:
+
+2003-07-28	Mark_Salyzyn@adaptec.com
+
+aacraid.h+common/include/fsaioctl.h+aachba.c
+	- Added the FSACTL_REGISTER_FIB_SEND function to the ioctl. This ioctl
+	  is *not* a user accessible ioctl, meant only for driver use to permit
+	  stacking a filter driver just ahead of the hardware layer. The call
+	  to register is:
+
+		typedef void (*fib_callback)(void *ctxt, struct fib *fibctx);
+		typedef struct {
+			int (*fib_send)(u16 command,
+					struct fib * context,
+					unsigned long fib_size,
+					int priority,
+					int wait,
+					int reply
+					fib_callback callback,
+					void * ctxt);
+		} fib_send_t;
+		. . .
+		fib_send_t original;
+		int dummy_fib_send (u16 command,
+				    struct fib * context,
+				    unsigned long fib_size,
+				    int priority,
+				    int wait,
+				    int reply
+				    fib_callback callback,
+				    void * ctxt)
+		{
+			return (*original->fib_send)(command, context, fib_size, priority, wait, reply, callback, ctxt);
+		}
+		. . .
+		Scsi_Host_Template * host;
+		Scsi_Device * adapter;
+		original->fib_send = dummy_fib_send;
+		host->ioctl(adapter, FSACTL_REGISTER_FIB_SEND, &original);
+
+	  Return value from the ioctl include ENOTTY (not supported), EINVAL
+	  (invalid argument pointer) and EBUSY (another function already
+	  registered) and the original fib_send function is returned in the
+	  ioctl argument structure. A NULL value for the fib_send member of the
+	  structure deregisters the filter driver. The fib_callback function is
+	  issued at interrupt priority and should follow all the constraints of
+	  interrupt operation. It is the responsibility of the registered
+	  fib_send function to ensure that the original fib_callback function
+	  is called with the ctxt value when completing the command (this
+	  subtlety is lost in the above dummy function).
+
+2003-07-28	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Added Kernel, Firmware and BIOS revision and build number to proc
+	  information.
+	- Added board serial number to proc information.
+
+aachba.c:
+	- Do not set removable bit in the inquiry command, the aif delivery
+	  of array status change will handle the reasons for the removable
+	  bit (capacity change and differences in the partition table). Some
+	  customers take issue with the fact our arrays appear as removable.
+
+commctrl.c:
+	- Reported driver version and build number instead of Firmware version
+	  and build number for the Miniport Version Check ioctl. ADPmp57715
+
+2003-08-06	Mark_Salyzyn@adaptec.com and a cast of thousands
+
+all files:
+	- Added appropriate ifdefs, or merged in additions, in support of the
+	  2.6.0-test2 kernels as follows:
+
+Makefile:
+	- Added ifdefs for 2.4 and 2.6 kernels so we can use a common Makefile
+	  for both kernel build environments.
+
+aachba.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- define aac_spin_* macros to differentiate between lock requirements
+	  in 2.5+ and 2.4 kernels.
+	- Use the SCSI layers definitions of the SCSI commands, rather than
+	  our own internal SS_* manifests.
+	- Define SCSICMD_TO_* macros to acquire the SCSI target host, channel,
+	  id and lun.
+	- Use the 2.6 SAM_* status codes for return, the 2.4 system will
+	  redefine the SAM_* codes to 2.4 variants.
+	- Change to devname instead of devno when referencing devices to
+	  simplify conversions.
+	- MAXIMUM_NUM_CONTAINERS references were +/- 1 in comparisons, made
+	  this value a `number' rather than a mix of `number' and `limit'.
+	- Resolved `Cast of pointer from integer of different size' by
+	  (void *)(ulong)dma_addr_t.
+	- Change to `id' rather than `target' to match SCSI subsystem
+	  references name for consistency.
+
+aacraid.h:
+	- MAXIMUM_NUM_CONTAINERS references were +/- 1 in comparisons, made
+	  this value a `number' rather than a mix of `number' and `limit'.
+	- Removed AAC_MAX_TARGET, as it is no longer used.
+	- Added CONTAINER_TO_* macros to simplify references.
+	- Change to `id' rather than `target' to match SCSI subsystem
+	  references name for consistency.
+	- Change to devname instead of devno when referencing devices.
+	- Use cap_to_cyls inline to handle 64 bit calculation correctly.
+
+commctrl.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- Change to `id' rather than `target' to match SCSI subsystem
+	  references name for consistency.
+
+comminit.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+
+commsup.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- Moved CONTAINER_TO_* macros to aacraid.h to simplify references.
+	- Device Discovery loops are different for 2.4 and 2.5+ kernels,
+	  use list_for_each_entry siblings instead of host_queue loop.
+	- daemonize adds the process name as a parameter, and requires
+	  SIGKILL to be enabled to permit kernel shutdown in 2.5+ kernels.
+
+dpcsup.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+
+linit.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- added aacids to provide a table hint for installers.
+	- changed over to utilize ANSI structure initialization.
+	- aac_biosparm and aac_procinfo change parameters in 2.5+ kernels.
+	- aac_slave_configure replaces aac_queuedepth in 2.5+ kernels.
+	- detect no longer needs to unlock io_request_lock to do it's duty
+	  in 2.5+ kernels.
+	- use SCSI_set_device in 2.5+ kernels rather than scsi_set_pci_device.
+	- Change to devname instead of devno when referencing devices to
+	  simplify conversions.
+	- Use MAXIMUM_NUM_CONTAINERS rather than AAC_MAX_TARGET
+	- Use cap_to_cyls inline to handle 64 bit calculation correctly in
+	  aac_biosparm.
+	- Use minor in 2.5+ kernels instead of MINOR macro.
+
+rx.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- interrupts now return irqreturn_t.
+
+sa.c:
+	- use linux/blkdev.h in 2.5+ kernels.
+	- interrupts now return irqreturn_t.
+
+2003-08-15	Mark_Salyzyn@adaptec.com
+
+install.sh:
+	- increased range of kernel version reports in the magic file to 30.
+
+2003-08-19	Mark_Salyzyn@adaptec.com & ijohns@elipsan.com
+
+aachba.c:
+	- status_byte in the result is shifted down by one.
+	- set_sense spoof was not immediately followed by a copy of the check
+	  condition results into the SCSI command.
+
+2003-08-20	Mark_Salyzyn@adaptec.com, Scott_Long@adaptec.com & Alan Cox
+
+commctrl.c:
+	- The raw SCSI SCB ioctl command in PAE mode was getting the fib
+	  size count wrong, by using the 32 bit command, then doing an (n-1)
+	  times the size of the 64 bit scatter gather. Resolution was to
+	  subtract the 32 bit scatter gather, then do an n times the 64 scatter
+	  gather size.
+
+aacraid.h:
+	- Added definition of CT_FLUSH_CACHE command and structures.
+	- Added AAC_QUIRK_31BIT for ROMB based adapters.
+
+linit.c:
+	- Added AAC_QUIRK_31BIT for ROMB based adapters.
+	- Check return from scsi_register.
+
+aachba.c:
+	- Added support for issuing CT_FLUSH_CACHE command when the SCSI
+	  SYNCHRONIZE command is issued to a container.
+	- Restored mask after adding AAC_QUIRK_31BIT for ROMB based adapters.
+
+2003-08-21	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Changed aac_get_container_name to be a none-blocking function,
+	  completing the incoming scsicmd with the adapter response.
+
+2003-08-26	Mark_Salyzyn@adaptec.com
+
+commsup.c + aacraid.h:
+	- Altered handling of AIF messages from Firmware to differentiate
+	  events in a finer grained manner.
+
+2003-08-29	Mark_Salyzyn@adaptec.com
+
+aachba.c + aacraid.h
+	- Driver too noisy, undefined AAC_DETAILD_STATUS_INFO and incorporated
+	  check condition report into the AAC_DETAILED_STATUS_INFO ifdef.
+
+2003-09-03	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Check if the device is in use and report that as a locked device
+	  to both the FSACTL_QUERY_DISK and FSACTL_DELETE_ARRAY ioctls.
+	- unlock/lock around probe_container as this is a blocking function.
+	  This change addresses a deadlock issue that surfaced in SMP only
+	  environments.
+
+Version: 1.1.4-2172
+
+2003-09-04	Mark_Salyzyn@adaptec.com
+
+commsup.c:
+	- References to the Status Job update structure were at incorrect
+	  offsets causing incorrect operation during an Array Clear with
+	  regards to plug and play actions.
+
+Version: 1.1.4-2177
+
+2003-09-05	Mark_Salyzyn@adaptec.com
+
+aachba.c:
+	- Cleanup request from the SCSI list maintainers.
+	- Dropped use of SCSICMD_TO_CHANNEL & friends since
+	  scsicmd->device->channel is available in all versions of the
+	  operating system.
+	- Removed deprecated code and/or comments related to deprecation.
+	- include <linux/blkdev.h> works in all versions of the operating
+	  system.
+
+2003-09-09	Mark_Salyzyn@adaptec.com
+
+aacraid.h:
+	- NUM_FIBs should be 64 larger (AIFS) larger than the NUM_IO_FIBS.
+
+commsup.c:
+	- efficiency improved if we hold on to the aac_queue variable, aims
+	  towards better code compliance and consistency.
+
+2003-09-15	Mark_Salyzyn@adaptec.com
+
+rkt.c:
+	- Copy if rx.c with rx = rkt
+
+aacraid.h:
+	- Added definition for rkt interface structures, copy of rx, but a
+	  larger reserved region.
+
+linit.c:
+	- Added product code for ROC (Lancer/Rocket) U320 two channel, use rkt
+	  interface.
+
+2003-09-16	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Show Adapter vendor and model in proc information.
+
+Version: 1.1.4-2185
+
+2003-09-16	Mark_Salyzyn@adaptec.com
+
+aacraid.h:
+	- Added definition of nblank() to assist us in determining if
+	  dprintk(x) is defined as a blank definition to enable us to ifdef
+	  debug code that ends up calling only dprintk functions.
+
+commsup.c:
+	- Ignore events that refer to containers > MAXIMUM_NUM_CONTAINERS
+	- include <linux/blkdev.h> works in all versions of the operating
+	  system.
+
+linit.c:
+	- print more details about outstanding commands when a SCSI hang
+	  occurs (first use of nblank() macro just defined in aacraid.h)
+
+2003-09-19	Mark_Salyzyn@adaptec.com & Mark Haverkamp <markh@osdi.org>
+
+commsup.c & aachba.c:
+	- valid flag has added support for a value of 2, which means target
+	  is still valid, but needs a probe_container.
+
+commsup.c:
+	- fib_alloc should not go to sleep, but return NULL if there are no
+	  available entries in the pool.
+
+dpcsup.c:
+	- print a message if the fib kmalloc fails when forwarding AIFs
+
+comminit.c:
+	- check fib_alloc return, and report -ENOMEM should the pool be
+	  empty.
+
+aachba.c:
+	- Check value of scsicmd->scsi_done in aac_io_done as we can get
+	  errant firmware which returns commands twice (no released firmware
+	  does this, this is a driver hardening issue only).
+	- When a fib_alloc fails, return -1 to SCSI layer. Formerly, we would
+	  send the command with DID_ERROR.
+
+Version: 1.1.4-2192
+
+2003-09-25	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Moved debug variables into block to reduce impact on none-debug
+	  environments.
+
+dpcsup.c + commsup.c:
+	- Use the fib pool instead of a kmalloc to allocate a fib for the
+	  processing of an AIF.
+
+install.sh:
+	- Install driver into any forgotten /lib/modules directories.
+
+2003-09-26	Mark_Salyzyn@adaptec.com
+
+commctrl.c + aacraid.h:
+	- AMD-64 and IA-64 management applications will fail, need to change
+	  fibctx to a 32 bit unique value.
+
+Version: 1.1.4-2194
+
+2003-09-29	Mark_Salyzyn@adaptec.com & Mark Haverkamp <markh@osdi.org>
+
+aachba.c:
+	- use linux/blkdev.h for all variants on Linux.
+	- hold on to the host pointer in aac_io_done, because it's reference
+	  in the device and scsicmd can go away after scsi_done is called.
+	- check return value of pci_set_dma_mask.
+
+commctrl.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+comminit.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+commsup.c:
+	- use linux/blkdev.h for all variants on Linux.
+	- drop linux/smp_lock.h include as it was added in a debug test from
+	  some time ago.
+	- Added current 2.6 kernel support routines for rescanning.
+
+dpcsup.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+linit.c:
+	- use linux/blkdev.h for all variants on Linux.
+	- check return value of pci_set_dma_mask.
+	- template->present is no longer relevant in 2.6 based kernels.
+
+rx.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+sa.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+rkt.c:
+	- use linux/blkdev.h for all variants on Linux.
+
+2003-10-01	Mark_Salyzyn@adaptec.com
+
+commsup.c:
+	- needed a fib_dealloc call ahead of the fib_free call added when
+	  we moved over to the fib pool to handle the AIFs.
+
+dpcsup.c:
+	- need to use the `local' fibctx so that the AIF command can be
+	  acknowledged.
+
+commctrl.c:
+	- return error status from the send_fib function in ioctl_send_fib.
+
+2003-10-07	Mark_Salyzyn@adaptec.com
+
+aachba.c + linit.c:
+	- serial number contains the cookie (fafa0001) that is at index 1
+	  of the serial number element. Only show the serial number which
+	  is at index 0.
+
+linit.c:
+	- Added registration to receive 32 bit ioctls.
+
+commsup.c + dpcsup.c + aacraid.h:
+	- Dropped code to acquire AIF's from the general FIB pool, it was a
+	  fool's errand. However, we kept the code that limits the AIF's
+	  received and allocated to the AdapterFibsSize / sizeof(hw_fib).
+	  The `last' AIF hw_fib is used to quickly acknowledge the entries,
+	  and drop the results on the floor.
+
+rx.c + rkt.c:
+	- Cache the OIMR data in dev->OIMR, it looks remarkably like irq_mask,
+	  which is really unused, but we can clean that up later.
+
+2003-10-08	Matthew Wilcox <willy@debian.org>
+
+aachba.c:
+	- Use SCp.dma_handle instead of SCp.ptr for holding on to the physical
+	  address of the allocated pci_map_single as part of the request.
+
+compat.h:
+	- define dma_handle to be ptr (in support of SCp.dma_handle change
+	  above) for kernels that do not define this member.
+
+2003-10-08	Christoph Hellwig <hch@infradead.org>
+
+aachba.c:
+	- drop use of scsi_to_pci_dma_dir() as it is a pass-through in all
+	  versions of the kernel.
+
+2003-10-09	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- When an Adapter Reset is requested, wait up to 60 seconds for all
+	  outstanding commands to complete and report SUCCESS.
+
+Version: 1.1.4-2221
+
+2003-10-09	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- Waited for *all* commands to complete for *all* devices on the
+	  controller when an Adapter Reset is requested.
+
+Version: 1.1.4-2222
+
+2003-10-10	Mark_Salyzyn@adaptec.com
+
+aacraid.h + rx.c + rkt.c + sa.c + linit.c:
+	- Added a aac_adapter_check_health, make sure the adapter is healthy
+	  when performing and Adapter Reset request, report error codes.
+
+aachba.c:
+	- revert to use of scsi_to_pci_dma_dir() as it is not a pass-through in
+	  all versions of the kernel.
+
+linit.c:
+	- SCSI_HAS_HOST_LOCK means that we should be working with releasing
+	  host->lock or host->host_lock instead of io_request_lock surrounding
+	  scsi_sleep.
+
+aacraid.h:
+	- Added definition for AAC_MAX_HOSTPHYSMEMPAGES
+
+comminit.c:
+	- Utilized AAC_MAX_HOSTPHYSMEMPAGES to limit the number of open DMA
+	  4096 byte PAGES of memory requested by the operating system.
+
+2003-10-16	Mark_Salyzyn@adaptec.com
+
+install.sh:
+	- Added support for x86_64 installs
+
+aachba.c:
+	- used SENSE KEYS from scsi.h rather than our own definitions.
+
+2003-10-20	Xose Vazquez Perez <xose@wanadoo.es>
+
+linit.c:
+	- Added pci_ids for 0x10110046/0x90050365
+
+Version: 1.1.4-2265
+
+2003-10-23	Mark_Salyzyn@adaptec.com
+
+linit.c:
+	- no need to set template->present as this is done by the SCSI layer.
+
+2003-10-24	Mark_Salyzyn@adaptec.com
+
+install.sh
+	- Added support for SuSE kernel determination for finer selection
+	  of modules
+	- If the kernel is compiled for athlon, use that instead of
+	  /proc/cpuinfo
+	- if /proc/cpuinfo is not present, don't show any errors during
+	  install
+
+2003-10-28	Mark_Salyzyn@adaptec.com
+
+install.sh
+	- The entire class of SuSE OS releases (sles7, sles8, suse7, suse8,
+	  suse8.1, suse8.2, ul1, ul1-sp2a) place the driver module results into
+	  /lib/modules/[kernel]/kernel/drivers/scsi/aacraid/aacraid.o. The
+	  package places updates in ...//scsi/aacraid.o (note, one directory
+	  up). The module selected for use in the mkinitrd is fed via a `find'
+	  command which reports files in raw directory order which in the
+	  reiser file system would be in the .../scsi directory, but for EXT2
+	  since the file was added later, would prefer the previously placed
+	  product in ../scsi/aacraid/aacraid.o. The fix is to have the driver
+	  disk post-install remove the older .../scsi/aacraid directory.
+
+2003-10-30	Mark_Salyzyn@adaptec.com
+
+install.sh
+	- For the installations to `extra' /lib/modules directories beyond
+	  the boot set, take the processor clue from the postscript (-athlon,
+	  -x86_64 or -ia64) rather than from /proc/cpuinfo.
+
+Version: 1.1.4-2282
+Version: 1.1.4-2292 (Debug)
+
+2003-10-31	Mark_Salyzyn@adaptec.com
+
+aacraid.h + aachba.c:
+	- Added a nested count to the fsa_scsi_dev structure since some kernels
+	  before 2.4.19 have troubles overflowing their stack when a device
+	  goes offline. The issue is that the SCSI done call nests into sending
+	  another queued command, which in turn spoofs a response back
+	  indicating failure which in turn calls SCSI done. We limit the
+	  nesting to 64 commands before we respond with a busy instead.
+
+Version: 1.1.4-2296 (Debug)
+
+linit.c & .version:
+	- Versioning is defined by the structure:
+	    struct {
+		unsigned char dash; // Dash version number
+		unsigned char type; // Type, 1=Devo, 2=Alpha, 3=Beta, 4=Release
+		unsigned char minor;// Minor version minor
+		unsigned char major;// Major version number
+	    }
+	  Adjusted version data to match this definition for generation and
+	  support.
+
+Version: 1.1.4-2299
+Version: 1.1.4-2301
+Version: 1.1.4-2302
+Version: 1.1.4-2303
+
+linit.c & aacraid.h:
+	- Allow 64 bit apps to call GET_NEXT_ADAPTER_FIB ioctl directly,
+	  promoting 32 bit apps when they call.
+
+aachba.c & aacraid.h:
+	- Set MAX_NESTED to 1, and improve code to reflect this simplicity.
+
+install.sh:
+	- Handle name change of products from *-athlon-athlon to *-athlon.
+	- Warn the user if the initrd shrinks too much
+
+Version: 1.1.4-2308
+
+install.sh:
+	- Add support for identifying 2.4.19-340 kernels.
+
+2003-12-12	Mark Haverkamp <markh@osdl.org>
+
+linit.c:
+	- updated aac_eh_reset to use __shost_for_each_device now that the
+	  device element is now private and we're supposed to use the helper
+	  function for access.
+
+Version: 1.1.4-2309
+Version: 1.1.4-2310 (debug)
+
+2003-12-18	Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+linit.c:
+	- suppress unused variable warning in debug code.
+	- cast sys_ioctl when registering as it does not match prototype
+	  argument for ioctl32 registration.
+
+Version: 1.1.4-2311
+
+2003-12-22	Mark Haverkamp <markh@osdl.org>
+
+aachba.c:
+	- change from pae to dac as this is the more public understanding of
+	  the 64 bit support concepts.
+aacraid.h:
+	- Remove padding and SavedIrql
+commsup.c + aachba.c:
+	- use atomic_read when accessing access_count member of device
+	  structure.
+linit.c & aacraid.h
+	- iminor takes the inode, not the inode->i_rdev member.
+
+Version: 1.1.4-2313
+
+aachba.c + commsup.c:
+	- use device_busy, shost_status, in_recovery instead of just
+	  access_count. Adjust for each OS release variant.
+
+Version: 1.1.4-2314
+
+2003-12-22: Ken Beaty <ken@nova.org>
+
+aachba.c + commsup.c:
+	- Adjusted ifdefs for kernel version to make more sense.
+
+2004-01-24: Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+install.sh:
+	- Altered script to discover prebuilt binaries from the classic
+	  Adaptec rpm package, the Red Hat install disk format, or the
+	  SuSE install disk format.
+
+2004-02-09: Christoph Hellwig <hch@lst.de>
+
+aachba.c:
+	- Remove fsa_dev structure since fsa_dev is always available.
+
+Version: 1.1.4-2324
+
+2004-02-10: Submit to scsi list for inclusion
+
+2004-02-17: Herve MORILLON <hmorillon@doremilabs.fr> + Mark_Salyzyn@adaptec.com
+
+rx.c + rkt.c:
+	- hit doorbell before processing host_command_normal
+
+aachba.c:
+	- Permit requests larger than 64KB
+
+aacraid.h:
+	- Permit 512 outstanding requests
+
+Version: 1.1.5-2326
+
+linit.c + build:
+	- Added support for vary_io, unfortunately the build system also needed
+	  to be adjusted to generate the SCSI_HAS_VARY_IO if the member is
+	  seen in the drivers/scsi/hosts.h file.
+
+build + install.sh:
+	- Added support for 2.4.19-189, 2.4.19-191 and 2.4.19-201 SuSE Kernels
+
+Version: 1.1.5-2327
+
+rkt.c + rx.c:
+	- Added support to issue the Temperature sync command. Since the
+	  cost of the sync command should not increase, the decision was
+	  made to support a `varargs' approach to dealing with the additional
+	  temperature elements *only* for this command.
+
+linit.c:
+	- Added a proc write that accepts the string "Temperature=[0-9.],..."
+	  to send the off-board temperature value to the Firmware so that it
+	  may be integrated into the Enclosure Data.
+	- Added SkyHawk SATA cards to device list. 2020S changes now to 
+	  2020ZCR, and we add 2020SA.
+
+aachba.c:
+	- PERCRAID RAID-5 is superfluous, changed to to PERC RAID-5.
+
+Version: 1.1.5-2328
+
+linit.c + aacraid.h:
+	- Migrate towards using CONFIG_COMPAT instead of __x86_64__
+
+rx.c + rkt.c:
+	- Added support to pick up an Adapter Blink code. ADPmp64499.
+
+linit.c:
+	- Report the Adapter Blink code to the console log. ADPmp64499.
+
+build:
+	- Correctly built the x86_64 SLES8 and ul1 driver disk. Side effects
+	  discovered also fix problems with ia32 SLES8 install. ADPmp64499.
+
+Version: 1.1.5-2329
+
+linit.c + aacraid.h:
+	- Report an AifExeFirmwarePanic AIF message to applications when the
+	  adapter is in a blinkled state.
+
+aachba.c + commsup.c: Brad House <brad@mainstreetsoftworks.com>
+	- use shost_for_each_device instead of list_for_each_entry.
+
+linit.c + aachba.c:
+	- xscale (arm) systems can not have highmem_io set as virtual/phys
+	  handling does not recognize the page/offset addressing.
+
+rkt.c + rx.c:
+	- The Mailbox[7] in none BBS systems is not active until shortly
+	  before the Firmware kernel is booted. The Outbound Message register
+	  is always active and contains the same bringup conditions. We must
+	  look at the OMR during the *_init wait.
+
+Version: 1.1.5-2330
+
+rkt.c + rx.c + sa.c:
+	- Set the time by using get_seconds (epoch January 1 1970) instead
+	  of jiffies/HZ (epoch machine startup). get_seconds is provided
+	  for kernels < 2.6.
+
+Version: 1.1.5-2331
+
+rkt.c:
+	- Mailbox[7] becomes momentarily inaccessible right after PATUWAIT
+	  on the Callisto, lets loop on OMR only. Do not know if this
+	  problem exists on other systems.
+
+Version: 1.1.5-2332
+
+aachba.c + linit.c:
+	- Issue CT_COMMIT_CONFIG before issuign the VM_NameServe. This is
+	  for systems that do not have a BIOS to perform this step.
+
+Version: 1.1.5-2333
+
+aacraid.h:
+	- SAS requires the ability to handle as many as 32 Adapters in a
+	  system, increased the manifest that limits the number of Adapters.
+	- Testing has shown that allowing 33MB I/O can starve a machine, so
+	  we are limiting the maximum I/O size to 4MB (to match other drivers
+	  that permit large I/O).
+
+linit.c:
+	- Make sure that the driver does not register more than
+	  AAC_MAXIMUM_ADAPTERS instances.
+	- Set the queue depth to each device as divided up from AAC_MAX_IO_FIB
+
+commctrl.c: Chris Wright <chrisw@osdl.org>
+	- aac_send_raw_srb added check for bounding of fibsize value.
+
+all: Mark Haverkamp <markh@osdl.org> & Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+	- merge 2.6 driver changes into tree to synchronize.
+
+Version: 1.1.5-2334
+
+aacraid.h+linit.c+commctrl.c+comminit.c:
+	- Added sg_tablesize and max_fib_size to adapter structure and
+	  negotiate these plus Scsi_Host sg_tablesize, can_queue and
+	  max_sectors based on the adapter capabilities.
+
+aachba.c:
+	- Added aac_raw_io command
+	- Recognize that read_callback is identical to write_callback, which
+	  is in turn identical to raw_io's need for a callback. Renamed to
+	  one callback function io_callback.
+
+rx.c+rkt.c+sa.c:
+	- Moved initialization around to permit New Command Interface probes
+	- dropped irq_mask and associated functions.
+	- moved acknowledgement of F/W commands *before* processing so that
+	  we get re-interrupted if a new command is added to the produced
+	  index while we are processing.
+
+linit.c+aachba.c:
+	- Do not print `bad0' for the serial number
+
+linit.c:
+	- this_id = 32, because it gets in the way of Container 16 being
+	  processed.
+
+aachba.c:
+	- scsi_add_timer call issued just before completion routine called
+	  since error recovery handler is there *just* to detect card
+	  failure and not to affect command processing.
+
+build:
+	- Added 2.4.19.SuSE-343 kernel in support of ul1-sles8-ia32 install,
+	  which adds yet another installation floppy to the list.
+
+Version: 1.1.5-2335
+
+linit.c+all:
+	- Revert temporarily to 1.1.4-2177, Changed ASR-2020S to ASR-2020ZCR,
+	  and ASR-2020S Terminator to ASR-2025ZCR.
+
+Version: 1.1.4-2336
+
+linit.c+all:
+	- Revert temporarily to 1.1.4-2322, Changed ASR-2020S to ASR-2020ZCR,
+	  and ASR-2020S Terminator to ASR-2025ZCR.
+
+Version: 1.1.4-2337
+
+all:
+	- Revert back to 1.1.5 code base.
+
+commsup.c:
+	- Fix Irq Moderation code. A Misnomer, since this is really a PCI
+	  utilization moderation, interrupts are not recurring on F/W.
+
+comminit.c:
+	- Turn on Irq Moderation feature (Tentatively 30% reduction in Host
+	  CPU utilization)
+
+Version: 1.1.5-2337
+
+aacraid.h+commsup.c+dpcsup.c+comminit.c+rx.c:
+	- Added support for the new comm interface.
+
+linit.c:
+	- Added debug information to proc output
+
+Version: 1.1.5-2338
+
+commsup.c: Mark Haverkamp <markh@osdl.org>
+	- Added scsi/scsi_device.h, scsi/scsi_driver.h to include file set
+	- set removable to a value of 1, not to TRUE.
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- Switch to using max_fib_size rather than FIB_DATA_SIZE_IN_BYTES,
+	  this permits SAS management applications to send ioctl FIBs larger
+	  than 512 bytes in size to adapters that accept larger FIBs.
+	- Added support for SAI_READ_CAPACITY_16, READ_12, WRITE_12, READ_16
+	  and WRITE_16 commands.
+	- Played `tricks' with device_blocked and queue_depth fields in the
+	  scsi_device structure to meter the outstanding commands down when
+	  large sequential activity is detected.
+
+aacraid.h: Mark_Salyzyn@adaptec.com
+	- Remove unused definition of FIB_DATA_SIZE_IN_BYTES.
+
+Version: 1.1.5-2339
+
+build: Mark_Salyzyn@adaptec.com
+	- Added support for 2.6.4-52 SuSE 9.1 Pro install
+	- Added support for multiple architectures for 2.4.21-15.EL RHEL3 QU2
+	  install.
+
+aacraid.h+aachba.c+linit.c: Mark Haverkamp <markh@osdl.org>
+	- Define 2131 as FSACTL_GET_CONTAINERS
+
+commctrl.c: Adam Manthei <amanthei@redhat.com>, Mark_Salyzyn@adaptec.com
+	- change all printk() to dprintk(()) as this is a user initiated
+	  call for aac_send_rw_srb & aac_get_pci_info.
+
+rx.c+rkt.c: Adam Manthei <amanthei@redhat.com>, Mark_Salyzyn@adaptec.com
+	- use pci_alloc_consistent/pci_free_consistent instead of an
+	  unchecked combination of kmalloc(,_GFP_DMA)/pci_map_single/
+	  pci_unmap_single/kfree.
+
+Version: 1.1.5-2340
+
+linit.c+commctrl.c: Mark Haverkamp <markh@osdl.org>
+	- adjust to reflect linux-scsi submission results
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- remove print for unhandled commands into a debug print. The
+	  unhandled commands are reported to the caller as unhandled, let
+	  the caller deal with this.
+
+rx.c+rkt.c+sa.c: maximilian attems <janitor@sternwelten.at>
+	- upon failure of the init routine, make sure that the registered
+	  interupt handler is deregistered.
+
+commsup.c:
+	- fib_adapter_complete is supposed to free the hw_fib and that is it,
+	  it tried to talk to hardware and caused a lockup.
+
+Version: 1.1.5-2341
+
+build:
+	- use aacraid.ko for 2.6 releases
+
+Version: 1.1.5-2342
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- added support for a module parameter 'commit=1' to enable COMMIT
+	  CONFIG to be issued to the adapter.
+	- added support for a module parameter 'coalescethreshold=16' which
+	  sets the maximum block size to consider for pushing back to the
+	  scsi_merge layer.
+	- added support for a module parameter 'acbsize=8192' which sets the
+	  suggested fib size to override the suggestion from Firmare.
+	- dropped call to scsi_add_timer, as it causes a panic. It was placed
+	  in the source to resolve a command completion race condition.
+
+Version: 1.1.5-2343
+
+install.sh: Mark_Salyzyn@adaptec.com
+	- globbing issue caused more whiny complaints about a missing
+	  installation into the initrd.
+	- fixed some issued surrounding using the script for SuSE module
+	  update.
+
+linit.c: Mark_Salyzyn@adaptec.com
+	- if the driver does not discover any targets, report failure.
+	- drop kernel_version hack to support build
+
+build: Mark_Salyzyn@adaptec.com
+	- Use vermagic instead of kernel_version to pick up matching kernel.
+	- when innoculating 2.6 tree builds, one needs a *full* compile in
+	  order to generate the struct_module member.
+	- use module.ko for 2.6 kernels.
+
+Version: 1.1.5-2344
+
+build: Mark_Salyzyn@adaptec.com
+	- floppy linux/suse/${ARCH}-${VERS}/modules/${PRODUCT}.o needs to be
+	  a ${PRODUCT}.ko in the 2.6 based installations.
+	- Placed module in both scsi and scsi/${PRODUCT} directories as it
+	  appears that the post-install is not functioning properly.
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- Checked if the lba exceeds 32 bit block address for systems that
+	  can not support it. raw_io_64 enables 64 bit block addresses.
+	- Redid math for u64 >> 32 as it appears the xscale 64 bit library
+	  is flawed.
+
+Version: 1.1.5-2345
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- Overrides to force 8KB fibs needs to be reverted to defaults.
+
+Version: 1.1.5-2346
+
+build: Mark_Salyzyn@adaptec.com
+	- Added 2.4.21-15.0.2.EL kernel
+	- Added 2.6.5-7.97 kernel to the build
+
+rx.c+rkt.c: Mark_Salyzyn@adaptec.com
+	- Mailbox7 continues to be a consternation regarding reliable
+	  adapter recovery scenarios; switched to using OMRx[0].
+
+Version: 1.1.5-2347
+
+aachba.c: Mark_Salyzyn@adaptec.com
+	- (u64)=((u8)<<24) does not give expected results, sign extension
+	  occurs. Replace with (u64)=((u64)(u8)<<24)
+
+Version: 1.1.5-2348
+
+install.sh: Mark_Salyzyn@adaptec.com
+	- initrd is blocked from incorporating our product if there is
+	  something in /lib/modules/${OS}-${CONFIG}/update/${PRODUCT}.o,
+	  so remove the file.
+
+Version: 1.1.5-2349
+
+aachba.c+aacraid.h:
+	- define commit_config FIB command
+	- define get_container_count FIB command.
+
+aachba.c+aacraid.h+commsup.c+linit.c
+	- fsa_dev becomes a dynamic structure to accommodate a variable
+	  maximum_num_containers.
+
+build:
+	- Added 2.4.21-231 kernel to build system.
+
+linit.c:
+	- Turned on debug printing of scsi timeouts for xscale only.
+
+Version: 1.1.5-2350
+
+rkt.c:
+	- Limit can_queue to 246 for rocket
+
+build:
+	- Added 2.4.19-306 kernel to build system.
+
+aachba.c:
+	- Removed an innocuous (obnoxious?) DEBUG printk
+
+2004-07-15: Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+Version: 1.1.5-2351
+
+build:
+	- Added 2.4.9-31 to the build system
+
+modules.conf:
+	- Added 2.4.9-e.41, 2.4.9-e.43, 2.4.21-17.EL & 2.4.21-15.0.3.EL kernels
+
+build:
+	- Dropped 2.4.21-231 from build
+
+2004-07-16: Mark Salyzyn <Mark_Salyzyn@adaptec.com>
+
+Version: 1.1.5-2352
+
+build:
+	- Added 2.6.3-7mdk to the build system
+
+Version: 1.1.5-2353 (Lantana Build w/o SLES9, SuSE9.1 & SuSE9 errata 231)
+Version: 1.1.5-2354 (Lantana Build w/o SLES9 & SuSE9 errata 231)
+Version: 1.1.5-2355 (BigQual refresh)
+
+install.sh:
+	- If missing, add a reference to the module to the kernel's module.dep
+	  file (affects drivers that are *not* shipped with the OS; HostRAID
+	  and some dpt_i2o)
+
+aachba.c:
+	- for __arm__ build, the default FIB size is selected by F/W and not
+	  overridden to 8192 bytes.
+
+Version: 1.1.5-2356 (Jupiter)
+
+aacraid.h+comminit.c+rkt.c+commsup.c+linit.c: Ken Sandars <Ken_Sandars@adaptec.com> + Mark Salyzyn
+	- Added AAC_NUM_MGT_FIB, and ensured can_queue represents the
+	  maximum number of io commands allowed and not be confused as the
+	  maximum number of FIB commands permitted into the Adapter. Thus
+	  host->can_queue is the maximum number of I/O commands, AAC_NUM_MGT_FIB
+	  is the maximum number of ioctl commands (set to 8 rather than legacy
+	  of 64) and init->MaxIoCommands sent back to the adapter is the total
+	  number of FIBs.
+
+Version: 1.1.5-2357 (Jupiter+BigQual)
+
+commctrl.c: Mark Salyzyn
+	- Added support for issuing FIBs that are larger than the negotiated
+	  size for the management interface.
+
+linit.c: Mark Salyzyn
+	- Added ASR-2240S, ASR-4005SAS, ASR-4000SAS, ASR-4800SAS, ASR-4805SAS
+	  and AAR-2610SA to the product list.
+
+install.sh: Mark Salyzyn
+	- Fixed problems with using the RH & SuSE modules disk as an update
+	  media, most of which was the selection of the extraction name from
+	  the modules.cgz file or acquiring the appropriate update.tar.gz file.
+
+build: Mark Salyzyn
+	- set 700 for update.sh in the modules disks to recognize at least
+	  that the RH modules disk works as an update media.
+
+aachba.c: Mark Salyzyn
+	- Dropped to 8K for the coalesce threshold for xscale builds.
+
+Version: 1.1.5-2358 (BigQual+Lantana)
+
diff -urNp linux-2.6.8/drivers/scsi/aacraid/commctrl.c linux-2.6.8.SUSE/drivers/scsi/aacraid/commctrl.c
--- linux-2.6.8/drivers/scsi/aacraid/commctrl.c	2004-08-14 07:36:46.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/commctrl.c	2004-07-30 19:42:15.000000000 +0200
@@ -40,6 +40,7 @@
 #include <linux/blkdev.h>
 #include <asm/semaphore.h>
 #include <asm/uaccess.h>
+#include <scsi/scsi.h>
 
 #include "aacraid.h"
 
@@ -52,14 +53,19 @@
  *	program.
  */
  
-static int ioctl_send_fib(struct aac_dev * dev, void __user *arg)
+static int ioctl_send_fib(struct aac_dev * dev, void *arg)
 {
 	struct hw_fib * kfib;
 	struct fib *fibptr;
+	struct hw_fib * hw_fib = (struct hw_fib *)0;
+	dma_addr_t hw_fib_pa = (dma_addr_t)0LL;
+	unsigned size;
+	int retval;
 
 	fibptr = fib_alloc(dev);
-	if(fibptr == NULL)
+	if(fibptr == NULL) {
 		return -ENOMEM;
+	}
 		
 	kfib = fibptr->hw_fib;
 	/*
@@ -74,14 +80,19 @@ static int ioctl_send_fib(struct aac_dev
 	 *	will not overrun the buffer when we copy the memory. Return
 	 *	an error if we would.
 	 */
-	if(le32_to_cpu(kfib->header.Size) > sizeof(struct hw_fib) - sizeof(struct aac_fibhdr)) {
-		fib_free(fibptr);
-		return -EINVAL;
+	size = le32_to_cpu(kfib->header.Size) + sizeof(struct aac_fibhdr);
+	if (size > dev->max_fib_size) {
+		/* Highjack the hw_fib */
+		hw_fib = fibptr->hw_fib;
+		hw_fib_pa = fibptr->hw_fib_pa;
+		fibptr->hw_fib = kfib = pci_alloc_consistent(dev->pdev, size, &fibptr->hw_fib_pa);
+		memset(((char *)kfib) + dev->max_fib_size, 0, size - dev->max_fib_size);
+		memcpy(kfib, hw_fib, dev->max_fib_size);
 	}
 
-	if (copy_from_user((void *) kfib, arg, le32_to_cpu(kfib->header.Size) + sizeof(struct aac_fibhdr))) {
-		fib_free(fibptr);
-		return -EFAULT;
+	if (copy_from_user((void *) kfib, arg, size)) {
+		retval = -EFAULT;
+		goto cleanup;
 	}
 
 	if (kfib->header.Command == cpu_to_le32(TakeABreakPt)) {
@@ -92,16 +103,14 @@ static int ioctl_send_fib(struct aac_dev
 		 */
 		kfib->header.XferState = 0;
 	} else {
-		int retval = fib_send(kfib->header.Command, fibptr,
+		retval = fib_send(kfib->header.Command, fibptr,
 				le32_to_cpu(kfib->header.Size) , FsaNormal,
 				1, 1, NULL, NULL);
-		if (retval) {
-			fib_free(fibptr);
-			return retval;
-		}
+		if (retval != 0)
+			goto cleanup;
 		if (fib_complete(fibptr) != 0) {
-			fib_free(fibptr);
-			return -EINVAL;
+			retval = -EINVAL;
+			goto cleanup;
 		}
 	}
 	/*
@@ -112,9 +121,14 @@ static int ioctl_send_fib(struct aac_dev
 	 *	was already included by the adapter.)
 	 */
 
-	if (copy_to_user(arg, (void *)kfib, kfib->header.Size)) {
-		fib_free(fibptr);
-		return -EFAULT;
+	retval = 0;
+	if (copy_to_user(arg, (void *)kfib, kfib->header.Size))
+		retval = -EFAULT;
+cleanup:
+	if (hw_fib) {
+		pci_free_consistent(dev->pdev, size, kfib, fibptr->hw_fib_pa);
+		fibptr->hw_fib_pa = hw_fib_pa;
+		fibptr->hw_fib = hw_fib;
 	}
 	fib_free(fibptr);
 	return 0;
@@ -127,7 +141,7 @@ static int ioctl_send_fib(struct aac_dev
  *	passed in from the user.
  */
 
-static int open_getadapter_fib(struct aac_dev * dev, void __user *arg)
+static int open_getadapter_fib(struct aac_dev * dev, void *arg)
 {
 	struct aac_fib_context * fibctx;
 	int status;
@@ -142,7 +156,7 @@ static int open_getadapter_fib(struct aa
 
 		fibctx->type = FSAFS_NTC_GET_ADAPTER_FIB_CONTEXT;
 		fibctx->size = sizeof(struct aac_fib_context);
- 		/*
+		/*
 		 *	Yes yes, I know this could be an index, but we have a
 		 * better guarantee of uniqueness for the locked loop below.
 		 * Without the aid of a persistent history, this also helps
@@ -168,7 +182,7 @@ static int open_getadapter_fib(struct aa
 		spin_lock_irqsave(&dev->fib_lock, flags);
 		/* Ensure that we have a unique identifier */
 		entry = dev->fib_list.next;
-		while (entry != &dev->fib_list) {
+		while(entry != &dev->fib_list) {
 			context = list_entry(entry, struct aac_fib_context, next);
 			if (context->unique == fibctx->unique) {
 				/* Not unique (32 bits) */
@@ -180,8 +194,8 @@ static int open_getadapter_fib(struct aa
 		}
 		list_add_tail(&fibctx->next, &dev->fib_list);
 		spin_unlock_irqrestore(&dev->fib_lock, flags);
-		if (copy_to_user(arg,  &fibctx->unique, 
-						sizeof(fibctx->unique))) {
+		if (copy_to_user(arg,  &fibctx->unique,
+					sizeof(fibctx->unique))) {
 			status = -EFAULT;
 		} else {
 			status = 0;
@@ -199,17 +213,18 @@ static int open_getadapter_fib(struct aa
  *	passed in from the user.
  */
 
-static int next_getadapter_fib(struct aac_dev * dev, void __user *arg)
+static int next_getadapter_fib(struct aac_dev * dev, void *arg)
 {
 	struct fib_ioctl f;
-	struct fib *fib;
 	struct aac_fib_context *fibctx;
+	struct fib * fib;
 	int status;
 	struct list_head * entry;
 	unsigned long flags;
 	
 	if(copy_from_user((void *)&f, arg, sizeof(struct fib_ioctl)))
 		return -EFAULT;
+
 	/*
 	 *	Verify that the HANDLE passed in was a valid AdapterFibContext
 	 *
@@ -219,12 +234,12 @@ static int next_getadapter_fib(struct aa
 	entry = dev->fib_list.next;
 	fibctx = NULL;
 
-	while (entry != &dev->fib_list) {
+	while(entry != &dev->fib_list) {
 		fibctx = list_entry(entry, struct aac_fib_context, next);
 		/*
 		 *	Extract the AdapterFibContext from the Input parameters.
 		 */
-		if (fibctx->unique == f.fibctx) {   /* We found a winner */
+		if(fibctx->unique == f.fibctx) {   /* We found a winner */
 			break;
 		}
 		entry = entry->next;
@@ -269,7 +284,6 @@ return_fib:
 		kfree(fib->hw_fib);
 		kfree(fib);
 		status = 0;
-		fibctx->jiffies = jiffies/HZ;
 	} else {
 		spin_unlock_irqrestore(&dev->fib_lock, flags);
 		if (f.wait) {
@@ -284,6 +298,7 @@ return_fib:
 			status = -EAGAIN;
 		}	
 	}
+	fibctx->jiffies = jiffies/HZ;
 	return status;
 }
 
@@ -332,7 +347,7 @@ int aac_close_fib_context(struct aac_dev
  *	This routine will close down the fibctx passed in from the user.
  */
  
-static int close_getadapter_fib(struct aac_dev * dev, void __user *arg)
+static int close_getadapter_fib(struct aac_dev * dev, void *arg)
 {
 	struct aac_fib_context *fibctx;
 	int status;
@@ -354,15 +369,14 @@ static int close_getadapter_fib(struct a
 		/*
 		 *	Extract the fibctx from the input parameters
 		 */
-		if (fibctx->unique == (u32)(unsigned long)arg) {   
-			/* We found a winner */
+		if(fibctx->unique == (u32)(unsigned long)arg) {   /* We found a winner */
 			break;
 		}
 		entry = entry->next;
 		fibctx = NULL;
 	}
 
-	if (!fibctx)
+	if(!fibctx)
 		return 0; /* Already gone */
 
 	if((fibctx->type != FSAFS_NTC_GET_ADAPTER_FIB_CONTEXT) ||
@@ -380,17 +394,22 @@ static int close_getadapter_fib(struct a
  *	@arg: ioctl arguments
  *
  *	This routine returns the driver version.
- *      Under Linux, there have been no version incompatibilities, so this is 
- *      simple!
+ *      Under Linux, there have been no version incompatibilities, so
+ *	this is simple!
  */
 
-static int check_revision(struct aac_dev *dev, void __user *arg)
+static int check_revision(struct aac_dev *dev, void *arg)
 {
 	struct revision response;
+	extern unsigned long aac_driver_version;
 
 	response.compat = 1;
-	response.version = dev->adapter_info.kernelrev;
-	response.build = dev->adapter_info.kernelbuild;
+	response.version = aac_driver_version;
+#	if (defined(AAC_DRIVER_BUILD))
+		response.build = AAC_DRIVER_BUILD;
+#	else
+		response.build = 9999;
+#	endif
 
 	if (copy_to_user(arg, &response, sizeof(response)))
 		return -EFAULT;
@@ -403,20 +422,20 @@ static int check_revision(struct aac_dev
  *
  */
 
-int aac_send_raw_srb(struct aac_dev* dev, void __user * arg)
+int aac_send_raw_srb(struct aac_dev* dev, void* arg)
 {
 	struct fib* srbfib;
 	int status;
 	struct aac_srb *srbcmd;
-	struct aac_srb __user *user_srb = arg;
-	struct aac_srb_reply __user *user_reply;
+	struct aac_srb *user_srb = arg;
+	struct aac_srb_reply* user_reply;
 	struct aac_srb_reply* reply;
 	u32 fibsize = 0;
 	u32 flags = 0;
 	s32 rcode = 0;
 	u32 data_dir;
-	void __user *sg_user[32];
-	void *sg_list[32];
+	ulong sg_user[32];
+	ulong sg_list[32];
 	u32   sg_indx = 0;
 	u32 byte_count = 0;
 	u32 actual_fibsize = 0;
@@ -424,7 +443,7 @@ int aac_send_raw_srb(struct aac_dev* dev
 
 
 	if (!capable(CAP_SYS_ADMIN)){
-		printk(KERN_DEBUG"aacraid: No permission to send raw srb\n"); 
+		dprintk((KERN_DEBUG"aacraid: No permission to send raw srb\n")); 
 		return -EPERM;
 	}
 	/*
@@ -437,19 +456,19 @@ int aac_send_raw_srb(struct aac_dev* dev
 
 	srbcmd = (struct aac_srb*) fib_data(srbfib);
 
-	if(copy_from_user(&fibsize, &user_srb->count,sizeof(u32))){
-		printk(KERN_DEBUG"aacraid: Could not copy data size from user\n"); 
+	if(copy_from_user((void*)&fibsize, (void*)&user_srb->count,sizeof(u32))){
+		dprintk((KERN_DEBUG"aacraid: Could not copy data size from user\n")); 
 		rcode = -EFAULT;
 		goto cleanup;
 	}
 
-	if (fibsize > FIB_DATA_SIZE_IN_BYTES) {
+	if (fibsize > (dev->max_fib_size - sizeof(struct aac_fibhdr))) {
 		rcode = -EINVAL;
 		goto cleanup;
 	}
 
 	if(copy_from_user(srbcmd, user_srb,fibsize)){
-		printk(KERN_DEBUG"aacraid: Could not copy srb from user\n"); 
+		dprintk((KERN_DEBUG"aacraid: Could not copy srb from user\n")); 
 		rcode = -EFAULT;
 		goto cleanup;
 	}
@@ -460,14 +479,14 @@ int aac_send_raw_srb(struct aac_dev* dev
 	// Fix up srb for endian and force some values
 	srbcmd->function = cpu_to_le32(SRBF_ExecuteScsi);	// Force this
 	srbcmd->channel  = cpu_to_le32(srbcmd->channel);
-	srbcmd->id	 = cpu_to_le32(srbcmd->id);
+	srbcmd->id       = cpu_to_le32(srbcmd->id);
 	srbcmd->lun      = cpu_to_le32(srbcmd->lun);
 	srbcmd->flags    = cpu_to_le32(srbcmd->flags);
 	srbcmd->timeout  = cpu_to_le32(srbcmd->timeout);
 	srbcmd->retry_limit =cpu_to_le32(0); // Obsolete parameter
 	srbcmd->cdb_size = cpu_to_le32(srbcmd->cdb_size);
 	
-	switch (srbcmd->flags & (SRB_DataIn | SRB_DataOut)) {
+	switch(srbcmd->flags & (SRB_DataIn | SRB_DataOut)){
 	case SRB_DataOut:
 		data_dir = DMA_TO_DEVICE;
 		break;
@@ -480,23 +499,21 @@ int aac_send_raw_srb(struct aac_dev* dev
 	default:
 		data_dir = DMA_NONE;
 	}
-	if (dev->pae_support == 1) {
+	if (dev->dac_support == 1) {
 		struct sgmap64* psg = (struct sgmap64*)&srbcmd->sg;
 		byte_count = 0;
 
-		/*
-		 * This should also catch if user used the 32 bit sgmap
-		 */
-		actual_fibsize = sizeof(struct aac_srb) - 
-			sizeof(struct sgentry) + ((srbcmd->sg.count & 0xff) * 
-			 	sizeof(struct sgentry64));
+		// This should also catch if user used the 32 bit sgmap
+		actual_fibsize = sizeof (struct aac_srb) -
+			sizeof(struct sgentry) + ((srbcmd->sg.count & 0xff) *
+				sizeof (struct sgentry64));
 		if(actual_fibsize != fibsize){ // User made a mistake - should not continue
-			printk(KERN_DEBUG"aacraid: Bad Size specified in Raw SRB command\n");
+			dprintk((KERN_DEBUG"aacraid: Bad Size specified in Raw SRB command\n"));
 			rcode = -EINVAL;
 			goto cleanup;
 		}
-		if ((data_dir == DMA_NONE) && psg->count) { 
-			printk(KERN_DEBUG"aacraid: SG with no direction specified in Raw SRB command\n");
+		if ((data_dir == DMA_NONE) && psg->count) { // Dogs and cats sleeping with eachother - should not continue
+			dprintk((KERN_DEBUG"aacraid: SG with no direction specified in Raw SRB command\n"));
 			rcode = -EINVAL;
 			goto cleanup;
 		}
@@ -507,18 +524,18 @@ int aac_send_raw_srb(struct aac_dev* dev
 			void* p;
 			p = kmalloc(psg->sg[i].count,GFP_KERNEL|__GFP_DMA);
 			if(p == 0) {
-				printk(KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
-				psg->sg[i].count,i,psg->count);
+				dprintk((KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
+				  psg->sg[i].count,i,psg->count));
 				rcode = -ENOMEM;
 				goto cleanup;
 			}
-			sg_user[i] = (void __user *)psg->sg[i].addr;
-			sg_list[i] = p; // save so we can clean up later
-			sg_indx = i;
+			sg_user[i] = (ulong)psg->sg[i].addr;
+			sg_list[i] = (ulong)p; // save so we can clean up later
+			sg_indx = i + 1;
 
 			if( flags & SRB_DataOut ){
-				if(copy_from_user(p,sg_user[i],psg->sg[i].count)){
-					printk(KERN_DEBUG"aacraid: Could not copy sg data from user\n"); 
+				if(copy_from_user(p,psg->sg[i].addr,psg->sg[i].count)){
+					dprintk((KERN_DEBUG"aacraid: Could not copy sg data from user\n")); 
 					rcode = -EFAULT;
 					goto cleanup;
 				}
@@ -533,19 +550,19 @@ int aac_send_raw_srb(struct aac_dev* dev
 		}
 
 		srbcmd->count = cpu_to_le32(byte_count);
-		status = fib_send(ScsiPortCommand64, srbfib, actual_fibsize, FsaNormal, 1, 1,NULL,NULL);
+		status = fib_send(ScsiPortCommand64, srbfib, actual_fibsize, FsaNormal, 1, 1,0,0);
 	} else {
 		struct sgmap* psg = &srbcmd->sg;
 		byte_count = 0;
 
 		actual_fibsize = sizeof (struct aac_srb) + (((srbcmd->sg.count & 0xff) - 1) * sizeof (struct sgentry));
 		if(actual_fibsize != fibsize){ // User made a mistake - should not continue
-			printk(KERN_DEBUG"aacraid: Bad Size specified in Raw SRB command\n");
+			dprintk((KERN_DEBUG"aacraid: Bad Size specified in Raw SRB command\n"));
 			rcode = -EINVAL;
 			goto cleanup;
 		}
-		if ((data_dir == DMA_NONE) && psg->count) {
-			printk(KERN_DEBUG"aacraid: SG with no direction specified in Raw SRB command\n");
+		if ((data_dir == DMA_NONE) && psg->count) { // Dogs and cats sleeping with eachother - should not continue
+			dprintk((KERN_DEBUG"aacraid: SG with no direction specified in Raw SRB command\n"));
 			rcode = -EINVAL;
 			goto cleanup;
 		}
@@ -554,18 +571,18 @@ int aac_send_raw_srb(struct aac_dev* dev
 			void* p;
 			p = kmalloc(psg->sg[i].count,GFP_KERNEL);
 			if(p == 0) {
-				printk(KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
-				psg->sg[i].count,i,psg->count);
+				dprintk((KERN_DEBUG"aacraid: Could not allocate SG buffer - size = %d buffer number %d of %d\n",
+				  psg->sg[i].count,i,psg->count));
 				rcode = -ENOMEM;
 				goto cleanup;
 			}
-			sg_user[i] = (void __user *)(psg->sg[i].addr);
-			sg_list[i] = p; // save so we can clean up later
-			sg_indx = i;
+			sg_user[i] = (ulong)(psg->sg[i].addr);
+			sg_list[i] = (ulong)p; // save so we can clean up later
+			sg_indx = i + 1;
 
 			if( flags & SRB_DataOut ){
-				if(copy_from_user(p,sg_user[i],psg->sg[i].count)){
-					printk(KERN_DEBUG"aacraid: Could not copy sg data from user\n"); 
+				if(copy_from_user((void*)p,(void*)(ulong)(psg->sg[i].addr),psg->sg[i].count)){
+					dprintk((KERN_DEBUG"aacraid: Could not copy sg data from user\n")); 
 					rcode = -EFAULT;
 					goto cleanup;
 				}
@@ -577,19 +594,19 @@ int aac_send_raw_srb(struct aac_dev* dev
 			byte_count += psg->sg[i].count;
 		}
 		srbcmd->count = cpu_to_le32(byte_count);
-		status = fib_send(ScsiPortCommand, srbfib, actual_fibsize, FsaNormal, 1, 1, NULL, NULL);
+		status = fib_send(ScsiPortCommand, srbfib, actual_fibsize, FsaNormal, 1, 1, 0, 0);
 	}
 
 	if (status != 0){
-		printk(KERN_DEBUG"aacraid: Could not send raw srb fib to hba\n"); 
+		dprintk((KERN_DEBUG"aacraid: Could not send raw srb fib to hba\n")); 
 		rcode = -1;
 		goto cleanup;
 	}
 
 	if( flags & SRB_DataIn ) {
-		for(i = 0 ; i <= sg_indx; i++){
-			if(copy_to_user(sg_user[i],sg_list[i],le32_to_cpu(srbcmd->sg.sg[i].count))){
-				printk(KERN_DEBUG"aacraid: Could not copy sg data to user\n"); 
+		for (i = 0 ; i < sg_indx; i++) {
+			if(copy_to_user((void*)(sg_user[i]),(void*)(sg_list[i]),le32_to_cpu(srbcmd->sg.sg[i].count))){
+				dprintk((KERN_DEBUG"aacraid: Could not copy sg data to user\n")); 
 				rcode = -EFAULT;
 				goto cleanup;
 
@@ -599,14 +616,14 @@ int aac_send_raw_srb(struct aac_dev* dev
 
 	reply = (struct aac_srb_reply *) fib_data(srbfib);
 	if(copy_to_user(user_reply,reply,sizeof(struct aac_srb_reply))){
-		printk(KERN_DEBUG"aacraid: Could not copy reply to user\n"); 
+		dprintk((KERN_DEBUG"aacraid: Could not copy reply to user\n")); 
 		rcode = -EFAULT;
 		goto cleanup;
 	}
 
 cleanup:
-	for(i=0; i <= sg_indx; i++){
-		kfree(sg_list[i]);
+	for (i=0; i < sg_indx; i++) {
+		kfree((void*)sg_list[i]);
 	}
 	fib_complete(srbfib);
 	fib_free(srbfib);
@@ -621,22 +638,22 @@ struct aac_pci_info {
 };
 
 
-int aac_get_pci_info(struct aac_dev* dev, void __user *arg)
+int aac_get_pci_info(struct aac_dev* dev, void* arg)
 {
         struct aac_pci_info pci_info;
 
 	pci_info.bus = dev->pdev->bus->number;
 	pci_info.slot = PCI_SLOT(dev->pdev->devfn);
 
-       if (copy_to_user(arg, &pci_info, sizeof(struct aac_pci_info))) {
-		printk(KERN_DEBUG "aacraid: Could not copy pci info\n");
+       if(copy_to_user( arg, (void*)&pci_info, sizeof(struct aac_pci_info))){
+               dprintk((KERN_DEBUG "aacraid: Could not copy pci info\n"));
                return -EFAULT;
 	}
         return 0;
- }
+}
  
 
-int aac_do_ioctl(struct aac_dev * dev, int cmd, void __user *arg)
+int aac_do_ioctl(struct aac_dev * dev, int cmd, void *arg)
 {
 	int status;
 	
@@ -645,8 +662,9 @@ int aac_do_ioctl(struct aac_dev * dev, i
 	 */
 	 
 	status = aac_dev_ioctl(dev, cmd, arg);
-	if(status != -ENOTTY)
+	if (status != -ENOTTY) {
 		return status;
+	}
 
 	switch (cmd) {
 	case FSACTL_MINIPORT_REV_CHECK:
diff -urNp linux-2.6.8/drivers/scsi/aacraid/comminit.c linux-2.6.8.SUSE/drivers/scsi/aacraid/comminit.c
--- linux-2.6.8/drivers/scsi/aacraid/comminit.c	2004-08-14 07:36:13.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/comminit.c	2004-07-30 19:42:15.000000000 +0200
@@ -41,16 +41,21 @@
 #include <linux/mm.h>
 #include <asm/semaphore.h>
 
+#include <scsi/scsi.h>
+#include <scsi/scsi_host.h>
+
 #include "aacraid.h"
 
-struct aac_common aac_config;
+struct aac_common aac_config = {
+	.irq_mod = 1
+};
 
 static int aac_alloc_comm(struct aac_dev *dev, void **commaddr, unsigned long commsize, unsigned long commalign)
 {
 	unsigned char *base;
 	unsigned long size, align;
-	unsigned long fibsize = 4096;
-	unsigned long printfbufsiz = 256;
+	const unsigned long fibsize = 4096;
+	const unsigned long printfbufsiz = 256;
 	struct aac_init *init;
 	dma_addr_t phys;
 
@@ -74,6 +79,8 @@ static int aac_alloc_comm(struct aac_dev
 	init = dev->init;
 
 	init->InitStructRevision = cpu_to_le32(ADAPTER_INIT_STRUCT_REVISION);
+	if (dev->max_fib_size != sizeof(struct hw_fib))
+		init->InitStructRevision = cpu_to_le32(ADAPTER_INIT_STRUCT_REVISION_4);
 	init->MiniPortRevision = cpu_to_le32(Sa_MINIPORT_REVISION);
 	init->fsrev = cpu_to_le32(dev->fsrev);
 
@@ -83,6 +90,7 @@ static int aac_alloc_comm(struct aac_dev
 	 */
 	dev->aif_base_va = (struct hw_fib *)base;
 	
+	/* We submit the physical address for AIF tags to limit to 32 bits */
 	init->AdapterFibsVirtualAddress = cpu_to_le32(0);
 	init->AdapterFibsPhysicalAddress = cpu_to_le32((u32)phys);
 	init->AdapterFibsSize = cpu_to_le32(fibsize);
@@ -94,22 +102,21 @@ static int aac_alloc_comm(struct aac_dev
 	 * mapping system, but older Firmware did, and had *troubles* dealing
 	 * with the math overloading past 32 bits, thus we must limit this
 	 * field.
-	 *
-	 * This assumes the memory is mapped zero->n, which isnt
-	 * always true on real computers. It also has some slight problems
-	 * with the GART on x86-64. I've btw never tried DMA from PCI space
-	 * on this platform but don't be suprised if its problematic.
 	 */
-#ifndef CONFIG_GART_IOMMU
 	if ((num_physpages << (PAGE_SHIFT - 12)) <= AAC_MAX_HOSTPHYSMEMPAGES) {
 		init->HostPhysMemPages = 
 			cpu_to_le32(num_physpages << (PAGE_SHIFT-12));
-	} else 
-#endif	
-	{
+	} else {
 		init->HostPhysMemPages = cpu_to_le32(AAC_MAX_HOSTPHYSMEMPAGES);
 	}
-
+	init->InitFlags = 0;
+	if (dev->new_comm_interface) {
+		init->InitFlags = INITFLAGS_NEW_COMM_SUPPORTED;
+		dprintk((KERN_WARNING"aacraid: New Comm Interface enabled\n"));
+	}
+	init->MaxIoCommands = dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB;
+	init->MaxIoSize = dev->scsi_host_ptr->max_sectors << 9;
+	init->MaxFibSize = dev->max_fib_size;
 
 	/*
 	 * Increment the base address by the amount already used
@@ -173,6 +180,8 @@ int aac_send_shutdown(struct aac_dev * d
 	int status;
 
 	fibctx = fib_alloc(dev);
+	if (!fibctx)
+		return -ENOMEM;
 	fib_init(fibctx);
 
 	cmd = (struct aac_close *) fib_data(fibctx);
@@ -293,6 +302,101 @@ int aac_comm_init(struct aac_dev * dev)
 
 struct aac_dev *aac_init_adapter(struct aac_dev *dev)
 {
+	u32 status[5];
+	struct Scsi_Host * host = dev->scsi_host_ptr;
+
+	/*
+	 *	Check the preferred comm settings, defaults from template.
+	 */
+	dev->max_fib_size = sizeof(struct hw_fib);
+	dev->sg_tablesize = host->sg_tablesize = (dev->max_fib_size
+		- sizeof(struct aac_fibhdr)
+		- sizeof(struct aac_write) + sizeof(struct sgmap))
+			/ sizeof(struct sgmap);
+	dev->new_comm_interface = 0;
+	dev->raw_io_64 = 0;
+	if ((!aac_adapter_sync_cmd(dev, GET_ADAPTER_PROPERTIES,
+	  0, 0, 0, 0, 0, 0, 0,
+	  status+0, status+1, status+2, NULL, NULL))
+	 && (status[0] == 0x00000001)) {
+		if (status[1] & AAC_OPT_NEW_COMM_64)
+			dev->raw_io_64 = 1;
+		if (status[1] & AAC_OPT_NEW_COMM)
+			dev->new_comm_interface = dev->a_ops.adapter_send != 0;
+		if (dev->new_comm_interface
+		 && (status[2] > AAC_MIN_FOOTPRINT_SIZE)) {
+			iounmap((void * )dev->regs.sa);
+			dprintk((KERN_DEBUG "ioremap(%lx,%d)\n",
+			  dev->scsi_host_ptr->base, status[2]));
+			if ((dev->regs.sa = (struct sa_registers *)ioremap(
+			  (unsigned long)dev->scsi_host_ptr->base, status[2]))
+			  == NULL) {
+				/* remap failed, go back ... */
+				dev->new_comm_interface = 0;
+				if ((dev->regs.sa
+				  = (struct sa_registers *)ioremap(
+				    (unsigned long)dev->scsi_host_ptr->base,
+				    AAC_MIN_FOOTPRINT_SIZE)) == NULL) {	
+					printk(KERN_WARNING
+					  "aacraid: unable to map adapter.\n");
+					return NULL;
+				}
+			}
+		}
+	}
+	if ((!aac_adapter_sync_cmd(dev, GET_COMM_PREFERRED_SETTINGS,
+	  0, 0, 0, 0, 0, 0, 0,
+	  status+0, status+1, status+2, status+3, status+4))
+	 && (status[0] == 0x00000001)) {
+		extern int acbsize;
+		/*
+		 *	status[1] >> 16		maximum command size in KB
+		 *	status[1] & 0xFFFF	maximum FIB size
+		 *	status[2] >> 16		maximum SG elements to driver
+		 *	status[2] & 0xFFFF	maximum SG elements from driver
+		 *	status[3] & 0xFFFF	maximum number FIBs outstanding
+		 */
+		host->max_sectors = (status[1] >> 16) << 1;
+		dev->max_fib_size = status[1] & 0xFFFF;
+		host->sg_tablesize = status[2] >> 16;
+		dev->sg_tablesize = status[2] & 0xFFFF;
+		host->can_queue = (status[3] & 0xFFFF) - AAC_NUM_MGT_FIB;
+		/*
+		 *	NOTE:
+		 *	All these overrides are based on a fixed internal
+		 *	knowledge and understanding of existing adapters,
+		 *	acbsize should be set with caution.
+		 */
+		if (acbsize == 512) {
+			host->max_sectors = AAC_MAX_32BIT_SGBCOUNT;
+			dev->max_fib_size = 512;
+			dev->sg_tablesize = host->sg_tablesize
+			  = (512 - sizeof(struct aac_fibhdr)
+			    - sizeof(struct aac_write) + sizeof(struct sgmap))
+			     / sizeof(struct sgmap);
+			host->can_queue = AAC_NUM_IO_FIB;
+		} else if (acbsize == 2048) {
+			host->max_sectors = 512;
+			dev->max_fib_size = 2048;
+			host->sg_tablesize = 65;
+			dev->sg_tablesize = 81;
+			host->can_queue = 512 - AAC_NUM_MGT_FIB;
+		} else if (acbsize == 4096) {
+			host->max_sectors = 1024;
+			dev->max_fib_size = 4096;
+			host->sg_tablesize = 129;
+			dev->sg_tablesize = 166;
+			host->can_queue = 256 - AAC_NUM_MGT_FIB;
+		} else if (acbsize == 8192) {
+			host->max_sectors = 2048;
+			dev->max_fib_size = 8192;
+			host->sg_tablesize = 257;
+			dev->sg_tablesize = 337;
+			host->can_queue = 128 - AAC_NUM_MGT_FIB;
+		} else if (acbsize > 0) {
+			printk("Illegal acbsize=%d ignored\n", acbsize);
+		}
+	}
 	/*
 	 *	Ok now init the communication subsystem
 	 */
@@ -312,7 +416,8 @@ struct aac_dev *aac_init_adapter(struct 
 	 *	Initialize the list of fibs
 	 */
 	if(fib_setup(dev)<0){
-		kfree(dev->queues);
+		if (dev->queues)
+			kfree(dev->queues);
 		return NULL;
 	}
 		
diff -urNp linux-2.6.8/drivers/scsi/aacraid/commsup.c linux-2.6.8.SUSE/drivers/scsi/aacraid/commsup.c
--- linux-2.6.8/drivers/scsi/aacraid/commsup.c	2004-09-06 17:02:22.894098719 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/commsup.c	2004-07-30 19:42:16.000000000 +0200
@@ -25,7 +25,7 @@
  *  commsup.c
  *
  * Abstract: Contain all routines that are required for FSA host/adapter
- *    commuication.
+ *    communication.
  *
  */
 
@@ -36,8 +36,13 @@
 #include <linux/pci.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
+#include <linux/delay.h>
 #include <linux/completion.h>
 #include <linux/blkdev.h>
+#include <scsi/scsi.h>
+#include <scsi/scsi_host.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_driver.h>
 #include <asm/semaphore.h>
 
 #include "aacraid.h"
@@ -52,7 +57,13 @@
  
 static int fib_map_alloc(struct aac_dev *dev)
 {
-	if((dev->hw_fib_va = pci_alloc_consistent(dev->pdev, sizeof(struct hw_fib) * AAC_NUM_FIB, &dev->hw_fib_pa))==NULL)
+	dprintk((KERN_INFO
+	  "allocate hardware fibs pci_alloc_consistent(%p, %d * (%d + %d), %p)\n",
+	  dev->pdev, dev->max_fib_size, dev->scsi_host_ptr->can_queue,
+	  AAC_NUM_MGT_FIB, &dev->hw_fib_pa));
+	if((dev->hw_fib_va = pci_alloc_consistent(dev->pdev, dev->max_fib_size
+	  * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB),
+	  &dev->hw_fib_pa))==NULL)
 		return -ENOMEM;
 	return 0;
 }
@@ -67,7 +78,7 @@ static int fib_map_alloc(struct aac_dev 
 
 void fib_map_free(struct aac_dev *dev)
 {
-	pci_free_consistent(dev->pdev, sizeof(struct hw_fib) * AAC_NUM_FIB, dev->hw_fib_va, dev->hw_fib_pa);
+	pci_free_consistent(dev->pdev, dev->max_fib_size * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB), dev->hw_fib_va, dev->hw_fib_pa);
 }
 
 /**
@@ -85,16 +96,21 @@ int fib_setup(struct aac_dev * dev)
 	dma_addr_t hw_fib_pa;
 	int i;
 	
-	if(fib_map_alloc(dev)<0)
+	while (((i = fib_map_alloc(dev)) == -ENOMEM)
+	 && (dev->scsi_host_ptr->can_queue > (64 - AAC_NUM_MGT_FIB))) {
+		dev->init->MaxIoCommands = (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB) >> 1;
+		dev->scsi_host_ptr->can_queue = dev->init->MaxIoCommands - AAC_NUM_MGT_FIB;
+	}
+	if (i<0)
 		return -ENOMEM;
 		
 	hw_fib_va = dev->hw_fib_va;
 	hw_fib_pa = dev->hw_fib_pa;
-	memset(hw_fib_va, 0, sizeof(struct hw_fib) * AAC_NUM_FIB);
+	memset(hw_fib_va, 0, dev->max_fib_size * (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB));
 	/*
 	 *	Initialise the fibs
 	 */
-	for (i = 0, fibptr = &dev->fibs[i]; i < AAC_NUM_FIB; i++, fibptr++) 
+	for (i = 0, fibptr = &dev->fibs[i]; i < (dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB); i++, fibptr++) 
 	{
 		fibptr->dev = dev;
 		fibptr->hw_fib = hw_fib_va;
@@ -102,16 +118,16 @@ int fib_setup(struct aac_dev * dev)
 		fibptr->next = fibptr+1;	/* Forward chain the fibs */
 		init_MUTEX_LOCKED(&fibptr->event_wait);
 		spin_lock_init(&fibptr->event_lock);
-		hw_fib_va->header.XferState = cpu_to_le32(0xffffffff);
-		hw_fib_va->header.SenderSize = cpu_to_le16(sizeof(struct hw_fib));
+		hw_fib_va->header.XferState = 0xffffffff;
+		hw_fib_va->header.SenderSize = cpu_to_le16(dev->max_fib_size);
 		fibptr->hw_fib_pa = hw_fib_pa;
-		hw_fib_va = (struct hw_fib *)((unsigned char *)hw_fib_va + sizeof(struct hw_fib));
-		hw_fib_pa = hw_fib_pa + sizeof(struct hw_fib); 
+		hw_fib_va = (struct hw_fib *)((unsigned char *)hw_fib_va + dev->max_fib_size);
+		hw_fib_pa = hw_fib_pa + dev->max_fib_size;
 	}
 	/*
 	 *	Add the fib chain to the free list
 	 */
-	dev->fibs[AAC_NUM_FIB-1].next = NULL;
+	dev->fibs[dev->scsi_host_ptr->can_queue + AAC_NUM_MGT_FIB - 1].next = NULL;
 	/*
 	 *	Enable this to debug out of queue space
 	 */
@@ -124,7 +140,7 @@ int fib_setup(struct aac_dev * dev)
  *	@dev: Adapter to allocate the fib for
  *
  *	Allocate a fib from the adapter fib pool. If the pool is empty we
- *	wait for fibs to become free.
+ *	return NULL.
  */
  
 struct fib * fib_alloc(struct aac_dev *dev)
@@ -133,10 +149,10 @@ struct fib * fib_alloc(struct aac_dev *d
 	unsigned long flags;
 	spin_lock_irqsave(&dev->fib_lock, flags);
 	fibptr = dev->free_fib;	
-	/* Cannot sleep here or you get hangs. Instead we did the
-	   maths at compile time. */
-	if(!fibptr)
-		BUG();
+	if(!fibptr){
+		spin_unlock_irqrestore(&dev->fib_lock, flags);
+		return fibptr;
+	}
 	dev->free_fib = fibptr->next;
 	spin_unlock_irqrestore(&dev->fib_lock, flags);
 	/*
@@ -148,10 +164,9 @@ struct fib * fib_alloc(struct aac_dev *d
 	 *	Null out fields that depend on being zero at the start of
 	 *	each I/O
 	 */
-	fibptr->hw_fib->header.XferState = cpu_to_le32(0);
+	fibptr->hw_fib->header.XferState = 0;
 	fibptr->callback = NULL;
 	fibptr->callback_data = NULL;
-
 	return fibptr;
 }
 
@@ -175,7 +190,7 @@ void fib_free(struct fib * fibptr)
 	} else {
 		if (fibptr->hw_fib->header.XferState != 0) {
 			printk(KERN_WARNING "fib_free, XferState != 0, fibptr = 0x%p, XferState = 0x%x\n", 
-				 (void*)fibptr, fibptr->hw_fib->header.XferState);
+				 (void*)fibptr, le32_to_cpu(fibptr->hw_fib->header.XferState));
 		}
 		fibptr->next = fibptr->dev->free_fib;
 		fibptr->dev->free_fib = fibptr;
@@ -195,11 +210,11 @@ void fib_init(struct fib *fibptr)
 	struct hw_fib *hw_fib = fibptr->hw_fib;
 
 	hw_fib->header.StructType = FIB_MAGIC;
-	hw_fib->header.Size = cpu_to_le16(sizeof(struct hw_fib));
-        hw_fib->header.XferState = cpu_to_le32(HostOwned | FibInitialized | FibEmpty | FastResponseCapable);
-	hw_fib->header.SenderFibAddress = cpu_to_le32(fibptr->hw_fib_pa);
+	hw_fib->header.Size = cpu_to_le16(fibptr->dev->max_fib_size);
+	hw_fib->header.XferState = cpu_to_le32(HostOwned | FibInitialized | FibEmpty | FastResponseCapable);
+	hw_fib->header.SenderFibAddress = 0; /* Filled in later if needed */
 	hw_fib->header.ReceiverFibAddress = cpu_to_le32(fibptr->hw_fib_pa);
-	hw_fib->header.SenderSize = cpu_to_le16(sizeof(struct hw_fib));
+	hw_fib->header.SenderSize = cpu_to_le16(fibptr->dev->max_fib_size);
 }
 
 /**
@@ -215,7 +230,7 @@ void fib_dealloc(struct fib * fibptr)
 	struct hw_fib *hw_fib = fibptr->hw_fib;
 	if(hw_fib->header.StructType != FIB_MAGIC) 
 		BUG();
-	hw_fib->header.XferState = cpu_to_le32(0);        
+	hw_fib->header.XferState = 0;        
 }
 
 /*
@@ -241,6 +256,7 @@ void fib_dealloc(struct fib * fibptr)
 static int aac_get_entry (struct aac_dev * dev, u32 qid, struct aac_entry **entry, u32 * index, unsigned long *nonotify)
 {
 	struct aac_queue * q;
+	unsigned long idx;
 
 	/*
 	 *	All of the queues wrap when they reach the end, so we check
@@ -251,9 +267,22 @@ static int aac_get_entry (struct aac_dev
 
 	q = &dev->queues->queue[qid];
 	
-	*index = le32_to_cpu(*(q->headers.producer));
-	if ((*index - 2) == le32_to_cpu(*(q->headers.consumer)))
+	idx = *index = le32_to_cpu(*(q->headers.producer));
+	/* Interrupt Moderation, only interrupt for first two entries */
+	if (idx != le32_to_cpu(*(q->headers.consumer))) {
+		if (--idx == 0) {
+			if (qid == AdapHighCmdQueue)
+				idx = ADAP_HIGH_CMD_ENTRIES;
+			else if (qid == AdapNormCmdQueue)
+				idx = ADAP_NORM_CMD_ENTRIES;
+			else if (qid == AdapHighRespQueue) 
+	        		idx = ADAP_HIGH_RESP_ENTRIES;
+			else if (qid == AdapNormRespQueue) 
+				idx = ADAP_NORM_RESP_ENTRIES;
+		}
+		if (idx != le32_to_cpu(*(q->headers.consumer)))
 			*nonotify = 1; 
+	}
 
 	if (qid == AdapHighCmdQueue) {
 	        if (*index >= ADAP_HIGH_CMD_ENTRIES)
@@ -278,7 +307,7 @@ static int aac_get_entry (struct aac_dev
 	}
 
         if ((*index + 1) == le32_to_cpu(*(q->headers.consumer))) { /* Queue is full */
-		printk(KERN_WARNING "Queue %d full, %d outstanding.\n",
+		printk(KERN_WARNING "Queue %d full, %ld outstanding.\n",
 				qid, q->numpending);
 		return 0;
 	} else {
@@ -307,10 +336,7 @@ static int aac_queue_get(struct aac_dev 
 {
 	struct aac_entry * entry = NULL;
 	int map = 0;
-	struct aac_queue * q = &dev->queues->queue[qid];
 		
-	spin_lock_irqsave(q->lock, q->SavedIrql);
-	    
 	if (qid == AdapHighCmdQueue || qid == AdapNormCmdQueue) 
 	{
 		/*  if no entries wait for some if caller wants to */
@@ -348,42 +374,6 @@ static int aac_queue_get(struct aac_dev 
 	return 0;
 }
 
-
-/**
- *	aac_insert_entry	-	insert a queue entry
- *	@dev: Adapter
- *	@index: Index of entry to insert
- *	@qid: Queue number
- *	@nonotify: Suppress adapter notification
- *
- *	Gets the next free QE off the requested priorty adapter command
- *	queue and associates the Fib with the QE. The QE represented by
- *	index is ready to insert on the queue when this routine returns
- *	success.
- */
- 
-static int aac_insert_entry(struct aac_dev * dev, u32 index, u32 qid, unsigned long nonotify) 
-{
-	struct aac_queue * q = &dev->queues->queue[qid];
-
-	if(q == NULL)
-		BUG();
-	*(q->headers.producer) = cpu_to_le32(index + 1);
-	spin_unlock_irqrestore(q->lock, q->SavedIrql);
-
-	if (qid == AdapHighCmdQueue ||
-	    qid == AdapNormCmdQueue ||
-	    qid == AdapHighRespQueue ||
-	    qid == AdapNormRespQueue)
-	{
-		if (!nonotify)
-			aac_adapter_notify(dev, qid);
-	}
-	else
-		printk("Suprise insert!\n");
-	return 0;
-}
-
 /*
  *	Define the highest level of host to adapter communication routines. 
  *	These routines will support host to adapter FS commuication. These 
@@ -408,23 +398,25 @@ static int aac_insert_entry(struct aac_d
  *	an event to wait on must be supplied. This event will be set when a
  *	response FIB is received from the adapter.
  */
- 
-int fib_send(u16 command, struct fib * fibptr, unsigned long size,  int priority, int wait, int reply, fib_callback callback, void * callback_data)
+
+int aac_fib_send(u16 command, struct fib * fibptr, unsigned long size,
+		int priority, int wait, int reply, fib_callback callback,
+		void * callback_data)
 {
-	u32 index;
 	u32 qid;
 	struct aac_dev * dev = fibptr->dev;
-	unsigned long nointr = 0;
 	struct hw_fib * hw_fib = fibptr->hw_fib;
 	struct aac_queue * q;
 	unsigned long flags = 0;
-	if (!(le32_to_cpu(hw_fib->header.XferState) & HostOwned))
+	unsigned long qflags;
+
+	if (!(hw_fib->header.XferState & cpu_to_le32(HostOwned)))
 		return -EBUSY;
 	/*
 	 *	There are 5 cases with the wait and reponse requested flags. 
 	 *	The only invalid cases are if the caller requests to wait and
 	 *	does not request a response and if the caller does not want a
-	 *	response and the Fibis not allocated from pool. If a response
+	 *	response and the Fib is not allocated from pool. If a response
 	 *	is not requesed the Fib will just be deallocaed by the DPC
 	 *	routine when the response comes back from the adapter. No
 	 *	further processing will be done besides deleting the Fib. We 
@@ -447,7 +439,7 @@ int fib_send(u16 command, struct fib * f
 	 *	Map the fib into 32bits by using the fib number
 	 */
 
-	hw_fib->header.SenderFibAddress = cpu_to_le32(((u32)(fibptr-dev->fibs)) << 1);
+	hw_fib->header.SenderFibAddress = cpu_to_le32(((u32)(fibptr - dev->fibs)) << 2);
 	hw_fib->header.SenderData = (u32)(fibptr - dev->fibs);
 	/*
 	 *	Set FIB state to indicate where it came from and if we want a
@@ -477,19 +469,7 @@ int fib_send(u16 command, struct fib * f
 		hw_fib->header.XferState |= cpu_to_le32(NormalPriority);
 		qid = AdapNormCmdQueue;
 	}
-	q = &dev->queues->queue[qid];
 
-	if(wait)
-		spin_lock_irqsave(&fibptr->event_lock, flags);
-	if(aac_queue_get( dev, &index, qid, hw_fib, 1, fibptr, &nointr)<0)
-		return -EWOULDBLOCK;
-	dprintk((KERN_DEBUG "fib_send: inserting a queue entry at index %d.\n",index));
-	dprintk((KERN_DEBUG "Fib contents:.\n"));
-	dprintk((KERN_DEBUG "  Command =               %d.\n", hw_fib->header.Command));
-	dprintk((KERN_DEBUG "  XferState  =            %x.\n", hw_fib->header.XferState));
-	dprintk((KERN_DEBUG "  hw_fib va being sent=%p\n",fibptr->hw_fib));
-	dprintk((KERN_DEBUG "  hw_fib pa being sent=%lx\n",(ulong)fibptr->hw_fib_pa));
-	dprintk((KERN_DEBUG "  fib being sent=%p\n",fibptr));
 	/*
 	 *	Fill in the Callback and CallbackContext if we are not
 	 *	going to wait.
@@ -498,15 +478,56 @@ int fib_send(u16 command, struct fib * f
 		fibptr->callback = callback;
 		fibptr->callback_data = callback_data;
 	}
-	FIB_COUNTER_INCREMENT(aac_config.FibsSent);
-	list_add_tail(&fibptr->queue, &q->pendingq);
-	q->numpending++;
 
 	fibptr->done = 0;
 	fibptr->flags = 0;
 
-	if(aac_insert_entry(dev, index, qid, (nointr & aac_config.irq_mod)) < 0)
-		return -EWOULDBLOCK;
+	FIB_COUNTER_INCREMENT(aac_config.FibsSent);
+
+	dprintk((KERN_DEBUG "Fib contents:.\n"));
+	dprintk((KERN_DEBUG "  Command =               %d.\n", le32_to_cpu(hw_fib->header.Command)));
+	dprintk((KERN_DEBUG "  SubCommand =            %d.\n", le32_to_cpu(((struct aac_query_mount *)fib_data(fibptr))->command)));
+	dprintk((KERN_DEBUG "  XferState  =            %x.\n", le32_to_cpu(hw_fib->header.XferState)));
+	dprintk((KERN_DEBUG "  hw_fib va being sent=%p\n",fibptr->hw_fib));
+	dprintk((KERN_DEBUG "  hw_fib pa being sent=%lx\n",(ulong)fibptr->hw_fib_pa));
+	dprintk((KERN_DEBUG "  fib being sent=%p\n",fibptr));
+
+	q = &dev->queues->queue[qid];
+
+	if(wait)
+		spin_lock_irqsave(&fibptr->event_lock, flags);
+	spin_lock_irqsave(q->lock, qflags);
+	if (dev->new_comm_interface) {
+		unsigned long count = 10000000L; /* 50 seconds */
+		list_add_tail(&fibptr->queue, &q->pendingq);
+		q->numpending++;
+		spin_unlock_irqrestore(q->lock, qflags);
+		while (aac_adapter_send(fibptr) != 0) {
+			if (--count == 0) {
+				if (wait)
+					spin_unlock_irqrestore(&fibptr->event_lock, flags);
+				spin_lock_irqsave(q->lock, qflags);
+				q->numpending--;
+				list_del(&fibptr->queue);
+				spin_unlock_irqrestore(q->lock, qflags);
+				return -ETIMEDOUT;
+			}
+			udelay(5);
+		}
+	} else {
+		u32 index;
+		unsigned long nointr = 0;
+		aac_queue_get( dev, &index, qid, hw_fib, 1, fibptr, &nointr);
+
+		list_add_tail(&fibptr->queue, &q->pendingq);
+		q->numpending++;
+		*(q->headers.producer) = cpu_to_le32(index + 1);
+		spin_unlock_irqrestore(q->lock, qflags);
+		dprintk((KERN_DEBUG "fib_send: inserting a queue entry at index %d.\n",index));
+		if (!(nointr & aac_config.irq_mod))
+			aac_adapter_notify(dev, qid);
+	}
+
 	/*
 	 *	If the caller wanted us to wait for response wait now. 
 	 */
@@ -631,13 +652,22 @@ int fib_adapter_complete(struct fib * fi
 {
 	struct hw_fib * hw_fib = fibptr->hw_fib;
 	struct aac_dev * dev = fibptr->dev;
+	struct aac_queue * q;
 	unsigned long nointr = 0;
-	if (le32_to_cpu(hw_fib->header.XferState) == 0)
+	unsigned long qflags;
+	u32 qid;
+
+	if (hw_fib->header.XferState == 0) {
+		if (dev->new_comm_interface)
+			kfree (hw_fib);
         	return 0;
+	}
 	/*
 	 *	If we plan to do anything check the structure type first.
 	 */ 
 	if ( hw_fib->header.StructType != FIB_MAGIC ) {
+		if (dev->new_comm_interface)
+			kfree (hw_fib);
         	return -EINVAL;
 	}
 	/*
@@ -648,37 +678,30 @@ int fib_adapter_complete(struct fib * fi
 	 *	send the completed cdb to the adapter.
 	 */
 	if (hw_fib->header.XferState & cpu_to_le32(SentFromAdapter)) {
-	        hw_fib->header.XferState |= cpu_to_le32(HostProcessed);
-	        if (hw_fib->header.XferState & cpu_to_le32(HighPriority)) {
-        		u32 index;
-       			if (size) 
-			{
-				size += sizeof(struct aac_fibhdr);
-				if (size > le16_to_cpu(hw_fib->header.SenderSize))
-					return -EMSGSIZE;
-				hw_fib->header.Size = cpu_to_le16(size);
-			}
-			if(aac_queue_get(dev, &index, AdapHighRespQueue, hw_fib, 1, NULL, &nointr) < 0) {
-				return -EWOULDBLOCK;
-			}
-			if (aac_insert_entry(dev, index, AdapHighRespQueue,  (nointr & (int)aac_config.irq_mod)) != 0) {
-			}
-		}
-		else if (hw_fib->header.XferState & NormalPriority) 
-		{
-			u32 index;
-
+		if (dev->new_comm_interface) {
+			kfree (hw_fib);
+		} else {
+	       		u32 index;
+		        hw_fib->header.XferState |= cpu_to_le32(HostProcessed);
+		        if (hw_fib->header.XferState & cpu_to_le32(HighPriority))
+				qid = AdapHighRespQueue;
+			else if (hw_fib->header.XferState & cpu_to_le32(NormalPriority))
+				qid = AdapNormRespQueue;
+			else
+				return 0;
 			if (size) {
 				size += sizeof(struct aac_fibhdr);
 				if (size > le16_to_cpu(hw_fib->header.SenderSize)) 
 					return -EMSGSIZE;
 				hw_fib->header.Size = cpu_to_le16(size);
 			}
-			if (aac_queue_get(dev, &index, AdapNormRespQueue, hw_fib, 1, NULL, &nointr) < 0) 
-				return -EWOULDBLOCK;
-			if (aac_insert_entry(dev, index, AdapNormRespQueue, (nointr & (int)aac_config.irq_mod)) != 0) 
-			{
-			}
+			q = &dev->queues->queue[qid];
+			spin_lock_irqsave(q->lock, qflags);
+			aac_queue_get(dev, &index, qid, hw_fib, 1, NULL, &nointr);
+			*(q->headers.producer) = cpu_to_le32(index + 1);
+			spin_unlock_irqrestore(q->lock, qflags);
+			if (!(nointr & (int)aac_config.irq_mod))
+				aac_adapter_notify(dev, qid);
 		}
 	}
 	else 
@@ -704,7 +727,7 @@ int fib_complete(struct fib * fibptr)
 	 *	Check for a fib which has already been completed
 	 */
 
-	if (hw_fib->header.XferState == cpu_to_le32(0))
+	if (hw_fib->header.XferState == 0)
         	return 0;
 	/*
 	 *	If we plan to do anything check the structure type first.
@@ -749,9 +772,10 @@ int fib_complete(struct fib * fibptr)
 
 void aac_printf(struct aac_dev *dev, u32 val)
 {
+	char *cp = dev->printfbuf;
+#ifdef AAC_PRINTF_ENABLED
 	int length = val & 0xffff;
 	int level = (val >> 16) & 0xffff;
-	char *cp = dev->printfbuf;
 	
 	/*
 	 *	The size of the printfbuf is set in port.c
@@ -761,10 +785,11 @@ void aac_printf(struct aac_dev *dev, u32
 		length = 255;
 	if (cp[length] != 0)
 		cp[length] = 0;
-	if (level == LOG_AAC_HIGH_ERROR)
+	if (level == AAC_LOG_HIGH_ERROR)
 		printk(KERN_WARNING "aacraid:%s", cp);
 	else
 		printk(KERN_INFO "aacraid:%s", cp);
+#endif
 	memset(cp, 0,  256);
 }
 
@@ -781,13 +806,225 @@ void aac_printf(struct aac_dev *dev, u32
 static void aac_handle_aif(struct aac_dev * dev, struct fib * fibptr)
 {
 	struct hw_fib * hw_fib = fibptr->hw_fib;
+	struct aac_aifcmd * aifcmd = (struct aac_aifcmd *)hw_fib->data;
+	int busy;
+	u32 container;
+	struct scsi_device *device;
+	struct scsi_driver * drv;
+	enum {
+		NOTHING,
+		DELETE,
+		ADD,
+		CHANGE
+	} DeviceConfigNeeded;
+
+	/* Sniff for container changes */
+	dprintk ((KERN_INFO "aac_handle_aif: Aif command=%x type=%x\n",
+	  le32_to_cpu(aifcmd->command), le32_to_cpu(*(u32 *)aifcmd->data)));
+
+	DeviceConfigNeeded = NOTHING;
+
+	/*
+	 *	We have set this up to try and minimize the number of
+	 * re-configures that take place. As a result of this when
+	 * certain AIF's come in we will set a flag waiting for another
+	 * type of AIF before setting the re-config flag.
+	 */
+	switch (le32_to_cpu(aifcmd->command)) {
+	case AifCmdDriverNotify:
+		switch (le32_to_cpu(((u32 *)aifcmd->data)[0])) {
+		/*
+		 *	Morph or Expand complete
+		 */
+		case AifDenMorphComplete:
+		case AifDenVolumeExtendComplete:
+			container = le32_to_cpu(((u32 *)aifcmd->data)[1]);
+			if (container >= dev->maximum_num_containers)
+				break;
+			dprintk ((KERN_INFO "container=%d(%d,%d,%d,%d)\n",
+			  container,
+			  (dev && dev->scsi_host_ptr)
+			    ? dev->scsi_host_ptr->host_no
+			    : -1,
+			  CONTAINER_TO_CHANNEL(container),
+			  CONTAINER_TO_ID(container),
+			  CONTAINER_TO_LUN(container)));
+
+			/*
+			 *	Find the Scsi_Device associated with the SCSI
+			 * address. Make sure we have the right array, and if
+			 * so set the flag to initiate a new re-config once we
+			 * see an AifEnConfigChange AIF come through.
+			 */
+
+			if ((dev != (struct aac_dev *)NULL)
+			 && (dev->scsi_host_ptr != (struct Scsi_Host *)NULL)) {
+				shost_for_each_device(device, dev->scsi_host_ptr)
+				{
+					if ((device->channel == CONTAINER_TO_CHANNEL(container))
+					 && (device->id == CONTAINER_TO_ID(container))
+					 && (device->lun == CONTAINER_TO_LUN(container))) {
+						dev->DeviceContainerID = container;
+						dev->DeviceConfigNeeded = CHANGE;
+						dev->DeviceConfigWaitingOn = AifEnConfigChange;
+						break;
+					}
+				}
+			}
+		}
+
+		/*
+		 *	If we are waiting on something and this happens to be
+		 * that thing then set the re-configure flag.
+		 */
+		if (dev->DeviceConfigWaitingOn == le32_to_cpu(*(u32 *)aifcmd->data)) {
+			DeviceConfigNeeded = dev->DeviceConfigNeeded;
+		}
+		break;
+
+	case AifCmdEventNotify:
+		switch (le32_to_cpu(((u32 *)aifcmd->data)[0])) {
+		/*
+		 *	Add an Array.
+		 */
+		case AifEnAddContainer:
+			container = le32_to_cpu(((u32 *)aifcmd->data)[1]);
+			if (container >= dev->maximum_num_containers)
+				break;
+			dev->DeviceContainerID = container;
+			dev->DeviceConfigNeeded = ADD;
+			dev->DeviceConfigWaitingOn = AifEnConfigChange;
+			break;
+
+		/*
+		 *	Delete an Array.
+		 */
+		case AifEnDeleteContainer:
+			container = le32_to_cpu(((u32 *)aifcmd->data)[1]);
+			if (container >= dev->maximum_num_containers)
+				break;
+			dev->DeviceContainerID = container;
+			dev->DeviceConfigNeeded = DELETE;
+			dev->DeviceConfigWaitingOn = AifEnConfigChange;
+			break;
+
+		/*
+		 *	Container change detected. If we currently are not
+		 * waiting on something else, setup to wait on a Config Change.
+		 */
+		case AifEnContainerChange:
+			container = le32_to_cpu(((u32 *)aifcmd->data)[1]);
+			if (container >= dev->maximum_num_containers)
+				break;
+			dev->DeviceContainerID = container;
+			if (dev->DeviceConfigWaitingOn) {
+				break;
+			}
+			dev->DeviceConfigNeeded = CHANGE;
+			dev->DeviceConfigWaitingOn = AifEnConfigChange;
+			break;
+		}
+
+		/*
+		 *	If we are waiting on something and this happens to be
+		 * that thing then set the re-configure flag.
+		 */
+		if (dev->DeviceConfigWaitingOn == le32_to_cpu(*(u32 *)aifcmd->data)) {
+			DeviceConfigNeeded = dev->DeviceConfigNeeded;
+		}
+		break;
+
+	case AifCmdJobProgress:
+		/*
+		 *	These are job progress AIF's. When a Clear is being
+		 * done on a container it is initially created then hidden from
+		 * the OS. When the clear completes we don't get a config
+		 * change so we monitor the job status complete on a clear then
+		 * wait for a containe change.
+		 */
+
+		if ((((u32 *)aifcmd->data)[1] == cpu_to_le32(AifJobCtrZero))
+		 && ((((u32 *)aifcmd->data)[6] == ((u32 *)aifcmd->data)[5])
+		  || (((u32 *)aifcmd->data)[4] == cpu_to_le32(AifJobStsSuccess)))) {
+			dev->DeviceContainerID = -1;
+			dev->DeviceConfigWaitingOn = AifEnContainerChange;
+			dev->DeviceConfigNeeded = ADD;
+		}
+		break;
+	}
+
+	if (DeviceConfigNeeded == NOTHING) {
+		return;
+	}
+
 	/*
-	 * Set the status of this FIB to be Invalid parameter.
-	 *
-	 *	*(u32 *)fib->data = ST_INVAL;
+	 *	If we decided that a re-configuration needs to be done,
+	 * schedule it here on the way out the door, please close the door
+	 * behind you.
+	 */
+	dev->DeviceConfigWaitingOn = 0;
+	dev->DeviceConfigNeeded = NOTHING;
+	container = dev->DeviceContainerID;
+	dev->DeviceContainerID = -1;
+
+	busy = 0;
+
+	dprintk ((KERN_INFO "container=%d(%d,%d,%d,%d)\n",
+	  container,
+	  (dev && dev->scsi_host_ptr)
+	    ? dev->scsi_host_ptr->host_no
+	    : -1,
+	  CONTAINER_TO_CHANNEL(container),
+	  CONTAINER_TO_ID(container),
+	  CONTAINER_TO_LUN(container)));
+
+	/*
+	 *	Find the Scsi_Device associated with the SCSI address,
+	 * and mark it as changed, invalidating the cache. This deals
+	 * with changes to existing device IDs.
 	 */
-	*(u32 *)hw_fib->data = cpu_to_le32(ST_OK);
-	fib_adapter_complete(fibptr, sizeof(u32));
+
+	if (!dev || !dev->scsi_host_ptr) {
+		return;
+	}
+	shost_for_each_device(device, dev->scsi_host_ptr)
+	{
+		dprintk((KERN_INFO "aifd: device (%d,%d,%d,%d)?\n",
+		  dev->scsi_host_ptr->host_no,
+		  device->channel,
+		  device->id,
+		  device->lun));
+		if ((device->channel == CONTAINER_TO_CHANNEL(container))
+		 && (device->id == CONTAINER_TO_ID(container))
+		 && (device->lun == CONTAINER_TO_LUN(container))) {
+			busy |= device->device_busy || test_bit(SHOST_RECOVERY, &dev->scsi_host_ptr->shost_state);
+			if (busy == 0) {
+				device->removable = 1;
+				switch (DeviceConfigNeeded) {
+				case CHANGE:
+					/*
+					 * force reload of disk info via probe_container
+					 */
+					if (dev->fsa_dev[container].valid == 1)
+						dev->fsa_dev[container].valid = 2;
+//					scsi_rescan_device(&device->sdev_gendev);
+					drv = to_scsi_driver(
+						device->sdev_gendev.driver);
+					if(drv->rescan)
+						drv->rescan(&device->sdev_gendev);
+					break;
+				case DELETE:
+					break;
+				case ADD:
+					break;
+				default:
+					break;
+				}
+			}
+		}
+	}
+	dprintk (("busy=%d\n", busy));
+
 }
 
 /**
@@ -804,7 +1041,7 @@ int aac_command_thread(struct aac_dev * 
 {
 	struct hw_fib *hw_fib, *hw_newfib;
 	struct fib *fib, *newfib;
-	struct aac_queue_block *queues = dev->queues;
+	struct aac_queue *q = &dev->queues->queue[HostNormCmdQueue];
 	struct aac_fib_context *fibctx;
 	unsigned long flags;
 	DECLARE_WAITQUEUE(wait, current);
@@ -824,21 +1061,22 @@ int aac_command_thread(struct aac_dev * 
 	 *	Let the DPC know it has a place to send the AIF's to.
 	 */
 	dev->aif_thread = 1;
-	add_wait_queue(&queues->queue[HostNormCmdQueue].cmdready, &wait);
+	add_wait_queue(&q->cmdready, &wait);
 	set_current_state(TASK_INTERRUPTIBLE);
+	dprintk ((KERN_INFO "aac_command_thread start\n"));
 	while(1) 
 	{
-		spin_lock_irqsave(queues->queue[HostNormCmdQueue].lock, flags);
-		while(!list_empty(&(queues->queue[HostNormCmdQueue].cmdq))) {
+		spin_lock_irqsave(q->lock, flags);
+		while(!list_empty(&(q->cmdq))) {
 			struct list_head *entry;
 			struct aac_aifcmd * aifcmd;
 
 			set_current_state(TASK_RUNNING);
-		
-			entry = queues->queue[HostNormCmdQueue].cmdq.next;
+
+			entry = q->cmdq.next;
 			list_del(entry);
-			
-			spin_unlock_irqrestore(queues->queue[HostNormCmdQueue].lock, flags);
+	
+			spin_unlock_irqrestore(q->lock, flags);
 			fib = list_entry(entry, struct fib, fiblink);
 			/*
 			 *	We will process the FIB here or pass it to a 
@@ -847,12 +1085,14 @@ int aac_command_thread(struct aac_dev * 
 			 *	anything defined for this thread to do.
 			 */
 			hw_fib = fib->hw_fib;
+
 			memset(fib, 0, sizeof(struct fib));
 			fib->type = FSAFS_NTC_FIB_CONTEXT;
 			fib->size = sizeof( struct fib );
 			fib->hw_fib = hw_fib;
 			fib->data = hw_fib->data;
 			fib->dev = dev;
+
 			/*
 			 *	We only handle AifRequest fibs from the adapter.
 			 */
@@ -869,13 +1109,59 @@ int aac_command_thread(struct aac_dev * 
 				   
 				u32 time_now, time_last;
 				unsigned long flagv;
+				unsigned num;
+				struct hw_fib ** hw_fib_pool, ** hw_fib_p;
+				struct fib ** fib_pool, ** fib_p;
 				
 				/* Sniff events */
-				if (aifcmd->command == cpu_to_le32(AifCmdEventNotify))
+				if ((aifcmd->command == cpu_to_le32(AifCmdEventNotify))
+				 || (aifcmd->command == cpu_to_le32(AifCmdJobProgress))) {
 					aac_handle_aif(dev, fib);
-				
+				}
+
 				time_now = jiffies/HZ;
 
+				/*
+				 * Warning: no sleep allowed while
+				 * holding spinlock. We take the estimate
+				 * and pre-allocate a set of fibs outside the
+				 * lock.
+				 */
+				num = 0;
+				spin_lock_irqsave(&dev->fib_lock, flagv);
+				entry = dev->fib_list.next;
+				while (entry != &dev->fib_list) {
+					entry = entry->next;
+					++num;
+				}
+				spin_unlock_irqrestore(&dev->fib_lock, flagv);
+				hw_fib_pool = NULL;
+				fib_pool = NULL;
+				if (num
+				 && ((hw_fib_pool = kmalloc(sizeof(struct hw_fib *) * num, GFP_ATOMIC)))
+				 && ((fib_pool = kmalloc(sizeof(struct fib *) * num, GFP_ATOMIC)))) {
+					hw_fib_p = hw_fib_pool;
+					fib_p = fib_pool;
+					while (hw_fib_p < &hw_fib_pool[num]) {
+						if (!(*(hw_fib_p++) = kmalloc(sizeof(struct hw_fib), GFP_ATOMIC))) {
+							--hw_fib_p;
+							break;
+						}
+						if (!(*(fib_p++) = kmalloc(sizeof(struct fib), GFP_ATOMIC))) { 
+							kfree(*(--hw_fib_p));
+							break;
+						}
+					}
+					if ((num = hw_fib_p - hw_fib_pool) == 0) {
+						kfree(fib_pool);
+						fib_pool = NULL;
+						kfree(hw_fib_pool);
+						hw_fib_pool = NULL;
+					}
+				} else if (hw_fib_pool) {
+					kfree(hw_fib_pool);
+					hw_fib_pool = NULL;
+				}
 				spin_lock_irqsave(&dev->fib_lock, flagv);
 				entry = dev->fib_list.next;
 				/*
@@ -884,6 +1170,8 @@ int aac_command_thread(struct aac_dev * 
 				 * fib, and then set the event to wake up the
 				 * thread that is waiting for it.
 				 */
+				hw_fib_p = hw_fib_pool;
+				fib_p = fib_pool;
 				while (entry != &dev->fib_list) {
 					/*
 					 * Extract the fibctx
@@ -895,11 +1183,6 @@ int aac_command_thread(struct aac_dev * 
 					 */
 					if (fibctx->count > 20)
 					{
-						/*
-						 * It's *not* jiffies folks,
-						 * but jiffies / HZ so do not
-						 * panic ...
-						 */
 						time_last = fibctx->jiffies;
 						/*
 						 * Has it been > 2 minutes 
@@ -916,9 +1199,11 @@ int aac_command_thread(struct aac_dev * 
 					 * Warning: no sleep allowed while
 					 * holding spinlock
 					 */
-					hw_newfib = kmalloc(sizeof(struct hw_fib), GFP_ATOMIC);
-					newfib = kmalloc(sizeof(struct fib), GFP_ATOMIC);
-					if (newfib && hw_newfib) {
+					if (hw_fib_p < &hw_fib_pool[num]) {
+						hw_newfib = *hw_fib_p;
+						*(hw_fib_p++) = NULL;
+						newfib = *fib_p;
+						*(fib_p++) = NULL;
 						/*
 						 * Make the copy of the FIB
 						 */
@@ -933,16 +1218,11 @@ int aac_command_thread(struct aac_dev * 
 						fibctx->count++;
 						/* 
 						 * Set the event to wake up the
-						 * thread that will waiting.
+						 * thread that is waiting.
 						 */
 						up(&fibctx->wait_sem);
-					} else {
+					} else
 						printk(KERN_WARNING "aifd: didn't allocate NewFib.\n");
-						if(newfib)
-							kfree(newfib);
-						if(hw_newfib)
-							kfree(hw_newfib);
-					}
 					entry = entry->next;
 				}
 				/*
@@ -951,21 +1231,37 @@ int aac_command_thread(struct aac_dev * 
 				*(u32 *)hw_fib->data = cpu_to_le32(ST_OK);
 				fib_adapter_complete(fib, sizeof(u32));
 				spin_unlock_irqrestore(&dev->fib_lock, flagv);
+				/* Free up the remaining resources */
+				hw_fib_p = hw_fib_pool;
+				fib_p = fib_pool;
+				while (hw_fib_p < &hw_fib_pool[num]) {
+					if (*hw_fib_p)
+						kfree(*hw_fib_p);
+					if (*fib_p)
+						kfree(*fib_p);
+					++fib_p;
+					++hw_fib_p;
+				}
+				if (hw_fib_pool)
+					kfree(hw_fib_pool);
+				if (fib_pool)
+					kfree(fib_pool);
 			}
-			spin_lock_irqsave(queues->queue[HostNormCmdQueue].lock, flags);
 			kfree(fib);
+			spin_lock_irqsave(q->lock, flags);
 		}
 		/*
 		 *	There are no more AIF's
 		 */
-		spin_unlock_irqrestore(queues->queue[HostNormCmdQueue].lock, flags);
+		spin_unlock_irqrestore(q->lock, flags);
 		schedule();
 
 		if(signal_pending(current))
 			break;
 		set_current_state(TASK_INTERRUPTIBLE);
 	}
-	remove_wait_queue(&queues->queue[HostNormCmdQueue].cmdready, &wait);
+	remove_wait_queue(&q->cmdready, &wait);
 	dev->aif_thread = 0;
 	complete_and_exit(&dev->aif_completion, 0);
+	return 0;
 }
diff -urNp linux-2.6.8/drivers/scsi/aacraid/compat.h linux-2.6.8.SUSE/drivers/scsi/aacraid/compat.h
--- linux-2.6.8/drivers/scsi/aacraid/compat.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/compat.h	2004-07-30 19:42:16.000000000 +0200
@@ -0,0 +1,29 @@
+/*
+ *	Adaptec AAC series RAID controller driver
+ *	(c) Copyright 2001 Red Hat Inc.	<alan@redhat.com>
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2, or (at your option)
+ * any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; see the file COPYING.  If not, write to
+ * the Free Software Foundation, 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ */
+/*
+ * This file is for backwards compatibility with older kernel versions
+ */
+
+
+
+
+
+
+    
diff -urNp linux-2.6.8/drivers/scsi/aacraid/dpcsup.c linux-2.6.8.SUSE/drivers/scsi/aacraid/dpcsup.c
--- linux-2.6.8/drivers/scsi/aacraid/dpcsup.c	2004-08-14 07:36:57.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/dpcsup.c	2004-07-30 19:42:16.000000000 +0200
@@ -71,11 +71,12 @@ unsigned int aac_response_normal(struct 
 	while(aac_consumer_get(dev, q, &entry))
 	{
 		int fast;
-		u32 index = le32_to_cpu(entry->addr);
+		u32 index;
+		index = le32_to_cpu(entry->addr);
 		fast = index & 0x01;
-		fib = &dev->fibs[index >> 1];
+		fib = &dev->fibs[index >> 2];
 		hwfib = fib->hw_fib;
-		
+
 		aac_consumer_free(dev, q, HostNormRespQueue);
 		/*
 		 *	Remove this fib from the Outstanding I/O queue.
@@ -90,7 +91,7 @@ unsigned int aac_response_normal(struct 
 			dev->queues->queue[AdapNormCmdQueue].numpending--;
 		} else {
 			printk(KERN_WARNING "aacraid: FIB timeout (%x).\n", fib->flags);
-			printk(KERN_DEBUG"aacraid: hwfib=%p fib index=%i fib=%p\n",hwfib, hwfib->header.SenderData,fib);
+			printk(KERN_DEBUG"aacraid: hwfib=%p index=%i fib=%p\n",hwfib, hwfib->header.SenderData,fib);
 			continue;
 		}
 		spin_unlock_irqrestore(q->lock, flags);
@@ -134,8 +135,9 @@ unsigned int aac_response_normal(struct 
 		spin_lock_irqsave(q->lock, flags);
 	}
 
-	if (consumed > aac_config.peak_fibs)
+	if (consumed > aac_config.peak_fibs) {
 		aac_config.peak_fibs = consumed;
+	}
 	if (consumed == 0) 
 		aac_config.zero_fibs++;
 
@@ -173,19 +175,25 @@ unsigned int aac_command_normal(struct a
 		struct hw_fib * hw_fib;
 		u32 index;
 		struct fib *fib = &fibctx;
-		
-		index = le32_to_cpu(entry->addr) / sizeof(struct hw_fib);
-		hw_fib = &dev->aif_base_va[index];
-		
+
 		/*
-		 *	Allocate a FIB at all costs. For non queued stuff
-		 *	we can just use the stack so we are happy. We need
-		 *	a fib object in order to manage the linked lists
+		 *	Allocate a FIB. For non queued stuff we can just use
+		 * the stack so we are happy. We need a fib object in order to
+		 * manage the linked lists.
 		 */
-		if (dev->aif_thread)
-			if((fib = kmalloc(sizeof(struct fib), GFP_ATOMIC)) == NULL)
+		if (dev->aif_thread) {
+			/* Limit the number we retreive from fib pool */
+			struct list_head * each;
+			int i = (dev->init->AdapterFibsSize / sizeof(struct hw_fib)) - 1;
+			list_for_each(each, &(q->cmdq))
+				if (--i <= 0)
+					break;
+			if ((i <= 0) || (!(fib = kmalloc(sizeof(struct fib),GFP_ATOMIC))))
 				fib = &fibctx;
-		
+		}
+
+		index = le32_to_cpu(entry->addr / sizeof(struct hw_fib));
+		hw_fib = &dev->aif_base_va[index];
 		memset(fib, 0, sizeof(struct fib));
 		INIT_LIST_HEAD(&fib->fiblink);
 		fib->type = FSAFS_NTC_FIB_CONTEXT;
@@ -194,9 +202,9 @@ unsigned int aac_command_normal(struct a
 		fib->data = hw_fib->data;
 		fib->dev = dev;
 		
-				
-		if (dev->aif_thread && fib != &fibctx) {
-		        list_add_tail(&fib->fiblink, &q->cmdq);
+		if (dev->aif_thread && fib != &fibctx)
+		{		
+			list_add_tail(&fib->fiblink, &q->cmdq);
 	 	        aac_consumer_free(dev, q, HostNormCmdQueue);
 		        wake_up_interruptible(&q->cmdready);
 		} else {
@@ -213,3 +221,116 @@ unsigned int aac_command_normal(struct a
 	spin_unlock_irqrestore(q->lock, flags);
 	return 0;
 }
+
+
+/**
+ *	aac_intr_normal	-	Handle command replies
+ *	@dev: Device
+ *	@index: completion reference
+ *
+ *	This DPC routine will be run when the adapter interrupts us to let us
+ *	know there is a response on our normal priority queue. We will pull off
+ *	all QE there are and wake up all the waiters before exiting.
+ */
+
+unsigned int aac_intr_normal(struct aac_dev * dev, u32 Index)
+{
+	u32 index = le32_to_cpu(Index);
+
+	dprintk((KERN_INFO "aac_intr_normal(%p,%x)\n", dev, Index));
+	if ((index & 0x00000002L)) {
+		struct hw_fib * hw_fib;
+		struct fib * fib;
+		struct aac_queue *q = &dev->queues->queue[HostNormCmdQueue];
+		unsigned long flags;
+
+		if (index == 0xFFFFFFFEL) /* Special Case */
+			return 0;	  /* Do nothing */
+		/*
+		 *	Allocate a FIB. For non queued stuff we can just use
+		 * the stack so we are happy. We need a fib object in order to
+		 * manage the linked lists.
+		 */
+		if ((!dev->aif_thread)
+		 || (!(fib = kmalloc(sizeof(struct fib),GFP_ATOMIC))))
+			return 1;
+		if (!(hw_fib = kmalloc(sizeof(struct hw_fib),GFP_ATOMIC))) {
+			kfree (fib);
+			return 1;
+		}
+		memset(hw_fib, 0, sizeof(struct hw_fib));
+		memcpy(hw_fib, (struct hw_fib *)(((char *)(dev->regs.sa)) + (index & ~0x00000002L)), sizeof(struct hw_fib));
+		memset(fib, 0, sizeof(struct fib));
+		INIT_LIST_HEAD(&fib->fiblink);
+		fib->type = FSAFS_NTC_FIB_CONTEXT;
+		fib->size = sizeof(struct fib);
+		fib->hw_fib = hw_fib;
+		fib->data = hw_fib->data;
+		fib->dev = dev;
+		
+		spin_lock_irqsave(q->lock, flags);
+		list_add_tail(&fib->fiblink, &q->cmdq);
+	        wake_up_interruptible(&q->cmdready);
+		spin_unlock_irqrestore(q->lock, flags);
+		return 1;
+	} else {
+		int fast = index & 0x01;
+		struct fib * fib = &dev->fibs[index >> 2];
+		struct hw_fib * hwfib = fib->hw_fib;
+
+		/*
+		 *	Remove this fib from the Outstanding I/O queue.
+		 *	But only if it has not already been timed out.
+		 *
+		 *	If the fib has been timed out already, then just 
+		 *	continue. The caller has already been notified that
+		 *	the fib timed out.
+		 */
+		if ((fib->flags & FIB_CONTEXT_FLAG_TIMED_OUT)) {
+			printk(KERN_WARNING "aacraid: FIB timeout (%x).\n", fib->flags);
+			printk(KERN_DEBUG"aacraid: hwfib=%p index=%i fib=%p\n",hwfib, hwfib->header.SenderData,fib);
+			return 0;
+		}
+
+		list_del(&fib->queue);
+		dev->queues->queue[AdapNormCmdQueue].numpending--;
+
+		if (fast) {
+			/*
+			 *	Doctor the fib
+			 */
+			*(u32 *)hwfib->data = cpu_to_le32(ST_OK);
+			hwfib->header.XferState |= cpu_to_le32(AdapterProcessed);
+		}
+
+		FIB_COUNTER_INCREMENT(aac_config.FibRecved);
+
+		if (hwfib->header.Command == cpu_to_le16(NuFileSystem))
+		{
+			u32 *pstatus = (u32 *)hwfib->data;
+			if (*pstatus & cpu_to_le32(0xffff0000))
+				*pstatus = cpu_to_le32(ST_OK);
+		}
+		if (hwfib->header.XferState & cpu_to_le32(NoResponseExpected | Async)) 
+		{
+	        	if (hwfib->header.XferState & cpu_to_le32(NoResponseExpected))
+				FIB_COUNTER_INCREMENT(aac_config.NoResponseRecved);
+			else 
+				FIB_COUNTER_INCREMENT(aac_config.AsyncRecved);
+			/*
+			 *	NOTE:  we cannot touch the fib after this
+			 *	    call, because it may have been deallocated.
+			 */
+			fib->callback(fib->callback_data, fib);
+		} else {
+			unsigned long flagv;
+	  		dprintk((KERN_INFO "event_wait up\n"));
+			spin_lock_irqsave(&fib->event_lock, flagv);
+			fib->done = 1;
+			up(&fib->event_wait);
+			spin_unlock_irqrestore(&fib->event_lock, flagv);
+			FIB_COUNTER_INCREMENT(aac_config.NormalRecved);
+		}
+		return 0;
+	}
+}
diff -urNp linux-2.6.8/drivers/scsi/aacraid/linit.c linux-2.6.8.SUSE/drivers/scsi/aacraid/linit.c
--- linux-2.6.8/drivers/scsi/aacraid/linit.c	2004-08-14 07:36:56.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/linit.c	2004-07-30 19:42:16.000000000 +0200
@@ -27,9 +27,9 @@
  * Abstract: Linux Driver entry module for Adaptec RAID Array Controller
  */
 
-#define AAC_DRIVER_VERSION		"1.1.2-lk2"
-#define AAC_DRIVER_BUILD_DATE		__DATE__
-#define AAC_DRIVERNAME			"aacraid"
+#define AAC_DRIVER_VERSION		0x01010005
+#define AAC_DRIVER_BUILD_DATE		__DATE__ " " __TIME__
+#define AAC_DRIVER_NAME			"aacraid"
 
 #include <linux/compat.h>
 #include <linux/blkdev.h>
@@ -43,7 +43,7 @@
 #include <linux/slab.h>
 #include <linux/spinlock.h>
 #include <linux/syscalls.h>
-#include <linux/ioctl32.h>
+#include <linux/ioctl.h>
 #include <asm/semaphore.h>
 
 #include <scsi/scsi.h>
@@ -53,6 +53,11 @@
 #include <scsi/scsi_tcq.h>
 #include <scsi/scsicam.h>
 #include <scsi/scsi_eh.h>
+#ifdef CONFIG_COMPAT
+  /* Cast the function, since sys_ioctl does not match */
+# define aac_ioctl32(x,y) register_ioctl32_conversion((x), \
+    (int(*)(unsigned int,unsigned int,unsigned long,struct file*))(y))
+#endif
 
 #include "aacraid.h"
 
@@ -62,19 +67,57 @@ MODULE_DESCRIPTION("Dell PERC2, 2/Si, 3/
 		   "Adaptec Advanced Raid Products, "
 		   "and HP NetRAID-4M SCSI driver");
 MODULE_LICENSE("GPL");
-
-
-int nondasd = -1;
-module_param(nondasd, int, S_IRUGO|S_IWUSR);
-MODULE_PARM_DESC(nondasd, "Control scanning of hba for nondasd devices. 0=off, 1=on");
-
-int paemode = -1;
-module_param(paemode, int, S_IRUGO|S_IWUSR);
-MODULE_PARM_DESC(paemode, "Control whether dma addressing is using PAE. 0=off, 1=on");
+/*
+ * Following bears malice and forethought regarding
+ * MODULE_VERSION, MODULE_INFO and __MODULE_INFO definitions
+ * because you can not get from here to there without this knowledge.
+ * This could break in the future ...
+ */
+#ifdef MODULE
+# if ((AAC_DRIVER_VERSION>>24)&0xFF) >= 10
+#  define AAC_DRIVER_VERSION_DIGIT1 ((((AAC_DRIVER_VERSION>>24)&0xFF)/10)%10)+'0',
+# else
+#  define AAC_DRIVER_VERSION_DIGIT1
+# endif
+# define AAC_DRIVER_VERSION_DIGIT2 (((AAC_DRIVER_VERSION>>24)&0xFF)%10)+'0', '.',
+# if ((AAC_DRIVER_VERSION>>16)&0xFF) >= 10
+#  define AAC_DRIVER_VERSION_DIGIT3 ((((AAC_DRIVER_VERSION>>16)&0xFF)/10)%10)+'0',
+# else
+#  define AAC_DRIVER_VERSION_DIGIT3
+# endif
+# define AAC_DRIVER_VERSION_DIGIT4 (((AAC_DRIVER_VERSION>>16)&0xFF)%10)+'0', '.',
+# if (AAC_DRIVER_VERSION&0xFF) >= 10
+#  define AAC_DRIVER_VERSION_DIGIT5 (((AAC_DRIVER_VERSION&0xFF)/10)%10)+'0',
+# else
+#  define AAC_DRIVER_VERSION_DIGIT5
+# endif
+# define AAC_DRIVER_VERSION_DIGIT6 ((AAC_DRIVER_VERSION&0xFF)%10)+'0',
+# if (defined(AAC_DRIVER_BUILD))
+#  define AAC_DRIVER_BUILD_DIGIT '-', \
+	((AAC_DRIVER_BUILD/1000)%10)+'0', \
+	((AAC_DRIVER_BUILD/100)%10)+'0', \
+	((AAC_DRIVER_BUILD/10)%10)+'0', \
+	(AAC_DRIVER_BUILD%10)+'0',
+# else
+#  define AAC_DRIVER_BUILD_DIGIT
+# endif
+# define AAC_DRIVER_SIGNATURE '\0', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', \
+	'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', 'x', \
+	'x', 'x', '\0'
+  static const char __module_cat(version,__LINE__)[]
+    __attribute_used__
+    __attribute__((section(".modinfo"),unused)) = {
+    'v', 'e', 'r', 's', 'i', 'o', 'n', '=',
+    AAC_DRIVER_VERSION_DIGIT1 AAC_DRIVER_VERSION_DIGIT2
+    AAC_DRIVER_VERSION_DIGIT3 AAC_DRIVER_VERSION_DIGIT4
+    AAC_DRIVER_VERSION_DIGIT5 AAC_DRIVER_VERSION_DIGIT6
+    AAC_DRIVER_BUILD_DIGIT AAC_DRIVER_SIGNATURE };
+#endif
 
 struct aac_dev *aac_devices[MAXIMUM_NUM_ADAPTERS];
 static unsigned aac_count;
 static int aac_cfg_major = -1;
+unsigned long aac_driver_version = AAC_DRIVER_VERSION | 0x00000400;
 
 /*
  * Because of the way Linux names scsi devices, the order in this table has
@@ -83,44 +126,54 @@ static int aac_cfg_major = -1;
  * Note: The last field is used to index into aac_drivers below.
  */
 static struct pci_device_id aac_pci_tbl[] = {
-	{ 0x1028, 0x0001, 0x1028, 0x0001, 0, 0, 0 }, /* PERC 2/Si */
-	{ 0x1028, 0x0002, 0x1028, 0x0002, 0, 0, 1 }, /* PERC 3/Di */
-	{ 0x1028, 0x0003, 0x1028, 0x0003, 0, 0, 2 }, /* PERC 3/Si */
-	{ 0x1028, 0x0004, 0x1028, 0x00d0, 0, 0, 3 }, /* PERC 3/Si */
-	{ 0x1028, 0x0002, 0x1028, 0x00d1, 0, 0, 4 }, /* PERC 3/Di */
-	{ 0x1028, 0x0002, 0x1028, 0x00d9, 0, 0, 5 }, /* PERC 3/Di */
-	{ 0x1028, 0x000a, 0x1028, 0x0106, 0, 0, 6 }, /* PERC 3/Di */
-	{ 0x1028, 0x000a, 0x1028, 0x011b, 0, 0, 7 }, /* PERC 3/Di */
-	{ 0x1028, 0x000a, 0x1028, 0x0121, 0, 0, 8 }, /* PERC 3/Di */
-	{ 0x9005, 0x0283, 0x9005, 0x0283, 0, 0, 9 }, /* catapult*/
-	{ 0x9005, 0x0284, 0x9005, 0x0284, 0, 0, 10 }, /* tomcat*/
-	{ 0x9005, 0x0285, 0x9005, 0x0286, 0, 0, 11 }, /* Adaptec 2120S (Crusader)*/
-	{ 0x9005, 0x0285, 0x9005, 0x0285, 0, 0, 12 }, /* Adaptec 2200S (Vulcan)*/
-	{ 0x9005, 0x0285, 0x9005, 0x0287, 0, 0, 13 }, /* Adaptec 2200S (Vulcan-2m)*/
-	{ 0x9005, 0x0285, 0x17aa, 0x0286, 0, 0, 14 }, /* Legend S220*/
-	{ 0x9005, 0x0285, 0x17aa, 0x0287, 0, 0, 15 }, /* Legend S230*/
-
-	{ 0x9005, 0x0285, 0x9005, 0x0288, 0, 0, 16 }, /* Adaptec 3230S (Harrier)*/
-	{ 0x9005, 0x0285, 0x9005, 0x0289, 0, 0, 17 }, /* Adaptec 3240S (Tornado)*/
-	{ 0x9005, 0x0285, 0x9005, 0x028a, 0, 0, 18 }, /* ASR-2020 ZCR PCI-X U320 */
-	{ 0x9005, 0x0285, 0x9005, 0x028b, 0, 0, 19 }, /* ASR-2025 ZCR DIMM U320 */
-	{ 0x9005, 0x0285, 0x9005, 0x0290, 0, 0, 20 }, /* AAR-2410SA PCI SATA 4ch (Jaguar II)*/
-
-	{ 0x9005, 0x0285, 0x1028, 0x0287, 0, 0, 21 }, /* Perc 320/DC*/
-	{ 0x1011, 0x0046, 0x9005, 0x0365, 0, 0, 22 }, /* Adaptec 5400S (Mustang)*/
-	{ 0x1011, 0x0046, 0x9005, 0x0364, 0, 0, 23 }, /* Adaptec 5400S (Mustang)*/
-	{ 0x1011, 0x0046, 0x9005, 0x1364, 0, 0, 24 }, /* Dell PERC2 "Quad Channel" */
-	{ 0x1011, 0x0046, 0x103c, 0x10c2, 0, 0, 25 }, /* HP NetRAID-4M */
-
+	{ 0x1028, 0x0001, 0x1028, 0x0001, 0, 0, 0 }, /* PERC 2/Si (Iguana/PERC2Si) */
+	{ 0x1028, 0x0002, 0x1028, 0x0002, 0, 0, 1 }, /* PERC 3/Di (Opal/PERC3Di) */
+	{ 0x1028, 0x0003, 0x1028, 0x0003, 0, 0, 2 }, /* PERC 3/Si (SlimFast/PERC3Si */
+	{ 0x1028, 0x0004, 0x1028, 0x00d0, 0, 0, 3 }, /* PERC 3/Di (Iguana FlipChip/PERC3DiF */
+	{ 0x1028, 0x0002, 0x1028, 0x00d1, 0, 0, 4 }, /* PERC 3/Di (Viper/PERC3DiV) */
+	{ 0x1028, 0x0002, 0x1028, 0x00d9, 0, 0, 5 }, /* PERC 3/Di (Lexus/PERC3DiL) */
+	{ 0x1028, 0x000a, 0x1028, 0x0106, 0, 0, 6 }, /* PERC 3/Di (Jaguar/PERC3DiJ) */
+	{ 0x1028, 0x000a, 0x1028, 0x011b, 0, 0, 7 }, /* PERC 3/Di (Dagger/PERC3DiD) */
+	{ 0x1028, 0x000a, 0x1028, 0x0121, 0, 0, 8 }, /* PERC 3/Di (Boxster/PERC3DiB) */
+	{ 0x9005, 0x0283, 0x9005, 0x0283, 0, 0, 9 }, /* catapult */
+	{ 0x9005, 0x0284, 0x9005, 0x0284, 0, 0, 10 }, /* tomcat */
+	{ 0x9005, 0x0285, 0x9005, 0x0286, 0, 0, 11 }, /* Adaptec 2120S (Crusader) */
+	{ 0x9005, 0x0285, 0x9005, 0x0285, 0, 0, 12 }, /* Adaptec 2200S (Vulcan) */
+	{ 0x9005, 0x0285, 0x9005, 0x0287, 0, 0, 13 }, /* Adaptec 2200S (Vulcan-2m) */
+	{ 0x9005, 0x0285, 0x17aa, 0x0286, 0, 0, 14 }, /* Legend S220 (Legend Crusader) */
+	{ 0x9005, 0x0285, 0x17aa, 0x0287, 0, 0, 15 }, /* Legend S230 (Legend Vulcan) */
+
+	{ 0x9005, 0x0285, 0x9005, 0x0288, 0, 0, 16 }, /* Adaptec 3230S (Harrier) */
+	{ 0x9005, 0x0285, 0x9005, 0x0289, 0, 0, 17 }, /* Adaptec 3240S (Tornado) */
+	{ 0x9005, 0x0285, 0x9005, 0x028a, 0, 0, 18 }, /* ASR-2020ZCR SCSI PCI-X ZCR (Skyhawk) */
+	{ 0x9005, 0x0285, 0x9005, 0x028b, 0, 0, 19 }, /* ASR-2025ZCR SCSI SO-DIMM PCI-X ZCR (Terminator) */
+	{ 0x9005, 0x0286, 0x9005, 0x028c, 0, 0, 20 }, /* ASR-2230S + ASR-2230SLP PCI-X (Lancer) */
+	{ 0x9005, 0x0286, 0x9005, 0x028d, 0, 0, 21 }, /* ASR-2130S (Lancer) */
+	{ 0x9005, 0x0286, 0x9005, 0x0800, 0, 0, 22 }, /* Jupiter Platform */
+	{ 0x9005, 0x0285, 0x9005, 0x028e, 0, 0, 23 }, /* ASR-2020SA SATA PCI-X ZCR (Skyhawk) */
+	{ 0x9005, 0x0285, 0x9005, 0x028f, 0, 0, 24 }, /* ASR-2025SA SATA SO-DIMM PCI-X ZCR (Terminator) */
+	{ 0x9005, 0x0285, 0x9005, 0x0290, 0, 0, 25 }, /* AAR-2410SA PCI SATA 4ch (Jaguar II) */
 	{ 0x9005, 0x0285, 0x1028, 0x0291, 0, 0, 26 }, /* CERC SATA RAID 2 PCI SATA 6ch (DellCorsair) */
 	{ 0x9005, 0x0285, 0x9005, 0x0292, 0, 0, 27 }, /* AAR-2810SA PCI SATA 8ch (Corsair-8) */
 	{ 0x9005, 0x0285, 0x9005, 0x0293, 0, 0, 28 }, /* AAR-21610SA PCI SATA 16ch (Corsair-16) */
 	{ 0x9005, 0x0285, 0x9005, 0x0294, 0, 0, 29 }, /* ESD SO-DIMM PCI-X SATA ZCR (Prowler) */
-	{ 0x9005, 0x0285, 0x0E11, 0x0295, 0, 0, 30 }, /* SATA 6Ch (Bearcat) */
-
-	{ 0x9005, 0x0286, 0x9005, 0x028c, 0, 0, 31 }, /* ASR-2230S + ASR-2230SLP PCI-X (Lancer) */
-	{ 0x9005, 0x0285, 0x9005, 0x028e, 0, 0, 32 }, /* ASR-2020SA      (ZCR PCI-X SATA) */
-	{ 0x9005, 0x0285, 0x9005, 0x028f, 0, 0, 33 }, /* ASR-2025SA      (ZCR DIMM SATA) */
+	{ 0x9005, 0x0285, 0x0E11, 0x0295, 0, 0, 30 }, /* AAR-2610SA PCI SATA 6ch */
+	{ 0x9005, 0x0285, 0x9005, 0x0296, 0, 0, 31 }, /* ASR-2240S */
+	{ 0x9005, 0x0285, 0x9005, 0x0296, 0, 0, 32 }, /* ASR-4005SAS */
+	{ 0x9005, 0x0285, 0x9005, 0x0296, 0, 0, 33 }, /* ASR-4000SAS */
+	{ 0x9005, 0x0285, 0x9005, 0x0296, 0, 0, 34 }, /* ASR-4800SAS */
+	{ 0x9005, 0x0285, 0x9005, 0x0296, 0, 0, 35 }, /* ASR-4805SAS */
+
+	{ 0x9005, 0x0285, 0x1028, 0x0287, 0, 0, 36 }, /* Perc 320/DC*/
+	{ 0x1011, 0x0046, 0x9005, 0x0365, 0, 0, 37 }, /* Adaptec 5400S (Mustang)*/
+	{ 0x1011, 0x0046, 0x9005, 0x0364, 0, 0, 38 }, /* Adaptec 5400S (Mustang)*/
+	{ 0x1011, 0x0046, 0x9005, 0x1364, 0, 0, 39 }, /* Dell PERC2/QC */
+	{ 0x1011, 0x0046, 0x103c, 0x10c2, 0, 0, 40 }, /* HP NetRAID-4M */
+
+	{ 0x9005, 0x0285, 0x1028, PCI_ANY_ID, 0, 0, 41 }, /* Dell Catchall */
+	{ 0x9005, 0x0285, 0x17aa, PCI_ANY_ID, 0, 0, 42 }, /* Legend Catchall */
+	{ 0x9005, 0x0285, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 43 }, /* Adaptec Catch All */
+	{ 0x9005, 0x0286, PCI_ANY_ID, PCI_ANY_ID, 0, 0, 44 }, /* Adaptec Rocket Catch All */
 	{ 0,}
 };
 MODULE_DEVICE_TABLE(pci, aac_pci_tbl);
@@ -131,68 +184,75 @@ MODULE_DEVICE_TABLE(pci, aac_pci_tbl);
  * for the card.  At that time we can remove the channels from here
  */
 static struct aac_driver_ident aac_drivers[] = {
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 2/Si */
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di */
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Si */
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Si */
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di */
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di */
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di */
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di */
-	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di */
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "catapult        ", 2, AAC_QUIRK_31BIT }, /* catapult*/
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "tomcat          ", 2, AAC_QUIRK_31BIT }, /* tomcat*/
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2120S   ", 1, AAC_QUIRK_31BIT }, /* Adaptec 2120S (Crusader)*/
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2200S   ", 2, AAC_QUIRK_31BIT }, /* Adaptec 2200S (Vulcan)*/
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2200S   ", 2, AAC_QUIRK_31BIT }, /* Adaptec 2200S (Vulcan-2m)*/
-	{ aac_rx_init, "aacraid",  "Legend  ", "Legend S220     ", 1, AAC_QUIRK_31BIT }, /* Legend S220*/
-	{ aac_rx_init, "aacraid",  "Legend  ", "Legend S230     ", 2, AAC_QUIRK_31BIT }, /* Legend S230*/
-
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 3230S   ", 2 }, /* Adaptec 3230S (Harrier)*/
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 3240S   ", 2 }, /* Adaptec 3240S (Tornado)*/
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2020ZCR     ", 2 }, /* ASR-2020 ZCR PCI-X U320 */
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2025ZCR     ", 2 }, /* ASR-2025 ZCR DIMM U320 */
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "AAR-2410SA SATA ", 2 }, /* AAR-2410SA PCI SATA 4ch (Jaguar II)*/
-
-	{ aac_rx_init, "percraid", "DELL    ", "PERC 320/DC     ", 2, AAC_QUIRK_31BIT }, /* Perc 320/DC*/
-	{ aac_sa_init, "aacraid",  "ADAPTEC ", "Adaptec 5400S   ", 4 }, /* Adaptec 5400S (Mustang)*/
-	{ aac_sa_init, "aacraid",  "ADAPTEC ", "AAC-364         ", 4 }, /* Adaptec 5400S (Mustang)*/
-	{ aac_sa_init, "percraid", "DELL    ", "PERCRAID        ", 4, AAC_QUIRK_31BIT }, /* Dell PERC2 "Quad Channel" */
-	{ aac_sa_init, "hpnraid",  "HP      ", "NetRAID         ", 4 },  /* HP NetRAID-4M */
-
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 2/Si (Iguana/PERC2Si) */
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di (Opal/PERC3Di) */
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Si (SlimFast/PERC3Si */
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di (Iguana FlipChip/PERC3DiF */
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di (Viper/PERC3DiV) */
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di (Lexus/PERC3DiL) */
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 1, AAC_QUIRK_31BIT }, /* PERC 3/Di (Jaguar/PERC3DiJ) */
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di (Dagger/PERC3DiD) */
+	{ aac_rx_init, "percraid", "DELL    ", "PERCRAID        ", 2, AAC_QUIRK_31BIT }, /* PERC 3/Di (Boxster/PERC3DiB) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "catapult        ", 2, AAC_QUIRK_31BIT }, /* catapult */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "tomcat          ", 2, AAC_QUIRK_31BIT }, /* tomcat */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2120S   ", 1, AAC_QUIRK_31BIT }, /* Adaptec 2120S (Crusader) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2200S   ", 2, AAC_QUIRK_31BIT }, /* Adaptec 2200S (Vulcan) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 2200S   ", 2, AAC_QUIRK_31BIT }, /* Adaptec 2200S (Vulcan-2m) */
+	{ aac_rx_init, "aacraid",  "Legend  ", "Legend S220     ", 1, AAC_QUIRK_31BIT }, /* Legend S220 (Legend Crusader) */
+	{ aac_rx_init, "aacraid",  "Legend  ", "Legend S230     ", 2, AAC_QUIRK_31BIT }, /* Legend S230 (Legend Vulcan) */
+
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 3230S   ", 2 }, /* Adaptec 3230S (Harrier) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "Adaptec 3240S   ", 2 }, /* Adaptec 3240S (Tornado) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2020ZCR     ", 2 }, /* ASR-2020ZCR SCSI PCI-X ZCR (Skyhawk) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2025ZCR     ", 2 }, /* ASR-2025ZCR SCSI SO-DIMM PCI-X ZCR (Terminator) */
+	{ aac_rkt_init, "aacraid",  "ADAPTEC ", "ASR-2230S PCI-X ", 2 }, /* ASR-2230S + ASR-2230SLP PCI-X (Lancer) */
+	{ aac_rkt_init, "aacraid",  "ADAPTEC ", "ASR-2130S PCI-X ", 1 }, /* ASR-2130S (Lancer) */
+	{ aac_rkt_init, "aacraid",  "ADAPTEC ", "Callisto        ", 2 }, /* Jupiter Platform */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2020SA       ", 1 }, /* ASR-2020SA SATA PCI-X ZCR (Skyhawk) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2025SA       ", 1 }, /* ASR-2025SA SATA SO-DIMM PCI-X ZCR (Terminator) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "AAR-2410SA SATA ", 1 }, /* AAR-2410SA PCI SATA 4ch (Jaguar II) */
 	{ aac_rx_init, "aacraid",  "DELL    ", "CERC SR2        ", 1 }, /* CERC SATA RAID 2 PCI SATA 6ch (DellCorsair) */
 	{ aac_rx_init, "aacraid",  "ADAPTEC ", "AAR-2810SA SATA ", 1 }, /* AAR-2810SA PCI SATA 8ch (Corsair-8) */
 	{ aac_rx_init, "aacraid",  "ADAPTEC ", "AAR-21610SA SATA", 1 }, /* AAR-21610SA PCI SATA 16ch (Corsair-16) */
 	{ aac_rx_init, "aacraid",  "ADAPTEC ", "SO-DIMM SATA ZCR", 1 }, /* ESD SO-DIMM PCI-X SATA ZCR (Prowler) */
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "SATA 6Channel   ", 1 }, /* SATA 6Ch (Bearcat) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "AAR-2610SA      ", 1 }, /* SATA 6Ch (Bearcat) */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2240S       ", 1 }, /* ASR-2240S */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-4005SAS     ", 1 }, /* ASR-4005SAS */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-4000SAS     ", 1 }, /* ASR-4000SAS */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-4800SAS     ", 1 }, /* ASR-4800SAS */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-4805SAS     ", 1 }, /* ASR-4805SAS */
 
-	{ aac_rkt_init,"aacraid",  "ADAPTEC ", "ASR-2230S PCI-X ", 2 }, /* ASR-2230S + ASR-2230SLP PCI-X (Lancer) */
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2020SA      ", 1 }, /* ASR-2020SA      (ZCR PCI-X SATA) */
-	{ aac_rx_init, "aacraid",  "ADAPTEC ", "ASR-2025SA      ", 1 }, /* ASR-2025SA      (ZCR DIMM SATA) */
+	{ aac_rx_init, "percraid", "DELL    ", "PERC 320/DC     ", 2, AAC_QUIRK_31BIT }, /* Perc 320/DC*/
+	{ aac_sa_init, "aacraid",  "ADAPTEC ", "Adaptec 5400S   ", 4 }, /* Adaptec 5400S (Mustang)*/
+	{ aac_sa_init, "aacraid",  "ADAPTEC ", "AAC-364         ", 4 }, /* Adaptec 5400S (Mustang)*/
+	{ aac_sa_init, "percraid", "DELL    ", "PERCRAID        ", 4, AAC_QUIRK_31BIT }, /* Dell PERC2/QC */
+	{ aac_sa_init, "hpnraid",  "HP      ", "NetRAID         ", 4 }, /* HP NetRAID-4M */
+
+	{ aac_rx_init, "aacraid",  "DELL    ", "RAID            ", 2, AAC_QUIRK_31BIT }, /* Dell Catchall */
+	{ aac_rx_init, "aacraid",  "Legend  ", "RAID            ", 2, AAC_QUIRK_31BIT }, /* Legend Catchall */
+	{ aac_rx_init, "aacraid",  "ADAPTEC ", "RAID            ", 2, AAC_QUIRK_31BIT }, /* Adaptec Catch All */
+	{ aac_rkt_init, "aacraid", "ADAPTEC ", "RAID            ", 2 } /* Adaptec Rocket Catch All */
 };
 
 #ifdef CONFIG_COMPAT
-/* 
- * Promote 32 bit apps that call get_next_adapter_fib_ioctl to 64 bit version 
- */
-static int aac_get_next_adapter_fib_ioctl(unsigned int fd, unsigned int cmd, 
-		unsigned long arg, struct file *file)
+/* Promote 32 bit apps that call get_next_adapter_fib_ioctl to 64 bit version */
+static int aac_get_next_adapter_fib_ioctl(unsigned int fd, unsigned int cmd, unsigned long arg)
 {
-	struct fib_ioctl __user *f;
+	struct fib_ioctl * f;
 
 	f = compat_alloc_user_space(sizeof(*f));
 	if (!access_ok(VERIFY_WRITE, f, sizeof(*f)))
 		return -EFAULT;
 
 	clear_user(f, sizeof(*f));
-	if (copy_in_user(f, (void __user *)arg, sizeof(struct fib_ioctl) - sizeof(u32)))
+	if(copy_from_user((void *)&f, (void *)arg,
+			sizeof(struct fib_ioctl) - sizeof(u32)))
 		return -EFAULT;
-
 	return sys_ioctl(fd, cmd, (unsigned long)f);
 }
+#define sys_ioctl NULL	/* register_ioctl32_conversion defaults to this when NULL passed in as a handler */
 #endif
 
-
 /**
  *	aac_queuecommand	-	queue a SCSI command
  *	@cmd:		SCSI command to queue
@@ -237,8 +297,8 @@ struct aac_driver_ident* aac_get_driver_
 /**
  *	aac_biosparm	-	return BIOS parameters for disk
  *	@sdev: The scsi device corresponding to the disk
- *	@bdev: the block device corresponding to the disk
- *	@capacity: the sector capacity of the disk
+ *	@bdev: The block device corresponding to the disk
+ *	@capacity: The sector capacity of the disk
  *	@geom: geometry block to fill in
  *
  *	Return the Heads/Sectors/Cylinders BIOS Disk Parameters for Disk.  
@@ -256,8 +316,9 @@ struct aac_driver_ident* aac_get_driver_
  *	be displayed.
  */
  
-static int aac_biosparm(struct scsi_device *sdev, struct block_device *bdev,
-			sector_t capacity, int *geom)
+static int aac_biosparm(
+	struct scsi_device *sdev, struct block_device *bdev, sector_t capacity,
+	int *geom)
 {
 	struct diskparm *param = (struct diskparm *)geom;
 	unsigned char *buf;
@@ -282,14 +343,19 @@ static int aac_biosparm(struct scsi_devi
 
 	param->cylinders = cap_to_cyls(capacity, param->heads * param->sectors);
 
+	/*
+	 *	Read the first 1024 bytes from the disk device
+	 */
+
+	buf = scsi_bios_ptable(bdev);
 	/* 
-	 *	Read the first 1024 bytes from the disk device, if the boot
-	 *	sector partition table is valid, search for a partition table
-	 *	entry whose end_head matches one of the standard geometry 
+	 *	If the boot sector partition table is valid, search for a partition 
+	 *	table entry whose end_head matches one of the standard geometry 
 	 *	translations ( 64/32, 128/32, 255/63 ).
 	 */
-	buf = scsi_bios_ptable(bdev);
-	if(*(unsigned short *)(buf + 0x40) == cpu_to_le16(0xaa55)) {
+	 
+	if(*(unsigned short *)(buf + 0x40) == cpu_to_le16(0xaa55))
+	{
 		struct partition *first = (struct partition * )buf;
 		struct partition *entry = first;
 		int saved_cylinders = param->cylinders;
@@ -338,7 +404,7 @@ static int aac_biosparm(struct scsi_devi
 }
 
 /**
- *	aac_queuedepth		-	compute queue depths
+ *	aac_slave_configure		-	compute queue depths
  *	@sdev:	SCSI device we are considering
  *
  *	Selects queue depths for each target device based on the host adapter's
@@ -348,34 +414,83 @@ static int aac_biosparm(struct scsi_devi
 
 static int aac_slave_configure(struct scsi_device *sdev)
 {
-	if (sdev->tagged_supported)
-		scsi_adjust_queue_depth(sdev, MSG_ORDERED_TAG, 128);
-	else
+	if (sdev->tagged_supported) {
+		struct scsi_device * dev;
+		struct Scsi_Host * host = sdev->host;
+		unsigned num_lsu = 0;
+		unsigned num_one = 0;
+		unsigned depth;
+
+		__shost_for_each_device(dev, host) {
+			if (dev->tagged_supported && (dev->type == 0))
+				++num_lsu;
+			else
+				++num_one;
+		}
+		if (num_lsu == 0)
+			++num_lsu;
+		depth = (host->can_queue - num_one) / num_lsu;
+		if (depth > 256)
+			depth = 256;
+		else if (depth < 2)
+			depth = 2;
+		scsi_adjust_queue_depth(sdev, MSG_ORDERED_TAG, depth);
+	} else
 		scsi_adjust_queue_depth(sdev, 0, 1);
 	return 0;
 }
 
-static int aac_ioctl(struct scsi_device *sdev, int cmd, void __user * arg)
+/**
+ *	aac_ioctl 	-	Handle SCSI ioctls
+ *	@sdev: scsi device to operate upon
+ *	@cmd: ioctl command to use issue
+ *	@arg: ioctl data pointer
+ *
+ *	Issue an ioctl on an aacraid device. Returns a standard unix error code or
+ *	zero for success
+ */
+ 
+/*------------------------------------------------------------------------------
+	aac_ioctl()
+
+		Handle SCSI ioctls
+ *----------------------------------------------------------------------------*/
+static int aac_ioctl(struct scsi_device *sdev, int cmd, void * arg)
 {
 	struct aac_dev *dev = (struct aac_dev *)sdev->host->hostdata;
 	return aac_do_ioctl(dev, cmd, arg);
 }
 
-/*
- * XXX: does aac really need no error handling??
+/**
+ *	aac_eh_abort	-	Abort command if possible.
+ *	@cmd:	SCSI command block to abort
+ *
+ *	Called when the midlayer wishes to abort a command. We don't support
+ *	this facility, and our firmware looks after life for us. We just
+ *	report this as failing
  */
 static int aac_eh_abort(struct scsi_cmnd *cmd)
 {
 	return FAILED;
 }
 
-/*
+/**
  *	aac_eh_reset	- Reset command handling
  *	@scsi_cmd:	SCSI command block causing the reset
  *
+ *	Issue a reset of a SCSI host. If things get this bad then arguably we should
+ *	go take a look at what the host adapter is doing and see if something really
+ *	broke (as can occur at least on my Dell QC card if a drive keeps failing spinup)
  */
+#ifdef __arm__
+//DEBUG
+#define AAC_DEBUG_INSTRUMENT_RESET
+#endif
 static int aac_eh_reset(struct scsi_cmnd* cmd)
 {
+#if (!defined(AAC_DEBUG_INSTRUMENT_RESET) && defined(__arm__))
+	return FAILED;
+#else
 	struct scsi_device * dev = cmd->device;
 	struct Scsi_Host * host = dev->host;
 	struct scsi_cmnd * command;
@@ -383,15 +498,135 @@ static int aac_eh_reset(struct scsi_cmnd
 	struct aac_dev * aac;
 	unsigned long flags;
 
-	printk(KERN_ERR "%s: Host adapter reset request. SCSI hang ?\n", 
-					AAC_DRIVERNAME);
+	printk(KERN_ERR "%s: Host adapter reset request. SCSI hang ?\n", AAC_DRIVER_NAME);
+	if (nblank(dprintk(x))) {
+		int active = 0;
 
+		active = active;
+		dprintk((KERN_ERR "%s: Outstanding commands on (%d,%d,%d,%d):\n", AAC_DRIVER_NAME, host->host_no, dev->channel, dev->id, dev->lun));
+		spin_lock_irqsave(&dev->list_lock, flags);
+		list_for_each_entry(command, &dev->cmd_list, list)
+		{
+			if (command->state != SCSI_STATE_FINISHED)
+			dprintk((KERN_ERR "%4d %c%c %02x %02x %02x %02x %02x %02x %02x %02x %02x %02x\n",
+			  active++,
+			  (command->serial_number) ? 'A' : 'C',
+			  (cmd == command) ? '*' : ' ',
+			  command->cmnd[0], command->cmnd[1], command->cmnd[2],
+			  command->cmnd[3], command->cmnd[4], command->cmnd[5],
+			  command->cmnd[6], command->cmnd[7], command->cmnd[8],
+			  command->cmnd[9]));
+		}
+		spin_unlock_irqrestore(&dev->list_lock, flags);
+	}
 
 	aac = (struct aac_dev *)host->hostdata;
-	if (aac_adapter_check_health(aac)) {
-		printk(KERN_ERR "%s: Host adapter appears dead\n", 
-				AAC_DRIVERNAME);
-		return -ENODEV;
+	if ((count = aac_adapter_check_health(aac))) {
+		/* Fake up an AIF:
+		 *	aac_aifcmd.command = AifCmdEventNotify = 1
+		 *	aac_aifcmd.seqnum = 0xFFFFFFFF
+		 *	aac_aifcmd.data[0] = AifEnExpEvent = 23
+		 *	aac_aifcmd.data[1] = AifExeFirmwarePanic = 3
+		 *	aac.aifcmd.data[2] = AifHighPriority = 3
+		 *	aac.aifcmd.data[3] = count
+		 */
+		struct list_head *entry;
+		u32 time_now = jiffies/HZ;
+		unsigned long flagv;
+			
+		spin_lock_irqsave(&aac->fib_lock, flagv);
+		entry = aac->fib_list.next;
+
+		/*
+		 * For each Context that is on the 
+		 * fibctxList, make a copy of the
+		 * fib, and then set the event to wake up the
+		 * thread that is waiting for it.
+		 */
+		while (entry != &aac->fib_list) {
+			/*
+			 * Extract the fibctx
+			 */
+			struct aac_fib_context *fibctx = list_entry(entry, struct aac_fib_context, next);
+			struct hw_fib * hw_fib;
+			struct fib * fib;
+			/*
+			 * Check if the queue is getting
+			 * backlogged
+			 */
+			if (fibctx->count > 20) {
+				/*
+				 * It's *not* jiffies folks,
+				 * but jiffies / HZ, so do not
+				 * panic ...
+				 */
+				u32 time_last = fibctx->jiffies;
+				/*
+				 * Has it been > 2 minutes 
+				 * since the last read off
+				 * the queue?
+				 */
+				if ((time_now - time_last) > 120) {
+					entry = entry->next;
+					aac_close_fib_context(aac, fibctx);
+					continue;
+				}
+			}
+			/*
+			 * Warning: no sleep allowed while
+			 * holding spinlock
+			 */
+			hw_fib = kmalloc(sizeof(struct hw_fib), GFP_ATOMIC);
+			fib = kmalloc(sizeof(struct fib), GFP_ATOMIC);
+			if (fib && hw_fib) {
+				struct aac_aifcmd * aif;
+				memset(hw_fib, 0, sizeof(struct hw_fib));
+				fib_init(fib);
+				memset(fib, 0, sizeof(struct fib));
+				fib->type = FSAFS_NTC_FIB_CONTEXT;
+				fib->size = sizeof (struct fib);
+				fib->hw_fib = hw_fib;
+				fib->data = hw_fib->data;
+				fib->dev = aac;
+				aif = (struct aac_aifcmd *)hw_fib->data;
+				aif->command = AifCmdEventNotify;
+			 	aif->seqnum = 0xFFFFFFFF;
+			 	aif->data[0] = AifEnExpEvent;
+				aif->data[1] = AifExeFirmwarePanic;
+			 	aif->data[2] = AifHighPriority;
+				aif->data[3] = count;
+
+				/*
+				 * Put the FIB onto the
+				 * fibctx's fibs
+				 */
+				list_add_tail(&fib->fiblink, &fibctx->fib_list);
+				fibctx->count++;
+				/* 
+				 * Set the event to wake up the
+				 * thread that will waiting.
+				 */
+				up(&fibctx->wait_sem);
+			} else {
+				printk(KERN_WARNING "aifd: didn't allocate NewFib.\n");
+				if(fib)
+					kfree(fib);
+				if(hw_fib)
+					kfree(hw_fib);
+			}
+			entry = entry->next;
+		}
+		spin_unlock_irqrestore(&aac->fib_lock, flagv);
+
+		printk(((count < 0)
+		    ? KERN_ERR "%s: Host adapter appears dead %d\n"
+		    : KERN_ERR "%s: Host adapter BLINK LED 0x%x\n"),
+		  AAC_DRIVER_NAME, count);
+		/*
+		 *	If a positive health, means in a known DEAD PANIC
+		 * state and unlikely to recover reliably
+		 */
+		return (count < 0) ? -ENODEV : SUCCESS;
 	}
 	/*
 	 * Wait for all commands to complete to this specific
@@ -408,19 +643,193 @@ static int aac_eh_reset(struct scsi_cmnd
 				}
 			}
 			spin_unlock_irqrestore(&dev->list_lock, flags);
-
-			/*
-			 * We can exit If all the commands are complete
-			 */
-			if (active == 0)
-				return SUCCESS;
+			if (active)
+				break;
 		}
+		/*
+		 * We can exit if all the commands are complete
+		 */
+		if (active == 0)
+			return SUCCESS;
 		spin_unlock_irq(host->host_lock);
 		scsi_sleep(HZ);
 		spin_lock_irq(host->host_lock);
 	}
-	printk(KERN_ERR "%s: SCSI bus appears hung\n", AAC_DRIVERNAME);
+	printk(KERN_ERR "%s: SCSI bus appears hung\n", AAC_DRIVER_NAME);
 	return -ETIMEDOUT;
+#endif
+}
+
+/**
+ *	aac_procinfo	-	Implement /proc/scsi/<drivername>/<n>
+ *	@proc_buffer: memory buffer for I/O
+ *	@start_ptr: pointer to first valid data
+ *	@offset: offset into file
+ *	@bytes_available: space left
+ *	@host_no: scsi host ident
+ *	@write: direction of I/O
+ *
+ *	Used to export driver statistics and other infos to the world outside 
+ *	the kernel using the proc file system. Also provides an interface to
+ *	feed the driver with information.
+ *
+ *		For reads
+ *			- if offset > 0 return 0
+ *			- if offset == 0 write data to proc_buffer and set the start_ptr to
+ *			beginning of proc_buffer, return the number of characters written.
+ *		For writes
+ *			- writes currently not supported, return 0
+ *
+ *	Bugs:	Only offset zero is handled
+ */
+
+static int aac_procinfo(
+	struct Scsi_Host * host,
+	char *proc_buffer, char **start_ptr,off_t offset,
+	int bytes_available,
+	int write)
+{
+	struct aac_dev * dev = (struct aac_dev *)NULL;
+	int index, ret, tmp;
+
+#ifdef AAC_LM_SENSOR
+	if(offset > 0)
+#else
+	if(write || offset > 0)
+#endif
+		return 0;
+	*start_ptr = proc_buffer;
+#ifdef AAC_LM_SENSOR
+	ret = 0;
+	if (!write)
+#endif
+#	if (defined(AAC_DRIVER_BUILD))
+		ret = sprintf(proc_buffer,
+		  "Adaptec Raid Controller %d.%d-%d[%d]\n",
+		  AAC_DRIVER_VERSION >> 24,
+		  (AAC_DRIVER_VERSION >> 16) & 0xFF,
+		  AAC_DRIVER_VERSION & 0xFF,
+		  AAC_DRIVER_BUILD);
+#	else
+		ret = sprintf(proc_buffer,
+		  "Adaptec Raid Controller %d.%d-%d %s\n",
+		  AAC_DRIVER_VERSION >> 24,
+		  (AAC_DRIVER_VERSION >> 16) & 0xFF,
+		  AAC_DRIVER_VERSION & 0xFF,
+		  AAC_DRIVER_BUILD_DATE);
+#	endif
+	for (index = 0; index < aac_count; ++index) {
+		if (((dev = aac_devices[index]) != (struct aac_dev *)NULL)
+		 && (dev->scsi_host_ptr == host)
+		) {
+			break;
+		}
+	}
+	if ((index >= aac_count) || (dev == (struct aac_dev *)NULL)) {
+		return ret;
+	}
+#ifdef AAC_LM_SENSOR
+	if (write) {
+		s32 temp[6];
+		static char temperature[] = "temperature=";
+		if (strnicmp (proc_buffer, temperature, sizeof(temperature) - 1))
+			return bytes_available;
+		for (index = 0;
+		  index < (sizeof(temp)/sizeof(temp[0]));
+		  ++index)
+			temp[index] = 0x80000000;
+		ret = sizeof(temperature) - 1;
+		for (index = 0;
+		  index < (sizeof(temp)/sizeof(temp[0]));
+		  ++index) {
+			int sign, mult, c;
+			if (ret >= bytes_available)
+				break;
+			c = proc_buffer[ret];
+			if (c == '\n') {
+				++ret;
+				break;
+			}
+			if (c == ',') {
+				++ret;
+				continue;
+			}
+			sign = 1;
+			mult = 0;
+			tmp = 0;
+			if (c == '-') {
+				sign = -1;
+				++ret;
+			}
+			for (;
+			  (ret < bytes_available) && ((c = proc_buffer[ret]));
+			  ++ret) {
+				if (('0' <= c) && (c <= '9')) {
+					tmp *= 10;
+					tmp += c - '0';
+					mult *= 10;
+				} else if ((c == '.') && (mult == 0))
+					mult = 1;
+				else
+					break;
+			}
+			if ((ret < bytes_available)
+			 && ((c == ',') || (c == '\n')))
+				++ret;
+			if (!mult)
+				mult = 1;
+			if (sign < 0)
+				tmp = -tmp;
+			temp[index] = ((tmp << 8) + (mult >> 1)) / mult;
+			if (c == '\n')
+				break;
+		}
+		ret = index;
+		if (nblank(dprintk(x))) {
+			for (index = 0; index < ret; ++index) {
+				int sign;
+				tmp = temp[index];
+				sign = tmp < 0;
+				if (sign)
+					tmp = -tmp;
+				dprintk((KERN_DEBUG "%s%s%d.%08doC",
+				  (index ? "," : ""),
+				  (sign ? "-" : ""),
+				  tmp >> 8, (tmp % 256) * 390625));
+			}
+		}
+		/* Send temperature message to Firmware */
+		(void)aac_adapter_sync_cmd(dev, RCV_TEMP_READINGS,
+		  ret, temp[0], temp[1], temp[2], temp[3], temp[4], temp[5],
+		  NULL, NULL, NULL, NULL, NULL);
+		return bytes_available;
+	}
+#endif
+	ret += sprintf(proc_buffer + ret, "Vendor: %s Model: %s\n",
+	  aac_drivers[dev->cardtype].vname, aac_drivers[dev->cardtype].model);
+	tmp = 0;
+	if (nblank(dprintk(x))) {
+		ret += sprintf(proc_buffer + ret, "dprintk");
+		tmp = '+';
+	}
+	if (tmp)
+		ret += sprintf(proc_buffer + ret, " flags\n");
+	tmp = dev->adapter_info.kernelrev;
+	ret += sprintf(proc_buffer + ret, "kernel: %d.%d-%d[%d]\n", 
+	  tmp >> 24, (tmp >> 16) & 0xff, tmp & 0xff,
+	  dev->adapter_info.kernelbuild);
+	tmp = dev->adapter_info.monitorrev;
+	ret += sprintf(proc_buffer + ret, "monitor: %d.%d-%d[%d]\n", 
+	  tmp >> 24, (tmp >> 16) & 0xff, tmp & 0xff,
+	  dev->adapter_info.monitorbuild);
+	tmp = dev->adapter_info.biosrev;
+	ret += sprintf(proc_buffer + ret, "bios: %d.%d-%d[%d]\n", 
+	  tmp >> 24, (tmp >> 16) & 0xff, tmp & 0xff,
+	  dev->adapter_info.biosbuild);
+	if (dev->adapter_info.serial[0] != 0xBAD0)
+		ret += sprintf(proc_buffer + ret, "serial: %x\n",
+		  dev->adapter_info.serial[0]);
+	return ret;
 }
 
 /**
@@ -437,11 +846,13 @@ static int aac_eh_reset(struct scsi_cmnd
 
 static int aac_cfg_open(struct inode *inode, struct file *file)
 {
-	unsigned minor = iminor(inode);
+	unsigned minor_number = iminor(inode);
 
-	if (minor >= aac_count)
+	if(minor_number >= aac_count)
+		return -ENODEV;
+	file->private_data = aac_devices[minor_number];
+	if (file->private_data == NULL)
 		return -ENODEV;
-	file->private_data = aac_devices[minor];
 	return 0;
 }
 
@@ -462,7 +873,7 @@ static int aac_cfg_open(struct inode *in
 static int aac_cfg_ioctl(struct inode *inode,  struct file *file,
 		unsigned int cmd, unsigned long arg)
 {
-	return aac_do_ioctl(file->private_data, cmd, (void __user *)arg);
+	return aac_do_ioctl(file->private_data, cmd, (void *)arg);
 }
 
 static struct file_operations aac_cfg_fops = {
@@ -474,24 +885,28 @@ static struct file_operations aac_cfg_fo
 static struct scsi_host_template aac_driver_template = {
 	.module				= THIS_MODULE,
 	.name           		= "AAC",
-	.proc_name			= "aacraid",
+	.proc_name			= AAC_DRIVER_NAME,
 	.info           		= aac_info,
 	.ioctl          		= aac_ioctl,
 	.queuecommand   		= aac_queuecommand,
 	.bios_param     		= aac_biosparm,	
+	.proc_info      		= aac_procinfo,
 	.slave_configure		= aac_slave_configure,
 	.eh_abort_handler		= aac_eh_abort,
 	.eh_host_reset_handler		= aac_eh_reset,
 	.can_queue      		= AAC_NUM_IO_FIB,	
-	.this_id        		= 16,
+	.this_id        		= MAXIMUM_NUM_CONTAINERS,
 	.sg_tablesize   		= 16,
 	.max_sectors    		= 128,
 #if (AAC_NUM_IO_FIB > 256)
 	.cmd_per_lun			= 256,
-#else		
-	.cmd_per_lun    		= AAC_NUM_IO_FIB, 
-#endif	
+#else
+	.cmd_per_lun			= AAC_NUM_IO_FIB,
+#endif
 	.use_clustering			= ENABLE_CLUSTERING,
+#ifdef SCSI_HAS_VARY_IO
+	.vary_io			= 1,
+#endif
 };
 
 
@@ -500,10 +915,14 @@ static int __devinit aac_probe_one(struc
 {
 	unsigned index = id->driver_data;
 	struct Scsi_Host *shost;
-	struct fsa_scsi_hba *fsa_dev_ptr;
 	struct aac_dev *aac;
-	int container;
 	int error = -ENODEV;
+	int unique_id = 0;
+
+	for (; (unique_id < aac_count) && aac_devices[unique_id]; ++unique_id)
+		continue;
+	if (unique_id >= MAXIMUM_NUM_ADAPTERS)
+		goto out;
 
 	if (pci_enable_device(pdev))
 		goto out;
@@ -523,7 +942,8 @@ static int __devinit aac_probe_one(struc
 	pci_set_master(pdev);
 
 	/* Increment the host adapter count */
-	aac_count++;
+	if (unique_id >= aac_count)
+		aac_count = unique_id + 1;
 
 	shost = scsi_host_alloc(&aac_driver_template, sizeof(struct aac_dev));
 	if (!shost)
@@ -531,7 +951,8 @@ static int __devinit aac_probe_one(struc
 
 	shost->irq = pdev->irq;
 	shost->base = pci_resource_start(pdev, 0);
-	shost->unique_id = aac_count - 1;
+	scsi_set_device(shost, &pdev->dev);
+	shost->unique_id = unique_id;
 
 	aac = (struct aac_dev *)shost->hostdata;
 	aac->scsi_host_ptr = shost;	
@@ -540,18 +961,28 @@ static int __devinit aac_probe_one(struc
 	aac->id = shost->unique_id;
 	aac->cardtype =  index;
 
-	aac->fibs = kmalloc(sizeof(struct fib) * AAC_NUM_FIB, GFP_KERNEL);
+	dprintk((KERN_INFO
+	  "allocate fibs: kmalloc(%d * (%d + %d), GFP_KERNEL)\n",
+	  sizeof(struct fib), shost->can_queue, AAC_NUM_MGT_FIB));
+	aac->fibs = kmalloc(sizeof(struct fib) * (shost->can_queue + AAC_NUM_MGT_FIB), GFP_KERNEL);
 	if (!aac->fibs)
 		goto out_free_host;
 	spin_lock_init(&aac->fib_lock);
 
-	/* Initialize the ordinal number of the device to -1 */
-	fsa_dev_ptr = &aac->fsa_dev;
-	for (container = 0; container < MAXIMUM_NUM_CONTAINERS; container++)
-		fsa_dev_ptr->devname[container][0] = '\0';
-
-	if ((*aac_drivers[index].init)(aac))
+	/*
+	 *	Map in the registers from the adapter.
+	 */
+	dprintk((KERN_INFO "ioremap(%lx,%d)\n", aac->scsi_host_ptr->base,
+	  AAC_MIN_FOOTPRINT_SIZE));
+	if ((aac->regs.sa = (struct sa_registers *)ioremap(
+	  (unsigned long)aac->scsi_host_ptr->base, AAC_MIN_FOOTPRINT_SIZE))
+	  == NULL) {	
+		printk(KERN_WARNING "%s: unable to map adapter.\n",
+		  AAC_DRIVER_NAME);
 		goto out_free_fibs;
+	}
+	if ((*aac_drivers[index].init)(aac))
+		goto out_unmap;
 
 	/*
 	 * If we had set a smaller DMA mask earlier, set it to 4gig
@@ -560,7 +991,7 @@ static int __devinit aac_probe_one(struc
 	 */
 	if (aac_drivers[index].quirks & AAC_QUIRK_31BIT)
 		if (pci_set_dma_mask(pdev, 0xFFFFFFFFULL))
-			goto out_free_fibs;
+			goto out_unmap;
 
 	aac_get_adapter_info(aac);
 
@@ -574,14 +1005,19 @@ static int __devinit aac_probe_one(struc
 	else
 		shost->max_channel = 1;
 
+	aac_get_config_status(aac);
 	aac_get_containers(aac);
-	aac_devices[aac_count-1] = aac;
+	aac_devices[unique_id] = aac;
 
+	shost->max_id = aac->maximum_num_containers;
+	if (shost->max_id < MAXIMUM_NUM_CONTAINERS)
+		shost->max_id = MAXIMUM_NUM_CONTAINERS;
+	else
+		shost->this_id = shost->max_id;
 	/*
 	 * dmb - we may need to move the setting of these parms somewhere else once
 	 * we get a fib that can report the actual numbers
 	 */
-	shost->max_id = MAXIMUM_NUM_CONTAINERS;
 	shost->max_lun = AAC_MAX_LUN;
 
 	error = scsi_add_host(shost, &pdev->dev);
@@ -601,7 +1037,10 @@ static int __devinit aac_probe_one(struc
 	fib_map_free(aac);
 	pci_free_consistent(aac->pdev, aac->comm_size, aac->comm_addr, aac->comm_phys);
 	kfree(aac->queues);
+	if (aac->fsa_dev)
+		kfree(aac->fsa_dev);
 	free_irq(pdev->irq, aac);
+ out_unmap:
 	iounmap((void * )aac->regs.sa);
  out_free_fibs:
 	kfree(aac->fibs);
@@ -609,7 +1048,9 @@ static int __devinit aac_probe_one(struc
 	scsi_host_put(shost);
  out_disable_pdev:
 	pci_disable_device(pdev);
-	aac_count--;
+	aac_devices[unique_id] = NULL;
+	if (unique_id == (aac_count - 1))
+		aac_count--;
  out:
 	return error;
 }
@@ -618,6 +1059,7 @@ static void __devexit aac_remove_one(str
 {
 	struct Scsi_Host *shost = pci_get_drvdata(pdev);
 	struct aac_dev *aac = (struct aac_dev *)shost->hostdata;
+	int index;
 
 	scsi_remove_host(shost);
 
@@ -634,23 +1076,23 @@ static void __devexit aac_remove_one(str
 	iounmap((void * )aac->regs.sa);
 	
 	kfree(aac->fibs);
+	kfree(aac->fsa_dev);
 	
 	scsi_host_put(shost);
 	pci_disable_device(pdev);
 
-	/*
-	 * We don't decrement aac_count here because adapters can be unplugged
-	 * in a different order than they were detected.  If we're ever going
-	 * to overflow MAXIMUM_NUM_ADAPTERS we'll have to consider using a
-	 * bintmap of free aac_devices slots.
-	 */
-#if 0
-	aac_count--;
-#endif
+	for (index = 0; index < aac_count; ++index) {
+		if (aac_devices[index] == aac) {
+			aac_devices[index] = NULL;
+			if (index == (aac_count - 1))
+				--aac_count;
+			break;
+		}
+	}
 }
 
 static struct pci_driver aac_pci_driver = {
-	.name		= AAC_DRIVERNAME,
+	.name		= AAC_DRIVER_NAME,
 	.id_table	= aac_pci_tbl,
 	.probe		= aac_probe_one,
 	.remove		= __devexit_p(aac_remove_one),
@@ -660,12 +1102,27 @@ static int __init aac_init(void)
 {
 	int error;
 	
-	printk(KERN_INFO "Red Hat/Adaptec aacraid driver (%s %s)\n",
-			AAC_DRIVER_VERSION, AAC_DRIVER_BUILD_DATE);
+#	if (defined(AAC_DRIVER_BUILD))
+		printk(KERN_INFO "Red Hat/Adaptec %s driver (%d.%d-%d[%d])\n",
+		  AAC_DRIVER_NAME,
+		  AAC_DRIVER_VERSION >> 24,
+		  (AAC_DRIVER_VERSION >> 16) & 0xFF,
+		  AAC_DRIVER_VERSION & 0xFF,
+		  AAC_DRIVER_BUILD);
+#	else
+		printk(KERN_INFO "Red Hat/Adaptec %s driver (%d.%d-%d %s)\n",
+		  AAC_DRIVER_NAME,
+		  AAC_DRIVER_VERSION >> 24,
+		  (AAC_DRIVER_VERSION >> 16) & 0xFF,
+		  AAC_DRIVER_VERSION & 0xFF,
+		  AAC_DRIVER_BUILD_DATE);
+#	endif
 
 	error = pci_module_init(&aac_pci_driver);
 	if (error)
 		return error;
+	if (!aac_count)
+		return -ENODEV;
 
 	aac_cfg_major = register_chrdev( 0, "aac", &aac_cfg_fops);
 	if (aac_cfg_major < 0) {
@@ -673,18 +1130,18 @@ static int __init aac_init(void)
 		       "aacraid: unable to register \"aac\" device.\n");
 	}
 #ifdef CONFIG_COMPAT
-	register_ioctl32_conversion(FSACTL_MINIPORT_REV_CHECK, NULL);
-	register_ioctl32_conversion(FSACTL_SENDFIB, NULL);
-	register_ioctl32_conversion(FSACTL_OPEN_GET_ADAPTER_FIB, NULL);
-	register_ioctl32_conversion(FSACTL_GET_NEXT_ADAPTER_FIB, 
-		aac_get_next_adapter_fib_ioctl);
-	register_ioctl32_conversion(FSACTL_CLOSE_GET_ADAPTER_FIB, NULL);
-	register_ioctl32_conversion(FSACTL_SEND_RAW_SRB, NULL);
-	register_ioctl32_conversion(FSACTL_GET_PCI_INFO, NULL);
-	register_ioctl32_conversion(FSACTL_QUERY_DISK, NULL);
-	register_ioctl32_conversion(FSACTL_DELETE_DISK, NULL);
-	register_ioctl32_conversion(FSACTL_FORCE_DELETE_DISK, NULL);
-	register_ioctl32_conversion(FSACTL_GET_CONTAINERS, NULL);
+	aac_ioctl32(FSACTL_MINIPORT_REV_CHECK, sys_ioctl);
+	aac_ioctl32(FSACTL_SENDFIB, sys_ioctl);
+	aac_ioctl32(FSACTL_OPEN_GET_ADAPTER_FIB, sys_ioctl);
+	aac_ioctl32(FSACTL_GET_NEXT_ADAPTER_FIB,
+	  aac_get_next_adapter_fib_ioctl);
+	aac_ioctl32(FSACTL_CLOSE_GET_ADAPTER_FIB, sys_ioctl);
+	aac_ioctl32(FSACTL_SEND_RAW_SRB, sys_ioctl);
+	aac_ioctl32(FSACTL_GET_PCI_INFO, sys_ioctl);
+	aac_ioctl32(FSACTL_QUERY_DISK, sys_ioctl);
+	aac_ioctl32(FSACTL_DELETE_DISK, sys_ioctl);
+	aac_ioctl32(FSACTL_FORCE_DELETE_DISK, sys_ioctl);
+	aac_ioctl32(FSACTL_GET_CONTAINERS, sys_ioctl);
 #endif
 
 	return 0;
diff -urNp linux-2.6.8/drivers/scsi/aacraid/README linux-2.6.8.SUSE/drivers/scsi/aacraid/README
--- linux-2.6.8/drivers/scsi/aacraid/README	2004-08-14 07:36:14.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/README	2004-07-30 19:42:14.000000000 +0200
@@ -10,28 +10,27 @@ the original).
 
 Supported Cards/Chipsets
 -------------------------
-	AAR-2410SA SATA
-	Adaptec 2120S
-	Adaptec 2200S
-	Adaptec 2230S
-	Adaptec 3230S
-	Adaptec 3240S
-	Adaptec 5400S
-	ASR-2020S PCI-X
-	Dell PERC 2 Quad Channel
-	Dell PERC 2/Si
-	Dell PERC 3/Si
-	Dell PERC 3/Di
-	Dell CERC 2
+	Dell Computer Corporation PERC 2 Quad Channel
+	Dell Computer Corporation PERC 2/Si
+	Dell Computer Corporation PERC 3/Si
+	Dell Computer Corporation PERC 3/Di
+	Dell Computer Corporation CERC 2
 	HP NetRAID-4M
+	ADAPTEC 2120S
+	ADAPTEC 2200S
+	ADAPTEC 2230S
+	ADAPTEC 5400S
 	Legend S220
 	Legend S230
+	Adaptec 3230S
+	Adaptec 3240S
+	ASR-2020S PCI-X
+	AAR-2410SA SATA
 
 People
 -------------------------
 Alan Cox <alan@redhat.com>
-Christoph Hellwig <hch@infradead.org>	(updates for new-style PCI probing and SCSI host registration,
-					 small cleanups/fixes)
+Christoph Hellwig <hch@infradead.org>	(updates for new-style PCI probing and SCSI host registration)
 Matt Domsch <matt_domsch@dell.com>	(revision ioctl, adapter messages)
 Deanna Bonds <deanna_bonds@adaptec.com> (non-DASD support, PAE fibs and 64 bit, added new adaptec controllers
 					 added new ioctls, changed scsi interface to use new error handler,
@@ -49,7 +48,6 @@ Adaptec Unix OEM Product Group
 Mailing List
 -------------------------
 linux-scsi@vger.kernel.org (Interested parties troll here)
-http://mbserver.adaptec.com/ (Currently more Community Support than Devel Support)
 Also note this is very different to Brian's original driver
 so don't expect him to support it.
 Adaptec does support this driver.  Contact either tech support or Mark Salyzyn.
diff -urNp linux-2.6.8/drivers/scsi/aacraid/rkt.c linux-2.6.8.SUSE/drivers/scsi/aacraid/rkt.c
--- linux-2.6.8/drivers/scsi/aacraid/rkt.c	2004-08-14 07:37:38.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/rkt.c	2004-07-30 19:42:17.000000000 +0200
@@ -49,130 +49,92 @@
 static irqreturn_t aac_rkt_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct aac_dev *dev = dev_id;
-	unsigned long bellbits;
-	u8 intstat, mask;
-	intstat = rkt_readb(dev, MUnit.OISR);
-	/*
-	 *	Read mask and invert because drawbridge is reversed.
-	 *	This allows us to only service interrupts that have 
-	 *	been enabled.
-	 */
-	mask = ~(dev->OIMR);
-	/* Check to see if this is our interrupt.  If it isn't just return */
-	if (intstat & mask) 
-	{
-		bellbits = rkt_readl(dev, OutboundDoorbellReg);
-		if (bellbits & DoorBellPrintfReady) {
-			aac_printf(dev, le32_to_cpu(rkt_readl (dev, IndexRegs.Mailbox[5])));
-			rkt_writel(dev, MUnit.ODR,DoorBellPrintfReady);
-			rkt_writel(dev, InboundDoorbellReg,DoorBellPrintfDone);
-		}
-		else if (bellbits & DoorBellAdapterNormCmdReady) {
-			rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdReady);
-			aac_command_normal(&dev->queues->queue[HostNormCmdQueue]);
-		}
-		else if (bellbits & DoorBellAdapterNormRespReady) {
-			aac_response_normal(&dev->queues->queue[HostNormRespQueue]);
-			rkt_writel(dev, MUnit.ODR,DoorBellAdapterNormRespReady);
-		}
-		else if (bellbits & DoorBellAdapterNormCmdNotFull) {
-			rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdNotFull);
+
+	if (dev->new_comm_interface) {
+		u32 Index = rkt_readl(dev, MUnit.OutboundQueue);
+		if (Index == 0xFFFFFFFFL)
+			Index = rkt_readl(dev, MUnit.OutboundQueue);
+		if (Index != 0xFFFFFFFFL) {
+			do {
+				if (aac_intr_normal(dev, Index)) {
+					rkt_writel(dev, MUnit.OutboundQueue, Index);
+					rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdReady);
+				}
+				Index = rkt_readl(dev, MUnit.OutboundQueue);
+			} while (Index != 0xFFFFFFFFL);
+			return IRQ_HANDLED;
 		}
-		else if (bellbits & DoorBellAdapterNormRespNotFull) {
-			rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdNotFull);
-			rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormRespNotFull);
+	} else {
+		unsigned long bellbits;
+		u8 intstat;
+		intstat = rkt_readb(dev, MUnit.OISR);
+		/*
+		 *	Read mask and invert because drawbridge is reversed.
+		 *	This allows us to only service interrupts that have 
+		 *	been enabled.
+		 *	Check to see if this is our interrupt.  If it isn't just return
+		 */
+		if (intstat & ~(dev->OIMR))
+		{
+			bellbits = rkt_readl(dev, OutboundDoorbellReg);
+			if (bellbits & DoorBellPrintfReady) {
+				aac_printf(dev, le32_to_cpu(rkt_readl (dev, IndexRegs.Mailbox[5])));
+				rkt_writel(dev, MUnit.ODR,DoorBellPrintfReady);
+				rkt_writel(dev, InboundDoorbellReg,DoorBellPrintfDone);
+			}
+			else if (bellbits & DoorBellAdapterNormCmdReady) {
+				rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdReady);
+				aac_command_normal(&dev->queues->queue[HostNormCmdQueue]);
+//				rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdReady);
+			}
+			else if (bellbits & DoorBellAdapterNormRespReady) {
+				rkt_writel(dev, MUnit.ODR,DoorBellAdapterNormRespReady);
+				aac_response_normal(&dev->queues->queue[HostNormRespQueue]);
+			}
+			else if (bellbits & DoorBellAdapterNormCmdNotFull) {
+				rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdNotFull);
+			}
+			else if (bellbits & DoorBellAdapterNormRespNotFull) {
+				rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdNotFull);
+				rkt_writel(dev, MUnit.ODR, DoorBellAdapterNormRespNotFull);
+			}
+			return IRQ_HANDLED;
 		}
-		return IRQ_HANDLED;
 	}
 	return IRQ_NONE;
 }
 
 /**
- *	aac_rkt_enable_interrupt	-	Enable event reporting
- *	@dev: Adapter
- *	@event: Event to enable
- *
- *	Enable event reporting from the i960 for a given event.
- */
- 
-static void aac_rkt_enable_interrupt(struct aac_dev * dev, u32 event)
-{
-	switch (event) {
-
-	case HostNormCmdQue:
-		dev->irq_mask &= ~(OUTBOUNDDOORBELL_1);
-		break;
-
-	case HostNormRespQue:
-		dev->irq_mask &= ~(OUTBOUNDDOORBELL_2);
-		break;
-
-	case AdapNormCmdNotFull:
-		dev->irq_mask &= ~(OUTBOUNDDOORBELL_3);
-		break;
-
-	case AdapNormRespNotFull:
-		dev->irq_mask &= ~(OUTBOUNDDOORBELL_4);
-		break;
-	}
-}
-
-/**
- *	aac_rkt_disable_interrupt	-	Disable event reporting
- *	@dev: Adapter
- *	@event: Event to enable
- *
- *	Disable event reporting from the i960 for a given event.
- */
-
-static void aac_rkt_disable_interrupt(struct aac_dev *dev, u32 event)
-{
-	switch (event) {
-
-	case HostNormCmdQue:
-		dev->irq_mask |= (OUTBOUNDDOORBELL_1);
-		break;
-
-	case HostNormRespQue:
-		dev->irq_mask |= (OUTBOUNDDOORBELL_2);
-		break;
-
-	case AdapNormCmdNotFull:
-		dev->irq_mask |= (OUTBOUNDDOORBELL_3);
-		break;
-
-	case AdapNormRespNotFull:
-		dev->irq_mask |= (OUTBOUNDDOORBELL_4);
-		break;
-	}
-}
-
-/**
  *	rkt_sync_cmd	-	send a command and wait
  *	@dev: Adapter
  *	@command: Command to execute
  *	@p1: first parameter
  *	@ret: adapter status
  *
- *	This routine will send a synchronous comamnd to the adapter and wait 
+ *	This routine will send a synchronous command to the adapter and wait 
  *	for its	completion.
  */
 
-static int rkt_sync_cmd(struct aac_dev *dev, u32 command, u32 p1, u32 *status)
+static int rkt_sync_cmd(struct aac_dev *dev, u32 command,
+	u32 p1, u32 p2, u32 p3, u32 p4, u32 p5, u32 p6, u32 p7,
+	u32 *status, u32 *r1, u32 *r2, u32 *r3, u32 *r4)
 {
 	unsigned long start;
 	int ok;
 	/*
 	 *	Write the command into Mailbox 0
 	 */
-	rkt_writel(dev, InboundMailbox0, cpu_to_le32(command));
+	rkt_writel(dev, InboundMailbox0, command);
 	/*
-	 *	Write the parameters into Mailboxes 1 - 4
+	 *	Write the parameters into Mailboxes 1 - 7
 	 */
 	rkt_writel(dev, InboundMailbox1, cpu_to_le32(p1));
-	rkt_writel(dev, InboundMailbox2, 0);
-	rkt_writel(dev, InboundMailbox3, 0);
-	rkt_writel(dev, InboundMailbox4, 0);
+	rkt_writel(dev, InboundMailbox2, cpu_to_le32(p2));
+	rkt_writel(dev, InboundMailbox3, cpu_to_le32(p3));
+	rkt_writel(dev, InboundMailbox4, cpu_to_le32(p4));
+	rkt_writel(dev, InboundMailbox5, cpu_to_le32(p5));
+	rkt_writel(dev, InboundMailbox6, cpu_to_le32(p6));
+	rkt_writel(dev, InboundMailbox7, cpu_to_le32(p7));
 	/*
 	 *	Clear the synch command doorbell to start on a clean slate.
 	 */
@@ -180,7 +142,7 @@ static int rkt_sync_cmd(struct aac_dev *
 	/*
 	 *	Disable doorbell interrupts
 	 */
-	rkt_writeb(dev, MUnit.OIMR, dev->OIMR |= 0x04);
+	rkt_writeb(dev, MUnit.OIMR, dev->OIMR = 0xff);
 	/*
 	 *	Force the completion of the mask register write before issuing
 	 *	the interrupt.
@@ -221,13 +183,25 @@ static int rkt_sync_cmd(struct aac_dev *
 		/*
 		 *	Restore interrupt mask even though we timed out
 		 */
-		rkt_writeb(dev, MUnit.OIMR, dev->OIMR &= 0xfb);
+		if (dev->new_comm_interface)
+			rkt_writeb(dev, MUnit.OIMR, dev->OIMR = 0xf7);
+		else
+			rkt_writeb(dev, MUnit.OIMR, dev->OIMR = 0xfb);
 		return -ETIMEDOUT;
 	}
 	/*
 	 *	Pull the synch status from Mailbox 0.
 	 */
-	*status = le32_to_cpu(rkt_readl(dev, IndexRegs.Mailbox[0]));
+	if (status)
+		*status = le32_to_cpu(rkt_readl(dev, IndexRegs.Mailbox[0]));
+	if (r1)
+		*r1 = le32_to_cpu(rkt_readl(dev, IndexRegs.Mailbox[1]));
+	if (r2)
+		*r2 = le32_to_cpu(rkt_readl(dev, IndexRegs.Mailbox[2]));
+	if (r3)
+		*r3 = le32_to_cpu(rkt_readl(dev, IndexRegs.Mailbox[3]));
+	if (r4)
+		*r4 = le32_to_cpu(rkt_readl(dev, IndexRegs.Mailbox[4]));
 	/*
 	 *	Clear the synch command doorbell.
 	 */
@@ -235,7 +209,10 @@ static int rkt_sync_cmd(struct aac_dev *
 	/*
 	 *	Restore interrupt mask
 	 */
-	rkt_writeb(dev, MUnit.OIMR, dev->OIMR &= 0xfb);
+	if (dev->new_comm_interface)
+		rkt_writeb(dev, MUnit.OIMR, dev->OIMR = 0xf7);
+	else
+		rkt_writeb(dev, MUnit.OIMR, dev->OIMR = 0xfb);
 	return 0;
 
 }
@@ -249,8 +226,8 @@ static int rkt_sync_cmd(struct aac_dev *
 
 static void aac_rkt_interrupt_adapter(struct aac_dev *dev)
 {
-	u32 ret;
-	rkt_sync_cmd(dev, BREAKPOINT_REQUEST, 0, &ret);
+	rkt_sync_cmd(dev, BREAKPOINT_REQUEST, 0, 0, 0, 0, 0, 0, 0,
+	  NULL, NULL, NULL, NULL, NULL);
 }
 
 /**
@@ -279,7 +256,8 @@ static void aac_rkt_notify_adapter(struc
 		rkt_writel(dev, MUnit.IDR,INBOUNDDOORBELL_3);
 		break;
 	case HostShutdown:
-//		rkt_sync_cmd(dev, HOST_CRASHING, 0, 0, 0, 0, &ret);
+//		rkt_sync_cmd(dev, HOST_CRASHING, 0, 0, 0, 0, 0, 0, 0,
+//		  NULL, NULL, NULL, NULL, NULL);
 		break;
 	case FastIo:
 		rkt_writel(dev, MUnit.IDR,INBOUNDDOORBELL_6);
@@ -302,27 +280,13 @@ static void aac_rkt_notify_adapter(struc
 
 static void aac_rkt_start_adapter(struct aac_dev *dev)
 {
-	u32 status;
 	struct aac_init *init;
 
 	init = dev->init;
 	init->HostElapsedSeconds = cpu_to_le32(get_seconds());
-	/*
-	 *	Tell the adapter we are back and up and running so it will scan
-	 *	its command queues and enable our interrupts
-	 */
-	dev->irq_mask = (DoorBellPrintfReady | OUTBOUNDDOORBELL_1 | OUTBOUNDDOORBELL_2 | OUTBOUNDDOORBELL_3 | OUTBOUNDDOORBELL_4);
-	/*
-	 *	First clear out all interrupts.  Then enable the one's that we
-	 *	can handle.
-	 */
-	rkt_writeb(dev, MUnit.OIMR, 0xff);
-	rkt_writel(dev, MUnit.ODR, 0xffffffff);
-//	rkt_writeb(dev, MUnit.OIMR, ~(u8)OUTBOUND_DOORBELL_INTERRUPT_MASK);
-	rkt_writeb(dev, MUnit.OIMR, dev->OIMR = 0xfb);
-
 	// We can only use a 32 bit address here
-	rkt_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa, &status);
+	rkt_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa,
+	  0, 0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
 }
 
 /**
@@ -334,7 +298,7 @@ static void aac_rkt_start_adapter(struct
  */
 static int aac_rkt_check_health(struct aac_dev *dev)
 {
-	long status = rkt_readl(dev, IndexRegs.Mailbox[7]);
+	long status = le32_to_cpu(rkt_readl(dev, MUnit.OMRx[0]));
 
 	/*
 	 *	Check to see if the board failed any self tests.
@@ -344,34 +308,43 @@ static int aac_rkt_check_health(struct a
 	/*
 	 *	Check to see if the board panic'd.
 	 */
-	if (status & KERNEL_PANIC)
-	{
-		char * buffer = kmalloc(512, GFP_KERNEL|__GFP_DMA);
+	if (status & KERNEL_PANIC) {
+		char * buffer;
 		struct POSTSTATUS {
 			u32 Post_Command;
 			u32 Post_Address;
-		} * post = kmalloc(sizeof(struct POSTSTATUS), GFP_KERNEL);
-		dma_addr_t paddr = pci_map_single(dev->pdev, post, sizeof(struct POSTSTATUS), 2);
-		dma_addr_t baddr = pci_map_single(dev->pdev, buffer, 512, 1);
-		u32 status = -1;
-		int ret = -2;
-		
-		memset(buffer, 0, 512);
-		post->Post_Command = cpu_to_le32(COMMAND_POST_RESULTS);
-		post->Post_Address = cpu_to_le32(baddr);
-		rkt_writel(dev, MUnit.IMRx[0], cpu_to_le32(paddr));
-		rkt_sync_cmd(dev, COMMAND_POST_RESULTS, baddr, &status);
-		pci_unmap_single(dev->pdev, paddr, sizeof(struct POSTSTATUS),2);
-		kfree(post);
-		if ((buffer[0] == '0') && (buffer[1] == 'x')) {
-			ret = (buffer[2] <= '9') ? (buffer[2] - '0') : (buffer[2] - 'A' + 10);
-			ret <<= 4;
-			ret += (buffer[3] <= '9') ? (buffer[3] - '0') : (buffer[3] - 'A' + 10);
+		} * post;
+		dma_addr_t paddr, baddr;
+		int ret;
+
+		if ((status & 0xFF000000L) == 0xBC000000L)
+			return (status >> 16) & 0xFF;
+		buffer = pci_alloc_consistent(dev->pdev, 512, &baddr);
+		ret = -2;
+		if (buffer == NULL)
+			return ret;
+		post = pci_alloc_consistent(dev->pdev,
+		  sizeof(struct POSTSTATUS), &paddr);
+		if (post == NULL) {
+			pci_free_consistent(dev->pdev, 512, buffer, baddr);
+			return ret;
 		}
-		pci_unmap_single(dev->pdev, baddr, 512, 1);
-		kfree(buffer);
-		return ret;
-	}
+                memset(buffer, 0, 512);
+                post->Post_Command = cpu_to_le32(COMMAND_POST_RESULTS);
+                post->Post_Address = cpu_to_le32(baddr);
+                rkt_writel(dev, MUnit.IMRx[0], cpu_to_le32(paddr));
+                rkt_sync_cmd(dev, COMMAND_POST_RESULTS, baddr, 0, 0, 0, 0, 0, 0,
+		  NULL, NULL, NULL, NULL, NULL);
+		pci_free_consistent(dev->pdev, sizeof(struct POSTSTATUS),
+		  post, paddr);
+                if ((buffer[0] == '0') && (buffer[1] == 'x')) {
+                        ret = (buffer[2] <= '9') ? (buffer[2] - '0') : (buffer[2] - 'A' + 10);
+                        ret <<= 4;
+                        ret += (buffer[3] <= '9') ? (buffer[3] - '0') : (buffer[3] - 'A' + 10);
+                }
+		pci_free_consistent(dev->pdev, 512, buffer, baddr);
+                return ret;
+        }
 	/*
 	 *	Wait for the adapter to be up and running.
 	 */
@@ -384,6 +357,39 @@ static int aac_rkt_check_health(struct a
 }
 
 /**
+ *	aac_rkt_send
+ *	@fib: fib to issue
+ *
+ *	Will send a fib, returning 0 if successful.
+ */
+static int aac_rkt_send(struct fib * fib)
+{
+	u64 addr = fib->hw_fib_pa;
+	struct aac_dev *dev = fib->dev;
+	u32 * device = (u32 *)(dev->regs.rkt);
+	u32 Index;
+
+	dprintk((KERN_DEBUG "%p->aac_rkt_send(%p->%llx)\n", dev, fib, addr));
+	Index = rkt_readl(dev, MUnit.InboundQueue);
+	if (Index == 0xFFFFFFFFL)
+		Index = rkt_readl(dev, MUnit.InboundQueue);
+	dprintk((KERN_DEBUG "Index = 0x%x\n", Index));
+	if (Index == 0xFFFFFFFFL)
+		return Index;
+	device += le32_to_cpu(Index) / sizeof(u32);
+	dprintk((KERN_DEBUG "entry = %x %x %u\n", (u32)(addr & 0xffffffff),
+	  (u32)(addr >> 32), (u32)le16_to_cpu(fib->hw_fib->header.Size)));
+	writel(cpu_to_le32((u32)(addr & 0xffffffff)), device);
+	++device;
+	writel(cpu_to_le32((u32)(addr >> 32)), device);
+	++device;
+	writel(cpu_to_le32(le16_to_cpu(fib->hw_fib->header.Size)), device);
+	rkt_writel(dev, MUnit.InboundQueue, Index);
+	dprintk((KERN_DEBUG "aac_rkt_send - return 0\n"));
+	return 0;
+}
+
+/**
  *	aac_rkt_init	-	initialize an i960 based AAC card
  *	@dev: device to configure
  *
@@ -395,7 +401,6 @@ static int aac_rkt_check_health(struct a
 int aac_rkt_init(struct aac_dev *dev)
 {
 	unsigned long start;
-	unsigned long status;
 	int instance;
 	const char * name;
 
@@ -403,45 +408,41 @@ int aac_rkt_init(struct aac_dev *dev)
 	name     = dev->name;
 
 	/*
-	 *	Map in the registers from the adapter.
-	 */
-	if((dev->regs.rkt = (struct rkt_registers *)ioremap((unsigned long)dev->scsi_host_ptr->base, 8192))==NULL)
-	{	
-		printk(KERN_WARNING "aacraid: unable to map i960.\n" );
-		goto error_iounmap;
-	}
-	/*
 	 *	Check to see if the board failed any self tests.
 	 */
-	if (rkt_readl(dev, MUnit.OMRx[0]) & SELF_TEST_FAILED) {
+	if (rkt_readl(dev, MUnit.OMRx[0]) & cpu_to_le32(SELF_TEST_FAILED)) {
 		printk(KERN_ERR "%s%d: adapter self-test failed.\n", dev->name, instance);
-		goto error_iounmap;
+		return -1;
 	}
 	/*
 	 *	Check to see if the monitor panic'd while booting.
 	 */
-	if (rkt_readl(dev, MUnit.OMRx[0]) & MONITOR_PANIC) {
-		printk(KERN_ERR "%s%d: adapter monitor panic.\n", dev->name, instance);
-		goto error_iounmap;
+	if (rkt_readl(dev, MUnit.OMRx[0]) & cpu_to_le32(MONITOR_PANIC)) {
+		printk(KERN_ERR "%s%d: adapter monitor panic'd.\n", dev->name, instance);
+		return -1;
 	}
 	/*
 	 *	Check to see if the board panic'd while booting.
 	 */
-	if (rkt_readl(dev, MUnit.OMRx[0]) & KERNEL_PANIC) {
+	if (rkt_readl(dev, MUnit.OMRx[0]) & cpu_to_le32(KERNEL_PANIC)) {
 		printk(KERN_ERR "%s%d: adapter kernel panic'd.\n", dev->name, instance);
-		goto error_iounmap;
+		return -1;
 	}
 	start = jiffies;
 	/*
 	 *	Wait for the adapter to be up and running. Wait up to 3 minutes
 	 */
-	while (!(rkt_readl(dev, MUnit.OMRx[0]) & KERNEL_UP_AND_RUNNING))
+	dprintk ((KERN_DEBUG "rkt_readl(dev,MUnit.OMRx[0]=%x\n",
+	  rkt_readl(dev, MUnit.OMRx[0])));
+	while (
+//	 (!(rkt_readl(dev, IndexRegs.Mailbox[7]) & cpu_to_le32(KERNEL_UP_AND_RUNNING))) || 
+	 (!(rkt_readl(dev, MUnit.OMRx[0]) & cpu_to_le32(KERNEL_UP_AND_RUNNING)))) 
 	{
 		if(time_after(jiffies, start+180*HZ))
 		{
-			status = rkt_readl(dev, IndexRegs.Mailbox[7]) >> 16;
-			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %ld.\n", dev->name, instance, status);
-			goto error_iounmap;
+			unsigned long status = le32_to_cpu(rkt_readl(dev, MUnit.OMRx[0]));
+			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %lx.\n", dev->name, instance, status);
+			return -1;
 		}
 		set_current_state(TASK_UNINTERRUPTIBLE);
 		schedule_timeout(1);
@@ -449,28 +450,61 @@ int aac_rkt_init(struct aac_dev *dev)
 	if (request_irq(dev->scsi_host_ptr->irq, aac_rkt_intr, SA_SHIRQ|SA_INTERRUPT, "aacraid", (void *)dev)<0) 
 	{
 		printk(KERN_ERR "%s%d: Interrupt unavailable.\n", name, instance);
-		goto error_iounmap;
+		return -1;
 	}
 	/*
 	 *	Fill in the function dispatch table.
 	 */
 	dev->a_ops.adapter_interrupt = aac_rkt_interrupt_adapter;
-	dev->a_ops.adapter_enable_int = aac_rkt_enable_interrupt;
-	dev->a_ops.adapter_disable_int = aac_rkt_disable_interrupt;
 	dev->a_ops.adapter_notify = aac_rkt_notify_adapter;
 	dev->a_ops.adapter_sync_cmd = rkt_sync_cmd;
 	dev->a_ops.adapter_check_health = aac_rkt_check_health;
+	dev->a_ops.adapter_send = aac_rkt_send;
+#ifdef __arm__
+//DEBUG
+//printk(KERN_INFO "Disabling New Comm Interface as xscale utilization is affected negatively\n");
+//	dev->a_ops.adapter_send = NULL;
+#endif
+
+	/*
+	 *	First clear out all interrupts.  Then enable the one's that we
+	 *	can handle.
+	 */
+	rkt_writeb(dev, MUnit.OIMR, 0xff);
+	rkt_writel(dev, MUnit.ODR, 0xffffffff);
+	rkt_writeb(dev, MUnit.OIMR, dev->OIMR = 0xfb);
 
-	if (aac_init_adapter(dev) == NULL)
-		goto error_irq;
+	if (aac_init_adapter(dev) == NULL) {
+		free_irq(dev->scsi_host_ptr->irq, (void *)dev);
+		return -1;
+	}
+	if (dev->new_comm_interface) {
+		/*
+		 * FIB Setup has already been done, but we can minimize the
+		 * damage by at least ensuring the OS never issues more
+		 * commands than we can handle. The Rocket adapters currently
+		 * can only handle 246 commands and 8 AIFs at the same time,
+		 * and in fact do notify us accordingly if we negotiate the
+		 * FIB size. The problem that causes us to add this check is
+		 * to ensure that we do not overdo it with the adapter when a
+		 * hard coded FIB override is being utilized. This special
+		 * case warrants this half baked, but convenient, check here.
+		 */
+		if (dev->scsi_host_ptr->can_queue > (246 - AAC_NUM_MGT_FIB)) {
+			dev->init->MaxIoCommands = 246;
+			dev->scsi_host_ptr->can_queue = 246 - AAC_NUM_MGT_FIB;
+		}
+		rkt_writeb(dev, MUnit.OIMR, dev->OIMR = 0xf7);
+	}
 	/*
 	 *	Start any kernel threads needed
 	 */
 	dev->thread_pid = kernel_thread((int (*)(void *))aac_command_thread, dev, 0);
 	if(dev->thread_pid < 0)
 	{
+		free_irq(dev->scsi_host_ptr->irq, (void *)dev);
 		printk(KERN_ERR "aacraid: Unable to create rkt thread.\n");
-		goto error_kfree;
+		return -1;
 	}	
 	/*
 	 *	Tell the adapter that all is configured, and it can start
@@ -478,15 +512,4 @@ int aac_rkt_init(struct aac_dev *dev)
 	 */
 	aac_rkt_start_adapter(dev);
 	return 0;
-
-error_kfree:
-	kfree(dev->queues);
-
-error_irq:
-	free_irq(dev->scsi_host_ptr->irq, (void *)dev);
-
-error_iounmap:
-	iounmap(dev->regs.rkt);
-
-	return -1;
 }
diff -urNp linux-2.6.8/drivers/scsi/aacraid/rx.c linux-2.6.8.SUSE/drivers/scsi/aacraid/rx.c
--- linux-2.6.8/drivers/scsi/aacraid/rx.c	2004-08-14 07:38:10.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/rx.c	2004-07-30 19:42:17.000000000 +0200
@@ -49,130 +49,95 @@
 static irqreturn_t aac_rx_intr(int irq, void *dev_id, struct pt_regs *regs)
 {
 	struct aac_dev *dev = dev_id;
-	unsigned long bellbits;
-	u8 intstat, mask;
-	intstat = rx_readb(dev, MUnit.OISR);
-	/*
-	 *	Read mask and invert because drawbridge is reversed.
-	 *	This allows us to only service interrupts that have 
-	 *	been enabled.
-	 */
-	mask = ~(dev->OIMR);
-	/* Check to see if this is our interrupt.  If it isn't just return */
-	if (intstat & mask) 
-	{
-		bellbits = rx_readl(dev, OutboundDoorbellReg);
-		if (bellbits & DoorBellPrintfReady) {
-			aac_printf(dev, le32_to_cpu(rx_readl (dev, IndexRegs.Mailbox[5])));
-			rx_writel(dev, MUnit.ODR,DoorBellPrintfReady);
-			rx_writel(dev, InboundDoorbellReg,DoorBellPrintfDone);
-		}
-		else if (bellbits & DoorBellAdapterNormCmdReady) {
-			rx_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdReady);
-			aac_command_normal(&dev->queues->queue[HostNormCmdQueue]);
-		}
-		else if (bellbits & DoorBellAdapterNormRespReady) {
-			aac_response_normal(&dev->queues->queue[HostNormRespQueue]);
-			rx_writel(dev, MUnit.ODR,DoorBellAdapterNormRespReady);
-		}
-		else if (bellbits & DoorBellAdapterNormCmdNotFull) {
-			rx_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdNotFull);
+
+	dprintk((KERN_DEBUG "aac_rx_intr(%d,%p,%p)\n", irq, dev_id, regs));
+	if (dev->new_comm_interface) {
+		u32 Index = rx_readl(dev, MUnit.OutboundQueue);
+		if (Index == 0xFFFFFFFFL)
+			Index = rx_readl(dev, MUnit.OutboundQueue);
+		if (Index != 0xFFFFFFFFL) {
+			do {
+				if (aac_intr_normal(dev, Index)) {
+					rx_writel(dev, MUnit.OutboundQueue, Index);
+					rx_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdReady);
+				}
+				Index = rx_readl(dev, MUnit.OutboundQueue);
+			} while (Index != 0xFFFFFFFFL);
+			return IRQ_HANDLED;
 		}
-		else if (bellbits & DoorBellAdapterNormRespNotFull) {
-			rx_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdNotFull);
-			rx_writel(dev, MUnit.ODR, DoorBellAdapterNormRespNotFull);
+	} else {
+		unsigned long bellbits;
+		u8 intstat;
+		intstat = rx_readb(dev, MUnit.OISR);
+		/*
+		 *	Read mask and invert because drawbridge is reversed.
+		 *	This allows us to only service interrupts that have 
+		 *	been enabled.
+		 *	Check to see if this is our interrupt.  If it isn't just return
+		 */
+		if (intstat & ~(dev->OIMR)) 
+		{
+			bellbits = rx_readl(dev, OutboundDoorbellReg);
+			if (bellbits & DoorBellPrintfReady) {
+				aac_printf(dev, le32_to_cpu(rx_readl (dev, IndexRegs.Mailbox[5])));
+				rx_writel(dev, MUnit.ODR,DoorBellPrintfReady);
+				rx_writel(dev, InboundDoorbellReg,DoorBellPrintfDone);
+			}
+			else if (bellbits & DoorBellAdapterNormCmdReady) {
+				rx_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdReady);
+				aac_command_normal(&dev->queues->queue[HostNormCmdQueue]);
+			}
+			else if (bellbits & DoorBellAdapterNormRespReady) {
+				rx_writel(dev, MUnit.ODR,DoorBellAdapterNormRespReady);
+				aac_response_normal(&dev->queues->queue[HostNormRespQueue]);
+			}
+			else if (bellbits & DoorBellAdapterNormCmdNotFull) {
+				rx_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdNotFull);
+			}
+			else if (bellbits & DoorBellAdapterNormRespNotFull) {
+				rx_writel(dev, MUnit.ODR, DoorBellAdapterNormCmdNotFull);
+				rx_writel(dev, MUnit.ODR, DoorBellAdapterNormRespNotFull);
+			}
+			return IRQ_HANDLED;
 		}
-		return IRQ_HANDLED;
 	}
 	return IRQ_NONE;
 }
 
 /**
- *	aac_rx_enable_interrupt	-	Enable event reporting
- *	@dev: Adapter
- *	@event: Event to enable
- *
- *	Enable event reporting from the i960 for a given event.
- */
- 
-static void aac_rx_enable_interrupt(struct aac_dev * dev, u32 event)
-{
-	switch (event) {
-
-	case HostNormCmdQue:
-		dev->irq_mask &= ~(OUTBOUNDDOORBELL_1);
-		break;
-
-	case HostNormRespQue:
-		dev->irq_mask &= ~(OUTBOUNDDOORBELL_2);
-		break;
-
-	case AdapNormCmdNotFull:
-		dev->irq_mask &= ~(OUTBOUNDDOORBELL_3);
-		break;
-
-	case AdapNormRespNotFull:
-		dev->irq_mask &= ~(OUTBOUNDDOORBELL_4);
-		break;
-	}
-}
-
-/**
- *	aac_rx_disable_interrupt	-	Disable event reporting
- *	@dev: Adapter
- *	@event: Event to enable
- *
- *	Disable event reporting from the i960 for a given event.
- */
-
-static void aac_rx_disable_interrupt(struct aac_dev *dev, u32 event)
-{
-	switch (event) {
-
-	case HostNormCmdQue:
-		dev->irq_mask |= (OUTBOUNDDOORBELL_1);
-		break;
-
-	case HostNormRespQue:
-		dev->irq_mask |= (OUTBOUNDDOORBELL_2);
-		break;
-
-	case AdapNormCmdNotFull:
-		dev->irq_mask |= (OUTBOUNDDOORBELL_3);
-		break;
-
-	case AdapNormRespNotFull:
-		dev->irq_mask |= (OUTBOUNDDOORBELL_4);
-		break;
-	}
-}
-
-/**
  *	rx_sync_cmd	-	send a command and wait
  *	@dev: Adapter
  *	@command: Command to execute
  *	@p1: first parameter
  *	@ret: adapter status
  *
- *	This routine will send a synchronous comamnd to the adapter and wait 
+ *	This routine will send a synchronous command to the adapter and wait 
  *	for its	completion.
  */
 
-static int rx_sync_cmd(struct aac_dev *dev, u32 command, u32 p1, u32 *status)
+static int rx_sync_cmd(struct aac_dev *dev, u32 command,
+	u32 p1, u32 p2, u32 p3, u32 p4, u32 p5, u32 p6, u32 p7,
+	u32 *status, u32 * r1, u32 * r2, u32 * r3, u32 * r4)
 {
 	unsigned long start;
 	int ok;
+	dprintk((KERN_DEBUG
+	  "rx_sync_cmd(%p,%x,%x,%x,%x,%x,%x,%x,%x,%p,%p,%p,%p,%p)\n",
+	  dev, command, p1, p2, p3, p4, p5, p6, p7, status, r1, r2, r3, r4));
 	/*
 	 *	Write the command into Mailbox 0
 	 */
-	rx_writel(dev, InboundMailbox0, cpu_to_le32(command));
+	rx_writel(dev, InboundMailbox0, command);
 	/*
-	 *	Write the parameters into Mailboxes 1 - 4
+	 *	Write the parameters into Mailboxes 1 - 7
 	 */
 	rx_writel(dev, InboundMailbox1, cpu_to_le32(p1));
-	rx_writel(dev, InboundMailbox2, 0);
-	rx_writel(dev, InboundMailbox3, 0);
-	rx_writel(dev, InboundMailbox4, 0);
+	rx_writel(dev, InboundMailbox2, cpu_to_le32(p2));
+	rx_writel(dev, InboundMailbox3, cpu_to_le32(p3));
+	rx_writel(dev, InboundMailbox4, cpu_to_le32(p4));
+	rx_writel(dev, InboundMailbox5, cpu_to_le32(p5));
+	rx_writel(dev, InboundMailbox6, cpu_to_le32(p6));
+	rx_writel(dev, InboundMailbox7, cpu_to_le32(p7));
 	/*
 	 *	Clear the synch command doorbell to start on a clean slate.
 	 */
@@ -180,7 +145,7 @@ static int rx_sync_cmd(struct aac_dev *d
 	/*
 	 *	Disable doorbell interrupts
 	 */
-	rx_writeb(dev, MUnit.OIMR, dev->OIMR |= 0x04);
+	rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xff);
 	/*
 	 *	Force the completion of the mask register write before issuing
 	 *	the interrupt.
@@ -221,13 +186,26 @@ static int rx_sync_cmd(struct aac_dev *d
 		/*
 		 *	Restore interrupt mask even though we timed out
 		 */
-		rx_writeb(dev, MUnit.OIMR, dev->OIMR &= 0xfb);
+		if (dev->new_comm_interface)
+			rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xf7);
+		else
+			rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xfb);
+		dprintk((KERN_DEBUG "rx_sync_cmd - return -ETIMEDOUT\n"));
 		return -ETIMEDOUT;
 	}
 	/*
 	 *	Pull the synch status from Mailbox 0.
 	 */
-	*status = le32_to_cpu(rx_readl(dev, IndexRegs.Mailbox[0]));
+	if (status)
+		*status = le32_to_cpu(rx_readl(dev, IndexRegs.Mailbox[0]));
+	if (r1)
+		*r1 = le32_to_cpu(rx_readl(dev, IndexRegs.Mailbox[1]));
+	if (r2)
+		*r2 = le32_to_cpu(rx_readl(dev, IndexRegs.Mailbox[2]));
+	if (r3)
+		*r3 = le32_to_cpu(rx_readl(dev, IndexRegs.Mailbox[3]));
+	if (r4)
+		*r4 = le32_to_cpu(rx_readl(dev, IndexRegs.Mailbox[4]));
 	/*
 	 *	Clear the synch command doorbell.
 	 */
@@ -235,7 +213,11 @@ static int rx_sync_cmd(struct aac_dev *d
 	/*
 	 *	Restore interrupt mask
 	 */
-	rx_writeb(dev, MUnit.OIMR, dev->OIMR &= 0xfb);
+	if (dev->new_comm_interface)
+		rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xf7);
+	else
+		rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xfb);
+	dprintk((KERN_DEBUG "rx_sync_cmd - return 0\n"));
 	return 0;
 
 }
@@ -249,8 +231,7 @@ static int rx_sync_cmd(struct aac_dev *d
 
 static void aac_rx_interrupt_adapter(struct aac_dev *dev)
 {
-	u32 ret;
-	rx_sync_cmd(dev, BREAKPOINT_REQUEST, 0, &ret);
+	rx_sync_cmd(dev, BREAKPOINT_REQUEST, 0, 0, 0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
 }
 
 /**
@@ -279,7 +260,8 @@ static void aac_rx_notify_adapter(struct
 		rx_writel(dev, MUnit.IDR,INBOUNDDOORBELL_3);
 		break;
 	case HostShutdown:
-//		rx_sync_cmd(dev, HOST_CRASHING, 0, 0, 0, 0, &ret);
+//		rx_sync_cmd(dev, HOST_CRASHING, 0, 0, 0, 0, 0, 0, 0,
+//		  NULL, NULL, NULL, NULL, NULL);
 		break;
 	case FastIo:
 		rx_writel(dev, MUnit.IDR,INBOUNDDOORBELL_6);
@@ -302,27 +284,13 @@ static void aac_rx_notify_adapter(struct
 
 static void aac_rx_start_adapter(struct aac_dev *dev)
 {
-	u32 status;
 	struct aac_init *init;
 
 	init = dev->init;
 	init->HostElapsedSeconds = cpu_to_le32(get_seconds());
-	/*
-	 *	Tell the adapter we are back and up and running so it will scan
-	 *	its command queues and enable our interrupts
-	 */
-	dev->irq_mask = (DoorBellPrintfReady | OUTBOUNDDOORBELL_1 | OUTBOUNDDOORBELL_2 | OUTBOUNDDOORBELL_3 | OUTBOUNDDOORBELL_4);
-	/*
-	 *	First clear out all interrupts.  Then enable the one's that we
-	 *	can handle.
-	 */
-	rx_writeb(dev, MUnit.OIMR, 0xff);
-	rx_writel(dev, MUnit.ODR, 0xffffffff);
-//	rx_writeb(dev, MUnit.OIMR, ~(u8)OUTBOUND_DOORBELL_INTERRUPT_MASK);
-	rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xfb);
-
 	// We can only use a 32 bit address here
-	rx_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa, &status);
+	rx_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa,
+	  0, 0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
 }
 
 /**
@@ -334,7 +302,7 @@ static void aac_rx_start_adapter(struct 
  */
 static int aac_rx_check_health(struct aac_dev *dev)
 {
-	long status = rx_readl(dev, IndexRegs.Mailbox[7]);
+	long status = le32_to_cpu(rx_readl(dev, MUnit.OMRx[0]));
 
 	/*
 	 *	Check to see if the board failed any self tests.
@@ -345,29 +313,40 @@ static int aac_rx_check_health(struct aa
 	 *	Check to see if the board panic'd.
 	 */
 	if (status & KERNEL_PANIC) {
-		char * buffer = kmalloc(512, GFP_KERNEL);
+		char * buffer;
 		struct POSTSTATUS {
 			u32 Post_Command;
 			u32 Post_Address;
-		} * post = kmalloc(sizeof(struct POSTSTATUS), GFP_KERNEL);
-		dma_addr_t paddr = pci_map_single(dev->pdev, post, sizeof(struct POSTSTATUS), 2);
-		dma_addr_t baddr = pci_map_single(dev->pdev, buffer, 512, 1);
-		u32 status = -1;
-		int ret = -2;
+		} * post;
+		dma_addr_t paddr, baddr;
+		int ret;
+
+		if ((status & 0xFF000000L) == 0xBC000000L)
+			return (status >> 16) & 0xFF;
+		buffer = pci_alloc_consistent(dev->pdev, 512, &baddr);
+		ret = -2;
+		if (buffer == NULL)
+			return ret;
+		post = pci_alloc_consistent(dev->pdev,
+		  sizeof(struct POSTSTATUS), &paddr);
+		if (post == NULL) {
+			pci_free_consistent(dev->pdev, 512, buffer, baddr);
+			return ret;
+		}
 		memset(buffer, 0, 512);
 		post->Post_Command = cpu_to_le32(COMMAND_POST_RESULTS);
 		post->Post_Address = cpu_to_le32(baddr);
 		rx_writel(dev, MUnit.IMRx[0], cpu_to_le32(paddr));
-		rx_sync_cmd(dev, COMMAND_POST_RESULTS, baddr, &status);
-		pci_unmap_single(dev->pdev, paddr, sizeof(struct POSTSTATUS), 2);
-		kfree(post);
+		rx_sync_cmd(dev, COMMAND_POST_RESULTS, baddr, 0, 0, 0, 0, 0, 0,
+		  NULL, NULL, NULL, NULL, NULL);
+		pci_free_consistent(dev->pdev, sizeof(struct POSTSTATUS),
+		  post, paddr);
 		if ((buffer[0] == '0') && (buffer[1] == 'x')) {
 			ret = (buffer[2] <= '9') ? (buffer[2] - '0') : (buffer[2] - 'A' + 10);
 			ret <<= 4;
 			ret += (buffer[3] <= '9') ? (buffer[3] - '0') : (buffer[3] - 'A' + 10);
 		}
-		pci_unmap_single(dev->pdev, baddr, 512, 1);
-		kfree(buffer);
+		pci_free_consistent(dev->pdev, 512, buffer, baddr);
 		return ret;
 	}
 	/*
@@ -379,7 +358,40 @@ static int aac_rx_check_health(struct aa
 	 *	Everything is OK
 	 */
 	return 0;
-} /* aac_rx_check_health */
+}
+
+/**
+ *	aac_rx_send
+ *	@fib: fib to issue
+ *
+ *	Will send a fib, returning 0 if successful.
+ */
+static int aac_rx_send(struct fib * fib)
+{
+	u64 addr = fib->hw_fib_pa;
+	struct aac_dev *dev = fib->dev;
+	u32 * device = (u32 *)(dev->regs.rx);
+	u32 Index;
+
+	dprintk((KERN_DEBUG "%p->aac_rx_send(%p->%llx)\n", dev, fib, addr));
+	Index = rx_readl(dev, MUnit.InboundQueue);
+	if (Index == 0xFFFFFFFFL)
+		Index = rx_readl(dev, MUnit.InboundQueue);
+	dprintk((KERN_DEBUG "Index = 0x%x\n", Index));
+	if (Index == 0xFFFFFFFFL)
+		return Index;
+	device += le32_to_cpu(Index) / sizeof(u32);
+	dprintk((KERN_DEBUG "entry = %x %x %u\n", (u32)(addr & 0xffffffff),
+	  (u32)(addr >> 32), (u32)le16_to_cpu(fib->hw_fib->header.Size)));
+	writel(cpu_to_le32((u32)(addr & 0xffffffff)), device);
+	++device;
+	writel(cpu_to_le32((u32)(addr >> 32)), device);
+	++device;
+	writel(cpu_to_le32(le16_to_cpu(fib->hw_fib->header.Size)), device);
+	rx_writel(dev, MUnit.InboundQueue, Index);
+	dprintk((KERN_DEBUG "aac_rx_send - return 0\n"));
+	return 0;
+}
 
 /**
  *	aac_rx_init	-	initialize an i960 based AAC card
@@ -393,7 +405,6 @@ static int aac_rx_check_health(struct aa
 int aac_rx_init(struct aac_dev *dev)
 {
 	unsigned long start;
-	unsigned long status;
 	int instance;
 	const char * name;
 
@@ -401,46 +412,38 @@ int aac_rx_init(struct aac_dev *dev)
 	name     = dev->name;
 
 	/*
-	 *	Map in the registers from the adapter.
-	 */
-	if((dev->regs.rx = (struct rx_registers *)ioremap((unsigned long)dev->scsi_host_ptr->base, 8192))==NULL)
-	{	
-		printk(KERN_WARNING "aacraid: unable to map i960.\n" );
-		return -1;
-	}
-	/*
 	 *	Check to see if the board failed any self tests.
 	 */
-	if (rx_readl(dev, MUnit.OMRx[0]) & SELF_TEST_FAILED) {
+	if (rx_readl(dev, MUnit.OMRx[0]) & cpu_to_le32(SELF_TEST_FAILED)) {
 		printk(KERN_ERR "%s%d: adapter self-test failed.\n", dev->name, instance);
-		goto error_iounmap;
+		return -1;
 	}
 	/*
 	 *	Check to see if the board panic'd while booting.
 	 */
-	if (rx_readl(dev, MUnit.OMRx[0]) & KERNEL_PANIC) {
-		printk(KERN_ERR "%s%d: adapter kernel panic.\n", dev->name, instance);
-		goto error_iounmap;
+	if (rx_readl(dev, MUnit.OMRx[0]) & cpu_to_le32(MONITOR_PANIC)) {
+		printk(KERN_ERR "%s%d: adapter monitor panic'd.\n", dev->name, instance);
+		return -1;
 	}
 	/*
-	 *	Check to see if the monitor panic'd while booting.
+	 *	Check to see if the board panic'd while booting.
 	 */
-	if (rx_readl(dev, MUnit.OMRx[0]) & MONITOR_PANIC) {
-		printk(KERN_ERR "%s%d: adapter monitor panic.\n", dev->name, instance);
-		goto error_iounmap;
+	if (rx_readl(dev, MUnit.OMRx[0]) & cpu_to_le32(KERNEL_PANIC)) {
+		printk(KERN_ERR "%s%d: adapter kernel panic'd.\n", dev->name, instance);
+		return -1;
 	}
 	start = jiffies;
 	/*
 	 *	Wait for the adapter to be up and running. Wait up to 3 minutes
 	 */
-	while ((!(rx_readl(dev, IndexRegs.Mailbox[7]) & KERNEL_UP_AND_RUNNING))
-		|| (!(rx_readl(dev, MUnit.OMRx[0]) & KERNEL_UP_AND_RUNNING)))
+	while ((!(rx_readl(dev, IndexRegs.Mailbox[7]) & cpu_to_le32(KERNEL_UP_AND_RUNNING))) 
+	 || (!(rx_readl(dev, MUnit.OMRx[0]) & cpu_to_le32(KERNEL_UP_AND_RUNNING))))
 	{
 		if(time_after(jiffies, start+180*HZ))
 		{
-			status = rx_readl(dev, IndexRegs.Mailbox[7]) >> 16;
-			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %ld.\n", dev->name, instance, status);
-			goto error_iounmap;
+			unsigned long status = le32_to_cpu(rx_readl(dev, IndexRegs.Mailbox[7]));
+			printk(KERN_ERR "%s%d: adapter kernel failed to start, init status = %lx.\n", dev->name, instance, status);
+			return -1;
 		}
 		set_current_state(TASK_UNINTERRUPTIBLE);
 		schedule_timeout(1);
@@ -448,44 +451,47 @@ int aac_rx_init(struct aac_dev *dev)
 	if (request_irq(dev->scsi_host_ptr->irq, aac_rx_intr, SA_SHIRQ|SA_INTERRUPT, "aacraid", (void *)dev)<0) 
 	{
 		printk(KERN_ERR "%s%d: Interrupt unavailable.\n", name, instance);
-		goto error_iounmap;
+		return -1;
 	}
 	/*
 	 *	Fill in the function dispatch table.
 	 */
 	dev->a_ops.adapter_interrupt = aac_rx_interrupt_adapter;
-	dev->a_ops.adapter_enable_int = aac_rx_enable_interrupt;
-	dev->a_ops.adapter_disable_int = aac_rx_disable_interrupt;
 	dev->a_ops.adapter_notify = aac_rx_notify_adapter;
 	dev->a_ops.adapter_sync_cmd = rx_sync_cmd;
 	dev->a_ops.adapter_check_health = aac_rx_check_health;
+	dev->a_ops.adapter_send = aac_rx_send;
+
+	/*
+	 *	First clear out all interrupts.  Then enable the one's that we
+	 *	can handle.
+	 */
+	rx_writeb(dev, MUnit.OIMR, 0xff);
+	rx_writel(dev, MUnit.ODR, 0xffffffff);
+	rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xfb);
+
+	if (aac_init_adapter(dev) == NULL) {
+		free_irq(dev->scsi_host_ptr->irq, (void *)dev);
+		return -1;
+	}
+	if (dev->new_comm_interface)
+		rx_writeb(dev, MUnit.OIMR, dev->OIMR = 0xf7);
 
-	if (aac_init_adapter(dev) == NULL)
-		goto error_irq;
 	/*
 	 *	Start any kernel threads needed
 	 */
 	dev->thread_pid = kernel_thread((int (*)(void *))aac_command_thread, dev, 0);
 	if(dev->thread_pid < 0)
 	{
+		free_irq(dev->scsi_host_ptr->irq, (void *)dev);
 		printk(KERN_ERR "aacraid: Unable to create rx thread.\n");
-		goto error_kfree;
-	}
+		return -1;
+	}	
 	/*
 	 *	Tell the adapter that all is configured, and it can start
 	 *	accepting requests
 	 */
 	aac_rx_start_adapter(dev);
+	dprintk((KERN_DEBUG "aac_rx_init - return 0\n"));
 	return 0;
-
-error_kfree:
-	kfree(dev->queues);
-
-error_irq:
-	free_irq(dev->scsi_host_ptr->irq, (void *)dev);
-
-error_iounmap:
-	iounmap(dev->regs.rx);
-
-	return -1;
 }
diff -urNp linux-2.6.8/drivers/scsi/aacraid/sa.c linux-2.6.8.SUSE/drivers/scsi/aacraid/sa.c
--- linux-2.6.8/drivers/scsi/aacraid/sa.c	2004-08-14 07:37:14.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/sa.c	2004-07-30 19:42:17.000000000 +0200
@@ -66,11 +66,11 @@ static irqreturn_t aac_sa_intr(int irq, 
 			sa_writew(dev, DoorbellClrReg_p, PrintfReady); /* clear PrintfReady */
 			sa_writew(dev, DoorbellReg_s, PrintfDone);
 		} else if (intstat & DOORBELL_1) {	// dev -> Host Normal Command Ready
-			aac_command_normal(&dev->queues->queue[HostNormCmdQueue]);
 			sa_writew(dev, DoorbellClrReg_p, DOORBELL_1);
+			aac_command_normal(&dev->queues->queue[HostNormCmdQueue]);
 		} else if (intstat & DOORBELL_2) {	// dev -> Host Normal Response Ready
-			aac_response_normal(&dev->queues->queue[HostNormRespQueue]);
 			sa_writew(dev, DoorbellClrReg_p, DOORBELL_2);
+			aac_response_normal(&dev->queues->queue[HostNormRespQueue]);
 		} else if (intstat & DOORBELL_3) {	// dev -> Host Normal Command Not Full
 			sa_writew(dev, DoorbellClrReg_p, DOORBELL_3);
 		} else if (intstat & DOORBELL_4) {	// dev -> Host Normal Response Not Full
@@ -82,68 +82,6 @@ static irqreturn_t aac_sa_intr(int irq, 
 }
 
 /**
- *	aac_sa_enable_interrupt	-	enable an interrupt event
- *	@dev: Which adapter to enable.
- *	@event: Which adapter event.
- *
- *	This routine will enable the corresponding adapter event to cause an interrupt on 
- * 	the host.
- */
- 
-void aac_sa_enable_interrupt(struct aac_dev *dev, u32 event)
-{
-	switch (event) {
-
-	case HostNormCmdQue:
-		sa_writew(dev, SaDbCSR.PRICLEARIRQMASK, DOORBELL_1);
-		break;
-
-	case HostNormRespQue:
-		sa_writew(dev, SaDbCSR.PRICLEARIRQMASK, DOORBELL_2);
-		break;
-
-	case AdapNormCmdNotFull:
-		sa_writew(dev, SaDbCSR.PRICLEARIRQMASK, DOORBELL_3);
-		break;
-
-	case AdapNormRespNotFull:
-		sa_writew(dev, SaDbCSR.PRICLEARIRQMASK, DOORBELL_4);
-		break;
-	}
-}
-
-/**
- *	aac_sa_disable_interrupt	-	disable an interrupt event
- *	@dev: Which adapter to enable.
- *	@event: Which adapter event.
- *
- *	This routine will enable the corresponding adapter event to cause an interrupt on 
- * 	the host.
- */
-
-void aac_sa_disable_interrupt (struct aac_dev *dev, u32 event)
-{
-	switch (event) {
-
-	case HostNormCmdQue:
-		sa_writew(dev, SaDbCSR.PRISETIRQMASK, DOORBELL_1);
-		break;
-
-	case HostNormRespQue:
-		sa_writew(dev, SaDbCSR.PRISETIRQMASK, DOORBELL_2);
-		break;
-
-	case AdapNormCmdNotFull:
-		sa_writew(dev, SaDbCSR.PRISETIRQMASK, DOORBELL_3);
-		break;
-
-	case AdapNormRespNotFull:
-		sa_writew(dev, SaDbCSR.PRISETIRQMASK, DOORBELL_4);
-		break;
-	}
-}
-
-/**
  *	aac_sa_notify_adapter		-	handle adapter notification
  *	@dev:	Adapter that notification is for
  *	@event:	Event to notidy
@@ -168,7 +106,8 @@ void aac_sa_notify_adapter(struct aac_de
 		sa_writew(dev, DoorbellReg_s,DOORBELL_3);
 		break;
 	case HostShutdown:
-		//sa_sync_cmd(dev, HOST_CRASHING, 0, &ret);
+		//sa_sync_cmd(dev, HOST_CRASHING, 0, 0, 0, 0, 0, 0, 0,
+		//  NULL, NULL, NULL, NULL, NULL);
 		break;
 	case FastIo:
 		sa_writew(dev, DoorbellReg_s,DOORBELL_6);
@@ -190,25 +129,30 @@ void aac_sa_notify_adapter(struct aac_de
  *	@p1: first parameter
  *	@ret: adapter status
  *
- *	This routine will send a synchronous comamnd to the adapter and wait 
+ *	This routine will send a synchronous command to the adapter and wait 
  *	for its	completion.
  */
 
-static int sa_sync_cmd(struct aac_dev *dev, u32 command, u32 p1, u32 *ret)
+static int sa_sync_cmd(struct aac_dev *dev, u32 command,
+	u32 p1, u32 p2, u32 p3, u32 p4, u32 p5, u32 p6, u32 p7,
+	u32 *ret, u32 * r1, u32 * r2, u32 * r3, u32 * r4)
 {
 	unsigned long start;
  	int ok;
 	/*
 	 *	Write the Command into Mailbox 0
 	 */
-	sa_writel(dev, Mailbox0, cpu_to_le32(command));
+	sa_writel(dev, Mailbox0, command);
 	/*
 	 *	Write the parameters into Mailboxes 1 - 4
 	 */
 	sa_writel(dev, Mailbox1, cpu_to_le32(p1));
-	sa_writel(dev, Mailbox2, 0);
-	sa_writel(dev, Mailbox3, 0);
-	sa_writel(dev, Mailbox4, 0);
+	sa_writel(dev, Mailbox2, cpu_to_le32(p2));
+	sa_writel(dev, Mailbox3, cpu_to_le32(p3));
+	sa_writel(dev, Mailbox4, cpu_to_le32(p4));
+	sa_writel(dev, Mailbox5, cpu_to_le32(p5));
+	sa_writel(dev, Mailbox6, cpu_to_le32(p6));
+//	sa_writel(dev, Mailbox7, cpu_to_le32(p7));
 	/*
 	 *	Clear the synch command doorbell to start on a clean slate.
 	 */
@@ -248,7 +192,16 @@ static int sa_sync_cmd(struct aac_dev *d
 	/*
 	 *	Pull the synch status from Mailbox 0.
 	 */
-	*ret = le32_to_cpu(sa_readl(dev, Mailbox0));
+	if (ret)
+		*ret = le32_to_cpu(sa_readl(dev, Mailbox0));
+	if (r1)
+		*r1 = le32_to_cpu(sa_readl(dev, Mailbox1));
+	if (r2)
+		*r2 = le32_to_cpu(sa_readl(dev, Mailbox2));
+	if (r3)
+		*r3 = le32_to_cpu(sa_readl(dev, Mailbox3));
+	if (r4)
+		*r4 = le32_to_cpu(sa_readl(dev, Mailbox4));
 	return 0;
 }
 
@@ -261,8 +214,8 @@ static int sa_sync_cmd(struct aac_dev *d
  
 static void aac_sa_interrupt_adapter (struct aac_dev *dev)
 {
-	u32 ret;
-	sa_sync_cmd(dev, BREAKPOINT_REQUEST, 0, &ret);
+	sa_sync_cmd(dev, BREAKPOINT_REQUEST, 0, 0, 0, 0, 0, 0, 0,
+	  NULL, NULL, NULL, NULL, NULL);
 }
 
 /**
@@ -274,30 +227,15 @@ static void aac_sa_interrupt_adapter (st
 
 static void aac_sa_start_adapter(struct aac_dev *dev)
 {
-	u32 ret;
 	struct aac_init *init;
 	/*
 	 * Fill in the remaining pieces of the init.
 	 */
 	init = dev->init;
-	init->HostElapsedSeconds = cpu_to_le32(jiffies/HZ);
-
-	dprintk(("INIT\n"));
-	/*
-	 * Tell the adapter we are back and up and running so it will scan its command
-	 * queues and enable our interrupts
-	 */
-	dev->irq_mask =	(PrintfReady | DOORBELL_1 | DOORBELL_2 | DOORBELL_3 | DOORBELL_4);
-	/*
-	 *	First clear out all interrupts.  Then enable the one's that 
-	 *	we can handle.
-	 */
-	dprintk(("MASK\n"));
-	sa_writew(dev, SaDbCSR.PRISETIRQMASK, cpu_to_le16(0xffff));
-	sa_writew(dev, SaDbCSR.PRICLEARIRQMASK, (PrintfReady | DOORBELL_1 | DOORBELL_2 | DOORBELL_3 | DOORBELL_4));
-	dprintk(("SYNCCMD\n"));
+	init->HostElapsedSeconds = cpu_to_le32(get_seconds());
 	/* We can only use a 32 bit address here */
-	sa_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa, &ret);
+	sa_sync_cmd(dev, INIT_STRUCT_BASE_ADDRESS, (u32)(ulong)dev->init_pa,
+	  0, 0, 0, 0, 0, 0, NULL, NULL, NULL, NULL, NULL);
 }
 
 /**
@@ -348,52 +286,40 @@ int aac_sa_init(struct aac_dev *dev)
 	int instance;
 	const char *name;
 
-	dprintk(("PREINST\n"));
 	instance = dev->id;
 	name     = dev->name;
 
 	/*
-	 *	Map in the registers from the adapter.
-	 */
-	dprintk(("PREMAP\n"));
-
-	if((dev->regs.sa = (struct sa_registers *)ioremap((unsigned long)dev->scsi_host_ptr->base, 8192))==NULL)
-	{	
-		printk(KERN_WARNING "aacraid: unable to map ARM.\n" );
-		goto error_iounmap;
-	}
-	/*
 	 *	Check to see if the board failed any self tests.
 	 */
-	if (sa_readl(dev, Mailbox7) & SELF_TEST_FAILED) {
+	if (sa_readl(dev, Mailbox7) & cpu_to_le32(SELF_TEST_FAILED)) {
 		printk(KERN_WARNING "%s%d: adapter self-test failed.\n", name, instance);
-		goto error_iounmap;
+		return -1;
 	}
 	/*
 	 *	Check to see if the board panic'd while booting.
 	 */
-	if (sa_readl(dev, Mailbox7) & KERNEL_PANIC) {
+	if (sa_readl(dev, Mailbox7) & cpu_to_le32(KERNEL_PANIC)) {
 		printk(KERN_WARNING "%s%d: adapter kernel panic'd.\n", name, instance);
-		goto error_iounmap;
+		return -1;
 	}
 	start = jiffies;
 	/*
 	 *	Wait for the adapter to be up and running. Wait up to 3 minutes.
 	 */
-	while (!(sa_readl(dev, Mailbox7) & KERNEL_UP_AND_RUNNING)) {
+	while (!(sa_readl(dev, Mailbox7) & cpu_to_le32(KERNEL_UP_AND_RUNNING))) {
 		if (time_after(jiffies, start+180*HZ)) {
-			status = sa_readl(dev, Mailbox7) >> 16;
-			printk(KERN_WARNING "%s%d: adapter kernel failed to start, init status = %d.\n", name, instance, le32_to_cpu(status));
-			goto error_iounmap;
+			status = le32_to_cpu(sa_readl(dev, Mailbox7));
+			printk(KERN_WARNING "%s%d: adapter kernel failed to start, init status = %lx.\n", name, instance, status);
+			return -1;
 		}
 		set_current_state(TASK_UNINTERRUPTIBLE);
 		schedule_timeout(1);
 	}
 
-	dprintk(("ATIRQ\n"));
 	if (request_irq(dev->scsi_host_ptr->irq, aac_sa_intr, SA_SHIRQ|SA_INTERRUPT, "aacraid", (void *)dev ) < 0) {
 		printk(KERN_WARNING "%s%d: Interrupt unavailable.\n", name, instance);
-		goto error_iounmap;
+		return -1;
 	}
 
 	/*
@@ -401,46 +327,37 @@ int aac_sa_init(struct aac_dev *dev)
 	 */
 
 	dev->a_ops.adapter_interrupt = aac_sa_interrupt_adapter;
-	dev->a_ops.adapter_enable_int = aac_sa_enable_interrupt;
-	dev->a_ops.adapter_disable_int = aac_sa_disable_interrupt;
 	dev->a_ops.adapter_notify = aac_sa_notify_adapter;
 	dev->a_ops.adapter_sync_cmd = sa_sync_cmd;
 	dev->a_ops.adapter_check_health = aac_sa_check_health;
 
-	dprintk(("FUNCDONE\n"));
+	/*
+	 *	First clear out all interrupts.  Then enable the one's that 
+	 *	we can handle.
+	 */
+	sa_writew(dev, SaDbCSR.PRISETIRQMASK, cpu_to_le16(0xffff));
+	sa_writew(dev, SaDbCSR.PRICLEARIRQMASK, (PrintfReady | DOORBELL_1 | DOORBELL_2 | DOORBELL_3 | DOORBELL_4));
 
-	if(aac_init_adapter(dev) == NULL)
-		goto error_irq;
+	if(aac_init_adapter(dev) == NULL) {
+		free_irq(dev->scsi_host_ptr->irq, (void *)dev);
+		return -1;
+	}
 
-	dprintk(("NEWADAPTDONE\n"));
 	/*
 	 *	Start any kernel threads needed
 	 */
 	dev->thread_pid = kernel_thread((int (*)(void *))aac_command_thread, dev, 0);
 	if (dev->thread_pid < 0) {
-		printk(KERN_ERR "aacraid: Unable to create command thread.\n");
-		goto error_kfree;
+	     free_irq(dev->scsi_host_ptr->irq, (void *)dev);
+	     printk(KERN_ERR "aacraid: Unable to create command thread.\n");
+	     return -1;
 	}
 
 	/*
 	 *	Tell the adapter that all is configure, and it can start 
 	 *	accepting requests
 	 */
-	dprintk(("STARTING\n"));
 	aac_sa_start_adapter(dev);
-	dprintk(("STARTED\n"));
 	return 0;
-
-
-error_kfree:
-	kfree(dev->queues);
-
-error_irq:
-	free_irq(dev->scsi_host_ptr->irq, (void *)dev);
-
-error_iounmap:
-	iounmap(dev->regs.sa);
-
-	return -1;
 }
 
diff -urNp linux-2.6.8/drivers/scsi/aacraid/TODO linux-2.6.8.SUSE/drivers/scsi/aacraid/TODO
--- linux-2.6.8/drivers/scsi/aacraid/TODO	2004-08-14 07:36:16.000000000 +0200
+++ linux-2.6.8.SUSE/drivers/scsi/aacraid/TODO	2004-07-30 19:42:14.000000000 +0200
@@ -1,6 +1,4 @@
 o	Testing
 o	More testing
-o	Feature request: display the firmware/bios/etc revisions in the
-	/proc info
-o	Drop irq_mask, basically unused
 o	I/O size increase
+o	add sysfs interface
