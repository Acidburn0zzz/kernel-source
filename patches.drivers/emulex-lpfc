diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/COPYING linux-2.6.3/drivers/scsi/lpfc/COPYING
--- linux-2.6.3.emulex/drivers/scsi/lpfc/COPYING	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/COPYING	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,342 @@
+		    GNU GENERAL PUBLIC LICENSE
+		       Version 2, June 1991
+
+ Copyright (C) 1989, 1991 Free Software Foundation, Inc.
+                       59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+			    Preamble
+
+  The licenses for most software are designed to take away your
+freedom to share and change it.  By contrast, the GNU General Public
+License is intended to guarantee your freedom to share and change free
+software--to make sure the software is free for all its users.  This
+General Public License applies to most of the Free Software
+Foundation's software and to any other program whose authors commit to
+using it.  (Some other Free Software Foundation software is covered by
+the GNU Library General Public License instead.)  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+this service if you wish), that you receive source code or can get it
+if you want it, that you can change the software or use pieces of it
+in new free programs; and that you know you can do these things.
+
+  To protect your rights, we need to make restrictions that forbid
+anyone to deny you these rights or to ask you to surrender the rights.
+These restrictions translate to certain responsibilities for you if you
+distribute copies of the software, or if you modify it.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must give the recipients all the rights that
+you have.  You must make sure that they, too, receive or can get the
+source code.  And you must show them these terms so they know their
+rights.
+
+  We protect your rights with two steps: (1) copyright the software, and
+(2) offer you this license which gives you legal permission to copy,
+distribute and/or modify the software.
+
+  Also, for each author's protection and ours, we want to make certain
+that everyone understands that there is no warranty for this free
+software.  If the software is modified by someone else and passed on, we
+want its recipients to know that what they have is not the original, so
+that any problems introduced by others will not reflect on the original
+authors' reputations.
+
+  Finally, any free program is threatened constantly by software
+patents.  We wish to avoid the danger that redistributors of a free
+program will individually obtain patent licenses, in effect making the
+program proprietary.  To prevent this, we have made it clear that any
+patent must be licensed for everyone's free use or not licensed at all.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+		    GNU GENERAL PUBLIC LICENSE
+   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION
+
+  0. This License applies to any program or other work which contains
+a notice placed by the copyright holder saying it may be distributed
+under the terms of this General Public License.  The "Program", below,
+refers to any such program or work, and a "work based on the Program"
+means either the Program or any derivative work under copyright law:
+that is to say, a work containing the Program or a portion of it,
+either verbatim or with modifications and/or translated into another
+language.  (Hereinafter, translation is included without limitation in
+the term "modification".)  Each licensee is addressed as "you".
+
+Activities other than copying, distribution and modification are not
+covered by this License; they are outside its scope.  The act of
+running the Program is not restricted, and the output from the Program
+is covered only if its contents constitute a work based on the
+Program (independent of having been made by running the Program).
+Whether that is true depends on what the Program does.
+
+  1. You may copy and distribute verbatim copies of the Program's
+source code as you receive it, in any medium, provided that you
+conspicuously and appropriately publish on each copy an appropriate
+copyright notice and disclaimer of warranty; keep intact all the
+notices that refer to this License and to the absence of any warranty;
+and give any other recipients of the Program a copy of this License
+along with the Program.
+
+You may charge a fee for the physical act of transferring a copy, and
+you may at your option offer warranty protection in exchange for a fee.
+
+  2. You may modify your copy or copies of the Program or any portion
+of it, thus forming a work based on the Program, and copy and
+distribute such modifications or work under the terms of Section 1
+above, provided that you also meet all of these conditions:
+
+    a) You must cause the modified files to carry prominent notices
+    stating that you changed the files and the date of any change.
+
+    b) You must cause any work that you distribute or publish, that in
+    whole or in part contains or is derived from the Program or any
+    part thereof, to be licensed as a whole at no charge to all third
+    parties under the terms of this License.
+
+    c) If the modified program normally reads commands interactively
+    when run, you must cause it, when started running for such
+    interactive use in the most ordinary way, to print or display an
+    announcement including an appropriate copyright notice and a
+    notice that there is no warranty (or else, saying that you provide
+    a warranty) and that users may redistribute the program under
+    these conditions, and telling the user how to view a copy of this
+    License.  (Exception: if the Program itself is interactive but
+    does not normally print such an announcement, your work based on
+    the Program is not required to print an announcement.)
+
+These requirements apply to the modified work as a whole.  If
+identifiable sections of that work are not derived from the Program,
+and can be reasonably considered independent and separate works in
+themselves, then this License, and its terms, do not apply to those
+sections when you distribute them as separate works.  But when you
+distribute the same sections as part of a whole which is a work based
+on the Program, the distribution of the whole must be on the terms of
+this License, whose permissions for other licensees extend to the
+entire whole, and thus to each and every part regardless of who wrote it.
+
+Thus, it is not the intent of this section to claim rights or contest
+your rights to work written entirely by you; rather, the intent is to
+exercise the right to control the distribution of derivative or
+collective works based on the Program.
+
+In addition, mere aggregation of another work not based on the Program
+with the Program (or with a work based on the Program) on a volume of
+a storage or distribution medium does not bring the other work under
+the scope of this License.
+
+  3. You may copy and distribute the Program (or a work based on it,
+under Section 2) in object code or executable form under the terms of
+Sections 1 and 2 above provided that you also do one of the following:
+
+    a) Accompany it with the complete corresponding machine-readable
+    source code, which must be distributed under the terms of Sections
+    1 and 2 above on a medium customarily used for software interchange; or,
+
+    b) Accompany it with a written offer, valid for at least three
+    years, to give any third party, for a charge no more than your
+    cost of physically performing source distribution, a complete
+    machine-readable copy of the corresponding source code, to be
+    distributed under the terms of Sections 1 and 2 above on a medium
+    customarily used for software interchange; or,
+
+    c) Accompany it with the information you received as to the offer
+    to distribute corresponding source code.  (This alternative is
+    allowed only for noncommercial distribution and only if you
+    received the program in object code or executable form with such
+    an offer, in accord with Subsection b above.)
+
+The source code for a work means the preferred form of the work for
+making modifications to it.  For an executable work, complete source
+code means all the source code for all modules it contains, plus any
+associated interface definition files, plus the scripts used to
+control compilation and installation of the executable.  However, as a
+special exception, the source code distributed need not include
+anything that is normally distributed (in either source or binary
+form) with the major components (compiler, kernel, and so on) of the
+operating system on which the executable runs, unless that component
+itself accompanies the executable.
+
+If distribution of executable or object code is made by offering
+access to copy from a designated place, then offering equivalent
+access to copy the source code from the same place counts as
+distribution of the source code, even though third parties are not
+compelled to copy the source along with the object code.
+
+  4. You may not copy, modify, sublicense, or distribute the Program
+except as expressly provided under this License.  Any attempt
+otherwise to copy, modify, sublicense or distribute the Program is
+void, and will automatically terminate your rights under this License.
+However, parties who have received copies, or rights, from you under
+this License will not have their licenses terminated so long as such
+parties remain in full compliance.
+
+  5. You are not required to accept this License, since you have not
+signed it.  However, nothing else grants you permission to modify or
+distribute the Program or its derivative works.  These actions are
+prohibited by law if you do not accept this License.  Therefore, by
+modifying or distributing the Program (or any work based on the
+Program), you indicate your acceptance of this License to do so, and
+all its terms and conditions for copying, distributing or modifying
+the Program or works based on it.
+
+  6. Each time you redistribute the Program (or any work based on the
+Program), the recipient automatically receives a license from the
+original licensor to copy, distribute or modify the Program subject to
+these terms and conditions.  You may not impose any further
+restrictions on the recipients' exercise of the rights granted herein.
+You are not responsible for enforcing compliance by third parties to
+this License.
+
+  7. If, as a consequence of a court judgment or allegation of patent
+infringement or for any other reason (not limited to patent issues),
+conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot
+distribute so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you
+may not distribute the Program at all.  For example, if a patent
+license would not permit royalty-free redistribution of the Program by
+all those who receive copies directly or indirectly through you, then
+the only way you could satisfy both it and this License would be to
+refrain entirely from distribution of the Program.
+
+If any portion of this section is held invalid or unenforceable under
+any particular circumstance, the balance of the section is intended to
+apply and the section as a whole is intended to apply in other
+circumstances.
+
+It is not the purpose of this section to induce you to infringe any
+patents or other property right claims or to contest validity of any
+such claims; this section has the sole purpose of protecting the
+integrity of the free software distribution system, which is
+implemented by public license practices.  Many people have made
+generous contributions to the wide range of software distributed
+through that system in reliance on consistent application of that
+system; it is up to the author/donor to decide if he or she is willing
+to distribute software through any other system and a licensee cannot
+impose that choice.
+
+This section is intended to make thoroughly clear what is believed to
+be a consequence of the rest of this License.
+
+  8. If the distribution and/or use of the Program is restricted in
+certain countries either by patents or by copyrighted interfaces, the
+original copyright holder who places the Program under this License
+may add an explicit geographical distribution limitation excluding
+those countries, so that distribution is permitted only in or among
+countries not thus excluded.  In such case, this License incorporates
+the limitation as if written in the body of this License.
+
+  9. The Free Software Foundation may publish revised and/or new versions
+of the General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+Each version is given a distinguishing version number.  If the Program
+specifies a version number of this License which applies to it and "any
+later version", you have the option of following the terms and conditions
+either of that version or of any later version published by the Free
+Software Foundation.  If the Program does not specify a version number of
+this License, you may choose any version ever published by the Free Software
+Foundation.
+
+  10. If you wish to incorporate parts of the Program into other free
+programs whose distribution conditions are different, write to the author
+to ask for permission.  For software which is copyrighted by the Free
+Software Foundation, write to the Free Software Foundation; we sometimes
+make exceptions for this.  Our decision will be guided by the two goals
+of preserving the free status of all derivatives of our free software and
+of promoting the sharing and reuse of software generally.
+
+			    NO WARRANTY
+
+  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
+FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
+OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
+PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
+OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
+TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
+PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
+REPAIR OR CORRECTION.
+
+  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
+REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
+INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
+OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
+TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
+YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
+PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
+POSSIBILITY OF SUCH DAMAGES.
+
+		     END OF TERMS AND CONDITIONS
+
+	    How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+convey the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software; you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation; either version 2 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program; if not, write to the Free Software
+    Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
+
+
+Also add information on how to contact you by electronic and paper mail.
+
+If the program is interactive, make it output a short notice like this
+when it starts in an interactive mode:
+
+    Gnomovision version 69, Copyright (C) year name of author
+    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, the commands you use may
+be called something other than `show w' and `show c'; they could even be
+mouse-clicks or menu items--whatever suits your program.
+
+You should also get your employer (if you work as a programmer) or your
+school, if any, to sign a "copyright disclaimer" for the program, if
+necessary.  Here is a sample; alter the names:
+
+  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
+  `Gnomovision' (which makes passes at compilers) written by James Hacker.
+
+  <signature of Ty Coon>, 1 April 1989
+  Ty Coon, President of Vice
+
+This General Public License does not permit incorporating your program into
+proprietary programs.  If your program is a subroutine library, you may
+consider it more useful to permit linking proprietary applications with the
+library.  If this is what you want to do, use the GNU Library General
+Public License instead of this License.
+
+
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/Makefile linux-2.6.3/drivers/scsi/lpfc/Makefile
--- linux-2.6.3.emulex/drivers/scsi/lpfc/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/Makefile	2004-03-01 14:18:13.000000000 +0100
@@ -0,0 +1,8 @@
+
+obj-$(CONFIG_SCSI_LPFCDD) := lpfcdd.o
+lpfcdd-objs := lpfc_core.o core.o prod_linux.o lpfcLINUXfcp.o
+
+obj-$(CONFIG_SCSI_LPFNDD) += lpfndd.o
+lpfndd-objs := lpfcLINUXlan.o
+
+EXTRA_CFLAGS += -Idrivers/scsi
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/Makefile.emulex linux-2.6.3/drivers/scsi/lpfc/Makefile.emulex
--- linux-2.6.3.emulex/drivers/scsi/lpfc/Makefile.emulex	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/Makefile.emulex	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,373 @@
+#/*******************************************************************
+# * This file is part of the Emulex Linux Device Driver for         *
+# * Enterprise Fibre Channel Host Bus Adapters.                     *
+# * Refer to the README file included with this package for         *
+# * driver version and adapter support.                             *
+# * Copyright (C) 2004 Emulex Corporation.                          *
+# * www.emulex.com                                                  *
+# *                                                                 *
+# * This program is free software; you can redistribute it and/or   *
+# * modify it under the terms of the GNU General Public License     *
+# * as published by the Free Software Foundation; either version 2  *
+# * of the License, or (at your option) any later version.          *
+# *                                                                 *
+# * This program is distributed in the hope that it will be useful, *
+# * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+# * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+# * GNU General Public License for more details, a copy of which    *
+# * can be found in the file COPYING included with this package.    *
+# *******************************************************************/
+
+# This Makefile builds the lpfcdd and lpfndd drivers for 2.4 and 2.6
+# Linux kernels, but uses a different process depending on whether
+# it's 2.4 or 2.6.
+
+ifneq (,$(KERNELRELEASE))
+
+obj-$(CONFIG_SCSI_LPFCDD) := lpfcdd.o
+lpfcdd-objs := lpfc_core.o core.o prod_linux.o lpfcLINUXfcp.o
+
+obj-$(CONFIG_SCSI_LPFNDD) += lpfndd.o
+lpfndd-objs := lpfcLINUXlan.o
+
+EXTRA_CFLAGS += -Idrivers/scsi
+
+clean-files := *.o *.ko *.mod.o *.mod.c .*.cmd .*.flags
+
+else
+
+ifeq (,$(KERNELVERSION))
+   KERNELVERSION := $(shell uname -r)
+endif
+
+# determine if this is a 2.4.x or 2.6.x module build
+ifneq (,$(findstring 2.6., $(KERNELVERSION)))
+# Building for 2.6 kernel
+
+ifeq (,$(KSRC))
+   KSRC := /lib/modules/$(KERNELVERSION)/build
+endif
+
+modules:
+	$(MAKE) -C $(KSRC) SUBDIRS=$(PWD) CONFIG_SCSI_LPFCDD=m CONFIG_SCSI_LPFNDD=m modules
+
+modules_install:
+	install -c lpfcdd.ko /lib/modules/$(KERNELVERSION)/kernel/drivers/scsi/$(lpfc-module)
+#	install -c $(lpfn-module) /lib/modules/$(KERNELVERSION)/kernel/drivers/net/$(lpfn-module)
+	depmod -a
+
+clean:
+	$(MAKE) -C $(KSRC) SUBDIRS=$(PWD) CONFIG_SCSI_LPFCDD=m CONFIG_SCSI_LPFNDD=m clean
+
+else
+# Building for 2.4 kernel
+
+# Change  the value to 20 in the following line if varyio is desired in SLES 8.
+SLES_VARYIO = 1
+
+#HARDW = i386;
+#HARDW = ia64;
+#HARDW = ppc64;
+#HARDW = x86_64;
+#RH = /usr/src/redhat;
+#RH = /usr/src/packages;
+#APP = rpm;
+#APP = rpmbuild;
+OBJ_LOWER = fcscsib.o fcmboxb.o fcmemb.o fcelsb.o fcstratb.o fcxmitb.o fcrpib.o fcclockb.o 
+
+ia64: build
+ifeq ($(MAKECMDGOALS),ia64)
+HARDW = $(MAKECMDGOALS)
+endif
+
+ppc64: build
+ifeq ($(MAKECMDGOALS),ppc64)
+HARDW = $(MAKECMDGOALS)
+endif
+
+i386: build
+ifeq ($(MAKECMDGOALS),i386)
+HARDW = $(MAKECMDGOALS)
+endif
+
+x86_64: build
+ifeq ($(MAKECMDGOALS), x86_64)
+HARDW = $(MAKECMDGOALS)
+endif
+
+build: clean STenv obj_lower linkit
+
+modules: clean STenv  obj_lower linkit 
+
+install: STenv
+	@install -d $(MODPATH)/scsi; 
+	@install -c $(LPFCVER) $(MODPATH)/scsi/$(LPFCO).o; 
+	@install -d $(MODPATH)/net; 
+	@install -c $(LPFNVER) $(MODPATH)/net/$(LPFNO).o;  
+
+STenv: find_env STX86 STX64 STP64 STA64
+
+find_env:  
+ifeq ($(MAKECMDGOALS),RPM)
+OPTRPM = -bb
+endif
+ifeq ($(MAKECMDGOALS),rpm)
+OPTRPM = -bb
+endif
+ifeq ($(MAKECMDGOALS),src)
+OPTRPM = -bs
+endif
+ifeq ($(MAKECMDGOALS),SRC)
+OPTRPM = -bs
+endif
+ifndef ($(RH))
+############ Determine distro
+RH := $(shell if [ -e /usr/src/packages ]; then echo /usr/src/packages; \
+   else echo /usr/src/redhat; fi)
+endif
+USE_HIGHMEM_IO = 0
+ifeq ($(RH),/usr/src/redhat)
+BASERH = redhat
+else
+BASERH = packages
+USE_HIGHMEM_IO = 3
+endif
+ifndef ($(APP))
+############ Determine rpm builder
+APP := $(shell if [ -x /usr/bin/rpmbuild ]; then echo rpmbuild; \
+          else echo rpm; fi)
+endif
+ifeq ($(HARDW),)
+############ Determine hardware
+HARDT := $(shell uname -m)
+ifeq ($(HARDT),i686)
+HARDW = i386
+else
+ifeq ($(HARDT),ia64)
+HARDW = ia64
+else
+ifeq ($(HARDT),x86_64)
+HARDW = x86_64
+else
+HARDW = ppc64
+endif
+endif
+endif
+endif
+CRVERS := $(shell `echo `grep LPFC_DRIVER_VERSION ./lpfcLINUXfcp.c | grep define | sed "s/.*VERSION .//" | sed s/\"//``)
+
+############ Determine context
+ifeq ($(CONFIG_SCSI_LPFC),m)
+ CONTX = KM
+else
+ ifeq ($(CONFIG_SCSI_LPFC),y)
+  CONTX = KB
+ else
+ CONTX = MO
+ endif
+endif
+
+ifeq ($(CONTX),MO)
+############ Determine includes 
+LIBPATH := /lib/modules/$(KERNELVERSION)
+MODPATH := $(LIBPATH)/kernel/drivers
+BASEINCLUDE := $(shell if [ -e $(LIBPATH)/build ]; then \
+             echo $(LIBPATH)/build; \
+             else if [ -e /usr/src/linux-2.4 ]; then \
+             echo /usr/src/linux-2.4; else echo /usr/src/linux; fi fi)
+else
+LIBPATH := $(shell if [ -e $(MODLIB) ]; then \
+             echo $(MODLIB); \
+             else echo /lib/modules/$(KERNELVERSION); fi)
+BASEINCLUDE := $(TOPDIR)
+MODPATH = $(LIBPATH)/kernel/drivers
+endif
+
+ifeq ($(HARDW),ppc64)
+ifndef ($(CROSS_COMPILE))
+CROSS_COMPILE := $(shell if [ -e /usr/local/ppc64-current3.0/bin/powerpc64-linux-gcc ]; then \
+    echo /usr/local/ppc64-current3.0/bin/powerpc64-linux-; \
+    else if [ -e /opt/cross/bin/powerpc64-linux-gcc ]; then \
+    echo /opt/cross/bin/powerpc64-linux- ; fi fi)
+endif
+endif
+MODINC = -DMODULE -DMODVERSIONS -include $(BASEINCLUDE)/include/linux/modversions.h 
+
+# The following variable controls VARYIO support:
+# If
+# VARYIO=1, the system will attempt to configure VARYIO support automatically
+# VARYIO=20, we set ".can_do_vary = 1" in the Scsi_Host_Template (Ex: SLES, AS2.1/IA64)
+# VARYIO=21, we use SCSI_HOST_VARYIO macro (Ex: AS2.1/x86)
+# VARYIO=3, we set ".vary_io = 1" in the Scsi_Host_Template (Ex: AS3.0)
+# any other value of VARYIO will disable VARYIO support (Ex: RH 9.0)
+
+VARYIO = $(SLES_VARYIO)
+ifeq ($(VARYIO),1)
+  VARYIO = 0 
+  ifeq ($(findstring release 2,$(shell cat /etc/redhat-release  2>/dev/null)),release 2)
+     ifeq ($(HARDT),i686)
+             VARYIO = 21
+             USE_HIGHMEM_IO = 2
+     else
+             USE_HIGHMEM_IO = 3
+             VARYIO = 20
+     endif
+  else
+    ifeq ($(findstring release 3,$(shell cat /etc/redhat-release  2>/dev/null)),release 3)
+       VARYIO = 3
+       USE_HIGHMEM_IO = 3
+    endif
+  endif
+endif
+
+ENV += -DVARYIO=$(VARYIO)
+ENV += -DUSE_HIGHMEM_IO=$(USE_HIGHMEM_IO)
+
+AS	=$(CROSS_COMPILE)as
+LD	=$(CROSS_COMPILE)ld
+CC	=$(CROSS_COMPILE)gcc
+CPP	=$(CC) -E
+AR	=$(CROSS_COMPILE)ar
+NM	=$(CROSS_COMPILE)nm
+STRIP	=$(CROSS_COMPILE)strip
+OBJDUMP	=$(CROSS_COMPILE)objdump
+AWK	=awk
+MAKE	=make
+GENKSYMS=/sbin/genksyms
+LPFCO   = lpfcdd
+LPFNO   = lpfndd
+ifeq ($(CONTX),MO)
+LPFCVER = $(LPFCO).o
+LPFNVER = $(LPFNO).o
+else
+LPFCVER = ../$(LPFCO).o
+LPFNVER = $(LPFNO).o
+endif
+OBJ_CORE_L = lpfc_core.o core.o prod_linux.o
+OBJ_PROD_L = lpfcLINUXfcp.o 
+OBJ_PROD_U = lpfcLINUXlan.o 
+
+
+obj_lower: 
+	$(CC) $(CDEFS) -D__KERNEL__ $(CFLAGS) $(ENV) $(INCLUDEDIR) -c lpfc_core.c
+	$(CC) $(CDEFS) -D__KERNEL__ $(CFLAGS) $(ENV) $(INCLUDEDIR) -c core.c
+	$(CC) $(CDEFS) -D__KERNEL__ $(CFLAGS) $(ENV) $(INCLUDEDIR) -c prod_linux.c
+	$(CC) $(CDEFS) -D__KERNEL__ $(CFLAGS) $(ENV) $(INCLUDEDIR) -c lpfcLINUXfcp.c 
+	$(CC) $(CDEFS) -D__KERNEL__ $(CFLAGS) $(ENV) $(INCLUDEDIR) -c lpfcLINUXlan.c
+linkit:
+ifeq ($(CONTX),KB)
+	ld -m $(ELF) -r -o ../lpfcdd.o $(OBJ_CORE_L) $(OBJ_PROD_L) $(OBJ_PROD_U)
+else
+	$(LD) -m $(ELF) -r -o $(LPFCVER) $(OBJ_CORE_L) $(OBJ_PROD_L)  
+	$(LD) -m $(ELF) -r -o $(LPFNVER) $(OBJ_PROD_U) 
+endif
+fastdep: clean
+
+clean:
+	@rm -fr ../lpfcdd.o
+	@rm -fr *.o
+
+kbuild_clean: clean
+	@rm $(VERSION_FILE)
+
+modules_install: STenv
+	@mkdir -p $(MODPATH)/net; 
+	@cp $(LPFNO).o $(MODPATH)/net/; 
+	@mkdir -p $(MODPATH)/scsi; 
+	@cp ../$(LPFCO).o $(MODPATH)/scsi/; 
+
+STX86:
+
+ifeq ($(HARDW),i386)
+CDEFS = -Wall -O2 -fomit-frame-pointer
+INCDIR = -I$(BASEINCLUDE)/include -I$(BASEINCLUDE)/drivers/scsi -I$(BASEINCLUDE)/include/scsi
+ELF = elf_i386 
+ifeq ($(CONTX),KB)
+INCLUDEDIR = $(INCDIR) 
+else
+INCLUDEDIR = $(INCDIR) $(MODINC) 
+endif
+endif
+
+STX64:
+ifeq ($(HARDW),ia64)
+INCDIR = -I$(BASEINCLUDE)/include -I$(BASEINCLUDE)/drivers/scsi -I$(BASEINCLUDE)/include/scsi 
+INCLUDEDIR = $(MODINC) $(INCDIR)
+ELF =  elf64_ia64
+ifeq ($(CONTX),MO)
+CDEFS = -Wall -O2 -fomit-frame-pointer
+CFLAGS = -Wstrict-prototypes -fno-strict-aliasing -pipe \
+       -Wa,-x -ffixed-r13 -mfixed-range=f10-f15,f32-f127 -funwind-tables  \
+       -falign-functions=32 -mb-step
+else
+ifeq ($(CONTX),KB)
+INCLUDEDIR = $(INCDIR) 
+endif
+endif
+endif
+
+STA64:
+ifeq ($(HARDW),x86_64)
+INCDIR = -I$(BASEINCLUDE)/include -I$(BASEINCLUDE)/drivers/scsi -I$(BASEINCLUDE)/include/scsi 
+INCLUDEDIR = $(MODINC) $(INCDIR)
+ELF =  elf_x86_64
+ifeq ($(CONTX),MO)
+CDEFS = -Wall -O2 -fomit-frame-pointer
+CFLAGS = -Wstrict-prototypes -Wno-trigraphs -fno-strict-aliasing -fno-common \
+         -mno-red-zone -mcmodel=kernel -pipe -fno-reorder-blocks -finline-limit=2000 \
+         -fno-strength-reduce -fno-asynchronous-unwind-tables 
+else
+ifeq ($(CONTX),KB)
+INCLUDEDIR = $(INCDIR) 
+endif
+endif
+endif
+
+STP64:
+ifeq ($(HARDW),ppc64)
+INCDIR = -I$(BASEINCLUDE)/include -I$(BASEINCLUDE)/drivers/scsi -I$(BASEINCLUDE)/include/scsi 
+ELF = elf64ppc
+ifeq ($(CONTX),MO)
+ifeq ($(BASERH),redhat)
+CDEFS = -m64 -Wall -O2 
+else
+CDEFS = -Wall -O2 
+endif
+CFLAGS = -Wstrict-prototypes -Wno-trigraphs \
+         -fno-strict-aliasing -fno-common  -Wno-unused \
+         -fomit-frame-pointer -fsigned-char -msoft-float \
+         -pipe -Wno-uninitialized -mminimal-toc -fno-builtin 
+INCLUDEDIR = $(MODINC) $(INCDIR) 
+else
+ifeq ($(CONTX),KB)
+INCLUDEDIR = $(INCDIR) 
+else
+ifeq ($(CONTX),KM)
+INCDIR = -I$(BASEINCLUDE)/include/scsi -I$(BASEINCLUDE)/drivers/scsi -I$(BASEINCLUDE)/include 
+INCLUDEDIR = $(MODINC) $(INCDIR) 
+endif
+endif
+endif
+endif
+
+src: SRC
+SRC: BRPM
+
+rpm: RPM
+RPM: BRPM 
+
+BRPM:	clean find_env
+	rm -rf /tmp/lpfcdriver-$(CRVERS); mkdir -p /tmp/lpfcdriver-$(CRVERS); cp * /tmp/lpfcdriver-$(CRVERS) 
+	cd /tmp; tar -cf $(RH)/SOURCES/lpfc-rpm.tar lpfcdriver-$(CRVERS)
+	rm -rf /tmp/lpfcdriver-$(CRVERS)
+ifeq ($(BASERH),packages)
+	@cat  ./lpfc.spec | sed s/LPFC_DRIVER_VERSION/$(CRVERS)/ | sed s/redhat/packages/ >  $(RH)/SPECS/lpfc.spec
+else
+	@cat  ./lpfc.spec | sed s/LPFC_DRIVER_VERSION/$(CRVERS)/ >  $(RH)/SPECS/lpfc.spec
+endif
+	$(APP) $(OPTRPM) $(RH)/SPECS/lpfc.spec
+
+endif
+
+endif
+
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/core.c linux-2.6.3/drivers/scsi/lpfc/core.c
--- linux-2.6.3.emulex/drivers/scsi/lpfc/core.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/core.c	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,11361 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#include "elx_os.h"
+#include "elx_util.h"
+#include "elx_clock.h"
+#include "elx_hw.h"
+#include "elx_mem.h"
+#include "elx_sli.h"
+#include "elx_sched.h"
+#include "elx.h"
+#include "elx_logmsg.h"
+#include "elx_disc.h"
+#include "elx_scsi.h"
+#include "elx_crtn.h"
+#include "prod_crtn.h"
+
+/* ELS Log Message Preamble Strings - 100 */
+char elx_msgPreambleELi[] = "ELi:";	/* ELS Information */
+char elx_msgPreambleELw[] = "ELw:";	/* ELS Warning */
+char elx_msgPreambleELe[] = "ELe:";	/* ELS Error */
+char elx_msgPreambleELp[] = "ELp:";	/* ELS Panic */
+
+/* DISCOVERY Log Message Preamble Strings - 200 */
+char elx_msgPreambleDIi[] = "DIi:";	/* Discovery Information */
+char elx_msgPreambleDIw[] = "DIw:";	/* Discovery Warning */
+char elx_msgPreambleDIe[] = "DIe:";	/* Discovery Error */
+char elx_msgPreambleDIp[] = "DIp:";	/* Discovery Panic */
+
+/* MAIBOX Log Message Preamble Strings - 300 */
+/* SLI Log Message Preamble Strings    - 300 */
+char elx_msgPreambleMBi[] = "MBi:";	/* Mailbox Information */
+char elx_msgPreambleMBw[] = "MBw:";	/* Mailbox Warning */
+char elx_msgPreambleMBe[] = "MBe:";	/* Mailbox Error */
+char elx_msgPreambleMBp[] = "MBp:";	/* Mailbox Panic */
+char elx_msgPreambleSLw[] = "SLw:";	/* SLI Warning */
+char elx_msgPreambleSLe[] = "SLe:";	/* SLI Error */
+char elx_msgPreambleSLi[] = "SLi:";	/* SLI Information */
+
+/* INIT Log Message Preamble Strings - 400, 500 */
+char elx_msgPreambleINi[] = "INi:";	/* INIT Information */
+char elx_msgPreambleINw[] = "INw:";	/* INIT Warning */
+char elx_msgPreambleINc[] = "INc:";	/* INIT Error Config */
+char elx_msgPreambleINe[] = "INe:";	/* INIT Error */
+char elx_msgPreambleINp[] = "INp:";	/* INIT Panic */
+
+/* IP Log Message Preamble Strings - 600 */
+char elx_msgPreambleIPi[] = "IPi:";	/* IP Information */
+char elx_msgPreambleIPw[] = "IPw:";	/* IP Warning */
+char elx_msgPreambleIPe[] = "IPe:";	/* IP Error */
+char elx_msgPreambleIPp[] = "IPp:";	/* IP Panic */
+
+/* FCP Log Message Preamble Strings - 700, 800 */
+char elx_msgPreambleFPi[] = "FPi:";	/* FP Information */
+char elx_msgPreambleFPw[] = "FPw:";	/* FP Warning */
+char elx_msgPreambleFPe[] = "FPe:";	/* FP Error */
+char elx_msgPreambleFPp[] = "FPp:";	/* FP Panic */
+
+/* NODE Log Message Preamble Strings - 900 */
+char elx_msgPreambleNDi[] = "NDi:";	/* Node Information */
+char elx_msgPreambleNDe[] = "NDe:";	/* Node Error */
+char elx_msgPreambleNDp[] = "NDp:";	/* Node Panic */
+
+/* MISC Log Message Preamble Strings - 1200 */
+char elx_msgPreambleMIi[] = "MIi:";	/* MISC Information */
+char elx_msgPreambleMIw[] = "MIw:";	/* MISC Warning */
+char elx_msgPreambleMIc[] = "MIc:";	/* MISC Error Config */
+char elx_msgPreambleMIe[] = "MIe:";	/* MISC Error */
+char elx_msgPreambleMIp[] = "MIp:";	/* MISC Panic */
+
+/* Link Log Message Preamble Strings - 1300 */
+char elx_msgPreambleLKi[] = "LKi:";	/* Link Information */
+char elx_msgPreambleLKw[] = "LKw:";	/* Link Warning */
+char elx_msgPreambleLKe[] = "LKe:";	/* Link Error */
+char elx_msgPreambleLKp[] = "Lkp:";	/* Link Panic */
+
+/* CHECK CONDITION Log Message Preamble Strings - 1500 */
+char elx_msgPreambleCKi[] = "CKi:";	/* Check Condition Information */
+char elx_msgPreambleCKe[] = "CKe:";	/* Check Condition Error */
+char elx_msgPreambleCKp[] = "CKp:";	/* Check Condition Panic */
+
+/* IOCtl Log Message Preamble Strings - 1600 */
+char elx_msgPreambleIOi[] = "IOi:";	/* IOCtl Information */
+char elx_msgPreambleIOw[] = "IOw:";	/* IOCtl Warning */
+char elx_msgPreambleIOe[] = "IOe:";	/* IOCtl Error */
+char elx_msgPreambleIOp[] = "IOp:";	/* IOCtl Panic */
+
+/* 
+ * The format of all code below this point must meet rules specified by 
+ * the ultility MKLOGRPT.
+ */
+
+/*
+ *  Begin ELS LOG message structures
+ */
+
+/*
+msgName: elx_mes0100
+message:  FLOGI failure
+descript: An ELS FLOGI command that was sent to the fabric failed.
+data:     (1) ulpStatus (2) ulpWord[4]
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0100[] = "%sFLOGI failure Data: x%x x%x";
+msgLogDef elx_msgBlk0100 = {
+	ELX_LOG_MSG_EL_0100,
+	elx_mes0100,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0101
+message:  FLOGI completes successfully
+descript: An ELS FLOGI command that was sent to the fabric succeeded.
+data:     (1) ulpWord[4] (2) e_d_tov (3) r_a_tov (4) edtovResolution
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0101[] = "%sFLOGI completes sucessfully Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0101 = {
+	ELX_LOG_MSG_EL_0101,
+	elx_mes0101,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0102
+message:  PLOGI completes to NPort <nlp_DID>
+descript: The HBA performed a PLOGI into a remote NPort
+data:     (1) ulpStatus (2) ulpWord[4] (3) disc (4) num_disc_nodes
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0102[] = "%sPLOGI completes to NPort x%x Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0102 = {
+	ELX_LOG_MSG_EL_0102,
+	elx_mes0102,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0103
+message:  PRLI completes to NPort <nlp_DID>
+descript: The HBA performed a PRLI into a remote NPort
+data:     (1) ulpStatus (2) ulpWord[4] (3) num_disc_nodes
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0103[] = "%sPRLI completes to NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0103 = {
+	ELX_LOG_MSG_EL_0103,
+	elx_mes0103,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0104
+message:  ADISC completes to NPort <nlp_DID>
+descript: The HBA performed a ADISC into a remote NPort
+data:     (1) ulpStatus (2) ulpWord[4] (3) disc (4) num_disc_nodes
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0104[] = "%sADISC completes to NPort x%x Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0104 = {
+	ELX_LOG_MSG_EL_0104,
+	elx_mes0104,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0105
+message:  LOGO completes to NPort <nlp_DID>
+descript: The HBA performed a LOGO to a remote NPort
+data:     (1) ulpStatus (2) ulpWord[4] (3) num_disc_nodes
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0105[] = "%sLOGO completes to NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0105 = {
+	ELX_LOG_MSG_EL_0105,
+	elx_mes0105,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0106
+message:  ELS cmd tag <ulpIoTag> completes
+descript: The specific ELS command was completed by the firmware.
+data:     (1) ulpStatus (2) ulpWord[4]
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0106[] = "%sELS cmd tag x%x completes Data: x%x x%x";
+msgLogDef elx_msgBlk0106 = {
+	ELX_LOG_MSG_EL_0106,
+	elx_mes0106,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0107
+message:  Retry ELS command <elsCmd> to remote NPORT <did>
+descript: The driver is retrying the specific ELS command.
+data:     (1) retry (2) delay
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0107[] =
+    "%sRetry ELS command x%x to remote NPORT x%x Data: x%x x%x";
+msgLogDef elx_msgBlk0107 = {
+	ELX_LOG_MSG_EL_0107,
+	elx_mes0107,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0108
+message:  No retry ELS command <elsCmd> to remote NPORT <did>
+descript: The driver decided not to retry the specific ELS command that failed.
+data:     (1) retry (2) nlp_flag
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0108[] =
+    "%sNo retry ELS command x%x to remote NPORT x%x Data: x%x x%x";
+msgLogDef elx_msgBlk0108 = {
+	ELX_LOG_MSG_EL_0108,
+	elx_mes0108,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0109
+message:  ACC to LOGO completes to NPort <nlp_DID>
+descript: The driver received a LOGO from a remote NPort and successfully issued an ACC response.
+data:     (1) nlp_flag (2) nlp_state (3) nlp_rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0109[] = "%sACC to LOGO completes to NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0109 = {
+	ELX_LOG_MSG_EL_0109,
+	elx_mes0109,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0110
+message:  ELS response tag <ulpIoTag> completes
+descript: The specific ELS response was completed by the firmware.
+data:     (1) ulpStatus (2) ulpWord[4] (3) nlp_DID (4) nlp_flag (5) nlp_state (6) nle.nlp_rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0110[] =
+    "%sELS response tag x%x completes Data: x%x x%x x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0110 = {
+	ELX_LOG_MSG_EL_0110,
+	elx_mes0110,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0111
+message:  Dropping received ELS cmd
+descript: The driver decided to drop an ELS Response ring entry
+data:     (1) ulpStatus (2) ulpWord[4]
+severity: Error
+log:      Always
+action:   This error could indicate a software driver or firmware 
+          problem. If problems persist report these errors to 
+          Technical Support.
+*/
+char elx_mes0111[] = "%sDropping received ELS cmd Data: x%x x%x";
+msgLogDef elx_msgBlk0111 = {
+	ELX_LOG_MSG_EL_0111,
+	elx_mes0111,
+	elx_msgPreambleELe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0112
+message:  ELS command <elsCmd> received from NPORT <did> 
+descript: Received the specific ELS command from a remote NPort.
+data:     (1) fc_ffstate
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0112[] = "%sELS command x%x received from NPORT x%x Data: x%x";
+msgLogDef elx_msgBlk0112 = {
+	ELX_LOG_MSG_EL_0112,
+	elx_mes0112,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0113
+message:  An FLOGI ELS command <elsCmd> was received from DID <did> in Loop Mode
+descript: While in Loop Mode an unknown or unsupported ELS commnad 
+          was received.
+data:     None
+severity: Error
+log:      Always
+action:   Check device DID
+*/
+char elx_mes0113[] =
+    "%sAn FLOGI ELS command x%x was received from DID x%x in Loop Mode";
+msgLogDef elx_msgBlk0113 = {
+	ELX_LOG_MSG_EL_0113,
+	elx_mes0113,
+	elx_msgPreambleELe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0114
+message:  PLOGI chkparm OK
+descript: Recieved a PLOGI from a remote NPORT and its Fibre Channel service 
+          parameters match this HBA. Request can be accepted.
+data:     (1) nlp_DID (2) nlp_state (3) nlp_flag (4) nlp_Rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0114[] = "%sPLOGI chkparm OK Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0114 = {
+	ELX_LOG_MSG_EL_0114,
+	elx_mes0114,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0115
+message:  Unknown ELS command <elsCmd> received from NPORT <did> 
+descript: Received an unsupported ELS command from a remote NPORT.
+data:     None
+severity: Error
+log:      Always
+action:   Check remote NPORT for potential problem.
+*/
+char elx_mes0115[] = "%sUnknown ELS command x%x received from NPORT x%x";
+msgLogDef elx_msgBlk0115 = {
+	ELX_LOG_MSG_EL_0115,
+	elx_mes0115,
+	elx_msgPreambleELe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0116
+message:  Xmit ELS command <elsCmd> to remote NPORT <did>
+descript: Xmit ELS command to remote NPORT 
+data:     (1) icmd->ulpIoTag (2) binfo->fc_ffstate
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0116[] = "%sXmit ELS command x%x to remote NPORT x%x Data: x%x x%x";
+msgLogDef elx_msgBlk0116 = {
+	ELX_LOG_MSG_EL_0116,
+	elx_mes0116,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0117
+message:  Xmit ELS response <elsCmd> to remote NPORT <did>
+descript: Xmit ELS response to remote NPORT 
+data:     (1) icmd->ulpIoTag (2) size
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0117[] =
+    "%sXmit ELS response x%x to remote NPORT x%x Data: x%x x%x";
+msgLogDef elx_msgBlk0117 = {
+	ELX_LOG_MSG_EL_0117,
+	elx_mes0117,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0118
+message:  Xmit CT response on exchange <xid>
+descript: Xmit a CT response on the appropriate exchange.
+data:     (1) ulpIoTag (2) fc_ffstate
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0118[] = "%sXmit CT response on exchange x%x Data: x%x x%x";
+msgLogDef elx_msgBlk0118 = {
+	ELX_LOG_MSG_EL_0118,
+	elx_mes0118,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0119
+message:  Issue GEN REQ IOCB for NPORT <did>
+descript: Issue a GEN REQ IOCB for remote NPORT.  These are typically
+          used for CT request. 
+data:     (1) ulpIoTag (2) fc_ffstate
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0119[] = "%sIssue GEN REQ IOCB for NPORT x%x Data: x%x x%x";
+msgLogDef elx_msgBlk0119 = {
+	ELX_LOG_MSG_EL_0119,
+	elx_mes0119,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0120
+message:  PLOGI chkparm OK
+descript: Recieved a PLOGI from a remote NPORT and its Fibre Channel service 
+          parameters match this HBA. Request can be accepted.
+data:     (1) nlp_DID (2) nlp_state (3) nlp_flag (4) nlp_Rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0120[] = "%sPLOGI chkparm OK Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0120 = {
+	ELX_LOG_MSG_EL_0120,
+	elx_mes0120,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0121
+message:  PLOGI chkparm OK
+descript: Recieved a PLOGI from a remote NPORT and its Fibre Channel service 
+          parameters match this HBA. Request can be accepted.
+data:     (1) nlp_DID (2) nlp_state (3) nlp_flag (4) nlp_Rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0121[] = "%sPLOGI chkparm OK Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0121 = {
+	ELX_LOG_MSG_EL_0121,
+	elx_mes0121,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0122
+message:  PLOGI chkparm OK
+descript: Recieved a PLOGI from a remote NPORT and its Fibre Channel service 
+          parameters match this HBA. Request can be accepted.
+data:     (1) nlp_DID (2) nlp_state (3) nlp_flag (4) nlp_Rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0122[] = "%sPLOGI chkparm OK Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0122 = {
+	ELX_LOG_MSG_EL_0122,
+	elx_mes0122,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0123
+message:  PLOGI chkparm OK
+descript: Recieved a PLOGI from a remote NPORT and its Fibre Channel service 
+          parameters match this HBA. Request can be accepted.
+data:     (1) nlp_DID (2) nlp_state (3) nlp_flag (4) nlp_Rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0123[] = "%sPLOGI chkparm OK Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0123 = {
+	ELX_LOG_MSG_EL_0123,
+	elx_mes0123,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0124
+message:  PLOGI chkparm OK
+descript: Recieved a PLOGI from a remote NPORT and its Fibre Channel service 
+          parameters match this HBA. Request can be accepted.
+data:     (1) nlp_DID (2) nlp_state (3) nlp_flag (4) nlp_Rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0124[] = "%sPLOGI chkparm OK Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0124 = {
+	ELX_LOG_MSG_EL_0124,
+	elx_mes0124,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0125
+message:  PLOGI chkparm OK
+descript: Recieved a PLOGI from a remote NPORT and its Fibre Channel service 
+          parameters match this HBA. Request can be accepted.
+data:     (1) nlp_DID (2) nlp_state (3) nlp_flag (4) nlp_Rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0125[] = "%sPLOGI chkparm OK Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0125 = {
+	ELX_LOG_MSG_EL_0125,
+	elx_mes0125,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0126
+message:  PLOGI chkparm OK
+descript: Recieved a PLOGI from a remote NPORT and its Fibre Channel service 
+          parameters match this HBA. Request can be accepted.
+data:     (1) nlp_DID (2) nlp_state (3) nlp_flag (4) nlp_Rpi
+severity: Information
+log:      LOG_ELS verbose
+action:   No action needed, informational
+*/
+char elx_mes0126[] = "%sPLOGI chkparm OK Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0126 = {
+	ELX_LOG_MSG_EL_0126,
+	elx_mes0126,
+	elx_msgPreambleELi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_ELS,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0127
+message:  ELS timeout
+descript: An ELS IOCB command was posted to a ring and did not complete
+          within ULP timeout seconds.
+data:     (1) elscmd (2) did (3) ulpcommand (4) iotag
+severity: Error
+log:      Always
+action:   If no ELS command is going through the adapter, reboot the system;
+          If problem persists, contact Technical Support.
+*/
+char elx_mes0127[] = "%sELS timeout Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0127 = {
+	ELX_LOG_MSG_EL_0127,
+	elx_mes0127,
+	elx_msgPreambleELe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_ELS,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+ *  Begin DSCOVERY LOG Message Structures
+ */
+
+/*
+msgName: elx_mes0200
+message:  CONFIG_LINK bad hba state <hba_state>
+descript: A CONFIG_LINK mbox command completed and the driver was not in the right state.
+data:     none
+severity: Error
+log:      Always
+action:   Software driver error.
+          If this problem persists, report these errors to Technical Support.
+*/
+char elx_mes0200[] = "%sCONFIG_LINK bad hba state x%x";
+msgLogDef elx_msgBlk0200 = {
+	ELX_LOG_MSG_DI_0200,
+	elx_mes0200,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0201
+message:  Abort outstanding I/O on NPort <nlp_DID>
+descript: All outstanding I/Os are cleaned up on the specified remote NPort.
+data:     (1) nlp_flag (2) nlp_state (3) nle.nlp_rpi
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0201[] = "%sAbort outstanding I/O on NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0201 = {
+	ELX_LOG_MSG_DI_0201,
+	elx_mes0201,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0202
+message:  Start Discovery hba state <hba_state>
+descript: Device discovery / rediscovery after FLOGI, FAN or RSCN has started.
+data:     (1) tmo (2) fc_plogi_cnt (3) fc_adisc_cnt
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0202[] = "%sStart Discovery hba state x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0202 = {
+	ELX_LOG_MSG_DI_0202,
+	elx_mes0202,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0203
+message:  Nodev timeout on NPort <nlp_DID>
+descript: A remote NPort the was discovered by the driver disappeared for more than ELX_NODEV_TMO seconds.
+data:     (1) nlp_flag (2) nlp_state (3) nlp_rpi
+severity: Error
+log:      Always
+action:   Check connections to Fabric / HUB or remote device.
+*/
+char elx_mes0203[] = "%sNodev timeout on NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0203 = {
+	ELX_LOG_MSG_DI_0203,
+	elx_mes0203,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0204
+message:  Create SCSI Target <tgt>
+descript: A mapped FCP target was discovered and the driver has allocated resources for it.
+data:     none
+severity: Information
+log:      LOG_DISCOVERY | LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0204[] = "%sCreate SCSI Target %d";
+msgLogDef elx_msgBlk0204 = {
+	ELX_LOG_MSG_DI_0204,
+	elx_mes0204,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY | LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0205
+message:  Create SCSI LUN <lun> on Target <tgt>
+descript: A LUN on a mapped FCP target was discovered and the driver has allocated resources for it.
+data:     none
+severity: Information
+log:      LOG_DISCOVERY | LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0205[] = "%sCreate SCSI LUN %d on Target %d";
+msgLogDef elx_msgBlk0205 = {
+	ELX_LOG_MSG_DI_0205,
+	elx_mes0205,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY | LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0206
+message:  Report Lun completes on NPort <nlp_DID>
+descript: The driver issued a REPORT_LUN SCSI command to a FCP target and it completed.
+data:     (1) ulpStatus (2) rspStatus2 (3) rspStatus3 (4) nlp_failMask
+severity: Information
+log:      LOG_DISCOVERY | LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0206[] =
+    "%sReport Lun completes on NPort x%x status: x%x status2: x%x status3: x%x failMask: x%x";
+msgLogDef elx_msgBlk0206 = {
+	ELX_LOG_MSG_DI_0206,
+	elx_mes0206,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY | LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0207
+message:  Issue Report LUN on NPort <nlp_DID>
+descript: The driver issued a REPORT_LUN SCSI command to a FCP target.
+data:     (1) nlp_failMask (2) nlp_state (3) nlp_rpi
+severity: Information
+log:      LOG_DISCOVERY | LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0207[] = "%sIssue Report LUN on NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0207 = {
+	ELX_LOG_MSG_DI_0207,
+	elx_mes0207,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY | LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0208
+message:  Failmask change on NPort <nlp_DID>
+descript: An event was processed that indicates the driver may not be able to communicate with
+          the remote NPort.
+data:     (1) nlp_failMask (2) bitmask (3) flag
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0208[] = "%sFailmask change on NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0208 = {
+	ELX_LOG_MSG_DI_0208,
+	elx_mes0208,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0209
+message:  RFT request completes ulpStatus <ulpStatus> CmdRsp <CmdRsp>
+descript: A RFT request that was sent to the fabric completed.
+data:     (1) nlp_failMask (2) bitmask (3) flag
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0209[] = "%sRFT request completes ulpStatus x%x CmdRsp x%x";
+msgLogDef elx_msgBlk0209 = {
+	ELX_LOG_MSG_DI_0209,
+	elx_mes0209,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0210
+message:  Continue discovery with <num_disc_nodes> ADISCs to go
+descript: Device discovery is in progress
+data:     (1) fc_adisc_cnt (2) fc_flag (3) phba->hba_state
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0210[] =
+    "%sContinue discovery with %d ADISCs to go Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0210 = {
+	ELX_LOG_MSG_DI_0210,
+	elx_mes0210,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0211
+message:  DSM in event <evt> on NPort <nlp_DID> in state <cur_state>
+descript: The driver Discovery State Machine is processing an event.
+data:     (1) nlp_flag
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0211[] = "%sDSM in event x%x on NPort x%x in state %d Data: x%x";
+msgLogDef elx_msgBlk0211 = {
+	ELX_LOG_MSG_DI_0211,
+	elx_mes0211,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0212
+message:  DSM out state <rc> on NPort <nlp_DID>
+descript: The driver Discovery State Machine completed processing an event.
+data:     (1) nlp_flag
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0212[] = "%sDSM out state %d on NPort x%x Data: x%x";
+msgLogDef elx_msgBlk0212 = {
+	ELX_LOG_MSG_DI_0212,
+	elx_mes0212,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0213
+message:  Reassign scsi id <sid> to NPort <nlp_DID>
+descript: A previously bound FCP Target has been rediscovered and reassigned a scsi id.
+data:     (1) nlp_bind_type (2) nlp_flag (3) nlp_state (4) nlp_rpi
+severity: Information
+log:      LOG_DISCOVERY | LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0213[] =
+    "%sReassign scsi id x%x to NPort x%x Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0213 = {
+	ELX_LOG_MSG_DI_0213,
+	elx_mes0213,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY | LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0214
+message:  RSCN received
+descript: A RSCN ELS command was received from a fabric.
+data:     (1) fc_flag (2) i (3) *lp (4) fc_rscn_id_cnt
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0214[] = "%sRSCN received Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0214 = {
+	ELX_LOG_MSG_DI_0214,
+	elx_mes0214,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0215
+message:  RSCN processed
+descript: A RSCN ELS command was received from a fabric and processed.
+data:     (1) fc_flag (2) cnt (3) fc_rscn_id_cnt (4) fc_ffstate
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0215[] = "%sRSCN processed Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0215 = {
+	ELX_LOG_MSG_DI_0215,
+	elx_mes0215,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0216
+message:  Assign scandown scsi id <sid> to NPort <nlp_DID>
+descript: A scsi id is assigned due to BIND_ALPA.
+data:     (1) nlp_bind_type (2) nlp_flag (3) nlp_state (4) nlp_rpi
+severity: Information
+log:      LOG_DISCOVERY | LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0216[] =
+    "%sAssign scandown scsi id x%x to NPort x%x Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0216 = {
+	ELX_LOG_MSG_DI_0216,
+	elx_mes0216,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY | LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0217
+message:  Unknown Identifier in RSCN payload
+descript: Typically the identifier in the RSCN payload specifies 
+          a domain, area or a specific NportID. If neither of 
+          these are specified, a warning will be recorded. 
+data:     (1) didp->un.word
+detail:   (1) Illegal identifier
+severity: Error
+log:      Always
+action:   Potential problem with Fabric. Check with Fabric vendor.
+*/
+char elx_mes0217[] = "%sUnknown Identifier in RSCN payload Data: x%x";
+msgLogDef elx_msgBlk0217 = {
+	ELX_LOG_MSG_DI_0217,
+	elx_mes0217,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0218
+message:  FDMI Request
+descript: The driver is sending an FDMI request to the fabric.
+data:     (1) fc_flag (2) hba_state (3) cmdcode
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0218[] = "%sFDMI Request Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0218 = {
+	ELX_LOG_MSG_DI_0218,
+	elx_mes0218,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0219
+message:  Issue FDMI request failed
+descript: Cannot issue FDMI request to HBA.
+data:     (1) cmdcode
+severity: Information
+log:      LOG_Discovery verbose
+action:   No action needed, informational
+*/
+char elx_mes0219[] = "%sIssue FDMI request failed Data: x%x";
+msgLogDef elx_msgBlk0219 = {
+	ELX_LOG_MSG_DI_0219,
+	elx_mes0219,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0220
+message:  FDMI rsp failed
+descript: An error response was received to FDMI request
+data:     (1) SWAP_DATA16(fdmi_cmd)
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   The fabric does not support FDMI, check fabric configuration.
+*/
+char elx_mes0220[] = "%sFDMI rsp failed Data: x%x";
+msgLogDef elx_msgBlk0220 = {
+	ELX_LOG_MSG_DI_0220,
+	elx_mes0220,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0221
+message:  FAN timeout
+descript: A link up event was received without the login bit set, 
+          so the driver waits E_D_TOV for the Fabric to send a FAN. 
+          If no FAN if received, a FLOGI will be sent after the timeout. 
+data:     None
+severity: Warning
+log:      LOG_DISCOVERY verbose
+action:   None required. The driver recovers from this condition by 
+          issuing a FLOGI to the Fabric.
+*/
+char elx_mes0221[] = "%sFAN timeout";
+msgLogDef elx_msgBlk0221 = {
+	ELX_LOG_MSG_DI_0221,
+	elx_mes0221,
+	elx_msgPreambleDIw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_DISCOVERY,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+msgName: elx_mes0222
+message:  Initial FLOGI timeout
+descript: The driver sent the initial FLOGI to fabric and never got a response back.
+data:     None
+severity: Error
+log:      Always
+action:   Check Fabric configuration. The driver recovers from this and 
+          continues with device discovery.
+*/
+char elx_mes0222[] = "%sInitial FLOGI timeout";
+msgLogDef elx_msgBlk0222 = {
+	ELX_LOG_MSG_DI_0222,
+	elx_mes0222,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+msgName: elx_mes0223
+message:  Timeout while waiting for NameServer login 
+descript: Our login request to the NameServer was not acknowledged 
+          within RATOV.
+data:     None
+severity: Error
+log:      Always
+action:   Check Fabric configuration. The driver recovers from this and 
+          continues with device discovery.
+*/
+char elx_mes0223[] = "%sTimeout while waiting for NameServer login";
+msgLogDef elx_msgBlk0223 = {
+	ELX_LOG_MSG_DI_0223,
+	elx_mes0223,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+msgName: elx_mes0224
+message:  NameServer Query timeout
+descript: Node authentication timeout, node Discovery timeout. A NameServer 
+          Query to the Fabric or discovery of reported remote NPorts is not 
+          acknowledged within R_A_TOV. 
+data:     (1) fc_ns_retry (2) fc_max_ns_retry
+severity: Error
+log:      Always
+action:   Check Fabric configuration. The driver recovers from this and 
+          continues with device discovery.
+*/
+char elx_mes0224[] = "%sNameServer Query timeout Data: x%x x%x";
+msgLogDef elx_msgBlk0224 = {
+	ELX_LOG_MSG_DI_0224,
+	elx_mes0224,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+msgName: elx_mes0225
+message:  Device Discovery completes
+descript: This indicates successful completion of device 
+          (re)discovery after a link up. 
+data:     None
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0225[] = "%sDevice Discovery completes";
+msgLogDef elx_msgBlk0225 = {
+	ELX_LOG_MSG_DI_0225,
+	elx_mes0225,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0226
+message:  Device Discovery completion error
+descript: This indicates an uncorrectable error was encountered 
+          during device (re)discovery after a link up. Fibre 
+          Channel devices will not be accessible if this message 
+          is displayed.
+data:     None
+severity: Error
+log:      Always
+action:   Reboot system. If problem persists, contact Technical 
+          Support. Run with verbose mode on for more details.
+*/
+char elx_mes0226[] = "%sDevice Discovery completion error";
+msgLogDef elx_msgBlk0226 = {
+	ELX_LOG_MSG_DI_0226,
+	elx_mes0226,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0227
+message:  Node Authentication timeout
+descript: The driver has lost track of what NPORTs are being authenticated.
+data:     None
+severity: Error
+log:      Always
+action:   None required. Driver should recover from this event.
+*/
+char elx_mes0227[] = "%sNode Authentication timeout";
+msgLogDef elx_msgBlk0227 = {
+	ELX_LOG_MSG_DI_0227,
+	elx_mes0227,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+msgName: elx_mes0228
+message:  CLEAR LA timeout
+descript: The driver issued a CLEAR_LA that never completed
+data:     None
+severity: Error
+log:      Always
+action:   None required. Driver should recover from this event.
+*/
+char elx_mes0228[] = "%sCLEAR LA timeout";
+msgLogDef elx_msgBlk0228 = {
+	ELX_LOG_MSG_DI_0228,
+	elx_mes0228,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+msgName: elx_mes0229
+message:  Assign scsi ID <sid> to NPort <nlp_DID>
+descript: The driver assigned a scsi id to a discovered mapped FCP target.
+data:     (1) nlp_bind_type (2) nlp_flag (3) nlp_state (4) nlp_rpi
+severity: Information
+log:      LOG_DISCOVERY | LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0229[] = "%sAssign scsi ID x%x to NPort x%x Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0229 = {
+	ELX_LOG_MSG_DI_0229,
+	elx_mes0229,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY | LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0230
+message:  Cannot assign scsi ID on NPort <nlp_DID>
+descript: The driver cannot assign a scsi id to a discovered mapped FCP target.
+data:     (1) nlp_flag (2) nlp_state (3) nlp_rpi
+severity: Information
+log:      LOG_DISCOVERY | LOG_FCP verbose
+action:   Check persistent binding information
+*/
+char elx_mes0230[] = "%sCannot assign scsi ID on NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0230 = {
+	ELX_LOG_MSG_DI_0230,
+	elx_mes0230,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY | LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0231
+message:  RSCN timeout
+descript: The driver has lost track of what NPORTs have RSCNs pending.
+data:     (1) fc_ns_retry (2) fc_max_ns_retry
+severity: Error
+log:      Always
+action:   None required. Driver should recover from this event.
+*/
+char elx_mes0231[] = "%sRSCN timeout Data: x%x x%x";
+msgLogDef elx_msgBlk0231 = {
+	ELX_LOG_MSG_DI_0231,
+	elx_mes0231,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+msgName: elx_mes0232
+message:  Continue discovery with <num_disc_nodes> PLOGIs to go
+descript: Device discovery is in progress
+data:     (1) fc_plogi_cnt (2) fc_flag (3) phba->hba_state
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0232[] =
+    "%sContinue discovery with %d PLOGIs to go Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0232 = {
+	ELX_LOG_MSG_DI_0232,
+	elx_mes0232,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0234
+message:  ReDiscovery RSCN
+descript: The number / type of RSCNs has forced the driver to go to 
+          the nameserver and re-discover all NPORTs.
+data:     (1) fc_defer_rscn.q_cnt (2) fc_flag (3) hba_state
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0234[] = "%sReDiscovery RSCN Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0234 = {
+	ELX_LOG_MSG_DI_0234,
+	elx_mes0234,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0235
+message:  Deferred RSCN
+descript: The driver has received multiple RSCNs and has deferred the 
+          processing of the most recent RSCN.
+data:     (1) fc_defer_rscn.q_cnt (2) fc_flag (3) hba_state
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0235[] = "%sDeferred RSCN Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0235 = {
+	ELX_LOG_MSG_DI_0235,
+	elx_mes0235,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0236
+message:  NameServer Req
+descript: The driver is issuing a nameserver request to the fabric.
+data:     (1) cmdcode (2) fc_flag (3) fc_rscn_id_cnt
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0236[] = "%sNameServer Req Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0236 = {
+	ELX_LOG_MSG_DI_0236,
+	elx_mes0236,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0237
+message:  Pending Link Event during Discovery
+descript: Received link event during discovery. Causes discovery restart.
+data:     (1) hba_state (2) ulpIoTag (3) ulpStatus (4) ulpWord[4]
+severity: Warning
+log:      LOG_DISCOVERY verbose
+action:   None required unless problem persist. If persistent check cabling.
+*/
+char elx_mes0237[] =
+    "%sPending Link Event during Discovery Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0237 = {
+	ELX_LOG_MSG_DI_0237,
+	elx_mes0237,
+	elx_msgPreambleDIw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0238
+message:  NameServer Rsp
+descript: The driver received a nameserver response.
+data:     (1) Did (2) nlp_flag (3) fc_flag (4) fc_rscn_id_cnt
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0238[] = "%sNameServer Rsp Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0238 = {
+	ELX_LOG_MSG_DI_0238,
+	elx_mes0238,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0239
+message:  NameServer Rsp
+descript: The driver received a nameserver response.
+data:     (1) Did (2) ndlp (3) fc_flag (4) fc_rscn_id_cnt
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0239[] = "%sNameServer Rsp Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0239 = {
+	ELX_LOG_MSG_DI_0239,
+	elx_mes0239,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0240
+message:  NameServer Rsp Error
+descript: The driver received a nameserver response containig a status error.
+data:     (1) CommandResponse.bits.CmdRsp (2) ReasonCode (3) Explanation 
+          (4) fc_flag
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   Check Fabric configuration. The driver recovers from this and 
+          continues with device discovery.
+*/
+char elx_mes0240[] = "%sNameServer Rsp Error Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0240 = {
+	ELX_LOG_MSG_DI_0240,
+	elx_mes0240,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0241
+message:  NameServer Rsp Error
+descript: The driver received a nameserver response containig a status error.
+data:     (1) CommandResponse.bits.CmdRsp (2) ReasonCode (3) Explanation 
+          (4) fc_flag
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   Check Fabric configuration. The driver recovers from this and 
+          continues with device discovery.
+*/
+char elx_mes0241[] = "%sNameServer Rsp Error Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0241 = {
+	ELX_LOG_MSG_DI_0241,
+	elx_mes0241,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0243
+message:  Issue FDMI request failed
+descript: Cannot issue FDMI request to HBA.
+data:     (1) cmdcode
+severity: Information
+log:      LOG_Discovery verbose
+action:   No action needed, informational
+*/
+char elx_mes0243[] = "%sIssue FDMI request failed Data: x%x";
+msgLogDef elx_msgBlk0243 = {
+	ELX_LOG_MSG_DI_0243,
+	elx_mes0243,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0244
+message:  Issue FDMI request failed
+descript: Cannot issue FDMI request to HBA.
+data:     (1) cmdcode
+severity: Information
+log:      LOG_Discovery verbose
+action:   No action needed, informational
+*/
+char elx_mes0244[] = "%sIssue FDMI request failed Data: x%x";
+msgLogDef elx_msgBlk0244 = {
+	ELX_LOG_MSG_DI_0244,
+	elx_mes0244,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0245
+message:  ALPA based bind method used on an HBA which is in a nonloop topology
+descript: ALPA based bind method used on an HBA which is not
+          in a loop topology.
+data:     (1) topology
+severity: Warning
+log:      LOG_DISCOVERY verbose
+action:   Change the bind method configuration parameter of the HBA to
+          1(WWNN) or 2(WWPN) or 3(DID)
+*/
+char elx_mes0245[] =
+    "%sALPA based bind method used on an HBA which is in a nonloop topology Data: x%x";
+msgLogDef elx_msgBlk0245 = {
+	ELX_LOG_MSG_DI_0245,
+	elx_mes0245,
+	elx_msgPreambleDIw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0246
+message:  RegLogin failed 
+descript: Firmware returned failure for the specified RegLogin 
+data:     Did, mbxStatus, hbaState 
+severity: Error
+log:      Always 
+action:   This message indicates that the firmware could not do
+          RegLogin for the specified Did. It could be because
+	  there is a limitation on how many nodes an HBA can see. 
+*/
+char elx_mes0246[] = "%sRegLogin failed Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0246 = {
+	ELX_LOG_MSG_DI_0246,
+	elx_mes0246,
+	elx_msgPreambleDIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0247
+message:  Start Discovery Timer state <hba_state>
+descript: Start device discovery / RSCN rescue timer
+data:     (1) tmo (2) disctmo (3) fc_plogi_cnt (4) fc_adisc_cnt
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0247[] = "%sStart Discovery Timer state x%x Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0247 = {
+	ELX_LOG_MSG_DI_0247,
+	elx_mes0247,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0248
+message:  Cancel Discovery Timer state <hba_state>
+descript: Cancel device discovery / RSCN rescue timer
+data:     (1) fc_flag (2) rc (3) fc_plogi_cnt (4) fc_adisc_cnt
+severity: Information
+log:      LOG_DISCOVERY verbose
+action:   No action needed, informational
+*/
+char elx_mes0248[] = "%sCancel Discovery Timer state x%x Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0248 = {
+	ELX_LOG_MSG_DI_0248,
+	elx_mes0248,
+	elx_msgPreambleDIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+ *  Begin MAILBOX LOG Message Structures
+ */
+
+/*
+msgName: elx_mes0300
+message:  READ_LA: no buffers
+descript: The driver attempted to issue READ_LA mailbox command to the HBA
+          but there were no buffer available.
+data:     None
+severity: Warning
+log:      LOG_MBOX verbose
+action:   This message indicates (1) a possible lack of memory resources. Try 
+          increasing the lpfc 'num_bufs' configuration parameter to allocate 
+          more buffers. (2) A possible driver buffer management problem. If 
+          this problem persists, report these errors to Technical Support.
+*/
+char elx_mes0300[] = "%sREAD_LA: no buffers";
+msgLogDef elx_msgBlk0300 = {
+	ELX_LOG_MSG_MB_0300,
+	elx_mes0300,
+	elx_msgPreambleMBw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0301
+message:  READ_SPARAM: no buffers
+descript: The driver attempted to issue READ_SPARAM mailbox command to the 
+          HBA but there were no buffer available.
+data:     None
+severity: Warning
+log:      LOG_MBOX verbose
+action:   This message indicates (1) a possible lack of memory resources. Try 
+          increasing the lpfc 'num_bufs' configuration parameter to allocate 
+          more buffers. (2) A possible driver buffer management problem. If 
+          this problem persists, report these errors to Technical Support.
+*/
+char elx_mes0301[] = "%sREAD_SPARAM: no buffers";
+msgLogDef elx_msgBlk0301 = {
+	ELX_LOG_MSG_MB_0301,
+	elx_mes0301,
+	elx_msgPreambleMBw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0302
+message:  REG_LOGIN: no buffers
+descript: The driver attempted to issue REG_LOGIN mailbox command to the HBA
+          but there were no buffer available.
+data:     None
+severity: Warning
+log:      LOG_MBOX verbose
+action:   This message indicates (1) a possible lack of memory resources. Try 
+          increasing the lpfc 'num_bufs' configuration parameter to allocate 
+          more buffers. (2) A possible driver buffer management problem. If 
+          this problem persists, report these errors to Technical Support.
+*/
+char elx_mes0302[] = "%sREG_LOGIN: no buffers Data x%x x%x";
+msgLogDef elx_msgBlk0302 = {
+	ELX_LOG_MSG_MB_0302,
+	elx_mes0302,
+	elx_msgPreambleMBw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0304
+message:  Stray Mailbox Interrupt, mbxCommand <cmd> mbxStatus <status>.
+descript: Received a mailbox completion interrupt and there are no 
+          outstanding mailbox commands.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0304[] = "%sStray Mailbox Interrupt mbxCommand x%x mbxStatus x%x";
+msgLogDef elx_msgBlk0304 = {
+	ELX_LOG_MSG_MB_0304,
+	elx_mes0304,
+	elx_msgPreambleMBe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0305
+message:  Mbox cmd cmpl error - RETRYing
+descript: A mailbox command completed with an error status that causes the 
+          driver to reissue the mailbox command.
+data:     (1) mbxCommand (2) mbxStatus (3) word1 (4) hba_state
+severity: Information
+log:      LOG_MBOX verbose
+action:   No action needed, informational
+*/
+char elx_mes0305[] = "%sMbox cmd cmpl error - RETRYing Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0305 = {
+	ELX_LOG_MSG_MB_0305,
+	elx_mes0305,
+	elx_msgPreambleMBi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0306
+message:  CONFIG_LINK mbxStatus error <mbxStatus> HBA state <hba_state>
+descript: The driver issued a CONFIG_LINK mbox command to the HBA that failed.
+data:     none
+severity: Error
+log:      Always
+action:   This error could indicate a firmware or hardware
+          problem. Report these errors to Technical Support.
+*/
+char elx_mes0306[] = "%sCONFIG_LINK mbxStatus error x%x HBA state x%x";
+msgLogDef elx_msgBlk0306 = {
+	ELX_LOG_MSG_MB_0306,
+	elx_mes0306,
+	elx_msgPreambleMBe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0307
+message:  Mailbox Cmpl, wd0 <pmbox> wd1 <varWord> wd2 <varWord> cmpl <mbox_cmpl)
+descript: A mailbox command completed.. 
+data:     none
+severity: Information
+log:      LOG_MBOX verbose
+action:   No action needed, informational
+*/
+char elx_mes0307[] = "%sMailbox Cmpl, wd0 x%x wd1 x%x wd2 x%x cmpl x%lx";
+msgLogDef elx_msgBlk0307 = {
+	ELX_LOG_MSG_MB_0307,
+	elx_mes0307,
+	elx_msgPreambleMBi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0308
+message:  Mbox cmd issue - BUSY
+descript: The driver attempted to issue a mailbox command while the mailbox 
+          was busy processing the previous command. The processing of the 
+          new command will be deferred until the mailbox becomes available.
+data:     (1) mbxCommand (2) hba_state (3) sli_flag (4) flag
+severity: Information
+log:      LOG_MBOX verbose
+action:   No action needed, informational
+*/
+char elx_mes0308[] = "%sMbox cmd issue - BUSY Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0308 = {
+	ELX_LOG_MSG_MB_0308,
+	elx_mes0308,
+	elx_msgPreambleMBi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0309
+message:  Mailbox cmd <cmd> issue
+descript: The driver is in the process of issuing a mailbox command.
+data:     (1) hba_state (2) sli_flag (3) flag
+severity: Information
+log:      LOG_MBOX verbose
+action:   No action needed, informational
+*/
+char elx_mes0309[] = "%sMailbox cmd x%x issue Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0309 = {
+	ELX_LOG_MSG_MB_0309,
+	elx_mes0309,
+	elx_msgPreambleMBi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0310
+message:  Mailbox command <cmd> timeout
+descript: A Mailbox command was posted to the adapter and did 
+          not complete within 30 seconds.
+data:     (1) hba_state (2) sli_flag (3) mbox_active
+severity: Error
+log:      Always
+action:   This error could indicate a software driver or firmware 
+          problem. If no I/O is going through the adapter, reboot 
+          the system. If these problems persist, report these 
+          errors to Technical Support.
+*/
+char elx_mes0310[] = "%sMailbox command x%x timeout Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0310 = {
+	ELX_LOG_MSG_MB_0310,
+	elx_mes0310,
+	elx_msgPreambleMBe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MBOX,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+msgName: elx_mes0311
+message:  Mailbox command <cmd> cannot issue
+descript: Driver is in the wrong state to issue the specified command
+data:     (1) hba_state (2) sli_flag (3) flag
+severity: Information
+log:      LOG_MBOX verbose
+action:   No action needed, informational
+*/
+char elx_mes0311[] = "%sMailbox command x%x cannot issue Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0311 = {
+	ELX_LOG_MSG_MB_0311,
+	elx_mes0311,
+	elx_msgPreambleMBi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0312
+message:  Ring <ringno> handler: portRspPut <portRspPut> is bigger then rsp ring <portRspMax> 
+descript: Port rsp ring put index is > size of rsp ring
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a software driver, firmware or hardware
+          problem. Report these errors to Technical Support.
+*/
+char elx_mes0312[] =
+    "%sRing %d handler: portRspPut %d is bigger then rsp ring %d";
+msgLogDef elx_msgBlk0312 = {
+	ELX_LOG_MSG_MB_0312,
+	elx_mes0312,
+	elx_msgPreambleSLe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0313
+message:  Ring <ringno> handler: unexpected Rctl <Rctl> Type <Type> received 
+descript: The Rctl/Type of a received frame did not match any for the configured masks
+          for the specified ring.           
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a software driver or firmware 
+          problem. If problems persist report these errors to 
+          Technical Support.
+*/
+char elx_mes0313[] =
+    "%sRing %d handler: unexpected Rctl x%x Type x%x received ";
+msgLogDef elx_msgBlk0313 = {
+	ELX_LOG_MSG_MB_0313,
+	elx_mes0313,
+	elx_msgPreambleSLe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0314
+message:  Ring <ringno> issue: portCmdGet <portCmdGet> is bigger then cmd ring <portCmdMax> 
+descript: Port cmd ring get index is > size of cmd ring
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a software driver, firmware or hardware
+          problem. Report these errors to Technical Support.
+*/
+char elx_mes0314[] =
+    "%sRing %d issue: portCmdGet %d is bigger then cmd ring %d";
+msgLogDef elx_msgBlk0314 = {
+	ELX_LOG_MSG_MB_0314,
+	elx_mes0314,
+	elx_msgPreambleSLe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0315
+message:  Ring <ringno> issue: portCmdGet <portCmdGet> is bigger then cmd ring <portCmdMax> 
+descript: Port cmd ring get index is > size of cmd ring
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a software driver or firmware 
+          problem. If problems persist report these errors to 
+          Technical Support.
+*/
+char elx_mes0315[] =
+    "%sRing %d issue: portCmdGet %d is bigger then cmd ring %d";
+msgLogDef elx_msgBlk0315 = {
+	ELX_LOG_MSG_MB_0315,
+	elx_mes0315,
+	elx_msgPreambleSLe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0316
+message:  Cmd ring <ringno> put: iotag <iotag> greater then configured max <fast_iotag> wd0 <icmd>
+descript: The assigned I/O iotag is > the max allowed
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a software driver
+          problem. If problems persist report these errors to 
+          Technical Support.
+*/
+char elx_mes0316[] =
+    "%sCmd ring %d put: iotag x%x greater then configured max x%x wd0 x%x";
+msgLogDef elx_msgBlk0316 = {
+	ELX_LOG_MSG_MB_0316,
+	elx_mes0316,
+	elx_msgPreambleSLe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0317
+message:  Rsp ring <ringno> get: iotag <iotag> greater then configured max <fast_iotag> wd0 <irsp>
+descript: The assigned I/O iotag is > the max allowed
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a software driver
+          problem. If problems persist report these errors to 
+          Technical Support.
+*/
+char elx_mes0317[] =
+    "%sRsp ring %d get: iotag x%x greater then configured max x%x wd0 x%x";
+msgLogDef elx_msgBlk0317 = {
+	ELX_LOG_MSG_MB_0317,
+	elx_mes0317,
+	elx_msgPreambleSLe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0318
+message:  Outstanding I/O count for ring <ringno> is at max <fast_iotag>
+descript: We cannot assign an I/O tag because none are available. Max allowed I/Os
+          are currently outstanding.
+data:     None
+severity: Information
+log:      LOG_SLI verbose
+action:   This message indicates the adapter hba I/O queue is full. 
+          Typically this happens if you are running heavy I/O on a
+	  low-end (3 digit) adapter. Suggest you upgrade to our high-end
+	  adapter.
+*/
+char elx_mes0318[] = "%sOutstanding I/O count for ring %d is at max x%x";
+msgLogDef elx_msgBlk0318 = {
+	ELX_LOG_MSG_MB_0318,
+	elx_mes0318,
+	elx_msgPreambleSLi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0319
+descript: The driver issued a READ_SPARAM mbox command to the HBA that failed.
+data:     none
+severity: Error
+log:      Always
+action:   This error could indicate a firmware or hardware
+          problem. Report these errors to Technical Support.
+*/
+char elx_mes0319[] = "%sREAD_SPARAM mbxStatus error x%x hba state x%x>";
+msgLogDef elx_msgBlk0319 = {
+	ELX_LOG_MSG_MB_0319,
+	elx_mes0319,
+	elx_msgPreambleMBe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0320
+message:  CLEAR_LA mbxStatus error <mbxStatus> hba state <hba_state>
+descript: The driver issued a CLEAR_LA mbox command to the HBA that failed.
+data:     none
+severity: Error
+log:      Always
+action:   This error could indicate a firmware or hardware
+          problem. Report these errors to Technical Support.
+*/
+char elx_mes0320[] = "%sCLEAR_LA mbxStatus error x%x hba state x%x";
+msgLogDef elx_msgBlk0320 = {
+	ELX_LOG_MSG_MB_0320,
+	elx_mes0320,
+	elx_msgPreambleMBe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0321
+message:  Unknown IOCB command
+descript: Received an unknown IOCB command completion.
+data:     (1) ulpCommand (2) ulpStatus (3) ulpIoTag (4) ulpContext)
+severity: Error
+log:      Always
+action:   This error could indicate a software driver or firmware 
+          problem. If these problems persist, report these errors 
+          to Technical Support.
+*/
+char elx_mes0321[] = "%sUnknown IOCB command Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0321 = {
+	ELX_LOG_MSG_MB_0321,
+	elx_mes0321,
+	elx_msgPreambleSLe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0322
+message:  Ring <ringno> handler: unexpected completion IoTag <IoTag>
+descript: The driver could not find a matching command for the completion
+          received on the specified ring.           
+data:     (1) ulpStatus (2) ulpWord[4] (3) ulpCommand (4) ulpContext
+severity: Warning
+log:      LOG_SLI verbose
+action:   This error could indicate a software driver or firmware 
+          problem. If problems persist report these errors to 
+          Technical Support.
+*/
+char elx_mes0322[] =
+    "%sRing %d handler: unexpected completion IoTag x%x Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0322 = {
+	ELX_LOG_MSG_MB_0322,
+	elx_mes0322,
+	elx_msgPreambleSLw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_SLI,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0323
+message:  Unknown Mailbox command <cmd> Cmpl 
+descript: A unknown mailbox command completed.. 
+data:     (1) Mailbox Command
+severity: Error
+log:      Always
+action:   This error could indicate a software driver, firmware or hardware
+          problem. Report these errors to Technical Support.
+*/
+char elx_mes0323[] = "%sUnknown Mailbox command %x Cmpl";
+msgLogDef elx_msgBlk0323 = {
+	ELX_LOG_MSG_MB_0323,
+	elx_mes0323,
+	elx_msgPreambleMBe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0324
+message:  Adapter initialization error, mbxCmd <cmd> READ_NVPARM, mbxStatus <status>
+descript: A read nvparams mailbox command failed during config port.
+data:     (1) Mailbox Command (2) Mailbox Command Status
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0324[] =
+    "%sConfig Port initialization error, mbxCmd x%x READ_NVPARM, mbxStatus x%x";
+msgLogDef elx_msgBlk0324 = {
+	ELX_LOG_MSG_MB_0324,
+	elx_mes0324,
+	elx_msgPreambleMBe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MBOX,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+ *  Begin INIT LOG Message Structures
+ */
+
+/*
+msgName: elx_mes0405
+message:  Service Level Interface (SLI) 2 selected
+descript: A CONFIG_PORT (SLI2) mailbox command was issued. 
+data:     None
+severity: Information
+log:      LOG_INIT verbose
+action:   No action needed, informational
+*/
+char elx_mes0405[] = "%sService Level Interface (SLI) 2 selected";
+msgLogDef elx_msgBlk0405 = {
+	ELX_LOG_MSG_IN_0405,
+	elx_mes0405,
+	elx_msgPreambleINi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_INIT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0406
+message:  Memory Buffer Pool is below low water mark
+descript: A driver memory buffer pool is low on buffers. 
+data:     (1) seg (2) fc_lowmem (3) low
+severity: Warning
+log:      LOG_INIT verbose
+action:   None required. Driver will recover as buffers are returned to pool.
+*/
+char elx_mes0406[] =
+    "%sMemory Buffer Pool is below low water mark Data x%x x%x x%x";
+msgLogDef elx_msgBlk0406 = {
+	ELX_LOG_MSG_IN_0406,
+	elx_mes0406,
+	elx_msgPreambleINw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_INIT,
+	ERRID_LOG_NO_RESOURCE
+};
+
+/*
+msgName: elx_mes0407
+message:  Memory Buffer Pool is at upper limit.
+descript: A memory buffer pool cannot add more buffers because
+          it is at its himem value. 
+data:     (1) seg (2) q_cnt (3) himem
+severity: Error
+log:      Always
+action:   None required. Driver will recover as buffers are returned to pool.
+*/
+char elx_mes0407[] =
+    "%sMemory Buffer Pool is at its high water mark Data x%x x%x x%x";
+msgLogDef elx_msgBlk0407 = {
+	ELX_LOG_MSG_IN_0407,
+	elx_mes0407,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_NO_RESOURCE
+};
+
+/*
+msgName: elx_mes0409
+message:  Memory Buffer Pool is out of buffers
+descript: A driver memory buffer pool is exhausted.
+data:     (1) seg (2) fc_free (3) fc_mbox.q_cnt (4) fc_memhi
+severity: Error
+log:      Always
+action:   Configure more resources for that buffer pool. If 
+          problems persist report these errors to Technical 
+          Support.
+*/
+char elx_mes0409[] = "%sMemory Buffer Pool is out of buffers Data x%x x%x x%x";
+msgLogDef elx_msgBlk0409 = {
+	ELX_LOG_MSG_IN_0409,
+	elx_mes0409,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_NO_RESOURCE
+};
+
+/*
+msgName: elx_mes0410
+message:  Cannot find virtual addr for mapped buf on ring <num>
+descript: The driver cannot find the specified buffer in its 
+          mapping table. Thus it cannot find the virtual address 
+          needed to access the data.
+data:     (1) first (2) q_first (3) q_last (4) q_cnt
+severity: Error
+log:      Always
+action:   This error could indicate a software driver or firmware 
+          problem. If problems persist report these errors to 
+          Technical Support.
+*/
+char elx_mes0410[] =
+    "%sCannot find virtual addr for mapped buf on ring %d Data x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0410 = {
+	ELX_LOG_MSG_IN_0410,
+	elx_mes0410,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_NO_RESOURCE
+};
+
+/*
+msgName: elx_mes0411
+message:  fcp_bind_method is 4 with Persistent binding - ignoring fcp_bind_method
+descript: The configuration parameter for fcp_bind_method conflicts with 
+          Persistent binding parameter.
+data:     (1) a_current (2) fcp_mapping
+severity: Error config
+log:      Always
+action:   Make necessary changes to lpfc configuration file.
+*/
+char elx_mes0411[] =
+    "%sfcp_bind_method is 4 with Persistent binding - ignoring fcp_bind_method Data: x%x x%x";
+msgLogDef elx_msgBlk0411 = {
+	ELX_LOG_MSG_IN_0411,
+	elx_mes0411,
+	elx_msgPreambleINc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0412
+message:  Scan-down is out of range - ignoring scan-down
+descript: The configuration parameter for Scan-down is out of range.
+data:     (1) clp[CFG_SCAN_DOWN].a_current (2) fcp_mapping
+severity: Error
+log:      Always
+action:   Make necessary changes to lpfc configuration file.
+*/
+char elx_mes0412[] =
+    "%sScan-down is out of range - ignoring scan-down Data: x%x x%x";
+msgLogDef elx_msgBlk0412 = {
+	ELX_LOG_MSG_IN_0412,
+	elx_mes0412,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0413
+message:  Configuration parameter out of range, resetting to default value
+descript: User is attempting to set a configuration parameter to a value not 
+          supported by the driver. Resetting the configuration parameter to the
+          default value.
+data:     (1) a_string (2) a_low (3) a_hi (4) a_default
+severity: Error config
+log:      Always
+action:   Make necessary changes to lpfc configuration file.
+*/
+char elx_mes0413[] =
+    "%sConfiguration parameter lpfc_%s out of range [%d,%d]. Using default value %d";
+msgLogDef elx_msgBlk0413 = {
+	ELX_LOG_MSG_IN_0413,
+	elx_mes0413,
+	elx_msgPreambleINc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0430
+message:  WWPN binding entry <num>: Syntax error code <code>
+descript: A syntax error occured while parsing WWPN binding 
+          configuration information.
+data:     None
+detail:   Binding syntax error codes
+          0  FC_SYNTAX_OK
+          1  FC_SYNTAX_OK_BUT_NOT_THIS_BRD
+          2  FC_SYNTAX_ERR_ASC_CONVERT
+          3  FC_SYNTAX_ERR_EXP_COLON
+          4  FC_SYNTAX_ERR_EXP_LPFC
+          5  FC_SYNTAX_ERR_INV_LPFC_NUM
+          6  FC_SYNTAX_ERR_EXP_T
+          7  FC_SYNTAX_ERR_INV_TARGET_NUM
+          8  FC_SYNTAX_ERR_EXP_D
+          9  FC_SYNTAX_ERR_INV_DEVICE_NUM
+          10 FC_SYNTAX_ERR_INV_RRATIO_NUM
+          11 FC_SYNTAX_ERR_EXP_NULL_TERM
+severity: Error config
+log:      Always
+action:   Make necessary changes to lpfc configuration file.
+*/
+char elx_mes0430[] = "%sWWPN binding entry %d: Syntax error code %d";
+msgLogDef elx_msgBlk0430 = {
+	ELX_LOG_MSG_IN_0430,
+	elx_mes0430,
+	elx_msgPreambleINc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0431
+message:  WWNN binding entry <num>: Syntax error code <code>
+descript: A syntax error occured while parsing WWNN binding 
+          configuration information.
+data:     None
+detail:   Binding syntax error codes
+          0  FC_SYNTAX_OK
+          1  FC_SYNTAX_OK_BUT_NOT_THIS_BRD
+          2  FC_SYNTAX_ERR_ASC_CONVERT
+          3  FC_SYNTAX_ERR_EXP_COLON
+          4  FC_SYNTAX_ERR_EXP_LPFC
+          5  FC_SYNTAX_ERR_INV_LPFC_NUM
+          6  FC_SYNTAX_ERR_EXP_T
+          7  FC_SYNTAX_ERR_INV_TARGET_NUM
+          8  FC_SYNTAX_ERR_EXP_D
+          9  FC_SYNTAX_ERR_INV_DEVICE_NUM
+          10 FC_SYNTAX_ERR_INV_RRATIO_NUM
+          11 FC_SYNTAX_ERR_EXP_NULL_TERM
+severity: Error config
+log:      Always
+action:   Make necessary changes to lpfc configuration file.
+*/
+char elx_mes0431[] = "%sWWNN binding entry %d: Syntax error code %d";
+msgLogDef elx_msgBlk0431 = {
+	ELX_LOG_MSG_IN_0431,
+	elx_mes0431,
+	elx_msgPreambleINc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0432
+message:  WWPN binding entry: node table full
+descript: More bindings entries were configured than the driver can handle. 
+data:     None
+severity: Error config
+log:      Always
+action:   Make necessary changes to lpfc configuration file such that 
+          fewer bindings are configured.
+*/
+char elx_mes0432[] = "%sWWPN binding entry: node table full";
+msgLogDef elx_msgBlk0432 = {
+	ELX_LOG_MSG_IN_0432,
+	elx_mes0432,
+	elx_msgPreambleINc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0433
+message:  WWNN binding entry: node table full
+descript: More bindings entries were configured than the driver can handle. 
+data:     None
+severity: Error config
+log:      Always
+action:   Make necessary changes to lpfc configuration file such that 
+          fewer bindings are configured.
+*/
+char elx_mes0433[] = "%sWWNN binding entry: node table full";
+msgLogDef elx_msgBlk0433 = {
+	ELX_LOG_MSG_IN_0433,
+	elx_mes0433,
+	elx_msgPreambleINc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0434
+message:  DID binding entry <num>: Syntax error code <code>
+descript: A syntax error occured while parsing DID binding 
+          configuration information.
+data:     None
+detail:   Binding syntax error codes
+          0  FC_SYNTAX_OK
+          1  FC_SYNTAX_OK_BUT_NOT_THIS_BRD
+          2  FC_SYNTAX_ERR_ASC_CONVERT
+          3  FC_SYNTAX_ERR_EXP_COLON
+          4  FC_SYNTAX_ERR_EXP_LPFC
+          5  FC_SYNTAX_ERR_INV_LPFC_NUM
+          6  FC_SYNTAX_ERR_EXP_T
+          7  FC_SYNTAX_ERR_INV_TARGET_NUM
+          8  FC_SYNTAX_ERR_EXP_D
+          9  FC_SYNTAX_ERR_INV_DEVICE_NUM
+          10 FC_SYNTAX_ERR_INV_RRATIO_NUM
+          11 FC_SYNTAX_ERR_EXP_NULL_TERM
+severity: Error config
+log:      Always
+action:   Make necessary changes to lpfc configuration file.
+*/
+char elx_mes0434[] = "%sDID binding entry %d: Syntax error code %d";
+msgLogDef elx_msgBlk0434 = {
+	ELX_LOG_MSG_IN_0434,
+	elx_mes0434,
+	elx_msgPreambleINc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0435
+message:  DID binding entry: node table full
+descript: More bindings entries were configured than the driver can handle. 
+data:     None
+severity: Error config
+log:      Always
+action:   Make necessary changes to lpfc configuration file such that 
+          fewer bindings are configured.
+*/
+char elx_mes0435[] = "%sDID binding entry: node table full";
+msgLogDef elx_msgBlk0435 = {
+	ELX_LOG_MSG_IN_0435,
+	elx_mes0435,
+	elx_msgPreambleINc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0436
+message:  Adapter failed to init, timeout, status reg <status>
+descript: The adapter failed during powerup diagnostics after it was reset.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0436[] = "%sAdapter failed to init, timeout, status reg x%x";
+msgLogDef elx_msgBlk0436 = {
+	ELX_LOG_MSG_IN_0436,
+	elx_mes0436,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0437
+message:  Adapter failed to init, chipset, status reg <status>
+descript: The adapter failed during powerup diagnostics after it was reset.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0437[] = "%sAdapter failed to init, chipset, status reg x%x";
+msgLogDef elx_msgBlk0437 = {
+	ELX_LOG_MSG_IN_0437,
+	elx_mes0437,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0438
+message:  Adapter failed to init, chipset, status reg <status>
+descript: The adapter failed during powerup diagnostics after it was reset.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0438[] = "%sAdapter failed to init, chipset, status reg x%x";
+msgLogDef elx_msgBlk0438 = {
+	ELX_LOG_MSG_IN_0438,
+	elx_mes0438,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0439
+message:  Adapter failed to init, mbxCmd <cmd> READ_REV, mbxStatus <status>
+descript: Adapter initialization failed when issuing READ_REV mailbox command.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0439[] =
+    "%sAdapter failed to init, mbxCmd x%x READ_REV, mbxStatus x%x";
+msgLogDef elx_msgBlk0439 = {
+	ELX_LOG_MSG_IN_0439,
+	elx_mes0439,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0440
+message:  Adapter failed to init, mbxCmd <cmd> READ_REV detected outdated firmware
+descript: Outdated firmware was detected during initialization. 
+data:     (1) read_rev_reset
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. Update 
+          firmware. If problems persist report these errors to Technical 
+          Support.
+*/
+char elx_mes0440[] =
+    "%sAdapter failed to init, mbxCmd x%x READ_REV detected outdated firmware Data: x%x";
+msgLogDef elx_msgBlk0440 = {
+	ELX_LOG_MSG_IN_0440,
+	elx_mes0440,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0441
+message:  VPD not present on adapter, mbxCmd <cmd> DUMP VPD, mbxStatus <status>
+descript: DUMP_VPD mailbox command failed.
+data:     None
+severity: Warning
+log:      LOG_INIT verbose
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these to Technical Support.
+*/
+char elx_mes0441[] =
+    "%sVPD not present on adapter, mbxCmd x%x DUMP VPD, mbxStatus x%x";
+msgLogDef elx_msgBlk0441 = {
+	ELX_LOG_MSG_IN_0441,
+	elx_mes0441,
+	elx_msgPreambleINi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0442
+message:  Adapter failed to init, mbxCmd <cmd> CONFIG_PORT, mbxStatus <status>
+descript: Adapter initialization failed when issuing CONFIG_PORT mailbox 
+          command.
+data:     (1) hbainit
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0442[] =
+    "%sAdapter failed to init, mbxCmd x%x CONFIG_PORT, mbxStatus x%x Data: x%x";
+msgLogDef elx_msgBlk0442 = {
+	ELX_LOG_MSG_IN_0442,
+	elx_mes0442,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0446
+message:  Adapter failed to init, mbxCmd <cmd> CFG_RING, mbxStatus <status>, ring <num>
+descript: Adapter initialization failed when issuing CFG_RING mailbox command.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0446[] =
+    "%sAdapter failed to init, mbxCmd x%x CFG_RING, mbxStatus x%x, ring %d";
+msgLogDef elx_msgBlk0446 = {
+	ELX_LOG_MSG_IN_0446,
+	elx_mes0446,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0447
+message:  Adapter failed init, mbxCmd <cmd> CONFIG_LINK mbxStatus <status>
+descript: Adapter initialization failed when issuing CONFIG_LINK mailbox 
+          command.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0447[] =
+    "%sAdapter failed init, mbxCmd x%x CONFIG_LINK mbxStatus x%x";
+msgLogDef elx_msgBlk0447 = {
+	ELX_LOG_MSG_IN_0447,
+	elx_mes0447,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0448
+message:  Adapter failed to init, mbxCmd <cmd> READ_SPARM mbxStatus <status>
+descript: Adapter initialization failed when issuing READ_SPARM mailbox 
+          command.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0448[] =
+    "%sAdapter failed init, mbxCmd x%x READ_SPARM mbxStatus x%x";
+msgLogDef elx_msgBlk0448 = {
+	ELX_LOG_MSG_IN_0448,
+	elx_mes0448,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0449
+message:  WorldWide PortName Type <type> doesn't conform to IP Profile
+descript: In order to run IP, the WorldWide PortName must be of type 
+          IEEE (NAA = 1). This message displays if the adapter WWPN 
+          doesn't conform with the standard.
+data:     None
+severity: Error
+log:      Always
+action:   Turn off the network-on configuration parameter or configure 
+          a different WWPN.
+*/
+char elx_mes0449[] =
+    "%sWorldWide PortName Type x%x doesn't conform to IP Profile";
+msgLogDef elx_msgBlk0449 = {
+	ELX_LOG_MSG_IN_0449,
+	elx_mes0449,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0450
+message:  Adapter failed to init, mbxCmd <cmd> FARP, mbxStatus <status> 
+descript: Adapter initialization failed when issuing FARP mailbox command.
+data:     None
+severity: Warning
+log:      LOG_INIT verbose
+action:   None required
+*/
+char elx_mes0450[] = "%sAdapter failed to init, mbxCmd x%x FARP, mbxStatus x%x";
+msgLogDef elx_msgBlk0450 = {
+	ELX_LOG_MSG_IN_0450,
+	elx_mes0450,
+	elx_msgPreambleINw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0451
+message:  Enable interrupt handler failed
+descript: The driver attempted to register the HBA interrupt service 
+          routine with the host operating system but failed.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or driver problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0451[] = "%sEnable interrupt handler failed";
+msgLogDef elx_msgBlk0451 = {
+	ELX_LOG_MSG_IN_0451,
+	elx_mes0451,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0453
+message:  Adapter failed to init, mbxCmd <cmd> READ_CONFIG, mbxStatus <status>
+descript: Adapter initialization failed when issuing READ_CONFIG mailbox 
+          command.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0453[] =
+    "%sAdapter failed to init, mbxCmd x%x READ_CONFIG, mbxStatus x%x";
+msgLogDef elx_msgBlk0453 = {
+	ELX_LOG_MSG_IN_0453,
+	elx_mes0453,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0454
+message:  Adapter failed to init, mbxCmd <cmd> INIT_LINK, mbxStatus <status>
+descript: Adapter initialization failed when issuing INIT_LINK mailbox command.
+data:     None
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0454[] =
+    "%sAdapter failed to init, mbxCmd x%x INIT_LINK, mbxStatus x%x";
+msgLogDef elx_msgBlk0454 = {
+	ELX_LOG_MSG_IN_0454,
+	elx_mes0454,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0455
+message:  Vital Product
+descript: Vital Product Data (VPD) contained in HBA flash.
+data:     (1) vpd[0] (2) vpd[1] (3) vpd[2] (4) vpd[3]
+severity: Information
+log:      LOG_INIT verbose
+action:   No action needed, informational
+*/
+char elx_mes0455[] = "%sVital Product Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0455 = {
+	ELX_LOG_MSG_IN_0455,
+	elx_mes0455,
+	elx_msgPreambleINi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0457
+message:  Adapter Hardware Error
+descript: The driver received an interrupt indicting a possible hardware 
+          problem.
+data:     (1) status (2) status1 (3) status2
+severity: Error
+log:      Always
+action:   This error could indicate a hardware or firmware problem. If 
+          problems persist report these errors to Technical Support.
+*/
+char elx_mes0457[] = "%sAdapter Hardware Error Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0457 = {
+	ELX_LOG_MSG_IN_0457,
+	elx_mes0457,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+msgName: elx_mes0458
+message:  Bring Adapter online
+descript: The FC driver has received a request to bring the adapter 
+          online. This may occur when running lputil.
+data:     None
+severity: Warning
+log:      LOG_INIT verbose
+action:   None required
+*/
+char elx_mes0458[] = "%sBring Adapter online";
+msgLogDef elx_msgBlk0458 = {
+	ELX_LOG_MSG_IN_0458,
+	elx_mes0458,
+	elx_msgPreambleINw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_INIT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0460
+message:  Bring Adapter offline
+descript: The FC driver has received a request to bring the adapter 
+          offline. This may occur when running lputil.
+data:     None
+severity: Warning
+log:      LOG_INIT verbose
+action:   None required
+*/
+char elx_mes0460[] = "%sBring Adapter offline";
+msgLogDef elx_msgBlk0460 = {
+	ELX_LOG_MSG_IN_0460,
+	elx_mes0460,
+	elx_msgPreambleINw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_INIT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0462
+message:  Too many cmd / rsp ring entries in SLI2 SLIM
+descript: The configuration parameter for Scan-down is out of range.
+data:     (1) totiocb (2) MAX_SLI2_IOCB
+severity: Error
+log:      Always
+action:   Software driver error.
+          If this problem persists, report these errors to Technical Support.
+*/
+char elx_mes0462[] =
+    "%sToo many cmd / rsp ring entries in SLI2 SLIM Data: x%x x%x";
+msgLogDef elx_msgBlk0462 = {
+	ELX_LOG_MSG_IN_0462,
+	elx_mes0462,
+	elx_msgPreambleINe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_INIT,
+	ERRID_LOG_INIT
+};
+
+/*
+ *  Begin IP LOG Message Structures
+ */
+
+/*
+msgName: elx_mes0600
+message:  FARP-RSP received from DID <did>.
+descript: A FARP ELS command response was received.
+data:     None
+severity: Information
+log:      LOG_IP verbose
+action:   No action needed, informational
+*/
+char elx_mes0600[] = "%sFARP-RSP received from DID x%x";
+msgLogDef elx_msgBlk0600 = {
+	ELX_LOG_MSG_IP_0600,
+	elx_mes0600,
+	elx_msgPreambleIPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0601
+message:  FARP-REQ received from DID <did>
+descript: A FARP ELS command request was received.
+data:     None
+severity: Information
+log:      LOG_IP verbose
+action:   No action needed, informational
+*/
+char elx_mes0601[] = "%sFARP-REQ received from DID x%x";
+msgLogDef elx_msgBlk0601 = {
+	ELX_LOG_MSG_IP_0601,
+	elx_mes0601,
+	elx_msgPreambleIPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0602
+message:  IP Response Ring <num> out of posted buffers
+descript: The IP ring returned all posted buffers to the driver 
+          and is waiting for the driver to post new buffers. This 
+          could mean the host system is out of TCP/IP buffers. 
+data:     (1) fc_missbufcnt (2) NoRcvBuf
+severity: Warning
+log:      LOG_IP verbose
+action:   Try allocating more IP buffers (STREAMS buffers or mbufs) 
+          of size 4096 and/or increasing the post-ip-buf lpfc 
+          configuration parameter. Reboot the system.
+*/
+char elx_mes0602[] =
+    "%sIP Response Ring %d out of posted buffers Data: x%x x%x";
+msgLogDef elx_msgBlk0602 = {
+	ELX_LOG_MSG_IP_0602,
+	elx_mes0602,
+	elx_msgPreambleIPw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_IP,
+	ERRID_LOG_NO_RESOURCE
+};
+
+/*
+msgName: elx_mes0603
+message:  Xmit Sequence completion error
+descript: A XMIT_SEQUENCE command completed with a status error 
+          in the IOCB.
+data:     (1) ulpStatus (2) ulpIoTag (3) ulpWord[4] (4) did
+severity: Warning
+log:      LOG_IP verbose
+action:   If there are many errors to one device, check physical 
+          connections to Fibre Channel network and the state of 
+          the remote PortID.  The driver attempts to recover by 
+          creating a new exchange to the remote device.
+*/
+char elx_mes0603[] = "%sXmit Sequence completion error Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0603 = {
+	ELX_LOG_MSG_IP_0603,
+	elx_mes0603,
+	elx_msgPreambleIPw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0604
+message:  Post buffer for IP ring <num> failed
+descript: The driver cannot allocate a buffer to post to the IP ring. 
+          This usually means the host system is out of TCP/IP buffers. 
+data:     (1) missbufcnt
+severity: Error
+log:      Always
+action:   Try allocating more IP buffers (STREAMS buffers or mbufs) 
+          of size 4096. Reboot the system.
+*/
+char elx_mes0604[] = "%sPost buffer for IP ring %d failed Data: x%x";
+msgLogDef elx_msgBlk0604 = {
+	ELX_LOG_MSG_IP_0604,
+	elx_mes0604,
+	elx_msgPreambleIPe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_IP,
+	ERRID_LOG_NO_RESOURCE
+};
+
+/*
+msgName: elx_mes0605
+message:  No room on IP xmit queue
+descript: The system is generating IOCB commands to be processed 
+          faster than the adapter can process them. 
+data:     (1) xmitnoroom
+severity: Warning
+log:      LOG_IP verbose
+action:   Check the state of the link. If the link is up and running, 
+          reconfigure the xmit queue size to be larger. Note, a larger 
+          queue size may require more system IP buffers. If the link 
+          is down, check physical connections to Fibre Channel network.
+*/
+char elx_mes0605[] = "%sNo room on IP xmit queue Data: x%x";
+msgLogDef elx_msgBlk0605 = {
+	ELX_LOG_MSG_IP_0605,
+	elx_mes0605,
+	elx_msgPreambleIPw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0606
+message:  XRI Create for IP traffic to DID <did>.
+descript: The lpfc driver is missing an exchange resource identifier
+          (XRI) for this node and needs to create one prior to 
+          the transmit operation.
+data:     None
+severity: Information
+log:      LOG_IP verbose
+action:   No action needed, informational
+*/
+char elx_mes0606[] = "%sXRI Create for IP traffic to DID x%x";
+msgLogDef elx_msgBlk0606 = {
+	ELX_LOG_MSG_IP_0606,
+	elx_mes0606,
+	elx_msgPreambleIPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0607
+message:  XRI response from DID with XRI <xri> and status <ulpStatus>
+descript: The driver received an XRI response from SLI with the resulting
+          exchange resource id and status.
+data:     None
+severity: Information
+log:      LOG_IP verbose
+action:   No action needed, informational
+*/
+char elx_mes0607[] = "%sXRI response from DID x%x with XRI x%x and status x%x";
+msgLogDef elx_msgBlk0607 = {
+	ELX_LOG_MSG_IP_0607,
+	elx_mes0607,
+	elx_msgPreambleIPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0608
+message:  IP packet timed out 
+descript: An IP IOCB command was posted to a ring and did not complete
+          within timeout seconds.
+data:     (1) Did
+severity: Warning
+log:      LOG_IP verbose
+action:   If no IP packet is going through the adapter, reboot the system;
+          If problem persists, contact Technical Support.
+*/
+char elx_mes0608[] = "%sIP packet timed out Data: x%x";
+msgLogDef elx_msgBlk0608 = {
+	ELX_LOG_MSG_IP_0608,
+	elx_mes0608,
+	elx_msgPreambleIPw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0609
+message:  Network buffer and DMA address mismatch
+descript: An IP buffer free operation found a mismatch between an
+          IP buffer and its dma address.
+data:     (1) pib (2) ip buff found (3) ip buf actual (4) dma address
+severity: Error
+log:      Always
+action:   Stop traffic and reboot the system.
+*/
+char elx_mes0609[] =
+    "%sIP buffer-DMA address mismatch Data: x%llx x%llx x%llx x%llx";
+msgLogDef elx_msgBlk0609 = {
+	ELX_LOG_MSG_IP_0609,
+	elx_mes0609,
+	elx_msgPreambleIPe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0610
+message:  FARP Request sent to remote DID
+descript: A send to a remote IP address has no node in the driver's nodelists.
+          Send a FARP request to obtain the node's HW address.
+data:     (1) IEEE[0] (2) IEEE[1] (3) IEEE[2] (4) IEEE[3] (5) IEEE[4] (6) IEEE[5] 
+severity: Information
+log:      LOG_IP verbose
+action:   Issue FARP and wait for PLOGI from remote node.
+*/
+char elx_mes0610[] =
+    "%sFARP Request sent to remote HW Address %02x-%02x-%02x-%02x-%02x-%02x";
+msgLogDef elx_msgBlk0610 = {
+	ELX_LOG_MSG_IP_0610,
+	elx_mes0610,
+	elx_msgPreambleIPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+ *  Begin FCP LOG Message Structures
+ */
+
+/*
+msgName: elx_mes0700
+message:  Start nodev timer
+descript: A target disappeared from the Fibre Channel network. If the 
+          target does not return within nodev-tmo timeout all I/O to 
+          the target will fail.
+data:     (1) nlp_DID (2) nlp_flag (3) nlp_state (4) nlp
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0700[] = "%sStart nodev timer Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0700 = {
+	ELX_LOG_MSG_FP_0700,
+	elx_mes0700,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0701
+message:  Issue Abort Task Set to TGT <num> LUN <num>
+descript: The SCSI layer detected that it needs to abort all I/O 
+          to a specific device. This results in an FCP Task 
+          Management command to abort the I/O in progress. 
+data:     (1) rpi (2) flags
+severity: Information
+log:      LOG_FCP verbose
+action:   Check state of device in question. 
+*/
+char elx_mes0701[] = "%sIssue Abort Task Set to TGT %d LUN %d Data: x%x x%x";
+msgLogDef elx_msgBlk0701 = {
+	ELX_LOG_MSG_FP_0701,
+	elx_mes0701,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0702
+message:  Issue Target Reset to TGT <num>
+descript: The SCSI layer detected that it needs to abort all I/O 
+          to a specific target. This results in an FCP Task 
+          Management command to abort the I/O in progress. 
+data:     (1) rpi (2) flags
+severity: Information
+log:      LOG_FCP verbose
+action:   Check state of target in question. 
+*/
+char elx_mes0702[] = "%sIssue Target Reset to TGT %d Data: x%x x%x";
+msgLogDef elx_msgBlk0702 = {
+	ELX_LOG_MSG_FP_0702,
+	elx_mes0702,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0703
+message:  Issue LUN Reset to TGT <num> LUN <num>
+descript: The SCSI layer detected that it needs to abort all I/O 
+          to a specific device. This results in an FCP Task 
+          Management command to abort the I/O in progress. 
+data:     (1) rpi (2) flags
+severity: Information
+log:      LOG_FCP verbose
+action:   Check state of device in question. 
+*/
+char elx_mes0703[] = "%sIssue LUN Reset to TGT %d LUN %d Data: x%x x%x";
+msgLogDef elx_msgBlk0703 = {
+	ELX_LOG_MSG_FP_0703,
+	elx_mes0703,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0706
+message:  Start nodev timer
+descript: A target disappeared from the Fibre Channel network. If the 
+          target does not return within nodev-tmo timeout all I/O to 
+          the target will fail.
+data:     (1) nlp_DID (2) nlp_flag (3) nlp_state (4) nlp
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0706[] = "%sStart nodev timer Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0706 = {
+	ELX_LOG_MSG_FP_0706,
+	elx_mes0706,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0710
+message:  Iodone <target>/<lun> error <result> SNS <lp> <lp3>
+descript: This error indicates the FC driver is returning SCSI 
+          command to the SCSI layer in error or with sense data.
+data:     (1) retry (2) resid
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0710[] = "%sIodone <%d/%d> error x%x SNS x%x x%x Data: x%x x%x";
+msgLogDef elx_msgBlk0710 = {
+	ELX_LOG_MSG_FP_0710,
+	elx_mes0710,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0712
+message:  SCSI layer issued abort device
+descript: The SCSI layer is requesting the driver to abort 
+          I/O to a specific device.
+data:     (1) target (2) lun (3)
+severity: Error
+log:      Always
+action:   Check state of device in question.
+*/
+char elx_mes0712[] = "%sSCSI layer issued abort device Data: x%x x%x";
+msgLogDef elx_msgBlk0712 = {
+	ELX_LOG_MSG_FP_0712,
+	elx_mes0712,
+	elx_msgPreambleFPe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0713
+message:  SCSI layer issued Target Reset
+descript: The SCSI layer is requesting the driver to abort 
+          I/O to a specific target.
+data:     (1) target (2) lun 
+severity: Error
+log:      Always
+action:   Check state of target in question.
+*/
+char elx_mes0713[] = "%sSCSI layer issued Target Reset Data: x%x x%x";
+msgLogDef elx_msgBlk0713 = {
+	ELX_LOG_MSG_FP_0713,
+	elx_mes0713,
+	elx_msgPreambleFPe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0714
+message:  SCSI layer issued Bus Reset
+descript: The SCSI layer is requesting the driver to abort 
+          all I/Os to all targets on this HBA.
+data:     (1) tgt (2) lun (3) rc - success / failure
+severity: Error
+log:      Always
+action:   Check state of targets in question.
+*/
+char elx_mes0714[] = "%sSCSI layer issued Bus Reset Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0714 = {
+	ELX_LOG_MSG_FP_0714,
+	elx_mes0714,
+	elx_msgPreambleFPe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0716
+message:  FCP Read Underrun, expected <len>, residual <resid>
+descript: FCP device provided less data than was requested.
+data:     (1) fcpi_parm (2) cmnd[0] (3) underflow 
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0716[] =
+    "%sFCP Read Underrun, expected %d, residual %d Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0716 = {
+	ELX_LOG_MSG_FP_0716,
+	elx_mes0716,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0717
+message:  FCP command <cmd> residual underrun converted to error
+descript: The driver convert this underrun condition to an error based 
+          on the underflow field in the SCSI cmnd.
+data:     (1) len (2) resid (3) underflow
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0717[] =
+    "%sFCP command x%x residual underrun converted to error Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0717 = {
+	ELX_LOG_MSG_FP_0717,
+	elx_mes0717,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0729
+message:  FCP cmd <cmnd> failed <target>/<lun>
+descript: The specifed device failed an FCP command. 
+data:     (1) status (2) result (3) xri (4) iotag
+severity: Warning
+log:      LOG_FCP verbose
+action:   Check the state of the target in question.
+*/
+char elx_mes0729[] =
+    "%sFCP cmd x%x failed <%d/%d> status: x%x result: x%x Data: x%x x%x";
+msgLogDef elx_msgBlk0729 = {
+	ELX_LOG_MSG_FP_0729,
+	elx_mes0729,
+	elx_msgPreambleFPw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0730
+message:  FCP command failed: RSP
+descript: The FCP command failed with a response error.
+data:     (1) Status2 (2) Status3 (3) ResId (4) SnsLen (5) RspLen (6) Info3
+severity: Warning
+log:      LOG_FCP verbose
+action:   Check the state of the target in question.
+*/
+char elx_mes0730[] = "%sFCP command failed: RSP Data: x%x x%x x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0730 = {
+	ELX_LOG_MSG_FP_0730,
+	elx_mes0730,
+	elx_msgPreambleFPw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0732
+message:  Retry FCP command due to 29,00 check condition
+descript: The issued FCP command got a 29,00 check condition and will 
+          be retried by the driver.
+data:     (1) *lp (2) *lp+1 (3) *lp+2 (4) *lp+3
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0732[] =
+    "%sRetry FCP command due to 29,00 check condition Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0732 = {
+	ELX_LOG_MSG_FP_0732,
+	elx_mes0732,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0734
+message:  FCP Read Check Error
+descript: The issued FCP command returned a Read Check Error
+data:     (1) fcpDl (2) rspResId (3) fcpi_parm (4) cdb[0]
+severity: Warning
+log:      LOG_FCP verbose
+action:   Check the state of the target in question.
+*/
+char elx_mes0734[] = "%sFCP Read Check Error Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0734 = {
+	ELX_LOG_MSG_FP_0734,
+	elx_mes0734,
+	elx_msgPreambleFPw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_FCP,
+	ERRID_LOG_HDW_ERR
+};
+
+/*
+msgName: elx_mes0735
+message:  FCP Read Check Error with Check Condition
+descript: The issued FCP command returned a Read Check Error and a 
+          Check condition.
+data:     (1) fcpDl (2) rspResId (3) fcpi_parm (4) cdb[0]
+severity: Warning
+log:      LOG_FCP verbose
+action:   Check the state of the target in question.
+*/
+char elx_mes0735[] =
+    "%sFCP Read Check Error with Check Condition Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0735 = {
+	ELX_LOG_MSG_FP_0735,
+	elx_mes0735,
+	elx_msgPreambleFPw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_FCP | LOG_CHK_COND,
+	ERRID_LOG_HDW_ERR
+};
+
+/*
+msgName: elx_mes0736
+message:  Recieved Queue Full status from FCP device <tgt> <lun>.
+descript: Recieved a Queue Full error status from specified FCP device.
+data:     (1) qfull_retry_count (2) qfull_retries (3) currentOutstanding (4) maxOutstanding
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0736[] =
+    "%sRecieved Queue Full status from FCP device %d %d Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0736 = {
+	ELX_LOG_MSG_FP_0736,
+	elx_mes0736,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0737
+message:  <ASC ASCQ> Check condition received
+descript: The issued FCP command resulted in a Check Condition.
+data:     (1) CFG_CHK_COND_ERR (2) CFG_DELAY_RSP_ERR (3) *lp
+severity: Information
+log:      LOG_FCP | LOG_CHK_COND verbose
+action:   No action needed, informational
+*/
+char elx_mes0737[] = "%sx%x Check condition received Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0737 = {
+	ELX_LOG_MSG_FP_0737,
+	elx_mes0737,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP | LOG_CHK_COND,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0747
+message:  Cmpl Target Reset
+descript: A driver initiated Target Reset completed.
+data:     (1) scsi_id (2) lun_id (3) statLocalError (4) *cmd + WD7
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0747[] = "%sCmpl Target Reset Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0747 = {
+	ELX_LOG_MSG_FP_0747,
+	elx_mes0747,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0748
+message:  Cmpl LUN Reset
+descript: A driver initiated LUN Reset completed.
+data:     (1) scsi_id (2) lun_id (3) statLocalError (4) *cmd + WD7
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0748[] = "%sCmpl LUN Reset Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0748 = {
+	ELX_LOG_MSG_FP_0748,
+	elx_mes0748,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0749
+message:  Cmpl Abort Task Set
+descript: A driver initiated Abort Task Set completed.
+data:     (1) scsi_id (2) lun_id (3) statLocalError (4) *cmd + WD7
+severity: Information
+log:      LOG_FCP verbose
+action:   No action needed, informational
+*/
+char elx_mes0749[] = "%sCmpl Abort Task Set Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0749 = {
+	ELX_LOG_MSG_FP_0749,
+	elx_mes0749,
+	elx_msgPreambleFPi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_FCP,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0754
+message:  SCSI timeout
+descript: An FCP IOCB command was posted to a ring and did not complete 
+          within ULP timeout seconds.
+data:     (1) did (2) sid (3) command (4) iotag
+severity: Error
+log:      Always
+action:   If no I/O is going through the adapter, reboot the system; 
+          If problem persists, contact Technical Support.
+*/
+char elx_mes0754[] = "%sSCSI timeout Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0754 = {
+	ELX_LOG_MSG_FP_0754,
+	elx_mes0754,
+	elx_msgPreambleFPe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_FCP,
+	ERRID_LOG_TIMEOUT
+};
+
+/*
+ *  Begin NODE LOG Message Structures
+ */
+
+/*
+msgName: elx_mes0900
+message:  Cleanup node for NPort <nlp_DID>
+descript: The driver node table entry for a remote NPort was removed.
+data:     (1) nlp_flag (2) nlp_state (3) nlp_rpi
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0900[] = "%sCleanup node for NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk0900 = {
+	ELX_LOG_MSG_ND_0900,
+	elx_mes0900,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0901
+message:  FIND node DID mapped
+descript: The driver is searching for a node table entry, on the 
+          mapped node list, based on DID.
+data:     (1) nlp (2) nlp_DID (3) nlp_flag (4) data1
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0901[] = "%sFIND node DID mapped Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0901 = {
+	ELX_LOG_MSG_ND_0901,
+	elx_mes0901,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0902
+message:  FIND node DID mapped
+descript: The driver is searching for a node table entry, on the 
+          mapped node list, based on DID.
+data:     (1) nlp (2) nlp_DID (3) nlp_flag (4) data1
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0902[] = "%sFIND node DID mapped Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0902 = {
+	ELX_LOG_MSG_ND_0902,
+	elx_mes0902,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0903
+message:  Add scsiid <sid> to BIND list 
+descript: The driver is putting the node table entry on the binding list.
+data:     (1) bind_cnt (2) nlp_DID (3) bind_type (4) blp
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0903[] = "%sAdd scsiid %d to BIND list Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0903 = {
+	ELX_LOG_MSG_ND_0903,
+	elx_mes0903,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0904
+message:  Add NPort <did> to PLOGI list
+descript: The driver is putting the node table entry on the plogi list.
+data:     (1) plogi_cnt (2) blp
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0904[] = "%sAdd NPort x%x to PLOGI list Data: x%x x%x";
+msgLogDef elx_msgBlk0904 = {
+	ELX_LOG_MSG_ND_0904,
+	elx_mes0904,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0905
+message:  Add NPort <did> to ADISC list
+descript: The driver is putting the node table entry on the adisc list.
+data:     (1) adisc_cnt (2) blp
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0905[] = "%sAdd NPort x%x to ADISC list Data: x%x x%x";
+msgLogDef elx_msgBlk0905 = {
+	ELX_LOG_MSG_ND_0905,
+	elx_mes0905,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0906
+message:  Add NPort <did> to UNMAP list
+descript: The driver is putting the node table entry on the unmap list.
+data:     (1) unmap_cnt (2) blp
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0906[] = "%sAdd NPort x%x to UNMAP list Data: x%x x%x";
+msgLogDef elx_msgBlk0906 = {
+	ELX_LOG_MSG_ND_0906,
+	elx_mes0906,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0907
+message:  Add NPort <did> to MAP list scsiid <sid>
+descript: The driver is putting the node table entry on the mapped list.
+data:     (1) map_cnt (2) blp
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0907[] = "%sAdd NPort x%x to MAP list scsiid %d Data: x%x x%x";
+msgLogDef elx_msgBlk0907 = {
+	ELX_LOG_MSG_ND_0907,
+	elx_mes0907,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0908
+message:  FIND node DID bind
+descript: The driver is searching for a node table entry, on the 
+          binding list, based on DID.
+data:     (1) nlp (2) nlp_DID (3) nlp_flag (4) data1
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0908[] = "%sFIND node DID bind Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0908 = {
+	ELX_LOG_MSG_ND_0908,
+	elx_mes0908,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0910
+message:  FIND node DID unmapped
+descript: The driver is searching for a node table entry, on the 
+          unmapped node list, based on DID.
+data:     (1) nlp (2) nlp_DID (3) nlp_flag (4) data1
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0910[] = "%sFIND node DID unmapped Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0910 = {
+	ELX_LOG_MSG_ND_0910,
+	elx_mes0910,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0911
+message:  FIND node DID unmapped
+descript: The driver is searching for a node table entry, on the 
+          unmapped node list, based on DID.
+data:     (1) nlp (2) nlp_DID (3) nlp_flag (4) data1
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0911[] = "%sFIND node DID unmapped Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0911 = {
+	ELX_LOG_MSG_ND_0911,
+	elx_mes0911,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0927
+message:  GET nodelist
+descript: The driver is allocating a buffer to hold a node table entry.
+data:     (1) bp (2) fc_free
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0927[] = "%sGET nodelist Data: x%x x%x";
+msgLogDef elx_msgBlk0927 = {
+	ELX_LOG_MSG_ND_0927,
+	elx_mes0927,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0928
+message:  PUT nodelist
+descript: The driver is freeing a node table entry buffer.
+data:     (1) bp (2) fc_free
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0928[] = "%sPUT nodelist Data: x%x x%x";
+msgLogDef elx_msgBlk0928 = {
+	ELX_LOG_MSG_ND_0928,
+	elx_mes0928,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0929
+message:  FIND node DID unmapped
+descript: The driver is searching for a node table entry, on the 
+          unmapped node list, based on DID.
+data:     (1) nlp (2) nlp_DID (3) nlp_flag (4) data1
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0929[] = "%sFIND node DID unmapped Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0929 = {
+	ELX_LOG_MSG_ND_0929,
+	elx_mes0929,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0930
+message:  FIND node DID mapped
+descript: The driver is searching for a node table entry, on the 
+          mapped node list, based on DID.
+data:     (1) nlp (2) nlp_DID (3) nlp_flag (4) data1
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0930[] = "%sFIND node DID mapped Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0930 = {
+	ELX_LOG_MSG_ND_0930,
+	elx_mes0930,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0931
+message:  FIND node DID bind
+descript: The driver is searching for a node table entry, on the 
+          binding list, based on DID.
+data:     (1) nlp (2) nlp_DID (3) nlp_flag (4) data1
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0931[] = "%sFIND node DID bind Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk0931 = {
+	ELX_LOG_MSG_ND_0931,
+	elx_mes0931,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes0932
+message:  FIND node did <did> NOT FOUND
+descript: The driver was searching for a node table entry based on DID 
+          and the entry was not found.
+data:     (1) order
+severity: Information
+log:      LOG_NODE verbose
+action:   No action needed, informational
+*/
+char elx_mes0932[] = "%sFIND node did x%x NOT FOUND Data: x%x";
+msgLogDef elx_msgBlk0932 = {
+	ELX_LOG_MSG_ND_0932,
+	elx_mes0932,
+	elx_msgPreambleNDi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_NODE,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+ *  Begin MISC LOG message structures
+ */
+
+/*
+msgName: elx_mes1201
+message:  linux_kmalloc: Bad phba
+descript: The driver manages its own memory for internal usage. This 
+          error indicates a problem occurred in the driver memory 
+          management routines. This error could also indicate the host 
+          system in low on memory resources.
+data:     (1) size (2) type (3) fc_idx_dmapool
+severity: Error
+log:      Always
+action:   This error could indicate a driver or host operating system 
+          problem. If problems persist report these errors to Technical 
+          Support.
+*/
+char elx_mes1201[] = "%slinux_kmalloc: Bad phba Data: x%x x%x x%x";
+msgLogDef elx_msgBlk1201 = {
+	ELX_LOG_MSG_MI_1201,
+	elx_mes1201,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1202
+message:  linux_kmalloc: Bad size
+descript: The driver manages its own memory for internal usage. This 
+          error indicates a problem occurred in the driver memory 
+          management routines. This error could also indicate the host 
+          system in low on memory resources.
+data:     (1) size (2) type (3) fc_idx_dmapool
+severity: Error
+log:      Always
+action:   This error could indicate a driver or host operating system 
+          problem. If problems persist report these errors to Technical 
+          Support.
+*/
+char elx_mes1202[] = "%slinux_kmalloc: Bad size Data: x%x x%x x%x";
+msgLogDef elx_msgBlk1202 = {
+	ELX_LOG_MSG_MI_1202,
+	elx_mes1202,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1204
+message:  linux_kmalloc: Bad virtual addr
+descript: The driver manages its own memory for internal usage. This 
+          error indicates a problem occurred in the driver memory 
+          management routines. This error could also indicate the host 
+          system in low on memory resources.
+data:     (1) i (2) size ( 3) type (4) fc_idx_dmapool
+severity: Error
+log:      Always
+action:   This error could indicate a driver or host operating system 
+          problem. If problems persist report these errors to Technical 
+          Support.
+*/
+char elx_mes1204[] = "%slinux_kmalloc: Bad virtual addr Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk1204 = {
+	ELX_LOG_MSG_MI_1204,
+	elx_mes1204,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1205
+message:  linux_kmalloc: dmapool FULL
+descript: The driver manages its own memory for internal usage. This 
+          error indicates a problem occurred in the driver memory 
+          management routines. This error could also indicate the host 
+          system in low on memory resources.
+data:     (1) i (2) size (3) type (4) fc_idx_dmapool
+severity: Error
+log:      Always
+action:   This error could indicate a driver or host operating system 
+          problem. If problems persist report these errors to Technical 
+          Support.
+*/
+char elx_mes1205[] = "%slinux_kmalloc: dmapool FULL Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk1205 = {
+	ELX_LOG_MSG_MI_1205,
+	elx_mes1205,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1206
+message:  linux_kfree: Bad phba
+descript: The driver manages its own memory for internal usage. This 
+          error indicates a problem occurred in the driver memory 
+          management routines. This error could also indicate the host 
+          system in low on memory resources.
+data:     (1) size (2) fc_idx_dmapool
+severity: Error
+log:      Always
+action:   This error could indicate a driver or host operating system 
+          problem. If problems persist report these errors to Technical 
+          Support.
+*/
+char elx_mes1206[] = "%slinux_kfree: Bad phba Data: x%x x%x";
+msgLogDef elx_msgBlk1206 = {
+	ELX_LOG_MSG_MI_1206,
+	elx_mes1206,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1207
+message:  linux_kfree: NOT in dmapool
+descript: The driver manages its own memory for internal usage. This 
+          error indicates a problem occurred in the driver memory 
+          management routines. This error could also indicate the host 
+          system in low on memory resources.
+data:     (1) virt (2) size (3) fc_idx_dmapool
+severity: Error
+log:      Always
+action:   This error could indicate a driver or host operating system 
+          problem. If problems persist report these errors to Technical 
+          Support.
+*/
+char elx_mes1207[] = "%slinux_kfree: NOT in dmapool Data: x%x x%x x%x";
+msgLogDef elx_msgBlk1207 = {
+	ELX_LOG_MSG_MI_1207,
+	elx_mes1207,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1208
+descript: The CT response returned more data than the user buffer could hold. 
+message:  C_CT Request error
+data:     (1) dfc_flag (2) 4096
+severity: Information
+log:      LOG_MISC verbose
+action:   Modify user application issuing CT request to allow for a larger 
+          response buffer.
+*/
+char elx_mes1208[] = "%sC_CT Request error Data: x%x x%x";
+msgLogDef elx_msgBlk1208 = {
+	ELX_LOG_MSG_MI_1208,
+	elx_mes1208,
+	elx_msgPreambleMIi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1210
+message:  Convert ASC to hex. Input byte cnt < 1
+descript: ASCII string to hex conversion failed. Input byte count < 1.
+data:     none
+severity: Error
+log:      Always
+action:   This error could indicate a software driver problem. 
+          If problems persist report these errors to Technical Support.
+*/
+char elx_mes1210[] = "%sConvert ASC to hex. Input byte cnt < 1";
+msgLogDef elx_msgBlk1210 = {
+	ELX_LOG_MSG_MI_1210,
+	elx_mes1210,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1211
+message:  Convert ASC to hex. Input byte cnt > max <num>
+descript: ASCII string to hex conversion failed. Input byte count > max <num>.
+data:     none
+severity: Error
+log:      Always
+action:   This error could indicate a software driver problem. 
+          If problems persist report these errors to Technical Support.
+*/
+char elx_mes1211[] = "%sConvert ASC to hex. Input byte cnt > max %d";
+msgLogDef elx_msgBlk1211 = {
+	ELX_LOG_MSG_MI_1211,
+	elx_mes1211,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1212
+message:  Convert ASC to hex. Output buffer to small 
+descript: ASCII string to hex conversion failed. The output buffer byte 
+          size is less than 1/2 of input byte count. Every 2 input chars 
+          (bytes) require 1 output byte.
+data:     none
+severity: Error
+log:      Always
+action:   This error could indicate a software driver problem. 
+          If problems persist report these errors to Technical Support.
+*/
+char elx_mes1212[] = "%sConvert ASC to hex. Output buffer too small";
+msgLogDef elx_msgBlk1212 = {
+	ELX_LOG_MSG_MI_1212,
+	elx_mes1212,
+	elx_msgPreambleMIe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1213
+message:  Convert ASC to hex. Input char seq not ASC hex.
+descript: The ASCII hex input string contains a non-ASCII hex characters
+data:     none
+severity: Error configuration
+log:      Always
+action:   Make necessary changes to lpfc configuration file.
+*/
+char elx_mes1213[] = "%sConvert ASC to hex. Input char seq not ASC hex.";
+msgLogDef elx_msgBlk1213 = {
+	ELX_LOG_MSG_MI_1213,
+	elx_mes1213,
+	elx_msgPreambleMIc,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR_CFG,
+	LOG_MISC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+ *  Begin LINK LOG Message Structures
+ */
+
+/*
+msgName: elx_mes1300
+message:  Re-establishing Link, timer expired
+descript: The driver detected a condition where it had to re-initialize 
+          the link.
+data:     (1) fc_flag (2) fc_ffstate
+severity: Error
+log:      Always
+action:   If numerous link events are occurring, check physical 
+          connections to Fibre Channel network.
+*/
+char elx_mes1300[] = "%sRe-establishing Link, timer expired Data: x%x x%x";
+msgLogDef elx_msgBlk1300 = {
+	ELX_LOG_MSG_LK_1300,
+	elx_mes1300,
+	elx_msgPreambleLKe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_LINK_EVENT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1301
+message:  Re-establishing Link
+descript: The driver detected a condition where it had to re-initialize 
+          the link.
+data:     (1) status (2) status1 (3) status2
+severity: Information
+log:      LOG_LINK_EVENT verbose
+action:   If numerous link events are occurring, check physical 
+          connections to Fibre Channel network.
+*/
+char elx_mes1301[] = "%sRe-establishing Link Data: x%x x%x x%x";
+msgLogDef elx_msgBlk1301 = {
+	ELX_LOG_MSG_LK_1301,
+	elx_mes1301,
+	elx_msgPreambleLKi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_LINK_EVENT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1302
+message:  Reset link speed to auto. 1G HBA cfg'd for 2G
+descript: The driver is reinitializing the link speed to auto-detect.
+data:     (1) current link speed
+severity: Warning
+log:      LOG_LINK_EVENT verbose
+action:   None required
+*/
+char elx_mes1302[] =
+    "%sReset link speed to auto. 1G HBA cfg'd for 2G Data: x%x";
+msgLogDef elx_msgBlk1302 = {
+	ELX_LOG_MSG_LK_1302,
+	elx_mes1302,
+	elx_msgPreambleLKw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_LINK_EVENT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1303
+message:  Link Up Event <eventTag> received
+descript: A link up event was received. It is also possible for 
+          multiple link events to be received together. 
+data:     (1) fc_eventTag (2) granted_AL_PA (3) UlnkSpeed (4) alpa_map[0]
+detail:   If link events received, log (1) last event number 
+          received, (2) ALPA granted, (3) Link speed 
+          (4) number of entries in the loop init LILP ALPA map. 
+          An ALPA map message is also recorded if LINK_EVENT 
+          verbose mode is set. Each ALPA map message contains 
+          16 ALPAs. 
+severity: Error
+log:      Always
+action:   If numerous link events are occurring, check physical 
+          connections to Fibre Channel network.
+*/
+char elx_mes1303[] = "%sLink Up Event x%x received Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk1303 = {
+	ELX_LOG_MSG_LK_1303,
+	elx_mes1303,
+	elx_msgPreambleLKe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_LINK_EVENT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1304
+message:  Link Up Event ALPA map
+descript: A link up event was received.
+data:     (1) wd1 (2) wd2 (3) wd3 (4) wd4
+severity: Warning
+log:      LOG_LINK_EVENT verbose
+action:   If numerous link events are occurring, check physical 
+          connections to Fibre Channel network.
+*/
+char elx_mes1304[] = "%sLink Up Event ALPA map Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk1304 = {
+	ELX_LOG_MSG_LK_1304,
+	elx_mes1304,
+	elx_msgPreambleLKw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_LINK_EVENT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1305
+message:  Link Down Event <eventTag> received
+descript: A link down event was received.
+data:     (1) fc_eventTag (2) hba_state (3) fc_flag
+severity: Error
+log:      Always
+action:   If numerous link events are occurring, check physical 
+          connections to Fibre Channel network.
+*/
+char elx_mes1305[] = "%sLink Down Event x%x received Data: x%x x%x x%x";
+msgLogDef elx_msgBlk1305 = {
+	ELX_LOG_MSG_LK_1305,
+	elx_mes1305,
+	elx_msgPreambleLKe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_LINK_EVENT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1306
+message:  Link Down timeout
+descript: The link was down for greater than the configuration parameter 
+          (lpfc_linkdown_tmo) seconds. All I/O associated with the devices
+          on this link will be failed.  
+data:     (1) hba_state (2) fc_flag (3) fc_ns_retry
+severity: Warning
+log:      LOG_LINK_EVENT | LOG_DISCOVERY verbose
+action:   Check HBA cable/connection to Fibre Channel network.
+*/
+char elx_mes1306[] = "%sLink Down timeout Data: x%x x%x x%x";
+msgLogDef elx_msgBlk1306 = {
+	ELX_LOG_MSG_LK_1306,
+	elx_mes1306,
+	elx_msgPreambleLKw,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_WARN,
+	LOG_LINK_EVENT | LOG_DISCOVERY,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1307
+message:  READ_LA mbox error <mbxStatus> state <hba_state>
+descript: The driver cannot determine what type of link event occurred.
+data:     None
+severity: Information
+log:      LOG_LINK_EVENT verbose
+action:   If numerous link events are occurring, check physical 
+          connections to Fibre Channel network. Could indicate
+          possible hardware or firmware problem.
+*/
+char elx_mes1307[] = "%sREAD_LA mbox error x%x state x%x";
+msgLogDef elx_msgBlk1307 = {
+	ELX_LOG_MSG_LK_1307,
+	elx_mes1307,
+	elx_msgPreambleLKi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_LINK_EVENT,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+ *  Begin XXX LOG Message Structures
+ */
+
+/*
+ *  Begin IOCTL Message Structures
+ */
+
+/*
+msgName: elx_mes1600
+message:  dfc_ioctl entry
+descript: Entry point for processing diagnostic ioctl.
+data:     (1) c_cmd (2) c_arg1 (3) c_arg2 (4) c_outsz
+severity: Information
+log:      LOG_IOC verbose
+action:   No action needed, informational
+*/
+char elx_mes1600[] = "%sdfc_ioctl entry Data: x%x x%x x%x x%x";
+msgLogDef elx_msgBlk1600 = {
+	ELX_LOG_MSG_IO_1600,
+	elx_mes1600,
+	elx_msgPreambleIOi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IOC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1601
+message:  dfc_ioctl exit
+descript: Exit point for processing diagnostic ioctl.
+data:     (1) rc (2) c_outsz (3) c_dataout
+severity: Information
+log:      LOG_IOC verbose
+action:   No action needed, informational
+*/
+char elx_mes1601[] = "%sdfc_ioctl exit Data: x%x x%x x%x";
+msgLogDef elx_msgBlk1601 = {
+	ELX_LOG_MSG_IO_1601,
+	elx_mes1601,
+	elx_msgPreambleIOi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IOC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1602
+message:  dfc_data_alloc
+descript: Allocating data buffer to process dfc ioct.
+data:     (1) fc_dataout (2) fc_outsz
+severity: Iniformation
+log:      LOG_IOC verbose
+action:   No action needed, informational
+*/
+char elx_mes1602[] = "%sdfc_data_alloc Data: x%x x%x";
+msgLogDef elx_msgBlk1602 = {
+	ELX_LOG_MSG_IO_1602,
+	elx_mes1602,
+	elx_msgPreambleIOi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IOC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1603
+message:  dfc_data_free
+descript: Freeing data buffer to process dfc ioct.
+data:     (1) fc_dataout (2) fc_outsz
+severity: Information
+log:      LOG_IOC verbose
+action:   No action needed, informational
+*/
+char elx_mes1603[] = "%sdfc_data_free Data: x%x x%x";
+msgLogDef elx_msgBlk1603 = {
+	ELX_LOG_MSG_IO_1603,
+	elx_mes1603,
+	elx_msgPreambleIOi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IOC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1604
+message:  lpfc_ioctl:error
+descript: SCSI send request buffer size limited exceeded
+data:     (1) error number index
+severity: Error
+log:      Always
+action:   Reduce application program's SCSI send request buffer size to < 320K bytes.  
+*/
+char elx_mes1604[] = "%slpfc_ioctl:error Data: %d";
+msgLogDef elx_msgBlk1604 = {
+	ELX_LOG_MSG_IO_1604,
+	elx_mes1604,
+	elx_msgPreambleIOe,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_ERR,
+	LOG_IOC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+/*
+msgName: elx_mes1605
+message:  Issue Report LUN on NPort <nlp_DID>
+descript: The driver issued an Ioctl REPORT_LUN SCSI command to a FCP target.
+data:     (1) nlp_failMask (2) nlp_state (3) nlp_rpi
+severity: Information
+log:      LOG_IOC verbose
+action:   No action needed, informational
+*/
+char elx_mes1605[] = "%sIssue Report LUN on NPort x%x Data: x%x x%x x%x";
+msgLogDef elx_msgBlk1605 = {
+	ELX_LOG_MSG_IO_1605,
+	elx_mes1605,
+	elx_msgPreambleIOi,
+	ELX_MSG_OPUT_GLOB_CTRL,
+	ELX_LOG_MSG_TYPE_INFO,
+	LOG_IOC,
+	ERRID_LOG_UNEXPECT_EVENT
+};
+
+void
+elx_read_rev(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+	mb->un.varRdRev.cv = 1;
+	mb->mbxCommand = MBX_READ_REV;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+void
+elx_config_ring(elxHBA_t * phba, int ring, ELX_MBOXQ_t * pmb)
+{
+	int i;
+	MAILBOX_t *mb;
+	ELX_SLI_t *psli;
+	ELX_RING_INIT_t *pring;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->un.varCfgRing.ring = ring;
+	mb->un.varCfgRing.maxOrigXchg = 0;
+	mb->un.varCfgRing.maxRespXchg = 0;
+	mb->un.varCfgRing.recvNotify = 1;
+
+	psli = &phba->sli;
+	pring = &psli->sliinit.ringinit[ring];
+	mb->un.varCfgRing.numMask = pring->num_mask;
+	mb->mbxCommand = MBX_CONFIG_RING;
+	mb->mbxOwner = OWN_HOST;
+
+	/* Is this ring configured for a specific profile */
+	if (pring->prt[0].profile) {
+		mb->un.varCfgRing.profile = pring->prt[0].profile;
+		return;
+	}
+
+	/* Otherwise we setup specific rctl / type masks for this ring */
+	for (i = 0; i < pring->num_mask; i++) {
+		mb->un.varCfgRing.rrRegs[i].rval = pring->prt[i].rctl;
+		if (mb->un.varCfgRing.rrRegs[i].rval != FC_ELS_REQ)	/* ELS request */
+			mb->un.varCfgRing.rrRegs[i].rmask = 0xff;
+		else
+			mb->un.varCfgRing.rrRegs[i].rmask = 0xfe;
+		mb->un.varCfgRing.rrRegs[i].tval = pring->prt[i].type;
+		mb->un.varCfgRing.rrRegs[i].tmask = 0xff;
+	}
+
+	return;
+}
+
+int
+elx_config_port(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+	uint32_t *hbainit;
+	elx_dma_addr_t pdma_addr;
+	uint32_t offset;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	psli = &phba->sli;
+	mb->mbxCommand = MBX_CONFIG_PORT;
+	mb->mbxOwner = OWN_HOST;
+
+	mb->un.varCfgPort.pcbLen = sizeof (PCB_t);
+	offset =
+	    (uint8_t *) (&((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb) -
+	    (uint8_t *) phba->slim2p.virt;
+	pdma_addr = phba->slim2p.phys + offset;
+	mb->un.varCfgPort.pcbLow = putPaddrLow(pdma_addr);
+	mb->un.varCfgPort.pcbHigh = putPaddrHigh(pdma_addr);
+
+	/* Now setup pcb */
+	((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.type =
+	    TYPE_NATIVE_SLI2;
+	((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.feature =
+	    FEATURE_INITIAL_SLI2;
+
+	/* Setup Mailbox pointers */
+	((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.mailBoxSize =
+	    sizeof (MAILBOX_t);
+	offset =
+	    (uint8_t *) (&((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.mbx) -
+	    (uint8_t *) phba->slim2p.virt;
+	pdma_addr = phba->slim2p.phys + offset;
+	((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.mbAddrHigh =
+	    putPaddrHigh(pdma_addr);
+	((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.mbAddrLow =
+	    putPaddrLow(pdma_addr);
+
+	/* Setup Host Group ring counters */
+	if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+		offset =
+		    (uint8_t *) (&((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.
+				 mbx.us.s2.host) -
+		    (uint8_t *) phba->slim2p.virt;
+		pdma_addr = phba->slim2p.phys + offset;
+		((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.hgpAddrHigh =
+		    putPaddrHigh(pdma_addr);
+		((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.hgpAddrLow =
+		    putPaddrLow(pdma_addr);
+	} else {
+		uint32_t Laddr;
+		HGP hgp;
+
+		((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.hgpAddrHigh =
+		    (uint32_t)
+		    (psli->sliinit.elx_sli_read_pci) (phba, PCI_BAR_1_REGISTER);
+		Laddr =
+		    (psli->sliinit.elx_sli_read_pci) (phba, PCI_BAR_0_REGISTER);
+		Laddr &= ~0x4;
+		((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.hgpAddrLow =
+		    (uint32_t) (Laddr + (SLIMOFF * sizeof (uint32_t)));
+		memset((void *)&hgp, 0, sizeof (HGP));
+		(psli->sliinit.elx_sli_write_slim) ((void *)phba, (void *)&hgp,
+						    (SLIMOFF *
+						     sizeof (uint32_t)),
+						    sizeof (HGP));
+	}
+
+	/* Setup Port Group ring counters */
+	offset =
+	    (uint8_t *) (&((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.mbx.us.
+			 s2.port) - (uint8_t *) phba->slim2p.virt;
+	pdma_addr = phba->slim2p.phys + offset;
+	((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.pgpAddrHigh =
+	    putPaddrHigh(pdma_addr);
+	((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.pcb.pgpAddrLow =
+	    putPaddrLow(pdma_addr);
+
+	/* Use callback routine to setp rings in the pcb */
+	hbainit = (psli->sliinit.elx_sli_config_pcb_setup) (phba);
+	if (hbainit != NULL)
+		memcpy(&mb->un.varCfgPort.hbainit, hbainit, 20);
+
+	/* Swap PCB if needed */
+	elx_sli_pcimem_bcopy((uint32_t
+			      *) (&((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.
+				  pcb),
+			     (uint32_t
+			      *) (&((SLI2_SLIM_t *) phba->slim2p.virt)->un.slim.
+				  pcb), sizeof (PCB_t));
+
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORDEV);
+
+	/* Service Level Interface (SLI) 2 selected */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0405,	/* ptr to msg structure */
+		       elx_mes0405,	/* ptr to msg */
+		       elx_msgBlk0405.msgPreambleStr);	/* begin & end varargs */
+	return (0);
+}
+
+void
+elx_mbox_put(elxHBA_t * phba, ELX_MBOXQ_t * mbq)
+{				/* pointer to mbq entry */
+	ELX_SLI_t *psli;
+
+	psli = &phba->sli;
+
+	/* mboxq is a single linked list with q_first pointing to the first
+	 * element and q_last pointing to the last.
+	 */
+	if (psli->mboxq.q_first) {
+		/* queue command to end of list */
+		((ELX_MBOXQ_t *) (psli->mboxq.q_last))->q_f = mbq;
+		psli->mboxq.q_last = (ELX_SLINK_t *) mbq;
+	} else {
+		/* add command to empty list */
+		psli->mboxq.q_first = (ELX_SLINK_t *) mbq;
+		psli->mboxq.q_last = (ELX_SLINK_t *) mbq;
+	}
+
+	mbq->q_f = 0;
+	psli->mboxq.q_cnt++;
+
+	return;
+}
+
+ELX_MBOXQ_t *
+elx_mbox_get(elxHBA_t * phba)
+{
+	ELX_MBOXQ_t *p_first = 0;
+	ELX_SLI_t *psli;
+
+	psli = &phba->sli;
+
+	/* mboxq is a single linked list with q_first pointing to the first
+	 * element and q_last pointing to the last.
+	 */
+	if (psli->mboxq.q_first) {
+		p_first = (ELX_MBOXQ_t *) psli->mboxq.q_first;
+		if ((psli->mboxq.q_first = (ELX_SLINK_t *) p_first->q_f) == 0) {
+			psli->mboxq.q_last = 0;
+		}
+		p_first->q_f = 0;
+		psli->mboxq.q_cnt--;
+	}
+
+	return (p_first);
+}
+
+void *elx_mem_alloc_dma(elxHBA_t *, uint32_t, uint32_t);
+
+DMABUF_t *
+elx_mem_alloc_dmabuf(elxHBA_t * phba, uint32_t size)
+{
+	return ((DMABUF_t *) elx_mem_alloc_dma(phba, size, ELX_MEM_DBUF));
+}
+
+void *
+elx_mem_alloc_dma(elxHBA_t * phba, uint32_t size, uint32_t type)
+{
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+	DMABUF_t *matp;
+	DMABUFEXT_t *matpext;
+	void *ptr;
+
+	buf_info = &bufinfo;
+	switch (type) {
+	case ELX_MEM_DBUF:
+		buf_info->size = sizeof (DMABUF_t);
+		break;
+	case ELX_MEM_DBUFEXT:
+		buf_info->size = sizeof (DMABUFEXT_t);
+		break;
+	}
+	buf_info->flags = ELX_MBUF_VIRT;
+	buf_info->align = sizeof (void *);
+	buf_info->dma_handle = 0;
+
+	elx_malloc(phba, buf_info);
+	if (buf_info->virt == 0) {
+		return (0);
+	}
+
+	ptr = buf_info->virt;
+
+	buf_info->size = size;
+	buf_info->flags = ELX_MBUF_DMA;
+	buf_info->dma_handle = 0;
+	buf_info->virt = 0;
+
+	switch (size) {
+	case 1024:
+		buf_info->align = 1024;
+		break;
+
+	case 2048:
+		buf_info->align = 2048;
+		break;
+
+	case 4096:
+		buf_info->align = 4096;
+		break;
+
+	default:
+		buf_info->align = sizeof (void *);
+		break;
+	}
+
+	elx_malloc(phba, buf_info);
+	/* if we fail the buffer allocation, free the container */
+	if (buf_info->virt == 0) {
+		buf_info->virt = ptr;
+		buf_info->flags = ELX_MBUF_VIRT;
+		elx_free(phba, buf_info);
+		return (0);
+	}
+	memset(buf_info->virt, 0, size);
+	switch (type) {
+	case ELX_MEM_DBUF:
+		matp = (DMABUF_t *) ptr;
+		memset(matp, 0, sizeof (DMABUF_t));
+		matp->virt = buf_info->virt;
+		if (buf_info->dma_handle) {
+			matp->dma_handle = buf_info->dma_handle;
+			matp->data_handle = buf_info->data_handle;
+		}
+		matp->phys = buf_info->phys;
+		ptr = (void *)matp;
+		break;
+	case ELX_MEM_DBUFEXT:
+		matpext = (DMABUFEXT_t *) ptr;
+		memset(matpext, 0, sizeof (DMABUFEXT_t));
+		matpext->dma.virt = buf_info->virt;
+		if (buf_info->dma_handle) {
+			matpext->dma.dma_handle = buf_info->dma_handle;
+			matpext->dma.data_handle = buf_info->data_handle;
+		}
+		matpext->dma.phys = buf_info->phys;
+		matpext->size = size;
+		ptr = (void *)matpext;
+		break;
+	}
+	return (ptr);
+}
+
+DMABUFIP_t *
+elx_mem_alloc_ipbuf(elxHBA_t * phba, uint32_t size)
+{
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+	DMABUFIP_t *matip;
+
+	buf_info = &bufinfo;
+	buf_info->size = sizeof (DMABUFIP_t);
+	buf_info->flags = ELX_MBUF_VIRT;
+	buf_info->align = sizeof (void *);
+	buf_info->dma_handle = 0;
+
+	elx_malloc(phba, buf_info);
+	if (buf_info->virt == 0) {
+		return (0);
+	}
+
+	matip = (DMABUFIP_t *) buf_info->virt;
+	memset(matip, 0, sizeof (DMABUFIP_t));
+
+	elx_ip_get_rcv_buf(phba, matip, size);
+	if (matip->ipbuf == 0) {
+		elx_free(phba, buf_info);
+		matip = 0;
+	}
+	return (matip);
+}
+
+uint8_t *
+elx_mem_alloc_buf(elxHBA_t * phba, uint32_t size)
+{
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+
+	buf_info = &bufinfo;
+	buf_info->size = size;
+	buf_info->flags = ELX_MBUF_VIRT;
+	buf_info->align = sizeof (void *);
+	buf_info->dma_handle = 0;
+
+	elx_malloc(phba, buf_info);
+	if (buf_info->virt == 0) {
+		return (0);
+	}
+	memset(buf_info->virt, 0, size);
+	return (buf_info->virt);
+}
+
+uint32_t
+elx_mem_alloc_pool(elxHBA_t * phba, MEMSEG_t * mp, uint32_t cnt)
+{
+	uint8_t *bp;
+	uint8_t *oldbp;
+	DMABUF_t *matp;
+	DMABUFIP_t *matip;
+	int i;
+
+	for (i = 0; i < cnt; i++) {
+		/* If this is a DMA buffer we need alignment on a page so we don't
+		 * want to worry about buffers spanning page boundries when mapping
+		 * memory for the adapter.
+		 */
+		if (mp->elx_memflag & ELX_MEM_DMA) {
+			if ((matp =
+			     elx_mem_alloc_dmabuf(phba,
+						  mp->elx_memsize)) == 0) {
+				return (i);
+			}
+			/* Link buffer into beginning of list. The first pointer in
+			 * each buffer is a forward pointer to the next buffer.
+			 */
+			oldbp = (uint8_t *) mp->mem_hdr.q_first;
+			if (oldbp == 0)
+				mp->mem_hdr.q_last = (ELX_SLINK_t *) matp;
+			mp->mem_hdr.q_first = (ELX_SLINK_t *) matp;
+			matp->next = (DMABUF_t *) oldbp;
+		} else if (mp->elx_memflag & ELX_MEM_ATTACH_IPBUF) {
+			if ((matip =
+			     elx_mem_alloc_ipbuf(phba, mp->elx_memsize)) == 0) {
+				return (i);
+			}
+			/* Link buffer into beginning of list. The first pointer in
+			 * each buffer is a forward pointer to the next buffer.
+			 */
+			oldbp = (uint8_t *) mp->mem_hdr.q_first;
+			if (oldbp == 0)
+				mp->mem_hdr.q_last = (ELX_SLINK_t *) matip;
+			mp->mem_hdr.q_first = (ELX_SLINK_t *) matip;
+			matip->dma.next = (DMABUF_t *) oldbp;
+		} else {
+			/* Does not have to be DMAable */
+			if ((bp =
+			     elx_mem_alloc_buf(phba, mp->elx_memsize)) == 0) {
+				return (i);
+			}
+			/* Link buffer into beginning of list. The first pointer in
+			 * each buffer is a forward pointer to the next buffer.
+			 */
+			oldbp = (uint8_t *) mp->mem_hdr.q_first;
+			if (oldbp == 0)
+				mp->mem_hdr.q_last = (ELX_SLINK_t *) bp;
+			mp->mem_hdr.q_first = (ELX_SLINK_t *) bp;
+			*((uint8_t * *)bp) = oldbp;
+		}
+	}
+
+	return (i);
+}
+
+int
+elx_mem_alloc(elxHBA_t * phba)
+{
+	MEMSEG_t *mp;
+	int j, cnt;
+	unsigned long iflag;
+
+	ELX_MEM_LOCK(phba, iflag);
+	/* Allocate buffer pools for above buffer structures */
+	for (j = 0; j < ELX_MAX_SEG; j++) {
+		mp = &phba->memseg[j];
+
+		mp->mem_hdr.q_first = 0;
+		mp->mem_hdr.q_last = 0;
+
+		cnt = mp->mem_hdr.q_max;
+		/* free blocks = total blocks right now */
+		if ((mp->mem_hdr.q_cnt =
+		     elx_mem_alloc_pool(phba, mp, cnt)) != cnt) {
+			elx_mem_free(phba);
+			return (0);
+		}
+	}
+	ELX_MEM_UNLOCK(phba, iflag);
+
+	return (1);
+}
+
+int
+elx_mem_free(elxHBA_t * phba)
+{
+	uint8_t *bp;
+	MEMSEG_t *mp;
+	DMABUF_t *mm;
+	DMABUFIP_t *mmip;
+	ELX_MBOXQ_t *mbox, *mbsave;
+	ELX_SLI_t *psli;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+	int j;
+	unsigned long iflag;
+
+	buf_info = &bufinfo;
+
+	ELX_SLI_LOCK(phba, iflag);
+	/* free the mapped address match area for each ring */
+	psli = &phba->sli;
+
+	/* Free everything on mbox queue */
+	mbox = (ELX_MBOXQ_t *) (psli->mboxq.q_first);
+	while (mbox) {
+		mbsave = mbox;
+		mbox = (ELX_MBOXQ_t *) mbox->q_f;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbsave);
+	}
+	psli->mboxq.q_first = 0;
+	psli->mboxq.q_last = 0;
+	psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+	if (psli->mbox_active) {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) psli->mbox_active);
+		psli->mbox_active = 0;
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+
+	ELX_MEM_LOCK(phba, iflag);
+	/* Loop through all memory buffer pools */
+	for (j = 0; j < ELX_MAX_SEG; j++) {
+		mp = &phba->memseg[j];
+		/* Free memory associated with all buffers on free buffer pool */
+		while ((bp = (uint8_t *) mp->mem_hdr.q_first) != 0) {
+			mp->mem_hdr.q_first = *((ELX_SLINK_t * *)bp);
+			if (mp->elx_memflag & ELX_MEM_DMA) {
+				mm = (DMABUF_t *) bp;
+				bp = mm->virt;
+				buf_info->size = mp->elx_memsize;
+				buf_info->virt = (uint32_t *) bp;
+				buf_info->phys = mm->phys;
+				buf_info->flags = ELX_MBUF_DMA;
+				if (mm->dma_handle) {
+					buf_info->dma_handle = mm->dma_handle;
+					buf_info->data_handle = mm->data_handle;
+				}
+				elx_free(phba, buf_info);
+
+				buf_info->size = sizeof (DMABUF_t);
+				buf_info->virt = (uint32_t *) mm;
+				buf_info->phys = 0;
+				buf_info->flags = ELX_MBUF_VIRT;
+				buf_info->dma_handle = 0;
+				elx_free(phba, buf_info);
+			} else if (mp->elx_memflag & ELX_MEM_ATTACH_IPBUF) {
+				mmip = (DMABUFIP_t *) bp;
+				mmip->dma.next = 0;
+				elx_ip_free_rcv_buf(phba, mmip,
+						    mp->elx_memsize);
+
+				buf_info->size = sizeof (DMABUFIP_t);
+				buf_info->virt = (uint32_t *) mmip;
+				buf_info->phys = 0;
+				buf_info->flags = ELX_MBUF_VIRT;
+				buf_info->dma_handle = 0;
+				elx_free(phba, buf_info);
+			} else {
+				buf_info->size = mp->elx_memsize;
+				buf_info->virt = (uint32_t *) bp;
+				buf_info->phys = 0;
+				buf_info->flags = ELX_MBUF_VIRT;
+				buf_info->dma_handle = 0;
+				elx_free(phba, buf_info);
+			}
+		}
+		mp->mem_hdr.q_last = 0;
+		mp->mem_hdr.q_cnt = 0;
+	}
+	ELX_MEM_UNLOCK(phba, iflag);
+
+	return (1);
+}
+
+void *
+elx_mem_get(elxHBA_t * phba, int arg)
+{
+	uint8_t *bp = NULL;
+	MEMSEG_t *mp;
+	unsigned long iflag;
+	int low;
+	uint32_t cnt, ask;
+	uint32_t seg = arg & MEM_SEG_MASK;
+
+	/* range check on seg argument */
+	if (seg >= ELX_MAX_SEG) {
+		return ((uint8_t *) 0);
+	}
+
+	ELX_MEM_LOCK(phba, iflag);
+	mp = &phba->memseg[seg];
+
+	if ((low = (!(arg & MEM_PRI) && (mp->mem_hdr.q_cnt <= mp->elx_lowmem)))) {
+		/* Memory Buffer Pool is below low water mark */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0406,	/* ptr to msg structure */
+			       elx_mes0406,	/* ptr to msg */
+			       elx_msgBlk0406.msgPreambleStr,	/* begin varargs */
+			       seg, mp->elx_lowmem, low);	/* end varargs */
+
+		if (mp->elx_memflag & ELX_MEM_GETMORE) {
+			goto getmore;
+		}
+		ELX_MEM_UNLOCK(phba, iflag);
+
+		/* Low priority request and not enough buffers, so fail */
+		return (bp);
+	}
+
+      top:
+	bp = (uint8_t *) mp->mem_hdr.q_first;
+
+	if (bp) {
+		/* If a memory block exists, take it off freelist and return it to the user. */
+		if (mp->mem_hdr.q_last == (ELX_SLINK_t *) bp) {
+			mp->mem_hdr.q_last = 0;
+		}
+
+		mp->mem_hdr.q_first = *((ELX_SLINK_t * *)bp);
+		*((uint8_t * *)bp) = 0;
+		mp->mem_hdr.q_cnt--;
+	} else {
+		if (mp->elx_memflag & ELX_MEM_GETMORE) {
+		      getmore:
+			/* Grow the pool by: (current max / 4) + 32.
+			 * This guarantees that the pool grows by at least 32 buffers.
+			 */
+			ask =
+			    ((mp->mem_hdr.q_max >> 2) & 0xffff) +
+			    ELX_MIN_POOL_GROWTH;
+			if (mp->elx_memflag & ELX_MEM_BOUND) {
+				if (mp->mem_hdr.q_max == mp->elx_himem) {
+					/* Hit himem water mark.  The driver cannot alloc more memory */
+					elx_printf_log(phba->brd_no, &elx_msgBlk0407,	/* ptr to msg structure */
+						       elx_mes0407,	/* ptr to msg */
+						       elx_msgBlk0407.msgPreambleStr,	/* begin varargs */
+						       seg, mp->mem_hdr.q_max, mp->elx_himem);	/* end varargs */
+
+					ELX_MEM_UNLOCK(phba, iflag);
+					return (bp);
+				}
+
+				/* Don't exceed the himem limitation. */
+				ask =
+				    ((mp->mem_hdr.q_max + ask) >
+				     mp->elx_himem) ? (mp->elx_himem -
+						       mp->mem_hdr.q_max) : ask;
+			}
+
+			/* if allocated some buffers, update counts and goto top: to use first buffer */
+			if ((cnt = elx_mem_alloc_pool(phba, mp, ask)) != 0) {
+				mp->mem_hdr.q_cnt += cnt;
+				mp->mem_hdr.q_max += cnt;
+				goto top;
+			}
+		}
+
+		/* Memory Buffer Pool is either out of buffers or the memory allocation failed.  */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0409,	/* ptr to msg structure */
+			       elx_mes0409,	/* ptr to msg */
+			       elx_msgBlk0409.msgPreambleStr,	/* begin varargs */
+			       seg, mp->mem_hdr.q_cnt, mp->mem_hdr.q_max);	/* end varargs */
+	}
+
+	if (seg == MEM_NLP) {
+		/* GET nodelist */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0927,	/* ptr to msg structure */
+			       elx_mes0927,	/* ptr to msg */
+			       elx_msgBlk0927.msgPreambleStr,	/* begin varargs */
+			       (unsigned long)bp, mp->mem_hdr.q_cnt);	/* end varargs */
+
+		/* NLP_FREED_NODE flag is to protect the node from being freed
+		 * more then once. For driver_abort and other cases where the DSM 
+		 * calls itself recursively, its possible to free the node twice.
+		 */
+		if (bp) {
+			((ELX_NODELIST_t *) bp)->nlp_rflag &= ~NLP_FREED_NODE;
+		}
+	}
+
+	ELX_MEM_UNLOCK(phba, iflag);
+	return (bp);
+}
+
+uint8_t *
+elx_mem_put(elxHBA_t * phba, int seg, uint8_t * bp)
+{
+	MEMSEG_t *mp;
+	uint8_t *oldbp;
+	unsigned long iflag;
+
+	/* range check on seg argument */
+	if (seg >= ELX_MAX_SEG)
+		return ((uint8_t *) 0);
+
+	ELX_MEM_LOCK(phba, iflag);
+	mp = &phba->memseg[seg];
+
+	if ((seg == MEM_IP_RCV_BUF) && ((DMABUFIP_t *) bp)->ipbuf == NULL) {
+		/* 
+		 * If IP buff is null, the network driver gave the buffer to upper layer.
+		 * Acquire a new buffer and detach the dma mapping of previous 
+		 * buffer.
+		 */
+		DMABUFIP_t *tmp;
+		MBUF_INFO_t *buf_info;
+		MBUF_INFO_t bufinfo;
+
+		tmp = (DMABUFIP_t *) bp;
+		buf_info = &bufinfo;
+		buf_info->phys = tmp->dma.phys;
+		buf_info->virt = tmp->dma.virt;
+		buf_info->size = mp->elx_memsize;
+		buf_info->flags = ELX_MBUF_PHYSONLY;
+		buf_info->dma_handle = tmp->dma.dma_handle;
+		elx_free(phba, buf_info);
+
+		elx_ip_get_rcv_buf(phba, tmp, mp->elx_memsize);
+	}
+	if (seg == MEM_NLP) {
+		ELX_NODELIST_t *ndlp;
+
+		ndlp = (ELX_NODELIST_t *) bp;
+
+		if (ndlp) {
+			/* PUT nodelist */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0928,	/* ptr to msg structure */
+				       elx_mes0928,	/* ptr to msg */
+				       elx_msgBlk0928.msgPreambleStr,	/* begin varargs */
+				       (unsigned long)bp, mp->mem_hdr.q_cnt + 1);	/* end varargs */
+
+			/* NLP_FREED_NODE flag is to protect the node from being freed
+			 * more then once. For driver_abort and other cases where the DSM 
+			 * calls itself recursively, its possible to free the node twice.
+			 */
+			if (ndlp->nlp_rflag & NLP_FREED_NODE) {
+				ELX_MEM_UNLOCK(phba, iflag);
+				return (bp);
+			}
+			ndlp->nlp_rflag |= NLP_FREED_NODE;
+		}
+	}
+
+	if (bp) {
+		/* If a memory block exists, put it on freelist 
+		 * and return it to the user.
+		 */
+		oldbp = (uint8_t *) mp->mem_hdr.q_first;
+		mp->mem_hdr.q_first = (ELX_SLINK_t *) bp;
+		*((uint8_t * *)bp) = oldbp;
+		if (oldbp == 0)
+			mp->mem_hdr.q_last = (ELX_SLINK_t *) bp;
+		mp->mem_hdr.q_cnt++;
+	}
+
+	ELX_MEM_UNLOCK(phba, iflag);
+	return (bp);
+}
+
+#include "elx_cfgparm.h"
+
+struct elxHBA;
+
+/* *********************************************************************
+**
+**    Forward declaration of internal routines to SCHED
+**
+** ******************************************************************** */
+
+static void elx_sched_internal_check(elxHBA_t * hba);
+
+/* ***************************************************************
+**
+**  Initialize HBA, TARGET and LUN SCHED structures
+**  Basically clear them, set MaxQueue Depth
+** and mark them ready to go
+**
+** **************************************************************/
+
+void
+elx_sched_init_hba(elxHBA_t * hba, uint16_t maxOutstanding)
+{
+	memset(&hba->hbaSched, 0, sizeof (hba->hbaSched));
+	hba->hbaSched.maxOutstanding = maxOutstanding;
+	hba->hbaSched.status = ELX_SCHED_STATUS_OKAYTOSEND;
+	elx_sch_init_lock(hba);
+}
+
+void
+elx_sched_target_init(ELXSCSITARGET_t * target, uint16_t maxOutstanding)
+{
+	memset(&target->targetSched, 0, sizeof (target->targetSched));
+	target->targetSched.maxOutstanding = maxOutstanding;
+	target->targetSched.status = ELX_SCHED_STATUS_OKAYTOSEND;
+	return;
+}
+
+void
+elx_sched_lun_init(ELXSCSILUN_t * lun, uint16_t maxOutstanding)
+{
+	memset(&lun->lunSched, 0, sizeof (lun->lunSched));
+	lun->lunSched.maxOutstanding = maxOutstanding;
+	lun->lunSched.status = ELX_SCHED_STATUS_OKAYTOSEND;
+
+	return;
+}
+
+void
+elx_sched_pause_target(ELXSCSITARGET_t * target)
+{
+	target->targetSched.status = ELX_SCHED_STATUS_PAUSED;
+
+	return;
+}
+
+void
+elx_sched_pause_hba(elxHBA_t * hba)
+{
+	hba->hbaSched.status = ELX_SCHED_STATUS_PAUSED;
+
+	return;
+}
+
+void
+elx_sched_continue_target(ELXSCSITARGET_t * target)
+{
+	unsigned long lockFlag;
+	target->targetSched.status = ELX_SCHED_STATUS_OKAYTOSEND;
+	ELX_SCH_LOCK(target->pHba, lockFlag);
+	/* Make target the next ELXSCSITARGET_t to process */
+	elx_sched_internal_check(target->pHba);
+	ELX_SCH_UNLOCK(target->pHba, lockFlag);
+	return;
+}
+
+void
+elx_sched_continue_hba(elxHBA_t * hba)
+{
+	unsigned long lockFlag;
+	hba->hbaSched.status = ELX_SCHED_STATUS_OKAYTOSEND;
+	ELX_SCH_LOCK(hba, lockFlag);
+	elx_sched_internal_check(hba);
+	ELX_SCH_UNLOCK(hba, lockFlag);
+	return;
+}
+
+void
+elx_sched_sli_done(elxHBA_t * pHba,
+		   ELX_IOCBQ_t * pIocbIn, ELX_IOCBQ_t * pIocbOut)
+{
+	ELX_SCSI_BUF_t *pCommand = (ELX_SCSI_BUF_t *) pIocbIn->context1;
+	ELXSCSILUN_t *plun = pCommand->pLun;
+	static int doNotCheck = 0;
+	unsigned long lockFlag;
+	elxCfgParam_t *clp;
+	FCP_RSP *fcprsp;
+
+	ELX_SCH_LOCK(pHba, lockFlag);
+	plun->lunSched.currentOutstanding--;
+	plun->pTarget->targetSched.currentOutstanding--;
+
+	pCommand->result = pIocbOut->iocb.un.ulpWord[4];
+	pCommand->status = pIocbOut->iocb.ulpStatus;
+	pCommand->IOxri = pIocbOut->iocb.ulpContext;
+	if (pCommand->status) {
+		plun->errorcnt++;
+	}
+	plun->iodonecnt++;
+
+	pHba->hbaSched.currentOutstanding--;
+	ELX_SCH_UNLOCK(pHba, lockFlag);
+
+	elx_pci_dma_sync((void *)pHba, (void *)pCommand->dma_ext,
+			 1024, ELX_DMA_SYNC_FORCPU);
+
+	fcprsp = pCommand->fcp_rsp;
+	if ((pCommand->status == IOSTAT_FCP_RSP_ERROR) &&
+	    (fcprsp->rspStatus3 == SCSI_STAT_QUE_FULL)) {
+
+		/* Received Queue Full status from FCP device (tgt> <lun> */
+		elx_printf_log(pHba->brd_no, &elx_msgBlk0736,	/* ptr to msg structure */
+			       elx_mes0736,	/* ptr to msg */
+			       elx_msgBlk0736.msgPreambleStr,	/* begin varargs */
+			       pCommand->scsi_target, pCommand->scsi_lun, pCommand->qfull_retry_count, plun->qfull_retries, plun->lunSched.currentOutstanding, plun->lunSched.maxOutstanding);	/* end varargs */
+
+		if ((plun->qfull_retries > 0) &&
+		    (pCommand->qfull_retry_count < plun->qfull_retries)) {
+			clp = &pHba->config[0];
+			if (clp[ELX_CFG_DQFULL_THROTTLE_UP_TIME].a_current) {
+				elx_scsi_lower_lun_qthrottle(pHba, pCommand);
+			}
+			if (plun->qfull_retry_interval > 0) {
+				/*
+				 * force to retrying after delay 1 second
+				 */
+				plun->qfull_tmo_id =
+				    elx_clk_set(pHba, 0, elx_qfull_retry,
+						pCommand, 0);
+			} else {
+				elx_qfull_retry(pHba, pCommand, 0);
+			}
+			pCommand->qfull_retry_count++;
+			goto skipcmpl;
+		}
+	}
+
+	(pCommand->cmd_cmpl) (pHba, pCommand);
+
+      skipcmpl:
+
+	ELX_SCH_LOCK(pHba, lockFlag);
+	if (!doNotCheck) {
+		doNotCheck = 1;
+		elx_sched_internal_check(pHba);
+		doNotCheck = 0;
+	}
+	ELX_SCH_UNLOCK(pHba, lockFlag);
+	return;
+}
+
+void
+elx_sched_check(elxHBA_t * hba)
+{
+	unsigned long lockFlag;
+
+	ELX_SCH_LOCK(hba, lockFlag);
+	elx_sched_internal_check(hba);
+	ELX_SCH_UNLOCK(hba, lockFlag);
+
+	return;
+}
+
+static void
+elx_sched_internal_check(elxHBA_t * hba)
+{
+	ELX_SCHED_HBA_t *hbaSched = &hba->hbaSched;
+	ELX_SLI_t *psli;
+	ELX_NODELIST_t *ndlp;
+	int numberOfFailedTargetChecks = 0;
+	int didSuccessSubmit = 0;	/* SLI optimization for Port signals */
+	int stopSched = 0;	/* used if SLI rejects on interloop */
+
+	psli = &hba->sli;
+
+	/* Service the High Priority Queue first */
+	if (elx_tqs_getcount(&hba->hbaSched.highPriorityCmdList))
+		elx_sched_service_high_priority_queue(hba);
+
+	/* If targetCount is identically 0 then there are no Targets on the ring therefore
+	   no pending commands on any LUN           
+	 */
+	if ((hbaSched->targetCount == 0) ||
+	    (hbaSched->status == ELX_SCHED_STATUS_PAUSED))
+		return;
+
+	/* We are going to cycle through the Targets
+	   on a round robin basis until we make a pass through
+	   with nothing to schedule. 
+	 */
+
+	while ((stopSched == 0) &&
+	       (hbaSched->currentOutstanding < hbaSched->maxOutstanding) &&
+	       (numberOfFailedTargetChecks < hbaSched->targetCount)) {
+		ELXSCSITARGET_t *target = hbaSched->nextTargetToCheck;
+		ELX_SCHED_TARGET_t *targetSched = &target->targetSched;
+		ELXSCSITARGET_t *newNext = targetSched->targetRing.q_f;
+		int numberOfFailedLunChecks = 0;
+
+		if ((targetSched->currentOutstanding <
+		     targetSched->maxOutstanding)
+		    && (targetSched->status != ELX_SCHED_STATUS_PAUSED)) {
+			while (numberOfFailedLunChecks < targetSched->lunCount) {
+				ELXSCSILUN_t *lun =
+				    target->targetSched.nextLunToCheck;
+				ELX_SCHED_LUN_t *lunSched = &lun->lunSched;
+				ELXSCSILUN_t *newNextLun =
+				    lunSched->lunRing.q_f;
+
+				if ((lunSched->currentOutstanding <
+				     lunSched->maxOutstanding)
+				    && (lunSched->status !=
+					ELX_SCHED_STATUS_PAUSED)) {
+					ELX_SCSI_BUF_t *command;
+					int sliStatus;
+					ELX_IOCBQ_t *pIocbq;
+
+					command =
+					    elx_tqs_dequeuefirst(&lunSched->
+								 commandList,
+								 commandSched.
+								 nextCommand);
+
+					if (!command) {
+						numberOfFailedLunChecks++;
+						targetSched->nextLunToCheck =
+						    newNextLun;
+						continue;
+					}
+
+					ndlp = command->pLun->pnode;
+					if (ndlp == 0) {
+						numberOfFailedLunChecks++;
+						elx_sched_queue_command(hba,
+									command);
+						targetSched->nextLunToCheck =
+						    newNextLun;
+						continue;
+					}
+
+					pIocbq = &command->cur_iocbq;
+					/*  Current assumption is let SLI queue it until it busy us */
+
+					pIocbq->context1 = command;
+					pIocbq->iocb_cmpl = elx_sched_sli_done;
+
+					/* put the RPI number and NODELIST info in the IOCB command */
+					pIocbq->iocb.ulpContext = ndlp->nlp_rpi;
+					if (ndlp->
+					    nlp_fcp_info & NLP_FCP_2_DEVICE) {
+						pIocbq->iocb.ulpFCP2Rcvy = 1;
+					}
+					pIocbq->iocb.ulpClass =
+					    (ndlp->nlp_fcp_info & 0x0f);
+
+					/* Get an iotag and finish setup of IOCB  */
+					pIocbq->iocb.ulpIoTag =
+					    elx_sli_next_iotag(hba,
+							       &psli->
+							       ring[psli->
+								    fcp_ring]);
+					if (pIocbq->iocb.ulpIoTag == 0) {
+						stopSched = 1;
+						elx_tqs_putfirst(&lunSched->
+								 commandList,
+								 command,
+								 commandSched.
+								 nextCommand);
+						break;
+					}
+
+					sliStatus = elx_sli_issue_iocb(hba,
+								       &psli->
+								       ring
+								       [psli->
+									fcp_ring],
+								       pIocbq,
+								       SLI_IOCB_RET_IOCB);
+
+					switch (sliStatus) {
+					case IOCB_ERROR:
+					case IOCB_BUSY:
+						stopSched = 1;
+						elx_tqs_putfirst(&lunSched->
+								 commandList,
+								 command,
+								 commandSched.
+								 nextCommand);
+						break;
+
+					case IOCB_SUCCESS:
+						didSuccessSubmit = 1;
+						lunSched->currentOutstanding++;
+						targetSched->
+						    currentOutstanding++;
+						hbaSched->currentOutstanding++;
+						targetSched->nextLunToCheck =
+						    newNextLun;
+						break;
+
+					default:
+
+						break;
+					}
+
+					/* 
+					 * Check if there is any pending command on the lun. If not 
+					 * remove the lun. If this is the last lun in the target, the
+					 * target also will get removed from the scheduler ring.
+					 */
+					if (!lunSched->commandList.q_cnt)
+						elx_sched_remove_lun_from_ring
+						    (hba, lun);
+
+					break;
+
+					/* This brace ends LUN window open */
+				} else {
+					numberOfFailedLunChecks++;
+					targetSched->nextLunToCheck =
+					    newNextLun;
+				}
+				/* This brace ends While looping through LUNs on a Target */
+			}
+
+			if (numberOfFailedLunChecks >= targetSched->lunCount)
+				numberOfFailedTargetChecks++;
+			else
+				numberOfFailedTargetChecks = 0;
+		} /* if Target isn't pended */
+		else
+			numberOfFailedTargetChecks++;
+
+		hbaSched->nextTargetToCheck = newNext;
+	}			/* While looping through Targets on HBA */
+
+	return;
+}
+
+void
+elx_sched_service_high_priority_queue(struct elxHBA *hba)
+{
+	ELX_SLI_t *psli;
+	ELX_NODELIST_t *ndlp;
+
+	ELX_IOCBQ_t *pIocbq;
+	ELX_SCSI_BUF_t *command;
+	int sliStatus;
+
+	psli = &hba->sli;
+
+	/* 
+	 * Iterate through highprioritycmdlist if any cmds waiting on it
+	 * dequeue first cmd from highPriorityCmdList
+	 * 
+	 */
+	while (elx_tqs_getcount(&hba->hbaSched.highPriorityCmdList)) {
+		command =
+		    elx_tqs_dequeuefirst(&hba->hbaSched.highPriorityCmdList,
+					 commandSched.nextCommand);
+
+		if (!command) {
+			continue;
+		}
+
+		if ((command->pLun) && (command->pLun->pnode)) {
+
+			ndlp = command->pLun->pnode;
+			if (ndlp == 0) {
+
+			} else {
+				/* put the RPI number and NODELIST info in the IOCB command */
+				pIocbq = &command->cur_iocbq;
+				pIocbq->iocb.ulpContext = ndlp->nlp_rpi;
+				if (ndlp->nlp_fcp_info & NLP_FCP_2_DEVICE) {
+					pIocbq->iocb.ulpFCP2Rcvy = 1;
+				}
+				pIocbq->iocb.ulpClass =
+				    (ndlp->nlp_fcp_info & 0x0f);
+			}
+		}
+
+		pIocbq = &command->cur_iocbq;
+		/*  Current assumption is let SLI queue it until it busy us */
+
+		pIocbq->context1 = command;
+
+		/* Fill in iocb completion callback  */
+		pIocbq->iocb_cmpl = elx_sli_wake_iocb_high_priority;
+
+		/* Fill in iotag if we don't have one yet */
+		if (pIocbq->iocb.ulpIoTag == 0) {
+			pIocbq->iocb.ulpIoTag = elx_sli_next_iotag(hba,
+								   &psli->
+								   ring[psli->
+									fcp_ring]);
+		}
+
+		sliStatus = elx_sli_issue_iocb(hba,
+					       &psli->ring[psli->fcp_ring],
+					       pIocbq,
+					       SLI_IOCB_HIGH_PRIORITY |
+					       SLI_IOCB_RET_IOCB);
+
+		switch (sliStatus) {
+		case IOCB_ERROR:
+		case IOCB_BUSY:
+			/* We'll put it back to the head of the q and try again */
+			elx_tqs_putfirst(&hba->hbaSched.highPriorityCmdList,
+					 command, commandSched.nextCommand);
+			break;
+
+		case IOCB_SUCCESS:
+			hba->hbaSched.currentOutstanding++;
+			break;
+
+		default:
+
+			break;
+		}
+
+		break;
+	}
+
+	return;
+}
+
+ELX_SCSI_BUF_t *
+elx_sched_dequeue(elxHBA_t * hba, ELX_SCSI_BUF_t * ourCommand)
+{
+	ELX_SCSI_BUF_t *previousCommand = NULL;
+	ELX_SCSI_BUF_t *currentCommand;
+	ELX_SCHED_LUN_t *pLunSched;
+	unsigned long lockFlag;
+
+	ELX_SCH_LOCK(hba, lockFlag);
+	pLunSched = &ourCommand->pLun->lunSched;
+
+	currentCommand = elx_tqs_getfirst(&pLunSched->commandList);
+	while (currentCommand && currentCommand != ourCommand) {
+		previousCommand = currentCommand;
+		currentCommand = elx_tqs_getnext(currentCommand,
+						 commandSched.nextCommand);
+	}
+
+	if (currentCommand == ourCommand) {	/* found it */
+		elx_tqs_dequeue(&pLunSched->commandList, currentCommand,
+				commandSched.nextCommand, previousCommand);
+		if (elx_tqs_getcount(&pLunSched->commandList) == 0)
+			elx_sched_remove_lun_from_ring(hba, ourCommand->pLun);
+	}
+
+	ELX_SCH_UNLOCK(hba, lockFlag);
+	return (currentCommand);;
+}
+
+uint32_t
+elx_sched_flush_command(elxHBA_t * pHba,
+			ELX_SCSI_BUF_t * command,
+			uint8_t iocbStatus, uint32_t word4)
+{
+	ELX_SCSI_BUF_t *foundCommand = elx_sched_dequeue(pHba, command);
+	uint32_t found = 0;
+
+	if (foundCommand) {
+		IOCB_t *pIOCB = (IOCB_t *) & (command->cur_iocbq.iocb);
+		found++;
+		pIOCB->ulpStatus = iocbStatus;
+		foundCommand->status = iocbStatus;
+		if (word4) {
+			pIOCB->un.ulpWord[4] = word4;
+			foundCommand->result = word4;
+		}
+
+		if (foundCommand->status) {
+			foundCommand->pLun->errorcnt++;
+		}
+		foundCommand->pLun->iodonecnt++;
+
+		(command->cmd_cmpl) (pHba, command);
+	} else {
+		/* if we couldn't find this command is not in the scheduler,
+		   look for it in the SLI layer */
+		if (elx_sli_abort_iocb_context1
+		    (pHba, &pHba->sli.ring[pHba->sli.fcp_ring], command) == 0) {
+			found++;
+		}
+	}
+
+	return found;
+}
+
+uint32_t
+elx_sched_flush_lun(elxHBA_t * pHba,
+		    ELXSCSILUN_t * lun, uint8_t iocbStatus, uint32_t word4)
+{
+	int numberFlushed = 0;
+	unsigned long lockFlag;
+
+	ELX_SCH_LOCK(pHba, lockFlag);
+	while (elx_tqs_getcount(&lun->lunSched.commandList)) {
+		IOCB_t *pIOCB;
+		ELX_SCSI_BUF_t *command =
+		    elx_tqs_dequeuefirst(&lun->lunSched.commandList,
+					 commandSched.nextCommand);
+		pIOCB = (IOCB_t *) & (command->cur_iocbq.iocb);
+		pIOCB->ulpStatus = iocbStatus;
+		command->status = iocbStatus;
+		if (word4) {
+			pIOCB->un.ulpWord[4] = word4;
+			command->result = word4;
+		}
+
+		if (command->status) {
+			lun->errorcnt++;
+		}
+		lun->iodonecnt++;
+
+		(command->cmd_cmpl) (pHba, command);
+
+		numberFlushed++;
+	}
+	elx_sched_remove_lun_from_ring(pHba, lun);
+	ELX_SCH_UNLOCK(pHba, lockFlag);
+
+	/* flush the SLI layer also */
+	elx_sli_abort_iocb_lun(pHba, &pHba->sli.ring[pHba->sli.fcp_ring],
+			       lun->pTarget->scsi_id, lun->lun_id);
+
+	return (numberFlushed);
+}
+
+uint32_t
+elx_sched_flush_target(elxHBA_t * pHba,
+		       ELXSCSITARGET_t * target,
+		       uint8_t iocbStatus, uint32_t word4)
+{
+	ELXSCSILUN_t *lun;
+	int numberFlushed = 0;
+	unsigned long lockFlag;
+
+	ELX_SCH_LOCK(pHba, lockFlag);
+	/* walk the list of LUNs on this target and flush each LUN.  We
+	   accomplish this by pulling the first LUN off the head of the
+	   queue until there aren't any LUNs left */
+	while (target->targetSched.lunList) {
+		lun = target->targetSched.lunList;
+
+		while (elx_tqs_getcount(&lun->lunSched.commandList)) {
+			IOCB_t *pIOCB;
+			ELX_SCSI_BUF_t *command =
+			    elx_tqs_dequeuefirst(&lun->lunSched.commandList,
+						 commandSched.nextCommand);
+
+			pIOCB = (IOCB_t *) & (command->cur_iocbq.iocb);
+			pIOCB->ulpStatus = iocbStatus;
+			command->status = iocbStatus;
+			if (word4) {
+				pIOCB->un.ulpWord[4] = word4;
+				command->result = word4;
+			}
+
+			if (command->status) {
+				lun->errorcnt++;
+			}
+			lun->iodonecnt++;
+
+			(command->cmd_cmpl) (pHba, command);
+
+			numberFlushed++;
+		}
+
+		elx_sched_remove_lun_from_ring(pHba, lun);
+	}
+	elx_sched_remove_target_from_ring(pHba, target);
+	ELX_SCH_UNLOCK(pHba, lockFlag);
+
+	/* flush the SLI layer also */
+	elx_sli_abort_iocb_tgt(pHba, &pHba->sli.ring[pHba->sli.fcp_ring],
+			       target->scsi_id);
+
+	return (numberFlushed);
+}
+
+uint32_t
+elx_sched_flush_hba(elxHBA_t * pHba, uint8_t iocbStatus, uint32_t word4)
+{
+	int numberFlushed = 0;
+	ELXSCSITARGET_t *target;
+	ELXSCSILUN_t *lun;
+	unsigned long lockFlag;
+
+	ELX_SCH_LOCK(pHba, lockFlag);
+	while (pHba->hbaSched.targetList) {
+		target = pHba->hbaSched.targetList;
+
+		while (target->targetSched.lunList) {
+			lun = target->targetSched.lunList;
+
+			while (elx_tqs_getcount(&lun->lunSched.commandList)) {
+				IOCB_t *pIOCB;
+				ELX_SCSI_BUF_t *command =
+				    elx_tqs_dequeuefirst(&lun->lunSched.
+							 commandList,
+							 commandSched.
+							 nextCommand);
+
+				pIOCB = (IOCB_t *) & (command->cur_iocbq.iocb);
+				pIOCB->ulpStatus = iocbStatus;
+				command->status = iocbStatus;
+				if (word4) {
+					pIOCB->un.ulpWord[4] = word4;
+					command->result = word4;
+				}
+
+				if (command->status) {
+					lun->errorcnt++;
+				}
+				lun->iodonecnt++;
+
+				(command->cmd_cmpl) (pHba, command);
+
+				numberFlushed++;
+			}
+
+			elx_sched_remove_lun_from_ring(pHba, lun);
+		}
+		elx_sched_remove_target_from_ring(pHba, target);
+	}
+	ELX_SCH_UNLOCK(pHba, lockFlag);
+
+	/* flush the SLI layer also */
+	elx_sli_abort_iocb_hba(pHba, &pHba->sli.ring[pHba->sli.fcp_ring]);
+
+	return (numberFlushed);
+}
+
+void
+elx_sched_submit_command(elxHBA_t * hba, ELX_SCSI_BUF_t * command)
+{
+	ELX_NODELIST_t *ndlp;
+	uint16_t okayToSchedule = 1;
+	unsigned long lockFlag;
+
+	ELX_SCH_LOCK(hba, lockFlag);
+
+	/* If we have a command see if we can cut through */
+	if (command != 0) {
+
+		/* Just some short cuts */
+		ELX_SCHED_HBA_t *hbaSched = &hba->hbaSched;
+		ELX_SCHED_LUN_t *lunSched = &command->pLun->lunSched;
+		ELX_SCHED_TARGET_t *targetSched =
+		    &command->pLun->pTarget->targetSched;
+		ELX_IOCBQ_t *pIocbq = &command->cur_iocbq;
+		ELX_SLI_t *psli = &hba->sli;
+
+		/*    Set it up so SLI calls us when it is done       */
+
+		ndlp = command->pLun->pnode;
+		if (ndlp == 0) {
+			/* For now, just requeue to scheduler if ndlp is not available yet */
+			elx_sched_queue_command(hba, command);
+			ELX_SCH_UNLOCK(hba, lockFlag);
+			return;
+		}
+
+		pIocbq->context1 = command;
+		pIocbq->iocb_cmpl = elx_sched_sli_done;
+
+		/* put the RPI number and NODELIST info in the IOCB command */
+		pIocbq->iocb.ulpContext = ndlp->nlp_rpi;
+		if (ndlp->nlp_fcp_info & NLP_FCP_2_DEVICE) {
+			pIocbq->iocb.ulpFCP2Rcvy = 1;
+		}
+		pIocbq->iocb.ulpClass = (ndlp->nlp_fcp_info & 0x0f);
+		/* Get an iotag and finish setup of IOCB  */
+		pIocbq->iocb.ulpIoTag = elx_sli_next_iotag(hba,
+							   &psli->ring[psli->
+								       fcp_ring]);
+
+		if ((pIocbq->iocb.ulpIoTag != 0) &&
+		    (hbaSched->currentOutstanding < hbaSched->maxOutstanding) &&
+		    (hbaSched->status & ELX_SCHED_STATUS_OKAYTOSEND) &&
+		    (targetSched->lunCount == 0) &&
+		    (targetSched->currentOutstanding <
+		     targetSched->maxOutstanding)
+		    && (targetSched->status & ELX_SCHED_STATUS_OKAYTOSEND)
+		    && (lunSched->currentOutstanding < lunSched->maxOutstanding)
+		    && (lunSched->status & ELX_SCHED_STATUS_OKAYTOSEND)
+		    ) {
+
+			/* The scheduler, target and lun are all in a position to accept
+			 * a send operation.  Call the SLI layer and issue the IOCB.
+			 */
+
+			int sliStatus;
+
+			sliStatus =
+			    elx_sli_issue_iocb(hba, &psli->ring[psli->fcp_ring],
+					       pIocbq, SLI_IOCB_RET_IOCB);
+
+			switch (sliStatus) {
+			case IOCB_ERROR:
+			case IOCB_BUSY:
+				okayToSchedule = 0;
+				elx_sched_queue_command(hba, command);
+				break;
+			case IOCB_SUCCESS:
+				lunSched->currentOutstanding++;
+				targetSched->currentOutstanding++;
+				hbaSched->currentOutstanding++;
+				break;
+			default:
+
+				break;
+			}
+
+			/* Remove this state to cause a scan of queues if submit worked. */
+			okayToSchedule = 0;
+		} else {
+			/* This clause is execute only if there are outstanding
+			 * commands in the scheduler.
+			 */
+			elx_sched_queue_command(hba, command);
+		}
+	}
+
+	/* if(command) */
+	/* We either queued something or someone called us to schedule
+	   so now go schedule. */
+	if (okayToSchedule)
+		elx_sched_internal_check(hba);
+	ELX_SCH_UNLOCK(hba, lockFlag);
+	return;
+}
+
+void
+elx_sched_queue_command(elxHBA_t * hba, ELX_SCSI_BUF_t * command)
+{
+	ELXSCSILUN_t *lun = command->pLun;
+	ELX_SCHED_LUN_t *lunSched = &lun->lunSched;
+
+	elx_tqs_enqueue(&lunSched->commandList, command,
+			commandSched.nextCommand);
+	elx_sched_add_lun_to_ring(hba, lun);
+
+	return;
+}
+
+void
+elx_sched_add_target_to_ring(elxHBA_t * hba, ELXSCSITARGET_t * target)
+{
+	ELX_SCHED_TARGET_t *targetSched = &target->targetSched;
+	ELX_SCHED_HBA_t *hbaSched = &hba->hbaSched;
+
+	if ((elx_tqd_onque(targetSched->targetRing)) ||	/* Already on list */
+	    (targetSched->lunCount == 0)	/* nothing to schedule */
+	    )
+		return;
+
+	elx_tqd_enque(target, hbaSched->targetList, targetSched.targetRing);
+	if (hbaSched->targetCount == 0) {
+		hbaSched->targetList = hbaSched->nextTargetToCheck = target;
+	}
+	hbaSched->targetCount++;
+	return;
+}
+
+void
+elx_sched_add_lun_to_ring(elxHBA_t * hba, ELXSCSILUN_t * lun)
+{
+	ELX_SCHED_LUN_t *lunSched = &lun->lunSched;
+	ELXSCSITARGET_t *target = lun->pTarget;
+	ELX_SCHED_TARGET_t *targetSched = &target->targetSched;
+
+	if ((elx_tqd_onque(lunSched->lunRing)) ||	/* Already on list */
+	    (elx_tqs_getcount(&lunSched->commandList) == 0)	/* nothing to schedule */
+	    )
+		return;
+
+	elx_tqd_enque(lun, targetSched->lunList, lunSched.lunRing);
+
+	if (targetSched->lunCount == 0) {
+		targetSched->lunList = targetSched->nextLunToCheck = lun;
+	}
+	targetSched->lunCount++;
+	elx_sched_add_target_to_ring(hba, target);
+	return;
+}
+
+void
+elx_sched_remove_target_from_ring(elxHBA_t * hba, ELXSCSITARGET_t * target)
+{
+	ELX_SCHED_TARGET_t *targetSched = &target->targetSched;
+	ELX_SCHED_HBA_t *hbaSched = &hba->hbaSched;
+
+	if (!elx_tqd_onque(targetSched->targetRing))
+		return;		/* Not on Ring */
+	hbaSched->targetCount--;
+	if (hbaSched->targetCount) {	/*  Delink the LUN from the Ring */
+		hbaSched->targetList = elx_tqd_getnext(targetSched->targetRing);	/* Just in case hba -> this target */
+		if (hbaSched->nextTargetToCheck == target)
+			hbaSched->nextTargetToCheck = hbaSched->targetList;
+	} else
+		hbaSched->targetList = NULL;
+	elx_tqd_deque(target, targetSched.targetRing)
+	    return;
+}
+
+void
+elx_sched_remove_lun_from_ring(elxHBA_t * hba, ELXSCSILUN_t * lun)
+{
+	ELXSCSITARGET_t *target = lun->pTarget;
+	ELX_SCHED_TARGET_t *targetSched = &target->targetSched;
+	ELX_SCHED_LUN_t *lunSched = &lun->lunSched;
+
+	if (!elx_tqd_onque(lunSched->lunRing))
+		return;		/* Not on Ring  */
+	targetSched->lunCount--;
+
+	if (targetSched->lunCount) {	/*  Delink the LUN from the Ring */
+		targetSched->lunList = elx_tqd_getnext(lunSched->lunRing);	/* Just in case target -> this lun */
+		if (targetSched->nextLunToCheck == lun)
+			targetSched->nextLunToCheck = targetSched->lunList;
+	} else
+		targetSched->lunList = NULL;	/*   Ring is empty */
+
+	elx_tqd_deque(lun, lunSched.lunRing);
+
+	if (!targetSched->lunCount)
+		elx_sched_remove_target_from_ring(hba, target);
+
+	return;
+}
+
+/* Functions required by the scsiport module. */
+
+/* This routine allocates a scsi buffer, which contains all the necessary
+ * information needed to initiate a SCSI I/O. The non-DMAable region of
+ * the buffer contains the area to build the IOCB. The DMAable region contains
+ * the memory for the FCP CMND, FCP RSP, and the inital BPL. 
+ * In addition to allocating memeory, the FCP CMND and FCP RSP BDEs are setup
+ * in the BPL and the BPL BDE is setup in the IOCB.
+ */
+ELX_SCSI_BUF_t *
+elx_get_scsi_buf(elxHBA_t * phba)
+{
+	ELX_SCSI_BUF_t *psb;
+	DMABUF_t *pdma;
+	ULP_BDE64 *bpl;
+	IOCB_t *cmd;
+	uint8_t *ptr;
+	elx_dma_addr_t pdma_phys;
+
+	/* Get a SCSI buffer for an I/O */
+	if ((psb = (ELX_SCSI_BUF_t *) elx_mem_get(phba, MEM_SCSI_BUF)) == 0) {
+		return (0);
+	}
+	memset(psb, 0, sizeof (ELX_SCSI_BUF_t));
+
+	/* Get a SCSI DMA extention for an I/O */
+	/*
+	 * The DMA buffer for FCP_CMND, FCP_RSP and BPL use MEM_SCSI_DMA_EXT
+	 *  memory segment.
+	 *
+	 *    The size of MEM_BPL   = 1024 bytes.
+	 *
+	 *    The size of FCP_CMND  = 32 bytes.         
+	 *    The size of FCP_RSP   = 160 bytes + 8 extra.         
+	 *    The size of ULP_BDE64 = 12 bytes and driver can only support
+	 *       ELX_SCSI_INITIAL_BPL_SIZE (65) S/G segments for scsi data.
+	 *       One ULP_BDE64 is used for each of the FCP_CMND and FCP_RSP
+	 *
+	 *    Total usage for each I/O use 32 + 168 + (2 * 12) +
+	 *    (65 * 12) = 1004 bytes.
+	 */
+	if ((pdma = (DMABUF_t *) elx_mem_get(phba, MEM_SCSI_DMA_EXT)) == 0) {
+		elx_mem_put(phba, MEM_SCSI_BUF, (uint8_t *) psb);
+		return (0);
+	}
+	/* Save DMABUF ptr for put routine */
+	psb->dma_ext = pdma;
+
+	/* This is used to save extra BPLs that are chained to pdma.
+	 * Only used if I/O has more then 65 data segments.
+	 */
+	pdma->next = 0;
+
+	/* Save virtual ptrs to FCP Command, Response, and BPL */
+	ptr = (uint8_t *) pdma->virt;
+	/* zero out MEM_SCSI_DMA_EXT buffer (MEM_BUF) which is 1024 bytes */
+	memset(ptr, 0, 1024);
+	psb->fcp_cmnd = (FCP_CMND *) ptr;
+	ptr += sizeof (FCP_CMND);
+	psb->fcp_rsp = (FCP_RSP *) ptr;
+	ptr += (sizeof (FCP_RSP) + 0x8);	/* extra 8 to be safe */
+	psb->fcp_bpl = (ULP_BDE64 *) ptr;
+	psb->scsi_hba = phba;
+
+	/* Since this is for a FCP cmd, the first 2 BDEs in the BPL are always
+	 * the FCP CMND and FCP RSP, so lets just set it up right here.
+	 */
+	bpl = psb->fcp_bpl;
+	/* ptr points to physical address of FCP CMD */
+	pdma_phys = pdma->phys;
+	bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(pdma_phys));
+	bpl->addrLow = PCIMEM_LONG(putPaddrLow(pdma_phys));
+	bpl->tus.f.bdeSize = sizeof (FCP_CMND);
+	bpl->tus.f.bdeFlags = BUFF_USE_CMND;
+	bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+	bpl++;
+
+	/* Setup FCP RSP */
+	pdma_phys += sizeof (FCP_CMND);
+	bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(pdma_phys));
+	bpl->addrLow = PCIMEM_LONG(putPaddrLow(pdma_phys));
+	bpl->tus.f.bdeSize = sizeof (FCP_RSP);
+	bpl->tus.f.bdeFlags = (BUFF_USE_CMND | BUFF_USE_RCV);
+	bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+	bpl++;
+
+	/* Since the IOCB for the FCP I/O is built into the ELX_SCSI_BUF_t,
+	 * lets setup what we can right here.
+	 */
+	pdma_phys += (sizeof (FCP_RSP) + 0x8);
+	cmd = &psb->cur_iocbq.iocb;
+	cmd->un.fcpi64.bdl.ulpIoTag32 = 0;
+	cmd->un.fcpi64.bdl.addrHigh = putPaddrHigh(pdma_phys);
+	cmd->un.fcpi64.bdl.addrLow = putPaddrLow(pdma_phys);
+	cmd->un.fcpi64.bdl.bdeSize = (2 * sizeof (ULP_BDE64));
+	cmd->un.fcpi64.bdl.bdeFlags = BUFF_TYPE_BDL;
+	cmd->ulpBdeCount = 1;
+	cmd->ulpClass = CLASS3;
+	cmd->ulpOwner = OWN_CHIP;
+
+	return (psb);
+}
+
+/* This routine frees a scsi buffer, both DMAable and non-DMAable regions */
+void
+elx_free_scsi_buf(ELX_SCSI_BUF_t * psb)
+{
+	elxHBA_t *phba;
+	DMABUF_t *pdma;
+	DMABUF_t *pbpl;
+	DMABUF_t *pnext;
+
+	phba = psb->scsi_hba;
+	if (psb) {
+		if ((pdma = psb->dma_ext)) {
+			/* Check to see if there were any extra buffers used to chain BPLs */
+			pbpl = pdma->next;
+			while (pbpl) {
+				pnext = pbpl->next;
+				elx_mem_put(phba, MEM_BPL, (uint8_t *) pbpl);
+				pbpl = pnext;
+			}
+			elx_mem_put(phba, MEM_SCSI_DMA_EXT, (uint8_t *) pdma);
+		}
+		elx_mem_put(phba, MEM_SCSI_BUF, (uint8_t *) psb);
+	}
+	return;
+}
+
+ELXSCSILUN_t *
+elx_find_lun_device(ELX_SCSI_BUF_t * elx_cmd)
+{
+	/* Search through the LUN list to find the LUN that has properties
+	   matching those outlined in this function's parameters. */
+	return elx_cmd->scsi_hba->elx_tran_find_lun(elx_cmd);
+}
+
+/*
+ * Generic routine used the setup and initiate a SCSI I/O.
+ */
+int
+elx_scsi_cmd_start(ELX_SCSI_BUF_t * elx_cmd)
+{
+
+	elxHBA_t *phba;
+	ELX_SLI_t *psli;
+	elxCfgParam_t *clp;
+	ELX_IOCBQ_t *piocbq;
+	IOCB_t *piocb;
+	FCP_CMND *fcp_cmnd;
+	ELXSCSILUN_t *lun_device;
+	ELX_NODELIST_t *ndlp;
+
+	/* interrupt coalescing - check for IOCB response ring
+	   completions and handle any */
+
+	/* map bus/target to lun-device pointer */
+	/* This function will handle all mapping, LUN mapping, LUN masking, etc. */
+	lun_device = elx_find_lun_device(elx_cmd);
+
+	/* Make sure the HBA is online (cable plugged) and that this target
+	   is not in an error recovery mode.
+	 */
+	if (lun_device == 0) {
+		return FAILURE;
+	}
+
+	ndlp = (ELX_NODELIST_t *) lun_device->pTarget->pcontext;
+	phba = lun_device->pHBA;
+
+	if ((lun_device->pTarget->targetFlags & FC_NPR_ACTIVE) ||
+	    (lun_device->pTarget->rptLunState == REPORT_LUN_ONGOING)) {
+		/* Make sure the target is paused. */
+		elx_sched_pause_target(lun_device->pTarget);
+	} else {
+		if ((lun_device->failMask & ELX_DEV_FATAL_ERROR) || (ndlp == 0)) {
+
+			elx_cmd->result = 0;
+			elx_cmd->status = IOSTAT_DRIVER_REJECT;
+			elx_os_return_scsi_cmd(phba, elx_cmd);
+			return 0;
+		}
+	}
+
+	/* allocate an iocb command */
+	piocbq = &(elx_cmd->cur_iocbq);
+	piocb = &piocbq->iocb;
+
+	clp = &phba->config[0];
+	psli = &phba->sli;
+
+	elx_cmd->pLun = lun_device;
+
+	/* Note: ndlp may be 0 in recovery mode */
+	elx_cmd->pLun->pnode = ndlp;
+	elx_cmd->cmd_cmpl = elx_os_return_scsi_cmd;
+
+	elx_os_prep_io(phba, elx_cmd);
+
+	/* ulpTimeout is only one byte */
+	if (elx_cmd->timeout > 0xff) {
+		/*
+		 * The driver provides the timeout mechanism for this command.
+		 */
+		piocb->ulpTimeout = 0;
+	} else {
+		piocb->ulpTimeout = elx_cmd->timeout;
+	}
+
+	/*
+	 * Setup driver timeout, in case the command does not complete
+	 * Driver timeout should be greater than ulpTimeout
+	 */
+
+	piocbq->drvrTimeout = elx_cmd->timeout + ELX_DRVR_TIMEOUT;
+
+	fcp_cmnd = elx_cmd->fcp_cmnd;
+	putLunHigh(fcp_cmnd->fcpLunMsl, lun_device->lun_id);
+	putLunLow(fcp_cmnd->fcpLunLsl, lun_device->lun_id);
+
+	/*
+	 * Setup addressing method
+	 * The Logical Unit Addressing method is not supported at
+	 * this current release.
+	 */
+	if (lun_device->pTarget->addrMode == VOLUME_SET_ADDRESSING) {
+		fcp_cmnd->fcpLunMsl |= SWAP_DATA(0x40000000);
+	}
+
+	elx_pci_dma_sync((void *)phba, (void *)elx_cmd->dma_ext,
+			 1024, ELX_DMA_SYNC_FORDEV);
+
+	if (!(piocbq->iocb_flag & ELX_IO_POLL)) {
+		lun_device->qcmdcnt++;
+		/* Pass the command on down to the SLI layer. */
+		elx_sched_submit_command(phba, elx_cmd);
+	} else {
+		int rc;
+
+		piocbq->context1 = elx_cmd;
+		piocbq->iocb_cmpl = elx_sched_sli_done;
+
+		/* put the RPI number and NODELIST info in the IOCB command */
+		piocbq->iocb.ulpContext = ndlp->nlp_rpi;
+		if (ndlp->nlp_fcp_info & NLP_FCP_2_DEVICE) {
+			piocbq->iocb.ulpFCP2Rcvy = 1;
+		}
+		piocbq->iocb.ulpClass = (ndlp->nlp_fcp_info & 0x0f);
+		/* Get an iotag and finish setup of IOCB  */
+		piocbq->iocb.ulpIoTag = elx_sli_next_iotag(phba,
+							   &psli->ring[psli->
+								       fcp_ring]);
+
+		/* Poll for command completion */
+		rc = elx_sli_issue_iocb(phba, &phba->sli.ring[psli->fcp_ring],
+					piocbq,
+					(SLI_IOCB_RET_IOCB | SLI_IOCB_POLL));
+		return (rc);
+	}
+
+	/* Return success. */
+	return 0;
+}
+
+int
+elx_scsi_prep_task_mgmt_cmd(elxHBA_t * phba,
+			    ELX_SCSI_BUF_t * elx_cmd, uint8_t task_mgmt_cmd)
+{
+
+	ELX_SLI_t *psli;
+	elxCfgParam_t *clp;
+	ELX_IOCBQ_t *piocbq;
+	IOCB_t *piocb;
+	FCP_CMND *fcp_cmnd;
+	ELXSCSILUN_t *lun_device;
+	ELX_NODELIST_t *ndlp;
+
+	lun_device = elx_find_lun_device(elx_cmd);
+	if (lun_device == 0) {
+		return 0;
+	}
+
+	ndlp = (ELX_NODELIST_t *) lun_device->pTarget->pcontext;
+
+	if ((lun_device->failMask & ELX_DEV_FATAL_ERROR) || (ndlp == 0)) {
+		return 0;
+	}
+
+	/* allocate an iocb command */
+	psli = &phba->sli;
+	piocbq = &(elx_cmd->cur_iocbq);
+	piocb = &piocbq->iocb;
+
+	clp = &phba->config[0];
+
+	fcp_cmnd = elx_cmd->fcp_cmnd;
+	putLunHigh(fcp_cmnd->fcpLunMsl, lun_device->lun_id);
+	putLunLow(fcp_cmnd->fcpLunLsl, lun_device->lun_id);
+	if (lun_device->pTarget->addrMode == VOLUME_SET_ADDRESSING) {
+		fcp_cmnd->fcpLunMsl |= SWAP_DATA(0x40000000);
+	}
+	fcp_cmnd->fcpCntl2 = task_mgmt_cmd;
+
+	piocb->ulpIoTag =
+	    elx_sli_next_iotag(phba, &phba->sli.ring[psli->fcp_ring]);
+	piocb->ulpCommand = CMD_FCP_ICMND64_CR;
+
+	piocb->ulpContext = ndlp->nlp_rpi;
+	if (ndlp->nlp_fcp_info & NLP_FCP_2_DEVICE) {
+		piocb->ulpFCP2Rcvy = 1;
+	}
+	piocb->ulpClass = (ndlp->nlp_fcp_info & 0x0f);
+
+	/* ulpTimeout is only one byte */
+	if (elx_cmd->timeout > 0xff) {
+		/*
+		 * Do not timeout the command at the firmware level.
+		 * The driver will provide the timeout mechanism.
+		 */
+		piocb->ulpTimeout = 0;
+	} else {
+		piocb->ulpTimeout = elx_cmd->timeout;
+	}
+
+	/*
+	 * Setup driver timeout, in case the command does not complete
+	 * Driver timeout should be greater than ulpTimeout
+	 */
+
+	piocbq->drvrTimeout = elx_cmd->timeout + ELX_DRVR_TIMEOUT;
+
+	lun_device->pnode = ndlp;
+	elx_cmd->pLun = lun_device;
+
+	switch (task_mgmt_cmd) {
+	case LUN_RESET:
+		/* Issue LUN Reset to TGT <num> LUN <num> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0703,	/* ptr to msg structure */
+			       elx_mes0703,	/* ptr to msg */
+			       elx_msgBlk0703.msgPreambleStr,	/* begin varargs */
+			       elx_cmd->scsi_target, elx_cmd->scsi_lun, ndlp->nlp_rpi, ndlp->nlp_rflag);	/* end varargs */
+
+		break;
+	case ABORT_TASK_SET:
+		/* Issue Abort Task Set to TGT <num> LUN <num> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0701,	/* ptr to msg structure */
+			       elx_mes0701,	/* ptr to msg */
+			       elx_msgBlk0701.msgPreambleStr,	/* begin varargs */
+			       elx_cmd->scsi_target, elx_cmd->scsi_lun, ndlp->nlp_rpi, ndlp->nlp_rflag);	/* end varargs */
+
+		break;
+	case TARGET_RESET:
+		/* Issue Target Reset to TGT <num> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0702,	/* ptr to msg structure */
+			       elx_mes0702,	/* ptr to msg */
+			       elx_msgBlk0702.msgPreambleStr,	/* begin varargs */
+			       elx_cmd->scsi_target, ndlp->nlp_rpi, ndlp->nlp_rflag);	/* end varargs */
+		break;
+	}
+
+	return (1);
+}
+
+/* returns:  0 if we successfully find and abort the command,
+             1 if we couldn't find the command
+*/
+int
+elx_scsi_cmd_abort(elxHBA_t * phba, ELX_SCSI_BUF_t * elx_cmd)
+{
+
+	/* when this function returns, the command has been aborted and
+	   returned to the OS, or it was returned before we could abort
+	   it */
+
+	/* tell the scheduler to find this command on LUN queue and remove
+	   it.  It's up to the scheduler to remove the command from the SLI
+	   layer. */
+	if (elx_sched_flush_command(phba, elx_cmd, ELX_CMD_STATUS_ABORTED, 0)) {
+		return 1;
+	} else {
+		/* couldn't find command - fail */
+
+		return 0;
+	}
+}
+
+int
+elx_scsi_hba_reset(elxHBA_t * phba, uint32_t bus)
+{
+
+	/* reset bus */
+	/* tell the scheduler to find all commands on this HBA/bus and
+	   remove them.  It's up to the scheduler to remove the command
+	   from the SLI layer. */
+	if (!elx_sched_flush_hba(phba, ELX_CMD_STATUS_ABORTED, 0)) {
+		/* REMOVE - the driver needs a log message here */
+	}
+
+	return 0;
+}
+
+int
+elx_scsi_lun_reset(ELX_SCSI_BUF_t * external_cmd,
+		   elxHBA_t * phba,
+		   uint32_t bus, uint32_t target, uint64_t lun, uint32_t flag)
+{
+	ELX_SCSI_BUF_t *elx_cmd;
+	ELX_IOCBQ_t *piocbq;
+	ELX_SLI_t *psli;
+	ELXSCSILUN_t *plun;
+	ELX_IOCBQ_t *piocbqrsp = NULL;
+	ELX_SCSI_BUF_t *internal_cmd = NULL;
+	int ret = 0;
+
+	/* Allocate command buf if internal command */
+	if (!(flag & ELX_EXTERNAL_RESET)) {
+		if ((internal_cmd = elx_get_scsi_buf(phba)) == 0) {
+			return (FAILURE);
+		}
+		elx_cmd = internal_cmd;
+	} else {
+		elx_cmd = external_cmd;
+	}
+
+	elx_cmd->scsi_hba = phba;
+	elx_cmd->scsi_bus = bus;
+	elx_cmd->scsi_target = target;
+	elx_cmd->scsi_lun = lun;
+
+	/*
+	 * Reset a device with either a LUN reset or an ABORT TASK
+	 * reset depending on the caller's flag value.
+	 */
+	if (flag & ELX_ISSUE_LUN_RESET) {
+		ret = elx_scsi_prep_task_mgmt_cmd(phba, elx_cmd, LUN_RESET);
+	} else {
+		if (flag & ELX_ISSUE_ABORT_TSET) {
+			ret =
+			    elx_scsi_prep_task_mgmt_cmd(phba, elx_cmd,
+							ABORT_TASK_SET);
+		} else {
+			ret = 0;
+		}
+	}
+
+	if (ret) {
+		psli = &phba->sli;
+		piocbq = &(elx_cmd->cur_iocbq);
+		if (flag & ELX_EXTERNAL_RESET) {
+
+			/* get a buffer for this response IOCB command */
+			if ((piocbqrsp =
+			     (ELX_IOCBQ_t *) elx_mem_get(phba,
+							 MEM_IOCB)) == 0) {
+				if (internal_cmd) {
+					elx_free_scsi_buf(internal_cmd);
+					internal_cmd = NULL;
+					elx_cmd = NULL;
+				}
+				return (ENOMEM);
+			}
+			memset((void *)piocbqrsp, 0, sizeof (ELX_IOCBQ_t));
+
+			piocbq->iocb_cmpl = elx_sli_wake_iocb_high_priority;
+			ret = elx_sli_issue_iocb_wait_high_priority(phba, &phba->sli.ring[psli->fcp_ring], piocbq, SLI_IOCB_USE_TXQ, piocbqrsp, 60);	/* 60 secs */
+			ret = (ret == IOCB_SUCCESS) ? 1 : 0;
+
+			elx_cmd->result = piocbqrsp->iocb.un.ulpWord[4];
+			elx_cmd->status = piocbqrsp->iocb.ulpStatus;
+
+			/* tell the scheduler to find all commands on this LUN queue and
+			 * remove them.  It's up to the scheduler to remove the command
+			 * from the SLI layer.
+			 */
+			plun = elx_find_lun_device(elx_cmd);
+			if (plun) {
+				if (!elx_sched_flush_lun
+				    (phba, plun, ELX_CMD_STATUS_ABORTED, 0)) {
+
+				}
+			}
+			/* Done with piocbqrsp, return to free list */
+			if (piocbqrsp) {
+				elx_mem_put(phba, MEM_IOCB,
+					    (uint8_t *) piocbqrsp);
+			}
+
+			/* If this was an external lun reset, issue a message indicating
+			 * its completion. 
+			 */
+			if (flag & ELX_ISSUE_LUN_RESET) {
+				elx_printf_log(phba->brd_no, &elx_msgBlk0748,	/* ptr to msg structure */
+					       elx_mes0748,	/* ptr to msg */
+					       elx_msgBlk0748.msgPreambleStr,	/* begin varargs */
+					       elx_cmd->scsi_target, elx_cmd->scsi_lun, elx_cmd->status, elx_cmd->result);	/* end varargs */
+			}
+		} else {
+
+			ret =
+			    elx_sli_issue_iocb(phba,
+					       &phba->sli.ring[psli->fcp_ring],
+					       piocbq,
+					       SLI_IOCB_HIGH_PRIORITY |
+					       SLI_IOCB_RET_IOCB);
+			ret = (ret == IOCB_SUCCESS) ? 1 : 0;
+		}
+	}
+
+	if (internal_cmd) {
+		elx_free_scsi_buf(internal_cmd);
+		internal_cmd = NULL;
+		elx_cmd = NULL;
+	}
+
+	return (ret);
+
+}
+
+int
+elx_scsi_tgt_reset(ELX_SCSI_BUF_t * external_cmd,
+		   elxHBA_t * phba,
+		   uint32_t bus, uint32_t target, uint32_t flag)
+{
+	ELX_SCSI_BUF_t *elx_cmd;
+	ELX_IOCBQ_t *piocbq;
+	ELX_SLI_t *psli;
+	ELX_SCHED_HBA_t *phbaSched;
+	ELXSCSITARGET_t *ptarget;
+	ELXSCSILUN_t *plun;
+	ELX_IOCBQ_t *piocbqrsp = NULL;
+	ELX_SCSI_BUF_t *internal_cmd = NULL;
+	int ret = 0;
+
+	/* Allocate command buf if internal command */
+	if (!(flag & ELX_EXTERNAL_RESET)) {
+		if ((internal_cmd = elx_get_scsi_buf(phba)) == 0) {
+			return (FAILURE);
+		}
+		elx_cmd = internal_cmd;
+	} else {
+		elx_cmd = external_cmd;
+	}
+
+	elx_cmd->scsi_hba = phba;
+	elx_cmd->scsi_bus = bus;
+	elx_cmd->scsi_target = target;
+
+	/*
+	 * target reset a device
+	 */
+	ret = elx_scsi_prep_task_mgmt_cmd(phba, elx_cmd, TARGET_RESET);
+	if (ret) {
+		psli = &phba->sli;
+		piocbq = &(elx_cmd->cur_iocbq);
+		if (flag & ELX_EXTERNAL_RESET) {
+
+			/* get a buffer for this IOCB command response */
+			if ((piocbqrsp =
+			     (ELX_IOCBQ_t *) elx_mem_get(phba,
+							 MEM_IOCB)) == 0) {
+				if (internal_cmd) {
+					elx_free_scsi_buf(internal_cmd);
+					internal_cmd = NULL;
+					elx_cmd = NULL;
+				}
+				return (ENOMEM);
+			}
+			memset((void *)piocbqrsp, 0, sizeof (ELX_IOCBQ_t));
+
+			piocbq->iocb_cmpl = elx_sli_wake_iocb_high_priority;
+
+			ret = elx_sli_issue_iocb_wait_high_priority(phba, &phba->sli.ring[psli->fcp_ring], piocbq, SLI_IOCB_HIGH_PRIORITY, piocbqrsp, 60);	/* 60 secs */
+			ret = (ret == IOCB_SUCCESS) ? 1 : 0;
+
+			elx_cmd->result = piocbqrsp->iocb.un.ulpWord[4];
+			elx_cmd->status = piocbqrsp->iocb.ulpStatus;
+
+			/* tell the scheduler to find all commands on this Tgt queue and
+			 * remove them.  It's up to the scheduler to remove the command
+			 * from the SLI layer.
+			 */
+			plun = elx_find_lun_device(elx_cmd);
+			if ((plun == 0) || (plun->pTarget == 0)) {
+
+				phbaSched = &phba->hbaSched;
+				ptarget = phbaSched->targetList;
+				do {
+					if ((ptarget == NULL)
+					    || (ptarget->scsi_id == target)) {
+						break;
+					}
+					ptarget =
+					    ptarget->targetSched.targetRing.q_f;
+				} while (ptarget != phbaSched->targetList);
+			} else {
+				ptarget = plun->pTarget;
+			}
+
+			if (ptarget) {
+				if (!elx_sched_flush_target
+				    (phba, ptarget, ELX_CMD_STATUS_ABORTED,
+				     0)) {
+
+				}
+			}
+			/* Done with piocbqrsp, return to free list */
+			if (piocbqrsp) {
+				elx_mem_put(phba, MEM_IOCB,
+					    (uint8_t *) piocbqrsp);
+			}
+		} else {
+
+			ret =
+			    elx_sli_issue_iocb(phba,
+					       &phba->sli.ring[psli->fcp_ring],
+					       piocbq,
+					       SLI_IOCB_HIGH_PRIORITY |
+					       SLI_IOCB_RET_IOCB);
+			ret = (ret == IOCB_SUCCESS) ? 1 : 0;
+		}
+	}
+
+	if (internal_cmd) {
+		elx_free_scsi_buf(internal_cmd);
+		internal_cmd = NULL;
+		elx_cmd = NULL;
+	}
+
+	return (ret);
+}
+
+#include "lpfc_crtn.h"
+void
+elx_scsi_lower_lun_qthrottle(elxHBA_t * phba, ELX_SCSI_BUF_t * elx_cmd)
+{
+	ELXSCSILUN_t *plun;
+	elxCfgParam_t *clp;
+
+	clp = &phba->config[0];
+	plun = elx_cmd->pLun;
+
+	if (plun->lunSched.maxOutstanding > ELX_MIN_QFULL) {
+		if (plun->lunSched.currentOutstanding > ELX_MIN_QFULL) {
+			/*
+			 * knock the current queue throttle down to (active_io_count - 1)
+			 */
+			plun->lunSched.maxOutstanding =
+			    plun->lunSched.currentOutstanding - 1;
+
+			/*
+			 * Delay ELX_NO_DEVICE_DELAY seconds before sending I/O this device again.
+			 * stop_send_io will be decreament by 1 in lpfc_qthrottle_up();
+			 */
+			plun->stop_send_io =
+			    clp[ELX_CFG_NO_DEVICE_DELAY].a_current;
+
+			/*
+			 * Kick off the lpfc_qthrottle_up()
+			 */
+			if (phba->dqfull_clk == 0) {
+				phba->dqfull_clk = elx_clk_set(phba,
+							       clp
+							       [ELX_CFG_DQFULL_THROTTLE_UP_TIME].
+							       a_current,
+							       lpfc_qthrottle_up,
+							       0, 0);
+			}
+		} else {
+			plun->lunSched.maxOutstanding = ELX_MIN_QFULL;
+		}
+	}
+}
+
+void
+elx_qfull_retry(elxHBA_t * phba, void *n1, void *n2)
+{
+	elx_sched_queue_command(phba, (ELX_SCSI_BUF_t *) n1);
+}
+
+int elx_sli_reset_on_init = 0;
+
+int elx_sli_handle_mb_event(elxHBA_t *);
+int elx_sli_handle_ring_event(elxHBA_t *, ELX_SLI_RING_t *, uint32_t);
+int elx_sli_ringtx_put(elxHBA_t *, ELX_SLI_RING_t *, ELX_IOCBQ_t *);
+int elx_sli_ringtxcmpl_put(elxHBA_t *, ELX_SLI_RING_t *, ELX_IOCBQ_t *);
+ELX_IOCBQ_t *elx_sli_ringtx_get(elxHBA_t *, ELX_SLI_RING_t *);
+ELX_IOCBQ_t *elx_sli_ringtxcmpl_get(elxHBA_t *, ELX_SLI_RING_t *,
+				    ELX_IOCBQ_t *, uint32_t);
+DMABUF_t *elx_sli_ringpostbuf_search(elxHBA_t *, ELX_SLI_RING_t *,
+				     elx_dma_addr_t, int);
+
+/* This will save a huge switch to determine if the IOCB cmd
+ * is unsolicited or solicited.
+ */
+#define ELX_UNKNOWN_IOCB 0
+#define ELX_UNSOL_IOCB   1
+#define ELX_SOL_IOCB     2
+#define ELX_ABORT_IOCB   3
+uint8_t elx_sli_iocb_cmd_type[CMD_MAX_IOCB_CMD] = {
+	ELX_UNKNOWN_IOCB,	/* 0x00 */
+	ELX_UNSOL_IOCB,		/* CMD_RCV_SEQUENCE_CX     0x01 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_SEQUENCE_CR    0x02 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_SEQUENCE_CX    0x03 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_BCAST_CN       0x04 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_BCAST_CX       0x05 */
+	ELX_UNKNOWN_IOCB,	/* CMD_QUE_RING_BUF_CN     0x06 */
+	ELX_UNKNOWN_IOCB,	/* CMD_QUE_XRI_BUF_CX      0x07 */
+	ELX_UNKNOWN_IOCB,	/* CMD_IOCB_CONTINUE_CN    0x08 */
+	ELX_UNKNOWN_IOCB,	/* CMD_RET_XRI_BUF_CX      0x09 */
+	ELX_SOL_IOCB,		/* CMD_ELS_REQUEST_CR      0x0A */
+	ELX_SOL_IOCB,		/* CMD_ELS_REQUEST_CX      0x0B */
+	ELX_UNKNOWN_IOCB,	/* 0x0C */
+	ELX_UNSOL_IOCB,		/* CMD_RCV_ELS_REQ_CX      0x0D */
+	ELX_ABORT_IOCB,		/* CMD_ABORT_XRI_CN        0x0E */
+	ELX_ABORT_IOCB,		/* CMD_ABORT_XRI_CX        0x0F */
+	ELX_ABORT_IOCB,		/* CMD_CLOSE_XRI_CR        0x10 */
+	ELX_ABORT_IOCB,		/* CMD_CLOSE_XRI_CX        0x11 */
+	ELX_SOL_IOCB,		/* CMD_CREATE_XRI_CR       0x12 */
+	ELX_SOL_IOCB,		/* CMD_CREATE_XRI_CX       0x13 */
+	ELX_SOL_IOCB,		/* CMD_GET_RPI_CN          0x14 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_ELS_RSP_CX     0x15 */
+	ELX_SOL_IOCB,		/* CMD_GET_RPI_CR          0x16 */
+	ELX_ABORT_IOCB,		/* CMD_XRI_ABORTED_CX      0x17 */
+	ELX_SOL_IOCB,		/* CMD_FCP_IWRITE_CR       0x18 */
+	ELX_SOL_IOCB,		/* CMD_FCP_IWRITE_CX       0x19 */
+	ELX_SOL_IOCB,		/* CMD_FCP_IREAD_CR        0x1A */
+	ELX_SOL_IOCB,		/* CMD_FCP_IREAD_CX        0x1B */
+	ELX_SOL_IOCB,		/* CMD_FCP_ICMND_CR        0x1C */
+	ELX_SOL_IOCB,		/* CMD_FCP_ICMND_CX        0x1D */
+	ELX_UNKNOWN_IOCB,	/* 0x1E */
+	ELX_SOL_IOCB,		/* CMD_FCP_TSEND_CX        0x1F */
+	ELX_SOL_IOCB,		/* CMD_ADAPTER_MSG         0x20 */
+	ELX_SOL_IOCB,		/* CMD_FCP_TRECEIVE_CX     0x21 */
+	ELX_SOL_IOCB,		/* CMD_ADAPTER_DUMP        0x22 */
+	ELX_SOL_IOCB,		/* CMD_FCP_TRSP_CX         0x23 */
+	/* 0x24 - 0x80 */
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	/* 0x30 */
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	/* 0x40 */
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	/* 0x50 */
+	ELX_SOL_IOCB,
+	ELX_SOL_IOCB,
+	ELX_UNKNOWN_IOCB,
+	ELX_SOL_IOCB,
+	ELX_SOL_IOCB,
+	ELX_UNSOL_IOCB,
+	ELX_UNSOL_IOCB,
+	ELX_SOL_IOCB,
+	ELX_SOL_IOCB,
+
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	/* 0x60 */
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	/* 0x70 */
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	/* 0x80 */
+	ELX_UNKNOWN_IOCB,
+	ELX_UNSOL_IOCB,		/* CMD_RCV_SEQUENCE64_CX   0x81 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_SEQUENCE64_CR  0x82 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_SEQUENCE64_CX  0x83 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_BCAST64_CN     0x84 */
+	ELX_SOL_IOCB,		/* CMD_XMIT_BCAST64_CX     0x85 */
+	ELX_UNKNOWN_IOCB,	/* CMD_QUE_RING_BUF64_CN   0x86 */
+	ELX_UNKNOWN_IOCB,	/* CMD_QUE_XRI_BUF64_CX    0x87 */
+	ELX_UNKNOWN_IOCB,	/* CMD_IOCB_CONTINUE64_CN  0x88 */
+	ELX_UNKNOWN_IOCB,	/* CMD_RET_XRI_BUF64_CX    0x89 */
+	ELX_SOL_IOCB,		/* CMD_ELS_REQUEST64_CR    0x8A */
+	ELX_SOL_IOCB,		/* CMD_ELS_REQUEST64_CX    0x8B */
+	ELX_ABORT_IOCB,		/* CMD_ABORT_MXRI64_CN     0x8C */
+	ELX_UNSOL_IOCB,		/* CMD_RCV_ELS_REQ64_CX    0x8D */
+	/* 0x8E - 0x94 */
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_SOL_IOCB,		/* CMD_XMIT_ELS_RSP64_CX   0x95 */
+	ELX_UNKNOWN_IOCB,	/* 0x96 */
+	ELX_UNKNOWN_IOCB,	/* 0x97 */
+	ELX_SOL_IOCB,		/* CMD_FCP_IWRITE64_CR     0x98 */
+	ELX_SOL_IOCB,		/* CMD_FCP_IWRITE64_CX     0x99 */
+	ELX_SOL_IOCB,		/* CMD_FCP_IREAD64_CR      0x9A */
+	ELX_SOL_IOCB,		/* CMD_FCP_IREAD64_CX      0x9B */
+	ELX_SOL_IOCB,		/* CMD_FCP_ICMND64_CR      0x9C */
+	ELX_SOL_IOCB,		/* CMD_FCP_ICMND64_CX      0x9D */
+	ELX_UNKNOWN_IOCB,	/* 0x9E */
+	ELX_SOL_IOCB,		/* CMD_FCP_TSEND64_CX      0x9F */
+	ELX_UNKNOWN_IOCB,	/* 0xA0 */
+	ELX_SOL_IOCB,		/* CMD_FCP_TRECEIVE64_CX   0xA1 */
+	ELX_UNKNOWN_IOCB,	/* 0xA2 */
+	ELX_SOL_IOCB,		/* CMD_FCP_TRSP64_CX       0xA3 */
+	/* 0xA4 - 0xC1 */
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_SOL_IOCB,		/* CMD_GEN_REQUEST64_CR    0xC2 */
+	ELX_SOL_IOCB,		/* CMD_GEN_REQUEST64_CX    0xC3 */
+	/* 0xC4 - 0xCF */
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+
+	ELX_SOL_IOCB,
+	ELX_SOL_IOCB,		/* CMD_SENDTEXT_CR              0xD1 */
+	ELX_SOL_IOCB,		/* CMD_SENDTEXT_CX              0xD2 */
+	ELX_SOL_IOCB,		/* CMD_RCV_LOGIN                0xD3 */
+	ELX_SOL_IOCB,		/* CMD_ACCEPT_LOGIN             0xD4 */
+	ELX_SOL_IOCB,		/* CMD_REJECT_LOGIN             0xD5 */
+	ELX_UNSOL_IOCB,
+	/* 0xD7 - 0xDF */
+	ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB, ELX_UNKNOWN_IOCB,
+	/* 0xE0 */
+	ELX_UNSOL_IOCB,
+	ELX_SOL_IOCB,
+	ELX_SOL_IOCB,
+	ELX_SOL_IOCB,
+	ELX_SOL_IOCB,
+	ELX_UNSOL_IOCB
+};
+
+int
+elx_sli_hba_setup(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_MBOXQ_t *pmb;
+	int read_rev_reset, i, rc;
+	uint32_t status;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+
+	/* Setep SLI interface for HBA register and HBA SLIM access */
+	(psli->sliinit.elx_sli_setup_slim_access) (phba);
+
+	/* Set board state to initialization started */
+	phba->hba_state = ELX_INIT_START;
+	read_rev_reset = 0;
+
+	iflag = phba->iflag;
+	ELX_DRVR_UNLOCK(phba, iflag);
+
+	/* On some platforms/OS's, the driver can't rely on the state the adapter
+	 * may be in.  For this reason, the driver is allowed to reset 
+	 * the HBA before initialization.
+	 */
+	if (elx_sli_reset_on_init) {
+		phba->hba_state = 0;	/* Don't skip post */
+		elx_sli_brdreset(phba);
+		phba->hba_state = ELX_INIT_START;
+		if (elx_in_intr())
+			mdelay(2500);
+		else
+			elx_sleep_ms(phba, 2500);
+	}
+
+      top:
+	/* Read the HBA Host Status Register */
+	status = (psli->sliinit.elx_sli_read_HS) (phba);
+
+	i = 0;			/* counts number of times thru while loop */
+
+	/* Check status register to see what current state is */
+	while ((status & (HS_FFRDY | HS_MBRDY)) != (HS_FFRDY | HS_MBRDY)) {
+
+		/* Check every 100ms for 5 retries, then every 500ms for 5, then
+		 * every 2.5 sec for 5, then reset board and every 2.5 sec for 4.
+		 */
+		if (i++ >= 20) {
+			/* Adapter failed to init, timeout, status reg <status> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0436,	/* ptr to msg structure */
+				       elx_mes0436,	/* ptr to msg */
+				       elx_msgBlk0436.msgPreambleStr,	/* begin varargs */
+				       status);	/* end varargs */
+			phba->hba_state = ELX_HBA_ERROR;
+			ELX_DRVR_LOCK(phba, iflag);
+			return (ETIMEDOUT);
+		}
+
+		/* Check to see if any errors occurred during init */
+		if (status & HS_FFERM) {
+			/* ERROR: During chipset initialization */
+			/* Adapter failed to init, chipset, status reg <status> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0437,	/* ptr to msg structure */
+				       elx_mes0437,	/* ptr to msg */
+				       elx_msgBlk0437.msgPreambleStr,	/* begin varargs */
+				       status);	/* end varargs */
+			phba->hba_state = ELX_HBA_ERROR;
+			ELX_DRVR_LOCK(phba, iflag);
+			return (EIO);
+		}
+
+		if (i <= 5) {
+			if (elx_in_intr())
+				mdelay(100);
+			else
+				elx_sleep_ms(phba, 100);
+		} else if (i <= 10) {
+			if (elx_in_intr())
+				mdelay(500);
+			else
+				elx_sleep_ms(phba, 500);
+		} else {
+			if (elx_in_intr())
+				mdelay(2500);
+			else
+				elx_sleep_ms(phba, 2500);
+		}
+
+		if (i == 15) {
+			phba->hba_state = 0;	/* Don't skip post */
+			elx_sli_brdreset(phba);
+			phba->hba_state = ELX_INIT_START;
+		}
+		/* Read the HBA Host Status Register */
+		status = (psli->sliinit.elx_sli_read_HS) (phba);
+	}
+
+	/* Check to see if any errors occurred during init */
+	if (status & HS_FFERM) {
+		/* ERROR: During chipset initialization */
+		/* Adapter failed to init, chipset, status reg <status> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0438,	/* ptr to msg structure */
+			       elx_mes0438,	/* ptr to msg */
+			       elx_msgBlk0438.msgPreambleStr,	/* begin varargs */
+			       status);	/* end varargs */
+		phba->hba_state = ELX_HBA_ERROR;
+		ELX_DRVR_LOCK(phba, iflag);
+		return (EIO);
+	}
+
+	/* Clear all interrupt enable conditions */
+	(psli->sliinit.elx_sli_write_HC) (phba, 0);
+
+	/* setup host attn register */
+	(psli->sliinit.elx_sli_write_HA) (phba, 0xffffffff);
+
+	/* Get a Mailbox buffer to setup mailbox commands for HBA initialization */
+	if ((pmb =
+	     (ELX_MBOXQ_t *) elx_mem_get(phba, (MEM_MBOX | MEM_PRI))) == 0) {
+		phba->hba_state = ELX_HBA_ERROR;
+		ELX_DRVR_LOCK(phba, iflag);
+		return (ENOMEM);
+	}
+
+	/* Call pre CONFIG_PORT mailbox command initialization.  A value of 0 
+	 * means the call was successful.  Any other nonzero value is a failure,
+	 * but if ERESTART is returned, the driver may reset the HBA and try again.
+	 */
+	if ((rc = (psli->sliinit.elx_sli_config_port_prep) (phba))) {
+		if ((rc == ERESTART) && (read_rev_reset == 0)) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			phba->hba_state = 0;	/* Don't skip post */
+			elx_sli_brdreset(phba);
+			phba->hba_state = ELX_INIT_START;
+			if (elx_in_intr())
+				mdelay(500);
+			else
+				elx_sleep_ms(phba, 500);
+			read_rev_reset = 1;
+			goto top;
+		}
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		ELX_DRVR_LOCK(phba, iflag);
+		return (ENXIO);
+	}
+
+	/* Setup and issue mailbox CONFIG_PORT command */
+	phba->hba_state = ELX_INIT_MBX_CMDS;
+	elx_config_port(phba, pmb);
+	if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+		/* Adapter failed to init, mbxCmd <cmd> CONFIG_PORT, mbxStatus <status> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0442,	/* ptr to msg structure */
+			       elx_mes0442,	/* ptr to msg */
+			       elx_msgBlk0442.msgPreambleStr,	/* begin varargs */
+			       pmb->mb.mbxCommand, pmb->mb.mbxStatus, 0);	/* end varargs */
+
+		/* This clause gives the config_port call is given multiple chances to succeed. */
+		if (read_rev_reset == 0) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			phba->hba_state = 0;	/* Don't skip post */
+			elx_sli_brdreset(phba);
+			phba->hba_state = ELX_INIT_START;
+			if (elx_in_intr())
+				mdelay(2500);
+			else
+				elx_sleep_ms(phba, 2500);
+			read_rev_reset = 1;
+			goto top;
+		}
+
+		psli->sliinit.sli_flag &= ~ELX_SLI2_ACTIVE;
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		ELX_DRVR_LOCK(phba, iflag);
+		return (ENXIO);
+	}
+
+	if ((rc = elx_sli_ring_map(phba))) {
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		ELX_DRVR_LOCK(phba, iflag);
+		return (ENXIO);
+	}
+	psli->sliinit.sli_flag |= ELX_PROCESS_LA;
+
+	/* Call post CONFIG_PORT mailbox command initialization. */
+	if ((rc = (psli->sliinit.elx_sli_config_port_post) (phba))) {
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		ELX_DRVR_LOCK(phba, iflag);
+		return (ENXIO);
+	}
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	ELX_DRVR_LOCK(phba, iflag);
+	return (0);
+}
+
+int
+elx_sli_ring_map(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_MBOXQ_t *pmb;
+	MAILBOX_t *pmbox;
+	int i;
+
+	psli = &phba->sli;
+
+	/* Get a Mailbox buffer to setup mailbox commands for HBA initialization */
+	if ((pmb =
+	     (ELX_MBOXQ_t *) elx_mem_get(phba, (MEM_MBOX | MEM_PRI))) == 0) {
+		phba->hba_state = ELX_HBA_ERROR;
+		return (ENOMEM);
+	}
+	pmbox = &pmb->mb;
+
+	/* Initialize the ELX_SLI_RING_t structure for each ring */
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		/* Issue a CONFIG_RING mailbox command for each ring */
+		phba->hba_state = ELX_INIT_MBX_CMDS;
+		elx_config_ring(phba, i, pmb);
+		if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+			/* Adapter failed to init, mbxCmd <cmd> CFG_RING, mbxStatus <status>, ring <num> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0446,	/* ptr to msg structure */
+				       elx_mes0446,	/* ptr to msg */
+				       elx_msgBlk0446.msgPreambleStr,	/* begin varargs */
+				       pmbox->mbxCommand, pmbox->mbxStatus, i);	/* end varargs */
+			phba->hba_state = ELX_HBA_ERROR;
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			return (ENXIO);
+		}
+	}
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	return (0);
+}
+
+int
+elx_sli_intr(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	uint32_t ha_copy, status;
+	int i;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	psli->slistat.sliIntr++;
+	ha_copy = (psli->sliinit.elx_sli_intr_prep) ((void *)phba);
+
+	if (!ha_copy) {
+		(psli->sliinit.elx_sli_intr_post) ((void *)phba);
+		/*
+		 * Don't claim that interrupt
+		 */
+		return (1);
+	}
+
+	ELX_SLI_LOCK(phba, iflag);
+
+	if (ha_copy & HA_ERATT) {	/* Link / board error */
+		psli->slistat.errAttnEvent++;
+		/* do what needs to be done, get error from STATUS REGISTER */
+		status = (psli->sliinit.elx_sli_read_HS) (phba);
+		/* Clear Chip error bit */
+		(psli->sliinit.elx_sli_write_HA) (phba, HA_ERATT);
+
+		ELX_SLI_UNLOCK(phba, iflag);
+		/* Process the Error Attention */
+		(psli->sliinit.elx_sli_handle_eratt) (phba, status);
+		return (0);
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+
+	if (ha_copy & HA_MBATT) {	/* Mailbox interrupt */
+		elx_sli_handle_mb_event(phba);
+	}
+
+	if (ha_copy & HA_LATT) {	/* Link Attention interrupt */
+		/* Process the Link Attention */
+		if (psli->sliinit.sli_flag & ELX_PROCESS_LA) {
+			(psli->sliinit.elx_sli_handle_latt) (phba);
+		}
+	}
+
+	/* Now process each ring */
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		pring = &psli->ring[i];
+
+		ELX_SLI_LOCK(phba, iflag);
+		if ((ha_copy & HA_RXATT)
+		    || (pring->flag & ELX_DEFERRED_RING_EVENT)) {
+			if (pring->flag & ELX_STOP_IOCB_MASK) {
+				pring->flag |= ELX_DEFERRED_RING_EVENT;
+			} else {
+				ELX_SLI_UNLOCK(phba, iflag);
+				elx_sli_handle_ring_event(phba, pring,
+							  (ha_copy &
+							   HA_RXMASK));
+				ELX_SLI_LOCK(phba, iflag);
+				pring->flag &= ~ELX_DEFERRED_RING_EVENT;
+			}
+		}
+		ELX_SLI_UNLOCK(phba, iflag);
+		ha_copy = (ha_copy >> 4);
+	}
+
+	(psli->sliinit.elx_sli_intr_post) ((void *)phba);
+	return (0);
+}
+
+int
+elx_sli_chk_mbxCommand(uint8_t mbxCommand)
+{
+	uint8_t ret;
+
+	switch (mbxCommand) {
+	case MBX_LOAD_SM:
+	case MBX_READ_NV:
+	case MBX_WRITE_NV:
+	case MBX_RUN_BIU_DIAG:
+	case MBX_INIT_LINK:
+	case MBX_DOWN_LINK:
+	case MBX_CONFIG_LINK:
+	case MBX_CONFIG_RING:
+	case MBX_RESET_RING:
+	case MBX_READ_CONFIG:
+	case MBX_READ_RCONFIG:
+	case MBX_READ_SPARM:
+	case MBX_READ_STATUS:
+	case MBX_READ_RPI:
+	case MBX_READ_XRI:
+	case MBX_READ_REV:
+	case MBX_READ_LNK_STAT:
+	case MBX_REG_LOGIN:
+	case MBX_UNREG_LOGIN:
+	case MBX_READ_LA:
+	case MBX_CLEAR_LA:
+	case MBX_DUMP_MEMORY:
+	case MBX_DUMP_CONTEXT:
+	case MBX_RUN_DIAGS:
+	case MBX_RESTART:
+	case MBX_UPDATE_CFG:
+	case MBX_DOWN_LOAD:
+	case MBX_DEL_LD_ENTRY:
+	case MBX_RUN_PROGRAM:
+	case MBX_SET_MASK:
+	case MBX_SET_SLIM:
+	case MBX_UNREG_D_ID:
+	case MBX_CONFIG_FARP:
+	case MBX_LOAD_AREA:
+	case MBX_RUN_BIU_DIAG64:
+	case MBX_CONFIG_PORT:
+	case MBX_READ_SPARM64:
+	case MBX_READ_RPI64:
+	case MBX_REG_LOGIN64:
+	case MBX_READ_LA64:
+	case MBX_FLASH_WR_ULA:
+	case MBX_SET_DEBUG:
+	case MBX_LOAD_EXP_ROM:
+		ret = mbxCommand;
+		break;
+	default:
+		ret = MBX_SHUTDOWN;
+		break;
+	}
+	return (ret);
+}
+
+int
+elx_sli_handle_mb_event(elxHBA_t * phba)
+{
+	MAILBOX_t *mbox;
+	MAILBOX_t *pmbox;
+	ELX_MBOXQ_t *pmb;
+	ELX_SLI_t *psli;
+	PGP *pgp;
+	ELX_SLI_RING_t *pring;
+	int i;
+	unsigned long iflag;
+	uint32_t status;
+	uint32_t portCmdGet, portGetIndex;
+
+	psli = &phba->sli;
+	/* We should only get here if we are in SLI2 mode */
+	if (!(psli->sliinit.sli_flag & ELX_SLI2_ACTIVE)) {
+		return (1);
+	}
+
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 sizeof (MAILBOX_t), ELX_DMA_SYNC_FORCPU);
+	psli->slistat.mboxEvent++;
+
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Get a Mailbox buffer to setup mailbox commands for callback */
+	if ((pmb = psli->mbox_active)) {
+		pmbox = &pmb->mb;
+		mbox = (MAILBOX_t *) psli->MBhostaddr;
+
+		/* First check out the status word */
+		elx_sli_pcimem_bcopy((uint32_t *) mbox, (uint32_t *) pmbox,
+				     sizeof (uint32_t));
+
+		/* Sanity check to ensure the host owns the mailbox */
+		if (pmbox->mbxOwner != OWN_HOST) {
+			/* Lets try for a while */
+			for (i = 0; i < 10240; i++) {
+				elx_pci_dma_sync((void *)phba,
+						 (void *)&phba->slim2p,
+						 sizeof (MAILBOX_t),
+						 ELX_DMA_SYNC_FORCPU);
+				/* First copy command data */
+				elx_sli_pcimem_bcopy((uint32_t *) mbox,
+						     (uint32_t *) pmbox,
+						     sizeof (uint32_t));
+				if (pmbox->mbxOwner == OWN_HOST)
+					goto mbout;
+			}
+			/* Stray Mailbox Interrupt, mbxCommand <cmd> mbxStatus <status> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0304,	/* ptr to msg structure */
+				       elx_mes0304,	/* ptr to msg */
+				       elx_msgBlk0304.msgPreambleStr,	/* begin varargs */
+				       pmbox->mbxCommand, pmbox->mbxStatus);	/* end varargs */
+
+			psli->sliinit.sli_flag |= ELX_SLI_MBOX_ACTIVE;
+			ELX_SLI_UNLOCK(phba, iflag);
+			return (1);
+		}
+
+	      mbout:
+		if (psli->mbox_tmo) {
+			elx_clk_can(phba, psli->mbox_tmo);
+			psli->mbox_tmo = 0;
+		}
+
+		/*
+		 * It is a fatal error if unknown mbox command completion.
+		 */
+		if (elx_sli_chk_mbxCommand(pmbox->mbxCommand) == MBX_SHUTDOWN) {
+
+			/* Unknow mailbox command compl */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0323,	/* ptr to msg structure */
+				       elx_mes0323,	/* ptr to msg */
+				       elx_msgBlk0323.msgPreambleStr,	/* begin varargs */
+				       pmbox->mbxCommand);	/* end varargs */
+			phba->hba_state = ELX_HBA_ERROR;
+			phba->hba_flag |= FC_STOP_IO;
+			(psli->sliinit.elx_sli_handle_eratt) (phba, HS_FFER3);
+			return (0);
+		}
+
+		psli->mbox_active = 0;
+		if (pmbox->mbxStatus) {
+			psli->slistat.mboxStatErr++;
+			if (pmbox->mbxStatus == MBXERR_NO_RESOURCES) {
+				/* Mbox cmd cmpl error - RETRYing */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0305,	/* ptr to msg structure */
+					       elx_mes0305,	/* ptr to msg */
+					       elx_msgBlk0305.msgPreambleStr,	/* begin varargs */
+					       pmbox->mbxCommand, pmbox->mbxStatus, pmbox->un.varWords[0], phba->hba_state);	/* end varargs */
+				pmbox->mbxStatus = 0;
+				pmbox->mbxOwner = OWN_HOST;
+				psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+				ELX_SLI_UNLOCK(phba, iflag);
+				if (elx_sli_issue_mbox(phba, pmb, MBX_NOWAIT) ==
+				    MBX_SUCCESS) {
+					return (0);
+				}
+				ELX_SLI_LOCK(phba, iflag);
+			}
+		}
+
+		/* Mailbox Cmpl, wd0 <pmbox> wd1 <varWord> wd2 <varWord> cmpl <mbox_cmpl) */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0307,	/* ptr to msg structure */
+			       elx_mes0307,	/* ptr to msg */
+			       elx_msgBlk0307.msgPreambleStr,	/* begin varargs */
+			       *((uint32_t *) pmbox), pmbox->un.varWords[0], pmbox->un.varWords[1], pmb->mbox_cmpl);	/* end varargs */
+
+		if (pmb->mbox_cmpl) {
+			/* Copy entire mbox completion over buffer */
+			elx_sli_pcimem_bcopy((uint32_t *) mbox,
+					     (uint32_t *) pmbox,
+					     (sizeof (uint32_t) *
+					      (MAILBOX_CMD_WSIZE)));
+
+			ELX_SLI_UNLOCK(phba, iflag);
+			(pmb->mbox_cmpl) ((void *)phba, pmb);
+
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		}
+	}
+
+      top:
+	psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+	/* Process next mailbox command if there is one */
+	if ((pmb = elx_mbox_get(phba))) {
+		ELX_SLI_UNLOCK(phba, iflag);
+		if (elx_sli_issue_mbox(phba, pmb, MBX_NOWAIT) ==
+		    MBX_NOT_FINISHED) {
+			ELX_SLI_LOCK(phba, iflag);
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			goto top;
+		}
+		ELX_SLI_LOCK(phba, iflag);
+	} else {
+		/* Turn on IOCB processing */
+		for (i = 0; i < psli->sliinit.num_rings; i++) {
+			pring = &psli->ring[i];
+			pgp =
+			    (PGP *) & (((MAILBOX_t *) psli->MBhostaddr)->us.s2.
+				       port[i]);
+			/* If the ring is active, flag it */
+			if (psli->ring[i].cmdringaddr) {
+				if (psli->ring[i].flag & ELX_STOP_IOCB_MBX) {
+					psli->ring[i].flag &=
+					    ~ELX_STOP_IOCB_MBX;
+					ELX_SLI_UNLOCK(phba, iflag);
+					portGetIndex =
+					    elx_sli_resume_iocb(phba, pring);
+					/* Make sure the host slim pointers are up-to-date before
+					 * continuing.  An update is NOT guaranteed on the first read.
+					 */
+					status = pgp->cmdGetInx;
+					portCmdGet = PCIMEM_LONG(status);
+					if (portGetIndex != portCmdGet) {
+						elx_sli_resume_iocb(phba,
+								    pring);
+					}
+					ELX_SLI_LOCK(phba, iflag);
+
+					/* If this is the FCP ring, the scheduler needs to be restarted. */
+					if (pring->ringno == psli->fcp_ring) {
+						elx_sched_check(phba);
+					}
+				}
+			}
+		}
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (0);
+}
+
+int
+elx_sli_handle_ring_event(elxHBA_t * phba,
+			  ELX_SLI_RING_t * pring, uint32_t mask)
+{
+	ELX_SLI_t *psli;
+	IOCB_t *entry;
+	IOCB_t *irsp = NULL;
+	ELX_IOCBQ_t *rspiocbp;
+	ELX_IOCBQ_t *cmdiocbp;
+	ELX_IOCBQ_t *saveq;
+	ELX_RING_INIT_t *pringinit;
+	HGP *hgp;
+	PGP *pgp;
+	MAILBOX_t *mbox;
+	uint32_t status;
+	uint32_t portRspPut, portRspMax;
+	uint32_t portCmdGet, portGetIndex;
+	int ringno, i, loopcnt;
+	uint8_t type;
+	unsigned long iflag;
+	int rc = 1;
+
+	psli = &phba->sli;
+	ringno = pring->ringno;
+	psli->slistat.iocbEvent[ringno]++;
+
+	/* At this point we assume SLI-2 */
+	mbox = (MAILBOX_t *) psli->MBhostaddr;
+	pgp = (PGP *) & mbox->us.s2.port[ringno];
+	hgp = (HGP *) & mbox->us.s2.host[ringno];
+
+	ELX_SLI_LOCK(phba, iflag);
+	/* portRspMax is the number of rsp ring entries for this specific ring. */
+	portRspMax = psli->sliinit.ringinit[ringno].numRiocb;
+
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORCPU);
+
+	rspiocbp = 0;
+	loopcnt = 0;
+
+	/* Gather iocb entries off response ring.
+	 * rspidx is the IOCB index of the next IOCB that the driver
+	 * is going to process.
+	 */
+	entry = (IOCB_t *) IOCB_ENTRY(pring->rspringaddr, pring->rspidx);
+	status = pgp->rspPutInx;
+	portRspPut = PCIMEM_LONG(status);
+
+	if (portRspPut >= portRspMax) {
+
+		/* Ring <ringno> handler: portRspPut <portRspPut> is bigger then rsp ring <portRspMax> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0312,	/* ptr to msg structure */
+			       elx_mes0312,	/* ptr to msg */
+			       elx_msgBlk0312.msgPreambleStr,	/* begin varargs */
+			       ringno, portRspPut, portRspMax);	/* end varargs */
+		ELX_SLI_UNLOCK(phba, iflag);
+		/*
+		 * Treat it as adapter hardware error.
+		 */
+		phba->hba_state = ELX_HBA_ERROR;
+		phba->hba_flag |= FC_STOP_IO;
+		(psli->sliinit.elx_sli_handle_eratt) (phba, HS_FFER3);
+		return (1);
+	}
+
+	/* Get the next available response iocb.
+	 * rspidx is the IOCB index of the next IOCB that the driver
+	 * is going to process.
+	 */
+	while (pring->rspidx != portRspPut) {
+		/* get an iocb buffer to copy entry into */
+		if ((rspiocbp =
+		     (ELX_IOCBQ_t *) elx_mem_get(phba,
+						 MEM_IOCB | MEM_PRI)) == NULL) {
+			break;
+		}
+
+		elx_sli_pcimem_bcopy((uint32_t *) entry,
+				     (uint32_t *) & rspiocbp->iocb,
+				     sizeof (IOCB_t));
+		irsp = &rspiocbp->iocb;
+
+		/* bump iocb available response index */
+		if (++pring->rspidx >= portRspMax) {
+			pring->rspidx = 0;
+		}
+
+		/* Let the HBA know what IOCB slot will be the next one the driver
+		 * will read a response from.
+		 */
+		if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+			status = (uint32_t) pring->rspidx;
+			hgp->rspGetInx = PCIMEM_LONG(status);
+
+			/* Since this may be expensive, sync it every 4 IOCBs */
+			loopcnt++;
+			if ((loopcnt & 0x3) == 0) {
+				/* sync hgp->rspGetInx in the MAILBOX_t */
+				elx_pci_dma_sync((void *)phba,
+						 (void *)&phba->slim2p,
+						 sizeof (MAILBOX_t),
+						 ELX_DMA_SYNC_FORDEV);
+			}
+		} else {
+			status = (uint32_t) pring->rspidx;
+			(psli->sliinit.elx_sli_write_slim) ((void *)phba,
+							    (void *)&status,
+							    (int)((SLIMOFF +
+								   (ringno *
+								    2) +
+								   1) * 4),
+							    sizeof (uint32_t));
+		}
+
+		/* chain all iocb entries until LE is set */
+		if (pring->iocb_continueq.q_first == NULL) {
+			pring->iocb_continueq.q_first =
+			    (ELX_SLINK_t *) rspiocbp;
+			pring->iocb_continueq.q_last = (ELX_SLINK_t *) rspiocbp;
+		} else {
+			((ELX_IOCBQ_t *) (pring->iocb_continueq.q_last))->q_f =
+			    (ELX_IOCBQ_t *) rspiocbp;
+			pring->iocb_continueq.q_last = (ELX_SLINK_t *) rspiocbp;
+		}
+		rspiocbp->q_f = 0;
+		pring->iocb_continueq.q_cnt++;
+
+		/* when LE is set, entire Command has been received */
+		if (irsp->ulpLe) {
+			/* get a ptr to first iocb entry in chain and process it */
+			saveq = (ELX_IOCBQ_t *) pring->iocb_continueq.q_first;
+			irsp = &(saveq->iocb);
+
+			pring->iocb_continueq.q_first = 0;
+			pring->iocb_continueq.q_last = 0;
+			pring->iocb_continueq.q_cnt = 0;
+
+			psli->slistat.iocbRsp[ringno]++;
+
+			/* Determine if IOCB command is a solicited or unsolicited event */
+			type =
+			    elx_sli_iocb_cmd_type[(irsp->
+						   ulpCommand & CMD_IOCB_MASK)];
+			if (type == ELX_SOL_IOCB) {
+				/* Solicited Responses */
+				/* Based on the iotag field, get the cmd IOCB from the txcmplq */
+				if ((cmdiocbp =
+				     elx_sli_ringtxcmpl_get(phba, pring, saveq,
+							    0))) {
+					/* Call the specified completion routine */
+					if (cmdiocbp->iocb_cmpl) {
+						ELX_SLI_UNLOCK(phba, iflag);
+						(cmdiocbp->
+						 iocb_cmpl) ((void *)phba,
+							     cmdiocbp, saveq);
+						ELX_SLI_LOCK(phba, iflag);
+						if (cmdiocbp->
+						    iocb_flag & ELX_IO_POLL) {
+							rc = 0;
+						}
+					} else {
+						elx_mem_put(phba, MEM_IOCB,
+							    (uint8_t *)
+							    cmdiocbp);
+					}
+				} else {
+					/* Could not find the initiating command based of the
+					 * response iotag.
+					 */
+					/* Ring <ringno> handler: unexpected completion IoTag <IoTag> */
+					elx_printf_log(phba->brd_no, &elx_msgBlk0322,	/* ptr to msg structure */
+						       elx_mes0322,	/* ptr to msg */
+						       elx_msgBlk0322.msgPreambleStr,	/* begin varargs */
+						       ringno, saveq->iocb.ulpIoTag, saveq->iocb.ulpStatus, saveq->iocb.un.ulpWord[4], saveq->iocb.ulpCommand, saveq->iocb.ulpContext);	/* end varargs */
+				}
+			} else if (type == ELX_UNSOL_IOCB) {
+				WORD5 *w5p;
+				uint32_t Rctl, Type;
+				uint32_t match;
+
+				match = 0;
+				if ((irsp->ulpCommand == CMD_RCV_ELS_REQ64_CX)
+				    || (irsp->ulpCommand ==
+					CMD_RCV_ELS_REQ_CX)) {
+					Rctl = FC_ELS_REQ;
+					Type = FC_ELS_DATA;
+				} else {
+					w5p =
+					    (WORD5 *) & (saveq->iocb.un.
+							 ulpWord[5]);
+					Rctl = w5p->hcsw.Rctl;
+					Type = w5p->hcsw.Type;
+				}
+				/* unSolicited Responses */
+				pringinit = &psli->sliinit.ringinit[ringno];
+				if (pringinit->prt[0].profile) {
+					/* If this ring has a profile set, just send it to prt[0] */
+					ELX_SLI_UNLOCK(phba, iflag);
+					(pringinit->prt[0].
+					 elx_sli_rcv_unsol_event)
+					    (phba, pring, saveq);
+					ELX_SLI_LOCK(phba, iflag);
+					match = 1;
+				} else {
+					/* We must search, based on rctl / type for the right routine */
+					for (i = 0; i < pringinit->num_mask;
+					     i++) {
+						if ((pringinit->prt[i].rctl ==
+						     Rctl)
+						    && (pringinit->prt[i].
+							type == Type)) {
+							ELX_SLI_UNLOCK(phba,
+								       iflag);
+							(pringinit->prt[i].
+							 elx_sli_rcv_unsol_event)
+							    (phba, pring,
+							     saveq);
+							ELX_SLI_LOCK(phba,
+								     iflag);
+							match = 1;
+							break;
+						}
+					}
+				}
+				if (match == 0) {
+					/* Unexpected Rctl / Type received */
+					/* Ring <ringno> handler: unexpected Rctl <Rctl> Type <Type> received */
+					elx_printf_log(phba->brd_no, &elx_msgBlk0313,	/* ptr to msg structure */
+						       elx_mes0313,	/* ptr to msg */
+						       elx_msgBlk0313.msgPreambleStr,	/* begin varargs */
+						       ringno, Rctl, Type);	/* end varargs */
+				}
+			} else if (type == ELX_ABORT_IOCB) {
+				/* Solicited ABORT Responses */
+				/* Based on the iotag field, get the cmd IOCB from the txcmplq */
+				if ((irsp->ulpCommand != CMD_XRI_ABORTED_CX) &&
+				    ((cmdiocbp =
+				      elx_sli_ringtxcmpl_get(phba, pring, saveq,
+							     0)))) {
+					/* Call the specified completion routine */
+					if (cmdiocbp->iocb_cmpl) {
+						ELX_SLI_UNLOCK(phba, iflag);
+						(cmdiocbp->
+						 iocb_cmpl) ((void *)phba,
+							     cmdiocbp, saveq);
+						ELX_SLI_LOCK(phba, iflag);
+					} else {
+						elx_mem_put(phba, MEM_IOCB,
+							    (uint8_t *)
+							    cmdiocbp);
+					}
+				}
+			} else if (type == ELX_UNKNOWN_IOCB) {
+				if (irsp->ulpCommand == CMD_ADAPTER_MSG) {
+
+					char adaptermsg[ELX_MAX_ADPTMSG];
+
+					memset((void *)adaptermsg, 0,
+					       ELX_MAX_ADPTMSG);
+					memcpy(&adaptermsg[0], (uint8_t *) irsp,
+					       MAX_MSG_DATA);
+					elx_printf("elx%d: %s", phba->brd_no,
+						   adaptermsg);
+				} else {
+					/* Unknown IOCB command */
+					elx_printf_log(phba->brd_no, &elx_msgBlk0321,	/* ptr to msg struct */
+						       elx_mes0321,	/* ptr to msg */
+						       elx_msgBlk0321.msgPreambleStr,	/* begin varargs */
+						       irsp->ulpCommand, irsp->ulpStatus, irsp->ulpIoTag, irsp->ulpContext);	/* end varargs */
+				}
+			}
+
+			/* Free up iocb buffer chain for command just processed */
+			while (saveq) {
+				rspiocbp = saveq;
+				saveq = (ELX_IOCBQ_t *) rspiocbp->q_f;
+				elx_mem_put(phba, MEM_IOCB,
+					    (uint8_t *) rspiocbp);
+			}
+
+		}
+		/* Entire Command has been received */
+		entry =
+		    (IOCB_t *) IOCB_ENTRY(pring->rspringaddr, pring->rspidx);
+
+		/* If the port response put pointer has not been updated, sync the pgp->rspPutInx
+		 * in the MAILBOX_tand fetch the new port response put pointer.
+		 */
+		if (pring->rspidx == portRspPut) {
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 sizeof (MAILBOX_t),
+					 ELX_DMA_SYNC_FORCPU);
+			status = pgp->rspPutInx;
+			portRspPut = PCIMEM_LONG(status);
+		}
+	}			/* while (pring->rspidx != portRspPut) */
+
+	if ((rspiocbp != NULL) && (mask & HA_R0RE_REQ)) {
+		/* At least one response entry has been freed */
+		psli->slistat.iocbRspFull[ringno]++;
+		/* SET RxRE_RSP in Chip Att register */
+		status = ((CA_R0ATT | CA_R0RE_RSP) << (ringno * 4));
+		(psli->sliinit.elx_sli_write_CA) (phba, status);
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	if ((mask & HA_R0CE_RSP) && (pring->flag & ELX_CALL_RING_AVAILABLE)) {
+		pring->flag &= ~ELX_CALL_RING_AVAILABLE;
+		psli->slistat.iocbCmdEmpty[ringno]++;
+		portGetIndex = elx_sli_resume_iocb(phba, pring);
+
+		/* Read the new portGetIndex value twice to ensure it was updated correctly. */
+		status = pgp->cmdGetInx;
+		portCmdGet = PCIMEM_LONG(status);
+		if (portGetIndex != portCmdGet) {
+			elx_sli_resume_iocb(phba, pring);
+		}
+		if ((psli->sliinit.ringinit[ringno].elx_sli_cmd_available))
+			(psli->sliinit.ringinit[ringno].
+			 elx_sli_cmd_available) (phba, pring);
+
+		/* Restart the scheduler on the FCP ring. */
+		if (pring->ringno == psli->fcp_ring) {
+			elx_sched_check(phba);
+		}
+	}
+	return (rc);
+}
+
+/*! elx_mbox_timeout
+ * 
+ * \pre
+ * \post
+ * \param hba Pointer to per elxHBA_t structure
+ * \param l1  Pointer to the driver's mailbox queue.
+ * \return 
+ *   void
+ *
+ * \b Description:
+ *
+ * This routine handles mailbox timeout events at timer interrupt context.
+ */
+void
+elx_mbox_timeout(elxHBA_t * phba, void *l1, void *l2)
+{
+	ELX_SLI_t *psli;
+	ELX_MBOXQ_t *pmbox;
+	MAILBOX_t *mb;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	pmbox = (ELX_MBOXQ_t *) l1;
+	mb = &pmbox->mb;
+
+	/* Mbox cmd <mbxCommand> timeout */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0310,	/* ptr to msg structure */
+		       elx_mes0310,	/* ptr to msg */
+		       elx_msgBlk0310.msgPreambleStr,	/* begin varargs */
+		       mb->mbxCommand, phba->hba_state, psli->sliinit.sli_flag, psli->mbox_active);	/* end varargs */
+
+	ELX_SLI_LOCK(phba, iflag);
+	if (psli->mbox_active == pmbox) {
+		psli->mbox_active = 0;
+		if (pmbox->mbox_cmpl) {
+			ELX_SLI_UNLOCK(phba, iflag);
+			mb->mbxStatus = MBX_NOT_FINISHED;
+			(pmbox->mbox_cmpl) ((void *)phba, pmbox);
+
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmbox);
+		}
+		psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+
+	elx_mbox_abort(phba);
+	return;
+}
+
+void
+elx_mbox_abort(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_MBOXQ_t *pmbox;
+	MAILBOX_t *mb;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+
+	ELX_SLI_LOCK(phba, iflag);
+
+	if (psli->mbox_active) {
+		if (psli->mbox_tmo) {
+			elx_clk_can(phba, psli->mbox_tmo);
+			psli->mbox_tmo = 0;
+		}
+		pmbox = psli->mbox_active;
+		mb = &pmbox->mb;
+		psli->mbox_active = 0;
+		if (pmbox->mbox_cmpl) {
+			ELX_SLI_UNLOCK(phba, iflag);
+			mb->mbxStatus = MBX_NOT_FINISHED;
+			(pmbox->mbox_cmpl) ((void *)phba, pmbox);
+
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmbox);
+		}
+		psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+	}
+
+	/* Abort all the non active mailbox commands. */
+	pmbox = elx_mbox_get(phba);
+	while (pmbox) {
+		mb = &pmbox->mb;
+		if (pmbox->mbox_cmpl) {
+			ELX_SLI_UNLOCK(phba, iflag);
+			mb->mbxStatus = MBX_NOT_FINISHED;
+			(pmbox->mbox_cmpl) ((void *)phba, pmbox);
+
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmbox);
+		}
+		pmbox = elx_mbox_get(phba);
+	}
+
+	ELX_SLI_UNLOCK(phba, iflag);
+
+	return;
+}
+
+int
+elx_sli_issue_mbox(elxHBA_t * phba, ELX_MBOXQ_t * pmbox, uint32_t flag)
+{
+	MAILBOX_t *mbox;
+	MAILBOX_t *mb;
+	ELX_SLI_t *psli;
+	uint32_t status, evtctr;
+	uint32_t ha_copy;
+	int i;
+	unsigned long drvr_flag;
+	unsigned long iflag;
+	volatile uint32_t word0, ldata;
+
+	psli = &phba->sli;
+	if (flag & MBX_POLL) {
+		ELX_DRVR_LOCK(phba, drvr_flag);
+	}
+
+	ELX_SLI_LOCK(phba, iflag);
+
+	mb = &pmbox->mb;
+	status = MBX_SUCCESS;
+
+	if (psli->sliinit.sli_flag & ELX_SLI_MBOX_ACTIVE) {
+		/* Polling for a mbox command when another one is
+		 * already active is not allowed in SLI. Also, the driver must 
+		 * have established SLI2 mode to queue and process multiple mbox commands.
+		 */
+
+		if (flag & MBX_POLL) {
+			psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+			ELX_SLI_UNLOCK(phba, iflag);
+			ELX_DRVR_UNLOCK(phba, drvr_flag);
+			goto mbxerr;
+		}
+
+		if (!(psli->sliinit.sli_flag & ELX_SLI2_ACTIVE)) {
+			psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+			ELX_SLI_UNLOCK(phba, iflag);
+			goto mbxerr;
+		}
+
+		/* Handle STOP IOCB processing flag. This is only meaningful
+		 * if we are not polling for mbox completion.
+		 */
+		if (flag & MBX_STOP_IOCB) {
+			flag &= ~MBX_STOP_IOCB;
+			/* Now flag each ring */
+			for (i = 0; i < psli->sliinit.num_rings; i++) {
+				/* If the ring is active, flag it */
+				if (psli->ring[i].cmdringaddr) {
+					psli->ring[i].flag |= ELX_STOP_IOCB_MBX;
+				}
+			}
+		}
+
+		/* Another mailbox command is still being processed, queue this
+		 * command to be processed later.
+		 */
+		elx_mbox_put(phba, pmbox);
+
+		/* Mbox cmd issue - BUSY */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0308,	/* ptr to msg structure */
+			       elx_mes0308,	/* ptr to msg */
+			       elx_msgBlk0308.msgPreambleStr,	/* begin varargs */
+			       mb->mbxCommand, phba->hba_state, psli->sliinit.sli_flag, flag);	/* end varargs */
+
+		psli->slistat.mboxBusy++;
+		ELX_SLI_UNLOCK(phba, iflag);
+		if (flag == MBX_POLL) {
+			ELX_DRVR_UNLOCK(phba, drvr_flag);
+		}
+		return (MBX_BUSY);
+	}
+
+	/* Handle STOP IOCB processing flag. This is only meaningful
+	 * if we are not polling for mbox completion.
+	 */
+	if (flag & MBX_STOP_IOCB) {
+		flag &= ~MBX_STOP_IOCB;
+		if (flag == MBX_NOWAIT) {
+			/* Now flag each ring */
+			for (i = 0; i < psli->sliinit.num_rings; i++) {
+				/* If the ring is active, flag it */
+				if (psli->ring[i].cmdringaddr) {
+					psli->ring[i].flag |= ELX_STOP_IOCB_MBX;
+				}
+			}
+		}
+	}
+
+	psli->sliinit.sli_flag |= ELX_SLI_MBOX_ACTIVE;
+
+	/* If we are not polling, we MUST be in SLI2 mode */
+	if (flag != MBX_POLL) {
+		if (!(psli->sliinit.sli_flag & ELX_SLI2_ACTIVE)) {
+			psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+			ELX_SLI_UNLOCK(phba, iflag);
+		      mbxerr:
+			/* Mbox command <mbxCommand> cannot issue */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0311,	/* ptr to msg structure */
+				       elx_mes0311,	/* ptr to msg */
+				       elx_msgBlk0311.msgPreambleStr,	/* begin varargs */
+				       mb->mbxCommand, phba->hba_state, psli->sliinit.sli_flag, flag);	/* end varargs */
+			return (MBX_NOT_FINISHED);
+		}
+		/* timeout active mbox command */
+		if (psli->mbox_tmo) {
+			elx_clk_res(phba, ELX_MBOX_TMO, psli->mbox_tmo);
+		} else {
+			psli->mbox_tmo = elx_clk_set(phba, ELX_MBOX_TMO,
+						     elx_mbox_timeout, pmbox,
+						     0);
+		}
+	}
+
+	/* Mailbox cmd <cmd> issue */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0309,	/* ptr to msg structure */
+		       elx_mes0309,	/* ptr to msg */
+		       elx_msgBlk0309.msgPreambleStr,	/* begin varargs */
+		       mb->mbxCommand, phba->hba_state, psli->sliinit.sli_flag, flag);	/* end varargs */
+
+	psli->slistat.mboxCmd++;
+	evtctr = psli->slistat.mboxEvent;
+
+	/* next set own bit for the adapter and copy over command word */
+	mb->mbxOwner = OWN_CHIP;
+
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+		/* First copy command data to host SLIM area */
+		mbox = (MAILBOX_t *) psli->MBhostaddr;
+		elx_sli_pcimem_bcopy((uint32_t *) mb, (uint32_t *) mbox,
+				     (sizeof (uint32_t) * (MAILBOX_CMD_WSIZE)));
+		elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+				 sizeof (MAILBOX_t), ELX_DMA_SYNC_FORDEV);
+
+	} else {
+		if (mb->mbxCommand == MBX_CONFIG_PORT) {
+			/* copy command data into host mbox for cmpl */
+			mbox = (MAILBOX_t *) psli->MBhostaddr;
+			elx_sli_pcimem_bcopy((uint32_t *) mb, (uint32_t *) mbox,
+					     (sizeof (uint32_t) *
+					      (MAILBOX_CMD_WSIZE)));
+		}
+
+		/* First copy mbox command data to HBA SLIM, skip past first word */
+		(psli->sliinit.elx_sli_write_slim) ((void *)phba,
+						    (void *)&mb->un.varWords[0],
+						    sizeof (uint32_t),
+						    ((MAILBOX_CMD_WSIZE -
+						      1) * sizeof (uint32_t)));
+
+		/* Next copy over first word, with mbxOwner set */
+		ldata = *((volatile uint32_t *)mb);
+		(psli->sliinit.elx_sli_write_slim) ((void *)phba,
+						    (void *)&ldata, 0,
+						    sizeof (uint32_t));
+
+		if (mb->mbxCommand == MBX_CONFIG_PORT) {
+			/* switch over to host mailbox */
+			psli->sliinit.sli_flag |= ELX_SLI2_ACTIVE;
+		}
+	}
+
+	/* interrupt board to doit right away */
+	(psli->sliinit.elx_sli_write_CA) (phba, CA_MBATT);
+
+	switch (flag) {
+	case MBX_NOWAIT:
+		/* Don't wait for it to finish, just return */
+		psli->mbox_active = pmbox;
+		break;
+
+	case MBX_POLL:
+		i = 0;
+		psli->mbox_active = 0;
+		if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 sizeof (MAILBOX_t),
+					 ELX_DMA_SYNC_FORCPU);
+
+			/* First read mbox status word */
+			mbox = (MAILBOX_t *) psli->MBhostaddr;
+			word0 = *((volatile uint32_t *)mbox);
+			word0 = PCIMEM_LONG(word0);
+		} else {
+			/* First read mbox status word */
+			(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+							   (void *)&word0, 0,
+							   sizeof (uint32_t));
+		}
+
+		/* Read the HBA Host Attention Register */
+		ha_copy = (psli->sliinit.elx_sli_read_HA) (phba);
+
+		/* Wait for command to complete */
+		while (((word0 & OWN_CHIP) == OWN_CHIP)
+		       || !(ha_copy & HA_MBATT)) {
+			if (i++ >= 100) {
+				psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+
+				ELX_SLI_UNLOCK(phba, iflag);
+				ELX_DRVR_UNLOCK(phba, drvr_flag);
+				return (MBX_NOT_FINISHED);
+			}
+
+			/* Check if we took a mbox interrupt while we were polling */
+			if (((word0 & OWN_CHIP) != OWN_CHIP)
+			    && (evtctr != psli->slistat.mboxEvent))
+				break;
+
+			ELX_SLI_UNLOCK(phba, iflag);
+			ELX_DRVR_UNLOCK(phba, drvr_flag);
+
+			/* If in interrupt context do not sleep */
+			if (elx_in_intr())
+				mdelay(i);
+			else
+				elx_sleep_ms(phba, i);
+
+			ELX_DRVR_LOCK(phba, drvr_flag);
+			ELX_SLI_LOCK(phba, iflag);
+
+			if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+				elx_pci_dma_sync((void *)phba,
+						 (void *)&phba->slim2p,
+						 sizeof (MAILBOX_t),
+						 ELX_DMA_SYNC_FORCPU);
+
+				/* First copy command data */
+				mbox = (MAILBOX_t *) psli->MBhostaddr;
+				word0 = *((volatile uint32_t *)mbox);
+				word0 = PCIMEM_LONG(word0);
+				if (mb->mbxCommand == MBX_CONFIG_PORT) {
+					MAILBOX_t *slimmb;
+					volatile uint32_t slimword0;
+					/* Check real SLIM for any errors */
+					(psli->sliinit.
+					 elx_sli_read_slim) ((void *)phba,
+							     (void *)&slimword0,
+							     0,
+							     sizeof (uint32_t));
+					slimmb = (MAILBOX_t *) & slimword0;
+					if (((slimword0 & OWN_CHIP) != OWN_CHIP)
+					    && slimmb->mbxStatus) {
+						psli->sliinit.sli_flag &=
+						    ~ELX_SLI2_ACTIVE;
+						word0 = slimword0;
+					}
+				}
+			} else {
+				/* First copy command data */
+				(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+								   (void *)
+								   &word0, 0,
+								   sizeof
+								   (uint32_t));
+			}
+			/* Read the HBA Host Attention Register */
+			ha_copy = (psli->sliinit.elx_sli_read_HA) (phba);
+		}
+
+		if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 sizeof (MAILBOX_t),
+					 ELX_DMA_SYNC_FORCPU);
+
+			/* First copy command data */
+			mbox = (MAILBOX_t *) psli->MBhostaddr;
+			/* copy results back to user */
+			elx_sli_pcimem_bcopy((uint32_t *) mbox, (uint32_t *) mb,
+					     (sizeof (uint32_t) *
+					      MAILBOX_CMD_WSIZE));
+		} else {
+			/* First copy command data */
+			(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+							   (void *)mb, 0,
+							   (sizeof (uint32_t) *
+							    (MAILBOX_CMD_WSIZE)));
+		}
+
+		(psli->sliinit.elx_sli_write_HA) (phba, HA_MBATT);
+
+		psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+		status = mb->mbxStatus;
+	}
+
+	ELX_SLI_UNLOCK(phba, iflag);
+	if (flag == MBX_POLL) {
+		ELX_DRVR_UNLOCK(phba, drvr_flag);
+	}
+	return (status);
+}
+
+int
+elx_sli_issue_iocb(elxHBA_t * phba,
+		   ELX_SLI_RING_t * pring, ELX_IOCBQ_t * piocb, uint32_t flag)
+{
+	ELX_SLI_t *psli;
+	IOCB_t *iocb;
+	IOCB_t *icmd = NULL;
+	HGP *hgp;
+	PGP *pgp;
+	MAILBOX_t *mbox;
+	ELX_IOCBQ_t *nextiocb;
+	ELX_IOCBQ_t *lastiocb;
+	uint32_t status;
+	int ringno, loopcnt;
+	uint32_t portCmdGet, portCmdMax;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	ringno = pring->ringno;
+
+	/* At this point we assume SLI-2 */
+	mbox = (MAILBOX_t *) psli->MBhostaddr;
+	pgp = (PGP *) & mbox->us.s2.port[ringno];
+	hgp = (HGP *) & mbox->us.s2.host[ringno];
+
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* portCmdMax is the number of cmd ring entries for this specific ring. */
+	portCmdMax = psli->sliinit.ringinit[ringno].numCiocb;
+
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORCPU);
+
+	/* portCmdGet is the IOCB index of the next IOCB that the HBA
+	 * is going to process.
+	 */
+	status = pgp->cmdGetInx;
+	portCmdGet = PCIMEM_LONG(status);
+
+	/* We should never get an IOCB if we are in a < LINK_DOWN state */
+	if (phba->hba_state < ELX_LINK_DOWN) {
+		/* If link is not initialized, just return */
+
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (IOCB_ERROR);
+	}
+
+	/* Check to see if we are blocking IOCB processing because of a
+	 * outstanding mbox command.
+	 */
+	if (pring->flag & ELX_STOP_IOCB_MBX) {
+		/* Queue command to ring xmit queue */
+		if (!(flag & SLI_IOCB_RET_IOCB)) {
+			elx_sli_ringtx_put(phba, pring, piocb);
+		}
+		psli->slistat.iocbCmdDelay[ringno]++;
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (IOCB_BUSY);
+	}
+
+	if (phba->hba_state == ELX_LINK_DOWN) {
+		icmd = &piocb->iocb;
+		if ((icmd->ulpCommand == CMD_QUE_RING_BUF_CN) ||
+		    (icmd->ulpCommand == CMD_QUE_RING_BUF64_CN) ||
+		    (icmd->ulpCommand == CMD_CLOSE_XRI_CN) ||
+		    (icmd->ulpCommand == CMD_ABORT_XRI_CN)) {
+			/* For IOCBs, like QUE_RING_BUF, that have no rsp ring 
+			 * completion, iocb_cmpl MUST be 0.
+			 */
+			if (piocb->iocb_cmpl) {
+				piocb->iocb_cmpl = 0;
+			}
+		} else {
+			if ((icmd->ulpCommand != CMD_CREATE_XRI_CR)) {
+				/* Queue command to ring xmit queue */
+				if (!(flag & SLI_IOCB_RET_IOCB)) {
+					elx_sli_ringtx_put(phba, pring, piocb);
+				}
+
+				/* If link is down, just return */
+				psli->slistat.iocbCmdDelay[ringno]++;
+				ELX_SLI_UNLOCK(phba, iflag);
+				return (IOCB_BUSY);
+			}
+		}
+		/* Only CREATE_XRI and QUE_RING_BUF can be issued if the link
+		 * is not up.
+		 */
+	} else {
+		/* For FCP commands, we must be in a state where we can process
+		 * link attention events.
+		 */
+		if (!(psli->sliinit.sli_flag & ELX_PROCESS_LA) &&
+		    (pring->ringno == psli->fcp_ring)) {
+			/* Queue command to ring xmit queue */
+			if (!(flag & SLI_IOCB_RET_IOCB)) {
+				elx_sli_ringtx_put(phba, pring, piocb);
+			}
+			psli->slistat.iocbCmdDelay[ringno]++;
+			ELX_SLI_UNLOCK(phba, iflag);
+			return (IOCB_BUSY);
+		}
+	}
+
+	/* onetime should only be set for QUE_RING_BUF or CREATE_XRI
+	 * iocbs sent with link down.
+	 */
+
+	/* Get the next available command iocb.
+	 * cmdidx is the IOCB index of the next IOCB that the driver
+	 * is going to issue a command with.
+	 */
+	iocb = (IOCB_t *) IOCB_ENTRY(pring->cmdringaddr, pring->cmdidx);
+
+	if (portCmdGet >= portCmdMax) {
+
+		/* Ring <ringno> issue: portCmdGet <portCmdGet> is bigger then cmd ring <portCmdMax> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0314,	/* ptr to msg structure */
+			       elx_mes0314,	/* ptr to msg */
+			       elx_msgBlk0314.msgPreambleStr,	/* begin varargs */
+			       ringno, portCmdGet, portCmdMax);	/* end varargs */
+		/* Queue command to ring xmit queue */
+		if (!(flag & SLI_IOCB_RET_IOCB)) {
+			elx_sli_ringtx_put(phba, pring, piocb);
+		}
+		psli->slistat.iocbCmdDelay[ringno]++;
+		ELX_SLI_UNLOCK(phba, iflag);
+		/*
+		 * Treat it as adapter hardware error.
+		 */
+		phba->hba_state = ELX_HBA_ERROR;
+		phba->hba_flag |= FC_STOP_IO;
+		(psli->sliinit.elx_sli_handle_eratt) (phba, HS_FFER3);
+		return (IOCB_BUSY);
+	}
+
+	/* Bump driver iocb command index to next IOCB */
+	if (++pring->cmdidx >= portCmdMax) {
+		pring->cmdidx = 0;
+	}
+	lastiocb = 0;
+	loopcnt = 0;
+
+	/* Check to see if this is a high priority
+	   command. If so bypass tx queue processing.
+	 */
+
+	if (flag & SLI_IOCB_HIGH_PRIORITY) {
+		nextiocb = NULL;
+		goto afterloop;
+	}
+
+	/* While IOCB entries are available */
+	while (pring->cmdidx != portCmdGet) {
+		/* If there is anything on the tx queue, process it before piocb */
+		if (((nextiocb = elx_sli_ringtx_get(phba, pring)) == NULL)
+		    && (piocb == NULL)) {
+		      issueout:
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 ELX_SLIM2_PAGE_AREA,
+					 ELX_DMA_SYNC_FORCPU);
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 ELX_SLIM2_PAGE_AREA,
+					 ELX_DMA_SYNC_FORDEV);
+
+			/* Make sure cmdidx is in sync with the HBA's current value. */
+			if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+				status = hgp->cmdPutInx;
+				pring->cmdidx = (uint8_t) PCIMEM_LONG(status);
+			} else {
+				(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+								   (void *)
+								   &status,
+								   (int)((SLIMOFF + (ringno * 2)) * 4), sizeof (uint32_t));
+				pring->cmdidx = (uint8_t) status;
+			}
+
+			/* Interrupt the HBA to let it know there is work to do
+			 * in ring ringno.
+			 */
+			status = ((CA_R0ATT) << (ringno * 4));
+			(psli->sliinit.elx_sli_write_CA) (phba, status);
+
+			/* If we are waiting for the IOCB to complete before returning */
+			if ((flag & SLI_IOCB_POLL) && lastiocb) {
+				uint32_t loopcnt, ha_copy;
+				int retval;
+
+				/* Wait 10240 loop iterations + 30 seconds before timing out the IOCB. */
+				for (loopcnt = 0; loopcnt < (10240 + 30);
+				     loopcnt++) {
+					ha_copy =
+					    (psli->sliinit.
+					     elx_sli_intr_prep) ((void *)phba);
+					ha_copy = (ha_copy >> (ringno * 4));
+					if (ha_copy & HA_RXATT) {
+						ELX_SLI_UNLOCK(phba, iflag);
+						retval =
+						    elx_sli_handle_ring_event
+						    (phba, pring,
+						     (ha_copy & HA_RXMASK));
+						ELX_SLI_LOCK(phba, iflag);
+						/*
+						 * The IOCB requires to poll for completion.
+						 * If retval is identically 0, the iocb has been handled.  
+						 * Otherwise, wait and retry.
+						 */
+						if (retval == 0) {
+							break;
+						}
+					}
+					if (loopcnt > 10240) {
+						elx_sleep_ms(phba, 1000);	/* 1 second delay */
+					}
+				}
+				if (loopcnt >= (10240 + 30)) {
+					/* Command timed out */
+					/* Based on the iotag field, get the cmd IOCB from the txcmplq */
+					if ((lastiocb =
+					     elx_sli_ringtxcmpl_get(phba, pring,
+								    lastiocb,
+								    0))) {
+						/* Call the specified completion routine */
+						icmd = &lastiocb->iocb;
+						icmd->ulpStatus =
+						    IOSTAT_LOCAL_REJECT;
+						icmd->un.ulpWord[4] =
+						    IOERR_SEQUENCE_TIMEOUT;
+						if (lastiocb->iocb_cmpl) {
+							ELX_SLI_UNLOCK(phba,
+								       iflag);
+							(lastiocb->
+							 iocb_cmpl) ((void *)
+								     phba,
+								     lastiocb,
+								     lastiocb);
+							ELX_SLI_LOCK(phba,
+								     iflag);
+						} else {
+							elx_mem_put(phba,
+								    MEM_IOCB,
+								    (uint8_t *)
+								    lastiocb);
+						}
+					}
+				}
+			}
+			ELX_SLI_UNLOCK(phba, iflag);
+			return (IOCB_SUCCESS);
+		}
+
+	      afterloop:
+
+		/* If there is nothing left in the tx queue, now we can send piocb */
+		if (nextiocb == NULL) {
+			nextiocb = piocb;
+			piocb = NULL;
+		}
+		icmd = &nextiocb->iocb;
+
+		/* issue iocb command to adapter */
+		elx_sli_pcimem_bcopy((uint32_t *) icmd, (uint32_t *) iocb,
+				     sizeof (IOCB_t));
+		psli->slistat.iocbCmd[ringno]++;
+
+		/* If there is no completion routine to call, we can release the IOCB
+		 * buffer back right now. For IOCBs, like QUE_RING_BUF, that have no
+		 * rsp ring completion, iocb_cmpl MUST be 0.
+		 */
+		if (nextiocb->iocb_cmpl) {
+			elx_sli_ringtxcmpl_put(phba, pring, nextiocb);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) nextiocb);
+		}
+
+		/* Let the HBA know what IOCB slot will be the next one the driver
+		 * will put a command into.
+		 */
+		if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+			status = (uint32_t) pring->cmdidx;
+			hgp->cmdPutInx = PCIMEM_LONG(status);
+
+			/* Since this may be expensive, sync it every 4 IOCBs */
+			loopcnt++;
+			if ((loopcnt & 0x3) == 0) {
+				/* sync hgp->cmdPutInx in the MAILBOX_t */
+				elx_pci_dma_sync((void *)phba,
+						 (void *)&phba->slim2p,
+						 sizeof (MAILBOX_t),
+						 ELX_DMA_SYNC_FORDEV);
+			}
+		} else {
+			status = (uint32_t) pring->cmdidx;
+			(psli->sliinit.elx_sli_write_slim) ((void *)phba,
+							    (void *)&status,
+							    (int)((SLIMOFF +
+								   (ringno *
+								    2)) * 4),
+							    sizeof (uint32_t));
+		}
+
+		/* Get the next available command iocb.
+		 * cmdidx is the IOCB index of the next IOCB that the driver
+		 * is going to issue a command with.
+		 */
+		iocb = (IOCB_t *) IOCB_ENTRY(pring->cmdringaddr, pring->cmdidx);
+
+		/* Bump driver iocb command index to next IOCB */
+		if (++pring->cmdidx >= portCmdMax) {
+			pring->cmdidx = 0;
+		}
+
+		lastiocb = nextiocb;
+
+		/* Make sure the ring's command index has been updated.  If 
+		 * not, sync the slim memory area and refetch the command index.
+		 */
+		if (pring->cmdidx == portCmdGet) {
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 sizeof (MAILBOX_t),
+					 ELX_DMA_SYNC_FORCPU);
+			status = pgp->cmdGetInx;
+			portCmdGet = PCIMEM_LONG(status);
+		}
+
+	}			/* pring->cmdidx != portCmdGet */
+
+	if (piocb == NULL && !(flag & SLI_IOCB_HIGH_PRIORITY)) {
+		goto issueout;
+	} else if (piocb == NULL) {
+		elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+				 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORCPU);
+		elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+				 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORDEV);
+
+		/* Make sure cmdidx is in sync with the HBA's current value. */
+		if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+			status = hgp->cmdPutInx;
+			pring->cmdidx = (uint8_t) PCIMEM_LONG(status);
+		} else {
+			(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+							   (void *)&status,
+							   (int)((SLIMOFF +
+								  (ringno *
+								   2)) * 4),
+							   sizeof (uint32_t));
+			pring->cmdidx = (uint8_t) status;
+		}
+
+		/* Interrupt the HBA to let it know there is work to do
+		 * in ring ringno.
+		 */
+		status = ((CA_R0ATT) << (ringno * 4));
+		(psli->sliinit.elx_sli_write_CA) (phba, status);
+
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (IOCB_SUCCESS);
+	}
+
+	/* This code is executed only if the command ring is full.  Wait for the
+	 * HBA to process some entries before handing it more work.
+	 */
+
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORCPU);
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORDEV);
+
+	/* Make sure cmdidx is in sync with the HBA's current value. */
+	if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+		status = hgp->cmdPutInx;
+		pring->cmdidx = (uint8_t) PCIMEM_LONG(status);
+	} else {
+		(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+						   (void *)&status,
+						   (int)((SLIMOFF +
+							  (ringno * 2)) * 4),
+						   sizeof (uint32_t));
+		pring->cmdidx = (uint8_t) status;
+	}
+
+	pring->flag |= ELX_CALL_RING_AVAILABLE;	/* indicates cmd ring was full */
+	/* 
+	 * Set ring 'ringno' to SET R0CE_REQ in Chip Att register.
+	 * The HBA will tell us when an IOCB entry is available.
+	 */
+	status = ((CA_R0ATT | CA_R0CE_REQ) << (ringno * 4));
+	(psli->sliinit.elx_sli_write_CA) (phba, status);
+
+	psli->slistat.iocbCmdFull[ringno]++;
+
+	/* Queue command to ring xmit queue */
+	if ((!(flag & SLI_IOCB_RET_IOCB)) && piocb) {
+		elx_sli_ringtx_put(phba, pring, piocb);
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (IOCB_BUSY);
+}
+
+int
+elx_sli_resume_iocb(elxHBA_t * phba, ELX_SLI_RING_t * pring)
+{
+	ELX_SLI_t *psli;
+	IOCB_t *iocb;
+	IOCB_t *icmd = NULL;
+	HGP *hgp;
+	PGP *pgp;
+	MAILBOX_t *mbox;
+	ELX_IOCBQ_t *nextiocb;
+	uint32_t status;
+	int ringno, loopcnt;
+	uint32_t portCmdGet, portCmdMax;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	ringno = pring->ringno;
+
+	/* At this point we assume SLI-2 */
+	mbox = (MAILBOX_t *) psli->MBhostaddr;
+	pgp = (PGP *) & mbox->us.s2.port[ringno];
+	hgp = (HGP *) & mbox->us.s2.host[ringno];
+
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* portCmdMax is the number of cmd ring entries for this specific ring. */
+	portCmdMax = psli->sliinit.ringinit[ringno].numCiocb;
+
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORCPU);
+
+	/* portCmdGet is the IOCB index of the next IOCB that the HBA
+	 * is going to process.
+	 */
+	status = pgp->cmdGetInx;
+	portCmdGet = PCIMEM_LONG(status);
+
+	/* First check to see if there is anything on the txq to send */
+	if (pring->txq.q_cnt == 0) {
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (portCmdGet);
+	}
+
+	if (phba->hba_state <= ELX_LINK_DOWN) {
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (portCmdGet);
+	}
+	/* For FCP commands, we must be in a state where we can process
+	 * link attention events.
+	 */
+	if (!(psli->sliinit.sli_flag & ELX_PROCESS_LA) &&
+	    (pring->ringno == psli->fcp_ring)) {
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (portCmdGet);
+	}
+
+	/* Check to see if we are blocking IOCB processing because of a
+	 * outstanding mbox command.
+	 */
+	if (pring->flag & ELX_STOP_IOCB_MBX) {
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (portCmdGet);
+	}
+
+	/* Get the next available command iocb.
+	 * cmdidx is the IOCB index of the next IOCB that the driver
+	 * is going to issue a command with.
+	 */
+	iocb = (IOCB_t *) IOCB_ENTRY(pring->cmdringaddr, pring->cmdidx);
+
+	if (portCmdGet >= portCmdMax) {
+
+		/* Ring <ringno> issue: portCmdGet <portCmdGet> is bigger then cmd ring <portCmdMax> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0315,	/* ptr to msg structure */
+			       elx_mes0315,	/* ptr to msg */
+			       elx_msgBlk0315.msgPreambleStr,	/* begin varargs */
+			       ringno, portCmdGet, portCmdMax);	/* end varargs */
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (portCmdGet);
+	}
+
+	/* Bump driver iocb command index to next IOCB */
+	if (++pring->cmdidx >= portCmdMax) {
+		pring->cmdidx = 0;
+	}
+	loopcnt = 0;
+
+	/* While IOCB entries are available */
+	while (pring->cmdidx != portCmdGet) {
+		/* If there is anything on the tx queue, process it */
+		if ((nextiocb = elx_sli_ringtx_get(phba, pring)) == NULL) {
+
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 ELX_SLIM2_PAGE_AREA,
+					 ELX_DMA_SYNC_FORCPU);
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 ELX_SLIM2_PAGE_AREA,
+					 ELX_DMA_SYNC_FORDEV);
+
+			/* Make sure cmdidx is in sync with the HBA's current value. */
+			if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+				status = hgp->cmdPutInx;
+				pring->cmdidx = (uint8_t) PCIMEM_LONG(status);
+			} else {
+				(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+								   (void *)
+								   &status,
+								   (int)((SLIMOFF + (ringno * 2)) * 4), sizeof (uint32_t));
+				pring->cmdidx = (uint8_t) status;
+			}
+
+			/* Interrupt the HBA to let it know there is work to do
+			 * in ring ringno.
+			 */
+			status = ((CA_R0ATT) << (ringno * 4));
+			(psli->sliinit.elx_sli_write_CA) (phba, status);
+
+			ELX_SLI_UNLOCK(phba, iflag);
+			return (portCmdGet);
+		}
+		icmd = &nextiocb->iocb;
+
+		/* issue iocb command to adapter */
+		elx_sli_pcimem_bcopy((uint32_t *) icmd, (uint32_t *) iocb,
+				     sizeof (IOCB_t));
+		psli->slistat.iocbCmd[ringno]++;
+
+		/* If there is no completion routine to call, we can release the IOCB
+		 * buffer back right now. For IOCBs, like QUE_RING_BUF, that have no
+		 * rsp ring completion, iocb_cmpl MUST be 0.
+		 */
+		if (nextiocb->iocb_cmpl) {
+			elx_sli_ringtxcmpl_put(phba, pring, nextiocb);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) nextiocb);
+		}
+
+		/* Let the HBA know what IOCB slot will be the next one the driver
+		 * will put a command into.
+		 */
+		if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+			status = (uint32_t) pring->cmdidx;
+			hgp->cmdPutInx = PCIMEM_LONG(status);
+
+			/* Since this may be expensive, sync it every 4 IOCBs */
+			loopcnt++;
+			if ((loopcnt & 0x3) == 0) {
+				/* sync hgp->cmdPutInx in the MAILBOX_t */
+				elx_pci_dma_sync((void *)phba,
+						 (void *)&phba->slim2p,
+						 sizeof (MAILBOX_t),
+						 ELX_DMA_SYNC_FORDEV);
+			}
+		} else {
+			status = (uint32_t) pring->cmdidx;
+			(psli->sliinit.elx_sli_write_slim) ((void *)phba,
+							    (void *)&status,
+							    (int)((SLIMOFF +
+								   (ringno *
+								    2)) * 4),
+							    sizeof (uint32_t));
+		}
+
+		/* Get the next available command iocb.
+		 * cmdidx is the IOCB index of the next IOCB that the driver
+		 * is going to issue a command with.
+		 */
+		iocb = (IOCB_t *) IOCB_ENTRY(pring->cmdringaddr, pring->cmdidx);
+
+		/* Bump driver iocb command index to next IOCB */
+		if (++pring->cmdidx >= portCmdMax) {
+			pring->cmdidx = 0;
+		}
+
+		/* Make sure the ring's command index has been updated.  If 
+		 * not, sync the slim memory area and refetch the command index.
+		 */
+		if (pring->cmdidx == portCmdGet) {
+			/* sync pgp->cmdGetInx in the MAILBOX_t */
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 sizeof (MAILBOX_t),
+					 ELX_DMA_SYNC_FORCPU);
+			status = pgp->cmdGetInx;
+			portCmdGet = PCIMEM_LONG(status);
+		}
+	}
+
+	/* This code is executed only if the command ring is full.  Wait for the
+	 * HBA to process some entries before handing it more work.
+	 */
+
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORCPU);
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORDEV);
+
+	/* Make sure cmdidx is in sync with the HBA's current value. */
+	if (psli->sliinit.sli_flag & ELX_HGP_HOSTSLIM) {
+		status = hgp->cmdPutInx;
+		pring->cmdidx = (uint8_t) PCIMEM_LONG(status);
+	} else {
+		(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+						   (void *)&status,
+						   (int)((SLIMOFF +
+							  (ringno * 2)) * 4),
+						   sizeof (uint32_t));
+		pring->cmdidx = (uint8_t) status;
+	}
+
+	pring->flag |= ELX_CALL_RING_AVAILABLE;	/* indicates cmd ring was full */
+	/* 
+	 * Set ring 'ringno' to SET R0CE_REQ in Chip Att register.
+	 * The HBA will tell us when an IOCB entry is available.
+	 */
+	status = ((CA_R0ATT | CA_R0CE_REQ) << (ringno * 4));
+	(psli->sliinit.elx_sli_write_CA) (phba, status);
+
+	psli->slistat.iocbCmdFull[ringno]++;
+
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (portCmdGet);
+}
+
+int
+elx_sli_brdreset(elxHBA_t * phba)
+{
+	MAILBOX_t *swpmb;
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	uint16_t cfg_value, skip_post;
+	volatile uint32_t word0;
+	unsigned long iflag;
+	int i;
+
+	psli = &phba->sli;
+
+	ELX_SLI_LOCK(phba, iflag);
+	/* A board reset must use REAL SLIM. */
+	psli->sliinit.sli_flag &= ~ELX_SLI2_ACTIVE;
+
+	word0 = 0;
+	swpmb = (MAILBOX_t *) & word0;
+	swpmb->mbxCommand = MBX_RESTART;
+	swpmb->mbxHc = 1;
+
+	(psli->sliinit.elx_sli_write_slim) ((void *)phba, (void *)swpmb,
+					    0, sizeof (uint32_t));
+
+	/* Only skip post after fc_ffinit is completed */
+	if (phba->hba_state) {
+		skip_post = 1;
+		word0 = 1;	/* This is really setting up word1 */
+		(psli->sliinit.elx_sli_write_slim) ((void *)phba, (void *)swpmb,
+						    sizeof (uint32_t),
+						    sizeof (uint32_t));
+	} else {
+		skip_post = 0;
+	}
+
+	/* Turn off SERR, PERR in PCI cmd register */
+	phba->hba_state = ELX_INIT_START;
+
+	ELX_SLI_UNLOCK(phba, iflag);
+	/* Call the registered board reset routine */
+	(psli->sliinit.elx_sli_brdreset) (phba);
+
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		pring = &psli->ring[i];
+		elx_sli_abort_iocb_ring(phba, pring, ELX_SLI_ABORT_IMED);
+	}
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Turn off parity checking and serr during the physical reset */
+	cfg_value = (psli->sliinit.elx_sli_read_pci_cmd) ((void *)phba);
+	(psli->sliinit.elx_sli_write_pci_cmd) ((void *)phba,
+					       (uint16_t) (cfg_value &
+							   ~(CMD_PARITY_CHK |
+							     CMD_SERR_ENBL)));
+
+	/* Now toggle INITFF bit in the Host Control Register */
+	(psli->sliinit.elx_sli_write_HC) (phba, HC_INITFF);
+	mdelay(1);
+	(psli->sliinit.elx_sli_write_HC) (phba, 0);
+
+	/* Restore PCI cmd register */
+	(psli->sliinit.elx_sli_write_pci_cmd) ((void *)phba, cfg_value);
+
+	phba->hba_state = ELX_INIT_START;
+
+	/* Initialize relevant SLI info */
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		pring = &psli->ring[i];
+		pring->flag = 0;
+		pring->rspidx = 0;
+		pring->cmdidx = 0;
+		pring->missbufcnt = 0;
+	}
+
+	ELX_SLI_UNLOCK(phba, iflag);
+	if (skip_post) {
+		mdelay(100);
+	} else {
+		mdelay(2000);
+	}
+	return (0);
+}
+
+int
+elx_sli_setup(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+	int i, cnt;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	buf_info = &bufinfo;
+
+	ELX_SLI_LOCK(phba, iflag);
+	/* Initialize list headers for txq and txcmplq as double linked lists */
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		pring = &psli->ring[i];
+		pring->ringno = i;
+		pring->txq.q_f = &pring->txq;
+		pring->txq.q_b = &pring->txq;
+		pring->txcmplq.q_f = &pring->txcmplq;
+		pring->txcmplq.q_b = &pring->txcmplq;
+		pring->postbufq.q_first = 0;
+		pring->postbufq.q_last = 0;
+		cnt = psli->sliinit.ringinit[i].fast_iotag;
+		if (cnt) {
+			/* Allocate space needed for fast lookup */
+			buf_info->size = (cnt * sizeof (ELX_IOCBQ_t *));
+			buf_info->flags = 0;
+			buf_info->align = sizeof (void *);
+			buf_info->dma_handle = 0;
+
+			/* Create a table to relate FCP iotags to fc_buf addresses */
+			elx_malloc(phba, buf_info);
+			if (buf_info->virt == 0) {
+				ELX_SLI_UNLOCK(phba, iflag);
+				return (0);
+			}
+			pring->fast_lookup = (void *)buf_info->virt;
+			memset((char *)pring->fast_lookup, 0, cnt);
+		}
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (1);
+}
+
+int
+elx_sli_hba_down(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_MBOXQ_t *pmb;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	IOCB_t *icmd = NULL;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+	int i, cnt;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	buf_info = &bufinfo;
+
+/*
+   phba->hba_state = ELX_INIT_START;
+*/
+
+	iflag = phba->iflag;
+	ELX_DRVR_UNLOCK(phba, iflag);
+
+	(psli->sliinit.elx_sli_hba_down_prep) (phba);
+
+	ELX_SLI_LOCK(phba, iflag);
+
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		pring = &psli->ring[i];
+		pring->flag |= ELX_DEFERRED_RING_EVENT;
+		/* Error everything on txq and txcmplq */
+		next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+		pring->txq.q_f = &pring->txq;
+		pring->txq.q_b = &pring->txq;
+		pring->txq.q_cnt = 0;
+		while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+			iocb = next_iocb;
+			next_iocb = next_iocb->q_f;
+			iocb->q_f = 0;
+			if (iocb->iocb_cmpl) {
+				icmd = &iocb->iocb;
+				icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+				icmd->un.ulpWord[4] = IOERR_SLI_DOWN;
+				ELX_SLI_UNLOCK(phba, iflag);
+				(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+				ELX_SLI_LOCK(phba, iflag);
+			} else {
+				elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+			}
+		}
+
+		/* Free any memory allocated for fast lookup */
+		cnt = psli->sliinit.ringinit[i].fast_iotag;
+		if (pring->fast_lookup) {
+			buf_info->size = (cnt * sizeof (ELX_IOCBQ_t *));
+			buf_info->virt = (uint32_t *) pring->fast_lookup;
+			buf_info->phys = 0;
+			buf_info->flags = ELX_MBUF_VIRT;
+			buf_info->dma_handle = 0;
+			elx_free(phba, buf_info);
+			pring->fast_lookup = 0;
+		}
+
+		while ((ELX_IOCBQ_t *) & pring->txcmplq !=
+		       (ELX_IOCBQ_t *) pring->txcmplq.q_f) {
+
+			next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+			pring->txcmplq.q_f = &pring->txcmplq;
+			pring->txcmplq.q_b = &pring->txcmplq;
+			pring->txcmplq.q_cnt = 0;
+			while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+				iocb = next_iocb;
+				next_iocb = next_iocb->q_f;
+				iocb->q_f = 0;
+				if (iocb->iocb_cmpl) {
+					icmd = &iocb->iocb;
+					icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+					icmd->un.ulpWord[4] = IOERR_SLI_DOWN;
+					ELX_SLI_UNLOCK(phba, iflag);
+					(iocb->iocb_cmpl) ((void *)phba, iocb,
+							   iocb);
+					ELX_SLI_LOCK(phba, iflag);
+				} else {
+					elx_mem_put(phba, MEM_IOCB,
+						    (uint8_t *) iocb);
+				}
+			}
+		}
+
+	}
+	/* Return any active mbox cmds */
+	if (psli->mbox_tmo) {
+		elx_clk_can(phba, psli->mbox_tmo);
+		psli->mbox_tmo = 0;
+	}
+	if ((psli->mbox_active)) {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) psli->mbox_active);
+	}
+	psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+	psli->mbox_active = 0;
+
+	/* Return any pending mbox cmds */
+	while ((pmb = elx_mbox_get(phba))) {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	}
+	psli->mboxq.q_first = 0;
+	psli->mboxq.q_last = 0;
+
+	ELX_SLI_UNLOCK(phba, iflag);
+
+	/*
+	 * Adapter can not handle any mbox command.
+	 * Skip borad reset.
+	 */
+	if (phba->hba_state != ELX_HBA_ERROR) {
+		phba->hba_state = ELX_INIT_START;
+		elx_sli_brdreset(phba);
+	}
+
+	ELX_DRVR_LOCK(phba, iflag);
+	return (1);
+}
+
+void
+elx_sli_pcimem_bcopy(uint32_t * src, uint32_t * dest, uint32_t cnt)
+{
+	uint32_t ldata;
+	int i;
+
+	for (i = 0; i < (int)cnt; i += sizeof (uint32_t)) {
+		ldata = *src++;
+		ldata = PCIMEM_LONG(ldata);
+		*dest++ = ldata;
+	}
+}
+
+int
+elx_sli_ringpostbuf_put(elxHBA_t * phba, ELX_SLI_RING_t * pring, DMABUF_t * mp)
+{
+	ELX_SLINK_t *slp;
+	unsigned long iflag;
+
+	ELX_SLI_LOCK(phba, iflag);
+	/* Stick DMABUF_t at end of postbufq so driver can look it up later */
+	slp = &pring->postbufq;
+	if (slp->q_first) {
+		((DMABUF_t *) slp->q_last)->next = mp;
+	} else {
+		slp->q_first = (ELX_SLINK_t *) mp;
+	}
+	slp->q_last = (ELX_SLINK_t *) mp;
+	mp->next = 0;
+	slp->q_cnt++;
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (0);
+}
+
+DMABUF_t *
+elx_sli_ringpostbuf_get(elxHBA_t * phba,
+			ELX_SLI_RING_t * pring, elx_dma_addr_t phys)
+{
+	return (elx_sli_ringpostbuf_search(phba, pring, phys, 1));
+}
+
+DMABUF_t *
+elx_sli_ringpostbuf_search(elxHBA_t * phba,
+			   ELX_SLI_RING_t * pring,
+			   elx_dma_addr_t phys, int unlink)
+{
+	DMABUF_t *mp;
+	DMABUF_t *mpprev;
+	ELX_SLINK_t *slp;
+	unsigned long iflag;
+	int count;
+
+	ELX_SLI_LOCK(phba, iflag);
+	slp = &pring->postbufq;
+
+	/* Search postbufq, from the begining, looking for a match on phys */
+	mpprev = 0;
+	count = 0;
+	mp = (DMABUF_t *) slp->q_first;
+	while (mp) {
+		count++;
+		if (mp->phys == phys) {
+			/* If we find a match, deque it and return it to the caller */
+			if (unlink) {
+				if (mpprev) {
+					mpprev->next = mp->next;
+				} else {
+					slp->q_first = (ELX_SLINK_t *) mp->next;
+				}
+				if (slp->q_last == (ELX_SLINK_t *) mp)
+					slp->q_last = (ELX_SLINK_t *) mpprev;
+
+				slp->q_cnt--;
+
+				elx_pci_dma_sync((void *)phba, (void *)mp, 0,
+						 ELX_DMA_SYNC_FORCPU);
+			}
+			ELX_SLI_UNLOCK(phba, iflag);
+			return (mp);
+		}
+		mpprev = mp;
+		mp = mp->next;
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	/* Cannot find virtual addr for mapped buf on ring <num> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0410,	/* ptr to msg structure */
+		       elx_mes0410,	/* ptr to msg */
+		       elx_msgBlk0410.msgPreambleStr,	/* begin varargs */
+		       pring->ringno, phys, slp->q_first, slp->q_last, slp->q_cnt);	/* end varargs */
+	return (0);
+}
+
+int
+elx_sli_ringtx_put(elxHBA_t * phba, ELX_SLI_RING_t * pring, ELX_IOCBQ_t * piocb)
+{
+	ELX_DLINK_t *dlp;
+	ELX_DLINK_t *dlp_end;
+
+	/* Stick IOCBQ_t at end of txq so driver can issue it later */
+	dlp = &pring->txq;
+	dlp_end = (ELX_DLINK_t *) dlp->q_b;
+	elx_enque(piocb, dlp_end);
+	dlp->q_cnt++;
+	return (0);
+}
+
+int
+elx_sli_ringtxcmpl_put(elxHBA_t * phba,
+		       ELX_SLI_RING_t * pring, ELX_IOCBQ_t * piocb)
+{
+	ELX_DLINK_t *dlp;
+	ELX_DLINK_t *dlp_end;
+	IOCB_t *icmd = NULL;
+	ELX_SLI_t *psli;
+	uint8_t *ptr;
+	uint16_t iotag;
+
+	dlp = &pring->txcmplq;
+	dlp_end = (ELX_DLINK_t *) dlp->q_b;
+
+	elx_enque(((ELX_DLINK_t *) piocb), dlp_end);
+	dlp->q_cnt++;
+	ptr = (uint8_t *) (pring->fast_lookup);
+
+	if (ptr) {
+		/* Setup fast lookup based on iotag for completion */
+		psli = &phba->sli;
+		icmd = &piocb->iocb;
+		iotag = icmd->ulpIoTag;
+		if (iotag < psli->sliinit.ringinit[pring->ringno].fast_iotag) {
+			ptr += (iotag * sizeof (ELX_IOCBQ_t *));
+			*((ELX_IOCBQ_t **) ptr) = piocb;
+		} else {
+
+			/* Cmd ring <ringno> put: iotag <iotag> greater then configured max <fast_iotag> wd0 <icmd> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0316,	/* ptr to msg structure */
+				       elx_mes0316,	/* ptr to msg */
+				       elx_msgBlk0316.msgPreambleStr,	/* begin varargs */
+				       pring->ringno, iotag, psli->sliinit.ringinit[pring->ringno].fast_iotag, *(((uint32_t *) icmd) + 7));	/* end varargs */
+		}
+	}
+	return (0);
+}
+
+ELX_IOCBQ_t *
+elx_sli_ringtx_get(elxHBA_t * phba, ELX_SLI_RING_t * pring)
+{
+	ELX_DLINK_t *dlp;
+	ELX_IOCBQ_t *cmd_iocb;
+	ELX_IOCBQ_t *next_iocb;
+
+	dlp = &pring->txq;
+	cmd_iocb = 0;
+	next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+	if (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+		/* If the first ptr is not equal to the list header, 
+		 * deque the IOCBQ_t and return it.
+		 */
+		cmd_iocb = next_iocb;
+		elx_deque(cmd_iocb);
+		dlp->q_cnt--;
+	}
+	return (cmd_iocb);
+}
+
+ELX_IOCBQ_t *
+elx_sli_ringtxcmpl_get(elxHBA_t * phba,
+		       ELX_SLI_RING_t * pring,
+		       ELX_IOCBQ_t * prspiocb, uint32_t srch)
+{
+	ELX_DLINK_t *dlp;
+	IOCB_t *icmd = NULL;
+	IOCB_t *irsp = NULL;
+	ELX_IOCBQ_t *cmd_iocb;
+	ELX_IOCBQ_t *next_iocb;
+	ELX_SLI_t *psli;
+	uint8_t *ptr;
+	uint16_t iotag;
+
+	dlp = &pring->txcmplq;
+	ptr = (uint8_t *) (pring->fast_lookup);
+
+	if (ptr && (srch == 0)) {
+		/* Use fast lookup based on iotag for completion */
+		psli = &phba->sli;
+		irsp = &prspiocb->iocb;
+		iotag = irsp->ulpIoTag;
+		if (iotag < psli->sliinit.ringinit[pring->ringno].fast_iotag) {
+			ptr += (iotag * sizeof (ELX_IOCBQ_t *));
+			cmd_iocb = *((ELX_IOCBQ_t **) ptr);
+			*((ELX_IOCBQ_t **) ptr) = 0;
+			if (cmd_iocb == NULL) {
+
+				goto search;
+			}
+			elx_deque(cmd_iocb);
+			dlp->q_cnt--;
+		} else {
+
+			/* Rsp ring <ringno> get: iotag <iotag> greater then configured max <fast_iotag> wd0 <irsp> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0317,	/* ptr to msg structure */
+				       elx_mes0317,	/* ptr to msg */
+				       elx_msgBlk0317.msgPreambleStr,	/* begin varargs */
+				       pring->ringno, iotag, psli->sliinit.ringinit[pring->ringno].fast_iotag, *(((uint32_t *) irsp) + 7));	/* end varargs */
+			cmd_iocb = 0;
+			goto search;
+		}
+	} else {
+		cmd_iocb = 0;
+	      search:
+		irsp = &prspiocb->iocb;
+		iotag = irsp->ulpIoTag;
+
+		/* Search through txcmpl from the begining */
+		next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+		while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+			icmd = &next_iocb->iocb;
+			if (iotag == icmd->ulpIoTag) {
+				/* found a match! */
+				cmd_iocb = next_iocb;
+				elx_deque(cmd_iocb);
+				dlp->q_cnt--;
+				break;
+			}
+			next_iocb = next_iocb->q_f;
+		}
+	}
+
+	return (cmd_iocb);
+}
+
+uint32_t
+elx_sli_next_iotag(elxHBA_t * phba, ELX_SLI_RING_t * pring)
+{
+	ELX_RING_INIT_t *pringinit;
+	ELX_SLI_t *psli;
+	uint8_t *ptr;
+	int i;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	ELX_SLI_LOCK(phba, iflag);
+	pringinit = &psli->sliinit.ringinit[pring->ringno];
+	for (i = 0; i < pringinit->iotag_max; i++) {
+		/* Never give an iotag of 0 back */
+		pringinit->iotag_ctr++;
+		if (pringinit->iotag_ctr == pringinit->iotag_max) {
+			pringinit->iotag_ctr = 1;	/* Never use 0 as an iotag */
+		}
+		/* If fast_iotaging is used, we can ensure that the iotag 
+		 * we give back is not already in use.
+		 */
+		if (pring->fast_lookup) {
+			ptr = (uint8_t *) (pring->fast_lookup);
+			ptr += (pringinit->iotag_ctr * sizeof (ELX_IOCBQ_t *));
+			if (*((ELX_IOCBQ_t **) ptr) != 0)
+				continue;
+		}
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (pringinit->iotag_ctr);
+	}
+
+	/* Outstanding I/O count for ring <ringno> is at max <fast_iotag> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0318,	/* ptr to msg structure */
+		       elx_mes0318,	/* ptr to msg */
+		       elx_msgBlk0318.msgPreambleStr,	/* begin varargs */
+		       pring->ringno, psli->sliinit.ringinit[pring->ringno].fast_iotag);	/* end varargs */
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (0);
+}
+
+void
+elx_sli_abort_cmpl(elxHBA_t * phba,
+		   ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	elx_mem_put(phba, MEM_IOCB, (uint8_t *) cmdiocb);
+	return;
+}
+
+void
+elx_sli_abort_elsreq_cmpl(elxHBA_t * phba,
+			  ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	/* Free the resources associated with the ELS_REQUEST64 IOCB the driver
+	 * just aborted.
+	 * In this case, context2  = cmd,  context2->next = rsp, context3 = bpl 
+	 */
+	if (cmdiocb->context2) {
+		/* Free the response IOCB before completing the abort command.  */
+		if (((DMABUF_t *) (cmdiocb->context2))->next) {
+			elx_mem_put(phba, MEM_BUF,
+				    (uint8_t
+				     *) (((DMABUF_t *) (cmdiocb->context2))->
+					 next));
+		}
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) (cmdiocb->context2));
+	}
+
+	if (cmdiocb->context3) {
+		elx_mem_put(phba, MEM_BPL, (uint8_t *) (cmdiocb->context3));
+	}
+	elx_mem_put(phba, MEM_IOCB, (uint8_t *) cmdiocb);
+	return;
+}
+
+int
+elx_sli_abort_iocb(elxHBA_t * phba, ELX_SLI_RING_t * pring, ELX_IOCBQ_t * piocb)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *abtsiocbp;
+	uint8_t *ptr;
+	IOCB_t *abort_cmd = NULL, *cmd = NULL;
+	unsigned long iflag;
+	uint16_t iotag;
+
+	psli = &phba->sli;
+	ELX_SLI_LOCK(phba, iflag);
+
+	cmd = &piocb->iocb;
+
+	if (piocb->abort_count == 2) {
+		/* Clear fast_lookup entry, if any */
+		iotag = cmd->ulpIoTag;
+		ptr = (uint8_t *) (pring->fast_lookup);
+		if (ptr
+		    && (iotag <
+			psli->sliinit.ringinit[pring->ringno].fast_iotag)) {
+			ELX_IOCBQ_t *cmd_iocb;
+			ptr += (iotag * sizeof (ELX_IOCBQ_t *));
+			cmd_iocb = *((ELX_IOCBQ_t **) ptr);
+			*((ELX_IOCBQ_t **) ptr) = 0;
+		}
+
+		/* Dequeue and complete with error */
+		elx_deque(piocb);
+		pring->txcmplq.q_cnt--;
+
+		if (piocb->iocb_cmpl) {
+			cmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+			cmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+			ELX_SLI_UNLOCK(phba, iflag);
+			(piocb->iocb_cmpl) ((void *)phba, piocb, piocb);
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) piocb);
+		}
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (1);
+	}
+
+	/* issue ABTS for this IOCB based on iotag */
+
+	if ((abtsiocbp = (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB | MEM_PRI))
+	    == NULL) {
+		ELX_SLI_UNLOCK(phba, iflag);
+		return (0);
+	}
+
+	memset((void *)abtsiocbp, 0, sizeof (ELX_IOCBQ_t));
+	abort_cmd = &abtsiocbp->iocb;
+
+	abort_cmd->un.acxri.abortType = ABORT_TYPE_ABTS;
+	abort_cmd->un.acxri.abortContextTag = cmd->ulpContext;
+	abort_cmd->un.acxri.abortIoTag = cmd->ulpIoTag;
+
+	abort_cmd->ulpLe = 1;
+	abort_cmd->ulpClass = cmd->ulpClass;
+	if (phba->hba_state >= ELX_LINK_UP) {
+		abort_cmd->ulpCommand = CMD_ABORT_XRI_CN;
+	} else {
+		abort_cmd->ulpCommand = CMD_CLOSE_XRI_CN;
+	}
+	abort_cmd->ulpOwner = OWN_CHIP;
+
+	ELX_SLI_UNLOCK(phba, iflag);
+	/* set up an iotag  */
+	abort_cmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+	if (elx_sli_issue_iocb(phba, pring, abtsiocbp, SLI_IOCB_USE_TXQ)
+	    == IOCB_ERROR) {
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+		return (0);
+	}
+
+	piocb->abort_count++;
+	return (1);
+}
+
+int
+elx_sli_abort_iocb_ring(elxHBA_t * phba, ELX_SLI_RING_t * pring, uint32_t flag)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	ELX_IOCBQ_t *abtsiocbp;
+	uint8_t *ptr;
+	IOCB_t *icmd = NULL, *cmd = NULL;
+	unsigned long iflag;
+	int errcnt;
+	uint16_t iotag;
+
+	psli = &phba->sli;
+	errcnt = 0;
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Error everything on txq and txcmplq 
+	 * First do the txq.
+	 */
+	next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+	pring->txq.q_f = &pring->txq;
+	pring->txq.q_b = &pring->txq;
+	pring->txq.q_cnt = 0;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		iocb->q_f = 0;
+		if (iocb->iocb_cmpl) {
+			icmd = &iocb->iocb;
+			icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+			icmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+			ELX_SLI_UNLOCK(phba, iflag);
+			(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+		}
+	}
+
+	/* Next issue ABTS for everything on the txcmplq */
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	if (flag == ELX_SLI_ABORT_IMED) {
+		pring->txcmplq.q_f = &pring->txcmplq;
+		pring->txcmplq.q_b = &pring->txcmplq;
+		pring->txcmplq.q_cnt = 0;
+	}
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+
+		if (flag == ELX_SLI_ABORT_IMED) {
+			/* Imediate abort of IOCB, deque and call compl */
+			iocb->q_f = 0;
+		}
+
+		/* issue ABTS for this IOCB based on iotag */
+
+		if ((abtsiocbp = (ELX_IOCBQ_t *) elx_mem_get(phba,
+							     MEM_IOCB |
+							     MEM_PRI)) ==
+		    NULL) {
+			errcnt++;
+			continue;
+		}
+		memset((void *)abtsiocbp, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &abtsiocbp->iocb;
+
+		icmd->un.acxri.abortType = ABORT_TYPE_ABTS;
+		icmd->un.acxri.abortContextTag = cmd->ulpContext;
+		icmd->un.acxri.abortIoTag = cmd->ulpIoTag;
+
+		icmd->ulpLe = 1;
+		icmd->ulpClass = cmd->ulpClass;
+		if (phba->hba_state >= ELX_LINK_UP) {
+			icmd->ulpCommand = CMD_ABORT_XRI_CN;
+		} else {
+			icmd->ulpCommand = CMD_CLOSE_XRI_CN;
+		}
+		icmd->ulpOwner = OWN_CHIP;
+
+		if (flag == ELX_SLI_ABORT_IMED) {
+			/* Clear fast_lookup entry, if any */
+			iotag = cmd->ulpIoTag;
+			ptr = (uint8_t *) (pring->fast_lookup);
+			if (ptr
+			    && (iotag <
+				psli->sliinit.ringinit[pring->ringno].
+				fast_iotag)) {
+				ptr += (iotag * sizeof (ELX_IOCBQ_t *));
+				*((ELX_IOCBQ_t **) ptr) = 0;
+			}
+			/* Imediate abort of IOCB, deque and call compl */
+			if (iocb->iocb_cmpl) {
+				cmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+				cmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+				ELX_SLI_UNLOCK(phba, iflag);
+				(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+				ELX_SLI_LOCK(phba, iflag);
+			} else {
+				elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+			}
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+		} else {
+			ELX_SLI_UNLOCK(phba, iflag);
+			/* set up an iotag  */
+			icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+			if (elx_sli_issue_iocb
+			    (phba, pring, abtsiocbp, SLI_IOCB_USE_TXQ)
+			    == IOCB_ERROR) {
+				ELX_SLI_LOCK(phba, iflag);
+				elx_mem_put(phba, MEM_IOCB,
+					    (uint8_t *) abtsiocbp);
+				errcnt++;
+				continue;
+			}
+			ELX_SLI_LOCK(phba, iflag);
+		}
+		/* The rsp ring completion will remove IOCB from txcmplq when 
+		 * abort is read by HBA.
+		 */
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (errcnt);
+}
+
+int
+elx_sli_issue_abort_iotag32(elxHBA_t * phba,
+			    ELX_SLI_RING_t * pring, ELX_IOCBQ_t * cmdiocb)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *abtsiocbp;
+	IOCB_t *icmd = NULL;
+	IOCB_t *iabt = NULL;
+	uint32_t iotag32;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* issue ABTS for this IOCB based on iotag */
+
+	if ((abtsiocbp = (ELX_IOCBQ_t *) elx_mem_get(phba,
+						     MEM_IOCB | MEM_PRI)) ==
+	    NULL) {
+		return (0);
+	}
+	memset((void *)abtsiocbp, 0, sizeof (ELX_IOCBQ_t));
+	iabt = &abtsiocbp->iocb;
+
+	icmd = &cmdiocb->iocb;
+	switch (icmd->ulpCommand) {
+	case CMD_ELS_REQUEST64_CR:
+		iotag32 = icmd->un.elsreq64.bdl.ulpIoTag32;
+		/* Even though we abort the ELS command, the firmware may access the BPL or other resources
+		 * before it processes our ABORT_MXRI64. Thus we must delay reusing the cmdiocb resources till
+		 * the actual abort request completes.
+		 */
+		abtsiocbp->context1 = (void *)((unsigned long)icmd->ulpCommand);
+		abtsiocbp->context2 = cmdiocb->context2;
+		abtsiocbp->context3 = cmdiocb->context3;
+		cmdiocb->context2 = 0;
+		cmdiocb->context3 = 0;
+		abtsiocbp->iocb_cmpl = elx_sli_abort_elsreq_cmpl;
+		break;
+	default:
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+		return (0);
+	}
+
+	iabt->un.amxri.abortType = ABORT_TYPE_ABTS;
+	iabt->un.amxri.iotag32 = iotag32;
+
+	iabt->ulpLe = 1;
+	iabt->ulpClass = CLASS3;
+	iabt->ulpCommand = CMD_ABORT_MXRI64_CN;
+	iabt->ulpOwner = OWN_CHIP;
+
+	ELX_SLI_UNLOCK(phba, iflag);
+	/* set up an iotag  */
+	iabt->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+	if (elx_sli_issue_iocb(phba, pring, abtsiocbp, SLI_IOCB_USE_TXQ)
+	    == IOCB_ERROR) {
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+		return (0);
+	}
+
+	return (1);
+}
+
+int
+elx_sli_abort_iocb_ctx(elxHBA_t * phba, ELX_SLI_RING_t * pring, uint32_t ctx)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	ELX_IOCBQ_t *abtsiocbp;
+	IOCB_t *icmd = NULL, *cmd = NULL;
+	unsigned long iflag;
+	int errcnt;
+
+	psli = &phba->sli;
+	errcnt = 0;
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Error matching iocb on txq or txcmplq 
+	 * First check the txq.
+	 */
+	next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+		if (cmd->ulpContext != ctx) {
+			continue;
+		}
+
+		elx_deque(iocb);
+		pring->txq.q_cnt--;
+		if (iocb->iocb_cmpl) {
+			icmd = &iocb->iocb;
+			icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+			icmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+			ELX_SLI_UNLOCK(phba, iflag);
+			(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+		}
+	}
+
+	/* Next check the txcmplq */
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+		if (cmd->ulpContext != ctx) {
+			continue;
+		}
+
+		/* issue ABTS for this IOCB based on iotag */
+
+		if ((abtsiocbp = (ELX_IOCBQ_t *) elx_mem_get(phba,
+							     MEM_IOCB |
+							     MEM_PRI)) ==
+		    NULL) {
+			errcnt++;
+			continue;
+		}
+		memset((void *)abtsiocbp, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &abtsiocbp->iocb;
+
+		icmd->un.acxri.abortType = ABORT_TYPE_ABTS;
+		icmd->un.acxri.abortContextTag = cmd->ulpContext;
+		icmd->un.acxri.abortIoTag = cmd->ulpIoTag;
+
+		icmd->ulpLe = 1;
+		icmd->ulpClass = cmd->ulpClass;
+		if (phba->hba_state >= ELX_LINK_UP) {
+			icmd->ulpCommand = CMD_ABORT_XRI_CN;
+		} else {
+			icmd->ulpCommand = CMD_CLOSE_XRI_CN;
+		}
+		icmd->ulpOwner = OWN_CHIP;
+
+		ELX_SLI_UNLOCK(phba, iflag);
+		/* set up an iotag  */
+		icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+		if (elx_sli_issue_iocb(phba, pring, abtsiocbp, SLI_IOCB_USE_TXQ)
+		    == IOCB_ERROR) {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+			errcnt++;
+			ELX_SLI_LOCK(phba, iflag);
+			continue;
+		}
+		/* The rsp ring completion will remove IOCB from txcmplq when 
+		 * abort is read by HBA.
+		 */
+		ELX_SLI_LOCK(phba, iflag);
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (errcnt);
+}
+
+int
+elx_sli_abort_iocb_context1(elxHBA_t * phba, ELX_SLI_RING_t * pring, void *ctx)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	ELX_IOCBQ_t *abtsiocbp;
+	IOCB_t *icmd = NULL, *cmd = NULL;
+	unsigned long iflag;
+	int errcnt;
+
+	psli = &phba->sli;
+	errcnt = 0;
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Error matching iocb on txq or txcmplq 
+	 * First check the txq.
+	 */
+	next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+		if (iocb->context1 != ctx) {
+			continue;
+		}
+
+		elx_deque(iocb);
+		pring->txq.q_cnt--;
+		if (iocb->iocb_cmpl) {
+			icmd = &iocb->iocb;
+			icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+			icmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+			ELX_SLI_UNLOCK(phba, iflag);
+			(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+		}
+	}
+
+	/* Next check the txcmplq */
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+		if (iocb->context1 != ctx) {
+			continue;
+		}
+
+		/* issue ABTS for this IOCB based on iotag */
+
+		if ((abtsiocbp = (ELX_IOCBQ_t *) elx_mem_get(phba,
+							     MEM_IOCB |
+							     MEM_PRI)) ==
+		    NULL) {
+			errcnt++;
+			continue;
+		}
+		memset((void *)abtsiocbp, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &abtsiocbp->iocb;
+
+		icmd->un.acxri.abortType = ABORT_TYPE_ABTS;
+		icmd->un.acxri.abortContextTag = cmd->ulpContext;
+		icmd->un.acxri.abortIoTag = cmd->ulpIoTag;
+
+		icmd->ulpLe = 1;
+		icmd->ulpClass = cmd->ulpClass;
+		if (phba->hba_state >= ELX_LINK_UP) {
+			icmd->ulpCommand = CMD_ABORT_XRI_CN;
+		} else {
+			icmd->ulpCommand = CMD_CLOSE_XRI_CN;
+		}
+		icmd->ulpOwner = OWN_CHIP;
+
+		ELX_SLI_UNLOCK(phba, iflag);
+		/* set up an iotag  */
+		icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+		if (elx_sli_issue_iocb(phba, pring, abtsiocbp, SLI_IOCB_USE_TXQ)
+		    == IOCB_ERROR) {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+			errcnt++;
+			ELX_SLI_LOCK(phba, iflag);
+			continue;
+		}
+		/* The rsp ring completion will remove IOCB from txcmplq when 
+		 * abort is read by HBA.
+		 */
+		ELX_SLI_LOCK(phba, iflag);
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (errcnt);
+}
+
+int
+elx_sli_abort_iocb_lun(elxHBA_t * phba,
+		       ELX_SLI_RING_t * pring,
+		       uint16_t scsi_target, uint64_t scsi_lun)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	ELX_IOCBQ_t *abtsiocbp;
+	IOCB_t *icmd = NULL, *cmd = NULL;
+	ELX_SCSI_BUF_t *elx_cmd;
+	unsigned long iflag;
+	int errcnt;
+
+	psli = &phba->sli;
+	errcnt = 0;
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Error matching iocb on txq or txcmplq 
+	 * First check the txq.
+	 */
+	next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+
+		/* Must be a FCP command */
+		if ((cmd->ulpCommand != CMD_FCP_ICMND64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IWRITE64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IREAD64_CR)) {
+			continue;
+		}
+
+		/* context1 MUST be a ELX_SCSI_BUF_t */
+		elx_cmd = (ELX_SCSI_BUF_t *) (iocb->context1);
+		if ((elx_cmd == 0) ||
+		    (elx_cmd->scsi_target != scsi_target) ||
+		    (elx_cmd->scsi_lun != scsi_lun)) {
+			continue;
+		}
+
+		elx_deque(iocb);
+		pring->txq.q_cnt--;
+		if (iocb->iocb_cmpl) {
+			icmd = &iocb->iocb;
+			icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+			icmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+			ELX_SLI_UNLOCK(phba, iflag);
+			(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+		}
+	}
+
+	/* Next check the txcmplq */
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+
+		/* Must be a FCP command */
+		if ((cmd->ulpCommand != CMD_FCP_ICMND64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IWRITE64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IREAD64_CR)) {
+			continue;
+		}
+
+		/* context1 MUST be a ELX_SCSI_BUF_t */
+		elx_cmd = (ELX_SCSI_BUF_t *) (iocb->context1);
+		if ((elx_cmd == 0) ||
+		    (elx_cmd->scsi_target != scsi_target) ||
+		    (elx_cmd->scsi_lun != scsi_lun)) {
+			continue;
+		}
+
+		/* issue ABTS for this IOCB based on iotag */
+
+		if ((abtsiocbp = (ELX_IOCBQ_t *) elx_mem_get(phba,
+							     MEM_IOCB |
+							     MEM_PRI)) ==
+		    NULL) {
+			errcnt++;
+			continue;
+		}
+		memset((void *)abtsiocbp, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &abtsiocbp->iocb;
+
+		icmd->un.acxri.abortType = ABORT_TYPE_ABTS;
+		icmd->un.acxri.abortContextTag = cmd->ulpContext;
+		icmd->un.acxri.abortIoTag = cmd->ulpIoTag;
+
+		icmd->ulpLe = 1;
+		icmd->ulpClass = cmd->ulpClass;
+		if (phba->hba_state >= ELX_LINK_UP) {
+			icmd->ulpCommand = CMD_ABORT_XRI_CN;
+		} else {
+			icmd->ulpCommand = CMD_CLOSE_XRI_CN;
+		}
+		icmd->ulpOwner = OWN_CHIP;
+
+		ELX_SLI_UNLOCK(phba, iflag);
+		/* set up an iotag  */
+		icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+		if (elx_sli_issue_iocb(phba, pring, abtsiocbp, SLI_IOCB_USE_TXQ)
+		    == IOCB_ERROR) {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+			errcnt++;
+			ELX_SLI_LOCK(phba, iflag);
+			continue;
+		}
+		/* The rsp ring completion will remove IOCB from txcmplq when 
+		 * abort is read by HBA.
+		 */
+		ELX_SLI_LOCK(phba, iflag);
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (errcnt);
+}
+
+int
+elx_sli_abort_iocb_tgt(elxHBA_t * phba,
+		       ELX_SLI_RING_t * pring, uint16_t scsi_target)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	ELX_IOCBQ_t *abtsiocbp;
+	IOCB_t *icmd = NULL, *cmd = NULL;
+	ELX_SCSI_BUF_t *elx_cmd;
+	unsigned long iflag;
+	int errcnt;
+
+	psli = &phba->sli;
+	errcnt = 0;
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Error matching iocb on txq or txcmplq 
+	 * First check the txq.
+	 */
+	next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+
+		/* Must be a FCP command */
+		if ((cmd->ulpCommand != CMD_FCP_ICMND64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IWRITE64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IREAD64_CR)) {
+			continue;
+		}
+
+		/* context1 MUST be a ELX_SCSI_BUF_t */
+		elx_cmd = (ELX_SCSI_BUF_t *) (iocb->context1);
+		if ((elx_cmd == 0) || (elx_cmd->scsi_target != scsi_target)) {
+			continue;
+		}
+
+		elx_deque(iocb);
+		pring->txq.q_cnt--;
+		if (iocb->iocb_cmpl) {
+			icmd = &iocb->iocb;
+			icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+			icmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+			ELX_SLI_UNLOCK(phba, iflag);
+			(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+		}
+	}
+
+	/* Next check the txcmplq */
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+
+		/* Must be a FCP command */
+		if ((cmd->ulpCommand != CMD_FCP_ICMND64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IWRITE64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IREAD64_CR)) {
+			continue;
+		}
+
+		/* context1 MUST be a ELX_SCSI_BUF_t */
+		elx_cmd = (ELX_SCSI_BUF_t *) (iocb->context1);
+		if ((elx_cmd == 0) || (elx_cmd->scsi_target != scsi_target)) {
+			continue;
+		}
+
+		/* issue ABTS for this IOCB based on iotag */
+
+		if ((abtsiocbp = (ELX_IOCBQ_t *) elx_mem_get(phba,
+							     MEM_IOCB |
+							     MEM_PRI)) ==
+		    NULL) {
+			errcnt++;
+			continue;
+		}
+		memset((void *)abtsiocbp, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &abtsiocbp->iocb;
+
+		icmd->un.acxri.abortType = ABORT_TYPE_ABTS;
+		icmd->un.acxri.abortContextTag = cmd->ulpContext;
+		icmd->un.acxri.abortIoTag = cmd->ulpIoTag;
+
+		icmd->ulpLe = 1;
+		icmd->ulpClass = cmd->ulpClass;
+		if (phba->hba_state >= ELX_LINK_UP) {
+			icmd->ulpCommand = CMD_ABORT_XRI_CN;
+		} else {
+			icmd->ulpCommand = CMD_CLOSE_XRI_CN;
+		}
+		icmd->ulpOwner = OWN_CHIP;
+
+		ELX_SLI_UNLOCK(phba, iflag);
+		/* set up an iotag  */
+		icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+		if (elx_sli_issue_iocb(phba, pring, abtsiocbp, SLI_IOCB_USE_TXQ)
+		    == IOCB_ERROR) {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+			errcnt++;
+			ELX_SLI_LOCK(phba, iflag);
+			continue;
+		}
+		/* The rsp ring completion will remove IOCB from txcmplq when 
+		 * abort is read by HBA.
+		 */
+		ELX_SLI_LOCK(phba, iflag);
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (errcnt);
+}
+
+int
+elx_sli_abort_iocb_hba(elxHBA_t * phba, ELX_SLI_RING_t * pring)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	ELX_IOCBQ_t *abtsiocbp;
+	IOCB_t *icmd = NULL, *cmd = NULL;
+	ELX_SCSI_BUF_t *elx_cmd;
+	unsigned long iflag;
+	int errcnt;
+
+	psli = &phba->sli;
+	errcnt = 0;
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Error matching iocb on txq or txcmplq 
+	 * First check the txq.
+	 */
+	next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+
+		/* Must be a FCP command */
+		if ((cmd->ulpCommand != CMD_FCP_ICMND64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IWRITE64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IREAD64_CR)) {
+			continue;
+		}
+
+		/* context1 MUST be a ELX_SCSI_BUF_t */
+		elx_cmd = (ELX_SCSI_BUF_t *) (iocb->context1);
+		if (elx_cmd == 0) {
+			continue;
+		}
+
+		elx_deque(iocb);
+		pring->txq.q_cnt--;
+		if (iocb->iocb_cmpl) {
+			icmd = &iocb->iocb;
+			icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+			icmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+			ELX_SLI_UNLOCK(phba, iflag);
+			(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+			ELX_SLI_LOCK(phba, iflag);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+		}
+	}
+
+	/* Next check the txcmplq */
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &iocb->iocb;
+
+		/* Must be a FCP command */
+		if ((cmd->ulpCommand != CMD_FCP_ICMND64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IWRITE64_CR) &&
+		    (cmd->ulpCommand != CMD_FCP_IREAD64_CR)) {
+			continue;
+		}
+
+		/* context1 MUST be a ELX_SCSI_BUF_t */
+		elx_cmd = (ELX_SCSI_BUF_t *) (iocb->context1);
+		if (elx_cmd == 0) {
+			continue;
+		}
+
+		/* issue ABTS for this IOCB based on iotag */
+
+		if ((abtsiocbp = (ELX_IOCBQ_t *) elx_mem_get(phba,
+							     MEM_IOCB |
+							     MEM_PRI)) ==
+		    NULL) {
+			errcnt++;
+			continue;
+		}
+		memset((void *)abtsiocbp, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &abtsiocbp->iocb;
+
+		icmd->un.acxri.abortType = ABORT_TYPE_ABTS;
+		icmd->un.acxri.abortContextTag = cmd->ulpContext;
+		icmd->un.acxri.abortIoTag = cmd->ulpIoTag;
+
+		icmd->ulpLe = 1;
+		icmd->ulpClass = cmd->ulpClass;
+		if (phba->hba_state >= ELX_LINK_UP) {
+			icmd->ulpCommand = CMD_ABORT_XRI_CN;
+		} else {
+			icmd->ulpCommand = CMD_CLOSE_XRI_CN;
+		}
+		icmd->ulpOwner = OWN_CHIP;
+
+		ELX_SLI_UNLOCK(phba, iflag);
+		/* set up an iotag  */
+		icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+		if (elx_sli_issue_iocb(phba, pring, abtsiocbp, SLI_IOCB_USE_TXQ)
+		    == IOCB_ERROR) {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) abtsiocbp);
+			errcnt++;
+			ELX_SLI_LOCK(phba, iflag);
+			continue;
+		}
+		/* The rsp ring completion will remove IOCB from txcmplq when 
+		 * abort is read by HBA.
+		 */
+		ELX_SLI_LOCK(phba, iflag);
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (errcnt);
+}
+
+/****************************************/
+/* Print Format Declarations Start Here */
+/****************************************/
+#define  LENGTH_LINE 71
+#define  MAX_IO_SIZE 32 * 2	/* iobuf cache size */
+#define  MAX_TBUFF   18 * 2	/* temp buffer size */
+
+typedef union {			/* Pointer to table of arguments. */
+	ulong *ip;
+	ulong *lip;
+	ulong *uip;
+	ulong *luip;
+	ulong **luipp;
+	uint8_t *cp;
+	uint8_t **csp;
+} ARGLIST;
+
+typedef struct {
+	uint8_t *string;
+	int index;
+	int count;
+	uint8_t buf[MAX_IO_SIZE + MAX_TBUFF];	/* extra room to convert numbers */
+} PRINTBLK;
+
+/*
+ * ASCII string declarations
+ */
+static uint8_t dig[] = { "0123456789ABCDEF" };
+static uint8_t ds_disabled[] = "disabled";
+static uint8_t ds_enabled[] = "enabled";
+static uint8_t ds_none[] = "none";
+static uint8_t ds_null_string[] = "";
+static uint8_t ds_unknown[] = "unknown";
+
+extern elxDRVR_t elxDRVR;
+
+uint32_t elx_dbg_flag = 0;
+
+/*
+ * Function Declarations: Local
+ */
+int elx_add_char(PRINTBLK * io, uint8_t ch);
+int elx_add_string(PRINTBLK * io, uint8_t * string);
+int elx_sprintf_fargs(uint8_t * string, void *control, va_list args);
+int elx_expanded_len(uint8_t * sp);
+void elx_print_string(PRINTBLK * io);
+
+int
+elx_expanded_len(uint8_t * sp)
+{
+	register int i;
+	uint8_t c;
+
+	i = 0;
+	while ((c = *sp++) != 0) {
+		if (c < 0x1b) {
+			if ((c == '\r') || (c == '\n'))
+				/* stop at cr or lf */
+				break;
+
+			/* double it */
+			i++;
+		}
+		i++;
+	}
+	return (i);
+}
+
+int
+elx_str_itos(int val, uint8_t * cp, int base)
+{
+	uint8_t tempc[16];
+	uint8_t *tcp;
+	int n = 0;		/* number of characters in result */
+	ulong uval;		/* unsigned value */
+
+	*(tcp = (tempc + 15)) = 0;
+	if (base < 0) {
+		/* needs signed conversion */
+		base = -base;
+		if (val < 0) {
+			n = 1;
+			val = -val;
+		}
+		do {
+			*(--tcp) = dig[(int)(val % base)];
+			val /= base;
+		} while (val);
+	} else {
+		uval = val;
+		do {
+			*(--tcp) = dig[(int)(uval % base)];
+			uval /= base;
+		} while (uval);
+	}
+	if (n)
+		*(--tcp) = '-';
+	n = (int)((long)&tempc[15] - (long)tcp);
+	memcpy(cp, tcp, n + 1);	/* from, to, cnt */
+	return (n);
+}
+
+int
+elx_add_char(PRINTBLK * io, uint8_t ch)
+{
+/* 
+ * Define the following definitions per Operating System type.
+ */
+#define OS_TYPE_UNIX
+
+	int index;
+
+	if (ch < 0x1b) {
+		switch (ch) {
+		case 0xd:	/* carriage return */
+			io->count = -1;	/* will be incremented to 0, below */
+			break;
+		case 0x8:	/* back space */
+			io->count -= 2;	/* will be incremented to 1 less, below */
+			break;
+		case 0xa:	/* line feed */
+#ifndef OS_TYPE_UNIX
+			elx_add_char(io, '\r');
+#endif
+		case 0x7:	/* bell */
+		case 0x9:	/* hortizontal tab */
+		case 0xe:	/* shift out */
+		case 0xf:	/* shift in */
+			io->count--;	/* will be incremented to same, below */
+			break;
+		default:
+			elx_add_char(io, '^');
+			ch |= 0x40;
+			break;
+		}
+	}
+	io->count++;
+	if (io->string != NULL) {
+		*io->string = ch;
+		*++io->string = '\0';
+		return (0);
+	}
+
+	index = io->index;
+	if (index < (MAX_IO_SIZE + MAX_TBUFF - 2)) {
+		io->buf[index] = ch;
+		io->buf[++index] = '\0';
+	}
+	return (++io->index);
+}
+
+int
+elx_add_string(PRINTBLK * io, uint8_t * string)
+{
+	union {
+		uint8_t *cp;
+		uint8_t byt[8];
+	} utmp;
+
+	if (io->string != NULL) {
+		io->string = (uint8_t *) elx_str_cpy((char *)io->string, (char *)string);	/*dst,src */
+		return (0);
+	}
+	utmp.cp = (uint8_t *) elx_str_cpy((char *)&io->buf[io->index], (char *)string);	/* dst, src */
+	return (io->index = utmp.cp - io->buf);	/* Calulate and return str index */
+}
+
+void
+elx_print_string(PRINTBLK * io)
+{
+	io->index = 0;
+	elx_print((char *)&io->buf[0], 0, 0);
+}
+
+int
+elx_fmtout(uint8_t * ostr,	/* Output buffer, or NULL if temp */
+	   uint8_t * control,	/* Control string */
+	   va_list inarg)
+{				/* Argument list */
+	short temp;		/* Output channel number if string NULL. */
+	int leftadj;		/* Negative pararameter width specified. */
+	int longflag;		/* Integer is long. */
+	int box;		/* not from body */
+	int chr;		/* control string character */
+	uint8_t padchar;	/* Pad character, typically space. */
+	int width;		/* Width of subfield. */
+	int length;		/* Length of subfield. */
+	ARGLIST arg;
+	PRINTBLK *io;
+
+	union {			/* Accumulate parameter value here. */
+		uint16_t tlong;
+		uint16_t tulong;
+		long ltlong;
+		ulong ltulong;
+		uint8_t str[4];
+		uint16_t twds[2];
+	} lw;
+
+	union {			/* Used by case %c */
+		int intchar;
+		uint8_t chr[4];
+	} ichar;
+
+	io = elx_kmem_alloc(sizeof (PRINTBLK), ELX_MEM_NDELAY);
+	if (io == NULL) {
+
+		elx_print
+		    ("lpfc: Not enough mem available for logging messages.\n",
+		     0, 0);
+		return -1;
+	}
+
+	arg.uip = (ulong *) inarg;
+	io->index = 0;
+	io->count = 0;
+	box = 0;
+
+	if ((io->string = ostr) != (uint8_t *) NULL)
+		*ostr = 0;	/* initialize output string to null */
+	control--;
+
+	while ((length = *++control) != 0) {	/* while more in control string */
+		if (length != '%') {	/* format control */
+			/* no control string, copy to output */
+			if ((length == '\n') && box) {
+				elx_print((char *)&io->buf[0], 0, 0);
+				continue;
+			}
+			if (elx_add_char(io, (uint8_t) length) >= MAX_IO_SIZE)
+				elx_print_string(io);	/* write it */
+			continue;
+		}
+		leftadj = (*++control == '-');
+		if (leftadj)
+			++control;
+		padchar = ' ';
+		width = 0;
+		if ((uint16_t) (length = (*control - '0')) <= 9) {
+			if (length == 0)
+				padchar = '0';
+			width = length;
+			while ((uint16_t) (length = (*++control - '0')) <= 9)
+				width = width * 10 + length;
+		}
+		longflag = (*control == 'l');
+		if (longflag)
+			++control;
+
+		chr = (int)(*control);
+		if (chr != 'E') {
+			chr |= 0x20;
+		}
+
+		switch (chr) {	/* switch on control (case insensitive except for 'E') */
+		case 'a':
+			longflag = 1;
+			temp = 16;
+			padchar = '0';
+			length = width = 8;
+			goto nosign;
+		case 'b':
+			temp = 2;
+			goto nosign;
+		case 'o':
+			temp = 8;
+			goto nosign;
+		case 'u':
+			temp = 10;
+			goto nosign;
+		case 'x':
+			temp = 16;
+			goto nosign;
+
+			/* Ethernet address on recursive call */
+
+		case 'e':
+			ostr = (uint8_t *) va_arg(inarg, caddr_t);
+			if ((chr == 'e') &&
+			    ((*(long *)ostr) == (long)NULL) &&
+			    ((*(uint16_t *) & ostr[4]) == (uint16_t) 0)) {
+				ostr = (uint8_t *) ds_unknown;
+				length = 7;
+				break;
+			}
+			temp = -1;
+			length = MAX_IO_SIZE - 1;
+			elx_str_cpy((char *)&io->buf[MAX_IO_SIZE], "00-00-00-00-00-00");	/* dst, src */
+			do {
+				elx_str_itos((long)(ostr[++temp] + 256), lw.str,
+					     16);
+				io->buf[++length] = lw.str[1];
+				io->buf[++length] = lw.str[2];
+			} while (++length < MAX_IO_SIZE + 17);
+			ostr = &io->buf[MAX_IO_SIZE];
+			length = 17;
+			break;
+
+			/* FC Portname or FC Nodename address on recursive call */
+
+		case 'E':
+			ostr = (uint8_t *) va_arg(inarg, caddr_t);
+			if ((chr == 'E') &&
+			    ((*(long *)ostr) == (long)NULL) &&
+			    ((*(long *)&ostr[4]) == (long)NULL)) {
+				ostr = (uint8_t *) ds_unknown;
+				length = 7;
+				break;
+			}
+			temp = -1;
+			length = MAX_IO_SIZE - 1;
+			elx_str_cpy((char *)&io->buf[MAX_IO_SIZE], "00-00-00-00-00-00-00-00");	/* dst, src */
+			do {
+				elx_str_itos((long)(ostr[++temp] + 256), lw.str,
+					     16);
+				io->buf[++length] = lw.str[1];
+				io->buf[++length] = lw.str[2];
+			} while (++length < MAX_IO_SIZE + 23);
+			ostr = &io->buf[MAX_IO_SIZE];
+			length = 23;
+			break;
+
+		case 'f':	/* flags */
+			ostr = (uint8_t *) ds_disabled;
+			length = 8;
+			if (va_arg(inarg, caddr_t) != 0) {	/* test value */
+				ostr = (uint8_t *) ds_enabled;
+				length = 7;
+			}
+			if (chr == 'F') {
+				length -= 7;
+				ostr = (uint8_t *) "-";
+			}
+			break;
+
+			/* IP address string use recursive call */
+
+		case 'i':
+			ostr = (uint8_t *) va_arg(inarg, caddr_t);
+			if ((chr == 'i') && *(long *)ostr == (long)NULL)
+				goto putnone;
+			temp = 0;
+			length = MAX_IO_SIZE;
+			do {
+				length +=
+				    elx_str_itos((long)ostr[temp],
+						 &io->buf[length], 10);
+				if (++temp >= 4)
+					break;
+				io->buf[length] = '.';
+				length++;
+			} while (1);
+			ostr = &io->buf[MAX_IO_SIZE];
+			length -= MAX_IO_SIZE;
+			break;
+
+		case 'y':	/* flags */
+			if (va_arg(inarg, caddr_t) != 0) {	/* test value */
+				ostr = (uint8_t *) "yes";
+				length = 3;
+			} else {
+				ostr = (uint8_t *) "no";
+				length = 2;
+			}
+			break;
+
+		case 'c':
+			if (chr == 'C') {	/* normal, control, or none */
+				if ((length = va_arg(inarg, int)) < ' ') {
+					if (length == 0) {
+						ostr = (uint8_t *) ds_none;
+						length = 4;
+					} else {
+						io->buf[MAX_IO_SIZE] = '^';
+						io->buf[MAX_IO_SIZE + 1] =
+						    ((uint8_t) length) + '@';
+						io->buf[MAX_IO_SIZE + 2] = 0;
+						ostr = &io->buf[MAX_IO_SIZE];
+						length = 2;
+					}
+					arg.ip++;
+					break;
+				}
+			}
+
+			/* normal, control, or none */
+			/*
+			   va_arg returns type of arg being process.
+			   Second arg passed to va_arg() specifies return 
+			   value type.
+			 */
+			ichar.intchar = va_arg(inarg, int);
+#if LITTLE_ENDIAN_HW
+			ostr = &ichar.chr[0];
+#else
+			ostr = &ichar.chr[3];
+#endif
+			length = 1;
+			break;
+
+		case 'd':
+			temp = -10;
+		      nosign:
+
+			if (longflag)
+				lw.ltulong = va_arg(inarg, ulong);
+			else if (temp < 0)
+				lw.ltlong = va_arg(inarg, long);
+			else
+				lw.ltulong = va_arg(inarg, ulong);
+/*
+   nosign2:
+*/
+			length = elx_str_itos(lw.ltlong, ostr =
+					      &io->buf[MAX_IO_SIZE], temp);
+			break;
+
+		case 's':
+			ostr = (uint8_t *) va_arg(inarg, caddr_t);	/* string */
+			if ((chr == 's') || (*ostr != '\0')) {
+				length = elx_expanded_len(ostr);
+				break;
+			}
+		      putnone:
+			ostr = (uint8_t *) ds_none;
+			length = 4;
+			break;
+
+		case 't':	/* tabbing */
+			if ((width -= io->count) < 0)	/* Spaces required to get to column. */
+				width = 0;
+			length = 0;	/* nothing other than width padding. */
+			ostr = (uint8_t *) ds_null_string;
+			break;
+		case ' ':
+			width = va_arg(inarg, int);
+			length = 0;	/* nothing other than width padding. */
+			ostr = (uint8_t *) ds_null_string;
+			break;
+
+		default:
+			ostr = control;
+			length = 1;
+			break;
+		}		/* switch on control */
+
+		if (length < 0) {	/* non printing */
+			if (elx_add_string(io, ostr) >= MAX_IO_SIZE)
+				elx_print_string(io);	/* no more room, dump current buffer */
+			continue;
+		}
+		/* non printing */
+		if (!leftadj && width > length) {
+			while (--width >= length) {
+				if (elx_add_char(io, padchar) >= MAX_IO_SIZE)
+					elx_print_string(io);	/* write it */
+			}
+		}
+
+		if (width > length)
+			width -= length;
+		else
+			width = 0;
+
+		if (length <= 1) {
+			if (length == 1) {
+				if (elx_add_char(io, *ostr) >= MAX_IO_SIZE)
+					elx_print_string(io);	/* write it */
+			}
+		} else {
+			while ((temp = *ostr++) != 0) {
+				if (elx_add_char(io, (uint8_t) temp) >=
+				    MAX_IO_SIZE)
+					elx_print_string(io);	/* write it */
+			}
+		}
+
+		while (--width >= 0) {
+			if (elx_add_char(io, padchar) >= MAX_IO_SIZE)
+				elx_print_string(io);	/* write it */
+		}
+	}			/* while more in control string */
+
+	/* The io->index should be O now, but if it is not, write the
+	 * remainder to console.
+	 */
+	if (io->index)
+		elx_print_string(io);
+
+	elx_kmem_free(io, sizeof (PRINTBLK));
+
+	return (io->count);
+}
+
+int
+elx_printf(void *control, ...)
+{
+	int iocnt;
+	va_list args;
+	va_start(args, control);
+
+	iocnt = elx_fmtout((uint8_t *) NULL, (uint8_t *) control, args);
+	va_end(args);
+	return (iocnt);
+}
+
+int
+elx_sprintf_fargs(uint8_t * string, void *control, va_list args)
+{
+	int i;
+	i = elx_fmtout((uint8_t *) string, (uint8_t *) control, args);
+	return (i);
+}
+
+int
+elx_str_sprintf(void *string,	/* output buffer */
+		void *control,	/* format string */
+		...)
+{				/* control arguments */
+	int iocnt;
+	va_list args;
+	va_start(args, control);
+
+	iocnt = elx_fmtout((uint8_t *) string, (uint8_t *) control, args);
+	va_end(args);
+	return (iocnt);
+}
+
+int
+elx_printf_log(int brdno, msgLogDef * msg,	/* Pointer to LOG msg structure */
+	       void *control, ...)
+{
+	uint8_t str2[MAX_IO_SIZE + MAX_TBUFF];	/* extra room to convert numbers */
+	int iocnt;
+	int log_only;
+	va_list args;
+	va_start(args, control);
+
+	log_only = 0;
+	if (elx_log_chk_msg_disabled(brdno, msg, &log_only))
+		return (0);	/* This LOG message disabled */
+
+	/* 
+	   If LOG message is disabled via any SW method, we SHOULD NOT get this far!
+	   We should have taken the above return. 
+	 */
+
+	str2[0] = '\0';
+	iocnt = elx_sprintf_fargs(str2, control, args);
+	va_end(args);
+	return (elx_printf_log_msgblk(brdno, msg, (char *)str2, log_only));
+}
+
+int
+elx_log_chk_msg_disabled(int brdno, msgLogDef * msg,	/* Pointer to LOG msg structure */
+			 int *log_only)
+{
+	elxHBA_t *phba;
+	elxCfgParam_t *clp;
+	int verbose;
+
+	verbose = 0;
+
+	if (msg->msgOutput == ELX_MSG_OPUT_DISA)
+		return (1);	/* This LOG message disabled */
+
+	if ((phba = elxDRVR.pHba[brdno])) {
+		clp = &phba->config[0];
+		*log_only = (int)(clp[ELX_CFG_LOG_ONLY].a_current);
+		verbose = clp[ELX_CFG_LOG_VERBOSE].a_current;
+	}
+
+	if (msg->msgOutput == ELX_MSG_OPUT_FORCE) {
+		return (0);	/* This LOG message enabled */
+	}
+
+	if ((msg->msgType == ELX_LOG_MSG_TYPE_INFO) ||
+	    (msg->msgType == ELX_LOG_MSG_TYPE_WARN)) {
+		/* LOG msg is INFO or WARN */
+		if ((msg->msgMask & verbose) == 0)
+			return (1);	/* This LOG message disabled */
+	}
+
+	return (0);		/* This LOG message enabled */
+}
+
+int
+elx_str_ctox(uint8_t c)
+{
+	if (c >= '0' && c <= '9')
+		return (c - '0');
+	else if (c >= 'A' && c <= 'F')
+		return (c - 'A' + 10);
+	else if (c >= 'a' && c <= 'f')
+		return (c - 'a' + 10);
+	else
+		return (-1);
+}
+
+int
+elx_str_atox(elxHBA_t * phba, int input_bc,	/* Number of bytes (ASC hex chars) to be converted */
+	     int output_bc,	/* Number of bytes in hex output buffer (modulo INT) */
+	     char *inp,		/* Pointer to ASC hex input character sequence */
+	     char *outp)
+{				/* Pointer to hex output buffer */
+#define HEX_DIGITS_PER_BYTE        2
+#define MAX_ASC_HEX_CHARS_INPUT   32	/* Limit damage if over-write */
+#define MAX_BUF_SIZE_HEX_OUTPUT   (MAX_ASC_HEX_CHARS_INPUT / HEX_DIGITS_PER_BYTE)
+
+	int lowNib, hiNib;
+	int inputCharsConverted;
+	uint8_t twoHexDig;
+
+	inputCharsConverted = 0;
+	lowNib = -1;
+	hiNib = -1;
+
+	if (input_bc < 1) {
+		/* Convert ASC to hex. Input byte cnt < 1. */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1210,	/* ptr to msg structure */
+			       elx_mes1210,	/* ptr to msg */
+			       elx_msgBlk1210.msgPreambleStr);	/* begin & end varargs */
+		return (-1);
+	}
+	if (input_bc > MAX_ASC_HEX_CHARS_INPUT) {
+		/* Convert ASC to hex. Input byte cnt > max <num> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1211,	/* ptr to msg structure */
+			       elx_mes1211,	/* ptr to msg */
+			       elx_msgBlk1211.msgPreambleStr,	/* begin varargs */
+			       MAX_ASC_HEX_CHARS_INPUT);	/* end varargs */
+		return (-2);
+	}
+	if ((output_bc * 2) < input_bc) {
+		/* Convert ASC to hex. Output buffer to small. */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1212,	/* ptr to msg structure */
+			       elx_mes1212,	/* ptr to msg */
+			       elx_msgBlk1212.msgPreambleStr);	/* begin & end varargs */
+		return (-4);
+	}
+
+	while (input_bc) {
+		twoHexDig = 0;
+		lowNib = -1;
+		hiNib = elx_str_ctox(*inp++);
+		if (--input_bc > 0) {
+			lowNib = elx_str_ctox(*inp++);
+			input_bc--;
+		}
+		if ((lowNib < 0) || (hiNib < 0)) {
+			/* Convert ASC to hex. Input char seq not ASC hex. */
+			elx_printf_log(phba->brd_no, &elx_msgBlk1213,	/* ptr to msg structure */
+				       elx_mes1213,	/* ptr to msg */
+				       elx_msgBlk1213.msgPreambleStr);	/* begin & end varargs */
+			return (-4);
+		}
+		if (lowNib >= 0) {
+			/* There were 2 digits */
+			hiNib <<= 4;
+			twoHexDig = (hiNib | lowNib);
+			inputCharsConverted += 2;
+		} else {
+			/* There was a single digit */
+			twoHexDig = lowNib;
+			inputCharsConverted++;
+		}
+		*outp++ = twoHexDig;
+	}			/* while */
+	return (inputCharsConverted);	/* ASC to hex conversion complete. Return # of chars converted */
+}
+
+char *
+elx_str_cpy(char *str1, char *str2)
+{
+	char *temp;
+	temp = str1;
+
+	while ((*str1++ = *str2++) != '\0') {
+		continue;
+	}
+	return (temp);
+}
+
+int
+elx_str_ncmp(char *str1, char *str2, int cnt)
+{
+	int c1, c2;
+	int dif;
+
+	while (cnt--) {
+		c1 = (int)*str1++ & 0xff;
+		c2 = (int)*str2++ & 0xff;
+		if ((c1 | c2) == 0)
+			return (0);	/* strings equal */
+		if ((dif = c1 - c2) == 0)
+			continue;	/* chars are equal */
+		if (c1 == 0)
+			return (-1);	/* str1 < str2 */
+		if (c2 == 0)
+			return (1);	/* str1 > str2 */
+		return (dif);
+	}
+	return (0);		/* strings equal */
+}
+
+int
+elx_is_digit(int chr)
+{
+	if ((chr >= '0') && (chr <= '9'))
+		return (1);
+	return (0);
+}				/* fc_is_digit */
+
+int
+elx_str_len(char *str)
+{
+	int n;
+
+	for (n = 0; *str++ != '\0'; n++) ;
+
+	return (n);
+}
+
+extern elxDRVR_t elxDRVR;
+
+ELXCLOCK_t *elx_clkgetb(elxHBA_t * phba);
+int elx_que_tin(ELX_DLINK_t * blk, ELX_DLINK_t * hdr);
+
+int elx_timer_inp = 0;
+
+/* 
+ * boolean to test if block is linked into specific queue
+ *  (intended for assertions)
+ */
+#define elx_inque(x,hdr)  elx_que_tin((ELX_DLINK_t *)(x), (ELX_DLINK_t *)(hdr))
+#define ELX_MAX_CLK_TIMEOUT 0xfffffff
+
+ELXCLOCK_t *
+elx_clkgetb(elxHBA_t * phba)
+{
+	ELXCLOCK_t *cb;
+
+	if (phba) {
+		cb = (ELXCLOCK_t *) elx_mem_get(phba, MEM_CLOCK);
+	} else {
+		cb = 0;
+	}
+
+	if (cb)
+		cb->cl_phba = (void *)phba;
+	return (cb);
+}
+
+void
+elx_clkrelb(elxHBA_t * phba, ELXCLOCK_t * cb)
+{
+	if (phba) {
+		elx_mem_put(phba, MEM_CLOCK, (uint8_t *) cb);
+	} else {
+		cb->cl_tix = (uint32_t) - 1;
+	}
+}
+
+int
+elx_clk_can(elxHBA_t * phba, ELXCLOCK_t * cb)
+{
+	ELXCLOCK_INFO_t *clock_info;
+	unsigned long iflag;
+
+	if (cb == 0)
+		return (0);
+
+	clock_info = &elxDRVR.elx_clock_info;
+	ELX_CLK_LOCK(iflag);
+
+	/*  Make sure timer has not expired */
+	if (!elx_inque(cb, &clock_info->elx_clkhdr)) {
+		ELX_CLK_UNLOCK(iflag);
+		return (0);
+	}
+
+	elx_clock_deque(cb);
+
+	/* Release clock block */
+	elx_clkrelb(phba, cb);
+	ELX_CLK_UNLOCK(iflag);
+	return (1);
+}
+
+unsigned long
+elx_clk_rem(elxHBA_t * phba, ELXCLOCK_t * cb)
+{
+	ELXCLOCK_INFO_t *clock_info;
+	ELXCLOCK_t *x;
+	unsigned long tix;
+	unsigned long iflag;
+
+	clock_info = &elxDRVR.elx_clock_info;
+	ELX_CLK_LOCK(iflag);
+
+	tix = 0;
+	/* get top of clock queue */
+	x = (ELXCLOCK_t *) & clock_info->elx_clkhdr;
+
+	/* Add up ticks in blocks upto specified request */
+	do {
+		x = x->cl_fw;
+		if (x == (ELXCLOCK_t *) & clock_info->elx_clkhdr) {
+			ELX_CLK_UNLOCK(iflag);
+			return (0);
+		}
+		tix += x->cl_tix;
+	} while (x != cb);
+
+	ELX_CLK_UNLOCK(iflag);
+	return (tix);
+}
+
+unsigned long
+elx_clk_res(elxHBA_t * phba, unsigned long tix, ELXCLOCK_t * cb)
+{
+	ELXCLOCK_t *x;
+	ELXCLOCK_INFO_t *clock_info;
+	unsigned long iflag;
+
+	clock_info = &elxDRVR.elx_clock_info;
+	ELX_CLK_LOCK(iflag);
+
+	/*  Make sure timer has not expired */
+	if (!elx_inque(cb, &clock_info->elx_clkhdr)) {
+		ELX_CLK_UNLOCK(iflag);
+		return (0);
+	}
+	if (tix <= 0) {
+		ELX_CLK_UNLOCK(iflag);
+		return (0);
+	}
+
+	/* Round up 1 sec to account for partial first tick */
+	tix++;
+
+	elx_clock_deque(cb);
+
+	/* Insert block into queue by order of amount of clock ticks,
+	 * each block contains difference in ticks between itself and
+	 * its predecessor.
+	 */
+	x = (ELXCLOCK_t *) clock_info->elx_clkhdr.q_f;
+	while (x != (ELXCLOCK_t *) & clock_info->elx_clkhdr) {
+		if (x->cl_tix >= tix) {
+			/* if inserting in middle of que, adjust next tix */
+			x->cl_tix -= tix;
+			break;
+		}
+		tix -= x->cl_tix;
+		x = x->cl_fw;
+	}
+
+	/* back up one in que */
+	x = x->cl_bw;
+	elx_enque(cb, x);
+	clock_info->elx_clkhdr.q_cnt++;
+	cb->cl_tix = tix;
+
+	ELX_CLK_UNLOCK(iflag);
+	return (1);
+}
+
+ELXCLOCK_t *
+elx_clk_set(elxHBA_t * phba,
+	    unsigned long tix,
+	    void (*func) (elxHBA_t *, void *, void *), void *arg1, void *arg2)
+{
+	ELXCLOCK_INFO_t *clock_info;
+	ELXCLOCK_t *x;
+	ELXCLOCK_t *cb;
+	unsigned long iflag;
+
+	if (tix > ELX_MAX_CLK_TIMEOUT) {
+		return (0);
+	}
+
+	/* round up 1 sec to account for partial first tick */
+	tix++;
+	clock_info = &elxDRVR.elx_clock_info;
+	ELX_CLK_LOCK(iflag);
+
+	/* Allocate a CLOCK block */
+	if ((cb = elx_clkgetb(phba)) == 0) {
+		ELX_CLK_UNLOCK(iflag);
+		return (0);
+	}
+
+	/* Insert block into queue by order of amount of clock ticks,
+	 * each block contains difference in ticks between itself and
+	 *its predecessor.
+	 */
+	x = (ELXCLOCK_t *) clock_info->elx_clkhdr.q_f;
+	while (x != (ELXCLOCK_t *) & clock_info->elx_clkhdr) {
+		if (x->cl_tix >= tix) {
+			/* if inserting in middle of que, adjust next tix */
+			if (x->cl_tix > tix) {
+				x->cl_tix -= tix;
+				break;
+			}
+			/* Another clock expires at same time.  Maintain the order of requests. */
+			for (x = x->cl_fw;
+			     x != (ELXCLOCK_t *) & clock_info->elx_clkhdr;
+			     x = x->cl_fw) {
+				if (x->cl_tix != 0)
+					break;
+			}
+
+			tix = 0;
+			break;
+		}
+
+		tix -= x->cl_tix;
+		x = x->cl_fw;
+	}
+
+	/* back up one in que */
+	x = x->cl_bw;
+
+	/* Count the current number of unexpired clocks */
+	clock_info->elx_clkhdr.q_cnt++;
+	elx_enque(cb, x);
+	cb->cl_func = (void (*)(void *, void *, void *))func;
+	cb->cl_arg1 = arg1;
+	cb->cl_arg2 = arg2;
+	cb->cl_tix = tix;
+	ELX_CLK_UNLOCK(iflag);
+	return ((ELXCLOCK_t *) cb);
+}
+
+void
+elx_timer(void *p)
+{
+	elxHBA_t *phba;
+	ELXCLOCK_t *x;
+	ELXCLOCK_INFO_t *clock_info;
+	unsigned long iflag;
+	unsigned long tix;
+
+	clock_info = &elxDRVR.elx_clock_info;
+	ELX_CLK_LOCK(iflag);
+	if (elx_timer_inp) {
+		ELX_CLK_UNLOCK(iflag);
+		return;
+	}
+	elx_timer_inp = 1;
+
+	/* Increment time_sample value */
+	clock_info->ticks++;
+
+	x = (ELXCLOCK_t *) clock_info->elx_clkhdr.q_f;
+
+	/* counter for propagating negative values */
+	tix = 0;
+	/* If there are expired clocks */
+	if (x != (ELXCLOCK_t *) & clock_info->elx_clkhdr) {
+		x->cl_tix = x->cl_tix - 1;
+		if (x->cl_tix <= 0) {
+			/* Loop thru all clock blocks */
+			while (x != (ELXCLOCK_t *) & clock_info->elx_clkhdr) {
+				x->cl_tix += tix;
+				/* If # of ticks left > 0, break out of loop */
+				if (x->cl_tix > 0)
+					break;
+				tix = x->cl_tix;
+
+				/* Deque expired clock */
+				elx_deque(x);
+				/* Decrement count of unexpired clocks */
+				clock_info->elx_clkhdr.q_cnt--;
+
+				phba = x->cl_phba;
+				if (phba) {
+					ELX_CLK_UNLOCK(iflag);
+					ELX_DRVR_LOCK(phba, iflag);
+					/* Call timeout routine */
+					(*x->cl_func) (phba, x->cl_arg1,
+						       x->cl_arg2);
+					ELX_DRVR_UNLOCK(phba, iflag);
+					ELX_CLK_LOCK(iflag);
+				}
+				/* Release clock block */
+				elx_clkrelb(phba, x);
+
+				/* start over */
+				x = (ELXCLOCK_t *) clock_info->elx_clkhdr.q_f;
+			}
+		}
+	}
+	elx_timer_inp = 0;
+	ELX_CLK_UNLOCK(iflag);
+	return;
+}
+
+void
+elx_clock_deque(ELXCLOCK_t * cb)
+{
+	ELXCLOCK_t *x;
+	ELXCLOCK_INFO_t *clock_info;
+
+	clock_info = &elxDRVR.elx_clock_info;
+	/*
+	 ***  Remove the block from its present spot, but first adjust
+	 ***  tix field of any successor.
+	 */
+	if (cb->cl_fw != (ELXCLOCK_t *) & clock_info->elx_clkhdr) {
+		x = cb->cl_fw;
+		x->cl_tix += cb->cl_tix;
+	}
+
+	/* Decrement count of unexpired clocks */
+	clock_info->elx_clkhdr.q_cnt--;
+
+	elx_deque(cb);
+}
+
+void
+elx_clock_init()
+{
+	ELXCLOCK_INFO_t *clock_info;
+
+	clock_info = &elxDRVR.elx_clock_info;
+
+	/* Initialize clock queue */
+	clock_info->elx_clkhdr.q_f = (ELX_DLINK_t *) & clock_info->elx_clkhdr;
+	clock_info->elx_clkhdr.q_b = (ELX_DLINK_t *) & clock_info->elx_clkhdr;
+	clock_info->elx_clkhdr.q_cnt = 0;
+
+	/* Initialize clock globals */
+	clock_info->ticks = 0;
+	clock_info->tmr_ct = 0;
+}
+
+int
+elx_que_tin(ELX_DLINK_t * blk, ELX_DLINK_t * hdr)
+{
+	ELX_DLINK_t *x;
+
+	x = hdr->q_f;
+	while (x != hdr) {
+		if (x == blk) {
+			return (1);
+		}
+		x = x->q_f;
+	}
+	return (0);
+}
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx.h linux-2.6.3/drivers/scsi/lpfc/elx.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,234 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX
+#define _H_ELX
+
+#include "elx_hw.h"
+#include "elx_sli.h"
+#include "elx_mem.h"
+#include "elx_clock.h"
+
+#include "elx_sched.h"
+
+#define ELX_SLIM2_PAGE_AREA  8192
+
+/* used for memory allocation */
+#define ELX_MEM_DELAY   0
+#define ELX_MEM_NDELAY  1
+
+/*****************************************************************************/
+/*                      device states                                        */
+/*****************************************************************************/
+#define CLOSED          0	/* initial device state */
+#define DEAD            1	/* fatal hardware error encountered */
+#define OPENED          4	/* opened successfully, functioning */
+
+#define NORMAL_OPEN     0x0	/* opened in normal mode */
+
+/***************************************************************************/
+/*
+ * This is the global device driver control structure
+ */
+/***************************************************************************/
+
+struct elx_driver {
+	ELXCLOCK_INFO_t elx_clock_info;	/* clock setup */
+	unsigned long cflag;	/* used to hold context for clock lock, if needed */
+	struct elxHBA *pHba[MAX_ELX_BRDS];	/* hba array */
+
+	void *pDrvrOSEnv;
+
+	uint16_t num_devs;	/* count of devices configed */
+};
+typedef struct elx_driver elxDRVR_t;
+
+#if LITTLE_ENDIAN_HOST
+#define SWAP_SHORT(x)   (x)
+#define SWAP_LONG(x)    (x)
+#define SWAP_DATA(x)    ((((x) & 0xFF)<<24) | (((x) & 0xFF00)<<8) | \
+                        (((x) & 0xFF0000)>>8) | (((x) & 0xFF000000)>>24))
+#define SWAP_DATA16(x)  ((((x) & 0xFF) << 8) | ((x) >> 8))
+#define PCIMEM_SHORT(x) SWAP_SHORT(x)
+#define PCIMEM_LONG(x)  SWAP_LONG(x)
+#define PCIMEM_DATA(x)  SWAP_DATA(x)
+
+#define putLunLow(lunlow, lun)              \
+   {                                        \
+   lunlow = 0;                              \
+   }
+
+#define putLunHigh(lunhigh, lun)            \
+   {                                        \
+   lunhigh = (uint32_t)(lun << 8);          \
+   }
+
+#else				/* BIG_ENDIAN_HOST */
+#define SWAP_SHORT(x)   ((((x) & 0xFF) << 8) | ((x) >> 8))
+#define SWAP_LONG(x)    ((((x) & 0xFF)<<24) | (((x) & 0xFF00)<<8) | \
+                        (((x) & 0xFF0000)>>8) | (((x) & 0xFF000000)>>24))
+#define SWAP_DATA(x)    (x)
+#define SWAP_DATA16(x)  (x)
+
+#ifdef BIU_BSE			/* This feature only makes sense for Big Endian */
+#define PCIMEM_SHORT(x) (x)
+#define PCIMEM_LONG(x)  (x)
+#define PCIMEM_DATA(x)  ((((x) & 0xFF)<<24) | (((x) & 0xFF00)<<8) | \
+                        (((x) & 0xFF0000)>>8) | (((x) & 0xFF000000)>>24))
+#else
+#define PCIMEM_SHORT(x) SWAP_SHORT(x)
+#define PCIMEM_LONG(x)  SWAP_LONG(x)
+#define PCIMEM_DATA(x)  SWAP_DATA(x)
+#endif
+
+#define putLunLow(lunlow, lun)              \
+   {                                        \
+   lunlow = 0;                              \
+   }
+
+#define putLunHigh(lunhigh, lun)            \
+   {                                        \
+   lunhigh = (uint32_t)(lun << 16);         \
+   }
+#endif
+
+#define SWAP_ALWAYS(x)  ((((x) & 0xFF)<<24) | (((x) & 0xFF00)<<8) | \
+                        (((x) & 0xFF0000)>>8) | (((x) & 0xFF000000)>>24))
+
+#define SWAP_ALWAYS16(x) ((((x) & 0xFF) << 8) | ((x) >> 8))
+
+/* CHECK */
+#define FC_SCSID(pan, sid)    ((uint32_t)((pan << 16) | sid))	/* For logging */
+
+/****************************************************************************/
+/*      Device VPD save area                                                */
+/****************************************************************************/
+typedef struct elx_vpd {
+	uint32_t status;	/* vpd status value */
+	uint32_t length;	/* number of bytes actually returned */
+	struct {
+		uint32_t rsvd1;	/* Revision numbers */
+		uint32_t biuRev;
+		uint32_t smRev;
+		uint32_t smFwRev;
+		uint32_t endecRev;
+		uint16_t rBit;
+		uint8_t fcphHigh;
+		uint8_t fcphLow;
+		uint8_t feaLevelHigh;
+		uint8_t feaLevelLow;
+		uint32_t postKernRev;
+		uint32_t opFwRev;
+		uint8_t opFwName[16];
+		uint32_t sli1FwRev;
+		uint8_t sli1FwName[16];
+		uint32_t sli2FwRev;
+		uint8_t sli2FwName[16];
+	} rev;
+} elx_vpd_t;
+
+typedef struct elx_cfgparam {
+	char *a_string;
+	uint32_t a_low;
+	uint32_t a_hi;
+	uint32_t a_default;
+	uint32_t a_current;
+	uint16_t a_flag;
+	uint16_t a_changestate;
+	char *a_help;
+} elxCfgParam_t;
+
+struct elxScsiLun;
+struct elx_scsi_buf;
+
+typedef struct elxHBA {
+	uint8_t intr_inited;	/* flag for interrupt registration */
+	struct elxHBA *nextHba;	/* point to the next device */
+	uint32_t fc_ipri;	/* save priority */
+	uint32_t hba_flag;	/* device flags */
+#define FC_SCHED_CFG_INIT   0x2	/* schedule a call to fc_cfg_init() */
+#define FC_FULL_INFO_CALL   0x4	/* set if fc_info() can return full info */
+#define FC_STOP_IO          0x8	/* set for offline call */
+#define FC_POLL_CMD         0x10	/* indicate to poll for command completion */
+#define FC_LFR_ACTIVE       0x20	/* Link Failure recovery activated */
+#define FC_NDISC_ACTIVE     0x40	/* Node discovery mode activated */
+
+	struct elx_sli sli;
+	DMABUF_t slim2p;
+
+	uint32_t hba_state;
+
+#define ELX_INIT_START           1	/* Initial state after board reset */
+#define ELX_INIT_MBX_CMDS        2	/* Initialize HBA with mbox commands */
+#define ELX_LINK_DOWN            3	/* HBA initialized, link is down */
+#define ELX_LINK_UP              4	/* Link is up  - issue READ_LA */
+#define ELX_LOCAL_CFG_LINK       5	/* local NPORT Id configured */
+#define ELX_FLOGI                6	/* FLOGI sent to Fabric */
+#define ELX_FABRIC_CFG_LINK      7	/* Fabric assigned NPORT Id configured */
+#define ELX_NS_REG               8	/* Register with NameServer */
+#define ELX_NS_QRY               9	/* Query NameServer for NPort ID list */
+#define ELX_BUILD_DISC_LIST      10	/* Build ADISC and PLOGI lists for
+					 * device authentication / discovery */
+#define ELX_DISC_AUTH            11	/* Processing ADISC list */
+#define ELX_CLEAR_LA             12	/* authentication cmplt - issue CLEAR_LA */
+#define ELX_HBA_READY            32
+#define ELX_HBA_ERROR            0xff
+
+	void *pHbaProto;	/* Private hba struct pointer per driver type.  */
+	elxCfgParam_t *config;	/* Configuration parameters */
+
+	uint32_t bus_intr_lvl;
+	uint32_t pci_id;
+	elx_vpd_t vpd;		/* vital product data */
+
+	unsigned long iflag;	/* used to hold context for drvr lock, if needed */
+
+	void *pHbaOSEnv;
+
+	uint8_t brd_no;		/* FC board number */
+	uint8_t fc_busflag;	/* bus access flags */
+
+	ELX_SCHED_HBA_t hbaSched;
+
+	uint16_t maxRpi;
+
+	uint32_t fcp_timeout_offset;
+
+	char adaptermsg[FC_MAX_ADPTMSG];	/* adapter printf messages */
+
+	char SerialNumber[32];	/* adapter Serial Number */
+	char OptionROMVersion[32];	/* adapter BIOS / Fcode version */
+	MEMSEG_t memseg[ELX_MAX_SEG];	/* memory for buffers / structures */
+
+	struct elxScsiLun *(*elx_tran_find_lun) (struct elx_scsi_buf *);
+	ELXCLOCK_t *dqfull_clk;
+	ELXCLOCK_t *els_tmofunc;
+	ELXCLOCK_t *ip_tmofunc;
+	ELXCLOCK_t *scsi_tmofunc;
+
+	/*
+	 * HBA API 2.0 specific counters
+	 */
+	uint64_t fc4InputRequests;
+	uint64_t fc4OutputRequests;
+	uint64_t fc4ControlRequests;
+} elxHBA_t;
+
+#endif				/* _H_ELX */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_cfgparm.h linux-2.6.3/drivers/scsi/lpfc/elx_cfgparm.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_cfgparm.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_cfgparm.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,48 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_CFGPARAM
+#define _H_ELX_CFGPARAM
+
+/* These are common configuration parameters */
+/* The order of the ELX_CFG defs must match that of icfgparam[] entries */
+
+#define ELX_CFG_LOG_VERBOSE               0	/* log-verbose */
+#define ELX_CFG_LOG_ONLY                  1	/* log-only */
+#define ELX_CFG_NUM_IOCBS                 2	/* num-iocbs */
+#define ELX_CFG_NUM_BUFS                  3	/* num-bufs */
+#define ELX_CFG_DFT_TGT_Q_DEPTH           4	/* tgt_queue_depth */
+#define ELX_CFG_DFT_LUN_Q_DEPTH           5	/* lun_queue_depth */
+#define ELX_CFG_EXTRA_IO_TMO              6	/* extra-io-tmo */
+#define ELX_CFG_FIRST_CHECK               7	/* first-check */
+#define ELX_CFG_NO_DEVICE_DELAY           8	/* no-device-delay */
+#define ELX_CFG_LINKDOWN_TMO              9	/* linkdown-tmo */
+#define ELX_CFG_HOLDIO                   10	/* nodev-holdio */
+#define ELX_CFG_DELAY_RSP_ERR            11	/* delay-rsp-err */
+#define ELX_CFG_CHK_COND_ERR             12	/* check-cond-err */
+#define ELX_CFG_NODEV_TMO                13	/* nodev-tmo */
+#define ELX_CFG_DQFULL_THROTTLE_UP_TIME  14	/* dqfull-throttle-up-time */
+#define ELX_CFG_DQFULL_THROTTLE_UP_INC   15	/* dqfull-throttle-up-inc */
+#define ELX_CFG_MAX_LUN                  16	/* max-lun */
+#define ELX_CFG_DFT_HBA_Q_DEPTH          17	/* dft_hba_q_depth */
+#define ELX_CFG_LUN_SKIP		 18
+#define ELX_CORE_NUM_OF_CFG_PARAM        19
+
+#endif				/* _H_ELX_CFGPARAM */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_clock.h linux-2.6.3/drivers/scsi/lpfc/elx_clock.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_clock.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_clock.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,55 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_CLOCK
+#define _H_ELX_CLOCK
+
+#define MIN_CLK_BLKS    256
+
+/* Structures using for clock / timeout handling */
+struct elxclock {
+	struct elxclock *cl_fw;	/* forward linkage */
+	union {
+		struct {
+			uint16_t cl_soft_arg;
+			uint16_t cl_soft_cmd;
+		} c1;
+		struct elxclock *cl_bw;	/* backward linkage */
+	} un;
+	uint32_t cl_tix;	/* differential number of clock ticks */
+	void (*cl_func) (void *, void *, void *);
+	void *cl_phba;
+	void *cl_arg1;		/* argument 1 to function */
+	void *cl_arg2;		/* argument 2 to function */
+};
+
+typedef struct elxclock ELXCLOCK_t;
+
+#define cl_bw         un.cl_bw
+
+typedef struct elxclock_info {
+	ELX_DLINK_t elx_clkhdr;
+	uint32_t ticks;		/* elapsed time since initialization */
+	uint32_t tmr_ct;	/* Timer expired count */
+	uint32_t timestamp[2];	/* SMT 64 bit timestamp */
+	void *clktimer;		/* used for scheduling clock routine */
+} ELXCLOCK_INFO_t;
+
+#endif				/* _H_ELX_CLOCK */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_crtn.h linux-2.6.3/drivers/scsi/lpfc/elx_crtn.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_crtn.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_crtn.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,137 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_CRTN
+#define _H_ELX_CRTN
+
+void elx_read_rev(elxHBA_t *, ELX_MBOXQ_t *);
+void elx_config_ring(elxHBA_t *, int, ELX_MBOXQ_t *);
+int elx_config_port(elxHBA_t *, ELX_MBOXQ_t *);
+void elx_mbox_put(elxHBA_t *, ELX_MBOXQ_t *);
+ELX_MBOXQ_t *elx_mbox_get(elxHBA_t *);
+
+DMABUF_t *elx_mem_alloc_dmabuf(elxHBA_t *, uint32_t);
+DMABUFEXT_t *elx_mem_alloc_dmabufext(elxHBA_t *, uint32_t);
+int elx_mem_alloc(elxHBA_t *);
+int elx_mem_free(elxHBA_t *);
+void *elx_mem_get(elxHBA_t *, int);
+uint8_t *elx_mem_put(elxHBA_t *, int, uint8_t *);
+
+int elx_sli_hba_setup(elxHBA_t *);
+int elx_sli_hba_down(elxHBA_t *);
+int elx_sli_ring_map(elxHBA_t *);
+int elx_sli_intr(elxHBA_t *);
+int elx_sli_issue_mbox(elxHBA_t *, ELX_MBOXQ_t *, uint32_t);
+void elx_mbox_abort(elxHBA_t *);
+int elx_sli_issue_iocb(elxHBA_t *, ELX_SLI_RING_t *, ELX_IOCBQ_t *, uint32_t);
+int elx_sli_resume_iocb(elxHBA_t *, ELX_SLI_RING_t *);
+int elx_sli_brdreset(elxHBA_t *);
+int elx_sli_setup(elxHBA_t *);
+void elx_sli_pcimem_bcopy(uint32_t *, uint32_t *, uint32_t);
+int elx_sli_ringpostbuf_put(elxHBA_t *, ELX_SLI_RING_t *, DMABUF_t *);
+DMABUF_t *elx_sli_ringpostbuf_get(elxHBA_t *, ELX_SLI_RING_t *, elx_dma_addr_t);
+uint32_t elx_sli_next_iotag(elxHBA_t *, ELX_SLI_RING_t *);
+int elx_sli_abort_iocb(elxHBA_t *, ELX_SLI_RING_t *, ELX_IOCBQ_t *);
+int elx_sli_issue_abort_iotag32(elxHBA_t *, ELX_SLI_RING_t *, ELX_IOCBQ_t *);
+int elx_sli_abort_iocb_ring(elxHBA_t *, ELX_SLI_RING_t *, uint32_t);
+int elx_sli_abort_iocb_ctx(elxHBA_t *, ELX_SLI_RING_t *, uint32_t);
+int elx_sli_abort_iocb_context1(elxHBA_t *, ELX_SLI_RING_t *, void *);
+int elx_sli_abort_iocb_lun(elxHBA_t *, ELX_SLI_RING_t *, uint16_t, uint64_t);
+int elx_sli_abort_iocb_tgt(elxHBA_t *, ELX_SLI_RING_t *, uint16_t);
+int elx_sli_abort_iocb_hba(elxHBA_t *, ELX_SLI_RING_t *);
+
+int elx_log_chk_msg_disabled(int, msgLogDef *, int *);
+int elx_printf(void *, ...);
+int elx_printf_log(int, msgLogDef *, void *, ...);
+int elx_str_sprintf(void *, void *, ...);
+int elx_str_atox(elxHBA_t *, int, int, char *, char *);
+int elx_str_ctox(uint8_t);
+char *elx_str_cpy(char *, char *);
+int elx_str_ctoh(uint8_t);
+int elx_str_itos(int, uint8_t *, int);
+int elx_str_isdigit(int);
+int elx_str_ncmp(char *, char *, int);
+int elx_is_digit(int);
+int elx_str_len(char *);
+
+int elx_fmtout(uint8_t * ostr, uint8_t * control, va_list inarg);
+
+int elx_clk_can(elxHBA_t *, ELXCLOCK_t *);
+unsigned long elx_clk_rem(elxHBA_t *, ELXCLOCK_t *);
+unsigned long elx_clk_res(elxHBA_t *, unsigned long, ELXCLOCK_t *);
+ELXCLOCK_t *elx_clk_set(elxHBA_t *, unsigned long,
+			void (*func) (elxHBA_t *, void *, void *), void *,
+			void *);
+void elx_timer(void *);
+void elx_clock_deque(ELXCLOCK_t *);
+void elx_clock_init(void);
+
+/* For Operating System Specific support */
+uint8_t *elx_malloc(elxHBA_t *, struct mbuf_info *);
+void elx_free(elxHBA_t *, struct mbuf_info *);
+uint32_t elx_hba_init(elxHBA_t *, ELX_MBOXQ_t *);
+int elx_print(char *, void *, void *);
+int elx_printf_log_msgblk(int, msgLogDef *, char *, int);
+void elx_sli_wake_iocb_wait(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+int elx_sli_issue_iocb_wait(elxHBA_t *, ELX_SLI_RING_t *,
+			    ELX_IOCBQ_t *, uint32_t, ELX_IOCBQ_t *, uint32_t);
+int elx_sli_issue_mbox_wait(elxHBA_t *, ELX_MBOXQ_t *, uint32_t);
+void elx_sli_wake_mbox_wait(elxHBA_t *, ELX_MBOXQ_t *);
+int elx_sleep(elxHBA_t *, void *, long tmo);
+void elx_wakeup(elxHBA_t *, void *);
+
+int elx_os_prep_io(elxHBA_t *, ELX_SCSI_BUF_t *);
+ELX_SCSI_BUF_t *elx_get_scsi_buf(elxHBA_t *);
+void elx_free_scsi_buf(ELX_SCSI_BUF_t *);
+ELXSCSILUN_t *elx_find_lun_device(ELX_SCSI_BUF_t *);
+void elx_map_fcp_cmnd_to_bpl(elxHBA_t *, ELX_SCSI_BUF_t *);
+void elx_free_scsi_cmd(ELX_SCSI_BUF_t *);
+uint32_t elx_os_timeout_transform(elxHBA_t *, uint32_t);
+void elx_os_return_scsi_cmd(elxHBA_t *, ELX_SCSI_BUF_t *);
+int elx_scsi_cmd_start(ELX_SCSI_BUF_t *);
+int elx_scsi_prep_task_mgmt_cmd(elxHBA_t *, ELX_SCSI_BUF_t *, uint8_t);
+int elx_scsi_cmd_abort(elxHBA_t *, ELX_SCSI_BUF_t *);
+int elx_scsi_lun_reset(ELX_SCSI_BUF_t *, elxHBA_t *, uint32_t,
+		       uint32_t, uint64_t, uint32_t);
+int elx_scsi_tgt_reset(ELX_SCSI_BUF_t *, elxHBA_t *, uint32_t,
+		       uint32_t, uint32_t);
+int elx_scsi_hba_reset(elxHBA_t *, uint32_t);
+void elx_qfull_retry(elxHBA_t *, void *, void *);
+void elx_scsi_lower_lun_qthrottle(elxHBA_t *, ELX_SCSI_BUF_t *);
+
+void elx_sched_init_hba(elxHBA_t *, uint16_t);
+void elx_sched_target_init(ELXSCSITARGET_t *, uint16_t);
+void elx_sched_lun_init(ELXSCSILUN_t *, uint16_t);
+void elx_sched_submit_command(elxHBA_t *, ELX_SCSI_BUF_t *);
+void elx_sched_queue_command(elxHBA_t *, ELX_SCSI_BUF_t *);
+void elx_sched_add_target_to_ring(elxHBA_t *, ELXSCSITARGET_t *);
+void elx_sched_remove_target_from_ring(elxHBA_t *, ELXSCSITARGET_t *);
+void elx_sched_add_lun_to_ring(elxHBA_t *, ELXSCSILUN_t *);
+void elx_sched_remove_lun_from_ring(elxHBA_t *, ELXSCSILUN_t *);
+int elx_sli_issue_iocb_wait_high_priority(elxHBA_t * phba,
+					  ELX_SLI_RING_t * pring,
+					  ELX_IOCBQ_t * piocb, uint32_t flag,
+					  ELX_IOCBQ_t * prspiocbq,
+					  uint32_t timeout);
+void elx_sched_service_high_priority_queue(struct elxHBA *hba);
+void elx_sli_wake_iocb_high_priority(elxHBA_t * phba, ELX_IOCBQ_t * queue1,
+				     ELX_IOCBQ_t * queue2);
+
+#endif				/* _H_ELX_CRTN */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_disc.h linux-2.6.3/drivers/scsi/lpfc/elx_disc.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_disc.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_disc.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,83 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef  _H_ELX_DISC
+#define  _H_ELX_DISC
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* This is a common structure definition for a Node List Entry.
+ * This can be used by both Fibre Channel and iSCSI protocols.
+ */
+	struct elx_nodelist {
+		struct elx_nodelist *nlp_listp_next;
+		struct elx_nodelist *nlp_listp_prev;
+		uint32_t nlp_failMask;	/* failure mask for device */
+		uint16_t nlp_type;
+#define NLP_FC_NODE        0x1	/* entry is an FC node */
+#define NLP_ISCSI          0x2	/* entry is an iSCSI node */
+#define NLP_FABRIC         0x4	/* entry represents a Fabric entity */
+#define NLP_FCP_TARGET     0x8	/* entry is an FCP target */
+#define NLP_IP_NODE        0x10	/* entry is an IP/FC node */
+
+		uint16_t nlp_rpi;
+		uint8_t nlp_fcp_info;	/* Remote class info */
+#define NLP_FCP_2_DEVICE   0x10	/* FCP-2 device */
+
+		uint8_t nlp_ip_info;	/* Remote class info */
+		volatile int nlp_rflag;
+#define NLP_SFR_ACTIVE     0x1	/* iSCSI Session Failure Recovery activated */
+#define NLP_NPR_ACTIVE     0x2	/* lpfc NPort recovery activated */
+#define NLP_FREED_NODE     0x4	/* nodelist entry is on free list */
+	};
+	typedef struct elx_nodelist ELX_NODELIST_t;
+
+/* Defines for failMask bitmask
+ * These are reasons that the device is not currently available 
+ * for I/O to be sent.
+ */
+#define ELX_DEV_LINK_DOWN       0x1	/* Link is down */
+#define ELX_DEV_DISAPPEARED     0x2	/* Device disappeared */
+#define ELX_DEV_RPTLUN          0x4	/* Device needs report luns cmd */
+#define ELX_DEV_INQSN_VALID     0x8	/* Validating Inquiry SN */
+/* If only these bits are set, the driver is trying to recover */
+#define ELX_DEV_HOLD_IO         0xf
+
+#define ELX_DEV_INVALID         0x10	/* DEV determined invalid by drvr */
+#define ELX_DEV_MAINT_MODE      0x20	/* HBA is in maintance mode */
+#define ELX_DEV_INACTIVE        0x40	/* DEV made inactive by drvr internally */
+#define ELX_DEV_DISCONNECTED    0x80	/* noactive connection to remote dev */
+#define ELX_DEV_USER_INITIATED  0x200	/* DEV taken offline by admin */
+/* If any of these bits are set, the device is gone */
+#define ELX_DEV_FATAL_ERROR     0x3f0
+
+#define ELX_DEV_DRVR_BITS       0x1ff	/* all valid driver failMask bits */
+#define ELX_DEV_ALL_BITS        0x3ff	/* all valid failMask bits */
+
+/* These defines are used for set failMask routines */
+#define ELX_SET_BITMASK		1
+#define ELX_CLR_BITMASK		2
+
+#ifdef __cplusplus
+}
+#endif
+#endif				/* _H_ELX_DISC */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_hw.h linux-2.6.3/drivers/scsi/lpfc/elx_hw.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_hw.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_hw.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,1787 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_HW
+#define _H_ELX_HW
+
+/*
+ *  Begin Adapter configuration parameters.  Many of these will be replaced
+ *  with parameters read from the registry or a configuration file in the 
+ *  future.
+ */
+
+#define FC_MAX_TRANSFER    0x40000	/* Maximum transfer size per operation */
+
+#define MAX_CONFIGURED_RINGS     3	/* # rings currently used for COMBO */
+#define MAX_RINGS                4
+
+#define FF_REG_AREA_SIZE       256	/* size, in bytes, of i/o register area */
+#define FF_SLIM_SIZE          4096	/* size, in bytes, of SLIM */
+
+#define OWN_CHIP        1	/* IOCB / Mailbox is owned by FireFly */
+#define OWN_HOST        0	/* IOCB / Mailbox is owned by Host */
+#define IOCB_WORD_SZ    8
+
+/* defines for type field in fc header */
+#define FC_ELS_DATA     0x1
+#define FC_LLC_SNAP     0x5
+#define FC_FCP_DATA     0x8
+#define FC_COMMON_TRANSPORT_ULP 0x20
+
+/* defines for rctl field in fc header */
+#define FC_DEV_DATA     0x0
+#define FC_UNSOL_CTL    0x2
+#define FC_SOL_CTL      0x3
+#define FC_UNSOL_DATA   0x4
+#define FC_FCP_CMND     0x6
+#define FC_ELS_REQ      0x22
+#define FC_ELS_RSP      0x23
+#define FC_NET_HDR      0x20	/* network headers for Dfctl field */
+
+/*
+ *  Start FireFly Register definitions
+ */
+
+/* PCI register offsets */
+#define MEM_ADDR_OFFSET 0x10	/* SLIM base memory address */
+#define MEMH_OFFSET     0x14	/* SLIM base memory high address */
+#define REG_ADDR_OFFSET 0x18	/* REGISTER base memory address */
+#define REGH_OFFSET     0x1c	/* REGISTER base memory high address */
+#define IO_ADDR_OFFSET  0x20	/* BIU I/O registers */
+#define REGIOH_OFFSET   0x24	/* REGISTER base io high address */
+
+#define CMD_REG_OFFSET  0x4	/* PCI command configuration */
+
+/* General PCI Register Definitions */
+/* Refer To The PCI Specification For Detailed Explanations */
+
+/* Register Offsets in little endian format */
+#define PCI_VENDOR_ID_REGISTER      0x00	/* PCI Vendor ID Register */
+#define PCI_DEVICE_ID_REGISTER      0x02	/* PCI Device ID Register */
+#define PCI_CONFIG_ID_REGISTER      0x00	/* PCI Configuration ID Register */
+#define PCI_COMMAND_REGISTER        0x04	/* PCI Command Register */
+#define PCI_STATUS_REGISTER         0x06	/* PCI Status Register */
+#define PCI_REV_ID_REGISTER         0x08	/* PCI Revision ID Register */
+#define PCI_CLASS_CODE_REGISTER     0x09	/* PCI Class Code Register */
+#define PCI_CACHE_LINE_REGISTER     0x0C	/* PCI Cache Line Register */
+#define PCI_LATENCY_TMR_REGISTER    0x0D	/* PCI Latency Timer Register */
+#define PCI_HEADER_TYPE_REGISTER    0x0E	/* PCI Header Type Register */
+#define PCI_BIST_REGISTER           0x0F	/* PCI Built-In SelfTest Register */
+#define PCI_BAR_0_REGISTER          0x10	/* PCI Base Address Register 0 */
+#define PCI_BAR_1_REGISTER          0x14	/* PCI Base Address Register 1 */
+#define PCI_BAR_2_REGISTER          0x18	/* PCI Base Address Register 2 */
+#define PCI_BAR_3_REGISTER          0x1C	/* PCI Base Address Register 3 */
+#define PCI_BAR_4_REGISTER          0x20	/* PCI Base Address Register 4 */
+#define PCI_BAR_5_REGISTER          0x24	/* PCI Base Address Register 5 */
+#define PCI_EXPANSION_ROM           0x30	/* PCI Expansion ROM Base Register */
+#define PCI_INTR_LINE_REGISTER      0x3C	/* PCI Interrupt Line Register */
+#define PCI_INTR_PIN_REGISTER       0x3D	/* PCI Interrupt Pin Register */
+#define PCI_MIN_GNT_REGISTER        0x3E	/* PCI Min-Gnt Register */
+#define PCI_MAX_LAT_REGISTER        0x3F	/* PCI Max_Lat Register */
+#define PCI_NODE_ADDR_REGISTER      0x40	/* PCI Node Address Register */
+
+/* number of PCI config bytes to access */
+#define PCI_BYTE        1
+#define PCI_WORD        2
+#define PCI_DWORD       4
+
+/* PCI related constants */
+#define CMD_IO_ENBL     0x0001
+#define CMD_MEM_ENBL    0x0002
+#define CMD_BUS_MASTER  0x0004
+#define CMD_MWI         0x0010
+#define CMD_PARITY_CHK  0x0040
+#define CMD_SERR_ENBL   0x0100
+
+#define CMD_CFG_VALUE   0x156	/* mem enable, master, MWI, SERR, PERR */
+
+#define PCI_VENDOR_ID_EMULEX        0x10df
+
+#define PCI_DEVICE_ID_SUPERFLY      0xf700
+#define PCI_DEVICE_ID_DRAGONFLY     0xf800
+#define PCI_DEVICE_ID_RFLY          0xf095
+#define PCI_DEVICE_ID_PFLY          0xf098
+#define PCI_DEVICE_ID_TFLY          0xf0a5
+#define PCI_DEVICE_ID_CENTAUR       0xf900
+#define PCI_DEVICE_ID_PEGASUS       0xf980
+#define PCI_DEVICE_ID_THOR          0xfa00
+#define PCI_DEVICE_ID_VIPER         0xfb00
+#define PCI_DEVICE_ID_LP101	    0xf0a1
+
+#define JEDEC_ID_ADDRESS            0x0080001c
+#define FIREFLY_JEDEC_ID            0x1ACC
+#define SUPERFLY_JEDEC_ID           0x0020
+#define DRAGONFLY_JEDEC_ID          0x0021
+#define DRAGONFLY_V2_JEDEC_ID       0x0025
+#define CENTAUR_2G_JEDEC_ID         0x0026
+#define CENTAUR_1G_JEDEC_ID         0x0028
+#define PEGASUS_ORION_JEDEC_ID      0x0036
+#define PEGASUS_JEDEC_ID            0x0038
+#define THOR_JEDEC_ID               0x0012
+#define VIPER_JEDEC_ID              0x4838
+
+#define JEDEC_ID_MASK               0x0FFFF000
+#define JEDEC_ID_SHIFT              12
+#define FC_JEDEC_ID(id)             ((id & JEDEC_ID_MASK) >> JEDEC_ID_SHIFT)
+
+#define DEFAULT_PCI_LATENCY_CLOCKS  0xf8	/* 0xF8 is a special value for
+						 * FF11.1N6 firmware.  Use
+						 * 0x80 for pre-FF11.1N6 &N7, etc
+						 */
+#define PCI_LATENCY_VALUE           0xf8
+
+typedef struct {		/* FireFly BIU registers */
+	uint32_t hostAtt;	/* See definitions for Host Attention register */
+	uint32_t chipAtt;	/* See definitions for Chip Attention register */
+	uint32_t hostStatus;	/* See definitions for Host Status register */
+	uint32_t hostControl;	/* See definitions for Host Control register */
+	uint32_t buiConfig;	/* See definitions for BIU configuration register */
+} FF_REGS, *PFF_REGS;
+
+/* Host Attention Register */
+
+#define HA_REG_OFFSET  0	/* Word offset from register base address */
+
+#define HA_R0RE_REQ    0x00000001	/* Bit  0 */
+#define HA_R0CE_RSP    0x00000002	/* Bit  1 */
+#define HA_R0ATT       0x00000008	/* Bit  3 */
+#define HA_R1RE_REQ    0x00000010	/* Bit  4 */
+#define HA_R1CE_RSP    0x00000020	/* Bit  5 */
+#define HA_R1ATT       0x00000080	/* Bit  7 */
+#define HA_R2RE_REQ    0x00000100	/* Bit  8 */
+#define HA_R2CE_RSP    0x00000200	/* Bit  9 */
+#define HA_R2ATT       0x00000800	/* Bit 11 */
+#define HA_R3RE_REQ    0x00001000	/* Bit 12 */
+#define HA_R3CE_RSP    0x00002000	/* Bit 13 */
+#define HA_R3ATT       0x00008000	/* Bit 15 */
+#define HA_LATT        0x20000000	/* Bit 29 */
+#define HA_MBATT       0x40000000	/* Bit 30 */
+#define HA_ERATT       0x80000000	/* Bit 31 */
+
+#define HA_RXRE_REQ    0x00000001	/* Bit  0 */
+#define HA_RXCE_RSP    0x00000002	/* Bit  1 */
+#define HA_RXATT       0x00000008	/* Bit  3 */
+#define HA_RXMASK      0x0000000f
+
+/* Chip Attention Register */
+
+#define CA_REG_OFFSET  1	/* Word offset from register base address */
+
+#define CA_R0CE_REQ    0x00000001	/* Bit  0 */
+#define CA_R0RE_RSP    0x00000002	/* Bit  1 */
+#define CA_R0ATT       0x00000008	/* Bit  3 */
+#define CA_R1CE_REQ    0x00000010	/* Bit  4 */
+#define CA_R1RE_RSP    0x00000020	/* Bit  5 */
+#define CA_R1ATT       0x00000080	/* Bit  7 */
+#define CA_R2CE_REQ    0x00000100	/* Bit  8 */
+#define CA_R2RE_RSP    0x00000200	/* Bit  9 */
+#define CA_R2ATT       0x00000800	/* Bit 11 */
+#define CA_R3CE_REQ    0x00001000	/* Bit 12 */
+#define CA_R3RE_RSP    0x00002000	/* Bit 13 */
+#define CA_R3ATT       0x00008000	/* Bit 15 */
+#define CA_MBATT       0x40000000	/* Bit 30 */
+
+/* Host Status Register */
+
+#define HS_REG_OFFSET  2	/* Word offset from register base address */
+
+#define HS_MBRDY       0x00400000	/* Bit 22 */
+#define HS_FFRDY       0x00800000	/* Bit 23 */
+#define HS_FFER8       0x01000000	/* Bit 24 */
+#define HS_FFER7       0x02000000	/* Bit 25 */
+#define HS_FFER6       0x04000000	/* Bit 26 */
+#define HS_FFER5       0x08000000	/* Bit 27 */
+#define HS_FFER4       0x10000000	/* Bit 28 */
+#define HS_FFER3       0x20000000	/* Bit 29 */
+#define HS_FFER2       0x40000000	/* Bit 30 */
+#define HS_FFER1       0x80000000	/* Bit 31 */
+#define HS_FFERM       0xFF000000	/* Mask for error bits 31:24 */
+
+/* Host Control Register */
+
+#define HC_REG_OFFSET  3	/* Word offset from register base address */
+
+#define HC_MBINT_ENA   0x00000001	/* Bit  0 */
+#define HC_R0INT_ENA   0x00000002	/* Bit  1 */
+#define HC_R1INT_ENA   0x00000004	/* Bit  2 */
+#define HC_R2INT_ENA   0x00000008	/* Bit  3 */
+#define HC_R3INT_ENA   0x00000010	/* Bit  4 */
+#define HC_INITHBI     0x02000000	/* Bit 25 */
+#define HC_INITMB      0x04000000	/* Bit 26 */
+#define HC_INITFF      0x08000000	/* Bit 27 */
+#define HC_LAINT_ENA   0x20000000	/* Bit 29 */
+#define HC_ERINT_ENA   0x80000000	/* Bit 31 */
+
+/* Mailbox Commands */
+#define MBX_SHUTDOWN        0x00	/* terminate testing */
+#define MBX_LOAD_SM         0x01
+#define MBX_READ_NV         0x02
+#define MBX_WRITE_NV        0x03
+#define MBX_RUN_BIU_DIAG    0x04
+#define MBX_INIT_LINK       0x05
+#define MBX_DOWN_LINK       0x06
+#define MBX_CONFIG_LINK     0x07
+#define MBX_CONFIG_RING     0x09
+#define MBX_RESET_RING      0x0A
+#define MBX_READ_CONFIG     0x0B
+#define MBX_READ_RCONFIG    0x0C
+#define MBX_READ_SPARM      0x0D
+#define MBX_READ_STATUS     0x0E
+#define MBX_READ_RPI        0x0F
+#define MBX_READ_XRI        0x10
+#define MBX_READ_REV        0x11
+#define MBX_READ_LNK_STAT   0x12
+#define MBX_REG_LOGIN       0x13
+#define MBX_UNREG_LOGIN     0x14
+#define MBX_READ_LA         0x15
+#define MBX_CLEAR_LA        0x16
+#define MBX_DUMP_MEMORY     0x17
+#define MBX_DUMP_CONTEXT    0x18
+#define MBX_RUN_DIAGS       0x19
+#define MBX_RESTART         0x1A
+#define MBX_UPDATE_CFG      0x1B
+#define MBX_DOWN_LOAD       0x1C
+#define MBX_DEL_LD_ENTRY    0x1D
+#define MBX_RUN_PROGRAM     0x1E
+#define MBX_SET_MASK        0x20
+#define MBX_SET_SLIM        0x21
+#define MBX_UNREG_D_ID      0x23
+#define MBX_CONFIG_FARP     0x25
+
+#define MBX_LOAD_AREA       0x81
+#define MBX_RUN_BIU_DIAG64  0x84
+#define MBX_CONFIG_PORT     0x88
+#define MBX_READ_SPARM64    0x8D
+#define MBX_READ_RPI64      0x8F
+#define MBX_REG_LOGIN64     0x93
+#define MBX_READ_LA64       0x95
+
+#define MBX_FLASH_WR_ULA    0x98
+#define MBX_SET_DEBUG       0x99
+#define MBX_LOAD_EXP_ROM    0x9C
+
+#define MBX_MAX_CMDS        0x9D
+#define MBX_SLI2_CMD_MASK   0x80
+
+/* IOCB Commands */
+
+#define CMD_RCV_SEQUENCE_CX     0x01
+#define CMD_XMIT_SEQUENCE_CR    0x02
+#define CMD_XMIT_SEQUENCE_CX    0x03
+#define CMD_XMIT_BCAST_CN       0x04
+#define CMD_XMIT_BCAST_CX       0x05
+#define CMD_QUE_RING_BUF_CN     0x06
+#define CMD_QUE_XRI_BUF_CX      0x07
+#define CMD_IOCB_CONTINUE_CN    0x08
+#define CMD_RET_XRI_BUF_CX      0x09
+#define CMD_ELS_REQUEST_CR      0x0A
+#define CMD_ELS_REQUEST_CX      0x0B
+#define CMD_RCV_ELS_REQ_CX      0x0D
+#define CMD_ABORT_XRI_CN        0x0E
+#define CMD_ABORT_XRI_CX        0x0F
+#define CMD_CLOSE_XRI_CN        0x10
+#define CMD_CLOSE_XRI_CX        0x11
+#define CMD_CREATE_XRI_CR       0x12
+#define CMD_CREATE_XRI_CX       0x13
+#define CMD_GET_RPI_CN          0x14
+#define CMD_XMIT_ELS_RSP_CX     0x15
+#define CMD_GET_RPI_CR          0x16
+#define CMD_XRI_ABORTED_CX      0x17
+#define CMD_FCP_IWRITE_CR       0x18
+#define CMD_FCP_IWRITE_CX       0x19
+#define CMD_FCP_IREAD_CR        0x1A
+#define CMD_FCP_IREAD_CX        0x1B
+#define CMD_FCP_ICMND_CR        0x1C
+#define CMD_FCP_ICMND_CX        0x1D
+
+#define CMD_ADAPTER_MSG         0x20
+#define CMD_ADAPTER_DUMP        0x22
+
+/*  SLI_2 IOCB Command Set */
+
+#define CMD_RCV_SEQUENCE64_CX   0x81
+#define CMD_XMIT_SEQUENCE64_CR  0x82
+#define CMD_XMIT_SEQUENCE64_CX  0x83
+#define CMD_XMIT_BCAST64_CN     0x84
+#define CMD_XMIT_BCAST64_CX     0x85
+#define CMD_QUE_RING_BUF64_CN   0x86
+#define CMD_QUE_XRI_BUF64_CX    0x87
+#define CMD_IOCB_CONTINUE64_CN  0x88
+#define CMD_RET_XRI_BUF64_CX    0x89
+#define CMD_ELS_REQUEST64_CR    0x8A
+#define CMD_ELS_REQUEST64_CX    0x8B
+#define CMD_ABORT_MXRI64_CN     0x8C
+#define CMD_RCV_ELS_REQ64_CX    0x8D
+#define CMD_XMIT_ELS_RSP64_CX   0x95
+#define CMD_FCP_IWRITE64_CR     0x98
+#define CMD_FCP_IWRITE64_CX     0x99
+#define CMD_FCP_IREAD64_CR      0x9A
+#define CMD_FCP_IREAD64_CX      0x9B
+#define CMD_FCP_ICMND64_CR      0x9C
+#define CMD_FCP_ICMND64_CX      0x9D
+
+#define CMD_GEN_REQUEST64_CR    0xC2
+#define CMD_GEN_REQUEST64_CX    0xC3
+
+#define CMD_MAX_IOCB_CMD        0xE6
+#define CMD_IOCB_MASK           0xff
+
+#define MAX_MSG_DATA            28	/* max msg data in CMD_ADAPTER_MSG iocb */
+#define ELX_MAX_ADPTMSG         32	/* max msg data */
+/*
+ *  Define Status
+ */
+#define MBX_SUCCESS                 0
+#define MBXERR_NUM_RINGS            1
+#define MBXERR_NUM_IOCBS            2
+#define MBXERR_IOCBS_EXCEEDED       3
+#define MBXERR_BAD_RING_NUMBER      4
+#define MBXERR_MASK_ENTRIES_RANGE   5
+#define MBXERR_MASKS_EXCEEDED       6
+#define MBXERR_BAD_PROFILE          7
+#define MBXERR_BAD_DEF_CLASS        8
+#define MBXERR_BAD_MAX_RESPONDER    9
+#define MBXERR_BAD_MAX_ORIGINATOR   10
+#define MBXERR_RPI_REGISTERED       11
+#define MBXERR_RPI_FULL             12
+#define MBXERR_NO_RESOURCES         13
+#define MBXERR_BAD_RCV_LENGTH       14
+#define MBXERR_DMA_ERROR            15
+#define MBXERR_ERROR                16
+#define MBX_NOT_FINISHED           255
+
+#define MBX_BUSY                   0xffffff	/* Attempted cmd to busy Mailbox */
+#define MBX_TIMEOUT                0xfffffe	/* time-out expired waiting for */
+
+/*
+ *    Begin Structure Definitions for Mailbox Commands
+ */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint8_t tval;
+	uint8_t tmask;
+	uint8_t rval;
+	uint8_t rmask;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t rmask;
+	uint8_t rval;
+	uint8_t tmask;
+	uint8_t tval;
+#endif
+} RR_REG;
+
+typedef struct {
+	uint32_t bdeAddress;
+#if BIG_ENDIAN_HW
+	uint32_t bdeReserved:4;
+	uint32_t bdeAddrHigh:4;
+	uint32_t bdeSize:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t bdeSize:24;
+	uint32_t bdeAddrHigh:4;
+	uint32_t bdeReserved:4;
+#endif
+} ULP_BDE;
+
+typedef struct ULP_BDE_64 {	/* SLI-2 */
+	union ULP_BDE_TUS {
+		uint32_t w;
+		struct {
+#if BIG_ENDIAN_HW
+			uint32_t bdeFlags:8;	/* BDE Flags 0 IS A SUPPORTED VALUE !! */
+			uint32_t bdeSize:24;	/* Size of buffer (in bytes) */
+#endif
+#if LITTLE_ENDIAN_HW
+			uint32_t bdeSize:24;	/* Size of buffer (in bytes) */
+			uint32_t bdeFlags:8;	/* BDE Flags 0 IS A SUPPORTED VALUE !! */
+#endif
+#define BUFF_USE_RSVD       0x01	/* bdeFlags */
+#define BUFF_USE_INTRPT     0x02	/* Not Implemented with LP6000 */
+#define BUFF_USE_CMND       0x04	/* Optional, 1=cmd/rsp 0=data buffer */
+#define BUFF_USE_RCV        0x08	/*  ""  "",  1=rcv buffer, 0=xmit buffer */
+#define BUFF_TYPE_32BIT     0x10	/*  ""  "",  1=32 bit addr 0=64 bit addr */
+#define BUFF_TYPE_SPECIAL   0x20	/* Not Implemented with LP6000  */
+#define BUFF_TYPE_BDL       0x40	/* Optional,  may be set in BDL */
+#define BUFF_TYPE_INVALID   0x80	/*  ""  "" */
+		} f;
+	} tus;
+	uint32_t addrLow;
+	uint32_t addrHigh;
+} ULP_BDE64;
+#define BDE64_SIZE_WORD 0
+#define BPL64_SIZE_WORD 0x40
+
+typedef struct ULP_BDL {	/* SLI-2 */
+#if BIG_ENDIAN_HW
+	uint32_t bdeFlags:8;	/* BDL Flags */
+	uint32_t bdeSize:24;	/* Size of BDL array in host memory (bytes) */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t bdeSize:24;	/* Size of BDL array in host memory (bytes) */
+	uint32_t bdeFlags:8;	/* BDL Flags */
+#endif
+	uint32_t addrLow;	/* Address 0:31 */
+	uint32_t addrHigh;	/* Address 32:63 */
+	uint32_t ulpIoTag32;	/* Can be used for 32 bit I/O Tag */
+} ULP_BDL;
+
+/* Structure for MB Command LOAD_SM and DOWN_LOAD */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t rsvd2:25;
+	uint32_t acknowledgment:1;
+	uint32_t version:1;
+	uint32_t erase_or_prog:1;
+	uint32_t update_flash:1;
+	uint32_t update_ram:1;
+	uint32_t method:1;
+	uint32_t load_cmplt:1;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t load_cmplt:1;
+	uint32_t method:1;
+	uint32_t update_ram:1;
+	uint32_t update_flash:1;
+	uint32_t erase_or_prog:1;
+	uint32_t version:1;
+	uint32_t acknowledgment:1;
+	uint32_t rsvd2:25;
+#endif
+
+#define DL_FROM_BDE     0	/* method */
+#define DL_FROM_SLIM    1
+
+#define PROGRAM_FLASH   0	/* erase_or_prog */
+#define ERASE_FLASH     1
+
+	uint32_t dl_to_adr_low;
+	uint32_t dl_to_adr_high;
+	uint32_t dl_len;
+	union {
+		uint32_t dl_from_mbx_offset;
+		ULP_BDE dl_from_bde;
+		ULP_BDE64 dl_from_bde64;
+	} un;
+
+} LOAD_SM_VAR;
+
+/* Structure for MB Command READ_NVPARM (02) */
+
+typedef struct {
+	uint32_t rsvd1[3];	/* Read as all one's */
+	uint32_t rsvd2;		/* Read as all zero's */
+	uint32_t portname[2];	/* N_PORT name */
+	uint32_t nodename[2];	/* NODE name */
+#if BIG_ENDIAN_HW
+	uint32_t pref_DID:24;
+	uint32_t hardAL_PA:8;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t hardAL_PA:8;
+	uint32_t pref_DID:24;
+#endif
+	uint32_t rsvd3[21];	/* Read as all one's */
+} READ_NV_VAR;
+
+/* Structure for MB Command WRITE_NVPARMS (03) */
+
+typedef struct {
+	uint32_t rsvd1[3];	/* Must be all one's */
+	uint32_t rsvd2;		/* Must be all zero's */
+	uint32_t portname[2];	/* N_PORT name */
+	uint32_t nodename[2];	/* NODE name */
+#if BIG_ENDIAN_HW
+	uint32_t pref_DID:24;
+	uint32_t hardAL_PA:8;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t hardAL_PA:8;
+	uint32_t pref_DID:24;
+#endif
+	uint32_t rsvd3[21];	/* Must be all one's */
+} WRITE_NV_VAR;
+
+/* Structure for MB Command RUN_BIU_DIAG (04) */
+/* Structure for MB Command RUN_BIU_DIAG64 (0x84) */
+
+typedef struct {
+	uint32_t rsvd1;
+	union {
+		struct {
+			ULP_BDE xmit_bde;
+			ULP_BDE rcv_bde;
+		} s1;
+		struct {
+			ULP_BDE64 xmit_bde64;
+			ULP_BDE64 rcv_bde64;
+		} s2;
+	} un;
+} BIU_DIAG_VAR;
+
+/* Structure for MB Command INIT_LINK (05) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t rsvd1:24;
+	uint32_t lipsr_AL_PA:8;	/* AL_PA to issue Lip Selective Reset to */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t lipsr_AL_PA:8;	/* AL_PA to issue Lip Selective Reset to */
+	uint32_t rsvd1:24;
+#endif
+
+#if BIG_ENDIAN_HW
+	uint8_t fabric_AL_PA;	/* If using a Fabric Assigned AL_PA */
+	uint8_t rsvd2;
+	uint16_t link_flags;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t link_flags;
+	uint8_t rsvd2;
+	uint8_t fabric_AL_PA;	/* If using a Fabric Assigned AL_PA */
+#endif
+#define FLAGS_LOCAL_LB               0x01	/* link_flags (=1) ENDEC loopback */
+#define FLAGS_TOPOLOGY_MODE_LOOP_PT  0x00	/* Attempt loop then pt-pt */
+#define FLAGS_TOPOLOGY_MODE_PT_PT    0x02	/* Attempt pt-pt only */
+#define FLAGS_TOPOLOGY_MODE_LOOP     0x04	/* Attempt loop only */
+#define FLAGS_TOPOLOGY_MODE_PT_LOOP  0x06	/* Attempt pt-pt then loop */
+#define FLAGS_LIRP_LILP              0x80	/* LIRP / LILP is disabled */
+
+#define FLAGS_TOPOLOGY_FAILOVER      0x0400	/* Bit 10 */
+#define FLAGS_LINK_SPEED             0x0800	/* Bit 11 */
+
+	uint32_t link_speed;	/* NEW_FEATURE */
+#define LINK_SPEED_AUTO 0	/* Auto selection */
+#define LINK_SPEED_1G   1	/* 1 Gigabaud */
+#define LINK_SPEED_2G   2	/* 2 Gigabaud */
+
+} INIT_LINK_VAR;
+
+/* Structure for MB Command DOWN_LINK (06) */
+
+typedef struct {
+	uint32_t rsvd1;
+} DOWN_LINK_VAR;
+
+/* Structure for MB Command CONFIG_LINK (07) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t cr:1;
+	uint32_t ci:1;
+	uint32_t cr_delay:6;
+	uint32_t cr_count:8;
+	uint32_t rsvd1:8;
+	uint32_t MaxBBC:8;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t MaxBBC:8;
+	uint32_t rsvd1:8;
+	uint32_t cr_count:8;
+	uint32_t cr_delay:6;
+	uint32_t ci:1;
+	uint32_t cr:1;
+#endif
+	uint32_t myId;
+	uint32_t rsvd2;
+	uint32_t edtov;
+	uint32_t arbtov;
+	uint32_t ratov;
+	uint32_t rttov;
+	uint32_t altov;
+	uint32_t crtov;
+	uint32_t citov;
+#if BIG_ENDIAN_HW
+	uint32_t rrq_enable:1;
+	uint32_t rrq_immed:1;
+	uint32_t rsvd4:29;
+	uint32_t ack0_enable:1;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t ack0_enable:1;
+	uint32_t rsvd4:29;
+	uint32_t rrq_immed:1;
+	uint32_t rrq_enable:1;
+#endif
+} CONFIG_LINK;
+
+/* Structure for MB Command PART_SLIM (08)
+ * will be removed since SLI1 is no longer supported!
+ */
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint16_t offCiocb;
+	uint16_t numCiocb;
+	uint16_t offRiocb;
+	uint16_t numRiocb;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t numCiocb;
+	uint16_t offCiocb;
+	uint16_t numRiocb;
+	uint16_t offRiocb;
+#endif
+} RING_DEF;
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t unused1:24;
+	uint32_t numRing:8;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t numRing:8;
+	uint32_t unused1:24;
+#endif
+	RING_DEF ringdef[4];
+	uint32_t hbainit;
+} PART_SLIM_VAR;
+
+/* Structure for MB Command CONFIG_RING (09) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t unused2:6;
+	uint32_t recvSeq:1;
+	uint32_t recvNotify:1;
+	uint32_t numMask:8;
+	uint32_t profile:8;
+	uint32_t unused1:4;
+	uint32_t ring:4;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t ring:4;
+	uint32_t unused1:4;
+	uint32_t profile:8;
+	uint32_t numMask:8;
+	uint32_t recvNotify:1;
+	uint32_t recvSeq:1;
+	uint32_t unused2:6;
+#endif
+#if BIG_ENDIAN_HW
+	uint16_t maxRespXchg;
+	uint16_t maxOrigXchg;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t maxOrigXchg;
+	uint16_t maxRespXchg;
+#endif
+	RR_REG rrRegs[6];
+} CONFIG_RING_VAR;
+
+/* Structure for MB Command RESET_RING (10) */
+
+typedef struct {
+	uint32_t ring_no;
+} RESET_RING_VAR;
+
+/* Structure for MB Command READ_CONFIG (11) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t cr:1;
+	uint32_t ci:1;
+	uint32_t cr_delay:6;
+	uint32_t cr_count:8;
+	uint32_t InitBBC:8;
+	uint32_t MaxBBC:8;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t MaxBBC:8;
+	uint32_t InitBBC:8;
+	uint32_t cr_count:8;
+	uint32_t cr_delay:6;
+	uint32_t ci:1;
+	uint32_t cr:1;
+#endif
+#if BIG_ENDIAN_HW
+	uint32_t topology:8;
+	uint32_t myDid:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t myDid:24;
+	uint32_t topology:8;
+#endif
+	/* Defines for topology (defined previously) */
+#if BIG_ENDIAN_HW
+	uint32_t AR:1;
+	uint32_t IR:1;
+	uint32_t rsvd1:29;
+	uint32_t ack0:1;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t ack0:1;
+	uint32_t rsvd1:29;
+	uint32_t IR:1;
+	uint32_t AR:1;
+#endif
+	uint32_t edtov;
+	uint32_t arbtov;
+	uint32_t ratov;
+	uint32_t rttov;
+	uint32_t altov;
+	uint32_t lmt;
+#define LMT_RESERVED    0x0	/* Not used */
+#define LMT_266_10bit   0x1	/*  265.625 Mbaud 10 bit iface */
+#define LMT_532_10bit   0x2	/*  531.25  Mbaud 10 bit iface */
+#define LMT_1063_10bit  0x3	/* 1062.5   Mbaud 20 bit iface */
+#define LMT_2125_10bit  0x8	/* 2125     Mbaud 10 bit iface */
+
+	uint32_t rsvd2;
+	uint32_t rsvd3;
+	uint32_t max_xri;
+	uint32_t max_iocb;
+	uint32_t max_rpi;
+	uint32_t avail_xri;
+	uint32_t avail_iocb;
+	uint32_t avail_rpi;
+	uint32_t default_rpi;
+} READ_CONFIG_VAR;
+
+/* Structure for MB Command READ_RCONFIG (12) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t rsvd2:7;
+	uint32_t recvNotify:1;
+	uint32_t numMask:8;
+	uint32_t profile:8;
+	uint32_t rsvd1:4;
+	uint32_t ring:4;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t ring:4;
+	uint32_t rsvd1:4;
+	uint32_t profile:8;
+	uint32_t numMask:8;
+	uint32_t recvNotify:1;
+	uint32_t rsvd2:7;
+#endif
+#if BIG_ENDIAN_HW
+	uint16_t maxResp;
+	uint16_t maxOrig;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t maxOrig;
+	uint16_t maxResp;
+#endif
+	RR_REG rrRegs[6];
+#if BIG_ENDIAN_HW
+	uint16_t cmdRingOffset;
+	uint16_t cmdEntryCnt;
+	uint16_t rspRingOffset;
+	uint16_t rspEntryCnt;
+	uint16_t nextCmdOffset;
+	uint16_t rsvd3;
+	uint16_t nextRspOffset;
+	uint16_t rsvd4;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t cmdEntryCnt;
+	uint16_t cmdRingOffset;
+	uint16_t rspEntryCnt;
+	uint16_t rspRingOffset;
+	uint16_t rsvd3;
+	uint16_t nextCmdOffset;
+	uint16_t rsvd4;
+	uint16_t nextRspOffset;
+#endif
+} READ_RCONF_VAR;
+
+/* Structure for MB Command READ_SPARM (13) */
+/* Structure for MB Command READ_SPARM64 (0x8D) */
+
+typedef struct {
+	uint32_t rsvd1;
+	uint32_t rsvd2;
+	union {
+		ULP_BDE sp;	/* This BDE points to SERV_PARM structure */
+		ULP_BDE64 sp64;
+	} un;
+} READ_SPARM_VAR;
+
+/* Structure for MB Command READ_STATUS (14) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t rsvd1:31;
+	uint32_t clrCounters:1;
+	uint16_t activeXriCnt;
+	uint16_t activeRpiCnt;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t clrCounters:1;
+	uint32_t rsvd1:31;
+	uint16_t activeRpiCnt;
+	uint16_t activeXriCnt;
+#endif
+	uint32_t xmitByteCnt;
+	uint32_t rcvByteCnt;
+	uint32_t xmitFrameCnt;
+	uint32_t rcvFrameCnt;
+	uint32_t xmitSeqCnt;
+	uint32_t rcvSeqCnt;
+	uint32_t totalOrigExchanges;
+	uint32_t totalRespExchanges;
+	uint32_t rcvPbsyCnt;
+	uint32_t rcvFbsyCnt;
+} READ_STATUS_VAR;
+
+/* Structure for MB Command READ_RPI (15) */
+/* Structure for MB Command READ_RPI64 (0x8F) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint16_t nextRpi;
+	uint16_t reqRpi;
+	uint32_t rsvd2:8;
+	uint32_t DID:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t reqRpi;
+	uint16_t nextRpi;
+	uint32_t DID:24;
+	uint32_t rsvd2:8;
+#endif
+	union {
+		ULP_BDE sp;
+		ULP_BDE64 sp64;
+	} un;
+
+} READ_RPI_VAR;
+
+/* Structure for MB Command READ_XRI (16) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint16_t nextXri;
+	uint16_t reqXri;
+	uint16_t rsvd1;
+	uint16_t rpi;
+	uint32_t rsvd2:8;
+	uint32_t DID:24;
+	uint32_t rsvd3:8;
+	uint32_t SID:24;
+	uint32_t rsvd4;
+	uint8_t seqId;
+	uint8_t rsvd5;
+	uint16_t seqCount;
+	uint16_t oxId;
+	uint16_t rxId;
+	uint32_t rsvd6:30;
+	uint32_t si:1;
+	uint32_t exchOrig:1;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t reqXri;
+	uint16_t nextXri;
+	uint16_t rpi;
+	uint16_t rsvd1;
+	uint32_t DID:24;
+	uint32_t rsvd2:8;
+	uint32_t SID:24;
+	uint32_t rsvd3:8;
+	uint32_t rsvd4;
+	uint16_t seqCount;
+	uint8_t rsvd5;
+	uint8_t seqId;
+	uint16_t rxId;
+	uint16_t oxId;
+	uint32_t exchOrig:1;
+	uint32_t si:1;
+	uint32_t rsvd6:30;
+#endif
+} READ_XRI_VAR;
+
+/* Structure for MB Command READ_REV (17) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t cv:1;
+	uint32_t rr:1;
+	uint32_t rsvd1:29;
+	uint32_t rv:1;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t rv:1;
+	uint32_t rsvd1:29;
+	uint32_t rr:1;
+	uint32_t cv:1;
+#endif
+	uint32_t biuRev;
+	uint32_t smRev;
+	union {
+		uint32_t smFwRev;
+		struct {
+#if BIG_ENDIAN_HW
+			uint8_t ProgType;
+			uint8_t ProgId;
+			uint16_t ProgVer:4;
+			uint16_t ProgRev:4;
+			uint16_t ProgFixLvl:2;
+			uint16_t ProgDistType:2;
+			uint16_t DistCnt:4;
+#endif
+#if LITTLE_ENDIAN_HW
+			uint16_t DistCnt:4;
+			uint16_t ProgDistType:2;
+			uint16_t ProgFixLvl:2;
+			uint16_t ProgRev:4;
+			uint16_t ProgVer:4;
+			uint8_t ProgId;
+			uint8_t ProgType;
+#endif
+		} b;
+	} un;
+	uint32_t endecRev;
+#if BIG_ENDIAN_HW
+	uint8_t feaLevelHigh;
+	uint8_t feaLevelLow;
+	uint8_t fcphHigh;
+	uint8_t fcphLow;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t fcphLow;
+	uint8_t fcphHigh;
+	uint8_t feaLevelLow;
+	uint8_t feaLevelHigh;
+#endif
+	uint32_t postKernRev;
+	uint32_t opFwRev;
+	uint8_t opFwName[16];
+	uint32_t sli1FwRev;
+	uint8_t sli1FwName[16];
+	uint32_t sli2FwRev;
+	uint8_t sli2FwName[16];
+	uint32_t rsvd2;
+	uint32_t RandomData[7];
+} READ_REV_VAR;
+
+#define rxSeqRev postKernRev
+#define txSeqRev opFwRev
+
+/* Structure for MB Command READ_LINK_STAT (18) */
+
+typedef struct {
+	uint32_t rsvd1;
+	uint32_t linkFailureCnt;
+	uint32_t lossSyncCnt;
+
+	uint32_t lossSignalCnt;
+	uint32_t primSeqErrCnt;
+	uint32_t invalidXmitWord;
+	uint32_t crcCnt;
+	uint32_t primSeqTimeout;
+	uint32_t elasticOverrun;
+	uint32_t arbTimeout;
+} READ_LNK_VAR;
+
+/* Structure for MB Command REG_LOGIN (19) */
+/* Structure for MB Command REG_LOGIN64 (0x93) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint16_t rsvd1;
+	uint16_t rpi;
+	uint32_t rsvd2:8;
+	uint32_t did:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t rpi;
+	uint16_t rsvd1;
+	uint32_t did:24;
+	uint32_t rsvd2:8;
+#endif
+	union {
+		ULP_BDE sp;
+		ULP_BDE64 sp64;
+	} un;
+
+} REG_LOGIN_VAR;
+
+/* Word 30 contents for REG_LOGIN */
+typedef union {
+	struct {
+#if BIG_ENDIAN_HW
+		uint16_t rsvd1:12;
+		uint16_t wd30_class:4;
+		uint16_t xri;
+#endif
+#if LITTLE_ENDIAN_HW
+		uint16_t xri;
+		uint16_t wd30_class:4;
+		uint16_t rsvd1:12;
+#endif
+	} f;
+	uint32_t word;
+} REG_WD30;
+
+/* Structure for MB Command UNREG_LOGIN (20) */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint16_t rsvd1;
+	uint16_t rpi;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t rpi;
+	uint16_t rsvd1;
+#endif
+} UNREG_LOGIN_VAR;
+
+/* Structure for MB Command UNREG_D_ID (0x23) */
+
+typedef struct {
+	uint32_t did;
+} UNREG_D_ID_VAR;
+
+/* Structure for MB Command READ_LA (21) */
+/* Structure for MB Command READ_LA64 (0x95) */
+
+typedef struct {
+	uint32_t eventTag;	/* Event tag */
+#if BIG_ENDIAN_HW
+	uint32_t rsvd1:22;
+	uint32_t pb:1;
+	uint32_t il:1;
+	uint32_t attType:8;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t attType:8;
+	uint32_t il:1;
+	uint32_t pb:1;
+	uint32_t rsvd1:22;
+#endif
+#define AT_RESERVED    0x00	/* Reserved - attType */
+#define AT_LINK_UP     0x01	/* Link is up */
+#define AT_LINK_DOWN   0x02	/* Link is down */
+#if BIG_ENDIAN_HW
+	uint8_t granted_AL_PA;
+	uint8_t lipAlPs;
+	uint8_t lipType;
+	uint8_t topology;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t topology;
+	uint8_t lipType;
+	uint8_t lipAlPs;
+	uint8_t granted_AL_PA;
+#endif
+#define LT_PORT_INIT    0x00	/* An L_PORT initing (F7, AL_PS) - lipType */
+#define LT_PORT_ERR     0x01	/* Err @L_PORT rcv'er (F8, AL_PS) */
+#define LT_RESET_APORT  0x02	/* Lip Reset of some other port */
+#define LT_RESET_MYPORT 0x03	/* Lip Reset of my port */
+#define TOPOLOGY_PT_PT 0x01	/* Topology is pt-pt / pt-fabric */
+#define TOPOLOGY_LOOP  0x02	/* Topology is FC-AL */
+
+	union {
+		ULP_BDE lilpBde;	/* This BDE points to a 128 byte buffer to */
+		/* store the LILP AL_PA position map into */
+		ULP_BDE64 lilpBde64;
+	} un;
+#if BIG_ENDIAN_HW
+	uint32_t Dlu:1;
+	uint32_t Dtf:1;
+	uint32_t Drsvd2:14;
+	uint32_t DlnkSpeed:8;
+	uint32_t DnlPort:4;
+	uint32_t Dtx:2;
+	uint32_t Drx:2;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t Drx:2;
+	uint32_t Dtx:2;
+	uint32_t DnlPort:4;
+	uint32_t DlnkSpeed:8;
+	uint32_t Drsvd2:14;
+	uint32_t Dtf:1;
+	uint32_t Dlu:1;
+#endif
+#if BIG_ENDIAN_HW
+	uint32_t Ulu:1;
+	uint32_t Utf:1;
+	uint32_t Ursvd2:14;
+	uint32_t UlnkSpeed:8;
+	uint32_t UnlPort:4;
+	uint32_t Utx:2;
+	uint32_t Urx:2;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t Urx:2;
+	uint32_t Utx:2;
+	uint32_t UnlPort:4;
+	uint32_t UlnkSpeed:8;
+	uint32_t Ursvd2:14;
+	uint32_t Utf:1;
+	uint32_t Ulu:1;
+#endif
+#define LA_1GHZ_LINK   4	/* lnkSpeed */
+#define LA_2GHZ_LINK   8	/* lnkSpeed */
+
+} READ_LA_VAR;
+
+/* Structure for MB Command CLEAR_LA (22) */
+
+typedef struct {
+	uint32_t eventTag;	/* Event tag */
+	uint32_t rsvd1;
+} CLEAR_LA_VAR;
+
+/* Structure for MB Command DUMP */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t rsvd:25;
+	uint32_t ra:1;
+	uint32_t co:1;
+	uint32_t cv:1;
+	uint32_t type:4;
+	uint32_t entry_index:16;
+	uint32_t region_id:16;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t type:4;
+	uint32_t cv:1;
+	uint32_t co:1;
+	uint32_t ra:1;
+	uint32_t rsvd:25;
+	uint32_t region_id:16;
+	uint32_t entry_index:16;
+#endif
+	uint32_t rsvd1;
+	uint32_t word_cnt;
+	uint32_t resp_offset;
+} DUMP_VAR;
+
+#define  DMP_MEM_REG             0x1
+#define  DMP_NV_PARAMS           0x2
+
+#define  DMP_REGION_VPD          0xe
+#define  DMP_VPD_SIZE            0x100
+
+/* Structure for MB Command CONFIG_PORT (0x88) */
+
+typedef struct {
+	uint32_t pcbLen;
+	uint32_t pcbLow;	/* bit 31:0  of memory based port config block */
+	uint32_t pcbHigh;	/* bit 63:32 of memory based port config block */
+	uint32_t hbainit[5];
+} CONFIG_PORT_VAR;
+
+/* SLI-2 Port Control Block */
+
+/* SLIM POINTER */
+#define SLIMOFF 0x30		/* WORD */
+
+typedef struct _SLI2_RDSC {
+	uint32_t cmdEntries;
+	uint32_t cmdAddrLow;
+	uint32_t cmdAddrHigh;
+
+	uint32_t rspEntries;
+	uint32_t rspAddrLow;
+	uint32_t rspAddrHigh;
+} SLI2_RDSC;
+
+typedef struct _PCB {
+#if BIG_ENDIAN_HW
+	uint32_t type:8;
+#define TYPE_NATIVE_SLI2       0x01;
+	uint32_t feature:8;
+#define FEATURE_INITIAL_SLI2   0x01;
+	uint32_t rsvd:12;
+	uint32_t maxRing:4;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t maxRing:4;
+	uint32_t rsvd:12;
+	uint32_t feature:8;
+#define FEATURE_INITIAL_SLI2   0x01;
+	uint32_t type:8;
+#define TYPE_NATIVE_SLI2       0x01;
+#endif
+
+	uint32_t mailBoxSize;
+	uint32_t mbAddrLow;
+	uint32_t mbAddrHigh;
+
+	uint32_t hgpAddrLow;
+	uint32_t hgpAddrHigh;
+
+	uint32_t pgpAddrLow;
+	uint32_t pgpAddrHigh;
+	SLI2_RDSC rdsc[MAX_RINGS];
+} PCB_t;
+
+/* NEW_FEATURE */
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint32_t rsvd0:27;
+	uint32_t discardFarp:1;
+	uint32_t IPEnable:1;
+	uint32_t nodeName:1;
+	uint32_t portName:1;
+	uint32_t filterEnable:1;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t filterEnable:1;
+	uint32_t portName:1;
+	uint32_t nodeName:1;
+	uint32_t IPEnable:1;
+	uint32_t discardFarp:1;
+	uint32_t rsvd:27;
+#endif
+	uint8_t portname[8];	/* Used to be NAME_TYPE */
+	uint8_t nodename[8];
+	uint32_t rsvd1;
+	uint32_t rsvd2;
+	uint32_t rsvd3;
+	uint32_t IPAddress;
+} CONFIG_FARP_VAR;
+
+/* Union of all Mailbox Command types */
+#define MAILBOX_CMD_WSIZE 32
+
+typedef union {
+	uint32_t varWords[MAILBOX_CMD_WSIZE - 1];
+	LOAD_SM_VAR varLdSM;	/* cmd =  1 (LOAD_SM)        */
+	READ_NV_VAR varRDnvp;	/* cmd =  2 (READ_NVPARMS)   */
+	WRITE_NV_VAR varWTnvp;	/* cmd =  3 (WRITE_NVPARMS)  */
+	BIU_DIAG_VAR varBIUdiag;	/* cmd =  4 (RUN_BIU_DIAG)   */
+	INIT_LINK_VAR varInitLnk;	/* cmd =  5 (INIT_LINK)      */
+	DOWN_LINK_VAR varDwnLnk;	/* cmd =  6 (DOWN_LINK)      */
+	CONFIG_LINK varCfgLnk;	/* cmd =  7 (CONFIG_LINK)    */
+	PART_SLIM_VAR varSlim;	/* cmd =  8 (PART_SLIM)      */
+	CONFIG_RING_VAR varCfgRing;	/* cmd =  9 (CONFIG_RING)    */
+	RESET_RING_VAR varRstRing;	/* cmd = 10 (RESET_RING)     */
+	READ_CONFIG_VAR varRdConfig;	/* cmd = 11 (READ_CONFIG)    */
+	READ_RCONF_VAR varRdRConfig;	/* cmd = 12 (READ_RCONFIG)   */
+	READ_SPARM_VAR varRdSparm;	/* cmd = 13 (READ_SPARM(64)) */
+	READ_STATUS_VAR varRdStatus;	/* cmd = 14 (READ_STATUS)    */
+	READ_RPI_VAR varRdRPI;	/* cmd = 15 (READ_RPI(64))   */
+	READ_XRI_VAR varRdXRI;	/* cmd = 16 (READ_XRI)       */
+	READ_REV_VAR varRdRev;	/* cmd = 17 (READ_REV)       */
+	READ_LNK_VAR varRdLnk;	/* cmd = 18 (READ_LNK_STAT)  */
+	REG_LOGIN_VAR varRegLogin;	/* cmd = 19 (REG_LOGIN(64))  */
+	UNREG_LOGIN_VAR varUnregLogin;	/* cmd = 20 (UNREG_LOGIN)    */
+	READ_LA_VAR varReadLA;	/* cmd = 21 (READ_LA(64))    */
+	CLEAR_LA_VAR varClearLA;	/* cmd = 22 (CLEAR_LA)       */
+	DUMP_VAR varDmp;	/* Warm Start DUMP mbx cmd   */
+	UNREG_D_ID_VAR varUnregDID;	/* cmd = 0x23 (UNREG_D_ID)   */
+	CONFIG_FARP_VAR varCfgFarp;	/* cmd = 0x25 (CONFIG_FARP)  NEW_FEATURE */
+	CONFIG_PORT_VAR varCfgPort;	/* cmd = 0x88 (CONFIG_PORT)  */
+} MAILVARIANTS;
+
+/*
+ * SLI-2 specific structures
+ */
+
+typedef struct {
+	uint32_t cmdPutInx;
+	uint32_t rspGetInx;
+} HGP;
+
+typedef struct {
+	uint32_t cmdGetInx;
+	uint32_t rspPutInx;
+} PGP;
+
+typedef struct _SLI2_DESC {
+	HGP host[MAX_RINGS];
+	uint32_t unused1[16];
+	PGP port[MAX_RINGS];
+} SLI2_DESC;
+
+typedef union {
+	SLI2_DESC s2;
+} SLI_VAR;
+
+typedef volatile struct {
+#if BIG_ENDIAN_HW
+	uint16_t mbxStatus;
+	uint8_t mbxCommand;
+	uint8_t mbxReserved:6;
+	uint8_t mbxHc:1;
+	uint8_t mbxOwner:1;	/* Low order bit first word */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t mbxOwner:1;	/* Low order bit first word */
+	uint8_t mbxHc:1;
+	uint8_t mbxReserved:6;
+	uint8_t mbxCommand;
+	uint16_t mbxStatus;
+#endif
+	MAILVARIANTS un;
+	SLI_VAR us;
+} MAILBOX_t, *PMAILBOX_t;
+
+/*
+ *    Begin Structure Definitions for IOCB Commands
+ */
+
+typedef struct {
+#if BIG_ENDIAN_HW
+	uint8_t statAction;
+	uint8_t statRsn;
+	uint8_t statBaExp;
+	uint8_t statLocalError;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t statLocalError;
+	uint8_t statBaExp;
+	uint8_t statRsn;
+	uint8_t statAction;
+#endif
+	/* statAction  FBSY reason codes */
+#define FBSY_RSN_MASK   0xF0	/* Rsn stored in upper nibble */
+#define FBSY_FABRIC_BSY 0x10	/* F_bsy due to Fabric BSY */
+#define FBSY_NPORT_BSY  0x30	/* F_bsy due to N_port BSY */
+
+	/* statAction  PBSY action codes */
+#define PBSY_ACTION1    0x01	/* Sequence terminated - retry */
+#define PBSY_ACTION2    0x02	/* Sequence active - retry */
+
+	/* statAction  P/FRJT action codes */
+#define RJT_RETRYABLE   0x01	/* Retryable class of error */
+#define RJT_NO_RETRY    0x02	/* Non-Retryable class of error */
+
+	/* statRsn  LS_RJT reason codes defined in LS_RJT structure */
+
+	/* statRsn  P_BSY reason codes */
+#define PBSY_NPORT_BSY  0x01	/* Physical N_port BSY */
+#define PBSY_RESRCE_BSY 0x03	/* N_port resource BSY */
+#define PBSY_VU_BSY     0xFF	/* See VU field for rsn */
+
+	/* statRsn  P/F_RJT reason codes */
+#define RJT_BAD_D_ID       0x01	/* Invalid D_ID field */
+#define RJT_BAD_S_ID       0x02	/* Invalid S_ID field */
+#define RJT_UNAVAIL_TEMP   0x03	/* N_Port unavailable temp. */
+#define RJT_UNAVAIL_PERM   0x04	/* N_Port unavailable perm. */
+#define RJT_UNSUP_CLASS    0x05	/* Class not supported */
+#define RJT_DELIM_ERR      0x06	/* Delimiter usage error */
+#define RJT_UNSUP_TYPE     0x07	/* Type not supported */
+#define RJT_BAD_CONTROL    0x08	/* Invalid link conrtol */
+#define RJT_BAD_RCTL       0x09	/* R_CTL invalid */
+#define RJT_BAD_FCTL       0x0A	/* F_CTL invalid */
+#define RJT_BAD_OXID       0x0B	/* OX_ID invalid */
+#define RJT_BAD_RXID       0x0C	/* RX_ID invalid */
+#define RJT_BAD_SEQID      0x0D	/* SEQ_ID invalid */
+#define RJT_BAD_DFCTL      0x0E	/* DF_CTL invalid */
+#define RJT_BAD_SEQCNT     0x0F	/* SEQ_CNT invalid */
+#define RJT_BAD_PARM       0x10	/* Param. field invalid */
+#define RJT_XCHG_ERR       0x11	/* Exchange error */
+#define RJT_PROT_ERR       0x12	/* Protocol error */
+#define RJT_BAD_LENGTH     0x13	/* Invalid Length */
+#define RJT_UNEXPECTED_ACK 0x14	/* Unexpected ACK */
+#define RJT_LOGIN_REQUIRED 0x16	/* Login required */
+#define RJT_TOO_MANY_SEQ   0x17	/* Excessive sequences */
+#define RJT_XCHG_NOT_STRT  0x18	/* Exchange not started */
+#define RJT_UNSUP_SEC_HDR  0x19	/* Security hdr not supported */
+#define RJT_UNAVAIL_PATH   0x1A	/* Fabric Path not available */
+#define RJT_VENDOR_UNIQUE  0xFF	/* Vendor unique error */
+
+	/* statRsn  BA_RJT reason codes */
+#define BARJT_BAD_CMD_CODE 0x01	/* Invalid command code */
+#define BARJT_LOGICAL_ERR  0x03	/* Logical error */
+#define BARJT_LOGICAL_BSY  0x05	/* Logical busy */
+#define BARJT_PROTOCOL_ERR 0x07	/* Protocol error */
+#define BARJT_VU_ERR       0xFF	/* Vendor unique error */
+
+	/* LS_RJT reason explanation defined in LS_RJT structure */
+
+	/* BA_RJT reason explanation */
+#define BARJT_EXP_INVALID_ID  0x01	/* Invalid OX_ID/RX_ID */
+#define BARJT_EXP_ABORT_SEQ   0x05	/* Abort SEQ, no more info */
+
+	/* FireFly localy detected errors */
+#define IOERR_SUCCESS                 0x00	/* statLocalError */
+#define IOERR_MISSING_CONTINUE        0x01
+#define IOERR_SEQUENCE_TIMEOUT        0x02
+#define IOERR_INTERNAL_ERROR          0x03
+#define IOERR_INVALID_RPI             0x04
+#define IOERR_NO_XRI                  0x05
+#define IOERR_ILLEGAL_COMMAND         0x06
+#define IOERR_XCHG_DROPPED            0x07
+#define IOERR_ILLEGAL_FIELD           0x08
+#define IOERR_BAD_CONTINUE            0x09
+#define IOERR_TOO_MANY_BUFFERS        0x0A
+#define IOERR_RCV_BUFFER_WAITING      0x0B
+#define IOERR_NO_CONNECTION           0x0C
+#define IOERR_TX_DMA_FAILED           0x0D
+#define IOERR_RX_DMA_FAILED           0x0E
+#define IOERR_ILLEGAL_FRAME           0x0F
+#define IOERR_EXTRA_DATA              0x10
+#define IOERR_NO_RESOURCES            0x11
+#define IOERR_RESERVED                0x12
+#define IOERR_ILLEGAL_LENGTH          0x13
+#define IOERR_UNSUPPORTED_FEATURE     0x14
+#define IOERR_ABORT_IN_PROGRESS       0x15
+#define IOERR_ABORT_REQUESTED         0x16
+#define IOERR_RECEIVE_BUFFER_TIMEOUT  0x17
+#define IOERR_LOOP_OPEN_FAILURE       0x18
+#define IOERR_RING_RESET              0x19
+#define IOERR_LINK_DOWN               0x1A
+#define IOERR_CORRUPTED_DATA          0x1B
+#define IOERR_CORRUPTED_RPI           0x1C
+#define IOERR_OUT_OF_ORDER_DATA       0x1D
+#define IOERR_OUT_OF_ORDER_ACK        0x1E
+#define IOERR_DUP_FRAME               0x1F
+#define IOERR_LINK_CONTROL_FRAME      0x20	/* ACK_N received */
+#define IOERR_BAD_HOST_ADDRESS        0x21
+#define IOERR_RCV_HDRBUF_WAITING      0x22
+#define IOERR_MISSING_HDR_BUFFER      0x23
+#define IOERR_MSEQ_CHAIN_CORRUPTED    0x24
+#define IOERR_ABORTMULT_REQUESTED     0x25
+#define IOERR_BUFFER_SHORTAGE         0x28
+#define IOERR_DEFAULT                 0x29
+#define IOERR_CNT                     0x2A
+
+#define IOERR_SLI_DOWN                0xF0	/* ulpStatus  - Driver defined */
+#define IOERR_SLI_BRESET              0xF1
+#define IOERR_SLI_ABORTED             0xF2
+} PARM_ERR;
+
+typedef union {
+	struct {
+#if BIG_ENDIAN_HW
+		uint8_t Rctl;	/* R_CTL field */
+		uint8_t Type;	/* TYPE field */
+		uint8_t Dfctl;	/* DF_CTL field */
+		uint8_t Fctl;	/* Bits 0-7 of IOCB word 5 */
+#endif
+#if LITTLE_ENDIAN_HW
+		uint8_t Fctl;	/* Bits 0-7 of IOCB word 5 */
+		uint8_t Dfctl;	/* DF_CTL field */
+		uint8_t Type;	/* TYPE field */
+		uint8_t Rctl;	/* R_CTL field */
+#endif
+
+#define BC      0x02		/* Broadcast Received  - Fctl */
+#define SI      0x04		/* Sequence Initiative */
+#define LA      0x08		/* Ignore Link Attention state */
+#define LS      0x80		/* Last Sequence */
+	} hcsw;
+	uint32_t reserved;
+} WORD5;
+
+/* IOCB Command template for a generic response */
+typedef struct {
+	uint32_t reserved[4];
+	PARM_ERR perr;
+} GENERIC_RSP;
+
+/* IOCB Command template for XMIT / XMIT_BCAST / RCV_SEQUENCE / XMIT_ELS */
+typedef struct {
+	ULP_BDE xrsqbde[2];
+	uint32_t xrsqRo;	/* Starting Relative Offset */
+	WORD5 w5;		/* Header control/status word */
+} XR_SEQ_FIELDS;
+
+/* IOCB Command template for ELS_REQUEST */
+typedef struct {
+	ULP_BDE elsReq;
+	ULP_BDE elsRsp;
+#if BIG_ENDIAN_HW
+	uint32_t word4Rsvd:7;
+	uint32_t fl:1;
+	uint32_t myID:24;
+	uint32_t word5Rsvd:8;
+	uint32_t remoteID:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t myID:24;
+	uint32_t fl:1;
+	uint32_t word4Rsvd:7;
+	uint32_t remoteID:24;
+	uint32_t word5Rsvd:8;
+#endif
+} ELS_REQUEST;
+
+/* IOCB Command template for RCV_ELS_REQ */
+typedef struct {
+	ULP_BDE elsReq[2];
+	uint32_t parmRo;
+#if BIG_ENDIAN_HW
+	uint32_t word5Rsvd:8;
+	uint32_t remoteID:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t remoteID:24;
+	uint32_t word5Rsvd:8;
+#endif
+} RCV_ELS_REQ;
+
+/* IOCB Command template for ABORT / CLOSE_XRI */
+typedef struct {
+	uint32_t rsvd[3];
+	uint32_t abortType;
+#define ABORT_TYPE_ABTX  0x00000000
+#define ABORT_TYPE_ABTS  0x00000001
+	uint32_t parm;
+#if BIG_ENDIAN_HW
+	uint16_t abortContextTag;	/* ulpContext from command to abort/close */
+	uint16_t abortIoTag;	/* ulpIoTag from command to abort/close */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t abortIoTag;	/* ulpIoTag from command to abort/close */
+	uint16_t abortContextTag;	/* ulpContext from command to abort/close */
+#endif
+} AC_XRI;
+
+/* IOCB Command template for ABORT_MXRI64 */
+typedef struct {
+	uint32_t rsvd[3];
+	uint32_t abortType;
+	uint32_t parm;
+	uint32_t iotag32;
+} A_MXRI64;
+
+/* IOCB Command template for GET_RPI */
+typedef struct {
+	uint32_t rsvd[4];
+	uint32_t parmRo;
+#if BIG_ENDIAN_HW
+	uint32_t word5Rsvd:8;
+	uint32_t remoteID:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t remoteID:24;
+	uint32_t word5Rsvd:8;
+#endif
+} GET_RPI;
+
+/* IOCB Command template for all FCP Initiator commands */
+typedef struct {
+	ULP_BDE fcpi_cmnd;	/* FCP_CMND payload descriptor */
+	ULP_BDE fcpi_rsp;	/* Rcv buffer */
+	uint32_t fcpi_parm;
+	uint32_t fcpi_XRdy;	/* transfer ready for IWRITE */
+} FCPI_FIELDS;
+
+/* IOCB Command template for all FCP Target commands */
+typedef struct {
+	ULP_BDE fcpt_Buffer[2];	/* FCP_CMND payload descriptor */
+	uint32_t fcpt_Offset;
+	uint32_t fcpt_Length;	/* transfer ready for IWRITE */
+} FCPT_FIELDS;
+
+/* SLI-2 IOCB structure definitions */
+
+/* IOCB Command template for 64 bit XMIT / XMIT_BCAST / XMIT_ELS */
+typedef struct {
+	ULP_BDL bdl;
+	uint32_t xrsqRo;	/* Starting Relative Offset */
+	WORD5 w5;		/* Header control/status word */
+} XMT_SEQ_FIELDS64;
+
+/* IOCB Command template for 64 bit RCV_SEQUENCE64 */
+typedef struct {
+	ULP_BDE64 rcvBde;
+	uint32_t rsvd1;
+	uint32_t xrsqRo;	/* Starting Relative Offset */
+	WORD5 w5;		/* Header control/status word */
+} RCV_SEQ_FIELDS64;
+
+/* IOCB Command template for ELS_REQUEST64 */
+typedef struct {
+	ULP_BDL bdl;
+#if BIG_ENDIAN_HW
+	uint32_t word4Rsvd:7;
+	uint32_t fl:1;
+	uint32_t myID:24;
+	uint32_t word5Rsvd:8;
+	uint32_t remoteID:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t myID:24;
+	uint32_t fl:1;
+	uint32_t word4Rsvd:7;
+	uint32_t remoteID:24;
+	uint32_t word5Rsvd:8;
+#endif
+} ELS_REQUEST64;
+
+/* IOCB Command template for GEN_REQUEST64 */
+typedef struct {
+	ULP_BDL bdl;
+	uint32_t xrsqRo;	/* Starting Relative Offset */
+	WORD5 w5;		/* Header control/status word */
+} GEN_REQUEST64;
+
+/* IOCB Command template for RCV_ELS_REQ64 */
+typedef struct {
+	ULP_BDE64 elsReq;
+	uint32_t rcvd1;
+	uint32_t parmRo;
+#if BIG_ENDIAN_HW
+	uint32_t word5Rsvd:8;
+	uint32_t remoteID:24;
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t remoteID:24;
+	uint32_t word5Rsvd:8;
+#endif
+} RCV_ELS_REQ64;
+
+/* IOCB Command template for all 64 bit FCP Initiator commands */
+typedef struct {
+	ULP_BDL bdl;
+	uint32_t fcpi_parm;
+	uint32_t fcpi_XRdy;	/* transfer ready for IWRITE */
+} FCPI_FIELDS64;
+
+/* IOCB Command template for all 64 bit FCP Target commands */
+typedef struct {
+	ULP_BDL bdl;
+	uint32_t fcpt_Offset;
+	uint32_t fcpt_Length;	/* transfer ready for IWRITE */
+} FCPT_FIELDS64;
+
+typedef volatile struct _IOCB {	/* IOCB structure */
+	union {
+		GENERIC_RSP grsp;	/* Generic response */
+		XR_SEQ_FIELDS xrseq;	/* XMIT / BCAST / RCV_SEQUENCE cmd */
+		ULP_BDE cont[3];	/* up to 3 continuation bdes */
+		RCV_ELS_REQ rcvels;	/* RCV_ELS_REQ template */
+		AC_XRI acxri;	/* ABORT / CLOSE_XRI template */
+		A_MXRI64 amxri;	/* abort multiple xri command overlay */
+		GET_RPI getrpi;	/* GET_RPI template */
+		FCPI_FIELDS fcpi;	/* FCP Initiator template */
+		FCPT_FIELDS fcpt;	/* FCP target template */
+
+		/* SLI-2 structures */
+
+		ULP_BDE64 cont64[2];	/* up to 2 64 bit continuation bde_64s */
+		ELS_REQUEST64 elsreq64;	/* ELS_REQUEST template */
+		GEN_REQUEST64 genreq64;	/* GEN_REQUEST template */
+		RCV_ELS_REQ64 rcvels64;	/* RCV_ELS_REQ template */
+		XMT_SEQ_FIELDS64 xseq64;	/* XMIT / BCAST cmd */
+		FCPI_FIELDS64 fcpi64;	/* FCP 64 bit Initiator template */
+		FCPT_FIELDS64 fcpt64;	/* FCP 64 bit target template */
+
+		uint32_t ulpWord[IOCB_WORD_SZ - 2];	/* generic 6 'words' */
+	} un;
+	union {
+		struct {
+#if BIG_ENDIAN_HW
+			uint16_t ulpContext;	/* High order bits word 6 */
+			uint16_t ulpIoTag;	/* Low  order bits word 6 */
+#endif
+#if LITTLE_ENDIAN_HW
+			uint16_t ulpIoTag;	/* Low  order bits word 6 */
+			uint16_t ulpContext;	/* High order bits word 6 */
+#endif
+		} t1;
+		struct {
+#if BIG_ENDIAN_HW
+			uint16_t ulpContext;	/* High order bits word 6 */
+			uint16_t ulpIoTag1:2;	/* Low  order bits word 6 */
+			uint16_t ulpIoTag0:14;	/* Low  order bits word 6 */
+#endif
+#if LITTLE_ENDIAN_HW
+			uint16_t ulpIoTag0:14;	/* Low  order bits word 6 */
+			uint16_t ulpIoTag1:2;	/* Low  order bits word 6 */
+			uint16_t ulpContext;	/* High order bits word 6 */
+#endif
+		} t2;
+	} un1;
+#define ulpContext un1.t1.ulpContext
+#define ulpIoTag   un1.t1.ulpIoTag
+#define ulpIoTag0  un1.t2.ulpIoTag0
+#define ulpDelayXmit  un1.t2.ulpIoTag1
+#define IOCB_DELAYXMIT_MSK 0x3000
+#if BIG_ENDIAN_HW
+	uint32_t ulpTimeout:8;
+	uint32_t ulpXS:1;
+	uint32_t ulpFCP2Rcvy:1;
+	uint32_t ulpPU:2;
+	uint32_t ulpIr:1;
+	uint32_t ulpClass:3;
+	uint32_t ulpCommand:8;
+	uint32_t ulpStatus:4;
+	uint32_t ulpBdeCount:2;
+	uint32_t ulpLe:1;
+	uint32_t ulpOwner:1;	/* Low order bit word 7 */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint32_t ulpOwner:1;	/* Low order bit word 7 */
+	uint32_t ulpLe:1;
+	uint32_t ulpBdeCount:2;
+	uint32_t ulpStatus:4;
+	uint32_t ulpCommand:8;
+	uint32_t ulpClass:3;
+	uint32_t ulpIr:1;
+	uint32_t ulpPU:2;
+	uint32_t ulpFCP2Rcvy:1;
+	uint32_t ulpXS:1;
+	uint32_t ulpTimeout:8;
+#endif
+
+#define IOCB_FCP           1	/* IOCB is used for FCP ELS cmds - ulpRsvByte */
+#define IOCB_IP            2	/* IOCB is used for IP ELS cmds */
+#define PARM_UNUSED        0	/* PU field (Word 4) not used */
+#define PARM_REL_OFF       1	/* PU field (Word 4) = R. O. */
+#define PARM_READ_CHECK    2	/* PU field (Word 4) = Data Transfer Length */
+#define CLASS1             0	/* Class 1 */
+#define CLASS2             1	/* Class 2 */
+#define CLASS3             2	/* Class 3 */
+#define CLASS_FCP_INTERMIX 7	/* FCP Data->Cls 1, all else->Cls 2 */
+
+#define IOSTAT_SUCCESS         0x0	/* ulpStatus  - HBA defined */
+#define IOSTAT_FCP_RSP_ERROR   0x1
+#define IOSTAT_REMOTE_STOP     0x2
+#define IOSTAT_LOCAL_REJECT    0x3
+#define IOSTAT_NPORT_RJT       0x4
+#define IOSTAT_FABRIC_RJT      0x5
+#define IOSTAT_NPORT_BSY       0x6
+#define IOSTAT_FABRIC_BSY      0x7
+#define IOSTAT_INTERMED_RSP    0x8
+#define IOSTAT_LS_RJT          0x9
+#define IOSTAT_BA_RJT          0xA
+#define IOSTAT_DRIVER_REJECT   0xB	/* ulpStatus  - Driver defined */
+#define IOSTAT_ISCSI_REJECT    0xC
+#define IOSTAT_DEFAULT         0xD
+#define IOSTAT_CNT             0xE
+
+} IOCB_t, *PIOCB_t;
+
+/* Up to 244 IOCBs will fit into 8k 
+ * 256 (MAILBOX_t) + 140 (PCB_t) + ( 32 (IOCB_t) * 240 ) = <8192
+ */
+#define SLI2_SLIM_SIZE   8192
+
+/* Maximum IOCBs that will fit in SLI2 slim */
+#define MAX_SLI2_IOCB    240
+
+typedef struct {
+	union {
+		uint8_t sli2slim[SLI2_SLIM_SIZE];
+		struct {
+			MAILBOX_t mbx;
+			PCB_t pcb;
+			IOCB_t IOCBs[MAX_SLI2_IOCB];
+		} slim;
+	} un;
+} SLI2_SLIM_t;
+
+#endif				/* _H_ELX_HW */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_ioctl.h linux-2.6.3/drivers/scsi/lpfc/elx_ioctl.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_ioctl.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_ioctl.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,144 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_IOCTL
+#define _H_ELX_IOCTL
+
+#define _ELX_DFC_64BIT 1
+
+#ifdef BITS_PER_LONG
+#if BITS_PER_LONG < 64
+#undef _ELX_DFC_64BIT
+#endif
+#endif
+
+#ifdef i386
+#undef _ELX_DFC_64BIT
+#endif
+
+#ifdef powerpc
+#ifndef CONFIG_PPC64
+#undef _ELX_DFC_64BIT
+#endif
+#endif
+
+/* ELX Ioctls() 0x00 - 0x3F. Redefine later when macro IOCTL_WORD is used */
+
+/* ELX_FIRST_COMMAND_USED		0x00	    First defines Ioctl used  */
+#define ELX_DISPLAY_PCI_ALL		0x00	/* Display configuration registers */
+#define ELX_WRITE_PCI             	0x01	/* Write to PCI */
+#define ELX_WRITE_HC             	0x02	/* Write to Host Control register */
+#define ELX_WRITE_HS              	0x03	/* Write to Host Status register */
+#define ELX_WRITE_HA              	0x04	/* Write to Host attention register */
+#define ELX_WRITE_CA              	0x05	/* Write capacity of target */
+#define ELX_READ_PCI              	0x06	/* Read from PCI */
+#define ELX_READ_HC               	0x07	/* Read Host Control register */
+#define ELX_READ_HS               	0x08	/* Read Host Status register */
+#define ELX_READ_HA               	0x09	/* Read Host Attention register */
+#define ELX_READ_CA               	0x0a	/* Read Capacity of target */
+#define ELX_READ_MB               	0x0b	/* Read mailbox information */
+
+/* ELX COMMAND POSITION 0xc available.  Used to be Read ring information. */
+
+#define ELX_READ_MEM              	0x0d	/* Read memory */
+#define ELX_READ_IOCB             	0x0e	/* Read IOCB information */
+
+/* ELX COMMAND POSITION 0xf available. */
+
+#define ELX_READ_MEMSEG           	0x11	/* Get  memory segment info */
+#define ELX_MBOX                  	0x12	/* Issue a MB cmd */
+#define ELX_RESET                 	0x13	/* Reset the adapter */
+#define ELX_READ_HBA	           	0x14	/* Get adapter info */
+
+/* ELX COMMAND POSITION 0x15 available.  Used to be Get NDD stats. */
+
+#define ELX_WRITE_MEM             	0x16	/* Write to SLIM memory */
+#define ELX_WRITE_CTLREG          	0x17	/* Write to Control register */
+#define ELX_READ_CTLREG           	0x18	/* Read from Control control register */
+#define ELX_INITBRDS              	0x19	/* Initialize the adapters */
+#define ELX_SETDIAG              	0x1a	/* Set/get board online/offline */
+#define ELX_INST			0x1b	/* get instance info */
+
+#define ELX_DEVP                	0x1c	/* Get Device infotmation */
+
+#define ELX_READ_BINFO			0x2c	/* Number of outstanding I/Os */
+#define ELX_READ_BPLIST			0x2d	/* Number of outstanding I/Os */
+#define ELX_INVAL			0x2e	/* Number of outstanding I/Os */
+#define ELX_LINKINFO			0x2f	/* Number of outstanding I/Os */
+#define ELX_IOINFO  			0x30	/* Number of outstanding I/Os */
+#define ELX_NODEINFO  			0x31	/* Number of outstanding I/Os */
+#define ELX_READ_LHBA	           	0x32	/* Get adapter info */
+#define ELX_READ_LXHBA	           	0x33	/* Get adapter info */
+#define ELX_SET		           	0x34	/* Select adapter  */
+#define ELX_DBG		           	0x35	/* set dbg trace val */
+#define ELX_ADD_BIND             	0x36	/* Add a new binding */
+#define ELX_DEL_BIND             	0x37	/* Del a binding */
+#define ELX_LIST_BIND                   0x38	/* List binding */
+/*	ELX_LAST_IOCTL_USED		0x38	Last ELX Ioctl used  */
+
+#define LPFC_DFC_IOCTL			0x01	/* For DFC invocation */
+
+/*
+Data structure definitions:
+
+Macro converting  to word format to uniquesly identify and group the Ioctls.
+*/
+
+#define IOCTL_WORD(ioctl_type1, ioctl_type2, ioctl_val) ((ioctl_type1 << 24 | ioctl_type2 << 16) | ioctl_val)
+
+/*
+ * Dignostic (DFC) Command & Input structures: (LPFC)
+ */
+
+typedef struct elxCmdInput {	/* For 64-bit copy_in */
+#ifdef _ELX_DFC_64BIT
+	short elx_brd;
+	short elx_ring;
+	short elx_iocb;
+	short elx_flag;
+	void *elx_arg1;
+	void *elx_arg2;
+	void *elx_arg3;
+	char *elx_dataout;
+	uint32_t elx_cmd;
+	uint32_t elx_outsz;
+	uint32_t elx_arg4;
+	uint32_t elx_arg5;
+#else
+	short elx_brd;
+	short elx_ring;
+	short elx_iocb;
+	short elx_flag;
+	void *elx_filler1;
+	void *elx_arg1;
+	void *elx_filler2;
+	void *elx_arg2;
+	void *elx_filler3;
+	void *elx_arg3;
+	void *elx_filler4;
+	char *elx_dataout;
+	uint32_t elx_cmd;
+	uint32_t elx_outsz;
+	uint32_t elx_arg4;
+	uint32_t elx_arg5;
+#endif				/* _ELX_DFC_64BIT */
+} ELXCMDINPUT_t;
+
+#endif				/*  _H_ELX_IOCTL */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_logmsg.h linux-2.6.3/drivers/scsi/lpfc/elx_logmsg.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_logmsg.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_logmsg.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,801 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_LOGMSG
+#define _H_ELX_LOGMSG
+
+/*
+ * Log Message Structure
+ *
+ * The following structure supports LOG messages only.
+ * Every LOG message is associated to a msgBlkLogDef structure of the 
+ * following type.
+ */
+
+typedef struct msgLogType {
+	int msgNum;		/* Message number */
+	char *msgStr;		/* Ptr to log message */
+	char *msgPreambleStr;	/* Ptr to log message preamble */
+	int msgOutput;		/* Message output target - bitmap */
+	/*
+	 * This member controls message OUTPUT.
+	 *
+	 * The phase 'global controls' refers to user configurable parameters
+	 * such as LOG_VERBOSE that control message output on a global basis.
+	 */
+
+#define ELX_MSG_OPUT_GLOB_CTRL         0x0	/* Use global control */
+#define ELX_MSG_OPUT_DISA              0x1	/* Override global control */
+#define ELX_MSG_OPUT_FORCE             0x2	/* Override global control */
+	int msgType;		/* Message LOG type - bitmap */
+#define ELX_LOG_MSG_TYPE_INFO          0x1	/* Maskable */
+#define ELX_LOG_MSG_TYPE_WARN          0x2	/* Non-Maskable */
+#define ELX_LOG_MSG_TYPE_ERR_CFG       0x4	/* Non-Maskable */
+#define ELX_LOG_MSG_TYPE_ERR           0x8	/* Non-Maskable */
+#define ELX_LOG_MSG_TYPE_PANIC        0x10	/* Non-Maskable */
+	int msgMask;		/* Message LOG mask - bitmap */
+	/*
+	 * NOTE: Only LOG messages of types MSG_TYPE_WARN & MSG_TYPE_INFO are 
+	 * maskable at the GLOBAL level.
+	 * 
+	 * Any LOG message regardless of message type can be disabled (override verbose) 
+	 * at the msgBlkLogDef struct level my setting member msgOutput = ELX_MSG_OPUT_DISA.
+	 * The message will never be displayed regardless of verbose mask.
+	 * 
+	 * Any LOG message regardless of message type can be enable (override verbose) 
+	 * at the msgBlkLogDef struct level my setting member msgOutput = ELX_MSG_OPUT_FORCE.
+	 * The message will always be displayed regardless of verbose mask.
+	 */
+#define LOG_ELS                       0x1	/* ELS events */
+#define LOG_DISCOVERY                 0x2	/* Link discovery events */
+#define LOG_MBOX                      0x4	/* Mailbox events */
+#define LOG_INIT                      0x8	/* Initialization events */
+#define LOG_LINK_EVENT                0x10	/* Link events */
+#define LOG_IP                        0x20	/* IP traffic history */
+#define LOG_FCP                       0x40	/* FCP traffic history */
+#define LOG_NODE                      0x80	/* Node table events */
+#define LOG_MISC                      0x400	/* Miscellaneous events */
+#define LOG_SLI                       0x800	/* SLI events */
+#define LOG_CHK_COND                  0x1000	/* FCP Check condition flag */
+#define LOG_IOC                       0x2000	/* IOCtl events */
+#define LOG_ALL_MSG                   0xffff	/* LOG all messages */
+
+	unsigned int msgAuxLogID;	/* Message LOG ID - This auxilliary member describes the failure. */
+#define ERRID_LOG_TIMEOUT             0xfdefefa7	/* Fibre Channel timeout */
+#define ERRID_LOG_HDW_ERR             0x1ae4fffc	/* Fibre Channel hardware failure */
+#define ERRID_LOG_UNEXPECT_EVENT      0xbdb7e728	/* Fibre Channel unexpected event */
+#define ERRID_LOG_INIT                0xbe1043b8	/* Fibre Channel init failure */
+#define ERRID_LOG_NO_RESOURCE         0x474c1775	/* Fibre Channel no resources */
+} msgLogDef;
+
+/*
+ * External Declarations for LOG Messages
+ */
+
+/* ELS LOG Messages */
+extern char elx_mes0100[];
+extern char elx_mes0101[];
+extern char elx_mes0102[];
+extern char elx_mes0103[];
+extern char elx_mes0104[];
+extern char elx_mes0105[];
+extern char elx_mes0106[];
+extern char elx_mes0107[];
+extern char elx_mes0108[];
+extern char elx_mes0109[];
+extern char elx_mes0110[];
+extern char elx_mes0111[];
+extern char elx_mes0112[];
+extern char elx_mes0113[];
+extern char elx_mes0114[];
+extern char elx_mes0115[];
+extern char elx_mes0116[];
+extern char elx_mes0117[];
+extern char elx_mes0118[];
+extern char elx_mes0119[];
+extern char elx_mes0120[];
+extern char elx_mes0121[];
+extern char elx_mes0122[];
+extern char elx_mes0123[];
+extern char elx_mes0124[];
+extern char elx_mes0125[];
+extern char elx_mes0126[];
+extern char elx_mes0127[];
+
+/* DISCOVERY LOG Messages */
+extern char elx_mes0200[];
+extern char elx_mes0201[];
+extern char elx_mes0202[];
+extern char elx_mes0203[];
+extern char elx_mes0204[];
+extern char elx_mes0205[];
+extern char elx_mes0206[];
+extern char elx_mes0207[];
+extern char elx_mes0208[];
+extern char elx_mes0209[];
+extern char elx_mes0210[];
+extern char elx_mes0211[];
+extern char elx_mes0212[];
+extern char elx_mes0213[];
+extern char elx_mes0214[];
+extern char elx_mes0215[];
+extern char elx_mes0216[];
+extern char elx_mes0217[];
+extern char elx_mes0218[];
+extern char elx_mes0219[];
+extern char elx_mes0220[];
+extern char elx_mes0221[];
+extern char elx_mes0222[];
+extern char elx_mes0223[];
+extern char elx_mes0224[];
+extern char elx_mes0225[];
+extern char elx_mes0226[];
+extern char elx_mes0227[];
+extern char elx_mes0228[];
+extern char elx_mes0229[];
+extern char elx_mes0230[];
+extern char elx_mes0231[];
+extern char elx_mes0232[];
+extern char elx_mes0234[];
+extern char elx_mes0235[];
+extern char elx_mes0236[];
+extern char elx_mes0237[];
+extern char elx_mes0238[];
+extern char elx_mes0239[];
+extern char elx_mes0240[];
+extern char elx_mes0241[];
+extern char elx_mes0243[];
+extern char elx_mes0244[];
+extern char elx_mes0245[];
+extern char elx_mes0246[];
+extern char elx_mes0247[];
+extern char elx_mes0248[];
+
+/* MAILBOX LOG Messages */
+extern char elx_mes0300[];
+extern char elx_mes0301[];
+extern char elx_mes0302[];
+extern char elx_mes0304[];
+extern char elx_mes0305[];
+extern char elx_mes0306[];
+extern char elx_mes0307[];
+extern char elx_mes0308[];
+extern char elx_mes0309[];
+extern char elx_mes0310[];
+extern char elx_mes0311[];
+extern char elx_mes0312[];
+extern char elx_mes0313[];
+extern char elx_mes0314[];
+extern char elx_mes0315[];
+extern char elx_mes0316[];
+extern char elx_mes0317[];
+extern char elx_mes0318[];
+extern char elx_mes0319[];
+extern char elx_mes0320[];
+extern char elx_mes0321[];
+extern char elx_mes0322[];
+extern char elx_mes0323[];
+extern char elx_mes0324[];
+
+/* INIT LOG Messages */
+extern char elx_mes0405[];
+extern char elx_mes0406[];
+extern char elx_mes0407[];
+extern char elx_mes0409[];
+extern char elx_mes0410[];
+extern char elx_mes0411[];
+extern char elx_mes0412[];
+extern char elx_mes0413[];
+extern char elx_mes0430[];
+extern char elx_mes0431[];
+extern char elx_mes0432[];
+extern char elx_mes0433[];
+extern char elx_mes0434[];
+extern char elx_mes0435[];
+extern char elx_mes0436[];
+extern char elx_mes0437[];
+extern char elx_mes0438[];
+extern char elx_mes0439[];
+extern char elx_mes0440[];
+extern char elx_mes0441[];
+extern char elx_mes0442[];
+extern char elx_mes0446[];
+extern char elx_mes0447[];
+extern char elx_mes0448[];
+extern char elx_mes0449[];
+extern char elx_mes0450[];
+extern char elx_mes0451[];
+extern char elx_mes0453[];
+extern char elx_mes0454[];
+extern char elx_mes0455[];
+extern char elx_mes0457[];
+extern char elx_mes0458[];
+extern char elx_mes0460[];
+extern char elx_mes0462[];
+
+/* IP LOG Messages */
+extern char elx_mes0600[];
+extern char elx_mes0601[];
+extern char elx_mes0602[];
+extern char elx_mes0603[];
+extern char elx_mes0604[];
+extern char elx_mes0605[];
+extern char elx_mes0606[];
+extern char elx_mes0607[];
+extern char elx_mes0608[];
+extern char elx_mes0609[];
+extern char elx_mes0610[];
+
+/* FCP LOG Messages */
+extern char elx_mes0700[];
+extern char elx_mes0701[];
+extern char elx_mes0702[];
+extern char elx_mes0703[];
+extern char elx_mes0706[];
+extern char elx_mes0710[];
+extern char elx_mes0712[];
+extern char elx_mes0713[];
+extern char elx_mes0714[];
+extern char elx_mes0716[];
+extern char elx_mes0717[];
+extern char elx_mes0729[];
+extern char elx_mes0730[];
+extern char elx_mes0732[];
+extern char elx_mes0734[];
+extern char elx_mes0735[];
+extern char elx_mes0736[];
+extern char elx_mes0737[];
+extern char elx_mes0747[];
+extern char elx_mes0748[];
+extern char elx_mes0749[];
+extern char elx_mes0754[];
+
+/* NODE LOG Messages */
+extern char elx_mes0900[];
+extern char elx_mes0901[];
+extern char elx_mes0902[];
+extern char elx_mes0903[];
+extern char elx_mes0904[];
+extern char elx_mes0905[];
+extern char elx_mes0906[];
+extern char elx_mes0907[];
+extern char elx_mes0908[];
+extern char elx_mes0910[];
+extern char elx_mes0911[];
+extern char elx_mes0927[];
+extern char elx_mes0928[];
+extern char elx_mes0929[];
+extern char elx_mes0930[];
+extern char elx_mes0931[];
+extern char elx_mes0932[];
+
+/* MISC LOG messages */
+extern char elx_mes1201[];
+extern char elx_mes1202[];
+extern char elx_mes1204[];
+extern char elx_mes1205[];
+extern char elx_mes1206[];
+extern char elx_mes1207[];
+extern char elx_mes1208[];
+extern char elx_mes1210[];
+extern char elx_mes1211[];
+extern char elx_mes1212[];
+extern char elx_mes1213[];
+
+/* LINK LOG Messages */
+extern char elx_mes1300[];
+extern char elx_mes1301[];
+extern char elx_mes1302[];
+extern char elx_mes1303[];
+extern char elx_mes1304[];
+extern char elx_mes1305[];
+extern char elx_mes1306[];
+extern char elx_mes1307[];
+
+/* CHK CONDITION LOG Messages */
+
+/* IOCtl Log Messages */
+extern char elx_mes1600[];
+extern char elx_mes1601[];
+extern char elx_mes1602[];
+extern char elx_mes1603[];
+extern char elx_mes1604[];
+extern char elx_mes1605[];
+
+/*
+ * External Declarations for LOG Message Structure msgBlkLogDef
+ */
+
+/* ELS LOG Message Structures */
+extern msgLogDef elx_msgBlk0100;
+extern msgLogDef elx_msgBlk0101;
+extern msgLogDef elx_msgBlk0102;
+extern msgLogDef elx_msgBlk0103;
+extern msgLogDef elx_msgBlk0104;
+extern msgLogDef elx_msgBlk0105;
+extern msgLogDef elx_msgBlk0106;
+extern msgLogDef elx_msgBlk0107;
+extern msgLogDef elx_msgBlk0108;
+extern msgLogDef elx_msgBlk0109;
+extern msgLogDef elx_msgBlk0110;
+extern msgLogDef elx_msgBlk0111;
+extern msgLogDef elx_msgBlk0112;
+extern msgLogDef elx_msgBlk0113;
+extern msgLogDef elx_msgBlk0114;
+extern msgLogDef elx_msgBlk0115;
+extern msgLogDef elx_msgBlk0116;
+extern msgLogDef elx_msgBlk0117;
+extern msgLogDef elx_msgBlk0118;
+extern msgLogDef elx_msgBlk0119;
+extern msgLogDef elx_msgBlk0120;
+extern msgLogDef elx_msgBlk0121;
+extern msgLogDef elx_msgBlk0122;
+extern msgLogDef elx_msgBlk0123;
+extern msgLogDef elx_msgBlk0124;
+extern msgLogDef elx_msgBlk0125;
+extern msgLogDef elx_msgBlk0126;
+extern msgLogDef elx_msgBlk0127;
+
+/* DISCOVERY LOG Message Structures */
+extern msgLogDef elx_msgBlk0200;
+extern msgLogDef elx_msgBlk0201;
+extern msgLogDef elx_msgBlk0202;
+extern msgLogDef elx_msgBlk0203;
+extern msgLogDef elx_msgBlk0204;
+extern msgLogDef elx_msgBlk0205;
+extern msgLogDef elx_msgBlk0206;
+extern msgLogDef elx_msgBlk0207;
+extern msgLogDef elx_msgBlk0208;
+extern msgLogDef elx_msgBlk0209;
+extern msgLogDef elx_msgBlk0210;
+extern msgLogDef elx_msgBlk0211;
+extern msgLogDef elx_msgBlk0212;
+extern msgLogDef elx_msgBlk0213;
+extern msgLogDef elx_msgBlk0214;
+extern msgLogDef elx_msgBlk0215;
+extern msgLogDef elx_msgBlk0216;
+extern msgLogDef elx_msgBlk0217;
+extern msgLogDef elx_msgBlk0218;
+extern msgLogDef elx_msgBlk0219;
+extern msgLogDef elx_msgBlk0220;
+extern msgLogDef elx_msgBlk0221;
+extern msgLogDef elx_msgBlk0222;
+extern msgLogDef elx_msgBlk0223;
+extern msgLogDef elx_msgBlk0224;
+extern msgLogDef elx_msgBlk0225;
+extern msgLogDef elx_msgBlk0226;
+extern msgLogDef elx_msgBlk0227;
+extern msgLogDef elx_msgBlk0228;
+extern msgLogDef elx_msgBlk0229;
+extern msgLogDef elx_msgBlk0230;
+extern msgLogDef elx_msgBlk0231;
+extern msgLogDef elx_msgBlk0232;
+extern msgLogDef elx_msgBlk0234;
+extern msgLogDef elx_msgBlk0235;
+extern msgLogDef elx_msgBlk0236;
+extern msgLogDef elx_msgBlk0237;
+extern msgLogDef elx_msgBlk0238;
+extern msgLogDef elx_msgBlk0239;
+extern msgLogDef elx_msgBlk0240;
+extern msgLogDef elx_msgBlk0241;
+extern msgLogDef elx_msgBlk0243;
+extern msgLogDef elx_msgBlk0244;
+extern msgLogDef elx_msgBlk0245;
+extern msgLogDef elx_msgBlk0246;
+extern msgLogDef elx_msgBlk0247;
+extern msgLogDef elx_msgBlk0248;
+
+/* MAILBOX LOG Message Structures */
+extern msgLogDef elx_msgBlk0300;
+extern msgLogDef elx_msgBlk0301;
+extern msgLogDef elx_msgBlk0302;
+extern msgLogDef elx_msgBlk0304;
+extern msgLogDef elx_msgBlk0305;
+extern msgLogDef elx_msgBlk0306;
+extern msgLogDef elx_msgBlk0307;
+extern msgLogDef elx_msgBlk0308;
+extern msgLogDef elx_msgBlk0309;
+extern msgLogDef elx_msgBlk0310;
+extern msgLogDef elx_msgBlk0311;
+extern msgLogDef elx_msgBlk0312;
+extern msgLogDef elx_msgBlk0313;
+extern msgLogDef elx_msgBlk0314;
+extern msgLogDef elx_msgBlk0315;
+extern msgLogDef elx_msgBlk0316;
+extern msgLogDef elx_msgBlk0317;
+extern msgLogDef elx_msgBlk0318;
+extern msgLogDef elx_msgBlk0319;
+extern msgLogDef elx_msgBlk0320;
+extern msgLogDef elx_msgBlk0321;
+extern msgLogDef elx_msgBlk0322;
+extern msgLogDef elx_msgBlk0323;
+extern msgLogDef elx_msgBlk0324;
+
+/* INIT LOG Message Structures */
+extern msgLogDef elx_msgBlk0405;
+extern msgLogDef elx_msgBlk0406;
+extern msgLogDef elx_msgBlk0407;
+extern msgLogDef elx_msgBlk0409;
+extern msgLogDef elx_msgBlk0410;
+extern msgLogDef elx_msgBlk0411;
+extern msgLogDef elx_msgBlk0412;
+extern msgLogDef elx_msgBlk0413;
+extern msgLogDef elx_msgBlk0430;
+extern msgLogDef elx_msgBlk0431;
+extern msgLogDef elx_msgBlk0432;
+extern msgLogDef elx_msgBlk0433;
+extern msgLogDef elx_msgBlk0434;
+extern msgLogDef elx_msgBlk0435;
+extern msgLogDef elx_msgBlk0436;
+extern msgLogDef elx_msgBlk0437;
+extern msgLogDef elx_msgBlk0438;
+extern msgLogDef elx_msgBlk0439;
+extern msgLogDef elx_msgBlk0440;
+extern msgLogDef elx_msgBlk0441;
+extern msgLogDef elx_msgBlk0442;
+extern msgLogDef elx_msgBlk0446;
+extern msgLogDef elx_msgBlk0447;
+extern msgLogDef elx_msgBlk0448;
+extern msgLogDef elx_msgBlk0449;
+extern msgLogDef elx_msgBlk0450;
+extern msgLogDef elx_msgBlk0451;
+extern msgLogDef elx_msgBlk0453;
+extern msgLogDef elx_msgBlk0454;
+extern msgLogDef elx_msgBlk0455;
+extern msgLogDef elx_msgBlk0457;
+extern msgLogDef elx_msgBlk0458;
+extern msgLogDef elx_msgBlk0460;
+extern msgLogDef elx_msgBlk0462;
+
+/* IP LOG Message Structures */
+extern msgLogDef elx_msgBlk0600;
+extern msgLogDef elx_msgBlk0601;
+extern msgLogDef elx_msgBlk0602;
+extern msgLogDef elx_msgBlk0603;
+extern msgLogDef elx_msgBlk0604;
+extern msgLogDef elx_msgBlk0605;
+extern msgLogDef elx_msgBlk0606;
+extern msgLogDef elx_msgBlk0607;
+extern msgLogDef elx_msgBlk0608;
+extern msgLogDef elx_msgBlk0609;
+extern msgLogDef elx_msgBlk0610;
+
+/* FCP LOG Message Structures */
+extern msgLogDef elx_msgBlk0700;
+extern msgLogDef elx_msgBlk0701;
+extern msgLogDef elx_msgBlk0702;
+extern msgLogDef elx_msgBlk0703;
+extern msgLogDef elx_msgBlk0706;
+extern msgLogDef elx_msgBlk0710;
+extern msgLogDef elx_msgBlk0712;
+extern msgLogDef elx_msgBlk0713;
+extern msgLogDef elx_msgBlk0714;
+extern msgLogDef elx_msgBlk0716;
+extern msgLogDef elx_msgBlk0717;
+extern msgLogDef elx_msgBlk0729;
+extern msgLogDef elx_msgBlk0730;
+extern msgLogDef elx_msgBlk0732;
+extern msgLogDef elx_msgBlk0734;
+extern msgLogDef elx_msgBlk0735;
+extern msgLogDef elx_msgBlk0736;
+extern msgLogDef elx_msgBlk0737;
+extern msgLogDef elx_msgBlk0747;
+extern msgLogDef elx_msgBlk0748;
+extern msgLogDef elx_msgBlk0749;
+extern msgLogDef elx_msgBlk0754;
+
+/* NODE LOG Message Structures */
+extern msgLogDef elx_msgBlk0900;
+extern msgLogDef elx_msgBlk0901;
+extern msgLogDef elx_msgBlk0902;
+extern msgLogDef elx_msgBlk0903;
+extern msgLogDef elx_msgBlk0904;
+extern msgLogDef elx_msgBlk0905;
+extern msgLogDef elx_msgBlk0906;
+extern msgLogDef elx_msgBlk0907;
+extern msgLogDef elx_msgBlk0908;
+extern msgLogDef elx_msgBlk0910;
+extern msgLogDef elx_msgBlk0911;
+extern msgLogDef elx_msgBlk0927;
+extern msgLogDef elx_msgBlk0928;
+extern msgLogDef elx_msgBlk0929;
+extern msgLogDef elx_msgBlk0930;
+extern msgLogDef elx_msgBlk0931;
+extern msgLogDef elx_msgBlk0932;
+
+/* MISC LOG Message Structures */
+extern msgLogDef elx_msgBlk1201;
+extern msgLogDef elx_msgBlk1202;
+extern msgLogDef elx_msgBlk1204;
+extern msgLogDef elx_msgBlk1205;
+extern msgLogDef elx_msgBlk1206;
+extern msgLogDef elx_msgBlk1207;
+extern msgLogDef elx_msgBlk1208;
+extern msgLogDef elx_msgBlk1210;
+extern msgLogDef elx_msgBlk1211;
+extern msgLogDef elx_msgBlk1212;
+extern msgLogDef elx_msgBlk1213;
+
+/* LINK LOG Message Structures */
+extern msgLogDef elx_msgBlk1300;
+extern msgLogDef elx_msgBlk1301;
+extern msgLogDef elx_msgBlk1302;
+extern msgLogDef elx_msgBlk1303;
+extern msgLogDef elx_msgBlk1304;
+extern msgLogDef elx_msgBlk1305;
+extern msgLogDef elx_msgBlk1306;
+extern msgLogDef elx_msgBlk1307;
+
+/* CHK CONDITION LOG Message Structures */
+
+/* IOCtl LOG Message Structures */
+extern msgLogDef elx_msgBlk1600;
+extern msgLogDef elx_msgBlk1601;
+extern msgLogDef elx_msgBlk1602;
+extern msgLogDef elx_msgBlk1603;
+extern msgLogDef elx_msgBlk1604;
+extern msgLogDef elx_msgBlk1605;
+
+/* 
+ * LOG Messages Numbers
+ */
+
+/* ELS LOG Message Numbers */
+#define ELX_LOG_MSG_EL_0100    100
+#define ELX_LOG_MSG_EL_0101    101
+#define ELX_LOG_MSG_EL_0102    102
+#define ELX_LOG_MSG_EL_0103    103
+#define ELX_LOG_MSG_EL_0104    104
+#define ELX_LOG_MSG_EL_0105    105
+#define ELX_LOG_MSG_EL_0106    106
+#define ELX_LOG_MSG_EL_0107    107
+#define ELX_LOG_MSG_EL_0108    108
+#define ELX_LOG_MSG_EL_0109    109
+#define ELX_LOG_MSG_EL_0110    110
+#define ELX_LOG_MSG_EL_0111    111
+#define ELX_LOG_MSG_EL_0112    112
+#define ELX_LOG_MSG_EL_0113    113
+#define ELX_LOG_MSG_EL_0114    114
+#define ELX_LOG_MSG_EL_0115    115
+#define ELX_LOG_MSG_EL_0116    116
+#define ELX_LOG_MSG_EL_0117    117
+#define ELX_LOG_MSG_EL_0118    118
+#define ELX_LOG_MSG_EL_0119    119
+#define ELX_LOG_MSG_EL_0120    120
+#define ELX_LOG_MSG_EL_0121    121
+#define ELX_LOG_MSG_EL_0122    122
+#define ELX_LOG_MSG_EL_0123    123
+#define ELX_LOG_MSG_EL_0124    124
+#define ELX_LOG_MSG_EL_0125    125
+#define ELX_LOG_MSG_EL_0126    126
+#define ELX_LOG_MSG_EL_0127    127
+
+/* DISCOVERY LOG Message Numbers */
+#define ELX_LOG_MSG_DI_0200    200
+#define ELX_LOG_MSG_DI_0201    201
+#define ELX_LOG_MSG_DI_0202    202
+#define ELX_LOG_MSG_DI_0203    203
+#define ELX_LOG_MSG_DI_0204    204
+#define ELX_LOG_MSG_DI_0205    205
+#define ELX_LOG_MSG_DI_0206    206
+#define ELX_LOG_MSG_DI_0207    207
+#define ELX_LOG_MSG_DI_0208    208
+#define ELX_LOG_MSG_DI_0209    209
+#define ELX_LOG_MSG_DI_0210    210
+#define ELX_LOG_MSG_DI_0211    211
+#define ELX_LOG_MSG_DI_0212    212
+#define ELX_LOG_MSG_DI_0213    213
+#define ELX_LOG_MSG_DI_0214    214
+#define ELX_LOG_MSG_DI_0215    215
+#define ELX_LOG_MSG_DI_0216    216
+#define ELX_LOG_MSG_DI_0217    217
+#define ELX_LOG_MSG_DI_0218    218
+#define ELX_LOG_MSG_DI_0219    219
+#define ELX_LOG_MSG_DI_0220    220
+#define ELX_LOG_MSG_DI_0221    221
+#define ELX_LOG_MSG_DI_0222    222
+#define ELX_LOG_MSG_DI_0223    223
+#define ELX_LOG_MSG_DI_0224    224
+#define ELX_LOG_MSG_DI_0225    225
+#define ELX_LOG_MSG_DI_0226    226
+#define ELX_LOG_MSG_DI_0227    227
+#define ELX_LOG_MSG_DI_0228    228
+#define ELX_LOG_MSG_DI_0229    229
+#define ELX_LOG_MSG_DI_0230    230
+#define ELX_LOG_MSG_DI_0231    231
+#define ELX_LOG_MSG_DI_0232    232
+#define ELX_LOG_MSG_DI_0234    234
+#define ELX_LOG_MSG_DI_0235    235
+#define ELX_LOG_MSG_DI_0236    236
+#define ELX_LOG_MSG_DI_0237    237
+#define ELX_LOG_MSG_DI_0238    238
+#define ELX_LOG_MSG_DI_0239    239
+#define ELX_LOG_MSG_DI_0240    240
+#define ELX_LOG_MSG_DI_0241    241
+#define ELX_LOG_MSG_DI_0243    243
+#define ELX_LOG_MSG_DI_0244    244
+#define ELX_LOG_MSG_DI_0245    245
+#define ELX_LOG_MSG_DI_0246    246
+#define ELX_LOG_MSG_DI_0247    247
+#define ELX_LOG_MSG_DI_0248    248
+
+/* MAILBOX LOG Message Numbers */
+#define ELX_LOG_MSG_MB_0300    300
+#define ELX_LOG_MSG_MB_0301    301
+#define ELX_LOG_MSG_MB_0302    302
+#define ELX_LOG_MSG_MB_0304    304
+#define ELX_LOG_MSG_MB_0305    305
+#define ELX_LOG_MSG_MB_0306    306
+#define ELX_LOG_MSG_MB_0307    307
+#define ELX_LOG_MSG_MB_0308    308
+#define ELX_LOG_MSG_MB_0309    309
+#define ELX_LOG_MSG_MB_0310    310
+#define ELX_LOG_MSG_MB_0311    311
+#define ELX_LOG_MSG_MB_0312    312
+#define ELX_LOG_MSG_MB_0313    313
+#define ELX_LOG_MSG_MB_0314    314
+#define ELX_LOG_MSG_MB_0315    315
+#define ELX_LOG_MSG_MB_0316    316
+#define ELX_LOG_MSG_MB_0317    317
+#define ELX_LOG_MSG_MB_0318    318
+#define ELX_LOG_MSG_MB_0319    319
+#define ELX_LOG_MSG_MB_0320    320
+#define ELX_LOG_MSG_MB_0321    321
+#define ELX_LOG_MSG_MB_0322    322
+#define ELX_LOG_MSG_MB_0323    323
+#define ELX_LOG_MSG_MB_0324    324
+
+/* INIT LOG Message Numbers */
+#define ELX_LOG_MSG_IN_0405    405
+#define ELX_LOG_MSG_IN_0406    406
+#define ELX_LOG_MSG_IN_0407    407
+#define ELX_LOG_MSG_IN_0409    409
+#define ELX_LOG_MSG_IN_0410    410
+#define ELX_LOG_MSG_IN_0411    411
+#define ELX_LOG_MSG_IN_0412    412
+#define ELX_LOG_MSG_IN_0413    413
+#define ELX_LOG_MSG_IN_0430    430
+#define ELX_LOG_MSG_IN_0431    431
+#define ELX_LOG_MSG_IN_0432    432
+#define ELX_LOG_MSG_IN_0433    433
+#define ELX_LOG_MSG_IN_0434    434
+#define ELX_LOG_MSG_IN_0435    435
+#define ELX_LOG_MSG_IN_0436    436
+#define ELX_LOG_MSG_IN_0437    437
+#define ELX_LOG_MSG_IN_0438    438
+#define ELX_LOG_MSG_IN_0439    439
+#define ELX_LOG_MSG_IN_0440    440
+#define ELX_LOG_MSG_IN_0441    441
+#define ELX_LOG_MSG_IN_0442    442
+#define ELX_LOG_MSG_IN_0446    446
+#define ELX_LOG_MSG_IN_0447    447
+#define ELX_LOG_MSG_IN_0448    448
+#define ELX_LOG_MSG_IN_0449    449
+#define ELX_LOG_MSG_IN_0450    450
+#define ELX_LOG_MSG_IN_0451    451
+#define ELX_LOG_MSG_IN_0453    453
+#define ELX_LOG_MSG_IN_0454    454
+#define ELX_LOG_MSG_IN_0455    455
+#define ELX_LOG_MSG_IN_0457    457
+#define ELX_LOG_MSG_IN_0458    458
+#define ELX_LOG_MSG_IN_0460    460
+#define ELX_LOG_MSG_IN_0462    462
+
+/*
+ * Available.ELX_LOG_MSG_IN_0500    500
+ */
+
+/* IP LOG Message Numbers */
+#define ELX_LOG_MSG_IP_0600    600
+#define ELX_LOG_MSG_IP_0601    601
+#define ELX_LOG_MSG_IP_0602    602
+#define ELX_LOG_MSG_IP_0603    603
+#define ELX_LOG_MSG_IP_0604    604
+#define ELX_LOG_MSG_IP_0605    605
+#define ELX_LOG_MSG_IP_0606    606
+#define ELX_LOG_MSG_IP_0607    607
+#define ELX_LOG_MSG_IP_0608    608
+#define ELX_LOG_MSG_IP_0609    609
+#define ELX_LOG_MSG_IP_0610    610
+
+/* FCP LOG Message Numbers */
+#define ELX_LOG_MSG_FP_0700    700
+#define ELX_LOG_MSG_FP_0701    701
+#define ELX_LOG_MSG_FP_0702    702
+#define ELX_LOG_MSG_FP_0703    703
+#define ELX_LOG_MSG_FP_0706    706
+#define ELX_LOG_MSG_FP_0710    710
+#define ELX_LOG_MSG_FP_0712    712
+#define ELX_LOG_MSG_FP_0713    713
+#define ELX_LOG_MSG_FP_0714    714
+#define ELX_LOG_MSG_FP_0716    716
+#define ELX_LOG_MSG_FP_0717    717
+#define ELX_LOG_MSG_FP_0729    729
+#define ELX_LOG_MSG_FP_0730    730
+#define ELX_LOG_MSG_FP_0732    732
+#define ELX_LOG_MSG_FP_0734    734
+#define ELX_LOG_MSG_FP_0735    735
+#define ELX_LOG_MSG_FP_0736    736
+#define ELX_LOG_MSG_FP_0737    737
+#define ELX_LOG_MSG_FP_0747    747
+#define ELX_LOG_MSG_FP_0748    748
+#define ELX_LOG_MSG_FP_0749    749
+#define ELX_LOG_MSG_FP_0754    754
+
+/*
+ * Available:  ELX_LOG_MSG_FP_0800    800
+ */
+
+/* NODE LOG Message Numbers */
+#define ELX_LOG_MSG_ND_0900    900
+#define ELX_LOG_MSG_ND_0901    901
+#define ELX_LOG_MSG_ND_0902    902
+#define ELX_LOG_MSG_ND_0903    903
+#define ELX_LOG_MSG_ND_0904    904
+#define ELX_LOG_MSG_ND_0905    905
+#define ELX_LOG_MSG_ND_0906    906
+#define ELX_LOG_MSG_ND_0907    907
+#define ELX_LOG_MSG_ND_0908    908
+#define ELX_LOG_MSG_ND_0910    910
+#define ELX_LOG_MSG_ND_0911    911
+#define ELX_LOG_MSG_ND_0927    927
+#define ELX_LOG_MSG_ND_0928    928
+#define ELX_LOG_MSG_ND_0929    929
+#define ELX_LOG_MSG_ND_0930    930
+#define ELX_LOG_MSG_ND_0931    931
+#define ELX_LOG_MSG_ND_0932    932
+
+/* MISC LOG Message Numbers */
+#define ELX_LOG_MSG_MI_1201   1201
+#define ELX_LOG_MSG_MI_1202   1202
+#define ELX_LOG_MSG_MI_1204   1204
+#define ELX_LOG_MSG_MI_1205   1205
+#define ELX_LOG_MSG_MI_1206   1206
+#define ELX_LOG_MSG_MI_1207   1207
+#define ELX_LOG_MSG_MI_1208   1208
+#define ELX_LOG_MSG_MI_1210   1210
+#define ELX_LOG_MSG_MI_1211   1211
+#define ELX_LOG_MSG_MI_1212   1212
+#define ELX_LOG_MSG_MI_1213   1213
+
+/* LINK LOG Message Numbers */
+#define ELX_LOG_MSG_LK_1300   1300
+#define ELX_LOG_MSG_LK_1301   1301
+#define ELX_LOG_MSG_LK_1302   1302
+#define ELX_LOG_MSG_LK_1303   1303
+#define ELX_LOG_MSG_LK_1304   1304
+#define ELX_LOG_MSG_LK_1305   1305
+#define ELX_LOG_MSG_LK_1306   1306
+#define ELX_LOG_MSG_LK_1307   1307
+
+/* CHK COMDITION LOG Message Numbers */
+/*
+ * Available ELX_LOG_MSG_LK_1500   1500
+ */
+
+/* IOCtl LOG Message Numbers */
+#define ELX_LOG_MSG_IO_1600   1600
+#define ELX_LOG_MSG_IO_1601   1601
+#define ELX_LOG_MSG_IO_1602   1602
+#define ELX_LOG_MSG_IO_1603   1603
+#define ELX_LOG_MSG_IO_1604   1604
+#define ELX_LOG_MSG_IO_1605   1605
+
+#endif				/* _H_ELX_LOGMSG */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_mem.h linux-2.6.3/drivers/scsi/lpfc/elx_mem.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_mem.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_mem.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,114 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_MEM
+#define _H_ELX_MEM
+
+/*
+ * This structure is used when allocating a buffer pool.
+ */
+struct mbuf_info {
+	uint32_t size;		/* Specifies the number of bytes to allocate. */
+	uint32_t align;		/* The desired address boundary. */
+
+	uint32_t flags;
+#define ELX_MBUF_VIRT       0x0	/* virtual memory (unmapped) */
+#define ELX_MBUF_DMA        0x1	/* blocks are for DMA */
+#define ELX_MBUF_PHYSONLY   0x2	/* For malloc - map a given virtual address
+				 * to physical (skip the malloc). For free -
+				 * just unmap the given physical address
+				 * (skip the free).
+				 */
+#define ELX_MBUF_MASK       0x3	/* Mask for flags */
+#define ELX_MBUF_SLEEP      0x8	/* sleep - no sleep */
+
+	void *virt;		/* specifies the virtual buffer pointer */
+	elx_dma_addr_t phys;	/* specifies the physical buffer pointer */
+	elx_acc_handle_t data_handle;
+	elx_dma_handle_t dma_handle;
+};
+typedef struct mbuf_info MBUF_INFO_t;
+
+#define  ELX_MEM_DBUF     1	/* Use DMABUF_t for referencing DMAable memory */
+#define  ELX_MEM_DBUFEXT  2	/* Use DMABUFEXT_t for referencing DMAable memory */
+
+struct elx_dmabuf {
+	struct elx_dmabuf *next;
+	void *virt;		/* virtual address ptr */
+	elx_dma_addr_t phys;	/* mapped address */
+	elx_acc_handle_t data_handle;
+	elx_dma_handle_t dma_handle;
+};
+typedef struct elx_dmabuf DMABUF_t;
+
+struct elx_dmabufext {
+	DMABUF_t dma;
+	uint32_t size;
+	uint32_t flag;
+};
+typedef struct elx_dmabufext DMABUFEXT_t;
+
+struct elx_dmabufip {
+	DMABUF_t dma;
+	void *ipbuf;
+};
+typedef struct elx_dmabufip DMABUFIP_t;
+
+#define MEM_BUF          0	/* memory seg to hold buffer data   */
+#define MEM_BPL          0	/* and to hold buffer ptr lists - SLI2   */
+#define MEM_MBOX         1	/* memory seg to hold mailbox cmds  */
+#define MEM_IOCB         2	/* memory seg to hold iocb commands */
+#define MEM_CLOCK        3	/* memory seg to hold clock blocks */
+#define MEM_SCSI_BUF     4	/* memory seg for scsi buffer for each I/O */
+
+#define MEM_FCP_CMND_BUF 5
+
+#define MEM_NLP          6	/* memory seg to hold node list entries */
+#define MEM_BIND         7	/* memory seg to hold bind list entries */
+#define MEM_IP_BUF       8	/* memory seg for ip buffer for each I/O */
+#define MEM_IP_RCV_BUF   9	/* memory seg for ip rcv buffers */
+#define MEM_IP_MAP       10	/* memory seg for ip net->phys/dma buffers. */
+#define MEM_SCSI_DMA_EXT 11	/* and to hold SCSI fcp_cmnd, fcp_rsp, bpl */
+#define MEM_IP_DMA_EXT   12	/* and to hold IP network header and bpl */
+#define ELX_MAX_SEG      13
+
+#define MEM_SEG_MASK    0xff	/* mask used to mask off the priority bit */
+#define MEM_PRI         0x100	/* Priority bit: set to exceed low water */
+
+struct elx_memseg {
+	ELX_SLINK_t mem_hdr;
+	uint16_t elx_memsize;	/* size of memory blocks */
+	uint16_t elx_memflag;	/* what to do when list is exhausted */
+	uint16_t elx_lowmem;	/* low water mark, used w/MEM_PRI flag */
+	uint16_t elx_himem;	/* high water mark */
+};
+typedef struct elx_memseg MEMSEG_t;
+
+#define ELX_MEM_ERR          0x1	/* return error memflag */
+#define ELX_MEM_GETMORE      0x2	/* get more memory memflag */
+#define ELX_MEM_DMA          0x4	/* blocks are for DMA */
+#define ELX_MEM_LOWHIT       0x8	/* low water mark was hit */
+#define ELX_MEMPAD           0x10	/* offset used for a FC_MEM_DMA buffer */
+#define ELX_MEM_ATTACH_IPBUF 0x20	/* attach a system IP buffer */
+#define ELX_MEM_BOUND        0x40	/* has a upper bound */
+
+#define ELX_MIN_POOL_GROWTH  32
+
+#endif				/* _H_ELX_MEM */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_os.h linux-2.6.3/drivers/scsi/lpfc/elx_os.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_os.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_os.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,133 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/utsname.h>
+#include <stdarg.h>
+
+typedef uint64_t elx_dma_addr_t;
+typedef uint64_t elx_dma_handle_t;
+typedef uint64_t elx_acc_handle_t;
+
+/* This structure provides data members that capture the sk_buff
+ * address, the next sk_buff, and the physical address mapping
+ * of the sk_buff data region.  This structure is used by 
+ * lpfc_ip_prep_io and lpfc_ip_unprep_io to.
+ */
+struct elx_phys_net_map {
+	struct elx_phys_net_map *p_next;
+	struct sk_buff *p_sk_buff;
+	elx_dma_addr_t phys_addr;
+};
+
+typedef struct elx_phys_net_map ELX_PHYS_NET_MAP_t;
+
+typedef struct elx_os_io {
+	int datadir;
+	elx_dma_addr_t nonsg_phys;
+} ELX_OS_IO_t;
+
+/* Open Source defines */
+
+#ifdef CONFIG_PPC64
+#define powerpc
+#endif
+
+#ifdef powerpc
+#define LITTLE_ENDIAN_HOST   0
+#define BIG_ENDIAN_HW        1
+#else
+#define LITTLE_ENDIAN_HOST   1
+#define LITTLE_ENDIAN_HW     1
+#endif
+
+#ifdef GRANULAR_LOCKS
+#define ELX_SLI_LOCK(phba, flag)    elx_sli_lock(phba, &flag)
+#define ELX_SLI_UNLOCK(phba, flag)  elx_sli_unlock(phba, &flag)
+#define ELX_MEM_LOCK(phba, flag)    elx_mem_lock(phba, &flag)
+#define ELX_MEM_UNLOCK(phba, flag)  elx_mem_unlock(phba, &flag)
+#define ELX_DISC_LOCK(phba, flag)   elx_disc_lock(phba, &flag)
+#define ELX_DISC_UNLOCK(phba, flag) elx_disc_unlock(phba, &flag)
+#define ELX_IOC_LOCK(phba, flag)    elx_ioc_lock(phba, &flag)
+#define ELX_IOC_UNLOCK(phba, flag)  elx_ioc_unlock(phba, &flag)
+#define ELX_SCH_LOCK(phba, flag)    elx_sch_lock(phba, &flag)
+#define ELX_SCH_UNLOCK(phba, flag)  elx_sch_unlock(phba, &flag)
+#define ELX_DRVR_LOCK(phba, flag)   flag = flag
+#define ELX_DRVR_UNLOCK(phba, flag) flag = flag
+#define ELX_CLK_LOCK(flag)          flag = flag
+#define ELX_CLK_UNLOCK(flag)        flag = flag
+#else
+#define ELX_SLI_LOCK(phba, flag)    flag = flag
+#define ELX_SLI_UNLOCK(phba, flag)  flag = flag
+#define ELX_MEM_LOCK(phba, flag)    flag = flag
+#define ELX_MEM_UNLOCK(phba, flag)  flag = flag
+#define ELX_DISC_LOCK(phba, flag)   flag = flag
+#define ELX_DISC_UNLOCK(phba, flag) flag = flag
+#define ELX_IOC_LOCK(phba, flag)    flag = flag
+#define ELX_IOC_UNLOCK(phba, flag)  flag = flag
+#define ELX_SCH_LOCK(phba, flag)    flag = flag
+#define ELX_SCH_UNLOCK(phba, flag)  flag = flag
+#define ELX_DRVR_LOCK(phba, flag)   elx_drvr_lock(phba, &flag)
+#define ELX_DRVR_UNLOCK(phba, flag) elx_drvr_unlock(phba, &flag)
+#define ELX_CLK_LOCK(flag)          elx_clk_lock(0, &flag)
+#define ELX_CLK_UNLOCK(flag)        elx_clk_unlock(0, &flag)
+#endif				/* GRANULAR_LOCKS */
+
+#define ELX_DMA_SYNC_FORDEV  1
+#define ELX_DMA_SYNC_FORCPU  2
+
+/* These macros are for 64 bit support */
+#define putPaddrLow(addr)    ((uint32_t) \
+(0xffffffff & (elx_dma_addr_t)(addr)))
+#define putPaddrHigh(addr)   ((uint32_t) \
+ (0xffffffff & (((elx_dma_addr_t)(addr))>>32)))
+#define getPaddr(high, low)  \
+  ( (( (elx_dma_addr_t)(high)<<16 ) << 16)|( (elx_dma_addr_t)(low)))
+
+#define _static_
+
+#define ELX_DRVR_TIMEOUT 16
+
+#define FC_MAX_SEGSZ 8192
+#define FC_MAX_POOL  1024
+struct elx_mem_pool {
+	void *p_virt;
+	elx_dma_addr_t p_phys;
+	uint16_t p_refcnt;
+	uint16_t p_left;
+};
+
+/* Defines to enable configuration parameters for LINUX */
+#define EXPORT_LINUX 1
+#define EXPORT_AIX 0
+
+#define MAX_ELX_BRDS       32	/* Max # boards per system */
+#define MAX_FC_BINDINGS    64	/* Max # of persistent bindings */
+#define MAX_FCP_TARGET     0xff	/* max num of FCP targets supported */
+#define MAX_FCP_LUN        0xff	/* max num of FCP LUNs supported */
+#define MAX_FCP_CMDS       0x4000	/* max num of FCP cmds supported */
+#define FC_MAX_ADPTMSG     64
+
+#define DEV_SID(x) (uint16_t)(x & 0xff)	/* extract sid from device id */
+#define DEV_PAN(x) (uint16_t)((x>>8) & 0x01)	/* extract pan from device id */
+#define LPFC_MAX_SCSI_ID_PER_PAN 0x100
+
+typedef uint32_t fc_lun_t;
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_os_scsiport.h linux-2.6.3/drivers/scsi/lpfc/elx_os_scsiport.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_os_scsiport.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_os_scsiport.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,120 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_OS_SCSIPORT
+#define _H_OS_SCSIPORT
+#include <scsi.h>
+/* Function prototypes. */
+int elx_revoke(Scsi_Device * pScsiDevice);
+int elx_queuecommand(Scsi_Cmnd *, void (*done) (Scsi_Cmnd *));
+int elx_abort_handler(Scsi_Cmnd *);
+int elx_reset_lun_handler(Scsi_Cmnd *);
+
+struct buf {
+	void *av_forw;
+	void *av_back;
+	int b_bcount;		/* transfer count */
+	int b_error;		/* expanded error field */
+	int b_resid;		/* words not transferred after error */
+	int b_flags;		/* see defines below */
+#define B_ERROR         0x0004	/* transaction aborted */
+#define B_READ          0x0040	/* read when I/O occurs */
+#define B_WRITE         0x0100	/* non-read pseudo-flag */
+	Scsi_Cmnd *cmnd;
+	int isdone;
+};
+
+/* refer to the SCSI ANSI X3.131-1986 standard for information */
+struct sc_cmd {			/* structure of the SCSI cmd block */
+	uint8_t scsi_op_code;	/* first byte of SCSI cmd block */
+	uint8_t lun;		/* second byte of SCSI cmd block */
+	uint8_t scsi_bytes[14];	/* other bytes of SCSI cmd block */
+};
+#define SCSI_RELEASE_UNIT                       0x17
+#define SCSI_REQUEST_SENSE                      0x03
+#define SCSI_RESERVE_UNIT                       0x16
+
+struct scsi {
+	uint8_t scsi_length;	/* byte length of scsi cmd (6,10, or 12) */
+	uint8_t scsi_id;	/* the target SCSI ID */
+	uint8_t scsi_lun;	/* which LUN on the target */
+	uint8_t flags;		/* flags for use with the physical scsi command */
+#define SC_NODISC       0x80	/* don't allow disconnections */
+#define SC_ASYNC        0x08	/* asynchronous data xfer */
+	struct sc_cmd scsi_cmd;	/* the actual SCSI cmd */
+};
+
+struct sc_buf {
+	struct buf bufstruct;	/* buffer structure containing request
+				   for device -- MUST BE FIRST! */
+	struct scsi scsi_command;	/* the information relating strictly
+					   to the scsi command itself */
+	uint32_t timeout_value;	/* timeout value for the command,
+				   in units of seconds */
+	uint32_t cmd_flag;
+#define FLAG_ABORT              0x01
+
+	uint8_t status_validity;	/* least significant bit - scsi_status
+					 * valid, next least significant bit -
+					 * card status valid */
+
+#define SC_SCSI_ERROR           1	/* scsi status reflects error */
+#define SC_ADAPTER_ERROR        2	/* general card status reflects err */
+	uint8_t scsi_status;	/* returned SCSI Bus status */
+#define SCSI_STATUS_MASK        0x3e	/* mask for useful bits */
+#define SC_GOOD_STATUS          0x00	/* target completed successfully */
+#define SC_CHECK_CONDITION      0x02	/* target is reporting an error,
+					 * exception, or abnormal condition */
+#define SC_BUSY_STATUS          0x08	/* target is busy and cannot accept
+					 * a command from initiator */
+#define SC_INTMD_GOOD           0x10	/* intermediate status good when using
+					 * linked commands */
+#define SC_RESERVATION_CONFLICT 0x18	/* attempted to access a LUN which is
+					 * reserved by another initiator */
+#define SC_COMMAND_TERMINATED   0x22	/* Command has been terminated by
+					 * the device. */
+#define SC_QUEUE_FULL           0x28	/* Device's command queue is full */
+
+	uint8_t general_card_status;	/* SCSI adapter card status byte */
+#define SC_HOST_IO_BUS_ERR      0x01	/* Host I/O Bus error condition */
+#define SC_SCSI_BUS_FAULT       0x02	/* failure of the SCSI Bus */
+#define SC_CMD_TIMEOUT          0x04	/* cmd didn't complete before timeout */
+#define SC_NO_DEVICE_RESPONSE   0x08	/* target device did not respond */
+#define SC_ADAPTER_HDW_FAILURE  0x10	/* indicating a hardware failure */
+#define SC_ADAPTER_SFW_FAILURE  0x20	/* indicating a microcode failure */
+#define SC_FUSE_OR_TERMINAL_PWR 0x40	/* indicating bad fuse or termination */
+#define SC_SCSI_BUS_RESET       0x80	/* detected external SCSI bus reset */
+
+	uint8_t adap_q_status;	/* adapter's device queue status. This */
+#define SC_DID_NOT_CLEAR_Q      0x1	/* SCSI adapter device driver has not */
+
+	uint8_t flags;		/* flags to SCSI adapter driver */
+#define SC_RESUME                0x01	/* resume transaction queueing for this
+					 * id/lun beginning with this sc_buf */
+#define SC_FAILOVER              0x10
+#define SC_LOAD_BALANCE_FAILOVER 0x20
+
+	uint32_t qfull_retry_count;
+	struct dev_info *current_devp;
+	struct dev_info *fover_devp;
+	struct Scsi_Host *fover_host;
+};
+
+#endif				/* _H_OS_SCSIPORT */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_sched.h linux-2.6.3/drivers/scsi/lpfc/elx_sched.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_sched.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_sched.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,259 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef         ELX_SCHED_H
+#define         ELX_SCHED_H
+
+/*
+
+There are two key data structures
+
+A LUN Ring which is just a circular list of all LUNs with pending commands.
+
+A command list.. a linked list of all pending commands for a particular LUN.
+The Comand List is a FIFO used by the scheduler although there are routines
+to search and remove a command from the lists.
+
+The HBA structure a pointer to the LUN Ring along with a pointer to the
+the next LUN to be checked for scheduling. The pointer moves around the ring
+as the scheduler checks for commands to release. The HBA has an pointer to the
+ring and a count of the number of LUNs on the ring. If the count is zero then
+the pointers are undefined.
+
+Pointers to each of the command lists pointers are stored in the LUN table
+along with a count of the number of commands on the list.  The list is
+singularly linked the LUN structure as a pointer to the first and last
+command on the list. If a count is zero, the pointers are undefined.
+
+Each Target Structure has a count of the number of LUNs in the target that
+currently have pended commands. As LUNs enter and exit the LUN Ring, the count
+is incremented and decremented respectively.
+
+The HBA, Targets and LUNs have queue depth limits. There are two counters, the
+number of outstanding commands sent to the SLI layer and the max. number of
+commands that should be sent. Associated with each HBA, Target and LUN is a
+status word that has two states OKAYTOSEND or Paused. If a paused, then no
+pending commands form that object will be scheduled. If OKAYTOSEND then pending
+commands will be released to the SLI layer as the queue depth window opens.
+
+
+*/
+
+/* **************************************************************************
+**
+**   The Pending Scheduler (called SCH here) requires a data structures in
+**   each HBA, Target, LUN and SCSI_BUF. This interface defines the following
+**      conventions for calling these structures :
+**               ELX_type_SCHED_t 
+**                   where type is HBA, LUN, TARGET or SCSI_BUF.
+**
+**   This header should be included BEFORE the actual declarations of the
+**   base structure are defined so the SCH structures can be inline.
+**
+**
+** NOTE:  HBA and LUN SCH structures have a "count" field.
+**        It represents the number of LUNs on the LUN RING and the
+**        number of SCSI_BUFs on the command QUEUEs.  If the "count" is identically 0, 
+**        then the value of all pointers in the SCH structure is NOT DEFINED.
+**        Check the "count" field before attempting to deference any pointers.
+**
+**   Locking consists of a lock in the HBA Scheduler Data
+**   Considerations for working with LUNs or Targets:
+**   1   Pause the LUN, Target, or HBA   ELX_SCHED_PAUSE_<LUN,TARGET,HBA>
+**   2   ELX_SCHED_DEQUEUE_LUN each LUN for commands until NULL is returned
+**   3   Make sure no more commands are sent down with that LUN
+**
+**   Once a LUN pending queue is empty, the Scheduler will have any references
+**   to that LUN structure.
+**
+** ************************************************************************ */
+
+/* ***************************************************************************
+**
+**   Forward declarations needed by the SCHED type structures.  Because
+**   the actual structures will contain these structures and the SCH
+**   structures contains pointers to the containers, the code forward declares
+**   the structure names.
+**
+** ************************************************************************* */
+
+struct elxHBA;
+struct elxScsiTarget;
+struct elxScsiLun;
+struct elx_scsi_buf;
+struct elxIocbq;
+
+typedef enum {
+	ELX_SCHED_STATUS_OKAYTOSEND = 1,	/* Okay to search this list  */
+	ELX_SCHED_STATUS_PAUSED = 2,	/* Do not schedule this list */
+} ELX_SCHED_STATUS_t;
+
+typedef struct elxSchedHBA {
+	ELX_TQS_LINK(elx_scsi_buf) highPriorityCmdList;	/* High priority command queue */
+	uint16_t targetCount;	/* Number of elements on Ring */
+	struct elxScsiTarget *targetList;	/* Ptr to the LUN ring Only valid if lunCount >0 */
+	struct elxScsiTarget *nextTargetToCheck;	/* Ptr to Target that should be checked next */
+	uint16_t maxOutstanding;	/* These 2 words implement queue */
+	uint16_t currentOutstanding;	/* Depth on the HBA. */
+	ELX_SCHED_STATUS_t status;	/* Status word for stopping any scheduling of the HBA */
+} ELX_SCHED_HBA_t;		/*   layer without queueing */
+
+/* ****************************************************************************
+**
+**    Scheduler Data for Target
+**
+**   lunCount lunList and nextLunToCheck are used to
+**   manage a list of LUNs that have pending commands
+**   We keep here the queue depth for the Target, Target Queue Status
+**
+** **************************************************************************** */
+
+typedef struct elxSchedTarget {
+	struct elxScsiLun *lunList;	/* Ptr to the LUN ring Only valid if lunCount >0 */
+	struct elxScsiLun *nextLunToCheck;	/* Ptr to LUN that should be checked next */
+	 ELX_TQD_LINK(elxScsiTarget) targetRing;
+	int16_t lunCount;	/* Number of elements on Ring */
+	int16_t maxOutstanding;	/* Max # of commands that can be outstanding */
+	int16_t currentOutstanding;	/* # of commands that currently outstanding. */
+	ELX_SCHED_STATUS_t status;	/* Pended entries can be scheduled or */
+	/*   or not at this time. */
+} ELX_SCHED_TARGET_t;
+
+/* ****************************************************************************
+**
+**    Scheduler Data for a LUN
+**
+**   SCSI_BUFs that are pending are keeped on a singly link list.
+**   Each LUN_SCH has a pointer to the first and last entry.
+**   In most cases 99.9999% all commands are released FIFO
+**   exceptions are ABORT, LUN and Target Resets (and internal
+**   conditions that have the same effect).
+**
+**  The "count" field is the number of commands on list.  If count is identically 0
+**  the values of firstCommand and lastCommand are undefined.
+**
+**  LUNS with pending commands are doubly linked into a ring.
+**  nextLun and previousLun point to other LUNs on the ring.
+**  (HBA_SCH contains a pointer to the LUN RING.)
+**  If count is identically 0 then there are no commands and therefore
+**  the LUN is NOT on the ring and therefore the
+**  nextLUN and previousLun are undefined when
+**  count is identically 0.
+**
+**  Status is used to signal whether commands on this LUN
+**  can be scheduled.
+**
+**  maxOutstanding and currentOutstanding are used for queue depth
+**  management for this LUN
+**
+**  Only Statistic variable is maxCount which is the max number of commands
+**  ever queued by this LUN.
+** **************************************************************************** */
+
+typedef struct {
+	ELX_TQS_LINK(elx_scsi_buf) commandList;	/* Next command to be scheduled */
+	ELX_TQD_LINK(elxScsiLun) lunRing;	/* links used for the LUN Ring   */
+	ELX_SCHED_STATUS_t status;	/*Status of this LUN's queue   */
+	uint16_t maxOutstanding;	/*Queue Depth for the LUN      */
+	uint16_t currentOutstanding;
+} ELX_SCHED_LUN_t;
+
+/*    Scheduler Data for each Command   */
+
+typedef struct {
+	struct elx_scsi_buf *nextCommand;
+} ELX_SCHED_SCSI_BUF_t;
+
+/* ********************** FUNCTION DECLARATIONS   **************************
+**
+**   The next 3 routines initialize the SCH structures. Basically
+**   clear the block and set the queue depth.  No Lock is taken
+**
+** ********************************************************************** */
+
+void elx_sched_hba_init(struct elxHBA *hba, uint16_t maxOutstanding);
+void elx_sched_target_init(struct elxScsiTarget *target,
+			   uint16_t maxOutstanding);
+void elx_sched_lun_init(struct elxScsiLun *lun, uint16_t maxOutstanding);
+
+/* **********************************************************************
+**
+**   Pause and Continue the scheduler
+**
+** ********************************************************************* */
+
+void elx_sched_pause_target(struct elxScsiTarget *target);
+void elx_sched_pause_hba(struct elxHBA *hba);
+void elx_sched_continue_target(struct elxScsiTarget *target);
+void elx_sched_continue_hba(struct elxHBA *hba);
+
+/* ********************************************************************
+**   Used to schedule a SCSI IO (including Task Management) IOCBs
+**   to be passed to the SLI layer.  HBA -> to the HBA structure
+**   command pts to the SCSI_BUF to be submitted.
+** ********************************************************************** */
+
+void elx_sched_submit_command(struct elxHBA *hba, struct elx_scsi_buf *command);
+void elx_sched_service_high_priority_queue(struct elxHBA *pHba);
+
+/*      
+ * When a command is returned from the SLI layer, pass it back through
+ * the scheduler so the queue depths can be updated.  Scheduling is NOT.
+ * performed as part of this command.  This approach allows multiple 
+ * completions before insertions and reduces recursion issues.
+ */
+
+void elx_sched_sli_done(struct elxHBA *hba, struct elxIocbq *iocbqin,
+			struct elxIocbq *iocbqout);
+
+/* **************************************************************************
+**
+**   Use this command to kick of a search of pended SCSI_BUFs to be sent to the
+**   SLI layer.
+**
+** ******************************************************************************/
+
+void elx_sched_check(struct elxHBA *hba);
+
+/* **************************************************************************
+**
+**   Check to see if a command is currently in the scheduler and removes
+**   it if it is.  Returns NULL if not found or the pointer if it was found
+**
+**   DEQUEUE_LUN just gets the first command on the LUN pending queue
+**   or NULL if there are none.  (You might want to pause the LUN before this call).
+**
+** ******************************************************************************/
+
+struct elx_scsi_buf *elx_sched_dequeue(struct elxHBA *hba,
+				       struct elx_scsi_buf *command);
+
+uint32_t elx_sched_flush_hba(struct elxHBA *hba, uint8_t status,
+			     uint32_t word4);
+uint32_t elx_sched_flush_target(struct elxHBA *hba,
+				struct elxScsiTarget *target, uint8_t status,
+				uint32_t word4);
+uint32_t elx_sched_flush_lun(struct elxHBA *hba, struct elxScsiLun *lun,
+			     uint8_t status, uint32_t word4);
+uint32_t elx_sched_flush_command(struct elxHBA *hba,
+				 struct elx_scsi_buf *command, uint8_t status,
+				 uint32_t word4);
+
+#endif
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_scsi.h linux-2.6.3/drivers/scsi/lpfc/elx_scsi.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_scsi.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_scsi.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,449 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_SCSI
+#define _H_ELX_SCSI
+
+/*
+ * SCSI node structure for each open Fibre Channel node
+ * used by scsi transport.
+ */
+
+typedef struct elxScsiTarget {
+	elxHBA_t *pHba;		/* adapter structure ptr */
+	ELX_SLINK_t lunlist;
+	void *pcontext;		/* ELX_NODELIST_t * for device */
+	void *tmofunc;
+	void *rptlunfunc;
+	ELX_SCHED_TARGET_t targetSched;	/* Scheduling Info for this target */
+
+	uint16_t scsi_cap;
+	uint16_t scsi_sync;
+	uint32_t scsi_options;
+	uint16_t max_lun;	/* max lun supported */
+	uint16_t scsi_id;	/* SCSI ID of this device */
+
+	uint16_t rpi;
+
+	uint16_t targetFlags;
+#define FC_NODEV_TMO        0x1	/* nodev-tmo tmr started and expired */
+#define FC_FCP2_RECOVERY    0x2	/* set FCP2 Recovery for commands */
+#define FC_RETRY_RPTLUN     0x4	/* Report Lun has been retried */
+#define FC_NPR_ACTIVE       0x10	/* NPort Recovery active */
+
+	uint16_t addrMode;	/* SCSI address method */
+#define PERIPHERAL_DEVICE_ADDRESSING    0
+#define VOLUME_SET_ADDRESSING           1
+#define LOGICAL_UNIT_ADDRESSING         2
+
+	uint16_t rptLunState;	/* For report lun SCSI command */
+#define REPORT_LUN_REQUIRED     0
+#define REPORT_LUN_ONGOING      1
+#define REPORT_LUN_COMPLETE     2
+#define REPORT_LUN_ERRORED      3
+
+	DMABUF_t *RptLunData;
+
+	void *pTargetProto;	/* target struc for driver type */
+	void *pTargetOSEnv;
+
+	uint32_t node_flag;	/* match node on WWPN WWNN or DID */
+	union {
+		uint32_t dev_did;	/* SCSI did */
+	} un;
+
+} ELXSCSITARGET_t;
+
+#define MAX_ELX_SNS       128
+#define ELX_SCSI_BUF_SZ   1024	/* used for driver generated scsi cmds */
+#define ELX_INQSN_SZ      64	/* Max size of Inquiry serial number */
+
+struct fcPathId;
+struct fcRouteId;
+
+struct elxScsiLun {
+	ELX_NODELIST_t *pnode;	/* Pointer to the node structure. */
+	elxHBA_t *pHBA;		/* Pointer to the HBA with
+				   which this LUN is
+				   associated. */
+	ELXSCSITARGET_t *pTarget;	/* Pointer to the target structure */
+	struct elxScsiLun *pnextLun;	/* Used for list of LUNs on this node */
+
+	uint64_t lun_id;	/* LUN ID of this device */
+
+	uint8_t first_check;	/* flag for first check condition */
+#define FIRST_CHECK_COND        0x1
+#define FIRST_IO                0x2
+
+	uint8_t opened;
+	uint8_t ioctl_wakeup;	/* wakeup sleeping ioctl call */
+	uint32_t ioctl_event;
+	uint32_t ioctl_errno;
+	uint32_t stop_event;
+
+	ELX_SLINK_t lun_waiting;	/* luns waiting for us to send io to */
+	ELX_DLINK_t lun_abort_bdr;	/* luns waiting for abdr */
+
+	/* list of dma-able memory to be used for fcp_cmd and fcp_rsp */
+	ELX_SLINK_t scsi_buf_list;
+
+	uint32_t qfullcnt;
+	uint32_t qcmdcnt;
+	uint32_t iodonecnt;
+	uint32_t errorcnt;
+
+	void *pLunOSEnv;
+
+	/*
+	 *  A command lives in a pending queue until it is sent to the HBA.
+	 *  Throttling constraints apply:
+	 *          No more than N commands total to a single target
+	 *          No more than M commands total to a single LUN on that target
+	 *
+	 *  A command that has left the pending queue and been sent to the HBA
+	 *  is an "underway" command.  We count underway commands, per-LUN,
+	 *  to obey the LUN throttling constraint.
+	 *
+	 *  Because we only allocate enough fc_buf_t structures to handle N
+	 *  commands, per target, we implicitly obey the target throttling
+	 *  constraint by being unable to send a command when we run out of
+	 *  free fc_buf_t structures.
+	 *
+	 *  We count the number of pending commands to determine whether the
+	 *  target has I/O to be issued at all.
+	 *
+	 *  We use next_pending to rotor through the LUNs, issuing one I/O at
+	 *  a time for each LUN.  This mechanism guarantees a fair distribution
+	 *  of I/Os across LUNs in the face of a target queue_depth lower than
+	 *  #LUNs*fcp_lun_queue_depth.
+	 */
+
+	ELX_SCHED_LUN_t lunSched;	/* Used to schedule I/O to HBA */
+	uint16_t fcp_lun_queue_depth;	/* maximum # cmds to each lun */
+	uint8_t stop_send_io;	/* stop sending any io to this dev */
+	uint8_t lunQState;	/* device general queue state */
+#define ACTIVE                  0
+#define STOPPING                1
+#define HALTED                  2
+#define RESTART_WHEN_READY      3
+#define ACTIVE_PASSTHRU         4
+#define WAIT_RESUME             8
+#define WAIT_INFO               10
+#define WAIT_ACA                11
+#define WAIT_FLUSH              12
+#define WAIT_HEAD_RESUME        13
+
+	uint32_t lunFlag;	/* flags for the drive */
+#define SCSI_TQ_HALTED        0x0001	/* The transaction Q is halted */
+#define SCSI_TQ_CLEARING      0x0002	/* The transaction Q is clearing */
+#define SCSI_TQ_CLEAR_ACA     0x0004	/* a CLEAR_ACA is PENDING      */
+#define SCSI_LUN_RESET        0x0008	/* sent LUN_RESET not of TARGET_RESET */
+#define SCSI_ABORT_TSET       0x0010	/* BDR requested but not yet sent */
+#define SCSI_TARGET_RESET     0x0020	/* a SCSI BDR is active for device */
+#define CHK_SCSI_ABDR         0x0038	/* value used to check tm flags */
+#define QUEUED_FOR_ABDR       0x0040	/* dev_ptr is on ABORT_BDR queue */
+#define NORPI_RESET_DONE      0x0100	/* BOGUS_RPI Bus Reset attempted */
+#define LUN_BLOCKED           0x0200	/* if flag is set, this lun has been blocked */
+#define SCSI_IOCTL_INPROGRESS 0x0400	/* An ioctl is in progress  */
+#define SCSI_BUMP_QDEPTH      0x0800	/* bump qdepth to max after cmpl */
+#define SCSI_SEND_INQUIRY_SN  0x1000	/* Serial number inq should be sent */
+#define SCSI_INQUIRY_SN       0x2000	/* Serial number inq has been sent */
+#define SCSI_INQUIRY_P0       0x4000	/* Page 0 inq has been sent */
+#define SCSI_INQUIRY_CMD      0x6000	/* Serial number or Page 0 inq sent */
+#define SCSI_P0_INFO          0x20000	/* device has good P0 info */
+
+	uint8_t sense[MAX_ELX_SNS];	/* Temporary request sense buffer */
+	uint8_t sense_valid;	/* flag to indicate new sense data */
+	uint32_t sense_length;	/* new sense data length */
+
+	uint16_t qfull_retries;	/* # of retries on qfull condition */
+#define MAX_QFULL_RETRIES   255
+#define MAX_QFULL_RETRY_INTERVAL 1000	/* 1000 (ms) */
+
+	uint16_t qfull_retry_interval;	/* the interval for qfull retry */
+	void *qfull_tmo_id;
+
+	uint32_t failMask;	/* failure mask for device */
+
+	uint8_t InquirySN[ELX_INQSN_SZ];	/* serial number from Inquiry */
+	uint8_t Vendor[8];	/* From Page 0 Inquiry */
+	uint8_t Product[16];	/* From Page 0 Inquiry */
+	uint8_t Rev[4];		/* From Page 0 Inquiry */
+	uint8_t sizeSN;		/* size of InquirySN */
+};
+
+typedef struct elxScsiLun ELXSCSILUN_t;
+
+#define ELX_MIN_QFULL    1	/* lowest we can decrement throttle */
+
+#define FCP_CONTINUE    0x01	/* flag for issue_fcp_cmd */
+#define FCP_REQUEUE     0x02	/* flag for issue_fcp_cmd */
+#define FCP_EXIT        0x04	/* flag for issue_fcp_cmd */
+
+typedef struct _FCP_RSP {
+	uint32_t rspRsvd1;	/* FC Word 0, byte 0:3 */
+	uint32_t rspRsvd2;	/* FC Word 1, byte 0:3 */
+
+	uint8_t rspStatus0;	/* FCP_STATUS byte 0 (reserved) */
+	uint8_t rspStatus1;	/* FCP_STATUS byte 1 (reserved) */
+	uint8_t rspStatus2;	/* FCP_STATUS byte 2 field validity */
+#define RSP_LEN_VALID  0x01	/* bit 0 */
+#define SNS_LEN_VALID  0x02	/* bit 1 */
+#define RESID_OVER     0x04	/* bit 2 */
+#define RESID_UNDER    0x08	/* bit 3 */
+	uint8_t rspStatus3;	/* FCP_STATUS byte 3 SCSI status byte */
+#define SCSI_STAT_GOOD        0x00
+#define SCSI_STAT_CHECK_COND  0x02
+#define SCSI_STAT_COND_MET    0x04
+#define SCSI_STAT_BUSY        0x08
+#define SCSI_STAT_INTERMED    0x10
+#define SCSI_STAT_INTERMED_CM 0x14
+#define SCSI_STAT_RES_CNFLCT  0x18
+#define SCSI_STAT_CMD_TERM    0x22
+#define SCSI_STAT_QUE_FULL    0x28
+
+	uint32_t rspResId;	/* Residual xfer if residual count field set in fcpStatus2 */
+	/* Received in Big Endian format */
+	uint32_t rspSnsLen;	/* Length of sense data in fcpSnsInfo */
+	/* Received in Big Endian format */
+	uint32_t rspRspLen;	/* Length of FCP response data in fcpRspInfo */
+	/* Received in Big Endian format */
+
+	uint8_t rspInfo0;	/* FCP_RSP_INFO byte 0 (reserved) */
+	uint8_t rspInfo1;	/* FCP_RSP_INFO byte 1 (reserved) */
+	uint8_t rspInfo2;	/* FCP_RSP_INFO byte 2 (reserved) */
+	uint8_t rspInfo3;	/* FCP_RSP_INFO RSP_CODE byte 3 */
+
+#define RSP_NO_FAILURE       0x00
+#define RSP_DATA_BURST_ERR   0x01
+#define RSP_CMD_FIELD_ERR    0x02
+#define RSP_RO_MISMATCH_ERR  0x03
+#define RSP_TM_NOT_SUPPORTED 0x04	/* Task mgmt function not supported */
+#define RSP_TM_NOT_COMPLETED 0x05	/* Task mgmt function not performed */
+
+	uint32_t rspInfoRsvd;	/* FCP_RSP_INFO bytes 4-7 (reserved) */
+
+	uint8_t rspSnsInfo[MAX_ELX_SNS];
+#define SNS_ILLEGAL_REQ 0x05	/* sense key is byte 3 ([2]) */
+#define SNSCOD_BADCMD 0x20	/* sense code is byte 13 ([12]) */
+} FCP_RSP, *PFCP_RSP;
+
+typedef struct _FCP_CMND {
+	uint32_t fcpLunMsl;	/* most  significant lun word (32 bits) */
+	uint32_t fcpLunLsl;	/* least significant lun word (32 bits) */
+	/* # of bits to shift lun id to end up in right
+	 * payload word, little endian = 8, big = 16.
+	 */
+#if LITTLE_ENDIAN_HW
+#define FC_LUN_SHIFT         8
+#define FC_ADDR_MODE_SHIFT   0
+#endif
+#if BIG_ENDIAN_HW
+#define FC_LUN_SHIFT         16
+#define FC_ADDR_MODE_SHIFT   24
+#endif
+
+	uint8_t fcpCntl0;	/* FCP_CNTL byte 0 (reserved) */
+	uint8_t fcpCntl1;	/* FCP_CNTL byte 1 task codes */
+#define  SIMPLE_Q        0x00
+#define  HEAD_OF_Q       0x01
+#define  ORDERED_Q       0x02
+#define  ACA_Q           0x04
+#define  UNTAGGED        0x05
+	uint8_t fcpCntl2;	/* FCP_CTL byte 2 task management codes */
+#define  ABORT_TASK_SET  0x02	/* Bit 1 */
+#define  CLEAR_TASK_SET  0x04	/* bit 2 */
+#define  BUS_RESET       0x08	/* bit 3 */
+#define  LUN_RESET       0x10	/* bit 4 */
+#define  TARGET_RESET    0x20	/* bit 5 */
+#define  CLEAR_ACA       0x40	/* bit 6 */
+#define  TERMINATE_TASK  0x80	/* bit 7 */
+	uint8_t fcpCntl3;
+#define  WRITE_DATA      0x01	/* Bit 0 */
+#define  READ_DATA       0x02	/* Bit 1 */
+
+	uint8_t fcpCdb[16];	/* SRB cdb field is copied here */
+	uint32_t fcpDl;		/* Total transfer length */
+
+} FCP_CMND, *PFCP_CMND;
+
+/* SCSI INQUIRY Command Structure */
+
+typedef struct inquiryDataType {
+	uint8_t DeviceType:5;
+	uint8_t DeviceTypeQualifier:3;
+
+	uint8_t DeviceTypeModifier:7;
+	uint8_t RemovableMedia:1;
+
+	uint8_t Versions;
+	uint8_t ResponseDataFormat;
+	uint8_t AdditionalLength;
+	uint8_t Reserved[2];
+
+	uint8_t SoftReset:1;
+	uint8_t CommandQueue:1;
+	uint8_t Reserved2:1;
+	uint8_t LinkedCommands:1;
+	uint8_t Synchronous:1;
+	uint8_t Wide16Bit:1;
+	uint8_t Wide32Bit:1;
+	uint8_t RelativeAddressing:1;
+
+	uint8_t VendorId[8];
+	uint8_t ProductId[16];
+	uint8_t ProductRevisionLevel[4];
+	uint8_t VendorSpecific[20];
+	uint8_t Reserved3[40];
+} INQUIRY_DATA_DEF;
+
+typedef struct _READ_CAPACITY_DATA {
+	uint32_t LogicalBlockAddress;
+	uint32_t BytesPerBlock;
+} READ_CAPACITY_DATA_DEF;
+
+/* SCSI CDB command codes */
+#define FCP_SCSI_FORMAT_UNIT                  0x04
+#define FCP_SCSI_INQUIRY                      0x12
+#define FCP_SCSI_MODE_SELECT                  0x15
+#define FCP_SCSI_MODE_SENSE                   0x1A
+#define FCP_SCSI_PAUSE_RESUME                 0x4B
+#define FCP_SCSI_PLAY_AUDIO                   0x45
+#define FCP_SCSI_PLAY_AUDIO_EXT               0xA5
+#define FCP_SCSI_PLAY_AUDIO_MSF               0x47
+#define FCP_SCSI_PLAY_AUDIO_TRK_INDX          0x48
+#define FCP_SCSI_PREVENT_ALLOW_REMOVAL        0x1E
+#define FCP_SCSI_READ                         0x08
+#define FCP_SCSI_READ_BUFFER                  0x3C
+#define FCP_SCSI_READ_CAPACITY                0x25
+#define FCP_SCSI_READ_DEFECT_LIST             0x37
+#define FCP_SCSI_READ_EXTENDED                0x28
+#define FCP_SCSI_READ_HEADER                  0x44
+#define FCP_SCSI_READ_LONG                    0xE8
+#define FCP_SCSI_READ_SUB_CHANNEL             0x42
+#define FCP_SCSI_READ_TOC                     0x43
+#define FCP_SCSI_REASSIGN_BLOCK               0x07
+#define FCP_SCSI_RECEIVE_DIAGNOSTIC_RESULTS   0x1C
+#define FCP_SCSI_RELEASE_UNIT                 0x17
+#define FCP_SCSI_REPORT_LUNS                  0xa0
+#define FCP_SCSI_REQUEST_SENSE                0x03
+#define FCP_SCSI_RESERVE_UNIT                 0x16
+#define FCP_SCSI_REZERO_UNIT                  0x01
+#define FCP_SCSI_SEEK                         0x0B
+#define FCP_SCSI_SEEK_EXTENDED                0x2B
+#define FCP_SCSI_SEND_DIAGNOSTIC              0x1D
+#define FCP_SCSI_START_STOP_UNIT              0x1B
+#define FCP_SCSI_TEST_UNIT_READY              0x00
+#define FCP_SCSI_VERIFY                       0x2F
+#define FCP_SCSI_WRITE                        0x0A
+#define FCP_SCSI_WRITE_AND_VERIFY             0x2E
+#define FCP_SCSI_WRITE_BUFFER                 0x3B
+#define FCP_SCSI_WRITE_EXTENDED               0x2A
+#define FCP_SCSI_WRITE_LONG                   0xEA
+#define FCP_SCSI_RELEASE_LUNR                 0xBB
+#define FCP_SCSI_RELEASE_LUNV                 0xBF
+
+#define HPVA_SETPASSTHROUGHMODE               0x27
+#define HPVA_EXECUTEPASSTHROUGH               0x29
+#define HPVA_CREATELUN                        0xE2
+#define HPVA_SETLUNSECURITYLIST               0xED
+#define HPVA_SETCLOCK                         0xF9
+#define HPVA_RECOVER                          0xFA
+#define HPVA_GENERICSERVICEOUT                0xFD
+
+#define DMEP_EXPORT_IN                        0x85
+#define DMEP_EXPORT_OUT                       0x89
+
+#define MDACIOCTL_DIRECT_CMD                  0x22
+#define MDACIOCTL_STOREIMAGE                  0x2C
+#define MDACIOCTL_WRITESIGNATURE              0xA6
+#define MDACIOCTL_SETREALTIMECLOCK            0xAC
+#define MDACIOCTL_PASS_THRU_CDB               0xAD
+#define MDACIOCTL_PASS_THRU_INITIATE          0xAE
+#define MDACIOCTL_CREATENEWCONF               0xC0
+#define MDACIOCTL_ADDNEWCONF                  0xC4
+#define MDACIOCTL_MORE                        0xC6
+#define MDACIOCTL_SETPHYSDEVPARAMETER         0xC8
+#define MDACIOCTL_SETLOGDEVPARAMETER          0xCF
+#define MDACIOCTL_SETCONTROLLERPARAMETER      0xD1
+#define MDACIOCTL_WRITESANMAP                 0xD4
+#define MDACIOCTL_SETMACADDRESS               0xD5
+
+struct elx_scsi_buf {
+/*   ELX_DLINK_t          scsibuf_list;     replacing fc_fwd, fc_bkwd */
+	ELX_SCHED_SCSI_BUF_t commandSched;	/* used by Scheduler */
+	uint32_t scsitmo;	/* IN */
+	uint32_t timeout;	/* IN */
+	elxHBA_t *scsi_hba;	/* IN */
+	uint8_t scsi_bus;	/* IN */
+	uint16_t scsi_target;	/* IN */
+	uint64_t scsi_lun;	/* IN */
+
+	void *pOSCmd;		/* IN */
+
+	uint32_t qfull_retry_count;	/* internal to scsi xport */
+	uint16_t flags;		/* flags for this cmd */
+#define DATA_MAPPED     0x0001	/* data buffer has been D_MAPed */
+#define FCBUF_ABTS      0x0002	/* ABTS has been sent for this cmd */
+#define FCBUF_ABTS2     0x0004	/* ABTS has been sent twice */
+#define FCBUF_INTERNAL  0x0008	/* Internal generated driver command */
+#define ELX_SCSI_ERR    0x0010
+	uint16_t IOxri;		/* From IOCB Word 6- ulpContext */
+	uint16_t status;	/* From IOCB Word 7- ulpStatus */
+	uint32_t result;	/* From IOCB Word 4. */
+
+	/*
+	 * Define an OS-specific structure to capture the extra buffer
+	 * pOSCmd requires of the driver.
+	 */
+	ELX_OS_IO_t OS_io_info;	/* bp, resid, cmd_flags, cmd_dmahandle etc. */
+
+	ELXSCSILUN_t *pLun;
+
+	/* dma_ext has both virt, phys to dma-able buffer
+	 * which contains fcp_cmd, fcp_rsp and scatter gather list fro upto 
+	 * 68 (ELX_SCSI_BPL_SIZE) BDE entries,
+	 * xfer length, cdb, data direction....
+	 */
+	DMABUF_t *dma_ext;
+	struct _FCP_CMND *fcp_cmnd;
+	struct _FCP_RSP *fcp_rsp;
+	ULP_BDE64 *fcp_bpl;
+
+	/* cur_iocbq has phys of the dma-able buffer.
+	 * Iotag is in here */
+	ELX_IOCBQ_t cur_iocbq;
+
+	void (*cmd_cmpl) (elxHBA_t *, struct elx_scsi_buf *);	/* IN */
+};
+
+typedef struct elx_scsi_buf ELX_SCSI_BUF_t;
+
+#define ELX_SCSI_INITIAL_BPL_SIZE  65	/* Number of scsi buf BDEs in fcp_bpl */
+
+#define FAILURE -1
+#define ELX_CMD_STATUS_ABORTED -1
+
+#define ELX_INTERNAL_RESET   0	/* internal reset */
+#define ELX_EXTERNAL_RESET   1	/* external reset, scsi layer */
+#define ELX_ISSUE_LUN_RESET  2	/* flag for reset routine to issue LUN_RESET */
+#define ELX_ISSUE_ABORT_TSET 4	/* flag for reset routine to issue ABORT_TSET */
+
+#endif				/* _H_ELX_SCSI */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_sli.h linux-2.6.3/drivers/scsi/lpfc/elx_sli.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_sli.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_sli.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,224 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_SLI
+#define _H_ELX_SLI
+
+#define IOCB_CMD_WSIZE  8	/* Length, in words, of a IOCB command */
+#define MBOX_CMD_WSIZE  32	/* max length, in words, of a mailbox command */
+
+/* forward declaration for ELX_IOCB_t's use */
+struct elxHBA;
+struct elxclock;
+
+/* This structure is used to handle IOCB requests / responses */
+typedef struct elxIocbq {
+	/* IOCBQs are used in double linked lists */
+	struct elxIocbq *q_f;	/* ptr to next iocb entry */
+	struct elxIocbq *q_b;	/* ptr to previous iocb entry */
+	IOCB_t iocb;		/* IOCB cmd */
+	uint8_t retry;		/* retry counter for IOCB cmd - if needed */
+	uint8_t iocb_flag;
+#define ELX_IO_POLL	1	/* Polling mode iocb */
+#define ELX_IO_IOCTL	2	/* IOCTL iocb */
+#define ELX_IO_WAIT	4
+
+	uint8_t abort_count;
+	uint8_t rsvd2;
+	uint32_t drvrTimeout;	/* driver timeout in seconds */
+	void *context1;		/* caller context information */
+	void *context2;		/* caller context information */
+	void *context3;		/* caller context information */
+
+	void (*iocb_cmpl) (struct elxHBA *, struct elxIocbq *,
+			   struct elxIocbq *);
+
+} ELX_IOCBQ_t;
+
+#define SLI_IOCB_USE_TXQ       1	/* Queue IOCB to txq if cmd ring full */
+#define SLI_IOCB_RET_IOCB      2	/* Return IOCB if cmd ring full */
+#define SLI_IOCB_POLL          4	/* poll for completion */
+#define SLI_IOCB_HIGH_PRIORITY 8	/* High priority command */
+
+#define IOCB_SUCCESS        0
+#define IOCB_BUSY           1
+#define IOCB_ERROR          2
+#define IOCB_TIMEDOUT       3
+
+typedef struct elxMboxq {
+	/* MBOXQs are used in single linked lists */
+	struct elxMboxq *q_f;	/* ptr to next mailbox command */
+	MAILBOX_t mb;		/* Mailbox cmd */
+	void *context1;		/* caller context information */
+	void *context2;		/* caller context information */
+
+	void (*mbox_cmpl) (struct elxHBA *, struct elxMboxq *);
+
+} ELX_MBOXQ_t;
+
+#define MBX_POLL        1	/* poll mailbox till command done, then return */
+#define MBX_NOWAIT      2	/* issue command then return immediately */
+#define MBX_STOP_IOCB   4	/* Stop iocb processing till mbox cmds complete */
+
+#define ELX_MAX_RING_MASK  4	/* max num of rctl/type masks allowed per ring */
+#define ELX_MAX_RING       4	/* max num of SLI rings used by driver */
+
+/* Structure used to hold SLI ring information */
+typedef struct {
+	uint16_t flag;		/* ring flags */
+#define ELX_DEFERRED_RING_EVENT 0x001	/* Deferred processing a ring event */
+#define ELX_CALL_RING_AVAILABLE 0x002	/* indicates cmd was full */
+#define ELX_STOP_IOCB_MBX       0x010	/* Stop processing IOCB cmds mbox */
+#define ELX_STOP_IOCB_EVENT     0x020	/* Stop processing IOCB cmds event */
+#define ELX_STOP_IOCB_MASK      0x030	/* Stop processing IOCB cmds mask */
+	uint16_t abtsiotag;	/* tracks next iotag to use for ABTS */
+
+	uint8_t rsvd;
+	uint8_t ringno;		/* ring number */
+	uint8_t rspidx;		/* current index in response ring */
+	uint8_t cmdidx;		/* current index in command ring */
+	ELX_IOCBQ_t *fast_lookup;	/* array of IOCB ptrs indexed by iotag */
+	ELX_DLINK_t txq;	/* iocb command queue */
+	ELX_DLINK_t txcmplq;	/* iocb pending queue */
+	volatile uint32_t *cmdringaddr;	/* virtual address for cmd rings */
+	volatile uint32_t *rspringaddr;	/* virtual address for rsp rings */
+	uint32_t missbufcnt;	/* keep track of buffers to post */
+	ELX_SLINK_t postbufq;	/* posted buffer list */
+	ELX_SLINK_t iocb_continueq;	/* track IOCB continues between interrupts */
+} ELX_SLI_RING_t;
+
+/* Structure used for configuring rings to a specific profile or rctl / type */
+typedef struct {
+	struct {
+		uint8_t profile;	/* profile associated with ring */
+		uint8_t rctl;	/* rctl / type pair configured for ring */
+		uint8_t type;	/* rctl / type pair configured for ring */
+		uint8_t rsvd;
+		/* rcv'd unsol event */
+		void (*elx_sli_rcv_unsol_event) (struct elxHBA *,
+						 ELX_SLI_RING_t *,
+						 ELX_IOCBQ_t *);
+	} prt[ELX_MAX_RING_MASK];
+	uint32_t num_mask;	/* number of mask entries in prt array */
+	uint32_t iotag_ctr;	/* keeps track of the next iotag to use */
+	uint32_t iotag_max;	/* keeps track of the next iotag to use */
+	uint32_t fast_iotag;	/* fast lookup based on iotag */
+	uint16_t numCiocb;	/* number of command iocb's per ring */
+	uint16_t numRiocb;	/* number of rsp iocb's per ring */
+	/* cmd ring available */
+	void (*elx_sli_cmd_available) (struct elxHBA *, ELX_SLI_RING_t *);
+} ELX_RING_INIT_t;
+
+typedef struct {
+	ELX_RING_INIT_t ringinit[ELX_MAX_RING];	/* ring initialization info */
+
+	/* HBA initialization callback routines */
+	int (*elx_sli_config_port_prep) (struct elxHBA *);
+	int (*elx_sli_config_port_post) (struct elxHBA *);
+	uint32_t *(*elx_sli_config_pcb_setup) (struct elxHBA *);
+	int (*elx_sli_hba_down_prep) (struct elxHBA *);
+
+	/* HBA interrupt callback routines */
+	 uint32_t(*elx_sli_intr_prep) (struct elxHBA *);
+	void (*elx_sli_handle_eratt) (struct elxHBA *, uint32_t);
+	void (*elx_sli_handle_latt) (struct elxHBA *);
+	void (*elx_sli_intr_post) (struct elxHBA *);
+	 uint32_t(*elx_sli_register_intr) (struct elxHBA *);
+	void (*elx_sli_unregister_intr) (struct elxHBA *);
+
+	/* HBA SLIM / Register access routines */
+	 uint32_t(*elx_sli_read_HA) (struct elxHBA *);
+	 uint32_t(*elx_sli_read_CA) (struct elxHBA *);
+	 uint32_t(*elx_sli_read_HS) (struct elxHBA *);
+	 uint32_t(*elx_sli_read_HC) (struct elxHBA *);
+	void (*elx_sli_write_HA) (struct elxHBA *, uint32_t);
+	void (*elx_sli_write_CA) (struct elxHBA *, uint32_t);
+	void (*elx_sli_write_HS) (struct elxHBA *, uint32_t);
+	void (*elx_sli_write_HC) (struct elxHBA *, uint32_t);
+	void (*elx_sli_write_titan_HS) (struct elxHBA *, uint32_t);
+	void (*elx_sli_read_slim) (struct elxHBA *, uint8_t *, int, int);
+	void (*elx_sli_write_slim) (struct elxHBA *, uint8_t *, int, int);
+	 uint32_t(*elx_sli_read_pci) (struct elxHBA *, int);
+	 uint16_t(*elx_sli_read_pci_cmd) (struct elxHBA *);
+	void (*elx_sli_write_pci_cmd) (struct elxHBA *, uint16_t);
+	void (*elx_sli_setup_slim_access) (struct elxHBA *);
+
+	/* General purpose callback routines */
+	void (*elx_sli_brdreset) (struct elxHBA *);
+
+	uint32_t num_rings;
+	uint32_t sli_flag;
+#define ELX_HGP_HOSTSLIM    1	/* Use Host Group pointers in HOST SLIM */
+} ELX_SLI_INIT_t;
+
+/* Structure used to hold SLI statistical counters and info */
+typedef struct {
+	uint64_t iocbEvent[ELX_MAX_RING];	/* IOCB event counters */
+	uint64_t iocbCmd[ELX_MAX_RING];	/* IOCB cmd issued */
+	uint64_t iocbRsp[ELX_MAX_RING];	/* IOCB rsp received */
+	uint64_t iocbCmdDelay[ELX_MAX_RING];	/* IOCB cmd ring delay */
+	uint64_t iocbCmdFull[ELX_MAX_RING];	/* IOCB cmd ring full */
+	uint64_t iocbCmdEmpty[ELX_MAX_RING];	/* IOCB cmd ring is now empty */
+	uint64_t iocbRspFull[ELX_MAX_RING];	/* IOCB rsp ring full */
+	uint64_t mboxStatErr;	/* Mbox cmds completed status error */
+	uint64_t mboxCmd;	/* Mailbox commands issued */
+	uint64_t sliIntr;	/* Count of Host Attention interrupts */
+	uint32_t errAttnEvent;	/* Error Attn event counters */
+	uint32_t linkEvent;	/* Link event counters */
+	uint32_t mboxEvent;	/* Mailbox event counters */
+	uint32_t mboxBusy;	/* Mailbox cmd busy */
+} ELX_SLI_STAT_t;
+
+/* Structure used to hold SLI information */
+typedef struct elx_sli {
+	ELX_SLI_INIT_t sliinit;	/* initialization info */
+	/* Additional sli_flags */
+#define ELX_SLI_MBOX_ACTIVE      0x100	/* HBA mailbox is currently active */
+#define ELX_SLI2_ACTIVE          0x200	/* SLI2 overlay in firmware is active */
+#define ELX_PROCESS_LA           0x400	/* Able to process link attention */
+
+	ELX_SLI_RING_t ring[ELX_MAX_RING];
+	int fcp_ring;		/* ring used for FCP initiator commands */
+	int next_ring;
+
+	int ip_ring;		/* ring used for IP network drv cmds */
+
+	ELX_SLI_STAT_t slistat;	/* SLI statistical info */
+	ELX_SLINK_t mboxq;	/* mbox command queue */
+	ELX_MBOXQ_t *mbox_active;	/* active mboxq information */
+	struct elxclock *mbox_tmo;	/* Hold clk to timeout active mbox cmd */
+
+	volatile uint32_t *MBhostaddr;	/* virtual address for mbox cmds */
+} ELX_SLI_t;
+
+/* Given a pointer to the start of the ring, and the slot number of
+ * the desired iocb entry, calc a pointer to that entry.
+ * (assume iocb entry size is 32 bytes, or 8 words)
+ */
+#define IOCB_ENTRY(ring,slot) ((uint32_t *)(((char *)(ring)) + \
+                               (((uint32_t)(slot)) << 5)))
+
+#define ELX_SLI_ABORT_WAIT	0	/* Wait for rsp ring completion of IOCBs */
+#define ELX_SLI_ABORT_IMED	0	/* Imediate abort of IOCB, deque and call
+					 * compl routine immediately.
+					 */
+#define ELX_MBOX_TMO           30	/* Sec tmo for outstanding mbox command */
+
+#endif				/* _H_ELX_SLI */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/elx_util.h linux-2.6.3/drivers/scsi/lpfc/elx_util.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/elx_util.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/elx_util.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,124 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_ELX_UTIL
+#define _H_ELX_UTIL
+
+/* Structure to be used for single linked list header */
+typedef struct elx_slink {
+	struct elx_slink *q_first;	/* queue first element */
+	struct elx_slink *q_last;	/* queue last element */
+	uint16_t q_cnt;		/* current length of queue */
+	uint16_t q_max;		/* max length */
+} ELX_SLINK_t;
+
+/* Structure to be used for double linked list header */
+typedef struct elx_dlink {
+	struct elx_dlink *q_f;	/* queue forward element */
+	struct elx_dlink *q_b;	/* queue backward element */
+	uint16_t q_cnt;		/* current length of queue */
+	uint16_t q_max;		/* max length */
+} ELX_DLINK_t;
+
+#define elx_enque(x,p) {(((ELX_DLINK_t *)x)->q_f    = ((ELX_DLINK_t *)p)->q_f, \
+      ((ELX_DLINK_t *)x)->q_b      = ((ELX_DLINK_t *)p),     \
+      ((ELX_DLINK_t *)p)->q_f->q_b = ((ELX_DLINK_t *)x),     \
+      ((ELX_DLINK_t *)p)->q_f      = ((ELX_DLINK_t *)x));}
+
+#define elx_deque(x) {(((ELX_DLINK_t *)x)->q_b->q_f = ((ELX_DLINK_t *)x)->q_f, \
+      ((ELX_DLINK_t *)x)->q_f->q_b = ((ELX_DLINK_t *)x)->q_b, \
+      ((ELX_DLINK_t *)x)->q_b      = 0,                       \
+      ((ELX_DLINK_t *)x)->q_f      = 0);}
+
+/*    Typed Queues (Single or Double.. no casing.. multiple queues in a item */
+
+/* Structure to be used for single linked list header */
+#define ELX_TQS_LINK(structName) struct  {  \
+   struct structName  *q_first;                   \
+   struct structName  *q_last;                    \
+   uint16_t           q_cnt;                      \
+   uint16_t           q_max;                      \
+}                                                 \
+
+#define  elx_tqs_enqueue(queue,item,nextPtr) { \
+   if(((queue)->q_cnt)++)                       \
+      (queue)->q_last->nextPtr=item;            \
+   else (queue)->q_first=item;                  \
+   (queue)->q_last=item;                        \
+   (item)->nextPtr=NULL;                        \
+   if((queue)->q_cnt > (queue)->q_max)          \
+            (queue)->q_max=(queue)->q_cnt;}              \
+
+#define  elx_tqs_getcount(queue) (queue)->q_cnt
+#define  elx_tqs_getfirst(queue) (queue)->q_first
+#define  elx_tqs_getnext(item,nextPtr) (item)->nextPtr
+
+#define  elx_tqs_putfirst(queue,newFirst,link) {      \
+   (newFirst)->link=(queue)->q_first;                 \
+   (queue)->q_first=newFirst;                         \
+   if(!((queue)->q_cnt++)) (queue)->q_last=newFirst;}
+
+#define  elx_tqs_dequeue(queue,item,link,previous) {  \
+   if((queue)->q_cnt) {                               \
+      (queue)->q_cnt--;                               \
+      if(previous) (previous)->link = (item)->link;   \
+      else (queue)->q_first = (item)->link;           \
+      if((queue)->q_last== item)                      \
+            (queue)->q_last=previous;                 \
+      (item)->link=NULL; }                            \
+   }                                                  \
+
+#define  elx_tqs_dequeuefirst(queue,link)              \
+      ((queue)->q_cnt) ? (queue)->q_first : NULL;      \
+   {                                                   \
+   if((queue)->q_cnt) {                                \
+      (queue)->q_cnt--;                                \
+      if((queue)->q_last == (queue)->q_first)          \
+         (queue)->q_last=(queue)->q_first->link;       \
+      (queue)->q_first =(queue)->q_first->link;        \
+      }                                                \
+  }						       \
+
+/* Structure to be used for double linked list header */
+
+#define ELX_TQD_LINK(structName) struct  {  \
+   struct structName  *q_f;                     \
+   struct structName  *q_b;                    \
+}                                                 \
+
+#define elx_tqd_onque(queue) ((queue).q_f ? 1 : 0)
+#define elx_tqd_getnext(queue) ((queue).q_f)
+
+#define elx_tqd_enque(x,p,queue) {        \
+   if(p) {                                \
+      ((x)->queue.q_f = (p)->queue.q_f,   \
+      (x)->queue.q_b  = (p),              \
+      (p)->queue.q_f->queue.q_b = (x),    \
+      (p)->queue.q_f  = (x));}             \
+      else (x)->queue.q_f=(x)->queue.q_b=x;}
+
+#define  elx_tpd_first
+
+#define elx_tqd_deque(x,queue) {((x)->queue.q_b->queue.q_f = (x)->queue.q_f, \
+      (x)->queue.q_f->queue.q_b = (x)->queue.q_b, \
+      (x)->queue.q_b      = 0,                       \
+      (x)->queue.q_f      = 0);}
+
+#endif				/* _H_ELX_UTIL */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/hbaapi.h linux-2.6.3/drivers/scsi/lpfc/hbaapi.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/hbaapi.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/hbaapi.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,468 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#ifndef HBA_API_H
+#define HBA_API_H
+
+/* Library version string */
+#define HBA_LIBVERSION 2
+
+/* DLL imports for WIN32 operation */
+#define HBA_API
+
+	typedef unsigned char HBA_UINT8;	/* Unsigned  8 bits */
+	typedef char HBA_INT8;	/* Signed    8 bits */
+	typedef unsigned short HBA_UINT16;	/* Unsigned 16 bits */
+	typedef short HBA_INT16;	/* Signed   16 bits */
+	typedef unsigned int HBA_UINT32;	/* Unsigned 32 bits */
+	typedef int HBA_INT32;	/* Signed   32 bits */
+	typedef void *HBA_PVOID;	/* Pointer  to void */
+	typedef HBA_UINT32 HBA_VOID32;	/* Opaque   32 bits */
+	typedef long long HBA_INT64;
+	typedef long long HBA_UINT64;
+
+/* 6.1        Handle to Device */
+	typedef HBA_UINT32 HBA_HANDLE;
+
+#define HBA_HANDLE_INVALID                   0
+
+/* 6.1        Status Return Values */
+	typedef HBA_UINT32 HBA_STATUS;
+
+#define HBA_STATUS_OK                        0
+#define HBA_STATUS_ERROR                     1	/* Error */
+#define HBA_STATUS_ERROR_NOT_SUPPORTED       2	/* Function not supported. */
+#define HBA_STATUS_ERROR_INVALID_HANDLE      3	/* invalid handle */
+#define HBA_STATUS_ERROR_ARG                 4	/* Bad argument */
+#define HBA_STATUS_ERROR_ILLEGAL_WWN         5	/* WWN not recognized */
+#define HBA_STATUS_ERROR_ILLEGAL_INDEX       6	/* Index not recognized */
+#define HBA_STATUS_ERROR_MORE_DATA           7	/* Larger buffer required */
+#define HBA_STATUS_ERROR_STALE_DATA          8	/* Information has changed since
+						 * last call to
+						 * HBA_Refreshinformation */
+#define HBA_STATUS_SCSI_CHECK_CONDITION      9	/* Obvious */
+#define HBA_STATUS_ERROR_BUSY                10	/* HBA busy or reserved,
+						 * retry may be effective */
+#define HBA_STATUS_ERROR_TRY_AGAIN           11	/* Request timedout,
+						 * retry may be effective */
+#define HBA_STATUS_ERROR_UNAVAILABLE         12	/* Referenced HBA has been removed
+						 * or deactivated */
+#define HBA_STATUS_ERROR_ELS_REJECT          13	/* The requested ELS was rejected by
+						 * the local HBA */
+#define HBA_STATUS_ERROR_INVALID_LUN         14	/* The specified LUN is not provided 
+						 *  the specified HBA */
+#define HBA_STATUS_ERROR_INCOMPATIBLE        15
+
+#define HBA_STATUS_ERROR_AMBIGUOUS_WWN       16	/* Multiple adapters have a matching
+						 * WWN. This could occur if the
+						 * NodeWWN of multiple adapters is 
+						 * identical */
+#define HBA_STATUS_ERROR_LOCAL_BUS           17	/* A persistent binding request
+						 * included a bad local SCSI bus
+						 * number */
+#define HBA_STATUS_ERROR_LOCAL_TARGET        18	/* A persistent binding request
+						 * included a bad local SCSI target
+						 * number */
+#define HBA_STATUS_ERROR_LOCAL_LUN           19	/* A persistent binding request
+						 * included a bad local SCSI logical
+						 * unit number */
+#define HBA_STATUS_ERROR_LOCAL_SCSIID_BOUND  20	/* A persistent binding set request
+						 * included a local SCSI ID that was
+						 * already bound */
+#define HBA_STATUS_ERROR_TARGET_FCID         21	/* A persistent binding request
+						 * included a bad or unlocatable FCP
+						 * Target FCID */
+#define HBA_STATUS_ERROR_TARGET_NODE_WWN     22	/* A persistent binding request 
+						 * included a bad FCP Target Node
+						 * WWN */
+#define HBA_STATUS_ERROR_TARGET_PORT_WWN     23	/* A persistent binding request
+						 * included a bad FCP Target Port
+						 * WWN */
+#define HBA_STATUS_ERROR_TARGET_LUN          24	/* A persistent binding request
+						 * included an FCP Logical Unit Number
+						 * not defined by the identified 
+						 * Target*/
+#define HBA_STATUS_ERROR_TARGET_LUID         25	/* A persistent binding request
+						 * included an undefined or otherwise
+						 * inaccessible Logical Unit Unique
+						 * Identifier */
+#define HBA_STATUS_ERROR_NO_SUCH_BINDING     26	/* A persistent binding remove request
+						 * included a binding which did not
+						 * match a binding established by the
+						 * specified port */
+#define HBA_STATUS_ERROR_NOT_A_TARGET        27	/* A SCSI command was requested to an
+						 * Nx_Port that was not a SCSI
+						 * Target Port */
+#define HBA_STATUS_ERROR_UNSUPPORTED_FC4     28	/* A request was made concerning an 
+						 * unsupported FC-4 protocol */
+#define HBA_STATUS_ERROR_INCAPABLE           29	/* A request was made to enable 
+						 * unimplemented capabilities for a 
+						 * port */
+#define HBA_STATUS_ERROR_TARGET_BUSY         30	/* A SCSI function was requested
+						 * at a time when issuing the 
+						 * requested command would cause a
+						 * a SCSI overlapped command 
+						 * condition (see SAM-3) */
+
+/* 6.4.1        Port Operational Modes Values */
+	typedef HBA_UINT32 HBA_PORTTYPE;
+
+#define HBA_PORTTYPE_UNKNOWN                1	/* Unknown */
+#define HBA_PORTTYPE_OTHER                  2	/* Other */
+#define HBA_PORTTYPE_NOTPRESENT             3	/* Not present */
+#define HBA_PORTTYPE_NPORT                  5	/* Fabric  */
+#define HBA_PORTTYPE_NLPORT                 6	/* Public Loop */
+#define HBA_PORTTYPE_FLPORT                 7
+#define HBA_PORTTYPE_FPORT                  8	/* Fabric Port */
+#define HBA_PORTTYPE_LPORT                  20	/* Private Loop */
+#define HBA_PORTTYPE_PTP                    21	/* Point to Point */
+
+	typedef HBA_UINT32 HBA_PORTSTATE;
+#define HBA_PORTSTATE_UNKNOWN               1	/* Unknown */
+#define HBA_PORTSTATE_ONLINE                2	/* Operational */
+#define HBA_PORTSTATE_OFFLINE               3	/* User Offline */
+#define HBA_PORTSTATE_BYPASSED              4	/* Bypassed */
+#define HBA_PORTSTATE_DIAGNOSTICS           5	/* In diagnostics mode */
+#define HBA_PORTSTATE_LINKDOWN              6	/* Link Down */
+#define HBA_PORTSTATE_ERROR                 7	/* Port Error */
+#define HBA_PORTSTATE_LOOPBACK              8	/* Loopback */
+
+	typedef HBA_UINT32 HBA_PORTSPEED;
+#define HBA_PORTSPEED_UNKNOWN               0	/* Unknown - transceiver incable
+						 * of reporting */
+#define HBA_PORTSPEED_1GBIT                 1	/* 1 GBit/sec */
+#define HBA_PORTSPEED_2GBIT                 2	/* 2 GBit/sec */
+#define HBA_PORTSPEED_10GBIT                4	/* 10 GBit/sec */
+#define HBA_PORTSPEED_NOT_NEGOTIATED        5	/* Speed not established */
+
+/* 6.4.1.4        See "Class of Service  - Format" in GC-GS-4 */
+
+	typedef HBA_UINT32 HBA_COS;
+
+/* 6.4.1.5        Fc4Types Values */
+
+	typedef struct HBA_fc4types {
+		HBA_UINT8 bits[32];	/* 32 bytes of FC-4 per GS-2 */
+	} HBA_FC4TYPES, *PHBA_FC4TYPES;
+
+/* 6.1        Basic Types */
+
+	typedef struct HBA_wwn {
+		HBA_UINT8 wwn[8];
+	} HBA_WWN, *PHBA_WWN;
+
+	typedef struct HBA_ipaddress {
+		int ipversion;	/* see enumerations in RNID */
+		union {
+			unsigned char ipv4address[4];
+			unsigned char ipv6address[16];
+		} ipaddress;
+	} HBA_IPADDRESS, *PHBA_IPADDRESS;
+
+	typedef HBA_INT8 HBA_BOOLEAN;
+
+/* 6.3.1        Adapter Attributes */
+	typedef struct hba_AdapterAttributes {
+		char Manufacturer[64];
+		char SerialNumber[64];
+		char Model[256];
+		char ModelDescription[256];
+		HBA_WWN NodeWWN;
+		char NodeSymbolicName[256];
+		char HardwareVersion[256];
+		char DriverVersion[256];
+		char OptionROMVersion[256];
+		char FirmwareVersion[256];
+		HBA_UINT32 VendorSpecificID;
+		HBA_UINT32 NumberOfPorts;
+		char DriverName[256];
+	} HBA_ADAPTERATTRIBUTES, *PHBA_ADAPTERATTRIBUTES;
+
+/* 6.4.1.6        Port Attributes */
+	typedef struct HBA_PortAttributes {
+		HBA_WWN NodeWWN;
+		HBA_WWN PortWWN;
+		HBA_UINT32 PortFcId;
+		HBA_PORTTYPE PortType;
+		HBA_PORTSTATE PortState;
+		HBA_COS PortSupportedClassofService;
+		HBA_FC4TYPES PortSupportedFc4Types;
+		HBA_FC4TYPES PortActiveFc4Types;
+		char PortSymbolicName[256];
+		char OSDeviceName[256];
+		HBA_PORTSPEED PortSupportedSpeed;
+		HBA_PORTSPEED PortSpeed;
+		HBA_UINT32 PortMaxFrameSize;
+		HBA_WWN FabricName;
+		HBA_UINT32 NumberofDiscoveredPorts;
+	} HBA_PORTATTRIBUTES, *PHBA_PORTATTRIBUTES;
+
+	typedef struct HBA_PortStatistics {
+		HBA_INT64 SecondsSinceLastReset;
+		HBA_INT64 TxFrames;
+		HBA_INT64 TxWords;
+		HBA_INT64 RxFrames;
+		HBA_INT64 RxWords;
+		HBA_INT64 LIPCount;
+		HBA_INT64 NOSCount;
+		HBA_INT64 ErrorFrames;
+		HBA_INT64 DumpedFrames;
+		HBA_INT64 LinkFailureCount;
+		HBA_INT64 LossOfSyncCount;
+		HBA_INT64 LossOfSignalCount;
+		HBA_INT64 PrimitiveSeqProtocolErrCount;
+		HBA_INT64 InvalidTxWordCount;
+		HBA_INT64 InvalidCRCCount;
+	} HBA_PORTSTATISTICS, *PHBA_PORTSTATISTICS;
+
+/* 6.6.1                FCP Attributes */
+
+	typedef enum HBA_fcpbindingtype { TO_D_ID, TO_WWN,
+		    TO_OTHER } HBA_FCPBINDINGTYPE;
+
+	typedef struct HBA_ScsiId {
+		char OSDeviceName[256];
+		HBA_UINT32 ScsiBusNumber;
+		HBA_UINT32 ScsiTargetNumber;
+		HBA_UINT32 ScsiOSLun;
+	} HBA_SCSIID, *PHBA_SCSIID;
+
+	typedef struct HBA_FcpId {
+		HBA_UINT32 FcId;
+		HBA_WWN NodeWWN;
+		HBA_WWN PortWWN;
+		HBA_UINT64 FcpLun;
+	} HBA_FCPID, *PHBA_FCPID;
+
+	typedef struct HBA_LUID {
+		char buffer[256];
+	} HBA_LUID, *PHBA_LUID;
+
+	typedef struct HBA_FcpScsiEntry {
+		HBA_SCSIID ScsiId;
+		HBA_FCPID FcpId;
+	} HBA_FCPSCSIENTRY, *PHBA_FCPSCSIENTRY;
+
+	typedef struct HBA_FcpScsiEntryV2 {
+		HBA_SCSIID ScsiId;
+		HBA_FCPID FcpId;
+		HBA_LUID LUID;
+	} HBA_FCPSCSIENTRYV2, *PHBA_FCPSCSIENTRYV2;
+
+	typedef struct HBA_FCPTargetMapping {
+		HBA_UINT32 NumberOfEntries;
+		HBA_FCPSCSIENTRY entry[1];	/* Variable length array
+						 * containing mappings */
+	} HBA_FCPTARGETMAPPING, *PHBA_FCPTARGETMAPPING;
+
+	typedef struct HBA_FCPTargetMappingV2 {
+		HBA_UINT32 NumberOfEntries;
+		HBA_FCPSCSIENTRYV2 entry[1];	/* Variable length array
+						 * containing mappings */
+	} HBA_FCPTARGETMAPPINGV2, *PHBA_FCPTARGETMAPPINGV2;
+
+	typedef struct HBA_FCPBindingEntry {
+		HBA_FCPBINDINGTYPE type;
+		HBA_SCSIID ScsiId;
+		HBA_FCPID FcpId;	/* WWN valid only if type is
+					 * to WWN, FcpLun always valid */
+		HBA_UINT32 FcId;
+	} HBA_FCPBINDINGENTRY, *PHBA_FCPBINDINGENTRY;
+
+	typedef struct HBA_FCPBinding {
+		HBA_UINT32 NumberOfEntries;
+		HBA_FCPBINDINGENTRY entry[1];	/* Variable length array */
+	} HBA_FCPBINDING, *PHBA_FCPBINDING;
+
+/* 6.7.1        FC-3 Management Atrributes */
+
+	typedef enum HBA_wwntype { NODE_WWN, PORT_WWN } HBA_WWNTYPE;
+
+	typedef struct HBA_MgmtInfo {
+		HBA_WWN wwn;
+		HBA_UINT32 unittype;
+		HBA_UINT32 PortId;
+		HBA_UINT32 NumberOfAttachedNodes;
+		HBA_UINT16 IPVersion;
+		HBA_UINT16 UDPPort;
+		HBA_UINT8 IPAddress[16];
+		HBA_UINT16 reserved;
+		HBA_UINT16 TopologyDiscoveryFlags;
+	} HBA_MGMTINFO, *PHBA_MGMTINFO;
+
+/* Event Codes */
+#define HBA_EVENT_LIP_OCCURRED           1
+#define HBA_EVENT_LINK_UP                2
+#define HBA_EVENT_LINK_DOWN              3
+#define HBA_EVENT_LIP_RESET_OCCURRED     4
+#define HBA_EVENT_RSCN                   5
+#define HBA_EVENT_PROPRIETARY            0xFFFF
+
+	typedef struct HBA_Link_EventInfo {
+		HBA_UINT32 PortFcId;	/* Port where event occurred */
+		HBA_UINT32 Reserved[3];
+	} HBA_LINK_EVENTINFO, *PHBA_LINK_EVENTINFO;
+
+	typedef struct HBA_RSCN_EventInfo {
+		HBA_UINT32 PortFcId;	/* Port where event occurred */
+		HBA_UINT32 NPortPage;	/* Reference FC-FS for RSCN ELS
+					 * "Affected N-Port Pages"*/
+		HBA_UINT32 Reserved[2];
+	} HBA_RSCN_EVENTINFO, *PHBA_RSCN_EVENTINFO;
+
+	typedef struct HBA_Pty_EventInfo {
+		HBA_UINT32 PtyData[4];	/* Proprietary data */
+	} HBA_PTY_EVENTINFO, *PHBA_PTY_EVENTINFO;
+
+	typedef struct HBA_EventInfo {
+		HBA_UINT32 EventCode;
+		union {
+			HBA_LINK_EVENTINFO Link_EventInfo;
+			HBA_RSCN_EVENTINFO RSCN_EventInfo;
+			HBA_PTY_EVENTINFO Pty_EventInfo;
+		} Event;
+	} HBA_EVENTINFO, *PHBA_EVENTINFO;
+
+/* Persistant Binding... */
+	typedef HBA_UINT32 HBA_BIND_TYPE;
+#define HBA_BIND_TO_D_ID                0x0001
+#define HBA_BIND_TO_WWPN                0x0002
+#define HBA_BIND_TO_WWNN                0x0004
+#define HBA_BIND_TO_LUID                0x0008
+#define HBA_BIND_TARGETS                0x0800
+
+/* A bit mask of Rev 2.0 persistent binding capabilities */
+	typedef HBA_UINT32 HBA_BIND_CAPABILITY;
+/* The following are bit flags indicating persistent binding capabilities */
+#define HBA_CAN_BIND_TO_D_ID                0x0001
+#define HBA_CAN_BIND_TO_WWPN                0x0002
+#define HBA_CAN_BIND_TO_WWNN                0x0004
+#define HBA_CAN_BIND_TO_LUID                0x0008
+#define HBA_CAN_BIND_ANY_LUNS               0x0400
+#define HBA_CAN_BIND_TARGETS                0x0800
+#define HBA_CAN_BIND_AUTOMAP                0x1000
+#define HBA_CAN_BIND_CONFIGURED             0x2000
+
+#define HBA_BIND_STATUS_DISABLED            0x00
+#define HBA_BIND_STATUS_ENABLED             0x01
+
+	typedef HBA_UINT32 HBA_BIND_STATUS;
+
+#define HBA_BIND_EFFECTIVE_AT_REBOOT        0x00
+#define HBA_BIND_EFFECTIVE_IMMEDIATE        0x01
+
+	typedef HBA_UINT32 HBA_BIND_EFFECTIVE;
+
+	typedef struct HBA_FCPBindingEntry2 {
+		HBA_BIND_TYPE type;
+		HBA_SCSIID ScsiId;
+		HBA_FCPID FcpId;
+		HBA_LUID LUID;
+		HBA_STATUS status;
+	} HBA_FCPBINDINGENTRY2, *PHBA_FCPBINDINGENTRY2;
+
+	typedef struct HBA_FcpBinding2 {
+		HBA_UINT32 NumberOfEntries;
+		HBA_FCPBINDINGENTRY2 entry[1];	/* Variable length array */
+	} HBA_FCPBINDING2, *PHBA_FCPBINDING2;
+
+/* FC-4 Instrumentation */
+	typedef struct HBA_FC4Statistics {
+		HBA_INT64 InputRequests;
+		HBA_INT64 OutputRequests;
+		HBA_INT64 ControlRequests;
+		HBA_INT64 InputMegabytes;
+		HBA_INT64 OutputMegabytes;
+	} HBA_FC4STATISTICS, *PHBA_FC4STATISTICS;
+
+	typedef void *HBA_CALLBACKHANDLE;
+/* Adapter Level Events */
+#define HBA_EVENT_ADAPTER_UNKNOWN       0x100
+#define HBA_EVENT_ADAPTER_ADD           0x101
+#define HBA_EVENT_ADAPTER_REMOVE        0x102
+#define HBA_EVENT_ADAPTER_CHANGE        0x103
+
+/* Port Level Events */
+#define HBA_EVENT_PORT_UNKNOWN          0x200
+#define HBA_EVENT_PORT_OFFLINE          0x201
+#define HBA_EVENT_PORT_ONLINE           0x202
+#define HBA_EVENT_PORT_NEW_TARGETS      0x203
+#define HBA_EVENT_PORT_FABRIC           0x204
+
+/* Port Statistics Events */
+#define HBA_EVENT_PORT_STAT_THRESHOLD   0x301
+#define HBA_EVENT_PORT_STAT_GROWTH      0x302
+
+/* Target Level Events */
+#define HBA_EVENT_TARGET_UNKNOWN        0x400
+#define HBA_EVENT_TARGET_OFFLINE        0x401
+#define HBA_EVENT_TARGET_ONLINE         0x402
+#define HBA_EVENT_TARGET_REMOVED        0x403
+
+/* Fabric Link  Events */
+#define HBA_EVENT_LINK_UNKNOWN          0x500
+#define HBA_EVENT_LINK_INCIDENT         0x501
+
+/* Used for OSDeviceName */
+	typedef struct HBA_osdn {
+		char drvname[32];
+		uint32_t instance;
+		uint32_t target;
+		uint32_t lun;
+		uint32_t bus;
+		char flags;
+		char sizeSN;
+		char InquirySN[64];
+	} HBA_OSDN;
+
+/* type definitions for GetBindList function */
+	typedef enum HBA_bindtype { BIND_NONE, BIND_WWNN, BIND_WWPN, BIND_DID,
+		    BIND_ALPA } HBA_BINDTYPE;
+/* Bind Entry flags */
+#define         HBA_BIND_AUTOMAP  0x1	/* Node is automapped            */
+#define         HBA_BIND_BINDLIST 0x2	/* entry in bind list not mapped */
+#define         HBA_BIND_MAPPED   0x4	/* Node is mapped to  a scsiid   */
+#define         HBA_BIND_UNMAPPED 0x8	/* Node is unmapped              */
+#define         HBA_BIND_NODEVTMO 0x10	/* NODEVTMO flag of the node     */
+#define         HBA_BIND_NOSCSIID 0x20	/* No scsi id is assigned yet    */
+#define         HBA_BIND_RPTLUNST 0x40	/* Node is in report lun cmpl st */
+	typedef struct {
+		HBA_BINDTYPE bind_type;
+		HBA_UINT32 scsi_id;
+		HBA_UINT32 did;
+		HBA_WWN wwnn;
+		HBA_WWN wwpn;
+		HBA_UINT32 flags;
+	} HBA_BIND_ENTRY;
+
+	typedef struct {
+		HBA_UINT32 NumberOfEntries;
+		HBA_BIND_ENTRY entry[1];	/* Variable length array */
+	} HBA_BIND_LIST, *HBA_BIND_LIST_PTR;
+
+#endif				/* HBA_API_H */
+
+#ifdef __cplusplus
+}
+#endif
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc.conf linux-2.6.3/drivers/scsi/lpfc/lpfc.conf
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc.conf	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc.conf	2004-02-27 19:18:50.000000000 +0100
@@ -0,0 +1,1460 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#include <linux/init.h>
+#include "lpfc_cfgparm.h"
+
+#ifndef _ETC_LPFC_CONF_
+#define _ETC_LPFC_CONF_
+#endif
+
+/**************************  GLOBAL PARMS **********************/
+
+/* 
+# Setup FCP persistent bindings,
+# fcp-bind-WWPN binds a specific WorldWide PortName to a target id,
+# fcp-bind-WWNN binds a specific WorldWide NodeName to a target id,
+# fcp-bind-DID binds a specific DID to a target id.
+# Each array must end with a NULL pointer.
+# Binding method must match with the bind method of that HBA, else the
+# binding will be ignored.
+# scan-down should NOT be set to 2 when one of these binding methods 
+# is used. 
+# WWNN, WWPN and DID are hexadecimal values.
+# WWNN must be 16 digit BCD with leading 0s.
+# WWPN must be 16 digit BCD with leading 0s.
+# DID must be 6 digit BCD with leading 0s.
+# The SCSI ID to bind to consists of two parts, the lpfc interface
+# to bind to, and the target number for that interface.
+# Thus lpfc0t2 specifies target 2 on interface lpfc0.
+#
+# Here are some examples:
+#                                   WWNN             SCSI ID
+# char *lpfc_fcp_bind_WWNN[MAX_FC_BINDINGS]={"22000020370b8275:lpfc0t1",
+#                                            "22000020370b8998:lpfc0t2",
+#                                            0};
+# 
+#                                   WWPN             SCSI ID
+# char *lpfc_fcp_bind_WWPN[MAX_FC_BINDINGS]={"22000020370b8275:lpfc0t1",
+#                                            "22000020370b8998:lpfc0t2",
+#                                            0};
+# 
+#                                   DID   SCSI ID
+# char *lpfc_fcp_bind_DID[MAX_FC_BINDINGS]={"0000dc:lpfc0t1",
+#                                           "0000e0:lpfc0t2",
+#                                           0};
+# 
+*/
+      
+char *lpfc_fcp_bind_WWNN[MAX_FC_BINDINGS]   =  {0};
+
+char *lpfc_fcp_bind_WWPN[MAX_FC_BINDINGS]   =  {0};
+
+char *lpfc_fcp_bind_DID[MAX_FC_BINDINGS]    =  {0};
+
+/************************  PER ADAPTER PARMS ********************/
+
+/*
+ * The per adapter parmaters are in the form of lpfcX_param where
+ * X is the adapter number. If lpfcX_param = -1 then it will assume
+ * the default value which is indicated by lpfc_param that precedes
+ * that particular set of lpfcX_param's.
+ */
+
+/*
+# lpfc_max_lun: Specifies the maximum number of luns per target. A value of
+# 20 means luns from 0 to 19 are valid. Value range is [0,256]. Default
+# value = 256.
+*/
+int lpfc_max_lun   =  256;
+int lpfc0_max_lun  = -1;
+int lpfc1_max_lun  = -1;
+int lpfc2_max_lun  = -1;
+int lpfc3_max_lun  = -1;
+int lpfc4_max_lun  = -1;
+int lpfc5_max_lun  = -1;
+int lpfc6_max_lun  = -1;
+int lpfc7_max_lun  = -1;
+int lpfc8_max_lun  = -1;
+int lpfc9_max_lun  = -1;
+int lpfc10_max_lun = -1;
+int lpfc11_max_lun = -1;
+int lpfc12_max_lun = -1;
+int lpfc13_max_lun = -1;
+int lpfc14_max_lun = -1;
+int lpfc15_max_lun = -1;
+int lpfc16_max_lun = -1;
+int lpfc17_max_lun = -1;
+int lpfc18_max_lun = -1;
+int lpfc19_max_lun = -1;
+int lpfc20_max_lun = -1;
+int lpfc21_max_lun = -1;
+int lpfc22_max_lun = -1;
+int lpfc23_max_lun = -1;
+int lpfc24_max_lun = -1;
+int lpfc25_max_lun = -1;
+int lpfc26_max_lun = -1;
+int lpfc27_max_lun = -1;
+int lpfc28_max_lun = -1;
+int lpfc29_max_lun = -1;
+int lpfc30_max_lun = -1;
+int lpfc31_max_lun = -1;
+
+/*
+# Specifies the maximum number of ELS cmds we can have outstanding (for 
+# discovery). Value range is [1,64]. Default value = 1.
+*/
+int lpfc_discovery_threads   =  1;
+int lpfc0_discovery_threads  = -1;
+int lpfc1_discovery_threads  = -1;
+int lpfc2_discovery_threads  = -1;
+int lpfc3_discovery_threads  = -1;
+int lpfc4_discovery_threads  = -1;
+int lpfc5_discovery_threads  = -1;
+int lpfc6_discovery_threads  = -1;
+int lpfc7_discovery_threads  = -1;
+int lpfc8_discovery_threads  = -1;
+int lpfc9_discovery_threads  = -1;
+int lpfc10_discovery_threads = -1;
+int lpfc11_discovery_threads = -1;
+int lpfc12_discovery_threads = -1;
+int lpfc13_discovery_threads = -1;
+int lpfc14_discovery_threads = -1;
+int lpfc15_discovery_threads = -1;
+int lpfc16_discovery_threads = -1;
+int lpfc17_discovery_threads = -1;
+int lpfc18_discovery_threads = -1;
+int lpfc19_discovery_threads = -1;
+int lpfc20_discovery_threads = -1;
+int lpfc21_discovery_threads = -1;
+int lpfc22_discovery_threads = -1;
+int lpfc23_discovery_threads = -1;
+int lpfc24_discovery_threads = -1;
+int lpfc25_discovery_threads = -1;
+int lpfc26_discovery_threads = -1;
+int lpfc27_discovery_threads = -1;
+int lpfc28_discovery_threads = -1;
+int lpfc29_discovery_threads = -1;
+int lpfc30_discovery_threads = -1;
+int lpfc31_discovery_threads = -1;
+
+/*
+# lpfc_max_target: This configuration parameter limits how many targets/luns
+# the driver will support. Don't exceed 255 for lpfc_max_target, otherwise
+# device scan will wrap around. Value range is [0,255]. Default value = 255.
+*/
+int  lpfc_max_target  = 255;
+int  lpfc0_max_target  = -1;
+int  lpfc1_max_target  = -1;
+int  lpfc2_max_target  = -1;
+int  lpfc3_max_target  = -1;
+int  lpfc4_max_target  = -1;
+int  lpfc5_max_target  = -1;
+int  lpfc6_max_target  = -1;
+int  lpfc7_max_target  = -1;
+int  lpfc8_max_target  = -1;
+int  lpfc9_max_target  = -1;
+int  lpfc10_max_target = -1;
+int  lpfc11_max_target = -1;
+int  lpfc12_max_target = -1;
+int  lpfc13_max_target = -1;
+int  lpfc14_max_target = -1;
+int  lpfc15_max_target = -1;
+int  lpfc16_max_target = -1;
+int  lpfc17_max_target = -1;
+int  lpfc18_max_target = -1;
+int  lpfc19_max_target = -1;
+int  lpfc20_max_target = -1;
+int  lpfc21_max_target = -1;
+int  lpfc22_max_target = -1;
+int  lpfc23_max_target = -1;
+int  lpfc24_max_target = -1;
+int  lpfc25_max_target = -1;
+int  lpfc26_max_target = -1;
+int  lpfc27_max_target = -1;
+int  lpfc28_max_target = -1;
+int  lpfc29_max_target = -1;
+int  lpfc30_max_target = -1;
+int  lpfc31_max_target = -1;
+
+/*
+# lpfc_fcp_bind_method: It specifies the method of binding to be used for each
+# port. This  binding method is used for persistent binding and automaped 
+# binding. A value of 1 will force WWNN binding, value of 2 will force WWPN
+# binding, value of 3 will force DID binding and value of 4 will force the
+# driver to derive binding from ALPA. Any persistent binding whose type does
+# not match with the bind method of the port will be ignored. Value range 
+# is [1,4]. Default value is 2.
+*/
+int  lpfc_fcp_bind_method   =  2;
+int  lpfc0_fcp_bind_method  = -1;
+int  lpfc1_fcp_bind_method  = -1;
+int  lpfc2_fcp_bind_method  = -1;
+int  lpfc3_fcp_bind_method  = -1;
+int  lpfc4_fcp_bind_method  = -1;
+int  lpfc5_fcp_bind_method  = -1;
+int  lpfc6_fcp_bind_method  = -1;
+int  lpfc7_fcp_bind_method  = -1;
+int  lpfc8_fcp_bind_method  = -1;
+int  lpfc9_fcp_bind_method  = -1;
+int  lpfc10_fcp_bind_method = -1;
+int  lpfc11_fcp_bind_method = -1;
+int  lpfc12_fcp_bind_method = -1;
+int  lpfc13_fcp_bind_method = -1;
+int  lpfc14_fcp_bind_method = -1;
+int  lpfc15_fcp_bind_method = -1;
+int  lpfc16_fcp_bind_method = -1;
+int  lpfc17_fcp_bind_method = -1;
+int  lpfc18_fcp_bind_method = -1;
+int  lpfc19_fcp_bind_method = -1;
+int  lpfc20_fcp_bind_method = -1;
+int  lpfc21_fcp_bind_method = -1;
+int  lpfc22_fcp_bind_method = -1;
+int  lpfc23_fcp_bind_method = -1;
+int  lpfc24_fcp_bind_method = -1;
+int  lpfc25_fcp_bind_method = -1;
+int  lpfc26_fcp_bind_method = -1;
+int  lpfc27_fcp_bind_method = -1;
+int  lpfc28_fcp_bind_method = -1;
+int  lpfc29_fcp_bind_method = -1;
+int  lpfc30_fcp_bind_method = -1;
+int  lpfc31_fcp_bind_method = -1;
+
+/*
+# If automap is set, SCSI IDs for all FCP nodes without
+# persistent bindings will be automatically generated.
+# If new FCP devices are added to the network when the system is down,
+# there is no guarantee that these SCSI IDs will remain the same
+# when the system is booted again. 
+# The bind method of the port is used as the binding method of
+# automap devices to preserve SCSI IDs between link down and link up.
+# If automap is 0, only devices with persistent bindings will be
+# recognized by the system. User can change the automap property
+# of port instance X by changing the value of lpfcX_automap parameter.
+# Value range is [0,1]. Default value is 1.
+*/
+int  lpfc_automap   =  1;
+int  lpfc0_automap  = -1;
+int  lpfc1_automap  = -1;
+int  lpfc2_automap  = -1;
+int  lpfc3_automap  = -1;
+int  lpfc4_automap  = -1;
+int  lpfc5_automap  = -1;
+int  lpfc6_automap  = -1;
+int  lpfc7_automap  = -1;
+int  lpfc8_automap  = -1;
+int  lpfc9_automap  = -1;
+int  lpfc10_automap = -1;
+int  lpfc11_automap = -1;
+int  lpfc12_automap = -1;
+int  lpfc13_automap = -1;
+int  lpfc14_automap = -1;
+int  lpfc15_automap = -1;
+int  lpfc16_automap = -1;
+int  lpfc17_automap = -1;
+int  lpfc18_automap = -1;
+int  lpfc19_automap = -1;
+int  lpfc20_automap = -1;
+int  lpfc21_automap = -1;
+int  lpfc22_automap = -1;
+int  lpfc23_automap = -1;
+int  lpfc24_automap = -1;
+int  lpfc25_automap = -1;
+int  lpfc26_automap = -1;
+int  lpfc27_automap = -1;
+int  lpfc28_automap = -1;
+int  lpfc29_automap = -1;
+int  lpfc30_automap = -1;
+int  lpfc31_automap = -1;
+
+/*
+# Some disk devices have a "select ID" or "select Target" capability.
+# From a protocol standpoint "select ID" usually means select the
+# Fibre channel "ALPA".  In the FC-AL Profile there is an "informative
+# annex" which contains a table that maps a "select ID" (a number
+# between 0 and 7F) to an ALPA.  By default, for compatibility with
+# older drivers, the lpfc driver scans this table from low ALPA to high
+# ALPA.
+#
+# Turning on the scan-down variable (on  = 1, off = 0) will
+# cause the lpfc driver to use an inverted table, effectively
+# scanning ALPAs from high to low. Value range is [0,1]. Default value is 1.
+#
+# (Note: This "select ID" functionality is a LOOP ONLY characteristic
+# and will not work across a fabric. Also this parameter will take
+# effect only in the case when ALPA map is not available.)
+*/
+int  lpfc_scan_down    =  1;
+int  lpfc0_scan_down   = -1;
+int  lpfc1_scan_down   = -1;
+int  lpfc2_scan_down   = -1;
+int  lpfc3_scan_down   = -1;
+int  lpfc4_scan_down   = -1;
+int  lpfc5_scan_down   = -1;
+int  lpfc6_scan_down   = -1;
+int  lpfc7_scan_down   = -1;
+int  lpfc8_scan_down   = -1;
+int  lpfc9_scan_down   = -1;
+int  lpfc10_scan_down  = -1;
+int  lpfc11_scan_down  = -1;
+int  lpfc12_scan_down  = -1;
+int  lpfc13_scan_down  = -1;
+int  lpfc14_scan_down  = -1;
+int  lpfc15_scan_down  = -1;
+int  lpfc16_scan_down  = -1;
+int  lpfc17_scan_down  = -1;
+int  lpfc18_scan_down  = -1;
+int  lpfc19_scan_down  = -1;
+int  lpfc20_scan_down  = -1;
+int  lpfc21_scan_down  = -1;
+int  lpfc22_scan_down  = -1;
+int  lpfc23_scan_down  = -1;
+int  lpfc24_scan_down  = -1;
+int  lpfc25_scan_down  = -1;
+int  lpfc26_scan_down  = -1;
+int  lpfc27_scan_down  = -1;
+int  lpfc28_scan_down  = -1;
+int  lpfc29_scan_down  = -1;
+int  lpfc30_scan_down  = -1;
+int  lpfc31_scan_down  = -1;
+
+/*
+# lpfc_log_verbose: Only turn this flag on if you are willing to risk being
+# deluged with LOTS of information.
+# You can set a bit mask to record specific types of verbose messages:
+#
+# LOG_ELS                       0x1        ELS events
+# LOG_DISCOVERY                 0x2        Link discovery events
+# LOG_MBOX                      0x4        Mailbox events
+# LOG_INIT                      0x8        Initialization events
+# LOG_LINK_EVENT                0x10       Link events
+# LOG_IP                        0x20       IP traffic history
+# LOG_FCP                       0x40       FCP traffic history
+# LOG_NODE                      0x80       Node table events
+# LOG_MISC                      0x400      Miscellaneous events
+# LOG_SLI                       0x800      SLI events
+# LOG_CHK_COND                  0x1000     FCP Check condition flag
+# LOG_IOC                       0x2000     IOCtl events
+# LOG_ALL_MSG                   0xffff     LOG all messages
+*/
+int  lpfc_log_verbose   =  0x0;
+int  lpfc0_log_verbose  = -1;
+int  lpfc1_log_verbose  = -1;
+int  lpfc2_log_verbose  = -1;
+int  lpfc3_log_verbose  = -1;
+int  lpfc4_log_verbose  = -1;
+int  lpfc5_log_verbose  = -1;
+int  lpfc6_log_verbose  = -1;
+int  lpfc7_log_verbose  = -1;
+int  lpfc8_log_verbose  = -1;
+int  lpfc9_log_verbose  = -1;
+int  lpfc10_log_verbose = -1;
+int  lpfc11_log_verbose = -1;
+int  lpfc12_log_verbose = -1;
+int  lpfc13_log_verbose = -1;
+int  lpfc14_log_verbose = -1;
+int  lpfc15_log_verbose = -1;
+int  lpfc16_log_verbose = -1;
+int  lpfc17_log_verbose = -1;
+int  lpfc18_log_verbose = -1;
+int  lpfc19_log_verbose = -1;
+int  lpfc20_log_verbose = -1;
+int  lpfc21_log_verbose = -1;
+int  lpfc22_log_verbose = -1;
+int  lpfc23_log_verbose = -1;
+int  lpfc24_log_verbose = -1;
+int  lpfc25_log_verbose = -1;
+int  lpfc26_log_verbose = -1;
+int  lpfc27_log_verbose = -1;
+int  lpfc28_log_verbose = -1;
+int  lpfc29_log_verbose = -1;
+int  lpfc30_log_verbose = -1;
+int  lpfc31_log_verbose = -1;
+
+/*
+# lun_queue_depth:  This parameter is used to limit the number of outstanding
+# commands per FCP LUN. Value range is [1,128]. Default value is 30.
+*/
+int lpfc_lun_queue_depth   = 30;
+int lpfc0_lun_queue_depth  = -1;
+int lpfc1_lun_queue_depth  = -1;
+int lpfc2_lun_queue_depth  = -1;
+int lpfc3_lun_queue_depth  = -1;
+int lpfc4_lun_queue_depth  = -1;
+int lpfc5_lun_queue_depth  = -1;
+int lpfc6_lun_queue_depth  = -1;
+int lpfc7_lun_queue_depth  = -1;
+int lpfc8_lun_queue_depth  = -1;
+int lpfc9_lun_queue_depth  = -1;
+int lpfc10_lun_queue_depth = -1;
+int lpfc11_lun_queue_depth = -1;
+int lpfc12_lun_queue_depth = -1;
+int lpfc13_lun_queue_depth = -1;
+int lpfc14_lun_queue_depth = -1;
+int lpfc15_lun_queue_depth = -1;
+int lpfc16_lun_queue_depth = -1;
+int lpfc17_lun_queue_depth = -1;
+int lpfc18_lun_queue_depth = -1;
+int lpfc19_lun_queue_depth = -1;
+int lpfc20_lun_queue_depth = -1;
+int lpfc21_lun_queue_depth = -1;
+int lpfc22_lun_queue_depth = -1;
+int lpfc23_lun_queue_depth = -1;
+int lpfc24_lun_queue_depth = -1;
+int lpfc25_lun_queue_depth = -1;
+int lpfc26_lun_queue_depth = -1;
+int lpfc27_lun_queue_depth = -1;
+int lpfc28_lun_queue_depth = -1;
+int lpfc29_lun_queue_depth = -1;
+int lpfc30_lun_queue_depth = -1;
+int lpfc31_lun_queue_depth = -1;
+
+/*
+# tgt_queue_depth: It is used to limit the number of outstanding commands
+# per FCP target. If tgt_queue_depth = 0, the driver will internally use a
+# value appropriate to the FC hardware adapter. Value range is [0,10240]. 
+# Default value is 0.
+*/
+int lpfc_tgt_queue_depth    = 0 ;
+int lpfc0_tgt_queue_depth   = -1;
+int lpfc1_tgt_queue_depth   = -1;
+int lpfc2_tgt_queue_depth   = -1;
+int lpfc3_tgt_queue_depth   = -1;
+int lpfc4_tgt_queue_depth   = -1;
+int lpfc5_tgt_queue_depth   = -1;
+int lpfc6_tgt_queue_depth   = -1;
+int lpfc7_tgt_queue_depth   = -1;
+int lpfc8_tgt_queue_depth   = -1;
+int lpfc9_tgt_queue_depth   = -1;
+int lpfc10_tgt_queue_depth  = -1;
+int lpfc11_tgt_queue_depth  = -1;
+int lpfc12_tgt_queue_depth  = -1;
+int lpfc13_tgt_queue_depth  = -1;
+int lpfc14_tgt_queue_depth  = -1;
+int lpfc15_tgt_queue_depth  = -1;
+int lpfc16_tgt_queue_depth  = -1;
+int lpfc17_tgt_queue_depth  = -1;
+int lpfc18_tgt_queue_depth  = -1;
+int lpfc19_tgt_queue_depth  = -1;
+int lpfc20_tgt_queue_depth  = -1;
+int lpfc21_tgt_queue_depth  = -1;
+int lpfc22_tgt_queue_depth  = -1;
+int lpfc23_tgt_queue_depth  = -1;
+int lpfc24_tgt_queue_depth  = -1;
+int lpfc25_tgt_queue_depth  = -1;
+int lpfc26_tgt_queue_depth  = -1;
+int lpfc27_tgt_queue_depth  = -1;
+int lpfc28_tgt_queue_depth  = -1;
+int lpfc29_tgt_queue_depth  = -1;
+int lpfc30_tgt_queue_depth  = -1;
+int lpfc31_tgt_queue_depth  = -1;
+
+/*
+# no_device_delay: determines the length of the interval between deciding to
+# fail back an I/O because there is no way to communicate with its particular
+# device (e.g., due to device failure) and the actual fail back.  A value of
+# zero implies no delay whatsoever.
+# Cautions:  
+# (1)  This value is in seconds.  
+# (2)  Setting a long delay value may permit I/O to build up, each with a
+# pending timeout, which could result in the exhaustion of critical kernel
+# resources. 
+# Value range is [0,30]. Default value is 1.
+#
+# Note that this value can have an impact on the speed with which a
+# system can shut down with I/Os pending and with the HBA not able to
+# communicate with the loop or fabric, e.g., with a cable pulled.
+*/
+int  lpfc_no_device_delay    =  1;
+int  lpfc0_no_device_delay   = -1;
+int  lpfc1_no_device_delay   = -1;
+int  lpfc2_no_device_delay   = -1;
+int  lpfc3_no_device_delay   = -1;
+int  lpfc4_no_device_delay   = -1;
+int  lpfc5_no_device_delay   = -1;
+int  lpfc6_no_device_delay   = -1;
+int  lpfc7_no_device_delay   = -1;
+int  lpfc8_no_device_delay   = -1;
+int  lpfc9_no_device_delay   = -1;
+int  lpfc10_no_device_delay  = -1;
+int  lpfc11_no_device_delay  = -1;
+int  lpfc12_no_device_delay  = -1;
+int  lpfc13_no_device_delay  = -1;
+int  lpfc14_no_device_delay  = -1;
+int  lpfc15_no_device_delay  = -1;
+int  lpfc16_no_device_delay  = -1;
+int  lpfc17_no_device_delay  = -1;
+int  lpfc18_no_device_delay  = -1;
+int  lpfc19_no_device_delay  = -1;
+int  lpfc20_no_device_delay  = -1;
+int  lpfc21_no_device_delay  = -1;
+int  lpfc22_no_device_delay  = -1;
+int  lpfc23_no_device_delay  = -1;
+int  lpfc24_no_device_delay  = -1;
+int  lpfc25_no_device_delay  = -1;
+int  lpfc26_no_device_delay  = -1;
+int  lpfc27_no_device_delay  = -1;
+int  lpfc28_no_device_delay  = -1;
+int  lpfc29_no_device_delay  = -1;
+int  lpfc30_no_device_delay  = -1;
+int  lpfc31_no_device_delay  = -1;
+
+/*
+# +++ Variables relating to IP networking support. +++
+*/
+
+/*
+# network_on:  True (1) if networking is enabled, False (0) if not. Value range
+# is [0,1]. Default value is 0.
+*/
+int lpfc_network_on    =  0;
+int lpfc0_network_on   = -1;
+int lpfc1_network_on   = -1;
+int lpfc2_network_on   = -1;
+int lpfc3_network_on   = -1;
+int lpfc4_network_on   = -1;
+int lpfc5_network_on   = -1;
+int lpfc6_network_on   = -1;
+int lpfc7_network_on   = -1;
+int lpfc8_network_on   = -1;
+int lpfc9_network_on   = -1;
+int lpfc10_network_on  = -1;
+int lpfc11_network_on  = -1;
+int lpfc12_network_on  = -1;
+int lpfc13_network_on  = -1;
+int lpfc14_network_on  = -1;
+int lpfc15_network_on  = -1;
+int lpfc16_network_on  = -1;
+int lpfc17_network_on  = -1;
+int lpfc18_network_on  = -1;
+int lpfc19_network_on  = -1;
+int lpfc20_network_on  = -1;
+int lpfc21_network_on  = -1;
+int lpfc22_network_on  = -1;
+int lpfc23_network_on  = -1;
+int lpfc24_network_on  = -1;
+int lpfc25_network_on  = -1;
+int lpfc26_network_on  = -1;
+int lpfc27_network_on  = -1;
+int lpfc28_network_on  = -1;
+int lpfc29_network_on  = -1;
+int lpfc30_network_on  = -1;
+int lpfc31_network_on  = -1;
+
+/*
+# xmt_que_size:  This is the size of the transmit queue for mbufs. Value
+# range is [128,10240]. Default value is 256.
+*/
+int lpfc_xmt_que_size  = 256;
+int lpfc0_xmt_que_size  = -1;
+int lpfc1_xmt_que_size  = -1;
+int lpfc2_xmt_que_size  = -1;
+int lpfc3_xmt_que_size  = -1;
+int lpfc4_xmt_que_size  = -1;
+int lpfc5_xmt_que_size  = -1;
+int lpfc6_xmt_que_size  = -1;
+int lpfc7_xmt_que_size  = -1;
+int lpfc8_xmt_que_size  = -1;
+int lpfc9_xmt_que_size  = -1;
+int lpfc10_xmt_que_size = -1;
+int lpfc11_xmt_que_size = -1;
+int lpfc12_xmt_que_size = -1;
+int lpfc13_xmt_que_size = -1;
+int lpfc14_xmt_que_size = -1;
+int lpfc15_xmt_que_size = -1;
+int lpfc16_xmt_que_size = -1;
+int lpfc17_xmt_que_size = -1;
+int lpfc18_xmt_que_size = -1;
+int lpfc19_xmt_que_size = -1;
+int lpfc20_xmt_que_size = -1;
+int lpfc21_xmt_que_size = -1;
+int lpfc22_xmt_que_size = -1;
+int lpfc23_xmt_que_size = -1;
+int lpfc24_xmt_que_size = -1;
+int lpfc25_xmt_que_size = -1;
+int lpfc26_xmt_que_size = -1;
+int lpfc27_xmt_que_size = -1;
+int lpfc28_xmt_que_size = -1;
+int lpfc29_xmt_que_size = -1;
+int lpfc30_xmt_que_size = -1;
+int lpfc31_xmt_que_size = -1;
+
+/*
+# +++ Variables common to both SCSI (FCP) and IP networking support. +++
+*/
+
+/*
+# lpfc_linkdown_tmo: Determine how long the driver will wait to begin
+# linkdown processing when a cable has been pulled or the link has
+# otherwise become inaccessible.  Linkdown processing includes failing back 
+# cmds to the target driver that have been waiting around for the link
+# to come back up.  There's a tradeoff here:  small values of the timer
+# cause the link to appear to "bounce", while large values of the
+# timer can delay redundent HBA recovery in a fault tolerant environment.
+# Units are in seconds. A value of 0 means never failback cmds until the
+# link comes up. Value range is [0,255]. Default value is 30.
+*/
+int  lpfc_linkdown_tmo   = 30;
+int  lpfc0_linkdown_tmo  = -1;
+int  lpfc1_linkdown_tmo  = -1;
+int  lpfc2_linkdown_tmo  = -1;
+int  lpfc3_linkdown_tmo  = -1;
+int  lpfc4_linkdown_tmo  = -1;
+int  lpfc5_linkdown_tmo  = -1;
+int  lpfc6_linkdown_tmo  = -1;
+int  lpfc7_linkdown_tmo  = -1;
+int  lpfc8_linkdown_tmo  = -1;
+int  lpfc9_linkdown_tmo  = -1;
+int  lpfc10_linkdown_tmo = -1;
+int  lpfc11_linkdown_tmo = -1;
+int  lpfc12_linkdown_tmo = -1;
+int  lpfc13_linkdown_tmo = -1;
+int  lpfc14_linkdown_tmo = -1;
+int  lpfc15_linkdown_tmo = -1;
+int  lpfc16_linkdown_tmo = -1;
+int  lpfc17_linkdown_tmo = -1;
+int  lpfc18_linkdown_tmo = -1;
+int  lpfc19_linkdown_tmo = -1;
+int  lpfc20_linkdown_tmo = -1;
+int  lpfc21_linkdown_tmo = -1;
+int  lpfc22_linkdown_tmo = -1;
+int  lpfc23_linkdown_tmo = -1;
+int  lpfc24_linkdown_tmo = -1;
+int  lpfc25_linkdown_tmo = -1;
+int  lpfc26_linkdown_tmo = -1;
+int  lpfc27_linkdown_tmo = -1;
+int  lpfc28_linkdown_tmo = -1;
+int  lpfc29_linkdown_tmo = -1;
+int  lpfc30_linkdown_tmo = -1;
+int  lpfc31_linkdown_tmo = -1;
+
+/*
+# lpfc_nodev_holdio: If set, it will hold all I/O errors on devices that
+# disappear until they come back. Value range is [0,1].  Default value is 0.
+*/
+int  lpfc_nodev_holdio   =  0;
+int  lpfc0_nodev_holdio  = -1;
+int  lpfc1_nodev_holdio  = -1;
+int  lpfc2_nodev_holdio  = -1;
+int  lpfc3_nodev_holdio  = -1;
+int  lpfc4_nodev_holdio  = -1;
+int  lpfc5_nodev_holdio  = -1;
+int  lpfc6_nodev_holdio  = -1;
+int  lpfc7_nodev_holdio  = -1;
+int  lpfc8_nodev_holdio  = -1;
+int  lpfc9_nodev_holdio  = -1;
+int  lpfc10_nodev_holdio = -1;
+int  lpfc11_nodev_holdio = -1;
+int  lpfc12_nodev_holdio = -1;
+int  lpfc13_nodev_holdio = -1;
+int  lpfc14_nodev_holdio = -1;
+int  lpfc15_nodev_holdio = -1;
+int  lpfc16_nodev_holdio = -1;
+int  lpfc17_nodev_holdio = -1;
+int  lpfc18_nodev_holdio = -1;
+int  lpfc19_nodev_holdio = -1;
+int  lpfc20_nodev_holdio = -1;
+int  lpfc21_nodev_holdio = -1;
+int  lpfc22_nodev_holdio = -1;
+int  lpfc23_nodev_holdio = -1;
+int  lpfc24_nodev_holdio = -1;
+int  lpfc25_nodev_holdio = -1;
+int  lpfc26_nodev_holdio = -1;
+int  lpfc27_nodev_holdio = -1;
+int  lpfc28_nodev_holdio = -1;
+int  lpfc29_nodev_holdio = -1;
+int  lpfc30_nodev_holdio = -1;
+int  lpfc31_nodev_holdio = -1;
+
+/*
+# lpfc_nodev_tmo: If set, it will hold all I/O errors on devices that disappear
+# until the timer expires. Value range is [0,255]. Default value is 30.
+*/
+int  lpfc_nodev_tmo   = 30;
+int  lpfc0_nodev_tmo  = -1;
+int  lpfc1_nodev_tmo  = -1;
+int  lpfc2_nodev_tmo  = -1;
+int  lpfc3_nodev_tmo  = -1;
+int  lpfc4_nodev_tmo  = -1;
+int  lpfc5_nodev_tmo  = -1;
+int  lpfc6_nodev_tmo  = -1;
+int  lpfc7_nodev_tmo  = -1;
+int  lpfc8_nodev_tmo  = -1;
+int  lpfc9_nodev_tmo  = -1;
+int  lpfc10_nodev_tmo = -1;
+int  lpfc11_nodev_tmo = -1;
+int  lpfc12_nodev_tmo = -1;
+int  lpfc13_nodev_tmo = -1;
+int  lpfc14_nodev_tmo = -1;
+int  lpfc15_nodev_tmo = -1;
+int  lpfc16_nodev_tmo = -1;
+int  lpfc17_nodev_tmo = -1;
+int  lpfc18_nodev_tmo = -1;
+int  lpfc19_nodev_tmo = -1;
+int  lpfc20_nodev_tmo = -1;
+int  lpfc21_nodev_tmo = -1;
+int  lpfc22_nodev_tmo = -1;
+int  lpfc23_nodev_tmo = -1;
+int  lpfc24_nodev_tmo = -1;
+int  lpfc25_nodev_tmo = -1;
+int  lpfc26_nodev_tmo = -1;
+int  lpfc27_nodev_tmo = -1;
+int  lpfc28_nodev_tmo = -1;
+int  lpfc29_nodev_tmo = -1;
+int  lpfc30_nodev_tmo = -1;
+int  lpfc31_nodev_tmo = -1;
+
+/*
+# lpfc_delay_rsp_err: Use this to delay FCP RSP errors and certain check
+# conditions. Value range is [0,1]. Default value is 0.
+*/
+int lpfc_delay_rsp_err   =  0;
+int lpfc0_delay_rsp_err  = -1;
+int lpfc1_delay_rsp_err  = -1;
+int lpfc2_delay_rsp_err  = -1;
+int lpfc3_delay_rsp_err  = -1;
+int lpfc4_delay_rsp_err  = -1;
+int lpfc5_delay_rsp_err  = -1;
+int lpfc6_delay_rsp_err  = -1;
+int lpfc7_delay_rsp_err  = -1;
+int lpfc8_delay_rsp_err  = -1;
+int lpfc9_delay_rsp_err  = -1;
+int lpfc10_delay_rsp_err = -1;
+int lpfc11_delay_rsp_err = -1;
+int lpfc12_delay_rsp_err = -1;
+int lpfc13_delay_rsp_err = -1;
+int lpfc14_delay_rsp_err = -1;
+int lpfc15_delay_rsp_err = -1;
+int lpfc16_delay_rsp_err = -1;
+int lpfc17_delay_rsp_err = -1;
+int lpfc18_delay_rsp_err = -1;
+int lpfc19_delay_rsp_err = -1;
+int lpfc20_delay_rsp_err = -1;
+int lpfc21_delay_rsp_err = -1;
+int lpfc22_delay_rsp_err = -1;
+int lpfc23_delay_rsp_err = -1;
+int lpfc24_delay_rsp_err = -1;
+int lpfc25_delay_rsp_err = -1;
+int lpfc26_delay_rsp_err = -1;
+int lpfc27_delay_rsp_err = -1;
+int lpfc28_delay_rsp_err = -1;
+int lpfc29_delay_rsp_err = -1;
+int lpfc30_delay_rsp_err = -1;
+int lpfc31_delay_rsp_err = -1;
+
+/*
+# lpfc_check_cond_err: Treat certain check conditions as a FCP error. Value
+# range is [0,1]. Default value is 0.
+*/
+int lpfc_check_cond_err   =  0;
+int lpfc0_check_cond_err  = -1;
+int lpfc1_check_cond_err  = -1;
+int lpfc2_check_cond_err  = -1;
+int lpfc3_check_cond_err  = -1;
+int lpfc4_check_cond_err  = -1;
+int lpfc5_check_cond_err  = -1;
+int lpfc6_check_cond_err  = -1;
+int lpfc7_check_cond_err  = -1;
+int lpfc8_check_cond_err  = -1;
+int lpfc9_check_cond_err  = -1;
+int lpfc10_check_cond_err = -1;
+int lpfc11_check_cond_err = -1;
+int lpfc12_check_cond_err = -1;
+int lpfc13_check_cond_err = -1;
+int lpfc14_check_cond_err = -1;
+int lpfc15_check_cond_err = -1;
+int lpfc16_check_cond_err = -1;
+int lpfc17_check_cond_err = -1;
+int lpfc18_check_cond_err = -1;
+int lpfc19_check_cond_err = -1;
+int lpfc20_check_cond_err = -1;
+int lpfc21_check_cond_err = -1;
+int lpfc22_check_cond_err = -1;
+int lpfc23_check_cond_err = -1;
+int lpfc24_check_cond_err = -1;
+int lpfc25_check_cond_err = -1;
+int lpfc26_check_cond_err = -1;
+int lpfc27_check_cond_err = -1;
+int lpfc28_check_cond_err = -1;
+int lpfc29_check_cond_err = -1;
+int lpfc30_check_cond_err = -1;
+int lpfc31_check_cond_err = -1;
+
+/*
+# lpfc_num_iocbs: Determines number of iocb buffers to allocate. Value 
+# range is [128, 10240]. Default value is 256.
+*/
+int lpfc_num_iocbs = 256;
+int lpfc0_num_iocbs  = -1;
+int lpfc1_num_iocbs  = -1;
+int lpfc2_num_iocbs  = -1;
+int lpfc3_num_iocbs  = -1;
+int lpfc4_num_iocbs  = -1;
+int lpfc5_num_iocbs  = -1;
+int lpfc6_num_iocbs  = -1;
+int lpfc7_num_iocbs  = -1;
+int lpfc8_num_iocbs  = -1;
+int lpfc9_num_iocbs  = -1;
+int lpfc10_num_iocbs = -1;
+int lpfc11_num_iocbs = -1;
+int lpfc12_num_iocbs = -1;
+int lpfc13_num_iocbs = -1;
+int lpfc14_num_iocbs = -1;
+int lpfc15_num_iocbs = -1;
+int lpfc16_num_iocbs = -1;
+int lpfc17_num_iocbs = -1;
+int lpfc18_num_iocbs = -1;
+int lpfc19_num_iocbs = -1;
+int lpfc20_num_iocbs = -1;
+int lpfc21_num_iocbs = -1;
+int lpfc22_num_iocbs = -1;
+int lpfc23_num_iocbs = -1;
+int lpfc24_num_iocbs = -1;
+int lpfc25_num_iocbs = -1;
+int lpfc26_num_iocbs = -1;
+int lpfc27_num_iocbs = -1;
+int lpfc28_num_iocbs = -1;
+int lpfc29_num_iocbs = -1;
+int lpfc30_num_iocbs = -1;
+int lpfc31_num_iocbs = -1;
+
+/*
+# lpfc_num_bufs:  Determines the number of ELS buffers to allocate.
+# ELS buffers are needed to support Fibre Channel Extended Link Services.
+# Also used for SLI-2 FCP buffers, one per FCP command, and Mailbox commands. 
+# Value range is [64,4096]. Default value is 128.
+*/
+int  lpfc_num_bufs = 128;
+int  lpfc0_num_bufs  = -1;
+int  lpfc1_num_bufs  = -1;
+int  lpfc2_num_bufs  = -1;
+int  lpfc3_num_bufs  = -1;
+int  lpfc4_num_bufs  = -1;
+int  lpfc5_num_bufs  = -1;
+int  lpfc6_num_bufs  = -1;
+int  lpfc7_num_bufs  = -1;
+int  lpfc8_num_bufs  = -1;
+int  lpfc9_num_bufs  = -1;
+int  lpfc10_num_bufs = -1;
+int  lpfc11_num_bufs = -1;
+int  lpfc12_num_bufs = -1;
+int  lpfc13_num_bufs = -1;
+int  lpfc14_num_bufs = -1;
+int  lpfc15_num_bufs = -1;
+int  lpfc16_num_bufs = -1;
+int  lpfc17_num_bufs = -1;
+int  lpfc18_num_bufs = -1;
+int  lpfc19_num_bufs = -1;
+int  lpfc20_num_bufs = -1;
+int  lpfc21_num_bufs = -1;
+int  lpfc22_num_bufs = -1;
+int  lpfc23_num_bufs = -1;
+int  lpfc24_num_bufs = -1;
+int  lpfc25_num_bufs = -1;
+int  lpfc26_num_bufs = -1;
+int  lpfc27_num_bufs = -1;
+int  lpfc28_num_bufs = -1;
+int  lpfc29_num_bufs = -1;
+int  lpfc30_num_bufs = -1;
+int  lpfc31_num_bufs = -1;
+
+/*
+# lpfc_topology:  link topology for init link
+#            0x0  = attempt loop mode then point-to-point
+#            0x02 = attempt point-to-point mode only
+#            0x04 = attempt loop mode only 
+#            0x06 = attempt point-to-point mode then loop
+# Set point-to-point mode if you want to run as an N_Port.
+# Set loop mode if you want to run as an NL_Port. Value range is [0,0x6].
+# Default value is 0.
+*/
+int lpfc_topology   =   0x0;
+int lpfc0_topology  =  -1;
+int lpfc1_topology  =  -1;
+int lpfc2_topology  =  -1;
+int lpfc3_topology  =  -1;
+int lpfc4_topology  =  -1;
+int lpfc5_topology  =  -1;
+int lpfc6_topology  =  -1;
+int lpfc7_topology  =  -1;
+int lpfc8_topology  =  -1;
+int lpfc9_topology  =  -1;
+int lpfc10_topology =  -1;
+int lpfc11_topology =  -1;
+int lpfc12_topology =  -1;
+int lpfc13_topology =  -1;
+int lpfc14_topology =  -1;
+int lpfc15_topology =  -1;
+int lpfc16_topology =  -1;
+int lpfc17_topology =  -1;
+int lpfc18_topology =  -1;
+int lpfc19_topology =  -1;
+int lpfc20_topology =  -1;
+int lpfc21_topology =  -1;
+int lpfc22_topology =  -1;
+int lpfc23_topology =  -1;
+int lpfc24_topology =  -1;
+int lpfc25_topology =  -1;
+int lpfc26_topology =  -1;
+int lpfc27_topology =  -1;
+int lpfc28_topology =  -1;
+int lpfc29_topology =  -1;
+int lpfc30_topology =  -1;
+int lpfc31_topology =  -1;
+
+/*
+# lpfc_link_speed: Link speed selection for initializing the Fibre Channel
+# connection.
+#       0 = auto select (default)
+#       1 = 1 Gigabaud
+#       2 = 2 Gigabaud
+# Value range is [0,2]. Default value is 0.
+*/
+int  lpfc_link_speed   =  0;
+int  lpfc0_link_speed  = -1;
+int  lpfc1_link_speed  = -1;
+int  lpfc2_link_speed  = -1;
+int  lpfc3_link_speed  = -1;
+int  lpfc4_link_speed  = -1;
+int  lpfc5_link_speed  = -1;
+int  lpfc6_link_speed  = -1;
+int  lpfc7_link_speed  = -1;
+int  lpfc8_link_speed  = -1;
+int  lpfc9_link_speed  = -1;
+int  lpfc10_link_speed = -1;
+int  lpfc11_link_speed = -1;
+int  lpfc12_link_speed = -1;
+int  lpfc13_link_speed = -1;
+int  lpfc14_link_speed = -1;
+int  lpfc15_link_speed = -1;
+int  lpfc16_link_speed = -1;
+int  lpfc17_link_speed = -1;
+int  lpfc18_link_speed = -1;
+int  lpfc19_link_speed = -1;
+int  lpfc20_link_speed = -1;
+int  lpfc21_link_speed = -1;
+int  lpfc22_link_speed = -1;
+int  lpfc23_link_speed = -1;
+int  lpfc24_link_speed = -1;
+int  lpfc25_link_speed = -1;
+int  lpfc26_link_speed = -1;
+int  lpfc27_link_speed = -1;
+int  lpfc28_link_speed = -1;
+int  lpfc29_link_speed = -1;
+int  lpfc30_link_speed = -1;
+int  lpfc31_link_speed = -1;
+
+/*
+# lpfc_ip_class:  Determines FC class to use for the IP protocol.
+# Value range is [2,3]. Default value is 3.
+*/
+int lpfc_ip_class    =  3;
+int lpfc0_ip_class   = -1;
+int lpfc1_ip_class   = -1;
+int lpfc2_ip_class   = -1;
+int lpfc3_ip_class   = -1;
+int lpfc4_ip_class   = -1;
+int lpfc5_ip_class   = -1;
+int lpfc6_ip_class   = -1;
+int lpfc7_ip_class   = -1;
+int lpfc8_ip_class   = -1;
+int lpfc9_ip_class   = -1;
+int lpfc10_ip_class  = -1;
+int lpfc11_ip_class  = -1;
+int lpfc12_ip_class  = -1;
+int lpfc13_ip_class  = -1;
+int lpfc14_ip_class  = -1;
+int lpfc15_ip_class  = -1;
+int lpfc16_ip_class  = -1;
+int lpfc17_ip_class  = -1;
+int lpfc18_ip_class  = -1;
+int lpfc19_ip_class  = -1;
+int lpfc20_ip_class  = -1;
+int lpfc21_ip_class  = -1;
+int lpfc22_ip_class  = -1;
+int lpfc23_ip_class  = -1;
+int lpfc24_ip_class  = -1;
+int lpfc25_ip_class  = -1;
+int lpfc26_ip_class  = -1;
+int lpfc27_ip_class  = -1;
+int lpfc28_ip_class  = -1;
+int lpfc29_ip_class  = -1;
+int lpfc30_ip_class  = -1;
+int lpfc31_ip_class  = -1;
+
+/*
+# lpfc_fcp_class:  Determines FC class to use for the FCP protocol.
+# Value range is [2,3]. Default value is 3.
+*/
+int lpfc_fcp_class   =  3;
+int lpfc0_fcp_class  = -1;
+int lpfc1_fcp_class  = -1;
+int lpfc2_fcp_class  = -1;
+int lpfc3_fcp_class  = -1;
+int lpfc4_fcp_class  = -1;
+int lpfc5_fcp_class  = -1;
+int lpfc6_fcp_class  = -1;
+int lpfc7_fcp_class  = -1;
+int lpfc8_fcp_class  = -1;
+int lpfc9_fcp_class  = -1;
+int lpfc10_fcp_class = -1;
+int lpfc11_fcp_class = -1;
+int lpfc12_fcp_class = -1;
+int lpfc13_fcp_class = -1;
+int lpfc14_fcp_class = -1;
+int lpfc15_fcp_class = -1;
+int lpfc16_fcp_class = -1;
+int lpfc17_fcp_class = -1;
+int lpfc18_fcp_class = -1;
+int lpfc19_fcp_class = -1;
+int lpfc20_fcp_class = -1;
+int lpfc21_fcp_class = -1;
+int lpfc22_fcp_class = -1;
+int lpfc23_fcp_class = -1;
+int lpfc24_fcp_class = -1;
+int lpfc25_fcp_class = -1;
+int lpfc26_fcp_class = -1;
+int lpfc27_fcp_class = -1;
+int lpfc28_fcp_class = -1;
+int lpfc29_fcp_class = -1;
+int lpfc30_fcp_class = -1;
+int lpfc31_fcp_class = -1;
+
+/*
+# lpfc_use_adisc: Use ADISC for FCP rediscovery instead of PLOGI. Value range
+# is [0,1]. Default value is 0.
+*/
+int  lpfc_use_adisc   =  0;
+int  lpfc0_use_adisc  = -1; 
+int  lpfc1_use_adisc  = -1; 
+int  lpfc2_use_adisc  = -1; 
+int  lpfc3_use_adisc  = -1; 
+int  lpfc4_use_adisc  = -1; 
+int  lpfc5_use_adisc  = -1; 
+int  lpfc6_use_adisc  = -1; 
+int  lpfc7_use_adisc  = -1; 
+int  lpfc8_use_adisc  = -1; 
+int  lpfc9_use_adisc  = -1; 
+int  lpfc10_use_adisc = -1; 
+int  lpfc11_use_adisc = -1; 
+int  lpfc12_use_adisc = -1; 
+int  lpfc13_use_adisc = -1; 
+int  lpfc14_use_adisc = -1; 
+int  lpfc15_use_adisc = -1; 
+int  lpfc16_use_adisc = -1; 
+int  lpfc17_use_adisc = -1; 
+int  lpfc18_use_adisc = -1; 
+int  lpfc19_use_adisc = -1; 
+int  lpfc20_use_adisc = -1; 
+int  lpfc21_use_adisc = -1; 
+int  lpfc22_use_adisc = -1; 
+int  lpfc23_use_adisc = -1; 
+int  lpfc24_use_adisc = -1; 
+int  lpfc25_use_adisc = -1; 
+int  lpfc26_use_adisc = -1; 
+int  lpfc27_use_adisc = -1; 
+int  lpfc28_use_adisc = -1; 
+int  lpfc29_use_adisc = -1; 
+int  lpfc30_use_adisc = -1; 
+int  lpfc31_use_adisc = -1; 
+
+/*
+# lpfc_extra_io_tmo: Extra FCP timeout for fabrics. Value range is [0,255].
+# Default value is 0.
+*/
+int  lpfc_extra_io_tmo   =  0;
+int  lpfc0_extra_io_tmo  = -1;
+int  lpfc1_extra_io_tmo  = -1;
+int  lpfc2_extra_io_tmo  = -1;
+int  lpfc3_extra_io_tmo  = -1;
+int  lpfc4_extra_io_tmo  = -1;
+int  lpfc5_extra_io_tmo  = -1;
+int  lpfc6_extra_io_tmo  = -1;
+int  lpfc7_extra_io_tmo  = -1;
+int  lpfc8_extra_io_tmo  = -1;
+int  lpfc9_extra_io_tmo  = -1;
+int  lpfc10_extra_io_tmo = -1;
+int  lpfc11_extra_io_tmo = -1;
+int  lpfc12_extra_io_tmo = -1;
+int  lpfc13_extra_io_tmo = -1;
+int  lpfc14_extra_io_tmo = -1;
+int  lpfc15_extra_io_tmo = -1;
+int  lpfc16_extra_io_tmo = -1;
+int  lpfc17_extra_io_tmo = -1;
+int  lpfc18_extra_io_tmo = -1;
+int  lpfc19_extra_io_tmo = -1;
+int  lpfc20_extra_io_tmo = -1;
+int  lpfc21_extra_io_tmo = -1;
+int  lpfc22_extra_io_tmo = -1;
+int  lpfc23_extra_io_tmo = -1;
+int  lpfc24_extra_io_tmo = -1;
+int  lpfc25_extra_io_tmo = -1;
+int  lpfc26_extra_io_tmo = -1;
+int  lpfc27_extra_io_tmo = -1;
+int  lpfc28_extra_io_tmo = -1;
+int  lpfc29_extra_io_tmo = -1;
+int  lpfc30_extra_io_tmo = -1;
+int  lpfc31_extra_io_tmo = -1;
+
+/*
+# lpfc_post_ip_buf: Determines number of 4k STREAMS buffers to post to IP ring.
+# Value range is [64, 1024]. Default value is 128.
+*/
+int  lpfc_post_ip_buf  = 128;
+int  lpfc0_post_ip_buf  = -1;
+int  lpfc1_post_ip_buf  = -1;
+int  lpfc2_post_ip_buf  = -1;
+int  lpfc3_post_ip_buf  = -1;
+int  lpfc4_post_ip_buf  = -1;
+int  lpfc5_post_ip_buf  = -1;
+int  lpfc6_post_ip_buf  = -1;
+int  lpfc7_post_ip_buf  = -1;
+int  lpfc8_post_ip_buf  = -1;
+int  lpfc9_post_ip_buf  = -1;
+int  lpfc10_post_ip_buf = -1;
+int  lpfc11_post_ip_buf = -1;
+int  lpfc12_post_ip_buf = -1;
+int  lpfc13_post_ip_buf = -1;
+int  lpfc14_post_ip_buf = -1;
+int  lpfc15_post_ip_buf = -1;
+int  lpfc16_post_ip_buf = -1;
+int  lpfc17_post_ip_buf = -1;
+int  lpfc18_post_ip_buf = -1;
+int  lpfc19_post_ip_buf = -1;
+int  lpfc20_post_ip_buf = -1;
+int  lpfc21_post_ip_buf = -1;
+int  lpfc22_post_ip_buf = -1;
+int  lpfc23_post_ip_buf = -1;
+int  lpfc24_post_ip_buf = -1;
+int  lpfc25_post_ip_buf = -1;
+int  lpfc26_post_ip_buf = -1;
+int  lpfc27_post_ip_buf = -1;
+int  lpfc28_post_ip_buf = -1;
+int  lpfc29_post_ip_buf = -1;
+int  lpfc30_post_ip_buf = -1;
+int  lpfc31_post_ip_buf = -1;
+
+/*
+# lpfc_dqfull_throttle_up_time: Use dqfull-throttle-up-time to specify when to
+# increment the current Q depth. This variable is in seconds. Value range
+# is [0,30]. Default value is 1.
+*/
+int lpfc_dqfull_throttle_up_time   =  1;
+int lpfc0_dqfull_throttle_up_time  = -1;
+int lpfc1_dqfull_throttle_up_time  = -1;
+int lpfc2_dqfull_throttle_up_time  = -1;
+int lpfc3_dqfull_throttle_up_time  = -1;
+int lpfc4_dqfull_throttle_up_time  = -1;
+int lpfc5_dqfull_throttle_up_time  = -1;
+int lpfc6_dqfull_throttle_up_time  = -1;
+int lpfc7_dqfull_throttle_up_time  = -1;
+int lpfc8_dqfull_throttle_up_time  = -1;
+int lpfc9_dqfull_throttle_up_time  = -1;
+int lpfc10_dqfull_throttle_up_time = -1;
+int lpfc11_dqfull_throttle_up_time = -1;
+int lpfc12_dqfull_throttle_up_time = -1;
+int lpfc13_dqfull_throttle_up_time = -1;
+int lpfc14_dqfull_throttle_up_time = -1;
+int lpfc15_dqfull_throttle_up_time = -1;
+int lpfc16_dqfull_throttle_up_time = -1;
+int lpfc17_dqfull_throttle_up_time = -1;
+int lpfc18_dqfull_throttle_up_time = -1;
+int lpfc19_dqfull_throttle_up_time = -1;
+int lpfc20_dqfull_throttle_up_time = -1;
+int lpfc21_dqfull_throttle_up_time = -1;
+int lpfc22_dqfull_throttle_up_time = -1;
+int lpfc23_dqfull_throttle_up_time = -1;
+int lpfc24_dqfull_throttle_up_time = -1;
+int lpfc25_dqfull_throttle_up_time = -1;
+int lpfc26_dqfull_throttle_up_time = -1;
+int lpfc27_dqfull_throttle_up_time = -1;
+int lpfc28_dqfull_throttle_up_time = -1;
+int lpfc29_dqfull_throttle_up_time = -1;
+int lpfc30_dqfull_throttle_up_time = -1;
+int lpfc31_dqfull_throttle_up_time = -1;
+
+/*
+# lpfc_dqfull_throttle_up_inc: Increment the current Q depth by 
+# dqfull-throttle-up-inc. Value range is [0,128]. Default value is 1.
+*/
+int lpfc_dqfull_throttle_up_inc   =  1;
+int lpfc0_dqfull_throttle_up_inc  = -1;
+int lpfc1_dqfull_throttle_up_inc  = -1;
+int lpfc2_dqfull_throttle_up_inc  = -1;
+int lpfc3_dqfull_throttle_up_inc  = -1;
+int lpfc4_dqfull_throttle_up_inc  = -1;
+int lpfc5_dqfull_throttle_up_inc  = -1;
+int lpfc6_dqfull_throttle_up_inc  = -1;
+int lpfc7_dqfull_throttle_up_inc  = -1;
+int lpfc8_dqfull_throttle_up_inc  = -1;
+int lpfc9_dqfull_throttle_up_inc  = -1;
+int lpfc10_dqfull_throttle_up_inc = -1;
+int lpfc11_dqfull_throttle_up_inc = -1;
+int lpfc12_dqfull_throttle_up_inc = -1;
+int lpfc13_dqfull_throttle_up_inc = -1;
+int lpfc14_dqfull_throttle_up_inc = -1;
+int lpfc15_dqfull_throttle_up_inc = -1;
+int lpfc16_dqfull_throttle_up_inc = -1;
+int lpfc17_dqfull_throttle_up_inc = -1;
+int lpfc18_dqfull_throttle_up_inc = -1;
+int lpfc19_dqfull_throttle_up_inc = -1;
+int lpfc20_dqfull_throttle_up_inc = -1;
+int lpfc21_dqfull_throttle_up_inc = -1;
+int lpfc22_dqfull_throttle_up_inc = -1;
+int lpfc23_dqfull_throttle_up_inc = -1;
+int lpfc24_dqfull_throttle_up_inc = -1;
+int lpfc25_dqfull_throttle_up_inc = -1;
+int lpfc26_dqfull_throttle_up_inc = -1;
+int lpfc27_dqfull_throttle_up_inc = -1;
+int lpfc28_dqfull_throttle_up_inc = -1;
+int lpfc29_dqfull_throttle_up_inc = -1;
+int lpfc30_dqfull_throttle_up_inc = -1;
+int lpfc31_dqfull_throttle_up_inc = -1;
+
+/*
+# lpfc_ack0: Use ACK0, instead of ACK1 for class 2 acknowledgement. Value
+# range is [0,1]. Default value is 0.
+*/
+int  lpfc_ack0   =  0;
+int  lpfc0_ack0  = -1;
+int  lpfc1_ack0  = -1;
+int  lpfc2_ack0  = -1;
+int  lpfc3_ack0  = -1;
+int  lpfc4_ack0  = -1;
+int  lpfc5_ack0  = -1;
+int  lpfc6_ack0  = -1;
+int  lpfc7_ack0  = -1;
+int  lpfc8_ack0  = -1;
+int  lpfc9_ack0  = -1;
+int  lpfc10_ack0 = -1;
+int  lpfc11_ack0 = -1;
+int  lpfc12_ack0 = -1;
+int  lpfc13_ack0 = -1;
+int  lpfc14_ack0 = -1;
+int  lpfc15_ack0 = -1;
+int  lpfc16_ack0 = -1;
+int  lpfc17_ack0 = -1;
+int  lpfc18_ack0 = -1;
+int  lpfc19_ack0 = -1;
+int  lpfc20_ack0 = -1;
+int  lpfc21_ack0 = -1;
+int  lpfc22_ack0 = -1;
+int  lpfc23_ack0 = -1;
+int  lpfc24_ack0 = -1;
+int  lpfc25_ack0 = -1;
+int  lpfc26_ack0 = -1;
+int  lpfc27_ack0 = -1;
+int  lpfc28_ack0 = -1;
+int  lpfc29_ack0 = -1;
+int  lpfc30_ack0 = -1;
+int  lpfc31_ack0 = -1;
+
+/* 
+# lpfc_cr_delay & lpfc_cr_count: Default values for I/O colaesing 
+# cr_delay (msec) or cr_count outstanding commands. cr_delay can take
+# value [0,63]. cr_count can take value [0,255]. Default value of cr_delay
+# is 0. Default value of cr_count is 0. The cr_count feature is disabled if
+# cr_delay is set to 0.
+*/
+int  lpfc_cr_delay   =  0;
+int  lpfc0_cr_delay  = -1;
+int  lpfc1_cr_delay  = -1;
+int  lpfc2_cr_delay  = -1;
+int  lpfc3_cr_delay  = -1;
+int  lpfc4_cr_delay  = -1;
+int  lpfc5_cr_delay  = -1;
+int  lpfc6_cr_delay  = -1;
+int  lpfc7_cr_delay  = -1;
+int  lpfc8_cr_delay  = -1;
+int  lpfc9_cr_delay  = -1;
+int  lpfc10_cr_delay = -1;
+int  lpfc11_cr_delay = -1;
+int  lpfc12_cr_delay = -1;
+int  lpfc13_cr_delay = -1;
+int  lpfc14_cr_delay = -1;
+int  lpfc15_cr_delay = -1;
+int  lpfc16_cr_delay = -1;
+int  lpfc17_cr_delay = -1;
+int  lpfc18_cr_delay = -1;
+int  lpfc19_cr_delay = -1;
+int  lpfc20_cr_delay = -1;
+int  lpfc21_cr_delay = -1;
+int  lpfc22_cr_delay = -1;
+int  lpfc23_cr_delay = -1;
+int  lpfc24_cr_delay = -1;
+int  lpfc25_cr_delay = -1;
+int  lpfc26_cr_delay = -1;
+int  lpfc27_cr_delay = -1;
+int  lpfc28_cr_delay = -1;
+int  lpfc29_cr_delay = -1;
+int  lpfc30_cr_delay = -1;
+int  lpfc31_cr_delay = -1;
+
+int  lpfc_cr_count   =  1;
+int  lpfc0_cr_count  = -1;
+int  lpfc1_cr_count  = -1;
+int  lpfc2_cr_count  = -1;
+int  lpfc3_cr_count  = -1;
+int  lpfc4_cr_count  = -1;
+int  lpfc5_cr_count  = -1;
+int  lpfc6_cr_count  = -1;
+int  lpfc7_cr_count  = -1;
+int  lpfc8_cr_count  = -1;
+int  lpfc9_cr_count  = -1;
+int  lpfc10_cr_count = -1;
+int  lpfc11_cr_count = -1;
+int  lpfc12_cr_count = -1;
+int  lpfc13_cr_count = -1;
+int  lpfc14_cr_count = -1;
+int  lpfc15_cr_count = -1;
+int  lpfc16_cr_count = -1;
+int  lpfc17_cr_count = -1;
+int  lpfc18_cr_count = -1;
+int  lpfc19_cr_count = -1;
+int  lpfc20_cr_count = -1;
+int  lpfc21_cr_count = -1;
+int  lpfc22_cr_count = -1;
+int  lpfc23_cr_count = -1;
+int  lpfc24_cr_count = -1;
+int  lpfc25_cr_count = -1;
+int  lpfc26_cr_count = -1;
+int  lpfc27_cr_count = -1;
+int  lpfc28_cr_count = -1;
+int  lpfc29_cr_count = -1;
+int  lpfc30_cr_count = -1;
+int  lpfc31_cr_count = -1;
+
+/*
+# lpfc_fdmi_on: controls FDMI support.
+# 	0 = no FDMI support
+#	1 = support FDMI without attribute of hostname
+#	2 = support FDMI with attribute of hostname
+# Value range [0,2]. Default value is 0.
+*/
+int  lpfc_fdmi_on   =  0;
+int  lpfc0_fdmi_on  = -1;
+int  lpfc1_fdmi_on  = -1;
+int  lpfc2_fdmi_on  = -1;
+int  lpfc3_fdmi_on  = -1;
+int  lpfc4_fdmi_on  = -1;
+int  lpfc5_fdmi_on  = -1;
+int  lpfc6_fdmi_on  = -1;
+int  lpfc7_fdmi_on  = -1;
+int  lpfc8_fdmi_on  = -1;
+int  lpfc9_fdmi_on  = -1;
+int  lpfc10_fdmi_on = -1;
+int  lpfc11_fdmi_on = -1;
+int  lpfc12_fdmi_on = -1;
+int  lpfc13_fdmi_on = -1;
+int  lpfc14_fdmi_on = -1;
+int  lpfc15_fdmi_on = -1;
+int  lpfc16_fdmi_on = -1;
+int  lpfc17_fdmi_on = -1;
+int  lpfc18_fdmi_on = -1;
+int  lpfc19_fdmi_on = -1;
+int  lpfc20_fdmi_on = -1;
+int  lpfc21_fdmi_on = -1;
+int  lpfc22_fdmi_on = -1;
+int  lpfc23_fdmi_on = -1;
+int  lpfc24_fdmi_on = -1;
+int  lpfc25_fdmi_on = -1;
+int  lpfc26_fdmi_on = -1;
+int  lpfc27_fdmi_on = -1;
+int  lpfc28_fdmi_on = -1;
+int  lpfc29_fdmi_on = -1;
+int  lpfc30_fdmi_on = -1;
+int  lpfc31_fdmi_on = -1;
+
+/*
+# lpfc_scsi_req_tmo: Time out value (in seconds) for SCSI request sent. 
+# Value range is [0,255]. Default value is 30.
+*/
+int  lpfc_scsi_req_tmo   = 30;
+int  lpfc0_scsi_req_tmo  = -1;
+int  lpfc1_scsi_req_tmo  = -1;
+int  lpfc2_scsi_req_tmo  = -1;
+int  lpfc3_scsi_req_tmo  = -1;
+int  lpfc4_scsi_req_tmo  = -1;
+int  lpfc5_scsi_req_tmo  = -1;
+int  lpfc6_scsi_req_tmo  = -1;
+int  lpfc7_scsi_req_tmo  = -1;
+int  lpfc8_scsi_req_tmo  = -1;
+int  lpfc9_scsi_req_tmo  = -1;
+int  lpfc10_scsi_req_tmo = -1;
+int  lpfc11_scsi_req_tmo = -1;
+int  lpfc12_scsi_req_tmo = -1;
+int  lpfc13_scsi_req_tmo = -1;
+int  lpfc14_scsi_req_tmo = -1;
+int  lpfc15_scsi_req_tmo = -1;
+int  lpfc16_scsi_req_tmo = -1;
+int  lpfc17_scsi_req_tmo = -1;
+int  lpfc18_scsi_req_tmo = -1;
+int  lpfc19_scsi_req_tmo = -1;
+int  lpfc20_scsi_req_tmo = -1;
+int  lpfc21_scsi_req_tmo = -1;
+int  lpfc22_scsi_req_tmo = -1;
+int  lpfc23_scsi_req_tmo = -1;
+int  lpfc24_scsi_req_tmo = -1;
+int  lpfc25_scsi_req_tmo = -1;
+int  lpfc26_scsi_req_tmo = -1;
+int  lpfc27_scsi_req_tmo = -1;
+int  lpfc28_scsi_req_tmo = -1;
+int  lpfc29_scsi_req_tmo = -1;
+int  lpfc30_scsi_req_tmo = -1;
+int  lpfc31_scsi_req_tmo = -1;
+
+/*
+# lpfc_lun_skip : If this is set to 1, lpfc will fake out the LINUX scsi layer
+# to allow it to detect all LUNs if there are LUN holes on a device.
+*/
+int  lpfc_lun_skip     = 0;
+int  lpfc0_lun_skip    = -1;
+int  lpfc1_lun_skip    = -1;
+int  lpfc2_lun_skip    = -1;
+int  lpfc3_lun_skip    = -1;
+int  lpfc4_lun_skip    = -1;
+int  lpfc5_lun_skip    = -1;
+int  lpfc6_lun_skip    = -1;
+int  lpfc7_lun_skip    = -1;
+int  lpfc8_lun_skip    = -1;
+int  lpfc9_lun_skip    = -1;
+int  lpfc10_lun_skip   = -1;
+int  lpfc11_lun_skip   = -1;
+int  lpfc12_lun_skip   = -1;
+int  lpfc13_lun_skip   = -1;
+int  lpfc14_lun_skip   = -1;
+int  lpfc15_lun_skip   = -1;
+int  lpfc16_lun_skip   = -1;
+int  lpfc17_lun_skip   = -1;
+int  lpfc18_lun_skip   = -1;
+int  lpfc19_lun_skip   = -1;
+int  lpfc20_lun_skip   = -1;
+int  lpfc21_lun_skip   = -1;
+int  lpfc22_lun_skip   = -1;
+int  lpfc23_lun_skip   = -1;
+int  lpfc24_lun_skip   = -1;
+int  lpfc25_lun_skip   = -1;
+int  lpfc26_lun_skip   = -1;
+int  lpfc27_lun_skip   = -1;
+int  lpfc28_lun_skip   = -1;
+int  lpfc29_lun_skip   = -1;
+int  lpfc30_lun_skip   = -1;
+int  lpfc31_lun_skip   = -1;
+
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfcLINUXfcp.c linux-2.6.3/drivers/scsi/lpfc/lpfcLINUXfcp.c
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfcLINUXfcp.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfcLINUXfcp.c	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,9219 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+/* This is to export entry points needed for IP interface */
+#ifndef EXPORT_SYMTAB
+#define EXPORT_SYMTAB
+#endif
+#include <linux/version.h>
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/utsname.h>
+#include <linux/fcntl.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/in.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+#include <linux/blk.h>
+#else
+#include <linux/blkdev.h>
+#endif
+#include <linux/string.h>
+#include <linux/ioport.h>
+#include <linux/pci.h>
+#include <linux/unistd.h>
+#include <linux/timex.h>
+#include <linux/timer.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/if_arp.h>
+#include <asm/system.h>
+#include <asm/bitops.h>
+#include <asm/io.h>
+#include <asm/dma.h>
+#include <asm/irq.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+#include <scsi/scsi_device.h>
+#include <asm/pci.h>
+#else
+/* From drivers/scsi */
+#include "sd.h"
+#endif
+#include "hosts.h"
+
+#include "elx_os.h"
+#include "prod_os.h"
+#include "elx_util.h"
+#include "elx_clock.h"
+#include "elx_hw.h"
+#include "elx_sli.h"
+#include "elx_mem.h"
+#include "elx_sched.h"
+#include "elx.h"
+#include "elx_logmsg.h"
+#include "elx_disc.h"
+#include "elx_scsi.h"
+#include "elx_os_scsiport.h"
+#include "elx_crtn.h"
+#include "elx_cfgparm.h"
+#include "lpfc_hba.h"
+#include "lpfc_ip.h"
+#include "lpfc_ioctl.h"
+#include "lpfc_crtn.h"
+#include "prod_crtn.h"
+
+#include <linux/spinlock.h>
+#include <linux/rtnetlink.h>
+
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <asm/byteorder.h>
+
+#ifdef powerpc
+#ifndef BITS_PER_LONG
+#define BITS_PER_LONG 64
+#endif
+#endif
+
+#include <linux/module.h>
+
+/* Configuration parameters defined */
+#define LPFC_DEF_ICFG
+#include "lpfc_diag.h"
+#include "lpfc_cfgparm.h"
+#include "lpfc_module_param.h"
+
+/* This file needs to be included from /etc */
+#include "lpfc.conf"
+
+#ifndef LPFC_DRIVER_VERSION
+#define LPFC_DRIVER_VERSION "2.10a"
+#define OSGT_DRIVER_VERSION "1.08"
+#endif				/* LPFC_DRIVER_VERSION */
+
+MODULE_DESCRIPTION("Emulex LightPulse Fibre Channel driver - Open Source");
+MODULE_AUTHOR("Emulex Corporation - tech.support@emulex.com");
+
+char *lpfc_release_version = LPFC_DRIVER_VERSION;
+char lpfc_os_name_version[256];
+#define FC_EXTEND_TRANS_A 1
+#define ScsiResult(host_code, scsi_code) (((host_code) << 16) | scsi_code)
+
+/* Linux 2.4 compatibility */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+typedef void irqreturn_t;
+#define IRQ_NONE
+#define IRQ_HANDLED
+#endif				/* < 2.6.0 */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+int lpfc_detect(Scsi_Host_Template *);
+int lpfc_DetectInstance(int, struct pci_dev *, uint32_t, Scsi_Host_Template *);
+#endif
+int lpfc_diag_init(void);
+int lpfc_linux_attach(int, Scsi_Host_Template *, struct pci_dev *);
+int lpfc_get_bind_type(elxHBA_t *);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+int lpfc_release(struct Scsi_Host *host);
+#endif
+int lpfc_diag_uninit(void);
+int lpfc_linux_detach(int);
+
+const char *lpfc_info(struct Scsi_Host *);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+void lpfc_select_queue_depth(struct Scsi_Host *, Scsi_Device *);
+#else
+static int lpfc_slave_configure(Scsi_Device *);
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+static int lpfc_proc_info(struct Scsi_Host *, char *, char **, off_t, int, int);
+#endif
+int lpfc_device_queue_depth(elxHBA_t *, Scsi_Device *);
+irqreturn_t lpfc_intr_handler(int, void *, struct pt_regs *);
+void lpfc_local_timeout(unsigned long);
+int lpfc_reset_bus_handler(Scsi_Cmnd * cmnd);
+
+int lpfc_memmap(elxHBA_t *);
+int lpfc_unmemmap(elxHBA_t *);
+int lpfc_pcimap(elxHBA_t *);
+
+int lpfc_mem_poolinit(elxHBA_t *);
+int lpfc_config_setup(elxHBA_t *);
+int lpfc_bind_setup(elxHBA_t *);
+int lpfc_sli_setup(elxHBA_t *);
+void lpfc_sli_brdreset(elxHBA_t *);
+int lpfc_bind_wwpn(elxHBA_t *, char **, u_int);
+int lpfc_bind_wwnn(elxHBA_t *, char **, u_int);
+int lpfc_bind_did(elxHBA_t *, char **, u_int);
+ELXSCSILUN_t *lpfc_tran_find_lun(ELX_SCSI_BUF_t *);
+
+extern struct elx_mem_pool *elx_mem_dmapool[MAX_ELX_BRDS];
+extern int elx_idx_dmapool[MAX_ELX_BRDS];
+extern int elx_size_dmapool[MAX_ELX_BRDS];
+extern spinlock_t elx_kmem_lock;
+extern char lpfc_fwrevision[32];
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+extern int elx_biosparam(struct scsi_device *, struct block_device *,
+			 sector_t capacity, int ip[]);
+#else
+extern int elx_biosparam(Disk *, kdev_t, int[]);
+#endif
+extern int elx_pci_getadd(struct pci_dev *, int, unsigned long *);
+extern void elx_scsi_add_timer(Scsi_Cmnd *, int);
+
+int lpfc_mem_poolinit(elxHBA_t *);
+
+/* Binding Definitions: Max string size  */
+#define FC_MAX_DID_STRING       6
+#define FC_MAX_WW_NN_PN_STRING 16
+
+#define LPFC_DRIVER_NAME    "lpfc"
+char *elx_drvr_name = LPFC_DRIVER_NAME;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+#if VARYIO == 20
+#define VARYIO_ENTRY .can_do_varyio = 1,
+#elif VARYIO == 3
+#define VARYIO_ENTRY .vary_io =1,
+#else
+#define VARYIO_ENTRY
+#endif
+
+#if defined CONFIG_HIGHMEM
+#if USE_HIGHMEM_IO ==2		// i386 & Redhat 2.1
+#define HIGHMEM_ENTRY .can_dma_32 = 1,
+#define SINGLE_SG_OK .single_sg_ok = 1,
+#else
+#if USE_HIGHMEM_IO ==3		// Redhat 3.0, Suse
+#define HIGHMEM_ENTRY .highmem_io = 1,
+#define SINGLE_SG_OK
+#else				// any other
+#define HIGHMEM_ENTRY
+#define SINGLE_SG_OK
+#endif
+#endif
+#else				// no highmem config
+#define HIGHMEM_ENTRY
+#define SINGLE_SG_OK
+#endif
+#endif
+
+static Scsi_Host_Template driver_template = {
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	.next = NULL,
+	.command = NULL,
+	.slave_attach = NULL,
+	.use_new_eh_code = 1,
+	.proc_info = NULL,
+	.proc_dir = NULL,
+	.detect = lpfc_detect,
+	.release = lpfc_release,
+	VARYIO_ENTRY
+	HIGHMEM_ENTRY
+	SINGLE_SG_OK
+#else
+	.proc_info = lpfc_proc_info,
+	.slave_configure = lpfc_slave_configure,
+#endif
+	.proc_name = LPFC_DRIVER_NAME,
+	.module = THIS_MODULE,
+	.name = LPFC_DRIVER_NAME,
+	.info = lpfc_info,
+	.queuecommand = elx_queuecommand,
+	.eh_strategy_handler = NULL,
+	.eh_abort_handler = elx_abort_handler,
+	.eh_device_reset_handler = elx_reset_lun_handler,
+	.eh_bus_reset_handler = lpfc_reset_bus_handler,
+	.eh_host_reset_handler = NULL,
+	.abort = NULL,
+	.reset = NULL,
+	.bios_param = elx_biosparam,
+	.can_queue = LPFC_DFT_HBA_Q_DEPTH,
+	.this_id = -1,
+	.sg_tablesize = SG_ALL,
+	.cmd_per_lun = 30,
+	.present = 0,
+	.unchecked_isa_dma = 0,
+	.use_clustering = DISABLE_CLUSTERING,
+	.emulated = 0
+};
+
+/* A chrdev is used for diagnostic interface */
+int lpfcdiag_ioctl(struct inode *inode, struct file *file,
+		   unsigned int cmd, unsigned long arg);
+int lpfcdiag_open(struct inode *inode, struct file *file);
+int lpfcdiag_release(struct inode *inode, struct file *file);
+
+static struct file_operations lpfc_fops = {
+	.ioctl = lpfcdiag_ioctl,
+	.open = lpfcdiag_open,
+	.release = lpfcdiag_release,
+};
+
+/*Other configuration parameters, not available to user*/
+static int lpfc_pci_latency_clocks = 0;
+static int lpfc_pci_cache_line = 0;
+/*Other configuration parameters, not available to user*/
+static int lpfc_mtu = 65280;	/* define IP max MTU size */
+static int lpfc_rcv_buff_size = 4 * 1024;	/* define IP recv buffer size */
+
+/* lpfc_detect_called can be either TRUE, FALSE or LPFN_PROBE_PENDING */
+#define LPFN_PROBE_PENDING 2
+static int lpfc_detect_called = FALSE;
+static int (*lpfn_probe) (void) = NULL;
+
+static int lpfc_major = 0;
+
+int lpfc_nethdr = 1;
+
+uint16_t lpfc_num_nodes = 128;	/* default number of NPort structs to alloc */
+int lpfc_use_data_direction = 1;
+
+LINUX_DRVR_t lpfcdrvr;
+/* Can be used to map driver instance number and hardware adapter number */
+int lpfc_instance[MAX_ELX_BRDS];
+int lpfc_instcnt = 0;
+uint32_t lpfc_diag_state = DDI_ONDI;
+int lpfc_isr = 0;
+int lpfc_tmr = 0;
+
+/* Used for driver 1 sec clock tick */
+int lpfc_clkCnt = 0;
+struct timer_list lpfc_sec_clk;
+
+extern elxDRVR_t elxDRVR;
+extern int prodMallocCnt;
+extern int prodMallocByte;
+extern int prodFreeCnt;
+extern int prodFreeByte;
+
+extern char *lpfc_fcp_bind_WWPN[];
+extern char *lpfc_fcp_bind_WWNN[];
+extern char *lpfc_fcp_bind_DID[];
+
+/* This is to export entry points needed for IP interface */
+int lpfc_xmit(elxHBA_t *, struct sk_buff *);
+int lpfc_ipioctl(int, void *);
+#ifdef MODVERSIONS
+EXPORT_SYMBOL(lpfc_xmit);
+EXPORT_SYMBOL(lpfc_ipioctl);
+#else
+EXPORT_SYMBOL_NOVERS(lpfc_xmit);
+EXPORT_SYMBOL_NOVERS(lpfc_ipioctl);
+#endif				/* MODVERSIONS */
+
+#if LINUX_VERSION_CODE <  KERNEL_VERSION(2,6,0)
+
+int
+lpfc_detect(Scsi_Host_Template * tmpt)
+{
+	struct pci_dev *pdev = NULL;
+	int instance = 0;
+	int i;
+	/* To add another, add a line before the last element.
+	 * Leave last element 0.
+	 */
+	uint32_t sType[] = {
+		PCI_DEVICE_ID_VIPER,
+		PCI_DEVICE_ID_THOR,
+		PCI_DEVICE_ID_PEGASUS,
+		PCI_DEVICE_ID_CENTAUR,
+		PCI_DEVICE_ID_DRAGONFLY,
+		PCI_DEVICE_ID_SUPERFLY,
+		PCI_DEVICE_ID_RFLY,
+		PCI_DEVICE_ID_PFLY,
+		PCI_DEVICE_ID_TFLY,
+		PCI_DEVICE_ID_LP101,
+		0
+	};
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+#if VARYIO == 21
+#ifdef SCSI_HOST_VARYIO
+	SCSI_HOST_VARYIO(tmpt) = 1;
+#endif
+#endif
+#endif
+
+	printk("Emulex LightPulse FC SCSI/IP: %s    Osgt: %s\n",
+	       lpfc_release_version, OSGT_DRIVER_VERSION);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+	/* Release the io_request_lock lock and reenable interrupts allowing
+	 * the driver to sleep if necessary.
+	 */
+	spin_unlock(&io_request_lock);
+#endif
+
+	memset((char *)&elxDRVR, 0, sizeof (elxDRVR_t));
+	memset((char *)&lpfcdrvr, 0, sizeof (LINUX_DRVR_t));
+	elxDRVR.pDrvrOSEnv = &lpfcdrvr;
+	for (i = 0; i < MAX_ELX_BRDS; i++) {
+		lpfc_instance[i] = -1;
+	}
+
+	/* Initialize all per Driver locks */
+	elx_clk_init_lock(0);
+
+	/* Search for all Device IDs supported */
+	i = 0;
+	while (sType[i]) {
+		instance = lpfc_DetectInstance(instance, pdev, sType[i], tmpt);
+		i++;
+	}
+
+	if (instance) {
+		lpfc_diag_init();	/* Initialize diagnostic interface */
+	}
+
+	/* This covers the case where the lpfn driver gets loaded before the
+	 * lpfc driver detect completes.
+	 */
+	if (lpfc_detect_called == 2) {
+		lpfc_detect_called = 1;
+		if (lpfn_probe != NULL)
+			lpfn_probe();
+
+	} else
+		lpfc_detect_called = 1;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+	/* reacquire io_request_lock as the midlayer was holding it when it
+	   called us */
+	spin_lock(&io_request_lock);
+#endif
+	return (instance);
+}
+
+int
+lpfc_DetectInstance(int instance,
+		    struct pci_dev *pdev, uint type, Scsi_Host_Template * tmpt)
+{
+
+	/* PCI_SUBSYSTEM_IDS supported */
+	while ((pdev = pci_find_subsys(PCI_VENDOR_ID_EMULEX, type,
+				       PCI_ANY_ID, PCI_ANY_ID, pdev))) {
+		if (pci_enable_device(pdev)) {
+			continue;
+		}
+		if (pci_request_regions(pdev, LPFC_DRIVER_NAME)) {
+			printk("lpfc pci I/O region is already in use. \n");
+			printk
+			    ("a driver for lpfc is already loaded on this system\n");
+			continue;
+		}
+
+		if (lpfc_linux_attach(instance, tmpt, pdev)) {
+			pci_release_regions(pdev);
+			continue;
+		}
+		instance++;
+	}
+
+	return (instance);
+}
+#endif				/* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0) */
+
+int
+lpfc_diag_init(void)
+{
+	int result;
+
+	result = register_chrdev(lpfc_major, "lpfcdfc", &lpfc_fops);
+	if (result < 0) {
+		return (result);
+	}
+	if (lpfc_major == 0)
+		lpfc_major = result;	/* dynamic */
+
+	return (0);
+}
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+int
+lpfc_release(struct Scsi_Host *host)
+{
+	elxHBA_t *phba;
+	int instance;
+	phba = (elxHBA_t *) host->hostdata[0];
+	instance = phba->brd_no;
+
+	/*
+	 * detach the board 
+	 */
+	lpfc_linux_detach(instance);
+
+	lpfc_diag_uninit();
+
+	return (0);
+}
+#endif				/* LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0) */
+
+int
+lpfc_diag_uninit(void)
+{
+	if (lpfc_major) {
+		unregister_chrdev(lpfc_major, "lpfcdfc");
+		lpfc_major = 0;
+	}
+	return (0);
+}
+
+int
+lpfc_linux_attach(int instance, Scsi_Host_Template * tmpt, struct pci_dev *pdev)
+{
+	struct Scsi_Host *host;
+	elxHBA_t *phba;
+	LINUX_HBA_t *plxhba;
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+	elxCfgParam_t *clp;
+	int rc, i;
+	unsigned long iflag;
+	uint32_t timeout;
+	int lpfc_max_target = 255;
+
+	/*
+	 * must have a valid pci_dev
+	 */
+	if (!pdev)
+		return (1);
+
+	/* Allocate memory to manage HBA dma pool.
+	 * This next section sets thing up for linux_kmalloc and linux_kfree to work.
+	 */
+	elx_mem_dmapool[instance] =
+	    kmalloc((sizeof (struct elx_mem_pool) * FC_MAX_POOL), GFP_ATOMIC);
+	if (elx_mem_dmapool[instance] == 0)
+		return (1);
+	memset((void *)elx_mem_dmapool[instance], 0,
+	       (sizeof (struct elx_mem_pool) * FC_MAX_POOL));
+	elx_idx_dmapool[instance] = 0;
+	elx_size_dmapool[instance] = FC_MAX_POOL;
+	spin_lock_init(&elx_kmem_lock);
+
+	/* 
+	 * Allocate space for adapter info structure
+	 */
+	if (!
+	    (phba =
+	     (elxHBA_t *) elx_kmem_zalloc(sizeof (elxHBA_t), ELX_MEM_DELAY))) {
+		return (1);
+	}
+
+	if (!
+	    (phba->pHbaProto =
+	     (void *)elx_kmem_zalloc(sizeof (LPFCHBA_t), ELX_MEM_DELAY))) {
+		elx_kmem_free(phba, sizeof (elxHBA_t));
+		return (1);
+	}
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if (!
+	    (phba->pHbaOSEnv =
+	     (void *)elx_kmem_zalloc(sizeof (LINUX_HBA_t), ELX_MEM_DELAY))) {
+		elx_kmem_free(phba->pHbaProto, sizeof (LPFCHBA_t));
+		elx_kmem_free(phba, sizeof (elxHBA_t));
+		return (1);
+	}
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	/* Initialize default values for configuration parameters */
+	if (!
+	    (phba->config =
+	     (elxCfgParam_t *) elx_kmem_zalloc(sizeof (lpfc_icfgparam),
+					       ELX_MEM_DELAY))) {
+		elx_kmem_free(phba->pHbaOSEnv, sizeof (LINUX_HBA_t));
+		elx_kmem_free(phba->pHbaProto, sizeof (LPFCHBA_t));
+		elx_kmem_free(phba, sizeof (elxHBA_t));
+		return (1);
+	}
+	memcpy(&phba->config[0], (uint8_t *) & lpfc_icfgparam[0],
+	       sizeof (lpfc_icfgparam));
+	clp = &phba->config[0];
+	/*
+	 * Set everything to the defaults
+	 */
+	for (i = 0; i < LPFC_TOTAL_NUM_OF_CFG_PARAM; i++)
+		clp[i].a_current = clp[i].a_default;
+
+	elxDRVR.pHba[instance] = phba;
+	lpfc_instance[instance] = instance;
+
+	/* Initialize plxhba */
+	phba->brd_no = instance;
+	phba->pci_id =
+	    ((((uint32_t) pdev->device) << 16) | (uint32_t) (pdev->vendor));
+	phba->pci_id = SWAP_LONG(phba->pci_id);
+
+	/* Initialize plhba - lpfc specific */
+	plhba->fc_nlpmap_start = (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start;
+	plhba->fc_nlpmap_end = (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start;
+	plhba->fc_nlpunmap_start =
+	    (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start;
+	plhba->fc_nlpunmap_end = (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start;
+	plhba->fc_plogi_start = (LPFC_NODELIST_t *) & plhba->fc_plogi_start;
+	plhba->fc_plogi_end = (LPFC_NODELIST_t *) & plhba->fc_plogi_start;
+	plhba->fc_adisc_start = (LPFC_NODELIST_t *) & plhba->fc_adisc_start;
+	plhba->fc_adisc_end = (LPFC_NODELIST_t *) & plhba->fc_adisc_start;
+	plhba->fc_nlpbind_start = (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start;
+	plhba->fc_nlpbind_end = (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start;
+
+	/* Initialize plxhba - LINUX specific */
+	plxhba->pcidev = pdev;
+	init_waitqueue_head(&plxhba->linkevtwq);
+	init_waitqueue_head(&plxhba->rscnevtwq);
+	init_waitqueue_head(&plxhba->ctevtwq);
+
+	if ((rc = lpfc_pcimap(phba))) {
+		elx_kmem_free(phba->pHbaOSEnv, sizeof (LINUX_HBA_t));
+		elx_kmem_free(phba->pHbaProto, sizeof (LPFCHBA_t));
+		elx_kmem_free(phba->config, sizeof (lpfc_icfgparam));
+		elx_kmem_free(phba, sizeof (elxHBA_t));
+		elxDRVR.pHba[instance] = 0;
+		return (1);
+	}
+
+	if ((rc = lpfc_memmap(phba))) {
+		elx_kmem_free(phba->pHbaOSEnv, sizeof (LINUX_HBA_t));
+		elx_kmem_free(phba->pHbaProto, sizeof (LPFCHBA_t));
+		elx_kmem_free(phba->config, sizeof (lpfc_icfgparam));
+		elx_kmem_free(phba, sizeof (elxHBA_t));
+		elxDRVR.pHba[instance] = 0;
+		return (1);
+	}
+
+	lpfc_instcnt++;
+	elxDRVR.num_devs++;
+	lpfc_config_setup(phba);	/* Setup configuration parameters */
+
+	/*
+	 * If the t.o value is not set, set it to 30
+	 */
+	if (clp[LPFC_CFG_SCSI_REQ_TMO].a_current == 0) {
+		clp[LPFC_CFG_SCSI_REQ_TMO].a_current = 30;
+	}
+
+	if (clp[LPFC_CFG_DISC_THREADS].a_current) {
+		/*
+		 * Set to FC_NLP_REQ if automap is set to 0 since order of
+		 * discovery does not matter if everything is persistently
+		 * bound. 
+		 */
+		if (clp[LPFC_CFG_AUTOMAP].a_current == 0) {
+			clp[LPFC_CFG_DISC_THREADS].a_current =
+			    LPFC_MAX_DISC_THREADS;
+		}
+	}
+
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		/* Setup nodelist entry to be used for IP Broadcasts */
+		ndlp = &plhba->fc_nlp_bcast;
+		memset(ndlp, 0, sizeof (LPFC_NODELIST_t));
+		ndlp->nlp_DID = Bcast_DID;
+		ndlp->nlp_portname.nameType = NAME_IEEE;
+		ndlp->nlp_portname.IEEE[0] = 0xff;
+		ndlp->nlp_portname.IEEE[1] = 0xff;
+		ndlp->nlp_portname.IEEE[2] = 0xff;
+		ndlp->nlp_portname.IEEE[3] = 0xff;
+		ndlp->nlp_portname.IEEE[4] = 0xff;
+		ndlp->nlp_portname.IEEE[5] = 0xff;
+		ndlp->nle.nlp_failMask = ELX_DEV_LINK_DOWN;
+		ndlp->nle.nlp_ip_info = CLASS3;
+	}
+
+	/* Initialize all per HBA locks */
+	elx_drvr_init_lock(phba);
+	elx_sli_init_lock(phba);
+	elx_mem_init_lock(phba);
+	elx_sch_init_lock(phba);
+	elx_ioc_init_lock(phba);
+	elx_disc_init_lock(phba);
+	elx_hipri_init_lock(phba);	/* init High Priority Queue lock */
+
+	/* Set up the HBA specific LUN device lookup routine */
+	phba->elx_tran_find_lun = lpfc_tran_find_lun;
+
+	lpfc_sli_setup(phba);	/* Setup SLI Layer to run over lpfc HBAs */
+	elx_sli_setup(phba);	/* Initialize the SLI Layer */
+	lpfc_mem_poolinit(phba);
+
+	if (elx_mem_alloc(phba) == 0) {
+		lpfc_instcnt--;
+		elxDRVR.num_devs--;
+		lpfc_unmemmap(phba);
+		elx_kmem_free(phba->pHbaOSEnv, sizeof (LINUX_HBA_t));
+		elx_kmem_free(phba->pHbaProto, sizeof (LPFCHBA_t));
+		elx_kmem_free(phba->config, sizeof (lpfc_icfgparam));
+		elx_kmem_free(phba, sizeof (elxHBA_t));
+		elxDRVR.pHba[instance] = 0;
+		return (1);
+	}
+
+	lpfc_bind_setup(phba);	/* Setup binding configuration parameters */
+
+	elx_sched_init_hba(phba, clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current);
+
+	/* Initialize HBA structure */
+	plhba->fc_edtov = FF_DEF_EDTOV;
+	plhba->fc_ratov = FF_DEF_RATOV;
+	plhba->fc_altov = FF_DEF_ALTOV;
+	plhba->fc_arbtov = FF_DEF_ARBTOV;
+
+	/* Set the FARP and XRI timeout values now since they depend on fc_ratov. */
+	plhba->fc_ipfarp_timeout = (3 * plhba->fc_ratov);
+	plhba->fc_ipxri_timeout = (3 * plhba->fc_ratov);
+
+	/* Initialise the network statistics structure */
+	plhba->ip_stat =
+	    (void *)elx_kmem_zalloc(sizeof (struct lpip_stats), ELX_MEM_DELAY);
+	if (!plhba->ip_stat) {
+		lpfc_instcnt--;
+		elxDRVR.num_devs--;
+		elx_sli_hba_down(phba);	/* Bring down the SLI Layer */
+		elx_mem_free(phba);
+		lpfc_unmemmap(phba);
+		elx_kmem_free(phba->pHbaOSEnv, sizeof (LINUX_HBA_t));
+		elx_kmem_free(phba->pHbaProto, sizeof (LPFCHBA_t));
+		elx_kmem_free(phba->config, sizeof (lpfc_icfgparam));
+		elx_kmem_free(phba, sizeof (elxHBA_t));
+		elxDRVR.pHba[instance] = 0;
+		return (1);
+	}
+
+	ELX_DRVR_LOCK(phba, iflag);
+
+	if ((rc = elx_sli_hba_setup(phba))) {	/* Initialize the HBA */
+		lpfc_instcnt--;
+		elxDRVR.num_devs--;
+		elx_sli_hba_down(phba);	/* Bring down the SLI Layer */
+		ELX_DRVR_UNLOCK(phba, iflag);
+		elx_mem_free(phba);
+		lpfc_unmemmap(phba);
+		elx_kmem_free(phba->pHbaOSEnv, sizeof (LINUX_HBA_t));
+		elx_kmem_free(phba->pHbaProto, sizeof (LPFCHBA_t));
+		elx_kmem_free(phba->config, sizeof (lpfc_icfgparam));
+		elx_kmem_free(phba, sizeof (elxHBA_t));
+		elxDRVR.pHba[instance] = 0;
+		return (1);
+	}
+	ELX_DRVR_UNLOCK(phba, iflag);
+
+	/* 
+	 * Register this board
+	 */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	host = scsi_register(tmpt, sizeof (unsigned long));
+#else
+	host = scsi_host_alloc(tmpt, sizeof (unsigned long));
+#endif
+	plxhba->host = host;
+
+	host->can_queue = clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current;
+
+	/*
+	 * Adjust the number of id's
+	 * Although max_id is an int, target id's are unsined chars
+	 * Do not exceed 255, otherwise the device scan will wrap around
+	 */
+	if (clp[LPFC_CFG_MAX_TARGET].a_current > 255) {
+		lpfc_max_target = 255;
+	} else {
+		lpfc_max_target = clp[LPFC_CFG_MAX_TARGET].a_current;
+	}
+	host->max_id = lpfc_max_target;
+	host->max_lun = clp[ELX_CFG_MAX_LUN].a_current;
+	host->unique_id = instance;
+
+	/* Adapter ID - tell midlayer not to reserve an ID for us */
+	host->this_id = -1;
+
+	/*
+	 * Setup the scsi timeout handler
+	 */
+
+	/*
+	 * timeout value = greater of (2*RATOV, 5)
+	 */
+	timeout = (plhba->fc_ratov << 1) > 5 ? (plhba->fc_ratov << 1) : 5;
+	elx_clk_set(phba, timeout, lpfc_scsi_timeout_handler,
+		    (void *)(unsigned long)timeout, 0);
+
+	/*
+	 * Setup the ip timeout handler
+	 */
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		/*
+		 * timeout value =  LPFC_IP_TOV
+		 */
+		timeout = LPFC_IP_TOV / 2;
+		elx_clk_set(phba, timeout, lpfc_ip_timeout_handler,
+			    (void *)(unsigned long)timeout, 0);
+	}
+
+	/*
+	 * Starting with 2.4.0 kernel, Linux can support commands longer
+	 * than 12 bytes. However, scsi_register() always sets it to 12.
+	 * For it to be useful to the midlayer, we have to set it here.
+	 */
+	host->max_cmd_len = 16;
+
+	/*
+	 * Queue depths per lun
+	 */
+	host->cmd_per_lun = 1;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+	host->select_queue_depths = lpfc_select_queue_depth;
+#endif
+
+	/*
+	 * Save a pointer to device control in host and increment board
+	 */
+	host->hostdata[0] = (unsigned long)phba;
+#if ((LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,4)) && \
+      LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0))
+	scsi_set_pci_device(host, pdev);
+#endif
+#if LINUX_VERSION_CODE > KERNEL_VERSION(2,6,0)
+	pci_set_drvdata(pdev, host);
+	scsi_add_host(host, &pdev->dev);
+	scsi_scan_host(host);
+#endif
+
+	return (0);
+}
+
+int
+lpfc_linux_detach(int instance)
+{
+	elxHBA_t *phba;
+	ELX_SLI_t *psli;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+	unsigned long iflag;
+	LINUX_HBA_t *plxhba;
+	LPFCHBA_t *plhba;
+
+	buf_info = &bufinfo;
+
+	phba = elxDRVR.pHba[instance];
+	if (phba == NULL) {
+		return (0);
+	}
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	psli = &phba->sli;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	scsi_unregister(plxhba->host);
+#else
+	scsi_remove_host(plxhba->host);
+	scsi_host_put(plxhba->host);
+#endif
+
+	ELX_DRVR_LOCK(phba, iflag);
+	elx_sli_hba_down(phba);	/* Bring down the SLI Layer */
+	if (phba->intr_inited) {
+		(psli->sliinit.elx_sli_unregister_intr) ((void *)phba);
+		phba->intr_inited = 0;
+	}
+
+	if (plxhba && plxhba->pcidev) {
+		pci_release_regions(plxhba->pcidev);
+	}
+
+	lpfc_cleanup(phba, 0);
+	lpfc_scsi_free(phba);
+
+	elx_mem_free(phba);
+
+	lpfc_unmemmap(phba);
+
+	if (phba->pHbaOSEnv)
+		elx_kmem_free(phba->pHbaOSEnv, sizeof (LINUX_HBA_t));
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if (plhba->ip_stat)
+		elx_kmem_free(plhba->ip_stat, sizeof (struct lpip_stats));
+
+	if (phba->pHbaProto)
+		elx_kmem_free(phba->pHbaProto, sizeof (LPFCHBA_t));
+	if (phba->config)
+		elx_kmem_free(phba->config, sizeof (lpfc_icfgparam));
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	elx_kmem_free(phba, sizeof (elxHBA_t));
+
+	/* Free memory that managed the HBA dma pool.  This next section
+	 * frees memory linux_kmalloc and linux_kfree used to work. */
+	kfree(elx_mem_dmapool[instance]);
+
+	for (; instance < lpfc_instcnt - 1; instance++) {
+		lpfc_instance[instance] = lpfc_instance[instance + 1];
+		elxDRVR.pHba[instance] = elxDRVR.pHba[instance + 1];
+		elxDRVR.pHba[instance]->brd_no = instance;
+		elx_mem_dmapool[instance] = elx_mem_dmapool[instance + 1];
+	}
+
+	elxDRVR.pHba[instance] = 0;
+	lpfc_instance[instance] = -1;
+
+	lpfc_instcnt--;
+	elxDRVR.num_devs--;
+
+	return (0);
+}
+
+static char lpfc_addrStr[18];
+
+char *
+lpfc_addr_sprintf(register uint8_t * ap)
+{
+	register int i;
+	register char *cp = lpfc_addrStr;
+	static char digits[] = "0123456789abcdef";
+
+	for (i = 0; i < 8; i++) {
+		*cp++ = digits[*ap >> 4];
+		*cp++ = digits[*ap++ & 0xf];
+		*cp++ = ':';
+	}
+	*--cp = 0;
+	return (lpfc_addrStr);
+}
+
+const char *
+lpfc_info(struct Scsi_Host *host)
+{
+	static char buf[4096];
+	elxHBA_t *phba;
+	LINUX_HBA_t *plxhba;
+	LPFCHBA_t *plhba;
+	struct pci_dev *pdev;
+	char *multip;
+	elx_vpd_t *vp;
+	LPFC_NODELIST_t *nlp;
+	int idx, i, j, incr;
+	char hdw[9];
+
+	buf[0] = '\0';
+	phba = (elxHBA_t *) host->hostdata[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	vp = &phba->vpd;
+	if (!phba || !plhba || !plxhba)
+		return buf;
+	pdev = plxhba->pcidev;
+
+	for (idx = 0; idx < MAX_ELX_BRDS; idx++) {
+		if ((phba == elxDRVR.pHba[idx]))
+			break;
+	}
+
+	if (!(phba->hba_flag & FC_FULL_INFO_CALL)) {
+		if (pdev != NULL) {
+			switch (pdev->device) {
+			case PCI_DEVICE_ID_CENTAUR:
+				if (FC_JEDEC_ID(vp->rev.biuRev) ==
+				    CENTAUR_2G_JEDEC_ID) {
+					sprintf(&buf[strlen(buf)],
+						"HBA: Emulex LightPulse LP9002 on PCI bus %02x device %02x irq %d",
+						plxhba->pcidev->bus->number,
+						plxhba->pcidev->devfn,
+						plxhba->pcidev->irq);
+				} else {
+					sprintf(&buf[strlen(buf)],
+						"HBA: Emulex LightPulse LP9000 on PCI bus %02x device %02x irq %d",
+						plxhba->pcidev->bus->number,
+						plxhba->pcidev->devfn,
+						plxhba->pcidev->irq);
+				}
+				break;
+			case PCI_DEVICE_ID_RFLY:
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP952 on PCI bus %02x device %02x irq %d",
+					plxhba->pcidev->bus->number,
+					plxhba->pcidev->devfn,
+					plxhba->pcidev->irq);
+				break;
+			case PCI_DEVICE_ID_DRAGONFLY:
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP8000 on PCI bus %02x device %02x irq %d",
+					plxhba->pcidev->bus->number,
+					plxhba->pcidev->devfn,
+					plxhba->pcidev->irq);
+				break;
+			case PCI_DEVICE_ID_SUPERFLY:
+				if ((vp->rev.biuRev >= 1)
+				    && (vp->rev.biuRev <= 3))
+					sprintf(&buf[strlen(buf)],
+						"HBA: Emulex LightPulse LP7000 on PCI bus %02x device %02x irq %d",
+						plxhba->pcidev->bus->number,
+						plxhba->pcidev->devfn,
+						plxhba->pcidev->irq);
+				else
+					sprintf(&buf[strlen(buf)],
+						"HBA: Emulex LightPulse LP7000E on PCI bus %02x device %02x irq %d",
+						plxhba->pcidev->bus->number,
+						plxhba->pcidev->devfn,
+						plxhba->pcidev->irq);
+				break;
+			case PCI_DEVICE_ID_PEGASUS:
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP9802 on PCI bus %02x device %02x irq %d",
+					plxhba->pcidev->bus->number,
+					plxhba->pcidev->devfn,
+					plxhba->pcidev->irq);
+				break;
+			case PCI_DEVICE_ID_PFLY:
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP982 on PCI bus %02x device %02x irq %d",
+					plxhba->pcidev->bus->number,
+					plxhba->pcidev->devfn,
+					plxhba->pcidev->irq);
+				break;
+			case PCI_DEVICE_ID_THOR:
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP10000 on PCI bus %02x device %02x irq %d",
+					plxhba->pcidev->bus->number,
+					plxhba->pcidev->devfn,
+					plxhba->pcidev->irq);
+				break;
+			case PCI_DEVICE_ID_TFLY:
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP1050 on PCI bus %02x device %02x irq %d",
+					plxhba->pcidev->bus->number,
+					plxhba->pcidev->devfn,
+					plxhba->pcidev->irq);
+				break;
+			default:
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse on PCI bus %02x device %02x irq %d",
+					plxhba->pcidev->bus->number,
+					plxhba->pcidev->devfn,
+					plxhba->pcidev->irq);
+			}
+		}
+		phba->hba_flag |= FC_FULL_INFO_CALL;
+		return (buf);
+	}
+
+	multip = "LPFC";
+
+	sprintf(buf, "Emulex LightPulse %s Driver Version: %s\n",
+		multip, lpfc_release_version);
+
+	if (pdev != NULL) {
+		switch (pdev->device) {
+		case PCI_DEVICE_ID_CENTAUR:
+			if (FC_JEDEC_ID(vp->rev.biuRev) == CENTAUR_2G_JEDEC_ID) {
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP9002 2 Gigabit PCI Fibre Channel Adapter\n");
+			} else {
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP9000 1 Gigabit PCI Fibre Channel Adapter\n");
+			}
+			break;
+		case PCI_DEVICE_ID_RFLY:
+			sprintf(&buf[strlen(buf)],
+				"HBA: Emulex LightPulse LP952 1 Gigabit PCI Fibre Channel Adapter\n");
+			break;
+		case PCI_DEVICE_ID_DRAGONFLY:
+			sprintf(&buf[strlen(buf)],
+				"HBA: Emulex LightPulse LP8000 1 Gigabit PCI Fibre Channel Adapter\n");
+			break;
+		case PCI_DEVICE_ID_SUPERFLY:
+			if ((vp->rev.biuRev >= 1) && (vp->rev.biuRev <= 3))
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP7000 1 Gigabit PCI Fibre Channel Adapter\n");
+			else
+				sprintf(&buf[strlen(buf)],
+					"HBA: Emulex LightPulse LP7000E 1 Gigabit PCI Fibre Channel Adapter\n");
+			break;
+		case PCI_DEVICE_ID_PEGASUS:
+			sprintf(&buf[strlen(buf)],
+				"HBA: Emulex LightPulse LP9802 2 Gigabit PCI Fibre Channel Adapter\n");
+			break;
+		case PCI_DEVICE_ID_PFLY:
+			sprintf(&buf[strlen(buf)],
+				"HBA: Emulex LightPulse LP982 2 Gigabit PCI Fibre Channel Adapter\n");
+			break;
+		case PCI_DEVICE_ID_THOR:
+			sprintf(&buf[strlen(buf)],
+				"HBA: Emulex LightPulse LP10000 2 Gigabit PCI Fibre Channel Adapter\n");
+			break;
+		case PCI_DEVICE_ID_TFLY:
+			sprintf(&buf[strlen(buf)],
+				"HBA: Emulex LightPulse LP1050 2 Gigabit PCI Fibre Channel Adapter\n");
+			break;
+		default:
+			sprintf(&buf[strlen(buf)],
+				"HBA: Emulex LightPulse PCI Fibre Channel Adapter\n");
+		}
+	}
+
+	sprintf(&buf[strlen(buf)], "SerialNum: %s\n", phba->SerialNumber);
+
+	multip = lpfc_decode_firmware_rev(phba);
+	sprintf(&buf[strlen(buf)], "Firmware Version: %s\n", multip);
+
+	sprintf(&buf[strlen(buf)], "Hdw: ");
+	/* Convert JEDEC ID to ascii for hardware version */
+	incr = vp->rev.biuRev;
+	for (i = 0; i < 8; i++) {
+		j = (incr & 0xf);
+		if (j <= 9)
+			hdw[7 - i] = (char)((uint8_t) 0x30 + (uint8_t) j);
+		else
+			hdw[7 - i] =
+			    (char)((uint8_t) 0x61 + (uint8_t) (j - 10));
+		incr = (incr >> 4);
+	}
+	hdw[8] = 0;
+	strcat(buf, hdw);
+
+	sprintf(&buf[strlen(buf)], "\nVendorId: 0x%x\n",
+		((((uint32_t) pdev->device) << 16) | (uint32_t) (pdev->
+								 vendor)));
+
+	sprintf(&buf[strlen(buf)], "Portname: ");
+	strcat(buf, lpfc_addr_sprintf((uint8_t *) & plhba->fc_portname));
+
+	sprintf(&buf[strlen(buf)], "   Nodename: ");
+	strcat(buf, lpfc_addr_sprintf((uint8_t *) & plhba->fc_nodename));
+
+	switch (phba->hba_state) {
+	case ELX_INIT_START:
+	case ELX_INIT_MBX_CMDS:
+	case ELX_LINK_DOWN:
+		sprintf(&buf[strlen(buf)], "\n\nLink Down\n");
+		break;
+	case ELX_LINK_UP:
+	case ELX_LOCAL_CFG_LINK:
+		sprintf(&buf[strlen(buf)], "\n\nLink Up\n");
+		break;
+	case ELX_FLOGI:
+	case ELX_FABRIC_CFG_LINK:
+	case ELX_NS_REG:
+	case ELX_NS_QRY:
+	case ELX_BUILD_DISC_LIST:
+	case ELX_DISC_AUTH:
+	case ELX_CLEAR_LA:
+		sprintf(&buf[strlen(buf)], "\n\nLink Up - Discovery\n");
+		break;
+	case ELX_HBA_READY:
+		sprintf(&buf[strlen(buf)], "\n\nLink Up - Ready:\n");
+		sprintf(&buf[strlen(buf)], "   PortID 0x%x\n", plhba->fc_myDID);
+		if (plhba->fc_topology == TOPOLOGY_LOOP) {
+			if (plhba->fc_flag & FC_PUBLIC_LOOP)
+				sprintf(&buf[strlen(buf)], "   Public Loop\n");
+			else
+				sprintf(&buf[strlen(buf)], "   Private Loop\n");
+		} else {
+			if (plhba->fc_flag & FC_FABRIC)
+				sprintf(&buf[strlen(buf)], "   Fabric\n");
+			else
+				sprintf(&buf[strlen(buf)],
+					"   Point-2-Point\n");
+		}
+
+		if (plhba->fc_linkspeed == LA_2GHZ_LINK)
+			sprintf(&buf[strlen(buf)], "   Current speed 2G\n");
+		else
+			sprintf(&buf[strlen(buf)], "   Current speed 1G\n");
+
+		nlp = plhba->fc_nlpmap_start;
+		while (nlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+			if (nlp->nlp_state == NLP_STE_MAPPED_NODE) {
+				sprintf(&buf[strlen(buf)],
+					"\nlpfc%dt%02x DID %06x WWPN ", idx,
+					FC_SCSID(nlp->nlp_pan, nlp->nlp_sid),
+					nlp->nlp_DID);
+				strcat(buf,
+				       lpfc_addr_sprintf((uint8_t *) & nlp->
+							 nlp_portname));
+				strcat(buf, " WWNN ");
+				strcat(buf,
+				       lpfc_addr_sprintf((uint8_t *) & nlp->
+							 nlp_nodename));
+			}
+			if ((4096 - strlen(buf)) < 90)
+				break;
+			nlp = (LPFC_NODELIST_t *) nlp->nle.nlp_listp_next;
+		}
+		if (nlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)
+			strcat(buf, "\n....\n");
+	}
+
+	return (buf);
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION (2,6,0)
+
+static int
+lpfc_proc_info(struct Scsi_Host *host,
+	       char *buffer, char **start, off_t offset, int count, int rw)
+{
+	/* If rw = 0, then read info
+	 * If rw = 1, then write info (NYI)
+	 */
+	if (rw) {
+		return -EINVAL;
+	} else {
+		return sprintf(buffer, "%s\n", lpfc_info(host));
+	}
+}
+#endif
+
+uint32_t
+lpfc_register_intr(elxHBA_t * arg)
+{
+	elxHBA_t *phba;
+	struct pci_dev *pdev;
+	LINUX_HBA_t *plxhba;
+	unsigned long cflag;
+
+	phba = (elxHBA_t *) arg;
+
+	/*
+	 * Get PCI for this board
+	 */
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	pdev = plxhba->pcidev;
+	if (!pdev)
+		return (1);
+
+	/* ihs->handler is not used here, instead we use our handler to call the
+	   common base handler
+	 */
+	if (request_irq(pdev->irq, lpfc_intr_handler, SA_INTERRUPT | SA_SHIRQ,
+			"lpfcdd", (void *)phba))
+		return (2);
+
+	ELX_CLK_LOCK(cflag);
+	if (lpfc_clkCnt == 0) {
+		/* Clock lock should already be inited */
+		elx_clock_init();
+		/* 
+		 * add our timer routine to kernel's list
+		 */
+		lpfc_sec_clk.expires = (uint32_t) (HZ + jiffies);
+		lpfc_sec_clk.function = lpfc_local_timeout;
+		lpfc_sec_clk.data = (unsigned long)(&elxDRVR.elx_clock_info);
+		init_timer(&lpfc_sec_clk);
+		add_timer(&lpfc_sec_clk);
+	}
+	lpfc_clkCnt++;
+	ELX_CLK_UNLOCK(cflag);
+
+	return (0);
+}
+
+void
+lpfc_unregister_intr(elxHBA_t * phba)
+{
+	struct pci_dev *pdev;
+	LINUX_HBA_t *plxhba;
+	ELX_SLI_t *psli;
+	ELXCLOCK_t *x, *nextx;
+	ELXCLOCK_INFO_t *clock_info;
+	uint32_t ha_copy;
+	unsigned long cflag;
+
+	clock_info = &elxDRVR.elx_clock_info;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	/*
+	 * Get PCI for this board
+	 */
+	pdev = plxhba->pcidev;
+	if (!pdev)
+		return;
+
+	psli = &phba->sli;
+	/* Clear all interrupt enable conditions */
+	(psli->sliinit.elx_sli_write_HC) (phba, 0);
+	/* Clear all pending interrupts */
+	ha_copy = readl(plxhba->HAregaddr);
+	writel(ha_copy, plxhba->HAregaddr);
+
+	free_irq(pdev->irq, phba);
+	phba->intr_inited = 0;
+
+	ELX_CLK_LOCK(cflag);
+	if (lpfc_clkCnt == 1) {
+		del_timer(&lpfc_sec_clk);
+	}
+	lpfc_clkCnt--;
+	/* Go thru clock list a free any timers waiting to expire */
+	x = (ELXCLOCK_t *) clock_info->elx_clkhdr.q_f;
+	while (x != (ELXCLOCK_t *) & clock_info->elx_clkhdr) {
+		nextx = x->cl_fw;
+		if (phba == x->cl_phba) {
+			/* Deque expired clock */
+			elx_deque(x);
+			/* Decrement count of unexpired clocks */
+			clock_info->elx_clkhdr.q_cnt--;
+			elx_mem_put(phba, MEM_CLOCK, (uint8_t *) x);
+		}
+		x = nextx;
+	}
+	ELX_CLK_UNLOCK(cflag);
+	return;
+}
+
+void
+lpfc_local_timeout(unsigned long data)
+{
+	elxHBA_t *phba;
+	LINUX_HBA_t *plxhba;
+	Scsi_Cmnd *cmnd, *next_cmnd;
+	struct Scsi_Host *host;
+	uint32_t i;
+	unsigned long cflag;
+	unsigned long iflag;
+	unsigned long sflag;
+
+	cflag = 0;
+	ELX_CLK_LOCK(cflag);
+	if (lpfc_clkCnt == 0) {
+		del_timer(&lpfc_sec_clk);
+		ELX_CLK_UNLOCK(cflag);
+		return;
+	}
+	lpfc_tmr |= (uint32_t) (1 << smp_processor_id());
+	ELX_CLK_UNLOCK(cflag);
+	elx_timer(0);
+	ELX_CLK_LOCK(cflag);
+	/* Reset the 1 sec tick */
+	lpfc_sec_clk.expires = (uint32_t) (HZ + jiffies);
+	lpfc_sec_clk.function = lpfc_local_timeout;
+	lpfc_sec_clk.data = (unsigned long)(&elxDRVR.elx_clock_info);
+	init_timer(&lpfc_sec_clk);
+	add_timer(&lpfc_sec_clk);
+	ELX_CLK_UNLOCK(cflag);
+
+	for (i = 0; i < lpfc_instcnt; i++) {
+		if (elxDRVR.pHba[i]) {
+			phba = elxDRVR.pHba[i];
+			ELX_DRVR_LOCK(phba, iflag);
+			plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+			host = plxhba->host;
+			/* Flush all done commands for this hba */
+			if (plxhba->iodone.q_first) {
+				cmnd = (Scsi_Cmnd *) plxhba->iodone.q_first;
+				plxhba->iodone.q_first = 0;
+				plxhba->iodone.q_last = 0;
+				plxhba->iodone.q_cnt = 0;
+				while (cmnd) {
+					next_cmnd =
+					    (Scsi_Cmnd *) cmnd->host_scribble;
+					cmnd->host_scribble = 0;
+					ELX_DRVR_UNLOCK(phba, iflag);
+					LPFC_LOCK_SCSI_DONE;
+
+					/* Give this command back to the OS */
+					elx_scsi_add_timer(cmnd,
+							   cmnd->
+							   timeout_per_command);
+					atomic_dec(&plxhba->cmnds_in_flight);
+					cmnd->scsi_done(cmnd);
+
+					LPFC_UNLOCK_SCSI_DONE;
+					ELX_DRVR_LOCK(phba, iflag);
+					cmnd = next_cmnd;
+				}
+			}
+			ELX_DRVR_UNLOCK(phba, iflag);
+		}
+	}
+	lpfc_tmr &= ~((uint32_t) (1 << smp_processor_id()));
+
+	return;
+}
+
+int
+lpfc_reset_bus_handler(Scsi_Cmnd * cmnd)
+{
+	elxHBA_t *phba;
+	ELX_SCSI_BUF_t *elx_cmd;
+	unsigned long iflag;
+	int rc, tgt, lun;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+	/* release io_request_lock */
+	spin_unlock_irq(&io_request_lock);
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+	phba = (elxHBA_t *) cmnd->device->host->hostdata[0];
+	tgt = cmnd->device->id;
+	lun = cmnd->device->lun;
+#else
+	phba = (elxHBA_t *) cmnd->host->hostdata[0];
+	tgt = cmnd->target;
+	lun = cmnd->lun;
+#endif
+	ELX_DRVR_LOCK(phba, iflag);
+
+	rc = 0;
+	if ((elx_cmd = elx_get_scsi_buf(phba))) {
+		rc = lpfc_scsi_hba_reset(phba, elx_cmd);
+		elx_free_scsi_buf(elx_cmd);
+	}
+
+	/* SCSI layer issued Bus Reset */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0714,	/* ptr to msg structure */
+		       elx_mes0714,	/* ptr to msg */
+		       elx_msgBlk0714.msgPreambleStr,	/* begin varargs */
+		       tgt, lun, rc);	/* end varargs */
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+	/* reacquire io_request_lock for midlayer */
+	spin_lock_irq(&io_request_lock);
+#endif
+
+	return (SUCCESS);
+
+}				/* lpfc_reset_bus_handler */
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+void
+lpfc_select_queue_depth(struct Scsi_Host *host, Scsi_Device * scsi_devs)
+{
+	Scsi_Device *device;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) host->hostdata[0];
+	for (device = scsi_devs; device != NULL; device = device->next) {
+		if (device->host == host)
+			lpfc_device_queue_depth(phba, device);
+	}
+}
+#else
+int
+lpfc_slave_configure(Scsi_Device * scsi_devs)
+{
+	elxHBA_t *phba;
+	phba = (elxHBA_t *) scsi_devs->host->hostdata[0];
+	lpfc_device_queue_depth(phba, scsi_devs);
+	return 0;
+}
+#endif
+
+int
+lpfc_device_queue_depth(elxHBA_t * phba, Scsi_Device * device)
+{
+
+	if (device->tagged_supported) {
+#if LINUX_VERSION_CODE 	< KERNEL_VERSION(2,6,0)
+		device->tagged_queue = 1;
+#endif
+		device->current_tag = 0;
+		device->queue_depth = 32;	/* Substitute configuration parameter */
+	} else {
+		device->queue_depth = 16;
+	}
+	return (device->queue_depth);
+}
+
+int
+lpfcdiag_ioctl(struct inode *inode,
+	       struct file *file, unsigned int cmd, unsigned long arg)
+{
+	int rc, fd;
+	elxHBA_t *phba;
+	ELXCMDINPUT_t *ci;
+	unsigned long iflag;
+
+	if (!arg)
+		return (-EINVAL);
+
+	ci = (ELXCMDINPUT_t *) kmalloc(sizeof (ELXCMDINPUT_t), GFP_ATOMIC);
+
+	if (!ci)
+		return (-ENOMEM);
+
+	if (copy_from_user
+	    ((uint8_t *) ci, (uint8_t *) arg, sizeof (ELXCMDINPUT_t))) {
+		kfree(ci);
+		return (-EIO);
+	}
+
+	fd = ci->elx_brd;
+	if (fd >= lpfc_instcnt) {
+		kfree(ci);
+		return (-EINVAL);
+	}
+	if (!(phba = elxDRVR.pHba[fd])) {
+		kfree(ci);
+		return (-EINVAL);
+	}
+
+	/*
+	 * call common base ioctl
+	 */
+	ELX_DRVR_LOCK(phba, iflag);
+	rc = lpfc_diag_ioctl(phba, ci);
+	ELX_DRVR_UNLOCK(phba, iflag);
+	kfree(ci);
+	return (-rc);
+}
+
+int
+lpfcdiag_open(struct inode *inode, struct file *file)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	MOD_INC_USE_COUNT;
+#else
+	if (!try_module_get(THIS_MODULE)) {
+		return (-ENODEV);
+	}
+#endif
+	return (0);
+}
+
+int
+lpfcdiag_release(struct inode *inode, struct file *file)
+{
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	MOD_DEC_USE_COUNT;
+#else
+	module_put(THIS_MODULE);
+#endif
+	return (0);
+}
+
+int
+lpfc_memmap(elxHBA_t * phba)
+{
+	LINUX_HBA_t *plxhba;
+	struct pci_dev *pdev;
+	ELX_SLI_t *psli;
+	int reg;
+	unsigned long base;
+	unsigned long bar0map, bar1map;
+
+	/*
+	 * Get PCI for board
+	 */
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	pdev = plxhba->pcidev;
+	if (!pdev) {
+		return (1);
+	}
+	psli = &phba->sli;
+
+	/* Configure DMA attributes. */
+	if (pci_set_dma_mask(pdev, (uint64_t) 0xffffffffffffffffULL)) {
+		if (pci_set_dma_mask(pdev, (uint64_t) 0xffffffff)) {
+			return (1);
+		}
+	}
+
+	/*
+	 * address in first register
+	 */
+	reg = 0;
+	reg = elx_pci_getadd(pdev, reg, &base);
+
+	/*
+	 * Mask the value to get the physical address
+	 */
+	base &= PCI_BASE_ADDRESS_MEM_MASK;
+	bar0map = base;
+
+	reg = elx_pci_getadd(pdev, reg, &base);
+	base &= PCI_BASE_ADDRESS_MEM_MASK;
+	bar1map = base;
+
+	/* 
+	 * Map adapter SLIM and Control Registers
+	 */
+	plxhba->pci_bar0_map =
+	    elx_remap_pci_mem((unsigned long)bar0map, FF_SLIM_SIZE);
+	if (plxhba->pci_bar0_map == ((void *)(-1))) {
+		return (1);
+	}
+
+	plxhba->pci_bar1_map =
+	    elx_remap_pci_mem((unsigned long)bar1map, FF_REG_AREA_SIZE);
+	if (plxhba->pci_bar1_map == ((void *)(-1))) {
+		elx_unmap_pci_mem((unsigned long)plxhba->pci_bar0_map);
+		return (1);
+	}
+
+	/*
+	 * Setup SLI2 interface
+	 */
+	if (phba->slim2p.virt == 0) {
+		MBUF_INFO_t *buf_info;
+		MBUF_INFO_t bufinfo;
+
+		buf_info = &bufinfo;
+
+		/*
+		 * Allocate memory for SLI-2 structures
+		 */
+		buf_info->size = sizeof (SLI2_SLIM_t);
+
+		buf_info->flags = ELX_MBUF_DMA;
+		buf_info->align = PAGE_SIZE;
+		buf_info->dma_handle = 0;
+		buf_info->data_handle = 0;
+		elx_malloc(phba, buf_info);
+		if (buf_info->virt == NULL) {
+			/*
+			 * unmap adapter SLIM and Control Registers
+			 */
+			elx_unmap_pci_mem((unsigned long)plxhba->pci_bar1_map);
+			elx_unmap_pci_mem((unsigned long)plxhba->pci_bar0_map);
+
+			return (1);
+		}
+
+		phba->slim2p.virt = (uint8_t *) buf_info->virt;
+		phba->slim2p.phys = buf_info->phys;
+		phba->slim2p.data_handle = buf_info->data_handle;
+		phba->slim2p.dma_handle = buf_info->dma_handle;
+		/* The SLIM2 size is stored in the next field */
+		phba->slim2p.next = (void *)(unsigned long)buf_info->size;
+		memset((char *)phba->slim2p.virt, 0, sizeof (SLI2_SLIM_t));
+	}
+	return (0);
+}
+
+int
+lpfc_unmemmap(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	LINUX_HBA_t *plxhba;
+
+	psli = &phba->sli;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	/* 
+	 * unmap adapter SLIM and Control Registers
+	 */
+	elx_unmap_pci_mem((unsigned long)plxhba->pci_bar1_map);
+	elx_unmap_pci_mem((unsigned long)plxhba->pci_bar0_map);
+
+	/*
+	 * Free resources associated with SLI2 interface
+	 */
+	if (phba->slim2p.virt) {
+		MBUF_INFO_t *buf_info;
+		MBUF_INFO_t bufinfo;
+
+		buf_info = &bufinfo;
+		buf_info->phys = phba->slim2p.phys;
+		buf_info->data_handle = phba->slim2p.data_handle;
+		buf_info->dma_handle = phba->slim2p.dma_handle;
+		buf_info->flags = ELX_MBUF_DMA;
+
+		buf_info->virt = (uint32_t *) phba->slim2p.virt;
+		buf_info->size = (uint32_t) (unsigned long)phba->slim2p.next;
+		elx_free(phba, buf_info);
+	}
+	return (0);
+}
+
+int
+lpfc_pcimap(elxHBA_t * phba)
+{
+	LINUX_HBA_t *plxhba;
+	struct pci_dev *pdev;
+	uint16_t cmd;
+
+	/*
+	 * PCI for board
+	 */
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	pdev = plxhba->pcidev;
+	if (!pdev)
+		return (1);
+
+	/*
+	 * bus mastering and parity checking enabled
+	 */
+	pci_read_config_word(pdev, PCI_COMMAND, &cmd);
+	if (cmd & CMD_PARITY_CHK)
+		cmd = CMD_CFG_VALUE;
+	else
+		cmd = (CMD_CFG_VALUE & ~(CMD_PARITY_CHK));
+
+	pci_write_config_word(pdev, PCI_COMMAND, cmd);
+
+	if (lpfc_pci_latency_clocks)
+		pci_write_config_byte(pdev, PCI_LATENCY_TMR_REGISTER,
+				      (uint8_t) lpfc_pci_latency_clocks);
+
+	if (lpfc_pci_cache_line)
+		pci_write_config_byte(pdev, PCI_CACHE_LINE_REGISTER,
+				      (uint8_t) lpfc_pci_cache_line);
+
+	/*
+	 * Get the irq from the pdev structure
+	 */
+	phba->bus_intr_lvl = (int)pdev->irq;
+
+	return (0);
+}
+
+void
+lpfc_setup_slim_access(elxHBA_t * arg)
+{
+	LINUX_HBA_t *plxhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	plxhba->MBslimaddr = plxhba->pci_bar0_map;
+	plxhba->HAregaddr = (uint32_t *) (plxhba->pci_bar1_map) + HA_REG_OFFSET;
+	plxhba->HCregaddr = (uint32_t *) (plxhba->pci_bar1_map) + HC_REG_OFFSET;
+	plxhba->CAregaddr = (uint32_t *) (plxhba->pci_bar1_map) + CA_REG_OFFSET;
+	plxhba->HSregaddr = (uint32_t *) (plxhba->pci_bar1_map) + HS_REG_OFFSET;
+	return;
+}
+
+uint32_t
+lpfc_read_HA(elxHBA_t * arg)
+{
+	uint32_t status;
+	LINUX_HBA_t *plxhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	status = readl(plxhba->HAregaddr);
+	return (status);
+}
+
+uint32_t
+lpfc_read_CA(elxHBA_t * arg)
+{
+	uint32_t status;
+	LINUX_HBA_t *plxhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	status = readl(plxhba->CAregaddr);
+	return (status);
+}
+
+uint32_t
+lpfc_read_hbaregs_plus_offset(elxHBA_t * arg, uint32_t offset)
+{
+	uint32_t status;
+	LINUX_HBA_t *plxhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	status = readl((plxhba->pci_bar1_map) + offset);
+	return (status);
+}
+
+uint32_t
+lpfc_read_HS(elxHBA_t * arg)
+{
+	uint32_t status;
+	LINUX_HBA_t *plxhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	status = readl(plxhba->HSregaddr);
+	return (status);
+}
+
+uint32_t
+lpfc_read_HC(elxHBA_t * arg)
+{
+	uint32_t status;
+	LINUX_HBA_t *plxhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	status = readl(plxhba->HCregaddr);
+	return (status);
+}
+
+void
+lpfc_write_HA(elxHBA_t * phba, uint32_t value)
+{
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	writel(value, plxhba->HAregaddr);
+	return;
+}
+
+void
+lpfc_write_CA(elxHBA_t * phba, uint32_t value)
+{
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	writel(value, plxhba->CAregaddr);
+	return;
+}
+
+void
+lpfc_write_hbaregs_plus_offset(elxHBA_t * arg, uint32_t offset, uint32_t value)
+{
+	LINUX_HBA_t *plxhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	writel(value, (plxhba->pci_bar1_map) + offset);
+}
+
+void
+lpfc_write_HS(elxHBA_t * phba, uint32_t value)
+{
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	writel(value, plxhba->HSregaddr);
+	return;
+}
+
+void
+lpfc_write_HC(elxHBA_t * phba, uint32_t value)
+{
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	writel(value, plxhba->HCregaddr);
+	return;
+}
+
+uint32_t
+lpfc_intr_prep(elxHBA_t * phba)
+{
+	LINUX_HBA_t *plxhba;
+	ELX_SLI_t *psli;
+	uint32_t ha_copy;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	/* Ignore all interrupts during initialization. */
+	if (phba->hba_state < ELX_LINK_DOWN) {
+		return (0);
+	}
+
+	psli = &phba->sli;
+	/* Read host attention register to determine interrupt source */
+	ha_copy = readl(plxhba->HAregaddr);
+
+	/* Clear Attention Sources, except ERATT (to preserve status) & LATT
+	 *    (ha_copy & ~(HA_ERATT | HA_LATT));
+	 */
+	writel((ha_copy & ~(HA_LATT | HA_ERATT)), plxhba->HAregaddr);
+	return (ha_copy);
+}				/* lpfc_intr_prep */
+
+void
+lpfc_intr_post(elxHBA_t * arg)
+{
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	return;
+}
+
+int
+lpfc_ValidLun(ELXSCSITARGET_t * targetp, uint64_t lun)
+{
+	uint32_t rptLunLen;
+	uint32_t *datap32;
+	uint32_t lunvalue, i;
+
+	if (targetp->rptLunState != REPORT_LUN_COMPLETE) {
+		return 1;
+	}
+
+	if (targetp->RptLunData) {
+		datap32 = (uint32_t *) targetp->RptLunData->virt;
+		rptLunLen = SWAP_DATA(*datap32);
+		for (i = 0; i < rptLunLen; i += 8) {
+			datap32 += 2;
+			lunvalue = (((*datap32) >> FC_LUN_SHIFT) & 0xff);
+			if (lunvalue == (uint32_t) lun)
+				return 1;
+		}
+		return 0;
+	} else {
+		return 1;
+	}
+}
+
+void
+lpfc_write_slim(elxHBA_t * phba, uint8_t * ptr, int offset, int cnt)
+{
+	LINUX_HBA_t *plxhba;
+	uint32_t *slimp;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	slimp = (uint32_t *) (((uint8_t *) plxhba->MBslimaddr) + offset);
+
+	/* Write cnt bytes to SLIM address pointed to by slimp */
+	elx_write_toio((uint32_t *) ptr, slimp, cnt);
+	return;
+}
+
+void
+lpfc_read_slim(elxHBA_t * phba, uint8_t * ptr, int offset, int cnt)
+{
+	uint32_t *slimp;
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	slimp = (uint32_t *) (((uint8_t *) plxhba->MBslimaddr) + offset);
+
+	/* Read cnt bytes from SLIM address pointed to by slimp */
+	elx_read_fromio(slimp, (uint32_t *) ptr, cnt);
+	return;
+}
+
+void
+elx_nodev_unsol_event(elxHBA_t * phba,
+		      ELX_SLI_RING_t * pring, ELX_IOCBQ_t * piocbq)
+{
+	return;
+}
+
+void
+lpfc_sli_brdreset(elxHBA_t * arg)
+{
+	LPFCHBA_t *plhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) arg;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plhba->fc_eventTag = 0;
+	plhba->fc_myDID = 0;
+	plhba->fc_prevDID = 0;
+	plhba->power_up = 0;	/* Pegasus */
+}
+
+int
+lpfc_sli_setup(elxHBA_t * phba)
+{
+	int i, totiocb;
+	ELX_SLI_t *psli;
+	ELX_RING_INIT_t *pring;
+	elxCfgParam_t *clp;
+
+	psli = &phba->sli;
+	psli->sliinit.num_rings = MAX_CONFIGURED_RINGS;
+	psli->fcp_ring = LPFC_FCP_RING;
+	psli->next_ring = LPFC_FCP_NEXT_RING;
+	psli->ip_ring = LPFC_IP_RING;
+
+	clp = &phba->config[0];
+
+	totiocb = 0;
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		pring = &psli->sliinit.ringinit[i];
+		switch (i) {
+		case LPFC_ELS_RING:	/* ring 0 - ELS / CT */
+			/* numCiocb and numRiocb are used in config_port */
+			pring->numCiocb = SLI2_IOCB_CMD_R0_ENTRIES;
+			pring->numRiocb = SLI2_IOCB_RSP_R0_ENTRIES;
+			pring->fast_iotag = 0;
+			pring->iotag_ctr = 0;
+			pring->iotag_max = 4096;
+			pring->num_mask = 4;
+			pring->prt[0].profile = 0;	/* Mask 0 */
+			pring->prt[0].rctl = FC_ELS_REQ;
+			pring->prt[0].type = FC_ELS_DATA;
+			pring->prt[0].elx_sli_rcv_unsol_event =
+			    lpfc_els_unsol_event;
+			pring->prt[1].profile = 0;	/* Mask 1 */
+			pring->prt[1].rctl = FC_ELS_RSP;
+			pring->prt[1].type = FC_ELS_DATA;
+			pring->prt[1].elx_sli_rcv_unsol_event =
+			    lpfc_els_unsol_event;
+			pring->prt[2].profile = 0;	/* Mask 2 */
+			pring->prt[2].rctl = FC_UNSOL_CTL;	/* NameServer Inquiry */
+			pring->prt[2].type = FC_COMMON_TRANSPORT_ULP;	/* NameServer */
+			pring->prt[2].elx_sli_rcv_unsol_event =
+			    lpfc_ct_unsol_event;
+			pring->prt[3].profile = 0;	/* Mask 3 */
+			pring->prt[3].rctl = FC_SOL_CTL;	/* NameServer response */
+			pring->prt[3].type = FC_COMMON_TRANSPORT_ULP;	/* NameServer */
+			pring->prt[3].elx_sli_rcv_unsol_event =
+			    lpfc_ct_unsol_event;
+			break;
+		case LPFC_IP_RING:	/* ring 1 - IP */
+			/* numCiocb and numRiocb are used in config_port */
+			pring->numCiocb = SLI2_IOCB_CMD_R1_ENTRIES;
+			pring->numRiocb = SLI2_IOCB_CMD_R1_ENTRIES;
+			if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+				pring->numCiocb += SLI2_IOCB_CMD_R1XTRA_ENTRIES;
+				pring->numRiocb += SLI2_IOCB_CMD_R1XTRA_ENTRIES;
+			}
+			pring->iotag_ctr = 0;
+			pring->iotag_max = clp[LPFC_CFG_XMT_Q_SIZE].a_current;
+			pring->fast_iotag = 0;
+			pring->num_mask = 1;
+			pring->prt[0].profile = 0;	/* Mask 0 */
+			pring->prt[0].rctl = FC_UNSOL_DATA;	/* Unsolicited Data */
+			if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+				pring->prt[0].type = FC_LLC_SNAP;	/* LLC/SNAP */
+			} else {
+				pring->prt[0].type = 0;
+			}
+			pring->prt[0].elx_sli_rcv_unsol_event =
+			    lpfc_ip_unsol_event;
+			break;
+		case LPFC_FCP_RING:	/* ring 2 - FCP */
+			/* numCiocb and numRiocb are used in config_port */
+			pring->numCiocb = SLI2_IOCB_CMD_R2_ENTRIES;
+			pring->numRiocb = SLI2_IOCB_CMD_R2_ENTRIES;
+			if (clp[LPFC_CFG_NETWORK_ON].a_current == 0) {
+				pring->numCiocb += SLI2_IOCB_CMD_R1XTRA_ENTRIES;
+				pring->numRiocb += SLI2_IOCB_CMD_R1XTRA_ENTRIES;
+			}
+			pring->numCiocb += SLI2_IOCB_CMD_R3XTRA_ENTRIES;
+			pring->numRiocb += SLI2_IOCB_CMD_R3XTRA_ENTRIES;
+			pring->iotag_ctr = 0;
+			pring->iotag_max =
+			    (clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current * 2);
+			pring->fast_iotag = pring->iotag_max;
+			pring->num_mask = 0;
+			break;
+		case LPFC_FCP_NEXT_RING:
+			/* numCiocb and numRiocb are used in config_port */
+			pring->numCiocb = SLI2_IOCB_CMD_R3_ENTRIES;
+			pring->numRiocb = SLI2_IOCB_CMD_R3_ENTRIES;
+			pring->fast_iotag = 0;
+			pring->iotag_ctr = 0;
+			pring->iotag_max = 4096;
+			pring->num_mask = 0;
+			pring->prt[0].profile = 0;	/* Mask 0 */
+			pring->prt[0].rctl = FC_FCP_CMND;
+			pring->prt[0].type = FC_FCP_DATA;
+			pring->prt[0].elx_sli_rcv_unsol_event =
+			    elx_nodev_unsol_event;
+			break;
+		}
+		totiocb += (pring->numCiocb + pring->numRiocb);
+	}
+	if (totiocb > MAX_SLI2_IOCB) {
+		/* Too many cmd / rsp ring entries in SLI2 SLIM */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0462,	/* ptr to msg structure */
+			       elx_mes0462,	/* ptr to msg */
+			       elx_msgBlk0462.msgPreambleStr,	/* begin varargs */
+			       totiocb, MAX_SLI2_IOCB);	/* end varargs */
+	}
+	psli->sliinit.elx_sli_handle_eratt = lpfc_handle_eratt;
+	psli->sliinit.elx_sli_handle_latt = lpfc_handle_latt;
+	psli->sliinit.elx_sli_intr_post = lpfc_intr_post;
+	psli->sliinit.elx_sli_intr_prep = lpfc_intr_prep;
+	psli->sliinit.elx_sli_read_pci = elx_read_pci;
+	psli->sliinit.elx_sli_read_pci_cmd = elx_read_pci_cmd;
+	psli->sliinit.elx_sli_write_pci_cmd = elx_write_pci_cmd;
+	psli->sliinit.elx_sli_read_slim = lpfc_read_slim;
+	psli->sliinit.elx_sli_write_slim = lpfc_write_slim;
+	psli->sliinit.elx_sli_config_port_prep = lpfc_config_port_prep;
+	psli->sliinit.elx_sli_config_port_post = lpfc_config_port_post;
+	psli->sliinit.elx_sli_config_pcb_setup = lpfc_config_pcb_setup;
+	psli->sliinit.elx_sli_write_HA = lpfc_write_HA;
+	psli->sliinit.elx_sli_write_CA = lpfc_write_CA;
+	psli->sliinit.elx_sli_write_HS = lpfc_write_HS;
+	psli->sliinit.elx_sli_write_HC = lpfc_write_HC;
+	psli->sliinit.elx_sli_read_HA = lpfc_read_HA;
+	psli->sliinit.elx_sli_read_CA = lpfc_read_CA;
+	psli->sliinit.elx_sli_read_HS = lpfc_read_HS;
+	psli->sliinit.elx_sli_read_HC = lpfc_read_HC;
+	psli->sliinit.elx_sli_setup_slim_access = lpfc_setup_slim_access;
+	psli->sliinit.elx_sli_register_intr = lpfc_register_intr;
+	psli->sliinit.elx_sli_unregister_intr = lpfc_unregister_intr;
+	psli->sliinit.elx_sli_brdreset = lpfc_sli_brdreset;
+	psli->sliinit.elx_sli_hba_down_prep = lpfc_hba_down_prep;
+#ifdef powerpc
+	psli->sliinit.sli_flag = ELX_HGP_HOSTSLIM;
+#else
+	psli->sliinit.sli_flag = 0;
+#endif
+	return (0);
+}
+
+int
+lpfc_mem_poolinit(elxHBA_t * phba)
+{
+	MEMSEG_t *mp;
+	elxCfgParam_t *clp;
+
+	clp = &phba->config[0];
+	/* Initialize xmit/receive buffer structure */
+	/* Three buffers per response entry will initially be posted to ELS ring */
+	/* Pool 0: MEM_BUF is same pool as MEM_BPL */
+	mp = &phba->memseg[MEM_BUF];
+	mp->elx_memflag = ELX_MEM_DMA | ELX_MEM_GETMORE;
+	mp->elx_memsize = 1024;
+	mp->mem_hdr.q_max = MAX_SLI2_IOCB;
+	mp->elx_lowmem = 0;
+	mp->elx_himem = 0;
+
+	/* Pool 1: MEM_MBOX */
+	/* Initialize mailbox cmd buffer structure */
+	mp = &phba->memseg[MEM_MBOX];
+	mp->elx_memflag = ELX_MEM_GETMORE | ELX_MEM_BOUND;
+	mp->elx_memsize = sizeof (ELX_MBOXQ_t);
+	mp->mem_hdr.q_max = lpfc_discovery_threads + 8;
+	mp->elx_lowmem = 8;
+	mp->elx_himem = LPFC_MAX_DISC_THREADS;
+
+	/* Pool 2: MEM_IOCB */
+	/* Initialize iocb buffer structure */
+	mp = &phba->memseg[MEM_IOCB];
+	mp->elx_memsize = sizeof (ELX_IOCBQ_t);
+	mp->elx_memflag = ELX_MEM_GETMORE | ELX_MEM_BOUND;
+	mp->mem_hdr.q_max = (uint16_t) clp[ELX_CFG_NUM_IOCBS].a_current;
+	mp->elx_lowmem = (2 * lpfc_discovery_threads) + 8;
+	mp->elx_himem = LPFC_MAX_NUM_IOCBS;
+
+	/* Pool 3: MEM_CLOCK */
+	/* Initialize clock buffer structure */
+	mp = &phba->memseg[MEM_CLOCK];
+	mp->elx_memflag = ELX_MEM_GETMORE;
+	mp->elx_memsize = sizeof (ELXCLOCK_t);
+	mp->mem_hdr.q_max = 64;
+	mp->elx_lowmem = 0;
+	mp->elx_himem = 0;
+
+	/* Pool 4: MEM_SCSI_BUF */
+	/* Initialize SCSI buffer structure */
+	mp = &phba->memseg[MEM_SCSI_BUF];
+	mp->elx_memflag = ELX_MEM_GETMORE | ELX_MEM_BOUND;
+	mp->elx_memsize = sizeof (ELX_SCSI_BUF_t);
+	mp->mem_hdr.q_max = clp[ELX_CFG_NUM_BUFS].a_current;
+	mp->elx_lowmem = 0;
+	mp->elx_himem = LPFC_MAX_NUM_BUFS;
+
+	/* Pool 5: MEM_FCP_CMND_BUF */
+	/* Initialize FCP_CMND buffer structure */
+	mp = &phba->memseg[MEM_FCP_CMND_BUF];
+	mp->elx_memflag = ELX_MEM_DMA;
+	mp->elx_memsize = sizeof (FCP_CMND);
+	mp->mem_hdr.q_max = 0;
+	mp->elx_lowmem = 0;
+	mp->elx_himem = 0;
+
+	/* Pool 6: MEM_NLP */
+	/* Initialize nodelist buffer structure */
+	mp = &phba->memseg[MEM_NLP];
+	mp->elx_memflag = ELX_MEM_GETMORE;
+	mp->elx_memsize = sizeof (LPFC_NODELIST_t);
+	mp->mem_hdr.q_max = lpfc_num_nodes;
+	mp->elx_lowmem = 0;
+	mp->elx_himem = 0;
+
+	/* Pool 7: MEM_BIND */
+	/* Initialize bindlist buffer structure */
+	mp = &phba->memseg[MEM_BIND];
+	mp->elx_memflag = ELX_MEM_GETMORE;
+	mp->elx_memsize = sizeof (LPFC_BINDLIST_t);
+	mp->mem_hdr.q_max = 16;
+	mp->elx_lowmem = 0;
+	mp->elx_himem = 0;
+
+	/* Pool 8: MEM_IP_BUF */
+	/* Initialize IP buffer structure */
+	mp = &phba->memseg[MEM_IP_BUF];
+	mp->elx_memflag = ELX_MEM_GETMORE;
+	mp->elx_memsize = sizeof (LPFC_IP_BUF_t);
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		mp->mem_hdr.q_max = 64;
+	} else {
+		mp->mem_hdr.q_max = 0;
+	}
+	mp->elx_lowmem = 0;
+	mp->elx_himem = 0;
+
+	/* Pool 9: MEM_IP_RCV_BUF */
+	/* Initialize IP rcv buffer structure */
+	mp = &phba->memseg[MEM_IP_RCV_BUF];
+	mp->elx_memflag =
+	    ELX_MEM_GETMORE | ELX_MEM_ATTACH_IPBUF | ELX_MEM_BOUND;
+	mp->elx_memsize = LPFC_IP_RCV_BUF_SIZE;
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		mp->mem_hdr.q_max = clp[LPFC_CFG_POST_IP_BUF].a_current;
+	} else {
+		mp->mem_hdr.q_max = 0;
+	}
+	mp->elx_lowmem = 0;
+	mp->elx_himem = LPFC_MAX_POST_IP_BUF;
+
+	/* Pool 10: MEM_IP_MAP */
+	/* Initialize IP Network Buffer to physical address or dma handle mapping pool. */
+	mp = &phba->memseg[MEM_IP_MAP];
+	mp->elx_memflag = ELX_MEM_GETMORE;
+	mp->elx_memsize = sizeof (ELX_PHYS_NET_MAP_t);
+	mp->mem_hdr.q_max = 64;
+	mp->elx_lowmem = 0;
+
+	/* Pool 11: MEM_SCSI_DMA_EXT */
+	/* Init SCSI DMA ext structure, using same counts as Pool 4: MEM_SCSI_BUF */
+	mp = &phba->memseg[MEM_SCSI_DMA_EXT];
+	mp->elx_memflag = ELX_MEM_DMA | ELX_MEM_GETMORE | ELX_MEM_BOUND;
+	mp->elx_memsize = 1024;
+	mp->mem_hdr.q_max = clp[ELX_CFG_NUM_BUFS].a_current;
+	mp->elx_lowmem = 0;
+	mp->elx_himem = LPFC_MAX_NUM_BUFS;
+
+	/* Pool 12: MEM_IP_DMA_EXT */
+	/* Initialize IP DMA ext structure, using same counts as Pool 8: MEM_IP_BUF */
+	mp = &phba->memseg[MEM_IP_DMA_EXT];
+	mp->elx_memflag = ELX_MEM_DMA | ELX_MEM_GETMORE;
+	mp->elx_memsize = 1024;
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		mp->mem_hdr.q_max = 64;
+	} else {
+		mp->mem_hdr.q_max = 0;
+	}
+	mp->elx_lowmem = 0;
+	mp->elx_himem = 0;
+
+	return (0);
+}
+
+irqreturn_t
+lpfc_intr_handler(int irq, void *dev_id, struct pt_regs * regs)
+{
+	elxHBA_t *phba;
+	LINUX_HBA_t *plxhba;
+	Scsi_Cmnd *cmnd;
+	Scsi_Cmnd *next_cmnd;
+	struct Scsi_Host *host;
+	int i;
+	unsigned long iflag;
+	unsigned long sflag;
+
+	/* Sanity check dev_id parameter */
+	phba = (elxHBA_t *) dev_id;
+	if (!phba) {
+		return IRQ_NONE;
+	}
+
+	/* More sanity checks on dev_id parameter.
+	 * We have seen our interrupt service routine being called
+	 * with the dev_id of another PCI card in the system.
+	 * Here we verify the dev_id is really ours!
+	 */
+	for (i = 0; i < lpfc_instcnt; i++) {
+		if (elxDRVR.pHba[i] == phba) {
+			break;
+		}
+	}
+	if (i == lpfc_instcnt) {
+		return IRQ_NONE;
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	lpfc_isr |= (uint32_t) (1 << smp_processor_id());
+
+	/* Call SLI Layer to process interrupt */
+	elx_sli_intr(phba);
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	host = plxhba->host;
+	/* Flush all done commands */
+	if (plxhba->iodone.q_first) {
+		cmnd = (Scsi_Cmnd *) plxhba->iodone.q_first;
+		plxhba->iodone.q_first = 0;
+		plxhba->iodone.q_last = 0;
+		plxhba->iodone.q_cnt = 0;
+		while (cmnd) {
+			next_cmnd = (Scsi_Cmnd *) cmnd->host_scribble;
+			cmnd->host_scribble = 0;
+			ELX_DRVR_UNLOCK(phba, iflag);
+			LPFC_LOCK_SCSI_DONE;
+
+			/* Give this command back to the OS */
+			elx_scsi_add_timer(cmnd, cmnd->timeout_per_command);
+			atomic_dec(&plxhba->cmnds_in_flight);
+			cmnd->scsi_done(cmnd);
+
+			LPFC_UNLOCK_SCSI_DONE;
+			ELX_DRVR_LOCK(phba, iflag);
+			cmnd = next_cmnd;
+		}
+	}
+
+	lpfc_isr &= ~((uint32_t) (1 << smp_processor_id()));
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	return IRQ_HANDLED;
+}				/* lpfc_intr_handler */
+
+int
+lpfc_bind_setup(elxHBA_t * phba)
+{
+	elxCfgParam_t *clp;
+	char **arrayp = 0;
+	LPFCHBA_t *plhba;
+	u_int cnt = 0;
+
+	/* 
+	 * Check if there are any WWNN / scsid bindings
+	 */
+	clp = &phba->config[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	lpfc_get_bind_type(phba);
+
+	switch (plhba->fcp_mapping) {
+	case FCP_SEED_WWNN:
+		arrayp = lpfc_fcp_bind_WWNN;
+		cnt = 0;
+		while (arrayp[cnt] != 0)
+			cnt++;
+		if (cnt && (*arrayp != 0)) {
+			lpfc_bind_wwnn(phba, arrayp, cnt);
+		}
+		break;
+
+	case FCP_SEED_WWPN:
+		arrayp = lpfc_fcp_bind_WWPN;
+		cnt = 0;
+		while (arrayp[cnt] != 0)
+			cnt++;
+		if (cnt && (*arrayp != 0)) {
+			lpfc_bind_wwpn(phba, arrayp, cnt);
+		}
+		break;
+
+	case FCP_SEED_DID:
+		if (clp[LPFC_CFG_BINDMETHOD].a_current != 4) {
+			arrayp = lpfc_fcp_bind_DID;
+			cnt = 0;
+			while (arrayp[cnt] != 0)
+				cnt++;
+			if (cnt && (*arrayp != 0)) {
+				lpfc_bind_did(phba, arrayp, cnt);
+			}
+		}
+		break;
+	}
+
+	if (cnt && (*arrayp != 0) && (clp[LPFC_CFG_BINDMETHOD].a_current == 4)) {
+		/* Using ALPA map with Persistent binding - ignoring ALPA map */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0411,	/* ptr to msg structure */
+			       elx_mes0411,	/* ptr to msg */
+			       elx_msgBlk0411.msgPreambleStr,	/* begin varargs */
+			       clp[LPFC_CFG_BINDMETHOD].a_current, plhba->fcp_mapping);	/* end varargs */
+	}
+
+	if (clp[LPFC_CFG_SCAN_DOWN].a_current > 1) {
+		/* Scan-down is out of range - ignoring scan-down */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0412,	/* ptr to msg structure */
+			       elx_mes0412,	/* ptr to msg */
+			       elx_msgBlk0412.msgPreambleStr,	/* begin varargs */
+			       clp[LPFC_CFG_BINDMETHOD].a_current, plhba->fcp_mapping);	/* end varargs */
+		clp[LPFC_CFG_SCAN_DOWN].a_current = 0;
+	}
+	return (0);
+}
+
+/******************************************************************************
+* Function name : lpfc_config_setup
+*
+* Description   : Called from attach to setup configuration parameters for 
+*                 adapter 
+*                 The goal of this routine is to fill in all the a_current 
+*                 members of the CfgParam structure for all configuration 
+*                 parameters.
+* Example:
+* clp[LPFC_CFG_XXX].a_current = (uint32_t)value;
+* value might be a define, a global variable, clp[LPFC_CFG_XXX].a_default,
+* or some other enviroment specific way of initializing config parameters.
+******************************************************************************/
+MODULE_PARM(targetenable, "i");
+int targetenable = 1;
+
+int
+lpfc_config_setup(elxHBA_t * phba)
+{
+	elxCfgParam_t *clp;
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	int i;
+	int brd;
+
+	clp = &phba->config[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	brd = phba->brd_no;
+
+	/*
+	 * Read the configuration parameters. Also set to default if
+	 * parameter value is out of allowed range.
+	 */
+	for (i = 0; i < LPFC_TOTAL_NUM_OF_CFG_PARAM; i++) {
+		clp[i].a_current =
+		    (uint32_t) ((ulong) fc_get_cfg_param(brd, i));
+
+		if (i == ELX_CFG_DFT_HBA_Q_DEPTH || i == ELX_CFG_LOG_ONLY
+		    || i == ELX_CFG_FIRST_CHECK)
+			continue;
+
+		if ((clp[i].a_current >= clp[i].a_low) &&
+		    (clp[i].a_current <= clp[i].a_hi)) {
+			/* we continue if the range check is satisfied
+			 * however LPFC_CFG_TOPOLOGY has holes and both
+			 * LPFC_CFG_FCP_CLASS AND LPFC_CFG_IP_CLASS need
+			 * to readjusted iff they satisfy the range check
+			 */
+			if (i == LPFC_CFG_TOPOLOGY) {
+				if (!(clp[i].a_current & 1))	/* odd values 1,3,5 are out */
+					continue;
+			} else if ((i == LPFC_CFG_FCP_CLASS)
+				   || (i == LPFC_CFG_IP_CLASS)) {
+				switch (clp[i].a_current) {
+				case 2:
+					clp[i].a_current = CLASS2;	/* CLASS2 = 1 */
+					break;
+				case 3:
+					clp[i].a_current = CLASS3;	/* CLASS3 = 2 */
+					break;
+				}
+				continue;
+			} else
+				continue;
+		}
+
+		/* The cr_count feature is disabled if cr_delay is set to 0.
+		 * So do not bother user with messages about cr_count if cr_delay is 0 */
+		if (i == LPFC_CFG_CR_COUNT)
+			if (clp[LPFC_CFG_CR_DELAY].a_current == 0)
+				continue;
+
+		elx_printf_log(phba->brd_no, &elx_msgBlk0413,	/* ptr to msg structure */
+			       elx_mes0413,	/* ptr to msg */
+			       elx_msgBlk0413.msgPreambleStr,	/* begin varargs */
+			       clp[i].a_string, clp[i].a_low, clp[i].a_hi, clp[i].a_default);	/* end varargs */
+
+		clp[i].a_current = clp[i].a_default;
+
+	}
+
+	switch (((SWAP_LONG(phba->pci_id)) >> 16) & 0xffff) {
+	case PCI_DEVICE_ID_LP101:
+		clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current = LPFC_LP101_HBA_Q_DEPTH;
+		break;
+	default:
+		clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current = LPFC_DFT_HBA_Q_DEPTH;
+	}
+	if (clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current <
+	    clp[ELX_CFG_NUM_BUFS].a_current) {
+		/* HBA QUEUE DEPTH should be atleast as high as the NUM BUFS */
+		clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current =
+		    clp[ELX_CFG_NUM_BUFS].a_current;
+	}
+	if (clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current > LPFC_MAX_HBA_Q_DEPTH) {
+		clp[ELX_CFG_DFT_HBA_Q_DEPTH].a_current = LPFC_MAX_HBA_Q_DEPTH;
+	}
+
+	phba->sli.ring[LPFC_IP_RING].txq.q_max =
+	    clp[LPFC_CFG_XMT_Q_SIZE].a_current;
+
+	plhba->lpfn_max_mtu = lpfc_mtu;
+	if ((lpfc_rcv_buff_size % PAGE_SIZE) == 0)
+		plhba->lpfn_rcv_buf_size = lpfc_rcv_buff_size;
+	else {
+		plhba->lpfn_rcv_buf_size =
+		    ((lpfc_rcv_buff_size + PAGE_SIZE) & (PAGE_MASK));
+
+		plhba->lpfn_rcv_buf_size -= 16;
+	}
+
+	return (0);
+}
+
+int
+lpfc_bind_wwpn(elxHBA_t * phba, char **arrayp, u_int cnt)
+{
+	uint8_t *datap, *np;
+	LPFC_BINDLIST_t *blp;
+	LPFCHBA_t *plhba;
+	NAME_TYPE pn;
+	int i, entry, lpfc_num, rstatus;
+	unsigned int sum;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plhba->fcp_mapping = FCP_SEED_WWPN;
+	np = (uint8_t *) & pn;
+
+	for (entry = 0; entry < cnt; entry++) {
+		datap = (uint8_t *) arrayp[entry];
+		if (datap == 0)
+			break;
+		/* Determined the number of ASC hex chars in WWNN & WWPN */
+		for (i = 0; i < FC_MAX_WW_NN_PN_STRING; i++) {
+			if (elx_str_ctox(datap[i]) < 0)
+				break;
+		}
+		if ((rstatus = lpfc_parse_binding_entry(phba, datap, np,
+							i, sizeof (NAME_TYPE),
+							LPFC_BIND_WW_NN_PN,
+							&sum, entry,
+							&lpfc_num)) > 0) {
+			if (rstatus == LPFC_SYNTAX_OK_BUT_NOT_THIS_BRD)
+				continue;
+
+			/* For syntax error code definitions see LPFC_SYNTAX_ERR_ defines. */
+			/* WWPN binding entry <num>: Syntax error code <code> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0430,	/* ptr to msg structure */
+				       elx_mes0430,	/* ptr to msg */
+				       elx_msgBlk0430.msgPreambleStr,	/* begin varargs */
+				       entry, rstatus);	/* end varargs */
+			goto out;
+		}
+
+		/* Loop through all BINDLIST entries and find
+		 * the next available entry.
+		 */
+		if ((blp =
+		     (LPFC_BINDLIST_t *) elx_mem_get(phba, MEM_BIND)) == NULL) {
+			/* WWPN binding entry: node table full */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0432,	/* ptr to msg structure */
+				       elx_mes0432,	/* ptr to msg */
+				       elx_msgBlk0432.msgPreambleStr);	/* begin & end varargs */
+			goto out;
+		}
+		memset((void *)blp, 0, sizeof (LPFC_BINDLIST_t));
+		blp->nlp_bind_type = FCP_SEED_WWPN;
+		blp->nlp_sid = (sum & 0xff);
+		memcpy(&blp->nlp_portname, (uint8_t *) & pn,
+		       sizeof (NAME_TYPE));
+
+		lpfc_nlp_bind(phba, blp);
+
+	      out:
+		np = (uint8_t *) & pn;
+	}
+	return (0);
+}				/* lpfc_bind_wwpn */
+
+int
+lpfc_get_bind_type(elxHBA_t * phba)
+{
+	int bind_type;
+	LPFCHBA_t *plhba;
+	elxCfgParam_t *clp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	bind_type = clp[LPFC_CFG_BINDMETHOD].a_current;
+
+	switch (bind_type) {
+	case 1:
+		plhba->fcp_mapping = FCP_SEED_WWNN;
+		break;
+
+	case 2:
+		plhba->fcp_mapping = FCP_SEED_WWPN;
+		break;
+
+	case 3:
+		plhba->fcp_mapping = FCP_SEED_DID;
+		break;
+
+	case 4:
+		plhba->fcp_mapping = FCP_SEED_DID;
+		break;
+	}
+
+	return 0;
+}
+
+int
+lpfc_bind_wwnn(elxHBA_t * phba, char **arrayp, u_int cnt)
+{
+	uint8_t *datap, *np;
+	LPFC_BINDLIST_t *blp;
+	LPFCHBA_t *plhba;
+	NAME_TYPE pn;
+	int i, entry, lpfc_num, rstatus;
+	unsigned int sum;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plhba->fcp_mapping = FCP_SEED_WWNN;
+	np = (uint8_t *) & pn;
+
+	for (entry = 0; entry < cnt; entry++) {
+		datap = (uint8_t *) arrayp[entry];
+		if (datap == 0)
+			break;
+		/* Determined the number of ASC hex chars in WWNN & WWPN */
+		for (i = 0; i < FC_MAX_WW_NN_PN_STRING; i++) {
+			if (elx_str_ctox(datap[i]) < 0)
+				break;
+		}
+		if ((rstatus = lpfc_parse_binding_entry(phba, datap, np,
+							i, sizeof (NAME_TYPE),
+							LPFC_BIND_WW_NN_PN,
+							&sum, entry,
+							&lpfc_num)) > 0) {
+			if (rstatus == LPFC_SYNTAX_OK_BUT_NOT_THIS_BRD) {
+				continue;
+			}
+
+			/* For syntax error code definitions see LPFC_SYNTAX_ERR_ defines. */
+			/* WWNN binding entry <num>: Syntax error code <code> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0431,	/* ptr to msg structure */
+				       elx_mes0431,	/* ptr to msg */
+				       elx_msgBlk0431.msgPreambleStr,	/* begin varargs */
+				       entry, rstatus);	/* end varargs */
+			goto out;
+		}
+
+		/* Loop through all BINDLIST entries and find
+		 * the next available entry.
+		 */
+		if ((blp =
+		     (LPFC_BINDLIST_t *) elx_mem_get(phba, MEM_BIND)) == NULL) {
+			/* WWNN binding entry: node table full */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0433,	/* ptr to msg structure */
+				       elx_mes0433,	/* ptr to msg */
+				       elx_msgBlk0433.msgPreambleStr);	/* begin & end varargs */
+			goto out;
+		}
+		memset((void *)blp, 0, sizeof (LPFC_BINDLIST_t));
+		blp->nlp_bind_type = FCP_SEED_WWNN;
+		blp->nlp_sid = (sum & 0xff);
+		memcpy(&blp->nlp_nodename, (uint8_t *) & pn,
+		       sizeof (NAME_TYPE));
+		lpfc_nlp_bind(phba, blp);
+
+	      out:
+		np = (uint8_t *) & pn;
+	}			/* for loop */
+	return (0);
+}				/* lpfc_bind_wwnn */
+
+int
+lpfc_bind_did(elxHBA_t * phba, char **arrayp, u_int cnt)
+{
+	uint8_t *datap, *np;
+	LPFC_BINDLIST_t *blp;
+	LPFCHBA_t *plhba;
+	D_ID ndid;
+	int i, entry, lpfc_num, rstatus;
+	unsigned int sum;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plhba->fcp_mapping = FCP_SEED_DID;
+	ndid.un.word = 0;
+	np = (uint8_t *) & ndid.un.word;
+
+	for (entry = 0; entry < cnt; entry++) {
+		datap = (uint8_t *) arrayp[entry];
+		if (datap == 0)
+			break;
+		/* Determined the number of ASC hex chars in DID */
+		for (i = 0; i < FC_MAX_DID_STRING; i++) {
+			if (elx_str_ctox(datap[i]) < 0)
+				break;
+		}
+		if ((rstatus = lpfc_parse_binding_entry(phba, datap, np,
+							i, sizeof (D_ID),
+							LPFC_BIND_DID, &sum,
+							entry,
+							&lpfc_num)) > 0) {
+			if (rstatus == LPFC_SYNTAX_OK_BUT_NOT_THIS_BRD)
+				continue;
+
+			/* For syntax error code definitions see LPFC_SYNTAX_ERR_ defines. */
+			/* DID binding entry <num>: Syntax error code <code> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0434,	/* ptr to msg structure */
+				       elx_mes0434,	/* ptr to msg */
+				       elx_msgBlk0434.msgPreambleStr,	/* begin varargs */
+				       entry, rstatus);	/* end varargs */
+			goto out;
+		}
+
+		/* Loop through all BINDLIST entries and find
+		 * the next available entry.
+		 */
+		if ((blp =
+		     (LPFC_BINDLIST_t *) elx_mem_get(phba, MEM_BIND)) == NULL) {
+			/* DID binding entry: node table full */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0435,	/* ptr to msg structure */
+				       elx_mes0435,	/* ptr to msg */
+				       elx_msgBlk0435.msgPreambleStr);	/* begin & end varargs */
+			goto out;
+		}
+		memset((void *)blp, 0, sizeof (LPFC_BINDLIST_t));
+		blp->nlp_bind_type = FCP_SEED_DID;
+		blp->nlp_sid = (sum & 0xff);
+		blp->nlp_DID = SWAP_DATA(ndid.un.word);
+
+		lpfc_nlp_bind(phba, blp);
+
+	      out:
+
+		np = (uint8_t *) & ndid.un.word;
+	}
+	return (0);
+}
+
+int
+elx_initpci(struct dfc_info *di, elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	LINUX_HBA_t *plxhba;
+	struct pci_dev *pdev;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	pdev = plxhba->pcidev;
+	/*
+	   must have the pci struct
+	 */
+	if (!pdev)
+		return (1);
+
+	di->fc_ba.a_onmask = (ONDI_MBOX | ONDI_RMEM | ONDI_RPCI | ONDI_RCTLREG |
+			      ONDI_IOINFO | ONDI_LNKINFO | ONDI_NODEINFO |
+			      ONDI_CFGPARAM | ONDI_CT | ONDI_HBAAPI);
+	di->fc_ba.a_offmask =
+	    (OFFDI_MBOX | OFFDI_RMEM | OFFDI_WMEM | OFFDI_RPCI | OFFDI_WPCI |
+	     OFFDI_RCTLREG | OFFDI_WCTLREG);
+
+	if (lpfc_diag_state == DDI_ONDI)
+		di->fc_ba.a_onmask |= ONDI_SLI2;
+	else
+		di->fc_ba.a_onmask |= ONDI_SLI1;
+#ifdef powerpc
+	di->fc_ba.a_onmask |= ONDI_BIG_ENDIAN;
+#else
+	di->fc_ba.a_onmask |= ONDI_LTL_ENDIAN;
+#endif
+	di->fc_ba.a_pci =
+	    ((((uint32_t) pdev->device) << 16) | (uint32_t) (pdev->vendor));
+	di->fc_ba.a_pci = SWAP_LONG(di->fc_ba.a_pci);
+	di->fc_ba.a_ddi = lpfc_instance[phba->brd_no];
+	if (pdev->bus)
+		di->fc_ba.a_busid = (uint32_t) (pdev->bus->number);
+	else
+		di->fc_ba.a_busid = 0;
+	di->fc_ba.a_devid = (uint32_t) (pdev->devfn);
+
+	memcpy(di->fc_ba.a_drvrid, (void *)lpfc_release_version, 8);
+	lpfc_decode_firmware_rev(phba);
+	memcpy(di->fc_ba.a_fwname, (void *)lpfc_fwrevision, 32);
+
+	return (0);
+}
+
+ELXSCSILUN_t *
+lpfc_tran_find_lun(ELX_SCSI_BUF_t * elx_cmd)
+{
+	elxHBA_t *phba;
+	ELXSCSILUN_t *lunp;
+
+	phba = elx_cmd->scsi_hba;
+	lunp = lpfc_find_lun(phba, elx_cmd->scsi_target, elx_cmd->scsi_lun, 1);
+	return (lunp);
+}
+
+int
+lpfc_utsname_nodename_check(void)
+{
+	if (system_utsname.nodename[0] == '\0')
+		return (1);
+
+	return (0);
+}
+
+char *
+lpfc_get_OsNameVersion(int cmd)
+{
+	memset((void *)lpfc_os_name_version, 0, 256);
+
+	switch (cmd) {
+	case GET_OS_VERSION:
+		elx_str_sprintf(lpfc_os_name_version, "%s %s %s",
+				system_utsname.sysname, system_utsname.release,
+				system_utsname.version);
+		break;
+	case GET_HOST_NAME:
+		elx_str_sprintf(lpfc_os_name_version, "%s",
+				system_utsname.nodename);
+		break;
+	}
+	return (lpfc_os_name_version);
+}
+
+int
+lpfc_xmit(elxHBA_t * phba, struct sk_buff *skb)
+{
+	LPFC_IP_BUF_t *lpfc_cmd;
+	unsigned long iflag;
+	int rc;
+	LPFCHBA_t *plhba;
+	uint16_t *dest_addr;
+	uint32_t total_length;
+	struct sk_buff *tmp_skb;
+	uint32_t is_mcast, is_bcast, is_ucast;
+
+	is_mcast = is_bcast = is_ucast = 0;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	ELX_DRVR_LOCK(phba, iflag);
+
+	/* Get an IP buffer which has all memory 
+	 * resources needed to initiate the I/O.
+	 */
+
+	lpfc_cmd = lpfc_get_ip_buf(phba);
+	if (lpfc_cmd == 0) {
+		plhba->ip_stat->lpfn_tx_dropped++;
+		ELX_DRVR_UNLOCK(phba, iflag);
+		/* error-out this command */
+		return (ENOMEM);
+	}
+	/* store our command structure for later */
+	lpfc_cmd->pOSCmd = (void *)skb;
+
+	total_length = 0;
+	tmp_skb = skb;
+	while (tmp_skb) {
+		total_length += tmp_skb->len;
+		tmp_skb = tmp_skb->next;
+	}
+
+	/* setup a virtual ptr to the Network Header */
+	lpfc_cmd->net_hdr = (LPFC_IPHDR_t *) skb->data;
+
+	dest_addr =
+	    (uint16_t *) & (lpfc_cmd->net_hdr->fcnet.fc_destname.IEEE[0]);
+
+	if ((dest_addr[0] == 0xffff) && (dest_addr[1] == 0xffff) &&
+	    (dest_addr[2] == 0xffff)) {
+		is_bcast = 1;
+	} else if (dest_addr[0] & 0x8000) {
+		is_mcast = 1;
+	} else {
+		is_ucast = 1;
+	}
+
+	/* 
+	   If the protocol is any thing other than IP or ARP drop the 
+	   packet.
+	 */
+	if (lpfc_cmd->net_hdr &&
+	    lpfc_cmd->net_hdr->llc.type != SWAP_DATA16(ETH_P_IP) &&
+	    lpfc_cmd->net_hdr->llc.type != SWAP_DATA16(ETH_P_ARP)) {
+		plhba->ip_stat->lpfn_tx_dropped++;
+		lpfc_free_ip_buf(lpfc_cmd);
+		ELX_DRVR_UNLOCK(phba, iflag);
+		return (0);
+	}
+	/* Send the packet */
+	rc = lpfc_ip_xmit(lpfc_cmd);
+	if (rc) {
+		lpfc_free_ip_buf(lpfc_cmd);
+		rc = ENXIO;
+		ELX_DRVR_UNLOCK(phba, iflag);
+		return (rc);
+	}
+
+	if (is_bcast) {
+		/* This is a broad cast packet */
+		if (++plhba->ip_stat->lpfn_brdcstxmt_lsw == 0) {
+			plhba->ip_stat->lpfn_brdcstxmt_msw++;
+		}
+	}
+	if (is_mcast) {
+		/* This is a multi cast packet */
+		if (++plhba->ip_stat->lpfn_multixmt_lsw == 0) {
+			plhba->ip_stat->lpfn_multixmt_msw++;
+		}
+	}
+	if (is_ucast) {
+		/* This is an uni cast packet */
+		if (++plhba->ip_stat->lpfn_Ucstxmt_lsw == 0) {
+			plhba->ip_stat->lpfn_Ucstxmt_msw++;
+		}
+	}
+	/* Update the total txmited bytes statistics. */
+	plhba->ip_stat->lpfn_xmtbytes_lsw += total_length;
+	if (plhba->ip_stat->lpfn_xmtbytes_lsw < total_length)
+		plhba->ip_stat->lpfn_xmtbytes_msw++;
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	return (rc);
+}
+
+int
+lpfc_ipioctl(int cmd, void *s)
+{
+	elxHBA_t *phba;
+	LPFCHBA_t *plhba;
+	elxCfgParam_t *clp;
+	NETDEVICE *dev;
+	struct lpfn_probe *lp;
+	int i, cnt = 0;
+	switch (cmd) {
+	case LPFN_PROBE:
+
+		if (lpfc_detect_called == FALSE) {
+			lp = (struct lpfn_probe *)s;
+			lpfn_probe = lp->probe;
+			lpfc_detect_called = LPFN_PROBE_PENDING;	/* defer calling this till after fc_detect */
+			return (1);
+		}
+
+		for (i = 0; i < MAX_ELX_BRDS; i++) {
+			if ((phba = elxDRVR.pHba[i])) {
+				clp = &phba->config[0];
+				plhba = (LPFCHBA_t *) phba->pHbaProto;
+				if (clp[LPFC_CFG_NETWORK_ON].a_current == 0)
+					continue;
+
+				if (plhba->lpfn_dev == 0) {
+					unsigned int alloc_size;
+
+					/* ensure 32-byte alignment of the private area */
+					alloc_size =
+					    (sizeof (NETDEVICE) & 0xffffffc0) +
+					    0x40;
+
+					dev =
+					    (NETDEVICE *) kmalloc(alloc_size,
+								  GFP_ATOMIC);
+					if (dev == NULL) {
+						continue;
+					}
+					memset((char *)dev, 0, alloc_size);
+					rtnl_lock();
+					elx_str_cpy(dev->name, "lpfn%d");
+					if (dev_alloc_name(dev, "lpfn%d") < 0) {
+						rtnl_unlock();
+						kfree((void *)dev);
+						continue;
+					}
+
+					dev->priv = (void *)phba;
+					plhba->lpfn_dev = (void *)dev;
+
+					lp = (struct lpfn_probe *)s;
+					/* Initialize the device structure. */
+					dev->hard_start_xmit =
+					    lp->hard_start_xmit;
+					dev->get_stats = lp->get_stats;
+					dev->open = lp->open;
+					dev->stop = lp->stop;
+					dev->hard_header = lp->hard_header;
+					dev->rebuild_header =
+					    lp->rebuild_header;
+					dev->change_mtu = lp->change_mtu;
+					plhba->lpfn_ip_rcv =
+					    (void (*)
+					     (elxHBA_t *, void *,
+					      uint32_t))(lp->receive);
+
+					/* Assume fc header + LLC/SNAP  24 bytes */
+					dev->hard_header_len = 24;
+					dev->type = ARPHRD_ETHER;
+					dev->mtu = plhba->lpfn_max_mtu;
+					dev->addr_len = 6;
+					dev->tx_queue_len = 100;
+
+					memset(dev->broadcast, 0xFF, 6);
+					memcpy(dev->dev_addr, plhba->phys_addr,
+					       6);
+
+					/* New-style flags */
+					dev->flags = IFF_BROADCAST;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+					dev_init_buffers(dev);
+#endif
+					register_netdevice(dev);
+					rtnl_unlock();
+
+					cnt++;
+				}
+			}
+		}
+		break;
+	case LPFN_DETACH:
+		for (i = 0; i < MAX_ELX_BRDS; i++) {
+			if ((phba = elxDRVR.pHba[i])) {
+				clp = &phba->config[i];
+				plhba = (LPFCHBA_t *) phba->pHbaProto;
+				if (clp[LPFC_CFG_NETWORK_ON].a_current == 0)
+					continue;
+				if ((dev = plhba->lpfn_dev)) {
+					unregister_netdev(dev);
+					dev->priv = NULL;
+					plhba->lpfn_dev = 0;
+					cnt++;
+				}
+			}
+		}
+		break;
+	case LPFN_DFC:
+		break;
+	default:
+		return (0);
+	}
+	return (cnt);
+}
+
+int
+lpfc_bufmap(elxHBA_t * phba, uint8_t * bp, uint32_t len, elx_dma_addr_t * phys)
+{
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+
+	buf_info = &bufinfo;
+	buf_info->phys = INVALID_PHYS;
+	buf_info->virt = bp;
+	buf_info->size = len;
+	buf_info->flags = ELX_MBUF_PHYSONLY;
+	elx_malloc(phba, buf_info);
+
+	if (buf_info->phys == INVALID_PHYS)
+		return (0);
+	phys[0] = buf_info->phys;
+	return (1);
+}
+
+int
+lpfc_ip_prep_io(elxHBA_t * phba, LPFC_IP_BUF_t * pib)
+{
+	LINUX_HBA_t *plxhba;
+	LPFC_IPHDR_t *pnethdr;
+	ULP_BDE64 *topbpl;
+	ULP_BDE64 *bpl;
+	DMABUF_t *bmp;
+	DMABUF_t *last_bmp;
+	IOCB_t *cmd;
+	struct sk_buff *skb;
+	struct sk_buff *cur_skb;
+	struct sk_buff *next_skb;
+	elx_dma_addr_t physaddr;
+	ELX_PHYS_NET_MAP_t *p_tmp_buff;
+	uint32_t cnt, rc;
+	uint32_t num_bmps, num_bde, max_bde;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	bpl = pib->ip_bpl;
+
+	max_bde = LPFC_IP_INITIAL_BPL_SIZE;
+
+	/* Get nonDMA ptrs from pib */
+	skb = (struct sk_buff *)pib->pOSCmd;
+	pnethdr = pib->net_hdr;
+	cmd = &pib->cur_iocbq.iocb;
+
+	/* These are needed if we chain BPLs */
+	last_bmp = pib->dma_ext;
+	num_bmps = 1;
+	topbpl = 0;
+	num_bde = 0;
+
+	/* This next section finishes building the BPL for the I/O from the
+	 * skb buffer chain and updates the IOCB accordingly.
+	 */
+	cnt = 0;
+	rc = 0;
+	cur_skb = skb;
+	while (cur_skb) {
+		next_skb = cur_skb->next;
+
+		/* If this skb has data */
+		if (cur_skb->len) {
+			cnt += cur_skb->len;
+
+			/* Check to see if current BPL is full of BDEs */
+			if (num_bde == max_bde) {
+				if ((bmp =
+				     (DMABUF_t *) elx_mem_get(phba,
+							      MEM_BPL)) == 0) {
+					rc = 1;
+					goto out;
+				}
+				max_bde = ((1024 / sizeof (ULP_BDE64)) - 3);
+				/* Fill in continuation entry to next bpl */
+				bpl->addrHigh = putPaddrHigh(bmp->phys);
+				bpl->addrHigh = PCIMEM_LONG(bpl->addrHigh);
+				bpl->addrLow = putPaddrLow(bmp->phys);
+				bpl->addrLow = PCIMEM_LONG(bpl->addrLow);
+				bpl->tus.f.bdeFlags = BPL64_SIZE_WORD;
+				num_bde++;
+				if (num_bmps == 1) {
+					cmd->un.xseq64.bdl.bdeSize +=
+					    (num_bde * sizeof (ULP_BDE64));
+				} else {
+					topbpl->tus.f.bdeSize =
+					    (num_bde * sizeof (ULP_BDE64));
+					topbpl->tus.w =
+					    PCIMEM_LONG(topbpl->tus.w);
+				}
+				topbpl = bpl;
+				bpl = (ULP_BDE64 *) bmp->virt;
+				last_bmp->next = (void *)bmp;
+				last_bmp = bmp;
+				num_bde = 0;
+				num_bmps++;
+			}
+
+			if (lpfc_bufmap
+			    (phba, cur_skb->data, cur_skb->len,
+			     &physaddr) == 0) {
+				rc = 1;
+				goto out;
+			}
+
+			/* Optimization.  If the sk_buff from the OS contains exactly one
+			 * entry, store the one phyaddr in data structure's local ELX_PHYS_NET_MAP_t
+			 * type.  Otherwise get a memory buffer to contain the list of physaddr's mapped
+			 * back to each sk_buff in the chain.
+			 */
+			if (next_skb == NULL) {
+				pib->elx_phys_net_map.phys_addr = physaddr;
+				pib->elx_phys_net_map.p_sk_buff = cur_skb;
+			} else {
+				/* The sk_buff contains more than one buffer.  Store the sk_buff and the physical
+				 * address for later processing by lpfc_ip_unprep_io.  The sk_buff is provided
+				 * as a check since the unprep has to access two lists.
+				 */
+				if ((p_tmp_buff =
+				     (ELX_PHYS_NET_MAP_t *) elx_mem_get(phba,
+									MEM_IP_MAP))
+				    == NULL) {
+					rc = 1;
+					goto out;
+				}
+
+				p_tmp_buff->p_sk_buff = cur_skb;
+				p_tmp_buff->phys_addr = physaddr;
+				elx_tqs_enqueue(&pib->elx_phys_net_map_list,
+						p_tmp_buff, p_next);
+			}
+
+			bpl->addrLow = PCIMEM_LONG(putPaddrLow(physaddr));
+			bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(physaddr));
+			bpl->tus.f.bdeSize = cur_skb->len;
+			bpl->tus.f.bdeFlags = BDE64_SIZE_WORD;
+			bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+			bpl++;
+			num_bde++;
+		}
+		cur_skb = next_skb;
+	}
+
+      out:
+	bpl->addrHigh = 0;
+	bpl->addrLow = 0;
+	bpl->tus.w = 0;
+	pib->totalSize = cnt;
+	if (num_bmps == 1) {
+		cmd->un.xseq64.bdl.bdeSize += (num_bde * sizeof (ULP_BDE64));
+	} else {
+		topbpl->tus.f.bdeSize = (num_bde * sizeof (ULP_BDE64));
+		topbpl->tus.w = PCIMEM_LONG(topbpl->tus.w);
+	}
+	cmd->ulpBdeCount = 1;
+	cmd->ulpLe = 1;		/* Set the LE bit in the iocb */
+
+	return (rc);
+}
+
+int
+lpfc_ip_unprep_io(elxHBA_t * phba, LPFC_IP_BUF_t * pib, uint32_t free_msg)
+{
+	int free_phys_rsc;
+	struct sk_buff *skb;
+	struct sk_buff *curr_skb;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+	ELX_PHYS_NET_MAP_t *p_tmp_buff;
+
+	free_phys_rsc = 0;
+	buf_info = &bufinfo;
+	skb = (struct sk_buff *)pib->pOSCmd;
+	while (skb) {
+		curr_skb = skb;
+		skb = skb->next;
+
+		/* Free the PCI mapping of the message block. */
+		buf_info->flags = ELX_MBUF_PHYSONLY;
+		buf_info->size = curr_skb->len;
+
+		if (skb == NULL) {
+			p_tmp_buff = &pib->elx_phys_net_map;
+			buf_info->phys = pib->elx_phys_net_map.phys_addr;
+		} else {
+			p_tmp_buff =
+			    elx_tqs_dequeuefirst(&pib->elx_phys_net_map_list,
+						 p_next);
+			buf_info->phys = p_tmp_buff->phys_addr;
+			free_phys_rsc = 1;
+		}
+
+		/* Make sure the ip buffer in the pOSCmd matches that stored in the pib's 
+		 * ELX_PHYS_NET_MAP_t data member. 
+		 */
+
+		if (p_tmp_buff->p_sk_buff != curr_skb) {
+			elx_printf_log(phba->brd_no, &elx_msgBlk0609,	/* ptr to msg structure */
+				       elx_mes0609,	/* ptr to msg */
+				       elx_msgBlk0609.msgPreambleStr,	/* begin varargs */
+				       pib, p_tmp_buff->p_sk_buff, curr_skb, p_tmp_buff->phys_addr);	/* end varargs */
+		}
+
+		/* Free the dma mapping now. */
+		elx_free(phba, buf_info);
+
+		/* Free the ELX_PHYS_NET_MAP_t resources. */
+		if (free_phys_rsc) {
+			elx_mem_put(phba, MEM_IP_MAP, (uint8_t *) p_tmp_buff);
+		}
+
+		/* Free the message block */
+		if (free_msg) {
+			if (in_irq()) {
+				dev_kfree_skb_irq(curr_skb);
+			} else {
+				dev_kfree_skb(curr_skb);
+			}
+		}
+	}
+
+	return 0;
+}
+
+int
+lpfc_sleep(elxHBA_t * phba, fcEVTHDR_t * ep)
+{
+	LINUX_HBA_t *plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	ep->e_mode |= E_SLEEPING_MODE;
+	switch (ep->e_mask) {
+	case FC_REG_LINK_EVENT:
+		return (elx_sleep(phba, &plxhba->linkevtwq, 0));
+	case FC_REG_RSCN_EVENT:
+		return (elx_sleep(phba, &plxhba->rscnevtwq, 0));
+	case FC_REG_CT_EVENT:
+		return (elx_sleep(phba, &plxhba->ctevtwq, 0));
+	}
+	return (0);
+}
+
+void
+lpfc_wakeup(elxHBA_t * phba, fcEVTHDR_t * ep)
+{
+	LINUX_HBA_t *plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	ep->e_mode &= ~E_SLEEPING_MODE;
+	switch (ep->e_mask) {
+	case FC_REG_LINK_EVENT:
+		elx_wakeup(phba, &plxhba->linkevtwq);
+		break;
+	case FC_REG_RSCN_EVENT:
+		elx_wakeup(phba, &plxhba->rscnevtwq);
+		break;
+	case FC_REG_CT_EVENT:
+		elx_wakeup(phba, &plxhba->ctevtwq);
+		break;
+	}
+	return;
+}
+
+void *
+fc_get_cfg_param(int brd, int param)
+{
+	void *value;
+
+	value = (void *)((ulong) (-1));
+	switch (brd) {
+	case 0:		/* HBA 0 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc0_log_verbose != -1)
+				value = (void *)((ulong) lpfc0_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc0_num_iocbs != -1)
+				value = (void *)((ulong) lpfc0_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc0_num_bufs != -1)
+				value = (void *)((ulong) lpfc0_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc0_automap != -1)
+				value = (void *)((ulong) lpfc0_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc0_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc0_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc0_cr_delay != -1)
+				value = (void *)((ulong) lpfc0_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc0_cr_count != -1)
+				value = (void *)((ulong) lpfc0_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc0_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc0_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc0_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc0_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc0_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc0_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc0_fcp_class != -1)
+				value = (void *)((ulong) lpfc0_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc0_use_adisc != -1)
+				value = (void *)((ulong) lpfc0_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc0_no_device_delay != -1)
+				value = (void *)((ulong) lpfc0_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc0_network_on != -1)
+				value = (void *)((ulong) lpfc0_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc0_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc0_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc0_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc0_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc0_ip_class != -1)
+				value = (void *)((ulong) lpfc0_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc0_ack0 != -1)
+				value = (void *)((ulong) lpfc0_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc0_topology != -1)
+				value = (void *)((ulong) lpfc0_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc0_scan_down != -1)
+				value = (void *)((ulong) lpfc0_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc0_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc0_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc0_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc0_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc0_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc0_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc0_check_cond_err != -1)
+				value = (void *)((ulong) lpfc0_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc0_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc0_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc0_link_speed != -1)
+				value = (void *)((ulong) lpfc0_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc0_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc0_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc0_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc0_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc0_fdmi_on != -1)
+				value = (void *)((ulong) lpfc0_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc0_max_lun != -1)
+				value = (void *)((ulong) lpfc0_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc0_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc0_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc0_max_target != -1)
+				value = (void *)((ulong) lpfc0_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc0_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc0_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc0_lun_skip != -1)
+				value = (void *)((ulong) lpfc0_lun_skip);
+			break;
+		default:
+			break;
+		}
+		break;
+	case 1:		/* HBA 1 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc1_log_verbose != -1)
+				value = (void *)((ulong) lpfc1_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc1_num_iocbs != -1)
+				value = (void *)((ulong) lpfc1_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc1_num_bufs != -1)
+				value = (void *)((ulong) lpfc1_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc1_automap != -1)
+				value = (void *)((ulong) lpfc1_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc1_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc1_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc1_cr_delay != -1)
+				value = (void *)((ulong) lpfc1_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc1_cr_count != -1)
+				value = (void *)((ulong) lpfc1_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc1_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc1_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc1_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc1_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc1_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc1_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc1_fcp_class != -1)
+				value = (void *)((ulong) lpfc1_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc1_use_adisc != -1)
+				value = (void *)((ulong) lpfc1_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc1_no_device_delay != -1)
+				value = (void *)((ulong) lpfc1_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc1_network_on != -1)
+				value = (void *)((ulong) lpfc1_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc1_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc1_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc1_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc1_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc1_ip_class != -1)
+				value = (void *)((ulong) lpfc1_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc1_ack0 != -1)
+				value = (void *)((ulong) lpfc1_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc1_topology != -1)
+				value = (void *)((ulong) lpfc1_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc1_scan_down != -1)
+				value = (void *)((ulong) lpfc1_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc1_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc1_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc1_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc1_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc1_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc1_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc1_check_cond_err != -1)
+				value = (void *)((ulong) lpfc1_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc1_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc1_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc1_link_speed != -1)
+				value = (void *)((ulong) lpfc1_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc1_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc1_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc1_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc1_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc1_fdmi_on != -1)
+				value = (void *)((ulong) lpfc1_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc1_max_lun != -1)
+				value = (void *)((ulong) lpfc1_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc1_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc1_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc1_max_target != -1)
+				value = (void *)((ulong) lpfc1_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc1_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc1_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc1_lun_skip != -1)
+				value = (void *)((ulong) lpfc1_lun_skip);
+			break;
+		}
+		break;
+	case 2:		/* HBA 2 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc2_log_verbose != -1)
+				value = (void *)((ulong) lpfc2_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc2_num_iocbs != -1)
+				value = (void *)((ulong) lpfc2_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc2_num_bufs != -1)
+				value = (void *)((ulong) lpfc2_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc2_automap != -1)
+				value = (void *)((ulong) lpfc2_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc2_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc2_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc2_cr_delay != -1)
+				value = (void *)((ulong) lpfc2_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc2_cr_count != -1)
+				value = (void *)((ulong) lpfc2_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc2_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc2_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc2_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc2_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc2_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc2_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc2_fcp_class != -1)
+				value = (void *)((ulong) lpfc2_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc2_use_adisc != -1)
+				value = (void *)((ulong) lpfc2_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc2_no_device_delay != -1)
+				value = (void *)((ulong) lpfc2_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc2_network_on != -1)
+				value = (void *)((ulong) lpfc2_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc2_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc2_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc2_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc2_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc2_ip_class != -1)
+				value = (void *)((ulong) lpfc2_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc2_ack0 != -1)
+				value = (void *)((ulong) lpfc2_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc2_topology != -1)
+				value = (void *)((ulong) lpfc2_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc2_scan_down != -1)
+				value = (void *)((ulong) lpfc2_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc2_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc2_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc2_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc2_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc2_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc2_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc2_check_cond_err != -1)
+				value = (void *)((ulong) lpfc2_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc2_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc2_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc2_link_speed != -1)
+				value = (void *)((ulong) lpfc2_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc2_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc2_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc2_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc2_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc2_fdmi_on != -1)
+				value = (void *)((ulong) lpfc2_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc2_max_lun != -1)
+				value = (void *)((ulong) lpfc2_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc2_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc2_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc2_max_target != -1)
+				value = (void *)((ulong) lpfc2_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc2_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc2_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc2_lun_skip != -1)
+				value = (void *)((ulong) lpfc2_lun_skip);
+			break;
+		}
+		break;
+	case 3:		/* HBA 3 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc3_log_verbose != -1)
+				value = (void *)((ulong) lpfc3_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc3_num_iocbs != -1)
+				value = (void *)((ulong) lpfc3_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc3_num_bufs != -1)
+				value = (void *)((ulong) lpfc3_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc3_automap != -1)
+				value = (void *)((ulong) lpfc3_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc3_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc3_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc3_cr_delay != -1)
+				value = (void *)((ulong) lpfc3_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc3_cr_count != -1)
+				value = (void *)((ulong) lpfc3_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc3_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc3_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc3_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc3_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc3_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc3_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc3_fcp_class != -1)
+				value = (void *)((ulong) lpfc3_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc3_use_adisc != -1)
+				value = (void *)((ulong) lpfc3_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc3_no_device_delay != -1)
+				value = (void *)((ulong) lpfc3_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc3_network_on != -1)
+				value = (void *)((ulong) lpfc3_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc3_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc3_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc3_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc3_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc3_ip_class != -1)
+				value = (void *)((ulong) lpfc3_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc3_ack0 != -1)
+				value = (void *)((ulong) lpfc3_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc3_topology != -1)
+				value = (void *)((ulong) lpfc3_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc3_scan_down != -1)
+				value = (void *)((ulong) lpfc3_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc3_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc3_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc3_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc3_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc3_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc3_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc3_check_cond_err != -1)
+				value = (void *)((ulong) lpfc3_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc3_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc3_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc3_link_speed != -1)
+				value = (void *)((ulong) lpfc3_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc3_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc3_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc3_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc3_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc3_fdmi_on != -1)
+				value = (void *)((ulong) lpfc3_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc3_max_lun != -1)
+				value = (void *)((ulong) lpfc3_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc3_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc3_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc3_max_target != -1)
+				value = (void *)((ulong) lpfc3_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc3_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc3_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc3_lun_skip != -1)
+				value = (void *)((ulong) lpfc3_lun_skip);
+			break;
+		}
+		break;
+	case 4:		/* HBA 4 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc4_log_verbose != -1)
+				value = (void *)((ulong) lpfc4_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc4_num_iocbs != -1)
+				value = (void *)((ulong) lpfc4_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc4_num_bufs != -1)
+				value = (void *)((ulong) lpfc4_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc4_automap != -1)
+				value = (void *)((ulong) lpfc4_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc4_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc4_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc4_cr_delay != -1)
+				value = (void *)((ulong) lpfc4_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc4_cr_count != -1)
+				value = (void *)((ulong) lpfc4_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc4_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc4_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc4_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc4_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc4_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc4_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc4_fcp_class != -1)
+				value = (void *)((ulong) lpfc4_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc4_use_adisc != -1)
+				value = (void *)((ulong) lpfc4_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc4_no_device_delay != -1)
+				value = (void *)((ulong) lpfc4_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc4_network_on != -1)
+				value = (void *)((ulong) lpfc4_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc4_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc4_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc4_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc4_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc4_ip_class != -1)
+				value = (void *)((ulong) lpfc4_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc4_ack0 != -1)
+				value = (void *)((ulong) lpfc4_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc4_topology != -1)
+				value = (void *)((ulong) lpfc4_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc4_scan_down != -1)
+				value = (void *)((ulong) lpfc4_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc4_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc4_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc4_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc4_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc4_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc4_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc4_check_cond_err != -1)
+				value = (void *)((ulong) lpfc4_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc4_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc4_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc4_link_speed != -1)
+				value = (void *)((ulong) lpfc4_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc4_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc4_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc4_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc4_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc4_fdmi_on != -1)
+				value = (void *)((ulong) lpfc4_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc4_max_lun != -1)
+				value = (void *)((ulong) lpfc4_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc4_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc4_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc4_max_target != -1)
+				value = (void *)((ulong) lpfc4_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc4_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc4_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc4_lun_skip != -1)
+				value = (void *)((ulong) lpfc4_lun_skip);
+			break;
+		}
+		break;
+	case 5:		/* HBA 5 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc5_log_verbose != -1)
+				value = (void *)((ulong) lpfc5_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc5_num_iocbs != -1)
+				value = (void *)((ulong) lpfc5_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc5_num_bufs != -1)
+				value = (void *)((ulong) lpfc5_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc5_automap != -1)
+				value = (void *)((ulong) lpfc5_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc5_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc5_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc5_cr_delay != -1)
+				value = (void *)((ulong) lpfc5_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc5_cr_count != -1)
+				value = (void *)((ulong) lpfc5_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc5_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc5_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc5_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc5_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc5_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc5_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc5_fcp_class != -1)
+				value = (void *)((ulong) lpfc5_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc5_use_adisc != -1)
+				value = (void *)((ulong) lpfc5_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc5_no_device_delay != -1)
+				value = (void *)((ulong) lpfc5_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc5_network_on != -1)
+				value = (void *)((ulong) lpfc5_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc5_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc5_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc5_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc5_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc5_ip_class != -1)
+				value = (void *)((ulong) lpfc5_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc5_ack0 != -1)
+				value = (void *)((ulong) lpfc5_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc5_topology != -1)
+				value = (void *)((ulong) lpfc5_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc5_scan_down != -1)
+				value = (void *)((ulong) lpfc5_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc5_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc5_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc5_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc5_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc5_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc5_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc5_check_cond_err != -1)
+				value = (void *)((ulong) lpfc5_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc5_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc5_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc5_link_speed != -1)
+				value = (void *)((ulong) lpfc5_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc5_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc5_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc5_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc5_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc5_fdmi_on != -1)
+				value = (void *)((ulong) lpfc5_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc5_max_lun != -1)
+				value = (void *)((ulong) lpfc5_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc5_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc5_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc5_max_target != -1)
+				value = (void *)((ulong) lpfc5_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc5_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc5_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc5_lun_skip != -1)
+				value = (void *)((ulong) lpfc5_lun_skip);
+			break;
+		}
+		break;
+	case 6:		/* HBA 6 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc6_log_verbose != -1)
+				value = (void *)((ulong) lpfc6_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc6_num_iocbs != -1)
+				value = (void *)((ulong) lpfc6_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc6_num_bufs != -1)
+				value = (void *)((ulong) lpfc6_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc6_automap != -1)
+				value = (void *)((ulong) lpfc6_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc6_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc6_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc6_cr_delay != -1)
+				value = (void *)((ulong) lpfc6_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc6_cr_count != -1)
+				value = (void *)((ulong) lpfc6_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc6_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc6_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc6_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc6_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc6_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc6_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc6_fcp_class != -1)
+				value = (void *)((ulong) lpfc6_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc6_use_adisc != -1)
+				value = (void *)((ulong) lpfc6_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc6_no_device_delay != -1)
+				value = (void *)((ulong) lpfc6_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc6_network_on != -1)
+				value = (void *)((ulong) lpfc6_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc6_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc6_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc6_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc6_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc6_ip_class != -1)
+				value = (void *)((ulong) lpfc6_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc6_ack0 != -1)
+				value = (void *)((ulong) lpfc6_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc6_topology != -1)
+				value = (void *)((ulong) lpfc6_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc6_scan_down != -1)
+				value = (void *)((ulong) lpfc6_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc6_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc6_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc6_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc6_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc6_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc6_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc6_check_cond_err != -1)
+				value = (void *)((ulong) lpfc6_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc6_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc6_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc6_link_speed != -1)
+				value = (void *)((ulong) lpfc6_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc6_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc6_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc6_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc6_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc6_fdmi_on != -1)
+				value = (void *)((ulong) lpfc6_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc6_max_lun != -1)
+				value = (void *)((ulong) lpfc6_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc6_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc6_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc6_max_target != -1)
+				value = (void *)((ulong) lpfc6_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc6_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc6_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc6_lun_skip != -1)
+				value = (void *)((ulong) lpfc6_lun_skip);
+			break;
+		}
+		break;
+	case 7:		/* HBA 7 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc7_log_verbose != -1)
+				value = (void *)((ulong) lpfc7_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc7_num_iocbs != -1)
+				value = (void *)((ulong) lpfc7_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc7_num_bufs != -1)
+				value = (void *)((ulong) lpfc7_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc7_automap != -1)
+				value = (void *)((ulong) lpfc7_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc7_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc7_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc7_cr_delay != -1)
+				value = (void *)((ulong) lpfc7_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc7_cr_count != -1)
+				value = (void *)((ulong) lpfc7_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc7_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc7_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc7_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc7_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc7_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc7_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc7_fcp_class != -1)
+				value = (void *)((ulong) lpfc7_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc7_use_adisc != -1)
+				value = (void *)((ulong) lpfc7_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc7_no_device_delay != -1)
+				value = (void *)((ulong) lpfc7_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc7_network_on != -1)
+				value = (void *)((ulong) lpfc7_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc7_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc7_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc7_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc7_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc7_ip_class != -1)
+				value = (void *)((ulong) lpfc7_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc7_ack0 != -1)
+				value = (void *)((ulong) lpfc7_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc7_topology != -1)
+				value = (void *)((ulong) lpfc7_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc7_scan_down != -1)
+				value = (void *)((ulong) lpfc7_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc7_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc7_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc7_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc7_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc7_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc7_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc7_check_cond_err != -1)
+				value = (void *)((ulong) lpfc7_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc7_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc7_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc7_link_speed != -1)
+				value = (void *)((ulong) lpfc7_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc7_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc7_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc7_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc7_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc7_fdmi_on != -1)
+				value = (void *)((ulong) lpfc7_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc7_max_lun != -1)
+				value = (void *)((ulong) lpfc7_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc7_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc7_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc7_max_target != -1)
+				value = (void *)((ulong) lpfc7_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc7_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc7_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc7_lun_skip != -1)
+				value = (void *)((ulong) lpfc7_lun_skip);
+			break;
+		}
+		break;
+	case 8:		/* HBA 8 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc8_log_verbose != -1)
+				value = (void *)((ulong) lpfc8_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc8_num_iocbs != -1)
+				value = (void *)((ulong) lpfc8_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc8_num_bufs != -1)
+				value = (void *)((ulong) lpfc8_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc8_automap != -1)
+				value = (void *)((ulong) lpfc8_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc8_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc8_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc8_cr_delay != -1)
+				value = (void *)((ulong) lpfc8_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc8_cr_count != -1)
+				value = (void *)((ulong) lpfc8_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc8_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc8_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc8_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc8_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc8_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc8_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc8_fcp_class != -1)
+				value = (void *)((ulong) lpfc8_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc8_use_adisc != -1)
+				value = (void *)((ulong) lpfc8_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc8_no_device_delay != -1)
+				value = (void *)((ulong) lpfc8_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc8_network_on != -1)
+				value = (void *)((ulong) lpfc8_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc8_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc8_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc8_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc8_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc8_ip_class != -1)
+				value = (void *)((ulong) lpfc8_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc8_ack0 != -1)
+				value = (void *)((ulong) lpfc8_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc8_topology != -1)
+				value = (void *)((ulong) lpfc8_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc8_scan_down != -1)
+				value = (void *)((ulong) lpfc8_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc8_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc8_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc8_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc8_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc8_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc8_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc8_check_cond_err != -1)
+				value = (void *)((ulong) lpfc8_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc8_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc8_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc8_link_speed != -1)
+				value = (void *)((ulong) lpfc8_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc8_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc8_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc8_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc8_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc8_fdmi_on != -1)
+				value = (void *)((ulong) lpfc8_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc8_max_lun != -1)
+				value = (void *)((ulong) lpfc8_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc8_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc8_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc8_max_target != -1)
+				value = (void *)((ulong) lpfc8_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc8_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc8_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc8_lun_skip != -1)
+				value = (void *)((ulong) lpfc8_lun_skip);
+			break;
+		}
+		break;
+	case 9:		/* HBA 9 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc9_log_verbose != -1)
+				value = (void *)((ulong) lpfc9_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc9_num_iocbs != -1)
+				value = (void *)((ulong) lpfc9_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc9_num_bufs != -1)
+				value = (void *)((ulong) lpfc9_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc9_automap != -1)
+				value = (void *)((ulong) lpfc9_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc9_fcp_bind_method != -1)
+				value = (void *)((ulong) lpfc9_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc9_cr_delay != -1)
+				value = (void *)((ulong) lpfc9_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc9_cr_count != -1)
+				value = (void *)((ulong) lpfc9_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc9_tgt_queue_depth != -1)
+				value = (void *)((ulong) lpfc9_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc9_lun_queue_depth != -1)
+				value = (void *)((ulong) lpfc9_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc9_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc9_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc9_fcp_class != -1)
+				value = (void *)((ulong) lpfc9_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc9_use_adisc != -1)
+				value = (void *)((ulong) lpfc9_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc9_no_device_delay != -1)
+				value = (void *)((ulong) lpfc9_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc9_network_on != -1)
+				value = (void *)((ulong) lpfc9_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc9_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc9_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc9_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc9_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc9_ip_class != -1)
+				value = (void *)((ulong) lpfc9_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc9_ack0 != -1)
+				value = (void *)((ulong) lpfc9_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc9_topology != -1)
+				value = (void *)((ulong) lpfc9_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc9_scan_down != -1)
+				value = (void *)((ulong) lpfc9_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc9_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc9_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc9_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc9_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc9_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc9_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc9_check_cond_err != -1)
+				value = (void *)((ulong) lpfc9_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc9_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc9_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc9_link_speed != -1)
+				value = (void *)((ulong) lpfc9_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc9_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc9_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc9_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc9_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc9_fdmi_on != -1)
+				value = (void *)((ulong) lpfc9_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc9_max_lun != -1)
+				value = (void *)((ulong) lpfc9_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc9_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc9_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc9_max_target != -1)
+				value = (void *)((ulong) lpfc9_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc9_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc9_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc9_lun_skip != -1)
+				value = (void *)((ulong) lpfc9_lun_skip);
+			break;
+		}
+		break;
+	case 10:		/* HBA 10 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc10_log_verbose != -1)
+				value = (void *)((ulong) lpfc10_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc10_num_iocbs != -1)
+				value = (void *)((ulong) lpfc10_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc10_num_bufs != -1)
+				value = (void *)((ulong) lpfc10_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc10_automap != -1)
+				value = (void *)((ulong) lpfc10_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc10_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc10_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc10_cr_delay != -1)
+				value = (void *)((ulong) lpfc10_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc10_cr_count != -1)
+				value = (void *)((ulong) lpfc10_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc10_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc10_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc10_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc10_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc10_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc10_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc10_fcp_class != -1)
+				value = (void *)((ulong) lpfc10_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc10_use_adisc != -1)
+				value = (void *)((ulong) lpfc10_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc10_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc10_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc10_network_on != -1)
+				value = (void *)((ulong) lpfc10_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc10_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc10_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc10_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc10_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc10_ip_class != -1)
+				value = (void *)((ulong) lpfc10_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc10_ack0 != -1)
+				value = (void *)((ulong) lpfc10_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc10_topology != -1)
+				value = (void *)((ulong) lpfc10_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc10_scan_down != -1)
+				value = (void *)((ulong) lpfc10_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc10_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc10_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc10_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc10_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc10_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc10_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc10_check_cond_err != -1)
+				value = (void *)((ulong) lpfc10_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc10_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc10_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc10_link_speed != -1)
+				value = (void *)((ulong) lpfc10_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc10_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc10_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc10_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc10_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc10_fdmi_on != -1)
+				value = (void *)((ulong) lpfc10_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc10_max_lun != -1)
+				value = (void *)((ulong) lpfc10_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc10_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc10_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc10_max_target != -1)
+				value = (void *)((ulong) lpfc10_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc10_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc10_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc10_lun_skip != -1)
+				value = (void *)((ulong) lpfc10_lun_skip);
+			break;
+		}
+		break;
+	case 11:		/* HBA 11 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc11_log_verbose != -1)
+				value = (void *)((ulong) lpfc11_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc11_num_iocbs != -1)
+				value = (void *)((ulong) lpfc11_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc11_num_bufs != -1)
+				value = (void *)((ulong) lpfc11_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc11_automap != -1)
+				value = (void *)((ulong) lpfc11_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc11_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc11_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc11_cr_delay != -1)
+				value = (void *)((ulong) lpfc11_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc11_cr_count != -1)
+				value = (void *)((ulong) lpfc11_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc11_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc11_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc11_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc11_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc11_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc11_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc11_fcp_class != -1)
+				value = (void *)((ulong) lpfc11_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc11_use_adisc != -1)
+				value = (void *)((ulong) lpfc11_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc11_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc11_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc11_network_on != -1)
+				value = (void *)((ulong) lpfc11_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc11_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc11_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc11_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc11_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc11_ip_class != -1)
+				value = (void *)((ulong) lpfc11_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc11_ack0 != -1)
+				value = (void *)((ulong) lpfc11_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc11_topology != -1)
+				value = (void *)((ulong) lpfc11_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc11_scan_down != -1)
+				value = (void *)((ulong) lpfc11_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc11_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc11_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc11_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc11_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc11_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc11_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc11_check_cond_err != -1)
+				value = (void *)((ulong) lpfc11_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc11_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc11_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc11_link_speed != -1)
+				value = (void *)((ulong) lpfc11_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc11_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc11_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc11_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc11_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc11_fdmi_on != -1)
+				value = (void *)((ulong) lpfc11_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc11_max_lun != -1)
+				value = (void *)((ulong) lpfc11_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc11_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc11_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc11_max_target != -1)
+				value = (void *)((ulong) lpfc11_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc11_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc11_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc11_lun_skip != -1)
+				value = (void *)((ulong) lpfc11_lun_skip);
+			break;
+		}
+		break;
+	case 12:		/* HBA 12 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc12_log_verbose != -1)
+				value = (void *)((ulong) lpfc12_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc12_num_iocbs != -1)
+				value = (void *)((ulong) lpfc12_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc12_num_bufs != -1)
+				value = (void *)((ulong) lpfc12_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc12_automap != -1)
+				value = (void *)((ulong) lpfc12_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc12_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc12_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc12_cr_delay != -1)
+				value = (void *)((ulong) lpfc12_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc12_cr_count != -1)
+				value = (void *)((ulong) lpfc12_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc12_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc12_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc12_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc12_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc12_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc12_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc12_fcp_class != -1)
+				value = (void *)((ulong) lpfc12_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc12_use_adisc != -1)
+				value = (void *)((ulong) lpfc12_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc12_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc12_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc12_network_on != -1)
+				value = (void *)((ulong) lpfc12_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc12_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc12_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc12_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc12_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc12_ip_class != -1)
+				value = (void *)((ulong) lpfc12_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc12_ack0 != -1)
+				value = (void *)((ulong) lpfc12_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc12_topology != -1)
+				value = (void *)((ulong) lpfc12_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc12_scan_down != -1)
+				value = (void *)((ulong) lpfc12_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc12_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc12_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc12_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc12_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc12_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc12_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc12_check_cond_err != -1)
+				value = (void *)((ulong) lpfc12_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc12_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc12_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc12_link_speed != -1)
+				value = (void *)((ulong) lpfc12_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc12_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc12_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc12_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc12_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc12_fdmi_on != -1)
+				value = (void *)((ulong) lpfc12_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc12_max_lun != -1)
+				value = (void *)((ulong) lpfc12_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc12_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc12_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc12_max_target != -1)
+				value = (void *)((ulong) lpfc12_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc12_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc12_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc12_lun_skip != -1)
+				value = (void *)((ulong) lpfc12_lun_skip);
+			break;
+		}
+		break;
+	case 13:		/* HBA 13 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc13_log_verbose != -1)
+				value = (void *)((ulong) lpfc13_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc13_num_iocbs != -1)
+				value = (void *)((ulong) lpfc13_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc13_num_bufs != -1)
+				value = (void *)((ulong) lpfc13_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc13_automap != -1)
+				value = (void *)((ulong) lpfc13_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc13_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc13_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc13_cr_delay != -1)
+				value = (void *)((ulong) lpfc13_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc13_cr_count != -1)
+				value = (void *)((ulong) lpfc13_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc13_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc13_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc13_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc13_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc13_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc13_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc13_fcp_class != -1)
+				value = (void *)((ulong) lpfc13_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc13_use_adisc != -1)
+				value = (void *)((ulong) lpfc13_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc13_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc13_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc13_network_on != -1)
+				value = (void *)((ulong) lpfc13_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc13_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc13_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc13_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc13_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc13_ip_class != -1)
+				value = (void *)((ulong) lpfc13_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc13_ack0 != -1)
+				value = (void *)((ulong) lpfc13_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc13_topology != -1)
+				value = (void *)((ulong) lpfc13_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc13_scan_down != -1)
+				value = (void *)((ulong) lpfc13_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc13_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc13_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc13_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc13_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc13_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc13_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc13_check_cond_err != -1)
+				value = (void *)((ulong) lpfc13_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc13_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc13_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc13_link_speed != -1)
+				value = (void *)((ulong) lpfc13_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc13_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc13_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc13_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc13_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc13_fdmi_on != -1)
+				value = (void *)((ulong) lpfc13_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc13_max_lun != -1)
+				value = (void *)((ulong) lpfc13_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc13_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc13_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc13_max_target != -1)
+				value = (void *)((ulong) lpfc13_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc13_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc13_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc13_lun_skip != -1)
+				value = (void *)((ulong) lpfc13_lun_skip);
+			break;
+		}
+		break;
+	case 14:		/* HBA 14 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc14_log_verbose != -1)
+				value = (void *)((ulong) lpfc14_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc14_num_iocbs != -1)
+				value = (void *)((ulong) lpfc14_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc14_num_bufs != -1)
+				value = (void *)((ulong) lpfc14_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc14_automap != -1)
+				value = (void *)((ulong) lpfc14_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc14_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc14_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc14_cr_delay != -1)
+				value = (void *)((ulong) lpfc14_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc14_cr_count != -1)
+				value = (void *)((ulong) lpfc14_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc14_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc14_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc14_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc14_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc14_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc14_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc14_fcp_class != -1)
+				value = (void *)((ulong) lpfc14_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc14_use_adisc != -1)
+				value = (void *)((ulong) lpfc14_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc14_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc14_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc14_network_on != -1)
+				value = (void *)((ulong) lpfc14_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc14_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc14_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc14_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc14_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc14_ip_class != -1)
+				value = (void *)((ulong) lpfc14_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc14_ack0 != -1)
+				value = (void *)((ulong) lpfc14_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc14_topology != -1)
+				value = (void *)((ulong) lpfc14_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc14_scan_down != -1)
+				value = (void *)((ulong) lpfc14_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc14_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc14_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc14_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc14_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc14_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc14_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc14_check_cond_err != -1)
+				value = (void *)((ulong) lpfc14_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc14_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc14_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc14_link_speed != -1)
+				value = (void *)((ulong) lpfc14_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc14_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc14_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc14_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc14_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc14_fdmi_on != -1)
+				value = (void *)((ulong) lpfc14_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc14_max_lun != -1)
+				value = (void *)((ulong) lpfc14_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc14_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc14_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc14_max_target != -1)
+				value = (void *)((ulong) lpfc14_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc14_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc14_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc14_lun_skip != -1)
+				value = (void *)((ulong) lpfc14_lun_skip);
+			break;
+		}
+		break;
+	case 15:		/* HBA 15 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc15_log_verbose != -1)
+				value = (void *)((ulong) lpfc15_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc15_num_iocbs != -1)
+				value = (void *)((ulong) lpfc15_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc15_num_bufs != -1)
+				value = (void *)((ulong) lpfc15_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc15_automap != -1)
+				value = (void *)((ulong) lpfc15_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc15_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc15_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc15_cr_delay != -1)
+				value = (void *)((ulong) lpfc15_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc15_cr_count != -1)
+				value = (void *)((ulong) lpfc15_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc15_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc15_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc15_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc15_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc15_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc15_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc15_fcp_class != -1)
+				value = (void *)((ulong) lpfc15_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc15_use_adisc != -1)
+				value = (void *)((ulong) lpfc15_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc15_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc15_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc15_network_on != -1)
+				value = (void *)((ulong) lpfc15_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc15_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc15_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc15_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc15_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc15_ip_class != -1)
+				value = (void *)((ulong) lpfc15_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc15_ack0 != -1)
+				value = (void *)((ulong) lpfc15_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc15_topology != -1)
+				value = (void *)((ulong) lpfc15_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc15_scan_down != -1)
+				value = (void *)((ulong) lpfc15_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc15_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc15_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc15_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc15_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc15_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc15_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc15_check_cond_err != -1)
+				value = (void *)((ulong) lpfc15_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc15_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc15_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc15_link_speed != -1)
+				value = (void *)((ulong) lpfc15_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc15_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc15_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc15_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc15_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc15_fdmi_on != -1)
+				value = (void *)((ulong) lpfc15_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc15_max_lun != -1)
+				value = (void *)((ulong) lpfc15_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc15_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc15_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc15_max_target != -1)
+				value = (void *)((ulong) lpfc15_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc15_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc15_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc15_lun_skip != -1)
+				value = (void *)((ulong) lpfc15_lun_skip);
+			break;
+		}
+		break;
+	case 16:		/* HBA 16 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc16_log_verbose != -1)
+				value = (void *)((ulong) lpfc16_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc16_num_iocbs != -1)
+				value = (void *)((ulong) lpfc16_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc16_num_bufs != -1)
+				value = (void *)((ulong) lpfc16_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc16_automap != -1)
+				value = (void *)((ulong) lpfc16_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc16_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc16_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc16_cr_delay != -1)
+				value = (void *)((ulong) lpfc16_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc16_cr_count != -1)
+				value = (void *)((ulong) lpfc16_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc16_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc16_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc16_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc16_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc16_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc16_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc16_fcp_class != -1)
+				value = (void *)((ulong) lpfc16_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc16_use_adisc != -1)
+				value = (void *)((ulong) lpfc16_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc16_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc16_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc16_network_on != -1)
+				value = (void *)((ulong) lpfc16_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc16_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc16_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc16_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc16_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc16_ip_class != -1)
+				value = (void *)((ulong) lpfc16_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc16_ack0 != -1)
+				value = (void *)((ulong) lpfc16_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc16_topology != -1)
+				value = (void *)((ulong) lpfc16_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc16_scan_down != -1)
+				value = (void *)((ulong) lpfc16_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc16_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc16_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc16_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc16_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc16_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc16_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc16_check_cond_err != -1)
+				value = (void *)((ulong) lpfc16_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc16_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc16_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc16_link_speed != -1)
+				value = (void *)((ulong) lpfc16_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc16_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc16_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc16_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc16_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc16_fdmi_on != -1)
+				value = (void *)((ulong) lpfc16_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc16_max_lun != -1)
+				value = (void *)((ulong) lpfc16_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc16_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc16_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc16_max_target != -1)
+				value = (void *)((ulong) lpfc16_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc16_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc16_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc16_lun_skip != -1)
+				value = (void *)((ulong) lpfc16_lun_skip);
+			break;
+		}
+		break;
+	case 17:		/* HBA 17 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc17_log_verbose != -1)
+				value = (void *)((ulong) lpfc17_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc17_num_iocbs != -1)
+				value = (void *)((ulong) lpfc17_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc17_num_bufs != -1)
+				value = (void *)((ulong) lpfc17_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc17_automap != -1)
+				value = (void *)((ulong) lpfc17_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc17_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc17_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc17_cr_delay != -1)
+				value = (void *)((ulong) lpfc17_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc17_cr_count != -1)
+				value = (void *)((ulong) lpfc17_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc17_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc17_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc17_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc17_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc17_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc17_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc17_fcp_class != -1)
+				value = (void *)((ulong) lpfc17_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc17_use_adisc != -1)
+				value = (void *)((ulong) lpfc17_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc17_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc17_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc17_network_on != -1)
+				value = (void *)((ulong) lpfc17_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc17_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc17_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc17_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc17_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc17_ip_class != -1)
+				value = (void *)((ulong) lpfc17_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc17_ack0 != -1)
+				value = (void *)((ulong) lpfc17_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc17_topology != -1)
+				value = (void *)((ulong) lpfc17_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc17_scan_down != -1)
+				value = (void *)((ulong) lpfc17_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc17_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc17_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc17_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc17_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc17_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc17_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc17_check_cond_err != -1)
+				value = (void *)((ulong) lpfc17_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc17_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc17_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc17_link_speed != -1)
+				value = (void *)((ulong) lpfc17_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc17_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc17_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc17_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc17_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc17_fdmi_on != -1)
+				value = (void *)((ulong) lpfc17_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc17_max_lun != -1)
+				value = (void *)((ulong) lpfc17_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc17_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc17_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc17_max_target != -1)
+				value = (void *)((ulong) lpfc17_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc17_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc17_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc17_lun_skip != -1)
+				value = (void *)((ulong) lpfc17_lun_skip);
+			break;
+		}
+		break;
+	case 18:		/* HBA 18 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc18_log_verbose != -1)
+				value = (void *)((ulong) lpfc18_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc18_num_iocbs != -1)
+				value = (void *)((ulong) lpfc18_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc18_num_bufs != -1)
+				value = (void *)((ulong) lpfc18_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc18_automap != -1)
+				value = (void *)((ulong) lpfc18_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc18_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc18_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc18_cr_delay != -1)
+				value = (void *)((ulong) lpfc18_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc18_cr_count != -1)
+				value = (void *)((ulong) lpfc18_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc18_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc18_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc18_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc18_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc18_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc18_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc18_fcp_class != -1)
+				value = (void *)((ulong) lpfc18_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc18_use_adisc != -1)
+				value = (void *)((ulong) lpfc18_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc18_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc18_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc18_network_on != -1)
+				value = (void *)((ulong) lpfc18_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc18_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc18_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc18_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc18_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc18_ip_class != -1)
+				value = (void *)((ulong) lpfc18_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc18_ack0 != -1)
+				value = (void *)((ulong) lpfc18_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc18_topology != -1)
+				value = (void *)((ulong) lpfc18_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc18_scan_down != -1)
+				value = (void *)((ulong) lpfc18_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc18_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc18_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc18_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc18_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc18_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc18_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc18_check_cond_err != -1)
+				value = (void *)((ulong) lpfc18_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc18_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc18_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc18_link_speed != -1)
+				value = (void *)((ulong) lpfc18_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc18_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc18_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc18_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc18_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc18_fdmi_on != -1)
+				value = (void *)((ulong) lpfc18_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc18_max_lun != -1)
+				value = (void *)((ulong) lpfc18_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc18_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc18_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc18_max_target != -1)
+				value = (void *)((ulong) lpfc18_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc18_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc18_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc18_lun_skip != -1)
+				value = (void *)((ulong) lpfc18_lun_skip);
+			break;
+		}
+		break;
+	case 19:		/* HBA 19 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc19_log_verbose != -1)
+				value = (void *)((ulong) lpfc19_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc19_num_iocbs != -1)
+				value = (void *)((ulong) lpfc19_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc19_num_bufs != -1)
+				value = (void *)((ulong) lpfc19_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc19_automap != -1)
+				value = (void *)((ulong) lpfc19_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc19_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc19_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc19_cr_delay != -1)
+				value = (void *)((ulong) lpfc19_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc19_cr_count != -1)
+				value = (void *)((ulong) lpfc19_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc19_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc19_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc19_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc19_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc19_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc19_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc19_fcp_class != -1)
+				value = (void *)((ulong) lpfc19_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc19_use_adisc != -1)
+				value = (void *)((ulong) lpfc19_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc19_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc19_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc19_network_on != -1)
+				value = (void *)((ulong) lpfc19_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc19_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc19_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc19_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc19_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc19_ip_class != -1)
+				value = (void *)((ulong) lpfc19_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc19_ack0 != -1)
+				value = (void *)((ulong) lpfc19_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc19_topology != -1)
+				value = (void *)((ulong) lpfc19_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc19_scan_down != -1)
+				value = (void *)((ulong) lpfc19_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc19_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc19_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc19_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc19_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc19_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc19_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc19_check_cond_err != -1)
+				value = (void *)((ulong) lpfc19_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc19_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc19_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc19_link_speed != -1)
+				value = (void *)((ulong) lpfc19_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc19_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc19_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc19_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc19_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc19_fdmi_on != -1)
+				value = (void *)((ulong) lpfc19_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc19_max_lun != -1)
+				value = (void *)((ulong) lpfc19_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc19_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc19_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc19_max_target != -1)
+				value = (void *)((ulong) lpfc19_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc19_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc19_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc19_lun_skip != -1)
+				value = (void *)((ulong) lpfc19_lun_skip);
+			break;
+		}
+		break;
+	case 20:		/* HBA 20 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc20_log_verbose != -1)
+				value = (void *)((ulong) lpfc20_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc20_num_iocbs != -1)
+				value = (void *)((ulong) lpfc20_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc20_num_bufs != -1)
+				value = (void *)((ulong) lpfc20_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc20_automap != -1)
+				value = (void *)((ulong) lpfc20_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc20_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc20_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc20_cr_delay != -1)
+				value = (void *)((ulong) lpfc20_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc20_cr_count != -1)
+				value = (void *)((ulong) lpfc20_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc20_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc20_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc20_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc20_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc20_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc20_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc20_fcp_class != -1)
+				value = (void *)((ulong) lpfc20_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc20_use_adisc != -1)
+				value = (void *)((ulong) lpfc20_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc20_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc20_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc20_network_on != -1)
+				value = (void *)((ulong) lpfc20_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc20_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc20_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc20_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc20_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc20_ip_class != -1)
+				value = (void *)((ulong) lpfc20_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc20_ack0 != -1)
+				value = (void *)((ulong) lpfc20_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc20_topology != -1)
+				value = (void *)((ulong) lpfc20_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc20_scan_down != -1)
+				value = (void *)((ulong) lpfc20_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc20_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc20_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc20_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc20_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc20_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc20_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc20_check_cond_err != -1)
+				value = (void *)((ulong) lpfc20_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc20_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc20_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc20_link_speed != -1)
+				value = (void *)((ulong) lpfc20_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc20_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc20_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc20_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc20_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc20_fdmi_on != -1)
+				value = (void *)((ulong) lpfc20_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc20_max_lun != -1)
+				value = (void *)((ulong) lpfc20_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc20_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc20_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc20_max_target != -1)
+				value = (void *)((ulong) lpfc20_max_target);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc20_lun_skip != -1)
+				value = (void *)((ulong) lpfc20_lun_skip);
+			break;
+		}
+		break;
+	case 21:		/* HBA 21 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc21_log_verbose != -1)
+				value = (void *)((ulong) lpfc21_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc21_num_iocbs != -1)
+				value = (void *)((ulong) lpfc21_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc21_num_bufs != -1)
+				value = (void *)((ulong) lpfc21_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc21_automap != -1)
+				value = (void *)((ulong) lpfc21_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc21_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc21_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc21_cr_delay != -1)
+				value = (void *)((ulong) lpfc21_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc21_cr_count != -1)
+				value = (void *)((ulong) lpfc21_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc21_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc21_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc21_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc21_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc21_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc21_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc21_fcp_class != -1)
+				value = (void *)((ulong) lpfc21_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc21_use_adisc != -1)
+				value = (void *)((ulong) lpfc21_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc21_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc21_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc21_network_on != -1)
+				value = (void *)((ulong) lpfc21_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc21_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc21_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc21_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc21_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc21_ip_class != -1)
+				value = (void *)((ulong) lpfc21_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc21_ack0 != -1)
+				value = (void *)((ulong) lpfc21_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc21_topology != -1)
+				value = (void *)((ulong) lpfc21_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc21_scan_down != -1)
+				value = (void *)((ulong) lpfc21_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc21_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc21_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc21_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc21_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc21_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc21_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc21_check_cond_err != -1)
+				value = (void *)((ulong) lpfc21_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc21_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc21_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc21_link_speed != -1)
+				value = (void *)((ulong) lpfc21_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc21_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc21_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc21_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc21_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc21_fdmi_on != -1)
+				value = (void *)((ulong) lpfc21_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc21_max_lun != -1)
+				value = (void *)((ulong) lpfc21_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc21_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc21_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc21_max_target != -1)
+				value = (void *)((ulong) lpfc21_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc21_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc21_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc21_lun_skip != -1)
+				value = (void *)((ulong) lpfc21_lun_skip);
+			break;
+		}
+		break;
+	case 22:		/* HBA 22 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc22_log_verbose != -1)
+				value = (void *)((ulong) lpfc22_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc22_num_iocbs != -1)
+				value = (void *)((ulong) lpfc22_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc22_num_bufs != -1)
+				value = (void *)((ulong) lpfc22_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc22_automap != -1)
+				value = (void *)((ulong) lpfc22_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc22_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc22_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc22_cr_delay != -1)
+				value = (void *)((ulong) lpfc22_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc22_cr_count != -1)
+				value = (void *)((ulong) lpfc22_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc22_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc22_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc22_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc22_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc22_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc22_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc22_fcp_class != -1)
+				value = (void *)((ulong) lpfc22_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc22_use_adisc != -1)
+				value = (void *)((ulong) lpfc22_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc22_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc22_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc22_network_on != -1)
+				value = (void *)((ulong) lpfc22_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc22_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc22_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc22_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc22_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc22_ip_class != -1)
+				value = (void *)((ulong) lpfc22_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc22_ack0 != -1)
+				value = (void *)((ulong) lpfc22_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc22_topology != -1)
+				value = (void *)((ulong) lpfc22_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc22_scan_down != -1)
+				value = (void *)((ulong) lpfc22_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc22_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc22_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc22_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc22_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc22_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc22_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc22_check_cond_err != -1)
+				value = (void *)((ulong) lpfc22_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc22_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc22_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc22_link_speed != -1)
+				value = (void *)((ulong) lpfc22_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc22_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc22_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc22_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc22_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc22_fdmi_on != -1)
+				value = (void *)((ulong) lpfc22_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc22_max_lun != -1)
+				value = (void *)((ulong) lpfc22_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc22_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc22_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc22_max_target != -1)
+				value = (void *)((ulong) lpfc22_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc22_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc22_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc22_lun_skip != -1)
+				value = (void *)((ulong) lpfc22_lun_skip);
+			break;
+		}
+		break;
+	case 23:		/* HBA 23 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc23_log_verbose != -1)
+				value = (void *)((ulong) lpfc23_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc23_num_iocbs != -1)
+				value = (void *)((ulong) lpfc23_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc23_num_bufs != -1)
+				value = (void *)((ulong) lpfc23_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc23_automap != -1)
+				value = (void *)((ulong) lpfc23_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc23_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc23_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc23_cr_delay != -1)
+				value = (void *)((ulong) lpfc23_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc23_cr_count != -1)
+				value = (void *)((ulong) lpfc23_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc23_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc23_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc23_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc23_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc23_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc23_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc23_fcp_class != -1)
+				value = (void *)((ulong) lpfc23_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc23_use_adisc != -1)
+				value = (void *)((ulong) lpfc23_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc23_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc23_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc23_network_on != -1)
+				value = (void *)((ulong) lpfc23_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc23_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc23_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc23_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc23_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc23_ip_class != -1)
+				value = (void *)((ulong) lpfc23_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc23_ack0 != -1)
+				value = (void *)((ulong) lpfc23_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc23_topology != -1)
+				value = (void *)((ulong) lpfc23_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc23_scan_down != -1)
+				value = (void *)((ulong) lpfc23_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc23_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc23_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc23_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc23_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc23_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc23_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc23_check_cond_err != -1)
+				value = (void *)((ulong) lpfc23_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc23_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc23_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc23_link_speed != -1)
+				value = (void *)((ulong) lpfc23_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc23_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc23_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc23_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc23_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc23_fdmi_on != -1)
+				value = (void *)((ulong) lpfc23_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc23_max_lun != -1)
+				value = (void *)((ulong) lpfc23_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc23_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc23_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc23_max_target != -1)
+				value = (void *)((ulong) lpfc23_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc23_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc23_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc23_lun_skip != -1)
+				value = (void *)((ulong) lpfc23_lun_skip);
+			break;
+		}
+		break;
+	case 24:		/* HBA 24 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc24_log_verbose != -1)
+				value = (void *)((ulong) lpfc24_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc24_num_iocbs != -1)
+				value = (void *)((ulong) lpfc24_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc24_num_bufs != -1)
+				value = (void *)((ulong) lpfc24_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc24_automap != -1)
+				value = (void *)((ulong) lpfc24_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc24_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc24_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc24_cr_delay != -1)
+				value = (void *)((ulong) lpfc24_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc24_cr_count != -1)
+				value = (void *)((ulong) lpfc24_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc24_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc24_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc24_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc24_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc24_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc24_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc24_fcp_class != -1)
+				value = (void *)((ulong) lpfc24_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc24_use_adisc != -1)
+				value = (void *)((ulong) lpfc24_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc24_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc24_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc24_network_on != -1)
+				value = (void *)((ulong) lpfc24_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc24_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc24_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc24_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc24_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc24_ip_class != -1)
+				value = (void *)((ulong) lpfc24_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc24_ack0 != -1)
+				value = (void *)((ulong) lpfc24_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc24_topology != -1)
+				value = (void *)((ulong) lpfc24_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc24_scan_down != -1)
+				value = (void *)((ulong) lpfc24_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc24_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc24_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc24_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc24_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc24_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc24_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc24_check_cond_err != -1)
+				value = (void *)((ulong) lpfc24_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc24_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc24_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc24_link_speed != -1)
+				value = (void *)((ulong) lpfc24_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc24_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc24_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc24_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc24_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc24_fdmi_on != -1)
+				value = (void *)((ulong) lpfc24_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc24_max_lun != -1)
+				value = (void *)((ulong) lpfc24_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc24_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc24_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc24_max_target != -1)
+				value = (void *)((ulong) lpfc24_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc24_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc24_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc24_lun_skip != -1)
+				value = (void *)((ulong) lpfc24_lun_skip);
+			break;
+		}
+		break;
+	case 25:		/* HBA 25 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc25_log_verbose != -1)
+				value = (void *)((ulong) lpfc25_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc25_num_iocbs != -1)
+				value = (void *)((ulong) lpfc25_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc25_num_bufs != -1)
+				value = (void *)((ulong) lpfc25_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc25_automap != -1)
+				value = (void *)((ulong) lpfc25_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc25_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc25_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc25_cr_delay != -1)
+				value = (void *)((ulong) lpfc25_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc25_cr_count != -1)
+				value = (void *)((ulong) lpfc25_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc25_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc25_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc25_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc25_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc25_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc25_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc25_fcp_class != -1)
+				value = (void *)((ulong) lpfc25_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc25_use_adisc != -1)
+				value = (void *)((ulong) lpfc25_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc25_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc25_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc25_network_on != -1)
+				value = (void *)((ulong) lpfc25_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc25_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc25_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc25_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc25_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc25_ip_class != -1)
+				value = (void *)((ulong) lpfc25_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc25_ack0 != -1)
+				value = (void *)((ulong) lpfc25_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc25_topology != -1)
+				value = (void *)((ulong) lpfc25_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc25_scan_down != -1)
+				value = (void *)((ulong) lpfc25_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc25_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc25_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc25_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc25_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc25_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc25_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc25_check_cond_err != -1)
+				value = (void *)((ulong) lpfc25_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc25_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc25_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc25_link_speed != -1)
+				value = (void *)((ulong) lpfc25_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc25_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc25_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc25_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc25_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc25_fdmi_on != -1)
+				value = (void *)((ulong) lpfc25_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc25_max_lun != -1)
+				value = (void *)((ulong) lpfc25_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc25_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc25_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc25_max_target != -1)
+				value = (void *)((ulong) lpfc25_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc25_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc25_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc25_lun_skip != -1)
+				value = (void *)((ulong) lpfc25_lun_skip);
+			break;
+		}
+		break;
+	case 26:		/* HBA 26 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc26_log_verbose != -1)
+				value = (void *)((ulong) lpfc26_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc26_num_iocbs != -1)
+				value = (void *)((ulong) lpfc26_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc26_num_bufs != -1)
+				value = (void *)((ulong) lpfc26_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc26_automap != -1)
+				value = (void *)((ulong) lpfc26_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc26_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc26_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc26_cr_delay != -1)
+				value = (void *)((ulong) lpfc26_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc26_cr_count != -1)
+				value = (void *)((ulong) lpfc26_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc26_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc26_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc26_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc26_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc26_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc26_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc26_fcp_class != -1)
+				value = (void *)((ulong) lpfc26_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc26_use_adisc != -1)
+				value = (void *)((ulong) lpfc26_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc26_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc26_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc26_network_on != -1)
+				value = (void *)((ulong) lpfc26_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc26_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc26_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc26_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc26_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc26_ip_class != -1)
+				value = (void *)((ulong) lpfc26_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc26_ack0 != -1)
+				value = (void *)((ulong) lpfc26_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc26_topology != -1)
+				value = (void *)((ulong) lpfc26_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc26_scan_down != -1)
+				value = (void *)((ulong) lpfc26_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc26_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc26_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc26_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc26_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc26_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc26_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc26_check_cond_err != -1)
+				value = (void *)((ulong) lpfc26_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc26_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc26_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc26_link_speed != -1)
+				value = (void *)((ulong) lpfc26_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc26_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc26_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc26_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc26_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc26_fdmi_on != -1)
+				value = (void *)((ulong) lpfc26_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc26_max_lun != -1)
+				value = (void *)((ulong) lpfc26_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc26_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc26_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc26_max_target != -1)
+				value = (void *)((ulong) lpfc26_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc26_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc26_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc26_lun_skip != -1)
+				value = (void *)((ulong) lpfc26_lun_skip);
+			break;
+		}
+		break;
+	case 27:		/* HBA 27 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc27_log_verbose != -1)
+				value = (void *)((ulong) lpfc27_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc27_num_iocbs != -1)
+				value = (void *)((ulong) lpfc27_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc27_num_bufs != -1)
+				value = (void *)((ulong) lpfc27_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc27_automap != -1)
+				value = (void *)((ulong) lpfc27_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc27_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc27_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc27_cr_delay != -1)
+				value = (void *)((ulong) lpfc27_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc27_cr_count != -1)
+				value = (void *)((ulong) lpfc27_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc27_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc27_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc27_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc27_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc27_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc27_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc27_fcp_class != -1)
+				value = (void *)((ulong) lpfc27_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc27_use_adisc != -1)
+				value = (void *)((ulong) lpfc27_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc27_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc27_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc27_network_on != -1)
+				value = (void *)((ulong) lpfc27_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc27_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc27_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc27_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc27_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc27_ip_class != -1)
+				value = (void *)((ulong) lpfc27_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc27_ack0 != -1)
+				value = (void *)((ulong) lpfc27_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc27_topology != -1)
+				value = (void *)((ulong) lpfc27_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc27_scan_down != -1)
+				value = (void *)((ulong) lpfc27_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc27_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc27_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc27_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc27_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc27_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc27_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc27_check_cond_err != -1)
+				value = (void *)((ulong) lpfc27_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc27_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc27_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc27_link_speed != -1)
+				value = (void *)((ulong) lpfc27_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc27_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc27_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc27_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc27_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc27_fdmi_on != -1)
+				value = (void *)((ulong) lpfc27_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc27_max_lun != -1)
+				value = (void *)((ulong) lpfc27_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc27_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc27_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc27_max_target != -1)
+				value = (void *)((ulong) lpfc27_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc27_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc27_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc27_lun_skip != -1)
+				value = (void *)((ulong) lpfc27_lun_skip);
+			break;
+		}
+		break;
+	case 28:		/* HBA 28 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc28_log_verbose != -1)
+				value = (void *)((ulong) lpfc28_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc28_num_iocbs != -1)
+				value = (void *)((ulong) lpfc28_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc28_num_bufs != -1)
+				value = (void *)((ulong) lpfc28_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc28_automap != -1)
+				value = (void *)((ulong) lpfc28_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc28_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc28_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc28_cr_delay != -1)
+				value = (void *)((ulong) lpfc28_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc28_cr_count != -1)
+				value = (void *)((ulong) lpfc28_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc28_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc28_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc28_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc28_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc28_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc28_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc28_fcp_class != -1)
+				value = (void *)((ulong) lpfc28_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc28_use_adisc != -1)
+				value = (void *)((ulong) lpfc28_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc28_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc28_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc28_network_on != -1)
+				value = (void *)((ulong) lpfc28_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc28_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc28_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc28_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc28_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc28_ip_class != -1)
+				value = (void *)((ulong) lpfc28_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc28_ack0 != -1)
+				value = (void *)((ulong) lpfc28_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc28_topology != -1)
+				value = (void *)((ulong) lpfc28_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc28_scan_down != -1)
+				value = (void *)((ulong) lpfc28_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc28_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc28_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc28_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc28_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc28_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc28_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc28_check_cond_err != -1)
+				value = (void *)((ulong) lpfc28_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc28_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc28_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc28_link_speed != -1)
+				value = (void *)((ulong) lpfc28_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc28_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc28_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc28_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc28_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc28_fdmi_on != -1)
+				value = (void *)((ulong) lpfc28_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc28_max_lun != -1)
+				value = (void *)((ulong) lpfc28_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc28_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc28_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc28_max_target != -1)
+				value = (void *)((ulong) lpfc28_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc28_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc28_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc28_lun_skip != -1)
+				value = (void *)((ulong) lpfc28_lun_skip);
+			break;
+		}
+		break;
+	case 29:		/* HBA 29 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc29_log_verbose != -1)
+				value = (void *)((ulong) lpfc29_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc29_num_iocbs != -1)
+				value = (void *)((ulong) lpfc29_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc29_num_bufs != -1)
+				value = (void *)((ulong) lpfc29_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc29_automap != -1)
+				value = (void *)((ulong) lpfc29_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc29_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc29_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc29_cr_delay != -1)
+				value = (void *)((ulong) lpfc29_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc29_cr_count != -1)
+				value = (void *)((ulong) lpfc29_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc29_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc29_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc29_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc29_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc29_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc29_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc29_fcp_class != -1)
+				value = (void *)((ulong) lpfc29_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc29_use_adisc != -1)
+				value = (void *)((ulong) lpfc29_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc29_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc29_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc29_network_on != -1)
+				value = (void *)((ulong) lpfc29_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc29_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc29_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc29_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc29_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc29_ip_class != -1)
+				value = (void *)((ulong) lpfc29_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc29_ack0 != -1)
+				value = (void *)((ulong) lpfc29_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc29_topology != -1)
+				value = (void *)((ulong) lpfc29_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc29_scan_down != -1)
+				value = (void *)((ulong) lpfc29_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc29_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc29_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc29_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc29_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc29_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc29_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc29_check_cond_err != -1)
+				value = (void *)((ulong) lpfc29_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc29_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc29_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc29_link_speed != -1)
+				value = (void *)((ulong) lpfc29_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc29_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc29_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc29_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc29_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc29_fdmi_on != -1)
+				value = (void *)((ulong) lpfc29_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc29_max_lun != -1)
+				value = (void *)((ulong) lpfc29_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc29_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc29_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc29_max_target != -1)
+				value = (void *)((ulong) lpfc29_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc29_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc29_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc29_lun_skip != -1)
+				value = (void *)((ulong) lpfc29_lun_skip);
+			break;
+		}
+		break;
+	case 30:		/* HBA 30 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc30_log_verbose != -1)
+				value = (void *)((ulong) lpfc30_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc30_num_iocbs != -1)
+				value = (void *)((ulong) lpfc30_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc30_num_bufs != -1)
+				value = (void *)((ulong) lpfc30_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc30_automap != -1)
+				value = (void *)((ulong) lpfc30_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc30_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc30_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc30_cr_delay != -1)
+				value = (void *)((ulong) lpfc30_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc30_cr_count != -1)
+				value = (void *)((ulong) lpfc30_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc30_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc30_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc30_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc30_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc30_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc30_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc30_fcp_class != -1)
+				value = (void *)((ulong) lpfc30_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc30_use_adisc != -1)
+				value = (void *)((ulong) lpfc30_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc30_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc30_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc30_network_on != -1)
+				value = (void *)((ulong) lpfc30_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc30_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc30_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc30_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc30_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc30_ip_class != -1)
+				value = (void *)((ulong) lpfc30_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc30_ack0 != -1)
+				value = (void *)((ulong) lpfc30_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc30_topology != -1)
+				value = (void *)((ulong) lpfc30_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc30_scan_down != -1)
+				value = (void *)((ulong) lpfc30_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc30_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc30_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc30_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc30_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc30_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc30_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc30_check_cond_err != -1)
+				value = (void *)((ulong) lpfc30_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc30_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc30_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc30_link_speed != -1)
+				value = (void *)((ulong) lpfc30_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc30_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc30_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc30_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc30_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc30_fdmi_on != -1)
+				value = (void *)((ulong) lpfc30_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc30_max_lun != -1)
+				value = (void *)((ulong) lpfc30_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc30_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc30_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc30_max_target != -1)
+				value = (void *)((ulong) lpfc30_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc30_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc30_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc30_lun_skip != -1)
+				value = (void *)((ulong) lpfc30_lun_skip);
+			break;
+		}
+		break;
+	case 31:		/* HBA 31 */
+		switch (param) {
+		case ELX_CFG_LOG_VERBOSE:	/* log-verbose */
+			value = (void *)((ulong) lpfc_log_verbose);
+			if (lpfc31_log_verbose != -1)
+				value = (void *)((ulong) lpfc31_log_verbose);
+			break;
+		case ELX_CFG_NUM_IOCBS:	/* num-iocbs */
+			value = (void *)((ulong) lpfc_num_iocbs);
+			if (lpfc31_num_iocbs != -1)
+				value = (void *)((ulong) lpfc31_num_iocbs);
+			break;
+		case ELX_CFG_NUM_BUFS:	/* num-bufs */
+			value = (void *)((ulong) lpfc_num_bufs);
+			if (lpfc31_num_bufs != -1)
+				value = (void *)((ulong) lpfc31_num_bufs);
+			break;
+		case LPFC_CFG_AUTOMAP:	/* automap */
+			value = (void *)((ulong) lpfc_automap);
+			if (lpfc31_automap != -1)
+				value = (void *)((ulong) lpfc31_automap);
+			break;
+		case LPFC_CFG_BINDMETHOD:	/* bind-method */
+			value = (void *)((ulong) lpfc_fcp_bind_method);
+			if (lpfc31_fcp_bind_method != -1)
+				value =
+				    (void *)((ulong) lpfc31_fcp_bind_method);
+			break;
+		case LPFC_CFG_CR_DELAY:	/* cr_delay */
+			value = (void *)((ulong) lpfc_cr_delay);
+			if (lpfc31_cr_delay != -1)
+				value = (void *)((ulong) lpfc31_cr_delay);
+			break;
+		case LPFC_CFG_CR_COUNT:	/* cr_count */
+			value = (void *)((ulong) lpfc_cr_count);
+			if (lpfc31_cr_count != -1)
+				value = (void *)((ulong) lpfc31_cr_count);
+			break;
+		case ELX_CFG_DFT_TGT_Q_DEPTH:	/* tgt_queue_depth */
+			value = (void *)((ulong) lpfc_tgt_queue_depth);
+			if (lpfc31_tgt_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc31_tgt_queue_depth);
+			break;
+		case ELX_CFG_DFT_LUN_Q_DEPTH:	/* lun_queue_depth */
+			value = (void *)((ulong) lpfc_lun_queue_depth);
+			if (lpfc31_lun_queue_depth != -1)
+				value =
+				    (void *)((ulong) lpfc31_lun_queue_depth);
+			break;
+		case ELX_CFG_EXTRA_IO_TMO:	/* fcpfabric-tmo */
+			value = (void *)((ulong) lpfc_extra_io_tmo);
+			if (lpfc31_extra_io_tmo != -1)
+				value = (void *)((ulong) lpfc31_extra_io_tmo);
+			break;
+		case LPFC_CFG_FCP_CLASS:	/* fcp-class */
+			value = (void *)((ulong) lpfc_fcp_class);
+			if (lpfc31_fcp_class != -1)
+				value = (void *)((ulong) lpfc31_fcp_class);
+			break;
+		case LPFC_CFG_USE_ADISC:	/* use-adisc */
+			value = (void *)((ulong) lpfc_use_adisc);
+			if (lpfc31_use_adisc != -1)
+				value = (void *)((ulong) lpfc31_use_adisc);
+			break;
+		case ELX_CFG_NO_DEVICE_DELAY:	/* no-device-delay */
+			value = (void *)((ulong) lpfc_no_device_delay);
+			if (lpfc31_no_device_delay != -1)
+				value =
+				    (void *)((ulong) lpfc31_no_device_delay);
+			break;
+		case LPFC_CFG_NETWORK_ON:	/* network-on */
+			value = (void *)((ulong) lpfc_network_on);
+			if (lpfc31_network_on != -1)
+				value = (void *)((ulong) lpfc31_network_on);
+			break;
+		case LPFC_CFG_POST_IP_BUF:	/* post-ip-buf */
+			value = (void *)((ulong) lpfc_post_ip_buf);
+			if (lpfc31_post_ip_buf != -1)
+				value = (void *)((ulong) lpfc31_post_ip_buf);
+			break;
+		case LPFC_CFG_XMT_Q_SIZE:	/* xmt-que-size */
+			value = (void *)((ulong) lpfc_xmt_que_size);
+			if (lpfc31_xmt_que_size != -1)
+				value = (void *)((ulong) lpfc31_xmt_que_size);
+			break;
+		case LPFC_CFG_IP_CLASS:	/* ip-class */
+			value = (void *)((ulong) lpfc_ip_class);
+			if (lpfc31_ip_class != -1)
+				value = (void *)((ulong) lpfc31_ip_class);
+			break;
+		case LPFC_CFG_ACK0:	/* ack0 */
+			value = (void *)((ulong) lpfc_ack0);
+			if (lpfc31_ack0 != -1)
+				value = (void *)((ulong) lpfc31_ack0);
+			break;
+		case LPFC_CFG_TOPOLOGY:	/* topology */
+			value = (void *)((ulong) lpfc_topology);
+			if (lpfc31_topology != -1)
+				value = (void *)((ulong) lpfc31_topology);
+			break;
+		case LPFC_CFG_SCAN_DOWN:	/* scan-down */
+			value = (void *)((ulong) lpfc_scan_down);
+			if (lpfc31_scan_down != -1)
+				value = (void *)((ulong) lpfc31_scan_down);
+			break;
+		case ELX_CFG_LINKDOWN_TMO:	/* linkdown-tmo */
+			value = (void *)((ulong) lpfc_linkdown_tmo);
+			if (lpfc31_linkdown_tmo != -1)
+				value = (void *)((ulong) lpfc31_linkdown_tmo);
+			break;
+		case ELX_CFG_HOLDIO:	/* nodev-holdio */
+			value = (void *)((ulong) lpfc_nodev_holdio);
+			if (lpfc31_nodev_holdio != -1)
+				value = (void *)((ulong) lpfc31_nodev_holdio);
+			break;
+		case ELX_CFG_DELAY_RSP_ERR:	/* delay-rsp-err */
+			value = (void *)((ulong) lpfc_delay_rsp_err);
+			if (lpfc31_delay_rsp_err != -1)
+				value = (void *)((ulong) lpfc31_delay_rsp_err);
+			break;
+		case ELX_CFG_CHK_COND_ERR:	/* check-cond-err */
+			value = (void *)((ulong) lpfc_check_cond_err);
+			if (lpfc31_check_cond_err != -1)
+				value = (void *)((ulong) lpfc31_check_cond_err);
+			break;
+		case ELX_CFG_NODEV_TMO:	/* nodev-tmo */
+			value = (void *)((ulong) lpfc_nodev_tmo);
+			if (lpfc31_nodev_tmo != -1)
+				value = (void *)((ulong) lpfc31_nodev_tmo);
+			break;
+		case LPFC_CFG_LINK_SPEED:	/* link-speed */
+			value = (void *)((ulong) lpfc_link_speed);
+			if (lpfc31_link_speed != -1)
+				value = (void *)((ulong) lpfc31_link_speed);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_TIME:	/* dqfull-throttle-up-time */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_time);
+			if (lpfc31_dqfull_throttle_up_time != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc31_dqfull_throttle_up_time);
+			break;
+		case ELX_CFG_DQFULL_THROTTLE_UP_INC:	/* dqfull-throttle-up-inc */
+			value = (void *)((ulong) lpfc_dqfull_throttle_up_inc);
+			if (lpfc31_dqfull_throttle_up_inc != -1)
+				value =
+				    (void *)((ulong)
+					     lpfc31_dqfull_throttle_up_inc);
+			break;
+		case LPFC_CFG_FDMI_ON:	/* fdmi-on */
+			value = (void *)((ulong) lpfc_fdmi_on);
+			if (lpfc31_fdmi_on != -1)
+				value = (void *)((ulong) lpfc31_fdmi_on);
+			break;
+		case ELX_CFG_MAX_LUN:	/* max-lun */
+			value = (void *)((ulong) lpfc_max_lun);
+			if (lpfc31_max_lun != -1)
+				value = (void *)((ulong) lpfc31_max_lun);
+			break;
+		case LPFC_CFG_DISC_THREADS:	/* discovery-threads */
+			value = (void *)((ulong) lpfc_discovery_threads);
+			if (lpfc31_discovery_threads != -1)
+				value =
+				    (void *)((ulong) lpfc31_discovery_threads);
+			break;
+		case LPFC_CFG_MAX_TARGET:	/* max-target */
+			value = (void *)((ulong) lpfc_max_target);
+			if (lpfc31_max_target != -1)
+				value = (void *)((ulong) lpfc31_max_target);
+			break;
+		case LPFC_CFG_SCSI_REQ_TMO:	/* scsi-req-tmo */
+			value = (void *)((ulong) lpfc_scsi_req_tmo);
+			if (lpfc31_scsi_req_tmo != -1)
+				value = (void *)((ulong) lpfc31_scsi_req_tmo);
+			break;
+		case ELX_CFG_LUN_SKIP:	/* lun-skip */
+			value = (void *)((ulong) lpfc_lun_skip);
+			if (lpfc31_lun_skip != -1)
+				value = (void *)((ulong) lpfc31_lun_skip);
+			break;
+		}
+		break;
+	default:
+		break;
+	}
+	return (value);
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+static struct pci_device_id lpfc_id_table[] __devinitdata = {
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_VIPER, PCI_ANY_ID, PCI_ANY_ID, 0,
+	 0, 0UL},
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_THOR, PCI_ANY_ID, PCI_ANY_ID, 0, 0,
+	 0UL},
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_PEGASUS, PCI_ANY_ID, PCI_ANY_ID, 0,
+	 0, 0UL},
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_CENTAUR, PCI_ANY_ID, PCI_ANY_ID, 0,
+	 0, 0UL},
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_DRAGONFLY, PCI_ANY_ID, PCI_ANY_ID,
+	 0, 0, 0UL},
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_SUPERFLY, PCI_ANY_ID, PCI_ANY_ID,
+	 0, 0, 0UL},
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_RFLY, PCI_ANY_ID, PCI_ANY_ID, 0, 0,
+	 0UL},
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_PFLY, PCI_ANY_ID, PCI_ANY_ID, 0, 0,
+	 0UL},
+	{PCI_VENDOR_ID_EMULEX, PCI_DEVICE_ID_TFLY, PCI_ANY_ID, PCI_ANY_ID, 0, 0,
+	 0UL},
+	{0, 0, 0, 0, 0, 0, 0UL},
+};
+
+MODULE_DEVICE_TABLE(pci, lpfc_id_table);
+
+static int __devinit
+lpfc_pci_detect(struct pci_dev *pdev, const struct pci_device_id *pid)
+{
+	int instance;
+
+	if (lpfc_instcnt == MAX_ELX_BRDS)
+		return -EPERM;	/* Only MAX_ELX_BRDS permitted */
+	for (instance = 0; instance < MAX_ELX_BRDS; instance++) {
+		if (lpfc_instance[instance] == -1)
+			break;
+	}
+
+	if (pci_enable_device(pdev))
+		return -ENODEV;
+	if (pci_request_regions(pdev, LPFC_DRIVER_NAME)) {
+		printk("lpfc PCI I/O region is already in use.\n");
+		printk("a driver for lpfc is already loaded on this system.\n");
+		return -ENODEV;
+	}
+	if (lpfc_linux_attach(instance, &driver_template, pdev)) {
+		pci_release_regions(pdev);
+		return -ENODEV;
+	}
+	return 0;
+}
+
+static void __devexit
+lpfc_pci_release(struct pci_dev *pdev)
+{
+	struct Scsi_Host *host;
+	elxHBA_t *phba;
+	int instance;
+
+	host = pci_get_drvdata(pdev);
+	phba = (elxHBA_t *) host->hostdata[0];
+	instance = phba->brd_no;
+
+	/*
+	 *  detach the board
+	 */
+	lpfc_linux_detach(instance);
+
+	pci_set_drvdata(pdev, NULL);
+}
+
+static struct pci_driver
+ lpfc_driver = {
+	.name = LPFC_DRIVER_NAME,
+	.id_table = lpfc_id_table,
+	.probe = lpfc_pci_detect,
+	.remove = __devexit_p(lpfc_pci_release),
+};
+
+static int __init
+lpfc_init(void)
+{
+	int rc, i;
+
+	printk("Emulex LightPulse FC SCSI/IP: %s    Osgt: %s\n",
+	       lpfc_release_version, OSGT_DRIVER_VERSION);
+	memset((char *)&elxDRVR, 0, sizeof (elxDRVR_t));
+	memset((char *)&lpfcdrvr, 0, sizeof (LINUX_DRVR_t));
+	elxDRVR.pDrvrOSEnv = &lpfcdrvr;
+	for (i = 0; i < MAX_ELX_BRDS; i++) {
+		lpfc_instance[i] = -1;
+	}
+
+	/* Initialize all per Driver locks */
+	elx_clk_init_lock(0);
+
+	rc = pci_module_init(&lpfc_driver);
+
+	if (lpfc_instcnt) {
+		lpfc_diag_init();
+		/* This covers the case where the lpfn driver gets loaded before the
+		 * lpfc driver detect completes.
+		 *  */
+		if (lpfc_detect_called == LPFN_PROBE_PENDING) {
+			if (lpfn_probe != NULL)
+				lpfn_probe();
+		}
+		lpfc_detect_called = TRUE;
+	}
+	return rc;
+
+}
+
+static void __exit
+lpfc_exit(void)
+{
+	pci_unregister_driver(&lpfc_driver);
+	lpfc_diag_uninit();
+}
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+#include "scsi_module.c"
+#else
+module_init(lpfc_init);
+module_exit(lpfc_exit);
+#endif
+MODULE_LICENSE("GPL");
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfcLINUXlan.c linux-2.6.3/drivers/scsi/lpfc/lpfcLINUXlan.c
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfcLINUXlan.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfcLINUXlan.c	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,463 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef EXPORT_SYMTAB
+#define EXPORT_SYMTAB
+#endif
+
+#include <linux/version.h>
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/types.h>
+#include <linux/fcntl.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/in.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+#include <linux/blk.h>
+#else
+#include <linux/blkdev.h>
+#endif
+#include <linux/string.h>
+#include <linux/ioport.h>
+#include <linux/pci.h>
+#include <linux/unistd.h>
+#include <linux/timex.h>
+#include <linux/timer.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/if_arp.h>
+#include <asm/system.h>
+#include <asm/bitops.h>
+#include <asm/io.h>
+#include <asm/dma.h>
+#include <asm/irq.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,3,17)
+#include <linux/spinlock.h>
+#else
+#include <asm/spinlock.h>
+#endif
+#include <linux/smp.h>
+#include <asm/byteorder.h>
+
+#include <linux/module.h>
+extern int lpfn_probe(void);
+
+/* lpfcLINUXlan.c IP interface network driver */
+
+#include "elx_os.h"
+#include "prod_os.h"
+#include "elx_util.h"
+#include "elx_clock.h"
+#include "elx_hw.h"
+#include "elx_sli.h"
+#include "elx_mem.h"
+#include "elx_sched.h"
+#include "elx.h"
+#include "elx_logmsg.h"
+#include "elx_disc.h"
+#include "elx_scsi.h"
+#include "elx_crtn.h"
+#include "elx_cfgparm.h"
+#include "lpfc_hba.h"
+#include "lpfc_ip.h"
+#include "lpfc_crtn.h"
+#include "prod_crtn.h"
+
+MODULE_DESCRIPTION("Emulex LightPulse Fibre Channel driver - Open Source");
+MODULE_AUTHOR("Emulex Corporation - tech.support@emulex.com");
+
+#ifndef LPFN_DRIVER_VERSION
+#define LPFN_DRIVER_VERSION "2.10a"
+#endif				/* LPFC_DRIVER_VERSION */
+
+char *lpfn_release_version = LPFN_DRIVER_VERSION;
+
+/* IP / ARP layer */
+extern int arp_find(unsigned char *, struct sk_buff *);
+
+/* lpfcdd driver entry points */
+extern int lpfc_xmit(elxHBA_t *, struct sk_buff *);
+extern int lpfc_ipioctl(int, void *);
+
+void lpfn_receive(elxHBA_t *, void *, uint32_t);
+#ifdef MODVERSIONS
+EXPORT_SYMBOL(lpfn_receive);
+#else
+EXPORT_SYMBOL_NOVERS(lpfn_receive);
+#endif				/* MODVERSIONS */
+
+int lpfn_probe(void);
+#ifdef MODVERSIONS
+EXPORT_SYMBOL(lpfn_probe);
+#else
+EXPORT_SYMBOL_NOVERS(lpfn_probe);
+#endif				/* MODVERSIONS */
+
+static int
+lpfn_open(NETDEVICE * dev)
+{
+	elxHBA_t *phba;
+	LPFCHBA_t *plhba;
+
+	if ((phba = (elxHBA_t *) (dev->priv)) == 0) {
+		return (-ENODEV);
+	}
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plhba->fc_open_count |= FC_LAN_OPEN;
+
+	netdevice_start(dev);
+	netif_start_queue(dev);
+
+	return 0;
+}
+
+static int
+lpfn_close(NETDEVICE * dev)
+{
+	elxHBA_t *phba;
+	LPFCHBA_t *plhba;
+
+	if ((phba = (elxHBA_t *) (dev->priv)) == 0) {
+		return (-ENODEV);
+	}
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plhba->fc_open_count &= ~FC_LAN_OPEN;
+
+	netdevice_stop(dev);
+	netif_stop_queue(dev);
+
+	return 0;
+}
+
+static int
+lpfn_change_mtu(NETDEVICE * dev, int new_mtu)
+{
+	elxHBA_t *phba;
+	LPFCHBA_t *plhba;
+
+	if ((phba = (elxHBA_t *) (dev->priv)) == 0) {
+		return (-ENODEV);
+	}
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if ((new_mtu < FC_MIN_MTU) || (new_mtu > plhba->lpfn_max_mtu))
+		return -EINVAL;
+	dev->mtu = new_mtu;
+	return (0);
+}
+
+/******************************************************************************
+* Function name : lpfn_header
+*
+* Description   : Create the FC MAC/LLC/SNAP header for an arbitrary protocol 
+*                 layer
+*              saddr=NULL   means use device source address
+*              daddr=NULL   means leave destination address (eg unresolved arp)
+* 
+******************************************************************************/
+
+static int
+lpfn_header(struct sk_buff *skb,
+	    NETDEVICE * dev,
+	    unsigned short type, void *daddr, void *saddr, unsigned len)
+{
+	LPFC_IPHDR_t *fchdr;
+	int rc;
+
+	if (type == ETH_P_IP || type == ETH_P_ARP) {
+		fchdr = (LPFC_IPHDR_t *) skb_push(skb, sizeof (LPFC_IPHDR_t));
+
+		fchdr->llc.dsap = FC_LLC_DSAP;	/* DSAP                    */
+		fchdr->llc.ssap = FC_LLC_SSAP;	/* SSAP                    */
+		fchdr->llc.ctrl = FC_LLC_CTRL;	/* control field           */
+		fchdr->llc.prot_id[0] = 0;	/* protocol id             */
+		fchdr->llc.prot_id[1] = 0;	/* protocol id             */
+		fchdr->llc.prot_id[2] = 0;	/* protocol id             */
+		fchdr->llc.type = htons(type);	/* type field              */
+		rc = sizeof (LPFC_IPHDR_t);
+	} else {
+		fchdr = (LPFC_IPHDR_t *) skb_push(skb, sizeof (LPFC_IPHDR_t));
+		rc = sizeof (LPFC_IPHDR_t);
+	}
+
+	/* Set the source and destination hardware addresses */
+	if (saddr != NULL)
+		memcpy(fchdr->fcnet.fc_srcname.IEEE, saddr, dev->addr_len);
+	else
+		memcpy(fchdr->fcnet.fc_srcname.IEEE, dev->dev_addr,
+		       dev->addr_len);
+
+	fchdr->fcnet.fc_srcname.nameType = NAME_IEEE;	/* IEEE name */
+	fchdr->fcnet.fc_srcname.IEEEextMsn = 0;
+	fchdr->fcnet.fc_srcname.IEEEextLsb = 0;
+
+	if (daddr != NULL) {
+		memcpy(fchdr->fcnet.fc_destname.IEEE, daddr, dev->addr_len);
+		fchdr->fcnet.fc_destname.nameType = NAME_IEEE;	/* IEEE name */
+		fchdr->fcnet.fc_destname.IEEEextMsn = 0;
+		fchdr->fcnet.fc_destname.IEEEextLsb = 0;
+		return (rc);
+	}
+	return (-rc);
+}
+
+/******************************************************************************
+* Function name : lpfn_rebuild_header
+*
+* Description   : Rebuild the FC MAC/LLC/SNAP header. 
+*                 This is called after an ARP (or in future other address 
+*                 resolution) has completed on this sk_buff.  
+*                 We now let ARP fill in the other fields.
+******************************************************************************/
+
+static int
+lpfn_rebuild_header(struct sk_buff *skb)
+{
+	LPFC_IPHDR_t *fchdr = (LPFC_IPHDR_t *) skb->data;
+	NETDEVICE *dev = skb->dev;
+
+	if (fchdr->llc.type == htons(ETH_P_IP)) {
+		return arp_find(fchdr->fcnet.fc_destname.IEEE, skb);
+	}
+
+	memcpy(fchdr->fcnet.fc_srcname.IEEE, dev->dev_addr, dev->addr_len);
+	fchdr->fcnet.fc_srcname.nameType = NAME_IEEE;	/* IEEE name */
+	fchdr->fcnet.fc_srcname.IEEEextMsn = 0;
+	fchdr->fcnet.fc_srcname.IEEEextLsb = 0;
+
+	return (0);
+}
+
+/******************************************************************************
+* Function name : lpfn_xmit
+*
+* Description   : 
+* 
+******************************************************************************/
+
+static int
+lpfn_xmit(struct sk_buff *skb, NETDEVICE * dev)
+{
+	elxHBA_t *phba;
+	int rc;
+
+	if ((phba = (elxHBA_t *) (dev->priv)) == 0) {
+		return (-ENODEV);
+	}
+
+	rc = lpfc_xmit(phba, skb);
+	return rc;
+}
+
+void
+lpfn_coalesce_skbuff(elxHBA_t * phba, void *ip_buff, uint32_t pktsize)
+{
+	LPFCHBA_t *plhba;
+	struct sk_buff *new_skb, *tmp_skb;
+	uint8_t *new_buff;
+	DMABUFIP_t *tmp_ip_buff;
+	uint32_t tmp_length;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if (pktsize <= plhba->lpfn_rcv_buf_size)
+		return;
+
+	/* Allocate big skb */
+
+	new_skb = alloc_skb(pktsize, GFP_ATOMIC);
+	if (!new_skb) {
+		/* 
+		   free all the sk_buffs and return . 
+		   This will cause the packet to be dropped 
+		 */
+		tmp_ip_buff = (DMABUFIP_t *) ip_buff;
+		while (tmp_ip_buff) {
+			tmp_skb = (struct sk_buff *)tmp_ip_buff->ipbuf;
+			tmp_ip_buff->ipbuf = NULL;
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+			if (in_irq()) {
+				dev_kfree_skb_irq(tmp_skb);
+			} else {
+				dev_kfree_skb(tmp_skb);
+			}
+#else
+			dev_kfree_skb(tmp_skb);
+#endif
+			tmp_ip_buff = (DMABUFIP_t *) tmp_ip_buff->dma.next;
+		}
+		return;
+	}
+
+	new_buff = new_skb->data;
+	tmp_ip_buff = (DMABUFIP_t *) ip_buff;
+	tmp_length = 0;
+	while (tmp_ip_buff) {
+		tmp_skb = (struct sk_buff *)tmp_ip_buff->ipbuf;
+		tmp_ip_buff->ipbuf = NULL;
+		memcpy(new_buff, tmp_skb->data, tmp_skb->len);
+		new_buff += tmp_skb->len;
+		tmp_length += tmp_skb->len;
+		tmp_ip_buff = (DMABUFIP_t *) tmp_ip_buff->dma.next;
+
+		/* Free the skb here */
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,0)
+		if (in_irq()) {
+			dev_kfree_skb_irq(tmp_skb);
+		} else {
+			dev_kfree_skb(tmp_skb);
+		}
+#else
+		dev_kfree_skb(tmp_skb);
+#endif
+
+	}
+
+	tmp_ip_buff = (DMABUFIP_t *) ip_buff;
+	new_skb->len = pktsize;
+	tmp_ip_buff->ipbuf = (void *)new_skb;
+
+	return;
+}
+
+void
+lpfn_receive(elxHBA_t * phba, void *ip_buff, uint32_t pktsize)
+{
+	LPFCHBA_t *plhba;
+	NETDEVICE *dev;
+	struct sk_buff *skb;
+	LPFC_IPHDR_t *fchdr;
+	struct ethhdr *eth;
+	unsigned short *sp;
+
+	lpfn_coalesce_skbuff(phba, ip_buff, pktsize);
+
+	skb = (struct sk_buff *)(((DMABUFIP_t *) ip_buff)->ipbuf);
+
+	if (!skb)
+		return;
+
+	fchdr = (LPFC_IPHDR_t *) skb->data;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	dev = plhba->lpfn_dev;
+	skb->dev = dev;
+
+	skb->mac.raw = fchdr->fcnet.fc_destname.IEEE;
+	sp = (unsigned short *)fchdr->fcnet.fc_srcname.IEEE;
+	*(sp - 1) = *sp;
+	sp++;
+	*(sp - 1) = *sp;
+	sp++;
+	*(sp - 1) = *sp;
+
+	skb_pull(skb, dev->hard_header_len);
+	eth = skb->mac.ethernet;
+
+	if (*eth->h_dest & 1) {
+		if (memcmp(eth->h_dest, dev->broadcast, ETH_ALEN) == 0)
+			skb->pkt_type = PACKET_BROADCAST;
+		else
+			skb->pkt_type = PACKET_MULTICAST;
+	}
+
+	else if (dev->flags & (IFF_PROMISC)) {
+		if (memcmp(eth->h_dest, dev->dev_addr, ETH_ALEN))
+			skb->pkt_type = PACKET_OTHERHOST;
+	}
+
+	skb->protocol = fchdr->llc.type;
+
+	if (skb->protocol == ntohs(ETH_P_ARP))
+		skb->data[1] = 0x06;
+
+	netif_rx(skb);
+}
+
+static struct net_device_stats *
+lpfn_get_stats(NETDEVICE * dev)
+{
+	elxHBA_t *phba;
+	LINUX_HBA_t *plxhba;
+	struct net_device_stats *stats;
+	LPFCHBA_t *plhba;
+
+	phba = (elxHBA_t *) dev->priv;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	stats = &plxhba->ndstats;
+	if (plhba && plhba->ip_stat) {
+		stats->rx_packets = plhba->ip_stat->lpfn_ipackets_lsw;
+		stats->tx_packets = plhba->ip_stat->lpfn_opackets_lsw;
+		stats->rx_bytes = plhba->ip_stat->lpfn_rcvbytes_lsw;
+		stats->tx_bytes = plhba->ip_stat->lpfn_xmtbytes_lsw;
+		stats->rx_errors = plhba->ip_stat->lpfn_ierrors;
+		stats->tx_errors = plhba->ip_stat->lpfn_oerrors;
+		stats->rx_dropped = plhba->ip_stat->lpfn_rx_dropped;
+		stats->tx_dropped = plhba->ip_stat->lpfn_tx_dropped;
+	}
+	return (stats);
+}
+
+int
+lpfn_init(void)
+{
+	printk("Emulex LightPulse FC IP %s\n", lpfn_release_version);
+	return lpfn_probe();
+}
+
+module_init(lpfn_init);
+
+int
+lpfn_probe(void)
+{
+	struct lpfn_probe lp;
+
+	lp.hard_start_xmit = &lpfn_xmit;
+	lp.receive = &lpfn_receive;
+	lp.get_stats = &lpfn_get_stats;
+	lp.open = &lpfn_open;
+	lp.stop = &lpfn_close;
+	lp.hard_header = &lpfn_header;
+	lp.rebuild_header = &lpfn_rebuild_header;
+	lp.change_mtu = &lpfn_change_mtu;
+	lp.probe = &lpfn_probe;
+	if (lpfc_ipioctl(LPFN_PROBE, (void *)&lp) == 0)
+		return (-ENODEV);
+
+	return (0);
+}
+
+void
+lpfn_exit(void)
+{
+	lpfc_ipioctl(LPFN_DETACH, 0);
+}
+
+module_exit(lpfn_exit);
+MODULE_LICENSE("GPL");
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_cfgparm.h linux-2.6.3/drivers/scsi/lpfc/lpfc_cfgparm.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_cfgparm.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_cfgparm.h	2004-02-27 19:18:51.000000000 +0100
@@ -0,0 +1,342 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_LPFC_CFGPARAM
+#define _H_LPFC_CFGPARAM
+
+#define LPFC_DFT_POST_IP_BUF            128
+#define LPFC_MIN_POST_IP_BUF            64
+#define LPFC_MAX_POST_IP_BUF            1024
+#define LPFC_DFT_XMT_QUE_SIZE           256
+#define LPFC_MIN_XMT_QUE_SIZE           128
+#define LPFC_MAX_XMT_QUE_SIZE           10240
+#define LPFC_DFT_NUM_IOCBS              256
+#define LPFC_MIN_NUM_IOCBS              128
+#define LPFC_MAX_NUM_IOCBS              10240
+#define LPFC_DFT_NUM_BUFS               128
+#define LPFC_MIN_NUM_BUFS               64
+#define LPFC_MAX_NUM_BUFS               4096
+#define LPFC_DFT_NUM_NODES              510
+#define LPFC_MIN_NUM_NODES              64
+#define LPFC_MAX_NUM_NODES              4096
+#define LPFC_DFT_TOPOLOGY               0
+#define LPFC_DFT_FC_CLASS               3
+
+#define LPFC_DFT_NO_DEVICE_DELAY        1	/* 1 sec */
+#define LPFC_MAX_NO_DEVICE_DELAY        30	/* 30 sec */
+#define LPFC_DFT_EXTRA_IO_TIMEOUT       0
+#define LPFC_MAX_EXTRA_IO_TIMEOUT       255	/* 255 sec */
+#define LPFC_DFT_LNKDWN_TIMEOUT         30
+#define LPFC_MAX_LNKDWN_TIMEOUT         255	/* 255 sec */
+#define LPFC_DFT_NODEV_TIMEOUT          30
+#define LPFC_MAX_NODEV_TIMEOUT          255	/* 255 sec */
+#define LPFC_DFT_RSCN_NS_DELAY          0
+#define LPFC_MAX_RSCN_NS_DELAY          255	/* 255 sec */
+
+#define LPFC_MAX_HBA_Q_DEPTH            10240	/* max cmds allowed per hba */
+#define LPFC_DFT_HBA_Q_DEPTH            2048	/* max cmds per hba */
+#define LPFC_LC_HBA_Q_DEPTH             1024	/* max cmds per low cost hba */
+#define LPFC_LP101_HBA_Q_DEPTH          128	/* max cmds per low cost hba */
+
+#define LPFC_MAX_TGT_Q_DEPTH            10240	/* max cmds allowed per tgt */
+#define LPFC_DFT_TGT_Q_DEPTH            0	/* default max cmds per tgt */
+
+#define LPFC_MAX_LUN_Q_DEPTH            128	/* max cmds to allow per lun */
+#define LPFC_DFT_LUN_Q_DEPTH            30	/* default max cmds per lun */
+
+#define LPFC_MAX_DQFULL_THROTTLE        1	/* Boolean (max value) */
+
+#define LPFC_MAX_DISC_THREADS           64	/* max outstanding discovery els requests */
+#define LPFC_DFT_DISC_THREADS           1	/* default outstanding discovery els requests */
+
+#define LPFC_MAX_NS_RETRY               3	/* Try to get to the NameServer 3 times and then give up. */
+
+#define LPFC_MAX_SCSI_REQ_TMO           255	/* Max timeout value for SCSI passthru requests */
+#define LPFC_DFT_SCSI_REQ_TMO           30	/* Default timeout value for SCSI passthru requests */
+
+#define LPFC_MAX_TARGET                 255	/* max nunber of targets supported */
+#define LPFC_DFT_MAX_TARGET             255	/* default max number of targets supported */
+
+/* LPFC specific parameters start at ELX_CORE_NUM_OF_CFG_PARAM */
+#define LPFC_CFG_AUTOMAP          ELX_CORE_NUM_OF_CFG_PARAM + 0	/* automap */
+#define LPFC_CFG_FCP_CLASS        ELX_CORE_NUM_OF_CFG_PARAM + 1	/* fcp-class */
+#define LPFC_CFG_USE_ADISC        ELX_CORE_NUM_OF_CFG_PARAM + 2	/* use-adisc */
+#define LPFC_CFG_NETWORK_ON       ELX_CORE_NUM_OF_CFG_PARAM + 3	/* network-on */
+#define LPFC_CFG_POST_IP_BUF      ELX_CORE_NUM_OF_CFG_PARAM + 4	/* post-ip-buf */
+#define LPFC_CFG_XMT_Q_SIZE       ELX_CORE_NUM_OF_CFG_PARAM + 5	/* xmt-que-size */
+#define LPFC_CFG_IP_CLASS         ELX_CORE_NUM_OF_CFG_PARAM + 6	/* ip-class */
+#define LPFC_CFG_ACK0             ELX_CORE_NUM_OF_CFG_PARAM + 7	/* ack0 */
+#define LPFC_CFG_TOPOLOGY         ELX_CORE_NUM_OF_CFG_PARAM + 8	/* topology */
+#define LPFC_CFG_SCAN_DOWN        ELX_CORE_NUM_OF_CFG_PARAM + 9	/* scan-down */
+#define LPFC_CFG_LINK_SPEED       ELX_CORE_NUM_OF_CFG_PARAM + 10	/* link-speed */
+#define LPFC_CFG_CR_DELAY         ELX_CORE_NUM_OF_CFG_PARAM + 11	/* cr-delay */
+#define LPFC_CFG_CR_COUNT         ELX_CORE_NUM_OF_CFG_PARAM + 12	/* cr-count */
+#define LPFC_CFG_FDMI_ON          ELX_CORE_NUM_OF_CFG_PARAM + 13	/* fdmi-on-count */
+#define LPFC_CFG_BINDMETHOD       ELX_CORE_NUM_OF_CFG_PARAM + 14	/* fcp-bind-method */
+#define LPFC_CFG_DISC_THREADS     ELX_CORE_NUM_OF_CFG_PARAM + 15	/* discovery-threads */
+#define LPFC_CFG_SCSI_REQ_TMO     ELX_CORE_NUM_OF_CFG_PARAM + 16	/* timeout value for SCSI passtru */
+
+#define LPFC_CFG_MAX_TARGET       ELX_CORE_NUM_OF_CFG_PARAM + 17	/* max-target */
+
+#define LPFC_NUM_OF_CFG_PARAM     18
+
+/* Note: The following define LPFC_TOTAL_NUM_OF_CFG_PARAM represents the total number
+         of user configuration params. This define is used to specify the number 
+         of entries in the array lpfc_icfgparam[].
+ */
+#define LPFC_TOTAL_NUM_OF_CFG_PARAM  ELX_CORE_NUM_OF_CFG_PARAM + LPFC_NUM_OF_CFG_PARAM
+
+/* The order of the icfgparam[] entries must match that of ELX_CORE_CFG defs */
+#ifdef LPFC_DEF_ICFG
+iCfgParam lpfc_icfgparam[LPFC_TOTAL_NUM_OF_CFG_PARAM] = {
+
+	/* general driver parameters */
+	{"log_verbose",
+	 0, 0xffff, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Verbose logging bit-mask"},
+
+	{"log-only",
+	 0, 1, 1, 0,
+	 (ushort) (CFG_IGNORE),
+	 (ushort) CFG_DYNAMIC,
+	 "Log messages to system logger only, not console"},
+
+	{"num_iocbs",
+	 LPFC_MIN_NUM_IOCBS, LPFC_MAX_NUM_IOCBS, LPFC_DFT_NUM_IOCBS, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Number of outstanding IOCBs driver can queue to adapter"},
+
+	{"num_bufs",
+	 LPFC_MIN_NUM_BUFS, LPFC_MAX_NUM_BUFS, LPFC_DFT_NUM_BUFS, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Number of buffers driver uses for ELS commands and Buffer Pointer Lists."},
+
+	{"tgt_queue_depth",
+	 0, LPFC_MAX_TGT_Q_DEPTH, LPFC_DFT_TGT_Q_DEPTH, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Max number of FCP commands we can queue to a specific target"},
+
+	{"lun_queue_depth",
+	 1, LPFC_MAX_LUN_Q_DEPTH, LPFC_DFT_LUN_Q_DEPTH, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Max number of FCP commands we can queue to a specific LUN"},
+
+	{"extra_io_tmo",
+	 0, LPFC_MAX_EXTRA_IO_TIMEOUT, 0, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Extra FCP command timeout"},
+
+	{"first-check",
+	 0, 1,
+	 FALSE,
+	 0,
+	 (ushort) EXPORT_AIX,
+	 (ushort) CFG_DYNAMIC,
+	 "Retry the first 29xx check condition for FCP devices during discovery"},
+
+	{"no_device_delay",
+	 0, LPFC_MAX_NO_DEVICE_DELAY, LPFC_DFT_NO_DEVICE_DELAY, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Length of interval in seconds for FCP device I/O failure"},
+
+	{"linkdown_tmo",
+	 0, LPFC_MAX_LNKDWN_TIMEOUT, LPFC_DFT_LNKDWN_TIMEOUT, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Seconds driver will wait before deciding link is really down"},
+
+	{"nodev_holdio",
+	 0, 1, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Hold I/O errors if device disappears "},
+
+	{"delay_rsp_err",
+	 0, 1, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Delay FCP error return for FCP RSP error and Check Condition"},
+
+	{"check_cond_err",
+	 0, 1, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Treat special Check Conditions as a FCP error"},
+
+	{"nodev_tmo",
+	 0, LPFC_MAX_NODEV_TIMEOUT, LPFC_DFT_NODEV_TIMEOUT, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Seconds driver will hold I/O waiting for a device to come back"},
+
+	{"dqfull_throttle_up_time",
+	 0, 30, 1, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "When to increment the current Q depth "},
+
+	{"dqfull_throttle_up_inc",
+	 0, LPFC_MAX_LUN_Q_DEPTH, 1, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Increment the current Q depth by dqfull-throttle-up-inc"},
+
+	{"max_lun",
+	 0, 256, 256, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "The maximun LUN number a target can support"},
+
+	{"hba_queue_depth",
+	 0, LPFC_MAX_HBA_Q_DEPTH, 0, 0,
+	 (ushort) (CFG_IGNORE),
+	 (ushort) CFG_RESTART,
+	 "Max number of FCP commands we can queue to a specific HBA"},
+
+	{"lun_skip",
+	 0, 1, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Enable SCSI layer to scan past lun holes"},
+
+	/* Start of product specific (lpfc) config params */
+
+	{"automap",
+	 0, 1, 1, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Automatically bind FCP devices as they are discovered"},
+
+	{"fcp_class",
+	 2, 3, LPFC_DFT_FC_CLASS, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Select Fibre Channel class of service for FCP sequences"},
+
+	{"use_adisc",
+	 0, 1, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Use ADISC on rediscovery to authenticate FCP devices"},
+
+	/* IP specific parameters */
+	{"network-on",
+	 0, 1, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_REBOOT,
+	 "Enable IP processing"},
+
+	{"post-ip-buf",
+	 LPFC_MIN_POST_IP_BUF, LPFC_MAX_POST_IP_BUF, LPFC_DFT_POST_IP_BUF, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Number of IP buffers to post to adapter"},
+
+	{"xmt-que-size",
+	 LPFC_MIN_XMT_QUE_SIZE, LPFC_MAX_XMT_QUE_SIZE, LPFC_DFT_XMT_QUE_SIZE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Number of outstanding IP cmds for an adapter"},
+
+	{"ip-class",
+	 2, 3, LPFC_DFT_FC_CLASS, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Select Fibre Channel class of service for IP sequences"},
+
+	/* Fibre Channel specific parameters */
+	{"ack0",
+
+	 0, 1, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Enable ACK0 support"},
+
+	{"topology",
+	 0, 6, LPFC_DFT_TOPOLOGY, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Select Fibre Channel topology"},
+
+	{"scan-down",
+	 0, 1, 1, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Start scanning for devices from highest ALPA to lowest"},
+
+	{"link_speed",
+	 0, 2, 0, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Select link speed"},
+
+	{"cr_delay",
+	 0, 63, 0, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "A count of milliseconds after which an interrupt response is generated"},
+
+	{"cr_count",
+	 1, 255, 1, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "A count of I/O completions after which an interrupt response is generated"},
+
+	{"fdmi_on",
+	 0, 2, FALSE, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Enable FDMI support"},
+
+	{"fcp_bind_method",
+	 1, 4, 2, 2,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Select the bind method to be used."},
+
+	{"discovery_threads",
+	 1, LPFC_MAX_DISC_THREADS, LPFC_DFT_DISC_THREADS, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "Maximum number of ELS commands during discovery"},
+
+	{"scsi_req_tmo",
+	 0, LPFC_MAX_SCSI_REQ_TMO, LPFC_DFT_SCSI_REQ_TMO, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_DYNAMIC,
+	 "Timeout value for SCSI passthru requests"},
+
+	{"max_target",
+	 0, LPFC_MAX_TARGET, LPFC_DFT_MAX_TARGET, 0,
+	 (ushort) (CFG_EXPORT),
+	 (ushort) CFG_RESTART,
+	 "The maximun number of targets an adapter can support"},
+};
+#endif				/* LPFC_DEF_ICFG */
+
+#endif				/* _H_LPFC_CFGPARAM */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_core.c linux-2.6.3/drivers/scsi/lpfc/lpfc_core.c
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_core.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_core.c	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,20452 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#include "elx_os.h"
+#include "elx_util.h"
+#include "elx_clock.h"
+#include "elx_hw.h"
+#include "elx_sli.h"
+#include "elx_mem.h"
+#include "elx_sched.h"
+#include "elx.h"
+#include "elx_logmsg.h"
+#include "elx_disc.h"
+#include "elx_scsi.h"
+#include "elx_crtn.h"
+#include "elx_cfgparm.h"
+#include "lpfc_hw.h"
+#include "lpfc_hba.h"
+#include "lpfc_crtn.h"
+#include "lpfc_cfgparm.h"
+#include "lpfc_diag.h"
+#include "prod_crtn.h"
+#include "hbaapi.h"
+
+extern char *lpfc_release_version;
+
+DMABUF_t *lpfc_alloc_ct_rsp(elxHBA_t *, ULP_BDE64 *, uint32_t, int *);
+
+void
+lpfc_ct_unsol_event(elxHBA_t * phba,
+		    ELX_SLI_RING_t * pring, ELX_IOCBQ_t * piocbq)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	DMABUF_t *p_mbuf = 0;
+	DMABUF_t *last_mp;
+	DMABUF_t *matp;
+	uint32_t ctx;
+	uint32_t count;
+	IOCB_t *icmd;
+	int i;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	icmd = &piocbq->iocb;
+	if (icmd->ulpStatus) {
+		goto dropit;
+	}
+	ctx = 0;
+	count = 0;
+	last_mp = 0;
+	while (piocbq) {
+		icmd = &piocbq->iocb;
+		if (ctx == 0)
+			ctx = (uint32_t) (icmd->ulpContext);
+		if (icmd->ulpStatus) {
+			if ((icmd->ulpStatus == IOSTAT_LOCAL_REJECT) &&
+			    ((icmd->un.ulpWord[4] & 0xff) ==
+			     IOERR_RCV_BUFFER_WAITING)) {
+				/* FCSTATCTR.NoRcvBuf++; */
+
+				if (!(plhba->fc_flag & FC_NO_RCV_BUF)) {
+
+				}
+				plhba->fc_flag |= FC_NO_RCV_BUF;
+
+				lpfc_post_buffer(phba, pring, 0, 1);
+			}
+			goto dropit;
+		}
+
+		if (icmd->ulpBdeCount == 0) {
+			piocbq = (ELX_IOCBQ_t *) piocbq->q_f;
+			continue;
+		}
+		for (i = 0; i < (int)icmd->ulpBdeCount; i++) {
+			matp = elx_sli_ringpostbuf_get(phba, pring,
+						       (elx_dma_addr_t)
+						       getPaddr(icmd->un.
+								cont64[i].
+								addrHigh,
+								icmd->un.
+								cont64[i].
+								addrLow));
+			if (matp == 0) {
+
+				goto dropit;
+			}
+
+			/* Typically for Unsolicited CT requests */
+
+			if (last_mp) {
+				last_mp->next = (void *)matp;
+			} else {
+				p_mbuf = matp;
+			}
+			last_mp = matp;
+			matp->next = 0;
+			count += icmd->un.cont64[i].tus.f.bdeSize;
+
+		}
+
+		lpfc_post_buffer(phba, pring, i, 1);
+		icmd->ulpBdeCount = 0;
+		piocbq = (ELX_IOCBQ_t *) piocbq->q_f;
+	}
+	if (p_mbuf == 0) {
+
+		goto dropit;
+	}
+
+	/* FC_REG_CT_EVENT for HBAAPI Ioctl event handling */
+	if (dfc_put_event
+	    (phba, FC_REG_CT_EVENT, ctx, (void *)p_mbuf,
+	     (void *)((ulong) count))) {
+
+		return;
+	}
+
+      dropit:
+
+	while (p_mbuf) {
+		matp = p_mbuf;
+		p_mbuf = (DMABUF_t *) matp->next;
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) matp);
+	}
+	return;
+}
+
+int
+lpfc_ns_cmd(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, int cmdcode)
+{
+	elxCfgParam_t *clp;
+	DMABUF_t *mp, *bmp;
+	SLI_CT_REQUEST *CtReq;
+	ULP_BDE64 *bpl;
+	LPFCHBA_t *plhba;
+	void (*cmpl) (struct elxHBA *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	/* fill in BDEs for command */
+	/* Allocate buffer for command payload */
+	if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+		return (1);
+	}
+
+	/* Allocate buffer for Buffer ptr list */
+	if ((bmp = (DMABUF_t *) elx_mem_get(phba, MEM_BPL)) == 0) {
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		return (1);
+	}
+	bpl = (ULP_BDE64 *) bmp->virt;
+	bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(mp->phys));
+	bpl->addrLow = PCIMEM_LONG(putPaddrLow(mp->phys));
+	bpl->tus.f.bdeFlags = 0;
+	if (cmdcode == SLI_CTNS_GID_FT)
+		bpl->tus.f.bdeSize = GID_REQUEST_SZ;
+	else if (cmdcode == SLI_CTNS_RFT_ID)
+		bpl->tus.f.bdeSize = RFT_REQUEST_SZ;
+	else if (cmdcode == SLI_CTNS_RNN_ID)
+		bpl->tus.f.bdeSize = RNN_REQUEST_SZ;
+	else if (cmdcode == SLI_CTNS_RSNN_NN)
+		bpl->tus.f.bdeSize = RSNN_REQUEST_SZ;
+	else
+		bpl->tus.f.bdeSize = 0;
+	bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+
+	CtReq = (SLI_CT_REQUEST *) mp->virt;
+	/* NameServer Req */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0236,	/* ptr to msg structure */
+		       elx_mes0236,	/* ptr to msg */
+		       elx_msgBlk0236.msgPreambleStr,	/* begin varargs */
+		       cmdcode, plhba->fc_flag, plhba->fc_rscn_id_cnt);	/* end varargs */
+
+	memset((void *)CtReq, 0, sizeof (SLI_CT_REQUEST));
+	CtReq->RevisionId.bits.Revision = SLI_CT_REVISION;
+	CtReq->RevisionId.bits.InId = 0;
+
+	CtReq->FsType = SLI_CT_DIRECTORY_SERVICE;
+	CtReq->FsSubType = SLI_CT_DIRECTORY_NAME_SERVER;
+
+	CtReq->CommandResponse.bits.Size = 0;
+
+	cmpl = 0;
+	switch (cmdcode) {
+	case SLI_CTNS_GID_FT:
+		CtReq->CommandResponse.bits.CmdRsp =
+		    SWAP_DATA16(SLI_CTNS_GID_FT);
+		CtReq->un.gid.Fc4Type = SLI_CTPT_FCP;
+		if (phba->hba_state < ELX_HBA_READY) {
+			phba->hba_state = ELX_NS_QRY;
+		}
+		lpfc_set_disctmo(phba);
+		cmpl = lpfc_cmpl_ct_cmd_gid_ft;
+		break;
+	case SLI_CTNS_RFT_ID:
+		CtReq->CommandResponse.bits.CmdRsp =
+		    SWAP_DATA16(SLI_CTNS_RFT_ID);
+		CtReq->un.rft.PortId = SWAP_DATA(plhba->fc_myDID);
+		CtReq->un.rft.fcpReg = 1;
+		if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+			CtReq->un.rft.ipReg = 1;
+		}
+		cmpl = lpfc_cmpl_ct_cmd_rft_id;
+		break;
+	case SLI_CTNS_RNN_ID:
+		CtReq->CommandResponse.bits.CmdRsp =
+		    SWAP_DATA16(SLI_CTNS_RNN_ID);
+		CtReq->un.rnn.PortId = SWAP_DATA(plhba->fc_myDID);
+		memcpy(CtReq->un.rnn.wwnn, (uint8_t *) & plhba->fc_nodename,
+		       sizeof (NAME_TYPE));
+		cmpl = lpfc_cmpl_ct_cmd_rnn_id;
+		break;
+	case SLI_CTNS_RSNN_NN:
+
+		CtReq->CommandResponse.bits.CmdRsp =
+		    SWAP_DATA16(SLI_CTNS_RSNN_NN);
+		memcpy(CtReq->un.rsnn.wwnn, (uint8_t *) & plhba->fc_nodename,
+		       sizeof (NAME_TYPE));
+		lpfc_get_hba_SymbNodeName(phba,
+					  (uint8_t *) CtReq->un.rsnn.symbname);
+		CtReq->un.rsnn.len =
+		    elx_str_len((char *)CtReq->un.rsnn.symbname);
+		cmpl = lpfc_cmpl_ct_cmd_rsnn_nn;
+		break;
+	}
+
+	if (lpfc_ct_cmd(phba, mp, bmp, ndlp, cmpl)) {
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+		return (1);
+	}
+	return (0);
+}
+
+int
+lpfc_ct_cmd(elxHBA_t * phba,
+	    DMABUF_t * inmp,
+	    DMABUF_t * bmp,
+	    LPFC_NODELIST_t * ndlp,
+	    void (*cmpl) (struct elxHBA *, ELX_IOCBQ_t *, ELX_IOCBQ_t *))
+{
+	ULP_BDE64 *bpl;
+	DMABUF_t *outmp;
+	int cnt;
+
+	bpl = (ULP_BDE64 *) bmp->virt;
+	bpl++;			/* Skip past ct request */
+
+	cnt = 0;
+	/* Put buffer(s) for ct rsp in bpl */
+	if ((outmp = lpfc_alloc_ct_rsp(phba, bpl, FC_MAX_NS_RSP, &cnt)) == 0) {
+		return (ENOMEM);
+	}
+
+	/* save ndlp for cmpl */
+	inmp->next = (DMABUF_t *) ndlp;
+
+	if ((lpfc_gen_req
+	     (phba, bmp, inmp, outmp, cmpl, ndlp->nle.nlp_rpi, 0, (cnt + 1),
+	      0))) {
+		lpfc_free_ct_rsp(phba, outmp);
+		return (ENOMEM);
+	}
+	return (0);
+}
+
+int
+lpfc_free_ct_rsp(elxHBA_t * phba, DMABUF_t * mlist)
+{
+	DMABUF_t *mlast;
+
+	while (mlist) {
+		mlast = mlist;
+		mlist = (DMABUF_t *) mlist->next;
+
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mlast);
+	}
+	return (0);
+}
+
+DMABUF_t *
+lpfc_alloc_ct_rsp(elxHBA_t * phba, ULP_BDE64 * bpl, uint32_t size, int *entries)
+{
+	DMABUF_t *mlist;
+	DMABUF_t *mlast;
+	DMABUF_t *mp;
+	int cnt, i;
+
+	mlist = 0;
+	mlast = 0;
+	i = 0;
+
+	while (size) {
+
+		/* We get chucks of FCELSSIZE */
+		if (size > FCELSSIZE)
+			cnt = FCELSSIZE;
+		else
+			cnt = size;
+
+		/* Allocate buffer for rsp payload */
+		if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+			lpfc_free_ct_rsp(phba, mlist);
+			return (0);
+		}
+
+		/* Queue it to a linked list */
+		if (mlast == 0) {
+			mlist = mp;
+			mlast = mp;
+		} else {
+			mlast->next = mp;
+			mlast = mp;
+		}
+		mp->next = 0;
+
+		bpl->tus.f.bdeFlags = BUFF_USE_RCV;
+
+		/* build buffer ptr list for IOCB */
+		bpl->addrLow = PCIMEM_LONG(putPaddrLow(mp->phys));
+		bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(mp->phys));
+		bpl->tus.f.bdeSize = (uint16_t) cnt;
+		bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+		bpl++;
+
+		i++;
+		size -= cnt;
+	}
+
+	*entries = i;
+	return (mlist);
+}
+
+int
+lpfc_ns_rsp(elxHBA_t * phba, DMABUF_t * mp, uint32_t Size)
+{
+	LPFCHBA_t *plhba;
+	elxCfgParam_t *clp;
+	SLI_CT_REQUEST *Response;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_NODELIST_t *new_ndlp;
+	ELXSCSITARGET_t *targetp;
+	DMABUF_t *mlast;
+	uint32_t *ctptr;
+	uint32_t Did;
+	uint32_t CTentry;
+	int Cnt, new_node;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+	ndlp = 0;
+
+	lpfc_set_disctmo(phba);
+
+	Response = (SLI_CT_REQUEST *) mp->virt;
+	ctptr = (uint32_t *) & Response->un.gid.PortType;
+	while (mp) {
+		mlast = mp;
+		mp = (DMABUF_t *) mp->next;
+		elx_pci_dma_sync((void *)phba, (void *)mp,
+				 0, ELX_DMA_SYNC_FORCPU);
+
+		if (Size > FCELSSIZE)
+			Cnt = FCELSSIZE;
+		else
+			Cnt = Size;
+		Size -= Cnt;
+
+		if (ctptr == 0)
+			ctptr = (uint32_t *) mlast->virt;
+		else
+			Cnt -= 16;	/* subtract length of CT header */
+
+		/* Loop through entire NameServer list of DIDs */
+		while (Cnt) {
+
+			/* Get next DID from NameServer List */
+			CTentry = *ctptr++;
+			Did = ((SWAP_DATA(CTentry)) & Mask_DID);
+
+			/* If we are processing an RSCN, check to ensure the Did falls
+			 * under the juristiction of the RSCN payload.
+			 */
+			if (phba->hba_state == ELX_HBA_READY) {
+				Did = lpfc_rscn_payload_check(phba, Did);
+				/* Did = 0 indicates Not part of RSCN, ignore this entry */
+			}
+
+			ndlp = 0;
+			if ((Did) && (Did != plhba->fc_myDID)) {
+				new_node = 0;
+				/* Skip if the node is already in the plogi / adisc list */
+				if ((ndlp = lpfc_findnode_did(phba,
+							      (NLP_SEARCH_PLOGI
+							       |
+							       NLP_SEARCH_ADISC),
+							      Did))) {
+					goto nsout0;
+				}
+				ndlp =
+				    lpfc_findnode_did(phba, NLP_SEARCH_ALL,
+						      Did);
+				if (ndlp) {
+					lpfc_disc_state_machine(phba, ndlp,
+								(void *)0,
+								NLP_EVT_DEVICE_ADD);
+				} else {
+					new_node = 1;
+					if ((ndlp =
+					     (LPFC_NODELIST_t *)
+					     elx_mem_get(phba, MEM_NLP))) {
+						memset((void *)ndlp, 0,
+						       sizeof
+						       (LPFC_NODELIST_t));
+						ndlp->nlp_state =
+						    NLP_STE_UNUSED_NODE;
+						ndlp->nlp_DID = Did;
+						lpfc_disc_state_machine(phba,
+									ndlp,
+									(void *)
+									0,
+									NLP_EVT_DEVICE_ADD);
+					}
+				}
+			}
+		      nsout0:
+			/* Mark all node table entries that are in the Nameserver */
+			if (ndlp) {
+				ndlp->nlp_flag |= NLP_NS_NODE;
+				/* NameServer Rsp */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0238,	/* ptr to msg structure */
+					       elx_mes0238,	/* ptr to msg */
+					       elx_msgBlk0238.msgPreambleStr,	/* begin varargs */
+					       Did, ndlp->nlp_flag, plhba->fc_flag, plhba->fc_rscn_id_cnt);	/* end varargs */
+			} else {
+				/* NameServer Rsp */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0239,	/* ptr to msg structure */
+					       elx_mes0239,	/* ptr to msg */
+					       elx_msgBlk0239.msgPreambleStr,	/* begin varargs */
+					       Did, Size, plhba->fc_flag, plhba->fc_rscn_id_cnt);	/* end varargs */
+			}
+
+			if (CTentry & (SWAP_DATA(SLI_CT_LAST_ENTRY)))
+				goto nsout1;
+			Cnt -= sizeof (uint32_t);
+		}
+		ctptr = 0;
+	}
+
+      nsout1:
+	ELX_DISC_LOCK(phba, iflag);
+	/* Take out all node table entries that are not in the NameServer */
+	ndlp = plhba->fc_plogi_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+		ndlp = plhba->fc_adisc_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+		ndlp = plhba->fc_nlpunmap_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+		ndlp = plhba->fc_nlpmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		new_ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		if ((ndlp->nlp_DID == plhba->fc_myDID) ||
+		    (ndlp->nlp_DID == NameServer_DID) ||
+		    (ndlp->nlp_DID == FDMI_DID) ||
+		    (ndlp->nle.nlp_type & NLP_FABRIC) ||
+		    (ndlp->nlp_flag & NLP_NS_NODE)) {
+			if (ndlp->nlp_flag & NLP_NS_NODE) {
+				ndlp->nlp_flag &= ~NLP_NS_NODE;
+			}
+			goto loop1;
+		}
+		ELX_DISC_UNLOCK(phba, iflag);
+		/* If we are processing an RSCN, check to ensure the Did falls
+		 * under the juristiction of the RSCN payload.
+		 */
+		if ((phba->hba_state == ELX_HBA_READY) &&
+		    (!(lpfc_rscn_payload_check(phba, ndlp->nlp_DID)))) {
+			ELX_DISC_LOCK(phba, iflag);
+			goto loop1;	/* Not part of RSCN, ignore this entry */
+		}
+
+		targetp = ndlp->nlp_Target;
+		/* Make sure nodev tmo is NOT running so DEVICE_RM really removes it */
+		if (ndlp->nlp_tmofunc) {
+			elx_clk_can(phba, ndlp->nlp_tmofunc);
+			ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+			ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+			ndlp->nlp_tmofunc = 0;
+		}
+		lpfc_disc_state_machine(phba, ndlp, (void *)0,
+					NLP_EVT_DEVICE_RM);
+
+		/* If we were a FCP target, go into NPort Recovery mode to give
+		 * it a chance to come back.
+		 */
+		if (targetp) {
+			if (clp[ELX_CFG_HOLDIO].a_current) {
+				targetp->targetFlags |= FC_NPR_ACTIVE;
+				if (targetp->tmofunc) {
+					elx_clk_can(phba, targetp->tmofunc);
+					targetp->tmofunc = 0;
+				}
+			} else {
+				if (clp[ELX_CFG_NODEV_TMO].a_current) {
+					targetp->targetFlags |= FC_NPR_ACTIVE;
+					if (targetp->tmofunc) {
+						elx_clk_can(phba,
+							    targetp->tmofunc);
+					}
+					targetp->tmofunc =
+					    elx_clk_set(phba,
+							clp[ELX_CFG_NODEV_TMO].
+							a_current,
+							lpfc_npr_timeout,
+							(void *)targetp,
+							(void *)0);
+				}
+			}
+		}
+		ELX_DISC_LOCK(phba, iflag);
+	      loop1:
+		ndlp = new_ndlp;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+			ndlp = plhba->fc_adisc_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+			ndlp = plhba->fc_nlpunmap_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+			ndlp = plhba->fc_nlpmap_start;
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	if (phba->hba_state == ELX_HBA_READY) {
+		lpfc_els_flush_rscn(phba);
+		plhba->fc_flag |= FC_RSCN_MODE;
+	}
+	return (0);
+}
+
+int
+lpfc_issue_ct_rsp(elxHBA_t * phba,
+		  uint32_t tag, DMABUF_t * bmp, DMABUFEXT_t * inp)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *ctiocb;
+	ELX_SLI_RING_t *pring;
+	uint32_t num_entry;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	num_entry = (uint32_t) inp->flag;
+	inp->flag = 0;
+
+	/* Allocate buffer for  command iocb */
+	if ((ctiocb = (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB)) == 0) {
+		return (ENOMEM);
+	}
+	memset((void *)ctiocb, 0, sizeof (ELX_IOCBQ_t));
+	icmd = &ctiocb->iocb;
+
+	icmd->un.xseq64.bdl.ulpIoTag32 = 0;
+	icmd->un.xseq64.bdl.addrHigh = putPaddrHigh(bmp->phys);
+	icmd->un.xseq64.bdl.addrLow = putPaddrLow(bmp->phys);
+	icmd->un.xseq64.bdl.bdeFlags = BUFF_TYPE_BDL;
+	icmd->un.xseq64.bdl.bdeSize = (num_entry * sizeof (ULP_BDE64));
+
+	icmd->un.xseq64.w5.hcsw.Fctl = (LS | LA);
+	icmd->un.xseq64.w5.hcsw.Dfctl = 0;
+	icmd->un.xseq64.w5.hcsw.Rctl = FC_SOL_CTL;
+	icmd->un.xseq64.w5.hcsw.Type = FC_COMMON_TRANSPORT_ULP;
+
+	elx_pci_dma_sync((void *)phba, (void *)bmp, 0, ELX_DMA_SYNC_FORDEV);
+
+	icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+	/* Fill in rest of iocb */
+	icmd->ulpCommand = CMD_XMIT_SEQUENCE64_CX;
+	icmd->ulpBdeCount = 1;
+	icmd->ulpLe = 1;
+	icmd->ulpClass = CLASS3;
+	icmd->ulpContext = (ushort) tag;
+	icmd->ulpOwner = OWN_CHIP;
+	/* Xmit CT response on exchange <xid> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0118,	/* ptr to msg structure */
+		       elx_mes0118,	/* ptr to msg */
+		       elx_msgBlk0118.msgPreambleStr,	/* begin varargs */
+		       icmd->ulpContext,	/* xid */
+		       icmd->ulpIoTag, phba->hba_state);	/* end varargs */
+
+	ctiocb->iocb_cmpl = 0;
+	ctiocb->iocb_flag |= ELX_IO_IOCTL;
+
+	rc = elx_sli_issue_iocb_wait(phba, pring, ctiocb, SLI_IOCB_USE_TXQ,
+				     NULL,
+				     plhba->fc_ratov * 2 + ELX_DRVR_TIMEOUT);
+	elx_mem_put(phba, MEM_IOCB, (uint8_t *) ctiocb);
+	return (rc);
+}				/* lpfc_issue_ct_rsp */
+
+int
+lpfc_gen_req(elxHBA_t * phba,
+	     DMABUF_t * bmp,
+	     DMABUF_t * inp,
+	     DMABUF_t * outp,
+	     void (*cmpl) (struct elxHBA *, ELX_IOCBQ_t *, ELX_IOCBQ_t *),
+	     uint32_t rpi, uint32_t usr_flg, uint32_t num_entry, uint32_t tmo)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *geniocb;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	/* Allocate buffer for  command iocb */
+	if ((geniocb = (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB)) == 0) {
+		return (1);
+	}
+	memset((void *)geniocb, 0, sizeof (ELX_IOCBQ_t));
+	icmd = &geniocb->iocb;
+
+	icmd->un.genreq64.bdl.ulpIoTag32 = 0;
+	icmd->un.genreq64.bdl.addrHigh = putPaddrHigh(bmp->phys);
+	icmd->un.genreq64.bdl.addrLow = putPaddrLow(bmp->phys);
+	icmd->un.genreq64.bdl.bdeFlags = BUFF_TYPE_BDL;
+	icmd->un.genreq64.bdl.bdeSize = (num_entry * sizeof (ULP_BDE64));
+
+	if (usr_flg)
+		geniocb->context3 = 0;
+	else
+		geniocb->context3 = (uint8_t *) bmp;
+
+	/* Save for completion so we can release these resources */
+	geniocb->context1 = (uint8_t *) inp;
+	geniocb->context2 = (uint8_t *) outp;
+
+	/* Fill in payload, bp points to frame payload */
+	icmd->ulpCommand = CMD_GEN_REQUEST64_CR;
+
+	elx_pci_dma_sync((void *)phba, (void *)bmp, 0, ELX_DMA_SYNC_FORDEV);
+
+	icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+
+	/* Fill in rest of iocb */
+	icmd->un.genreq64.w5.hcsw.Fctl = (SI | LA);
+	icmd->un.genreq64.w5.hcsw.Dfctl = 0;
+	icmd->un.genreq64.w5.hcsw.Rctl = FC_UNSOL_CTL;
+	icmd->un.genreq64.w5.hcsw.Type = FC_COMMON_TRANSPORT_ULP;
+
+	if (tmo == 0)
+		tmo = (2 * plhba->fc_ratov) + 1;
+	icmd->ulpTimeout = tmo;
+	icmd->ulpBdeCount = 1;
+	icmd->ulpLe = 1;
+	icmd->ulpClass = CLASS3;
+	icmd->ulpContext = (volatile ushort)rpi;
+	icmd->ulpOwner = OWN_CHIP;
+	/* Issue GEN REQ IOCB for NPORT <did> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0119,	/* ptr to msg structure */
+		       elx_mes0119,	/* ptr to msg */
+		       elx_msgBlk0119.msgPreambleStr,	/* begin varargs */
+		       icmd->un.ulpWord[5],	/* did */
+		       icmd->ulpIoTag, phba->hba_state);	/* end varargs */
+	geniocb->iocb_cmpl = cmpl;
+	geniocb->drvrTimeout = icmd->ulpTimeout + ELX_DRVR_TIMEOUT;
+	if (elx_sli_issue_iocb(phba, pring, geniocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) geniocb);
+		return (1);
+	}
+
+	return (0);
+}
+
+void
+lpfc_cmpl_ct_cmd_gid_ft(elxHBA_t * phba,
+			ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFCHBA_t *plhba;
+	IOCB_t *irsp;
+	ELX_SLI_t *psli;
+	DMABUF_t *bmp;
+	DMABUF_t *inp;
+	DMABUF_t *outp;
+	LPFC_NODELIST_t *ndlp;
+	SLI_CT_REQUEST *CTrsp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	/* we pass cmdiocb to state machine which needs rspiocb as well */
+	cmdiocb->q_f = rspiocb;
+
+	inp = (DMABUF_t *) cmdiocb->context1;
+	outp = (DMABUF_t *) cmdiocb->context2;
+	bmp = (DMABUF_t *) cmdiocb->context3;
+
+	irsp = &rspiocb->iocb;
+	if (irsp->ulpStatus) {
+		/* Check for retry */
+		if (plhba->fc_ns_retry < LPFC_MAX_NS_RETRY) {
+			plhba->fc_ns_retry++;
+			/* CT command is being retried */
+			ndlp =
+			    lpfc_findnode_did(phba, NLP_SEARCH_UNMAPPED,
+					      NameServer_DID);
+			if (ndlp) {
+				if (lpfc_ns_cmd(phba, ndlp, SLI_CTNS_GID_FT) ==
+				    0) {
+					goto out;
+				}
+			}
+		}
+	} else {
+		/* Good status, continue checking */
+		CTrsp = (SLI_CT_REQUEST *) outp->virt;
+		if (CTrsp->CommandResponse.bits.CmdRsp ==
+		    SWAP_DATA16(SLI_CT_RESPONSE_FS_ACC)) {
+			lpfc_ns_rsp(phba, outp,
+				    (uint32_t) (irsp->un.genreq64.bdl.bdeSize));
+		} else if (CTrsp->CommandResponse.bits.CmdRsp ==
+			   SWAP_DATA16(SLI_CT_RESPONSE_FS_RJT)) {
+			/* NameServer Rsp Error */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0240,	/* ptr to msg structure */
+				       elx_mes0240,	/* ptr to msg */
+				       elx_msgBlk0240.msgPreambleStr,	/* begin varargs */
+				       CTrsp->CommandResponse.bits.CmdRsp, (uint32_t) CTrsp->ReasonCode, (uint32_t) CTrsp->Explanation, plhba->fc_flag);	/* end varargs */
+		} else {
+			/* NameServer Rsp Error */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0241,	/* ptr to msg structure */
+				       elx_mes0241,	/* ptr to msg */
+				       elx_msgBlk0241.msgPreambleStr,	/* begin varargs */
+				       CTrsp->CommandResponse.bits.CmdRsp, (uint32_t) CTrsp->ReasonCode, (uint32_t) CTrsp->Explanation, plhba->fc_flag);	/* end varargs */
+		}
+	}
+	/* Link up / RSCN discovery */
+	lpfc_disc_start(phba);
+      out:
+	lpfc_free_ct_rsp(phba, outp);
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) inp);
+	elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+	elx_mem_put(phba, MEM_IOCB, (uint8_t *) cmdiocb);
+	return;
+}
+
+void
+lpfc_cmpl_ct_cmd_rft_id(elxHBA_t * phba,
+			ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	DMABUF_t *bmp;
+	DMABUF_t *inp;
+	DMABUF_t *outp;
+	IOCB_t *irsp;
+	SLI_CT_REQUEST *CTrsp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	/* we pass cmdiocb to state machine which needs rspiocb as well */
+	cmdiocb->q_f = rspiocb;
+
+	inp = (DMABUF_t *) cmdiocb->context1;
+	outp = (DMABUF_t *) cmdiocb->context2;
+	bmp = (DMABUF_t *) cmdiocb->context3;
+	irsp = &rspiocb->iocb;
+
+	CTrsp = (SLI_CT_REQUEST *) outp->virt;
+
+	/* RFT request completes status <ulpStatus> CmdRsp <CmdRsp> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0209,	/* ptr to msg structure */
+		       elx_mes0209,	/* ptr to msg */
+		       elx_msgBlk0209.msgPreambleStr,	/* begin varargs */
+		       irsp->ulpStatus, CTrsp->CommandResponse.bits.CmdRsp);	/* end varargs */
+
+	lpfc_free_ct_rsp(phba, outp);
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) inp);
+	elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+	elx_mem_put(phba, MEM_IOCB, (uint8_t *) cmdiocb);
+	return;
+}
+
+void
+lpfc_cmpl_ct_cmd_rnn_id(elxHBA_t * phba,
+			ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	lpfc_cmpl_ct_cmd_rft_id(phba, cmdiocb, rspiocb);
+	return;
+}
+
+void
+lpfc_cmpl_ct_cmd_rsnn_nn(elxHBA_t * phba,
+			 ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	lpfc_cmpl_ct_cmd_rft_id(phba, cmdiocb, rspiocb);
+	return;
+}
+
+int
+lpfc_fdmi_cmd(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, int cmdcode)
+{
+	elxCfgParam_t *clp;
+	DMABUF_t *mp, *bmp;
+	SLI_CT_REQUEST *CtReq;
+	ULP_BDE64 *bpl;
+	LPFCHBA_t *plhba;
+	uint32_t size;
+	PREG_HBA rh;
+	PPORT_ENTRY pe;
+	PREG_PORT_ATTRIBUTE pab;
+	PATTRIBUTE_BLOCK ab;
+	PATTRIBUTE_ENTRY ae;
+	uint32_t id;
+	void (*cmpl) (struct elxHBA *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	/* fill in BDEs for command */
+	/* Allocate buffer for command payload */
+	if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+		/* Issue FDMI request failed */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0219,	/* ptr to msg structure */
+			       elx_mes0219,	/* ptr to msg */
+			       elx_msgBlk0219.msgPreambleStr,	/* begin varargs */
+			       cmdcode);	/* end varargs */
+		return (1);
+	}
+
+	/* Allocate buffer for Buffer ptr list */
+	if ((bmp = (DMABUF_t *) elx_mem_get(phba, MEM_BPL)) == 0) {
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		/* Issue FDMI request failed */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0243,	/* ptr to msg structure */
+			       elx_mes0243,	/* ptr to msg */
+			       elx_msgBlk0243.msgPreambleStr,	/* begin varargs */
+			       cmdcode);	/* end varargs */
+		return (1);
+	}
+
+	/* FDMI request */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0218,	/* ptr to msg structure */
+		       elx_mes0218,	/* ptr to msg */
+		       elx_msgBlk0218.msgPreambleStr,	/* begin varargs */
+		       plhba->fc_flag, phba->hba_state, cmdcode);	/* end varargs */
+
+	CtReq = (SLI_CT_REQUEST *) mp->virt;
+
+/*
+   memset((void *)CtReq, 0, sizeof(SLI_CT_REQUEST));
+*/
+	memset((void *)CtReq, 0, 1024);
+	CtReq->RevisionId.bits.Revision = SLI_CT_REVISION;
+	CtReq->RevisionId.bits.InId = 0;
+
+	CtReq->FsType = SLI_CT_MANAGEMENT_SERVICE;
+	CtReq->FsSubType = SLI_CT_FDMI_Subtypes;
+	size = 0;
+
+#define FOURBYTES	4
+
+	switch (cmdcode) {
+	case SLI_MGMT_RHBA:
+		{
+			elx_vpd_t *vp;
+			char *str;
+			uint32_t i, j, incr;
+			int len;
+			uint8_t HWrev[8];
+
+			vp = &phba->vpd;
+
+			CtReq->CommandResponse.bits.CmdRsp =
+			    SWAP_DATA16(SLI_MGMT_RHBA);
+			CtReq->CommandResponse.bits.Size = 0;
+			rh = (REG_HBA *) & CtReq->un.PortID;
+			memcpy((uint8_t *) & rh->hi.PortName,
+			       (uint8_t *) & plhba->fc_sparam.portName,
+			       sizeof (NAME_TYPE));
+			rh->rpl.EntryCnt = SWAP_DATA(1);	/* One entry (port) per adapter */
+			memcpy((uint8_t *) & rh->rpl.pe,
+			       (uint8_t *) & plhba->fc_sparam.portName,
+			       sizeof (NAME_TYPE));
+
+			/* point to the HBA attribute block */
+			size =
+			    sizeof (NAME_TYPE) + FOURBYTES + sizeof (NAME_TYPE);
+			ab = (ATTRIBUTE_BLOCK *) ((uint8_t *) rh + size);
+			ab->EntryCnt = 0;
+
+			/* Point to the begin of the first HBA attribute entry */
+			/* #1 HBA attribute entry */
+			size += FOURBYTES;
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(NODE_NAME);
+			ae->ad.bits.AttrLen =
+			    SWAP_DATA16(FOURBYTES + sizeof (NAME_TYPE));
+			memcpy((uint8_t *) & ae->un.NodeName,
+			       (uint8_t *) & plhba->fc_sparam.nodeName,
+			       sizeof (NAME_TYPE));
+			ab->EntryCnt++;
+			size += FOURBYTES + sizeof (NAME_TYPE);
+
+			/* #2 HBA attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(MANUFACTURER);
+			elx_str_cpy((char *)ae->un.Manufacturer,
+				    "Emulex Corporation");
+			len = elx_str_len((char *)ae->un.Manufacturer);
+			len += (len & 3) ? (4 - (len & 3)) : 4;
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + len);
+			ab->EntryCnt++;
+			size += FOURBYTES + len;
+
+			/* #3 HBA attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(SERIAL_NUMBER);
+			elx_str_cpy((char *)ae->un.SerialNumber,
+				    phba->SerialNumber);
+			len = elx_str_len((char *)ae->un.SerialNumber);
+			len += (len & 3) ? (4 - (len & 3)) : 4;
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + len);
+			ab->EntryCnt++;
+			size += FOURBYTES + len;
+
+			/* #4 HBA attribute entry */
+			id = elx_read_pci(phba, PCI_VENDOR_ID_REGISTER);
+			switch ((id >> 16) & 0xffff) {
+			case PCI_DEVICE_ID_SUPERFLY:
+				if ((vp->rev.biuRev == 1)
+				    || (vp->rev.biuRev == 2)
+				    || (vp->rev.biuRev == 3)) {
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL);
+					elx_str_cpy((char *)ae->un.Model,
+						    "LP7000");
+					len = elx_str_len((char *)ae->un.Model);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+
+					/* #5 HBA attribute entry */
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL_DESCRIPTION);
+					elx_str_cpy((char *)ae->un.
+						    ModelDescription,
+						    "Emulex LightPulse LP7000 1 Gigabit PCI Fibre Channel Adapter");
+					len =
+					    elx_str_len((char *)ae->un.
+							ModelDescription);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+				} else {
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL);
+					elx_str_cpy((char *)ae->un.Model,
+						    "LP7000E");
+					len = elx_str_len((char *)ae->un.Model);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+
+					/* #5 HBA attribute entry */
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL_DESCRIPTION);
+					elx_str_cpy((char *)ae->un.
+						    ModelDescription,
+						    "Emulex LightPulse LP7000E 1 Gigabit PCI Fibre Channel Adapter");
+					len =
+					    elx_str_len((char *)ae->un.
+							ModelDescription);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+				}
+				break;
+			case PCI_DEVICE_ID_DRAGONFLY:
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType = SWAP_DATA16(MODEL);
+				elx_str_cpy((char *)ae->un.Model, "LP8000");
+				len = elx_str_len((char *)ae->un.Model);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+
+				/* #5 HBA attribute entry */
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType =
+				    SWAP_DATA16(MODEL_DESCRIPTION);
+				elx_str_cpy((char *)ae->un.ModelDescription,
+					    "Emulex LightPulse LP8000 1 Gigabit PCI Fibre Channel Adapter");
+				len =
+				    elx_str_len((char *)ae->un.
+						ModelDescription);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+				break;
+			case PCI_DEVICE_ID_CENTAUR:
+				if (FC_JEDEC_ID(vp->rev.biuRev) ==
+				    CENTAUR_2G_JEDEC_ID) {
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL);
+					elx_str_cpy((char *)ae->un.Model,
+						    "LP9002");
+					len = elx_str_len((char *)ae->un.Model);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+
+					/* #5 HBA attribute entry */
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL_DESCRIPTION);
+					elx_str_cpy((char *)ae->un.
+						    ModelDescription,
+						    "Emulex LightPulse LP9002 2 Gigabit PCI Fibre Channel Adapter");
+					len =
+					    elx_str_len((char *)ae->un.
+							ModelDescription);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+				} else {
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL);
+					elx_str_cpy((char *)ae->un.Model,
+						    "LP9000");
+					len = elx_str_len((char *)ae->un.Model);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+
+					/* #5 HBA attribute entry */
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL_DESCRIPTION);
+					elx_str_cpy((char *)ae->un.
+						    ModelDescription,
+						    "Emulex LightPulse LP9000 1 Gigabit PCI Fibre Channel Adapter");
+					len =
+					    elx_str_len((char *)ae->un.
+							ModelDescription);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+				}
+				break;
+			case PCI_DEVICE_ID_RFLY:
+				{
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL);
+					elx_str_cpy((char *)ae->un.Model,
+						    "LP952");
+					len = elx_str_len((char *)ae->un.Model);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+
+					/* #5 HBA attribute entry */
+					ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh
+								  + size);
+					ae->ad.bits.AttrType =
+					    SWAP_DATA16(MODEL_DESCRIPTION);
+					elx_str_cpy((char *)ae->un.
+						    ModelDescription,
+						    "Emulex LightPulse LP952 2 Gigabit PCI Fibre Channel Adapter");
+					len =
+					    elx_str_len((char *)ae->un.
+							ModelDescription);
+					len += (len & 3) ? (4 - (len & 3)) : 4;
+					ae->ad.bits.AttrLen =
+					    SWAP_DATA16(FOURBYTES + len);
+					ab->EntryCnt++;
+					size += FOURBYTES + len;
+				}
+				break;
+			case PCI_DEVICE_ID_PEGASUS:
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType = SWAP_DATA16(MODEL);
+				elx_str_cpy((char *)ae->un.Model, "LP9802");
+				len = elx_str_len((char *)ae->un.Model);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+
+				/* #5 HBA attribute entry */
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType =
+				    SWAP_DATA16(MODEL_DESCRIPTION);
+				elx_str_cpy((char *)ae->un.ModelDescription,
+					    "Emulex LightPulse LP9802 2 Gigabit PCI Fibre Channel Adapter");
+				len =
+				    elx_str_len((char *)ae->un.
+						ModelDescription);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+				break;
+			case PCI_DEVICE_ID_PFLY:
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType = SWAP_DATA16(MODEL);
+				elx_str_cpy((char *)ae->un.Model, "LP982");
+				len = elx_str_len((char *)ae->un.Model);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+
+				/* #5 HBA attribute entry */
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType =
+				    SWAP_DATA16(MODEL_DESCRIPTION);
+				elx_str_cpy((char *)ae->un.ModelDescription,
+					    "Emulex LightPulse LP982 2 Gigabit PCI Fibre Channel Adapter");
+				len =
+				    elx_str_len((char *)ae->un.
+						ModelDescription);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+				break;
+			case PCI_DEVICE_ID_THOR:
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType = SWAP_DATA16(MODEL);
+				elx_str_cpy((char *)ae->un.Model, "LP10000");
+				len = elx_str_len((char *)ae->un.Model);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+
+				/* #5 HBA attribute entry */
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType =
+				    SWAP_DATA16(MODEL_DESCRIPTION);
+				elx_str_cpy((char *)ae->un.ModelDescription,
+					    "Emulex LightPulse LP10000 2 Gigabit PCI Fibre Channel Adapter");
+				len =
+				    elx_str_len((char *)ae->un.
+						ModelDescription);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+				break;
+			case PCI_DEVICE_ID_VIPER:
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType = SWAP_DATA16(MODEL);
+				elx_str_cpy((char *)ae->un.Model, "LPX1000");
+				len = elx_str_len((char *)ae->un.Model);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+
+				/* #5 HBA attribute entry */
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType =
+				    SWAP_DATA16(MODEL_DESCRIPTION);
+				elx_str_cpy((char *)ae->un.ModelDescription,
+					    "Emulex LightPulse LPX1000 10 Gigabit PCI Fibre Channel Adapter");
+				len =
+				    elx_str_len((char *)ae->un.
+						ModelDescription);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+				break;
+			case PCI_DEVICE_ID_TFLY:
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType = SWAP_DATA16(MODEL);
+				elx_str_cpy((char *)ae->un.Model, "LP1050");
+				len = elx_str_len((char *)ae->un.Model);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+
+				/* #5 HBA attribute entry */
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType =
+				    SWAP_DATA16(MODEL_DESCRIPTION);
+				elx_str_cpy((char *)ae->un.ModelDescription,
+					    "Emulex LightPulse LP1050 2 Gigabit PCI Fibre Channel Adapter");
+				len =
+				    elx_str_len((char *)ae->un.
+						ModelDescription);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+				break;
+			case PCI_DEVICE_ID_LP101:
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType = SWAP_DATA16(MODEL);
+				elx_str_cpy((char *)ae->un.Model, "LP101");
+				len = elx_str_len((char *)ae->un.Model);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+
+				/* #5 HBA attribute entry */
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh +
+							  size);
+				ae->ad.bits.AttrType =
+				    SWAP_DATA16(MODEL_DESCRIPTION);
+				elx_str_cpy((char *)ae->un.ModelDescription,
+					    "Emulex LightPulse LP101 2 Gigabit PCI Fibre Channel Adapter");
+				len =
+				    elx_str_len((char *)ae->un.
+						ModelDescription);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				ab->EntryCnt++;
+				size += FOURBYTES + len;
+				break;
+			}
+
+			/* #6 HBA attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(HARDWARE_VERSION);
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + 8);
+			/* Convert JEDEC ID to ascii for hardware version */
+			incr = vp->rev.biuRev;
+			for (i = 0; i < 8; i++) {
+				j = (incr & 0xf);
+				if (j <= 9)
+					HWrev[7 - i] =
+					    (char)((uint8_t) 0x30 +
+						   (uint8_t) j);
+				else
+					HWrev[7 - i] =
+					    (char)((uint8_t) 0x61 +
+						   (uint8_t) (j - 10));
+				incr = (incr >> 4);
+			}
+			memcpy(ae->un.HardwareVersion, (uint8_t *) HWrev, 8);
+			ab->EntryCnt++;
+			size += FOURBYTES + 8;
+
+			/* #7 HBA attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(DRIVER_VERSION);
+			elx_str_cpy((char *)ae->un.DriverVersion,
+				    (char *)lpfc_release_version);
+			len = elx_str_len((char *)ae->un.DriverVersion);
+			len += (len & 3) ? (4 - (len & 3)) : 4;
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + len);
+			ab->EntryCnt++;
+			size += FOURBYTES + len;
+
+			/* #8 HBA attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(OPTION_ROM_VERSION);
+			elx_str_cpy((char *)ae->un.OptionROMVersion,
+				    (char *)phba->OptionROMVersion);
+			len = elx_str_len((char *)ae->un.OptionROMVersion);
+			len += (len & 3) ? (4 - (len & 3)) : 4;
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + len);
+			ab->EntryCnt++;
+			size += FOURBYTES + len;
+
+			/* #9 HBA attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(FIRMWARE_VERSION);
+			str = lpfc_decode_firmware_rev(phba);
+			elx_str_cpy((char *)ae->un.FirmwareVersion,
+				    (char *)str);
+			len = elx_str_len((char *)ae->un.FirmwareVersion);
+			len += (len & 3) ? (4 - (len & 3)) : 4;
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + len);
+			ab->EntryCnt++;
+			size += FOURBYTES + len;
+
+			/* #10 HBA attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(OS_NAME_VERSION);
+			str = lpfc_get_OsNameVersion(GET_OS_VERSION);
+			elx_str_cpy((char *)ae->un.OsNameVersion, (char *)str);
+			len = elx_str_len((char *)ae->un.OsNameVersion);
+			len += (len & 3) ? (4 - (len & 3)) : 4;
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + len);
+			ab->EntryCnt++;
+			size += FOURBYTES + len;
+
+			/* #11 HBA attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) rh + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(MAX_CT_PAYLOAD_LEN);
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + 4);
+			ae->un.MaxCTPayloadLen = (65 * 4096);
+			ab->EntryCnt++;
+			size += FOURBYTES + 4;
+
+			ab->EntryCnt = SWAP_DATA(ab->EntryCnt);
+			/* Total size */
+			size = GID_REQUEST_SZ - 4 + size;
+		}
+		break;
+
+	case SLI_MGMT_RPA:
+		{
+			elx_vpd_t *vp;
+			SERV_PARM *hsp;
+			char *str;
+			int len;
+
+			vp = &phba->vpd;
+
+			CtReq->CommandResponse.bits.CmdRsp =
+			    SWAP_DATA16(SLI_MGMT_RPA);
+			CtReq->CommandResponse.bits.Size = 0;
+			pab = (REG_PORT_ATTRIBUTE *) & CtReq->un.PortID;
+			size = sizeof (NAME_TYPE) + FOURBYTES;
+			memcpy((uint8_t *) & pab->PortName,
+			       (uint8_t *) & plhba->fc_sparam.portName,
+			       sizeof (NAME_TYPE));
+			pab->ab.EntryCnt = 0;
+
+			/* #1 Port attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) pab + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(SUPPORTED_FC4_TYPES);
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + 32);
+			ae->un.SupportFC4Types[2] = 1;
+			ae->un.SupportFC4Types[7] = 1;
+			pab->ab.EntryCnt++;
+			size += FOURBYTES + 32;
+
+			/* #2 Port attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) pab + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(SUPPORTED_SPEED);
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + 4);
+			if (FC_JEDEC_ID(vp->rev.biuRev) == VIPER_JEDEC_ID)
+				ae->un.SupportSpeed = HBA_PORTSPEED_10GBIT;
+			else if ((FC_JEDEC_ID(vp->rev.biuRev) ==
+				  CENTAUR_2G_JEDEC_ID)
+				 || (FC_JEDEC_ID(vp->rev.biuRev) ==
+				     PEGASUS_JEDEC_ID)
+				 || (FC_JEDEC_ID(vp->rev.biuRev) ==
+				     THOR_JEDEC_ID))
+				ae->un.SupportSpeed = HBA_PORTSPEED_2GBIT;
+			else
+				ae->un.SupportSpeed = HBA_PORTSPEED_1GBIT;
+			pab->ab.EntryCnt++;
+			size += FOURBYTES + 4;
+
+			/* #3 Port attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) pab + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(PORT_SPEED);
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + 4);
+			if (plhba->fc_linkspeed == LA_2GHZ_LINK)
+				ae->un.PortSpeed = HBA_PORTSPEED_2GBIT;
+			else
+				ae->un.PortSpeed = HBA_PORTSPEED_1GBIT;
+			pab->ab.EntryCnt++;
+			size += FOURBYTES + 4;
+
+			/* #4 Port attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) pab + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(MAX_FRAME_SIZE);
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + 4);
+			hsp = (SERV_PARM *) & plhba->fc_sparam;
+			ae->un.MaxFrameSize =
+			    (((uint32_t) hsp->cmn.
+			      bbRcvSizeMsb) << 8) | (uint32_t) hsp->cmn.
+			    bbRcvSizeLsb;
+			pab->ab.EntryCnt++;
+			size += FOURBYTES + 4;
+
+			/* #5 Port attribute entry */
+			ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) pab + size);
+			ae->ad.bits.AttrType = SWAP_DATA16(OS_DEVICE_NAME);
+			elx_str_cpy((char *)ae->un.OsDeviceName, "lpfcdd");
+			len = elx_str_len((char *)ae->un.OsDeviceName);
+			len += (len & 3) ? (4 - (len & 3)) : 4;
+			ae->ad.bits.AttrLen = SWAP_DATA16(FOURBYTES + len);
+			pab->ab.EntryCnt++;
+			size += FOURBYTES + len;
+
+			if (clp[LPFC_CFG_FDMI_ON].a_current == 2) {
+				/* #6 Port attribute entry */
+				ae = (ATTRIBUTE_ENTRY *) ((uint8_t *) pab +
+							  size);
+				ae->ad.bits.AttrType = SWAP_DATA16(HOST_NAME);
+				str = lpfc_get_OsNameVersion(GET_HOST_NAME);
+				elx_str_cpy((char *)ae->un.HostName,
+					    (char *)str);
+				len = elx_str_len((char *)ae->un.HostName);
+				len += (len & 3) ? (4 - (len & 3)) : 4;
+				ae->ad.bits.AttrLen =
+				    SWAP_DATA16(FOURBYTES + len);
+				pab->ab.EntryCnt++;
+				size += FOURBYTES + len;
+			}
+
+			pab->ab.EntryCnt = SWAP_DATA(pab->ab.EntryCnt);
+			/* Total size */
+			size = GID_REQUEST_SZ - 4 + size;
+		}
+		break;
+
+	case SLI_MGMT_DHBA:
+		CtReq->CommandResponse.bits.CmdRsp = SWAP_DATA16(SLI_MGMT_DHBA);
+		CtReq->CommandResponse.bits.Size = 0;
+		pe = (PORT_ENTRY *) & CtReq->un.PortID;
+		memcpy((uint8_t *) & pe->PortName,
+		       (uint8_t *) & plhba->fc_sparam.portName,
+		       sizeof (NAME_TYPE));
+		size = GID_REQUEST_SZ - 4 + sizeof (NAME_TYPE);
+		break;
+
+	case SLI_MGMT_DPRT:
+		CtReq->CommandResponse.bits.CmdRsp = SWAP_DATA16(SLI_MGMT_DPRT);
+		CtReq->CommandResponse.bits.Size = 0;
+		pe = (PORT_ENTRY *) & CtReq->un.PortID;
+		memcpy((uint8_t *) & pe->PortName,
+		       (uint8_t *) & plhba->fc_sparam.portName,
+		       sizeof (NAME_TYPE));
+		size = GID_REQUEST_SZ - 4 + sizeof (NAME_TYPE);
+		break;
+	}
+
+	bpl = (ULP_BDE64 *) bmp->virt;
+	bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(mp->phys));
+	bpl->addrLow = PCIMEM_LONG(putPaddrLow(mp->phys));
+	bpl->tus.f.bdeFlags = 0;
+	bpl->tus.f.bdeSize = size;
+	bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+
+	cmpl = lpfc_cmpl_ct_cmd_fdmi;
+
+	if (lpfc_ct_cmd(phba, mp, bmp, ndlp, cmpl)) {
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+		/* Issue FDMI request failed */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0244,	/* ptr to msg structure */
+			       elx_mes0244,	/* ptr to msg */
+			       elx_msgBlk0244.msgPreambleStr,	/* begin varargs */
+			       cmdcode);	/* end varargs */
+		return (1);
+	}
+	return (0);
+}
+
+void
+lpfc_cmpl_ct_cmd_fdmi(elxHBA_t * phba,
+		      ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFCHBA_t *plhba;
+	DMABUF_t *bmp;
+	DMABUF_t *inp;
+	DMABUF_t *outp;
+	SLI_CT_REQUEST *CTrsp;
+	SLI_CT_REQUEST *CTcmd;
+	LPFC_NODELIST_t *ndlp;
+	uint16_t fdmi_cmd;
+	uint16_t fdmi_rsp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	inp = (DMABUF_t *) cmdiocb->context1;
+	outp = (DMABUF_t *) cmdiocb->context2;
+	bmp = (DMABUF_t *) cmdiocb->context3;
+
+	CTcmd = (SLI_CT_REQUEST *) inp->virt;
+	CTrsp = (SLI_CT_REQUEST *) outp->virt;
+	ndlp = (LPFC_NODELIST_t *) inp->next;
+
+	fdmi_rsp = CTrsp->CommandResponse.bits.CmdRsp;
+	fdmi_cmd = CTcmd->CommandResponse.bits.CmdRsp;
+
+	if (fdmi_rsp == SWAP_DATA16(SLI_CT_RESPONSE_FS_RJT)) {
+		/* FDMI rsp failed */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0220,	/* ptr to msg structure */
+			       elx_mes0220,	/* ptr to msg */
+			       elx_msgBlk0220.msgPreambleStr,	/* begin varargs */
+			       SWAP_DATA16(fdmi_cmd));	/* end varargs */
+	}
+
+	switch (SWAP_DATA16(fdmi_cmd)) {
+	case SLI_MGMT_RHBA:
+		lpfc_fdmi_cmd(phba, ndlp, SLI_MGMT_RPA);
+		break;
+
+	case SLI_MGMT_RPA:
+		break;
+
+	case SLI_MGMT_DHBA:
+		lpfc_fdmi_cmd(phba, ndlp, SLI_MGMT_DPRT);
+		break;
+
+	case SLI_MGMT_DPRT:
+		lpfc_fdmi_cmd(phba, ndlp, SLI_MGMT_RHBA);
+		break;
+	}
+
+	lpfc_free_ct_rsp(phba, outp);
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) inp);
+	elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+	elx_mem_put(phba, MEM_IOCB, (uint8_t *) cmdiocb);
+	return;
+}
+
+void
+lpfc_fdmi_tmo(elxHBA_t * phba, void *arg1, void *arg2)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+	int ret;
+
+	ndlp = (LPFC_NODELIST_t *) arg1;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ret = lpfc_utsname_nodename_check();
+	if (ret) {
+		plhba->fc_fdmitmo =
+		    elx_clk_set(phba, 60, lpfc_fdmi_tmo, ndlp, 0);
+		return;
+	}
+	plhba->fc_fdmitmo = 0;
+	lpfc_fdmi_cmd(phba, ndlp, SLI_MGMT_DHBA);
+	return;
+}
+
+#define TRUE    1
+#define FALSE   0
+
+int lpfc_els_rcv_rscn(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_rcv_flogi(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_rcv_rrq(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_rcv_rnid(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_rcv_farp(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_rcv_farpr(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_rcv_fan(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+
+int lpfc_max_els_tries = 3;
+
+int
+lpfc_initial_flogi(elxHBA_t * phba)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* First look for Fabric ndlp on the unmapped list */
+
+	if ((ndlp =
+	     lpfc_findnode_did(phba, (NLP_SEARCH_UNMAPPED | NLP_SEARCH_DEQUE),
+			       Fabric_DID)) == 0) {
+		/* Cannot find existing Fabric ndlp, so allocate a new one */
+		if ((ndlp =
+		     (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP)) == 0) {
+			return (0);
+		}
+		memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+		ndlp->nlp_DID = Fabric_DID;
+	}
+	if (lpfc_issue_els_flogi(phba, ndlp, 0)) {
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	}
+	return (1);
+}
+
+int
+lpfc_issue_els_flogi(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, uint8_t retry)
+{
+	SERV_PARM *sp;
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+	uint32_t tmo;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = (sizeof (uint32_t) + sizeof (SERV_PARM));
+	if ((elsiocb = lpfc_prep_els_iocb(phba, TRUE, cmdsize, retry,
+					  ndlp, ELS_CMD_FLOGI)) == 0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	/* For FLOGI request, remainder of payload is service parameters */
+	*((uint32_t *) (pCmd)) = ELS_CMD_FLOGI;
+	pCmd += sizeof (uint32_t);
+	memcpy((void *)pCmd, (void *)&plhba->fc_sparam, sizeof (SERV_PARM));
+	sp = (SERV_PARM *) pCmd;
+
+	/* Setup CSPs accordingly for Fabric */
+	sp->cmn.e_d_tov = 0;
+	sp->cmn.w2.r_a_tov = 0;
+	sp->cls1.classValid = 0;
+	sp->cls2.seqDelivery = 1;
+	sp->cls3.seqDelivery = 1;
+	if (sp->cmn.fcphLow < FC_PH3)
+		sp->cmn.fcphLow = FC_PH3;
+	if (sp->cmn.fcphHigh < FC_PH3)
+		sp->cmn.fcphHigh = FC_PH3;
+
+	tmo = plhba->fc_ratov;
+	plhba->fc_ratov = LPFC_DISC_FLOGI_TMO;
+	lpfc_set_disctmo(phba);
+	plhba->fc_ratov = tmo;
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitFLOGI++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_flogi;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+void
+lpfc_cmpl_els_flogi(elxHBA_t * phba,
+		    ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFCHBA_t *plhba;
+	IOCB_t *irsp;
+	DMABUF_t *pCmd, *pRsp;
+	SERV_PARM *sp;
+	uint32_t *lp;
+	ELX_MBOXQ_t *mbox;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	elxCfgParam_t *clp;
+	uint32_t rc;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	irsp = &(rspiocb->iocb);
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	clp = &phba->config[0];
+
+	/* Check to see if link went down during discovery */
+	lpfc_els_chk_latt(phba, rspiocb);
+
+	if (irsp->ulpStatus) {
+		/* Check for retry */
+		if (lpfc_els_retry(phba, cmdiocb, rspiocb)) {
+			/* ELS command is being retried */
+			goto out;
+		}
+		/* FLOGI failed, so there is no fabric */
+		plhba->fc_flag &= ~(FC_FABRIC | FC_PUBLIC_LOOP);
+
+		/* If private loop, then allow max outstandting els to be
+		 * LPFC_MAX_DISC_THREADS (32). Scanning in the case of no 
+		 * alpa map would take too long otherwise. 
+		 */
+		if (plhba->alpa_map[0] == 0) {
+			clp[LPFC_CFG_DISC_THREADS].a_current =
+			    LPFC_MAX_DISC_THREADS;
+		}
+
+		/* FLOGI failure */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0100,	/* ptr to msg structure */
+			       elx_mes0100,	/* ptr to msg */
+			       elx_msgBlk0100.msgPreambleStr,	/* begin varargs */
+			       irsp->ulpStatus, irsp->un.ulpWord[4]);	/* end varargs */
+	} else {
+		pRsp = (DMABUF_t *) pCmd->next;
+		/* Good status */
+		lp = (uint32_t *) pRsp->virt;
+		elx_pci_dma_sync((void *)phba, (void *)pRsp,
+				 0, ELX_DMA_SYNC_FORCPU);
+		sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+
+		/* FLOGI completes successfully */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0101,	/* ptr to msg structure */
+			       elx_mes0101,	/* ptr to msg */
+			       elx_msgBlk0101.msgPreambleStr,	/* begin varargs */
+			       irsp->un.ulpWord[4], sp->cmn.e_d_tov, sp->cmn.w2.r_a_tov, sp->cmn.edtovResolution);	/* end varargs */
+
+		if (phba->hba_state == ELX_FLOGI) {
+			/* If Common Service Parameters indicate Nport
+			 * we are point to point, if Fport we are Fabric.
+			 */
+			if (sp->cmn.fPort) {
+				plhba->fc_flag |= FC_FABRIC;
+				if (sp->cmn.edtovResolution) {
+					/* E_D_TOV ticks are in nanoseconds */
+					plhba->fc_edtov =
+					    (SWAP_DATA(sp->cmn.e_d_tov) +
+					     999999) / 1000000;
+				} else {
+					/* E_D_TOV ticks are in milliseconds */
+					plhba->fc_edtov =
+					    SWAP_DATA(sp->cmn.e_d_tov);
+				}
+				plhba->fc_ratov =
+				    (SWAP_DATA(sp->cmn.w2.r_a_tov) +
+				     999) / 1000;
+				phba->fcp_timeout_offset =
+				    2 * plhba->fc_ratov +
+				    clp[ELX_CFG_EXTRA_IO_TMO].a_current;
+
+				if (plhba->fc_topology == TOPOLOGY_LOOP) {
+					plhba->fc_flag |= FC_PUBLIC_LOOP;
+				} else {
+					/* If we are a N-port connected to a Fabric, 
+					 * fixup sparam's so logins to devices on
+					 * remote loops work.
+					 */
+					plhba->fc_sparam.cmn.altBbCredit = 1;
+				}
+
+				plhba->fc_myDID =
+				    irsp->un.ulpWord[4] & Mask_DID;
+
+				memcpy((void *)&ndlp->nlp_portname,
+				       (void *)&sp->portName,
+				       sizeof (NAME_TYPE));
+				memcpy((void *)&ndlp->nlp_nodename,
+				       (void *)&sp->nodeName,
+				       sizeof (NAME_TYPE));
+				memcpy((void *)&plhba->fc_fabparam, (void *)sp,
+				       sizeof (SERV_PARM));
+				if ((mbox =
+				     (ELX_MBOXQ_t *) elx_mem_get(phba,
+								 MEM_MBOX)) ==
+				    0) {
+					goto flogifail;
+				}
+				phba->hba_state = ELX_FABRIC_CFG_LINK;
+				lpfc_config_link(phba, mbox);
+				if (elx_sli_issue_mbox
+				    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+				    == MBX_NOT_FINISHED) {
+					elx_mem_put(phba, MEM_MBOX,
+						    (uint8_t *) mbox);
+					goto flogifail;
+				}
+
+				if ((mbox =
+				     (ELX_MBOXQ_t *) elx_mem_get(phba,
+								 MEM_MBOX)) ==
+				    0) {
+					goto flogifail;
+				}
+				if (lpfc_reg_login(phba, Fabric_DID,
+						   (uint8_t *) sp, mbox,
+						   0) == 0) {
+					/* set_slim mailbox command needs to execute first,
+					 * queue this command to be processed later.
+					 */
+					mbox->mbox_cmpl =
+					    lpfc_mbx_cmpl_fabric_reg_login;
+					mbox->context2 = (void *)ndlp;
+					if (elx_sli_issue_mbox
+					    (phba, mbox,
+					     (MBX_NOWAIT | MBX_STOP_IOCB))
+					    == MBX_NOT_FINISHED) {
+						elx_mem_put(phba, MEM_MBOX,
+							    (uint8_t *) mbox);
+						goto flogifail;
+					}
+				} else {
+					elx_mem_put(phba, MEM_MBOX,
+						    (uint8_t *) mbox);
+					goto flogifail;
+				}
+			} else {
+				/* We FLOGIed into an NPort, initiate pt2pt protocol */
+				plhba->fc_flag &= ~(FC_FABRIC | FC_PUBLIC_LOOP);
+				plhba->fc_edtov = FF_DEF_EDTOV;
+				plhba->fc_ratov = FF_DEF_RATOV;
+				phba->fcp_timeout_offset = 2 * plhba->fc_ratov +
+				    clp[ELX_CFG_EXTRA_IO_TMO].a_current;
+				if ((rc =
+				     lpfc_geportname((NAME_TYPE *) & plhba->
+						     fc_portname,
+						     (NAME_TYPE *) & sp->
+						     portName))) {
+					/* This side will initiate the PLOGI */
+					plhba->fc_flag |= FC_PT2PT_PLOGI;
+
+					/* N_Port ID cannot be 0, set our to LocalID the 
+					 * other side will be RemoteID.
+					 */
+
+					/* not equal */
+					if (rc == 1)
+						plhba->fc_myDID = PT2PT_LocalID;
+					rc = 0;
+
+					if ((mbox =
+					     (ELX_MBOXQ_t *) elx_mem_get(phba,
+									 MEM_MBOX))
+					    == 0) {
+						goto flogifail;
+					}
+					lpfc_config_link(phba, mbox);
+					if (elx_sli_issue_mbox
+					    (phba, mbox,
+					     (MBX_NOWAIT | MBX_STOP_IOCB))
+					    == MBX_NOT_FINISHED) {
+						elx_mem_put(phba, MEM_MBOX,
+							    (uint8_t *) mbox);
+						goto flogifail;
+					}
+					elx_mem_put(phba, MEM_NLP,
+						    (uint8_t *) ndlp);
+
+					if ((ndlp =
+					     lpfc_findnode_did(phba,
+							       NLP_SEARCH_ALL,
+							       PT2PT_RemoteID))
+					    == 0) {
+						/* Cannot find existing Fabric ndlp, so allocate a new one */
+						if ((ndlp =
+						     (LPFC_NODELIST_t *)
+						     elx_mem_get(phba,
+								 MEM_NLP)) ==
+						    0) {
+							goto flogifail;
+						}
+						memset((void *)ndlp, 0,
+						       sizeof
+						       (LPFC_NODELIST_t));
+						ndlp->nlp_DID = PT2PT_RemoteID;
+					}
+					memcpy((void *)&ndlp->nlp_portname,
+					       (void *)&sp->portName,
+					       sizeof (NAME_TYPE));
+					memcpy((void *)&ndlp->nlp_nodename,
+					       (void *)&sp->nodeName,
+					       sizeof (NAME_TYPE));
+					lpfc_nlp_plogi(phba, ndlp);
+				} else {
+					/* This side will wait for the PLOGI */
+					elx_mem_put(phba, MEM_NLP,
+						    (uint8_t *) ndlp);
+				}
+
+				plhba->fc_flag |= FC_PT2PT;
+				lpfc_set_disctmo(phba);
+
+				/* Start discovery - this should just do CLEAR_LA */
+				lpfc_disc_start(phba);
+			}
+			goto out;
+		}
+	}
+
+      flogifail:
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+
+	/* FLOGI failed, so just use loop map to make discovery list */
+	lpfc_disc_list_loopmap(phba);
+
+	/* Start discovery */
+	lpfc_disc_start(phba);
+
+      out:
+	lpfc_els_free_iocb(phba, cmdiocb);
+	return;
+}
+
+int
+lpfc_issue_els_plogi(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, uint8_t retry)
+{
+	SERV_PARM *sp;
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = (sizeof (uint32_t) + sizeof (SERV_PARM));
+	if ((elsiocb = lpfc_prep_els_iocb(phba, TRUE, cmdsize, retry,
+					  ndlp, ELS_CMD_PLOGI)) == 0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	/* For PLOGI request, remainder of payload is service parameters */
+	*((uint32_t *) (pCmd)) = ELS_CMD_PLOGI;
+	pCmd += sizeof (uint32_t);
+
+	/* For LOGI request, remainder of payload is service parameters */
+	memcpy((void *)pCmd, (void *)&plhba->fc_sparam, sizeof (SERV_PARM));
+	sp = (SERV_PARM *) pCmd;
+
+	if (sp->cmn.fcphLow < FC_PH_4_3)
+		sp->cmn.fcphLow = FC_PH_4_3;
+
+	if (sp->cmn.fcphHigh < FC_PH3)
+		sp->cmn.fcphHigh = FC_PH3;
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitPLOGI++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_plogi;
+	ndlp->nlp_flag |= NLP_PLOGI_SND;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		ndlp->nlp_flag &= ~NLP_PLOGI_SND;
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+void
+lpfc_cmpl_els_plogi(elxHBA_t * phba,
+		    ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	IOCB_t *irsp;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	int disc;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* we pass cmdiocb to state machine which needs rspiocb as well */
+	cmdiocb->q_f = rspiocb;
+
+	irsp = &rspiocb->iocb;
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+	ndlp->nlp_flag &= ~NLP_PLOGI_SND;
+
+	/* Since ndlp can be freed in the disc state machine, note if this node
+	 * is being used during discovery.
+	 */
+	disc = (ndlp->nlp_flag & NLP_DISC_NODE);
+	ndlp->nlp_flag &= ~NLP_DISC_NODE;
+
+	/* PLOGI completes to NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0102,	/* ptr to msg structure */
+		       elx_mes0102,	/* ptr to msg */
+		       elx_msgBlk0102.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, irsp->ulpStatus, irsp->un.ulpWord[4], disc, plhba->num_disc_nodes);	/* end varargs */
+
+	/* Check to see if link went down during discovery */
+	lpfc_els_chk_latt(phba, rspiocb);
+
+	if (irsp->ulpStatus) {
+		/* Check for retry */
+		if (lpfc_els_retry(phba, cmdiocb, rspiocb)) {
+			/* ELS command is being retried */
+			if (disc) {
+				ndlp->nlp_flag |= NLP_DISC_NODE;
+			}
+			goto out;
+		}
+
+		/* PLOGI failed */
+		lpfc_disc_state_machine(phba, ndlp, (void *)cmdiocb,
+					NLP_EVT_CMPL_PLOGI);
+	} else {
+		/* Good status, call state machine */
+		lpfc_disc_state_machine(phba, ndlp, (void *)cmdiocb,
+					NLP_EVT_CMPL_PLOGI);
+	}
+
+	if (disc && plhba->num_disc_nodes) {
+		/* Check to see if there are more PLOGIs to be sent */
+		lpfc_more_plogi(phba);
+	}
+
+	if (plhba->num_disc_nodes == 0) {
+		if (disc) {
+			phba->hba_flag &= ~FC_NDISC_ACTIVE;
+		}
+		lpfc_can_disctmo(phba);
+		if (plhba->fc_flag & FC_RSCN_MODE) {
+			/* Check to see if more RSCNs came in while we were
+			 * processing this one.
+			 */
+			if ((plhba->fc_rscn_id_cnt == 0) &&
+			    (!(plhba->fc_flag & FC_RSCN_DISCOVERY))) {
+				lpfc_els_flush_rscn(phba);
+			} else {
+				lpfc_els_handle_rscn(phba);
+			}
+		}
+	}
+      out:
+	lpfc_els_free_iocb(phba, cmdiocb);
+	return;
+}
+
+int
+lpfc_issue_els_prli(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, uint8_t retry)
+{
+	PRLI *npr;
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = (sizeof (uint32_t) + sizeof (PRLI));
+	if ((elsiocb = lpfc_prep_els_iocb(phba, TRUE, cmdsize, retry,
+					  ndlp, ELS_CMD_PRLI)) == 0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	/* For PRLI request, remainder of payload is service parameters */
+	memset((void *)pCmd, 0, (sizeof (PRLI) + sizeof (uint32_t)));
+	*((uint32_t *) (pCmd)) = ELS_CMD_PRLI;
+	pCmd += sizeof (uint32_t);
+
+	/* For PRLI, remainder of payload is PRLI parameter page */
+	npr = (PRLI *) pCmd;
+	/*
+	 * If our firmware version is 3.20 or later, 
+	 * set the following bits for FC-TAPE support.
+	 */
+	if (phba->vpd.rev.feaLevelHigh >= 0x02) {
+		npr->ConfmComplAllowed = 1;
+		npr->Retry = 1;
+		npr->TaskRetryIdReq = 1;
+	}
+	npr->estabImagePair = 1;
+	npr->readXferRdyDis = 1;
+
+	/* For FCP support */
+	npr->prliType = PRLI_FCP_TYPE;
+	npr->initiatorFunc = 1;
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitPRLI++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_prli;
+	ndlp->nlp_flag |= NLP_PRLI_SND;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		ndlp->nlp_flag &= ~NLP_PRLI_SND;
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	plhba->fc_prli_sent++;
+	return (0);
+}
+
+void
+lpfc_cmpl_els_prli(elxHBA_t * phba,
+		   ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFCHBA_t *plhba;
+	IOCB_t *irsp;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	/* we pass cmdiocb to state machine which needs rspiocb as well */
+	cmdiocb->q_f = rspiocb;
+
+	irsp = &(rspiocb->iocb);
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+	ndlp->nlp_flag &= ~NLP_PRLI_SND;
+
+	/* PRLI completes to NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0103,	/* ptr to msg structure */
+		       elx_mes0103,	/* ptr to msg */
+		       elx_msgBlk0103.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, irsp->ulpStatus, irsp->un.ulpWord[4], plhba->num_disc_nodes);	/* end varargs */
+
+	plhba->fc_prli_sent--;
+	/* Check to see if link went down during discovery */
+	lpfc_els_chk_latt(phba, rspiocb);
+
+	if (irsp->ulpStatus) {
+		/* Check for retry */
+		if (lpfc_els_retry(phba, cmdiocb, rspiocb)) {
+			/* ELS command is being retried */
+			goto out;
+		}
+		/* PRLI failed */
+		lpfc_disc_state_machine(phba, ndlp, (void *)cmdiocb,
+					NLP_EVT_CMPL_PRLI);
+	} else {
+		/* Good status, call state machine */
+		lpfc_disc_state_machine(phba, ndlp, (void *)cmdiocb,
+					NLP_EVT_CMPL_PRLI);
+	}
+      out:
+	lpfc_els_free_iocb(phba, cmdiocb);
+	return;
+}
+
+int
+lpfc_issue_els_adisc(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, uint8_t retry)
+{
+	ADISC *ap;
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = (sizeof (uint32_t) + sizeof (ADISC));
+	if ((elsiocb = lpfc_prep_els_iocb(phba, TRUE, cmdsize, retry,
+					  ndlp, ELS_CMD_ADISC)) == 0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	/* For ADISC request, remainder of payload is service parameters */
+	*((uint32_t *) (pCmd)) = ELS_CMD_ADISC;
+	pCmd += sizeof (uint32_t);
+
+	/* Fill in ADISC payload */
+	ap = (ADISC *) pCmd;
+	ap->hardAL_PA = plhba->fc_pref_ALPA;
+	memcpy((void *)&ap->portName, (void *)&plhba->fc_portname,
+	       sizeof (NAME_TYPE));
+	memcpy((void *)&ap->nodeName, (void *)&plhba->fc_nodename,
+	       sizeof (NAME_TYPE));
+	ap->DID = SWAP_DATA(plhba->fc_myDID);
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitADISC++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_adisc;
+	ndlp->nlp_flag |= NLP_ADISC_SND;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		ndlp->nlp_flag &= ~NLP_ADISC_SND;
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+void
+lpfc_cmpl_els_adisc(elxHBA_t * phba,
+		    ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	IOCB_t *irsp;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	ELX_MBOXQ_t *mbox;
+	int disc;
+	elxCfgParam_t *clp;
+
+	clp = &phba->config[0];
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* we pass cmdiocb to state machine which needs rspiocb as well */
+	cmdiocb->q_f = rspiocb;
+
+	irsp = &(rspiocb->iocb);
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+	ndlp->nlp_flag &= ~NLP_ADISC_SND;
+
+	/* Since ndlp can be freed in the disc state machine, note if this node
+	 * is being used during discovery.
+	 */
+	disc = (ndlp->nlp_flag & NLP_DISC_NODE);
+	ndlp->nlp_flag &= ~NLP_DISC_NODE;
+
+	/* ADISC completes to NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0104,	/* ptr to msg structure */
+		       elx_mes0104,	/* ptr to msg */
+		       elx_msgBlk0104.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, irsp->ulpStatus, irsp->un.ulpWord[4], disc, plhba->num_disc_nodes);	/* end varargs */
+
+	/* Check to see if link went down during discovery */
+	lpfc_els_chk_latt(phba, rspiocb);
+
+	if (irsp->ulpStatus) {
+		/* Check for retry */
+		if (lpfc_els_retry(phba, cmdiocb, rspiocb)) {
+			/* ELS command is being retried */
+			if (disc) {
+				ndlp->nlp_flag |= NLP_DISC_NODE;
+				lpfc_set_disctmo(phba);
+			}
+			goto out;
+		}
+		/* ADISC failed */
+		lpfc_disc_state_machine(phba, ndlp, (void *)cmdiocb,
+					NLP_EVT_CMPL_ADISC);
+	} else {
+		/* Good status, call state machine */
+		lpfc_disc_state_machine(phba, ndlp, (void *)cmdiocb,
+					NLP_EVT_CMPL_ADISC);
+	}
+
+	if (disc && plhba->num_disc_nodes) {
+		/* Check to see if there are more ADISCs to be sent */
+		lpfc_more_adisc(phba);
+
+		/* Check to see if we are done with ADISC authentication */
+		if (plhba->num_disc_nodes == 0) {
+			/* If we get here, there is nothing left to wait for */
+			if ((phba->hba_state < ELX_HBA_READY) &&
+			    (phba->hba_state != ELX_CLEAR_LA)) {
+				/* Link up discovery */
+				if ((mbox =
+				     (ELX_MBOXQ_t *) elx_mem_get(phba,
+								 MEM_MBOX |
+								 MEM_PRI))) {
+					phba->hba_state = ELX_CLEAR_LA;
+					lpfc_clear_la(phba, mbox);
+					mbox->mbox_cmpl =
+					    lpfc_mbx_cmpl_clear_la;
+					if (elx_sli_issue_mbox
+					    (phba, mbox,
+					     (MBX_NOWAIT | MBX_STOP_IOCB))
+					    == MBX_NOT_FINISHED) {
+						elx_mem_put(phba, MEM_MBOX,
+							    (uint8_t *) mbox);
+						lpfc_disc_flush_list(phba);
+						psli->ring[(psli->ip_ring)].
+						    flag &=
+						    ~ELX_STOP_IOCB_EVENT;
+						psli->ring[(psli->fcp_ring)].
+						    flag &=
+						    ~ELX_STOP_IOCB_EVENT;
+						psli->ring[(psli->next_ring)].
+						    flag &=
+						    ~ELX_STOP_IOCB_EVENT;
+						phba->hba_state = ELX_HBA_READY;
+					}
+				}
+			} else {
+				/* RSCN discovery */
+				/* go thru PLOGI list and issue ELS PLOGIs */
+				if (plhba->fc_plogi_cnt) {
+					ndlp = plhba->fc_plogi_start;
+					while (ndlp !=
+					       (LPFC_NODELIST_t *) & plhba->
+					       fc_plogi_start) {
+						if (ndlp->nlp_state ==
+						    NLP_STE_UNUSED_NODE) {
+							ndlp->nlp_state =
+							    NLP_STE_PLOGI_ISSUE;
+							lpfc_issue_els_plogi
+							    (phba, ndlp, 0);
+							ndlp->nlp_flag |=
+							    NLP_DISC_NODE;
+							plhba->num_disc_nodes++;
+							if (plhba->
+							    num_disc_nodes >=
+							    clp
+							    [LPFC_CFG_DISC_THREADS].
+							    a_current) {
+								if (plhba->
+								    fc_plogi_cnt
+								    >
+								    plhba->
+								    num_disc_nodes)
+									plhba->
+									    fc_flag
+									    |=
+									    FC_NLP_MORE;
+								break;
+							}
+						}
+						ndlp =
+						    (LPFC_NODELIST_t *) ndlp->
+						    nle.nlp_listp_next;
+					}
+				} else {
+					if (plhba->fc_flag & FC_RSCN_MODE) {
+						/* Check to see if more RSCNs came in while we were
+						 * processing this one.
+						 */
+						if ((plhba->fc_rscn_id_cnt == 0)
+						    &&
+						    (!(plhba->
+						       fc_flag &
+						       FC_RSCN_DISCOVERY))) {
+							lpfc_els_flush_rscn
+							    (phba);
+						} else {
+							lpfc_els_handle_rscn
+							    (phba);
+						}
+					}
+				}
+			}
+		}
+	}
+      out:
+	lpfc_els_free_iocb(phba, cmdiocb);
+	return;
+}
+
+int
+lpfc_issue_els_logo(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, uint8_t retry)
+{
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = 2 * (sizeof (uint32_t) + sizeof (NAME_TYPE));
+	if ((elsiocb = lpfc_prep_els_iocb(phba, TRUE, cmdsize, retry,
+					  ndlp, ELS_CMD_LOGO)) == 0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+	*((uint32_t *) (pCmd)) = ELS_CMD_LOGO;
+	pCmd += sizeof (uint32_t);
+
+	/* Fill in LOGO payload */
+	*((uint32_t *) (pCmd)) = SWAP_DATA(plhba->fc_myDID);
+	pCmd += sizeof (uint32_t);
+	memcpy((void *)pCmd, (void *)&plhba->fc_portname, sizeof (NAME_TYPE));
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitLOGO++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_logo;
+	ndlp->nlp_flag |= NLP_LOGO_SND;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		ndlp->nlp_flag &= ~NLP_LOGO_SND;
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+void
+lpfc_cmpl_els_logo(elxHBA_t * phba,
+		   ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	IOCB_t *irsp;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	/* we pass cmdiocb to state machine which needs rspiocb as well */
+	cmdiocb->q_f = rspiocb;
+
+	irsp = &(rspiocb->iocb);
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+	ndlp->nlp_flag &= ~NLP_LOGO_SND;
+
+	/* LOGO completes to NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0105,	/* ptr to msg structure */
+		       elx_mes0105,	/* ptr to msg */
+		       elx_msgBlk0105.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, irsp->ulpStatus, irsp->un.ulpWord[4], plhba->num_disc_nodes);	/* end varargs */
+
+	/* Check to see if link went down during discovery */
+	lpfc_els_chk_latt(phba, rspiocb);
+
+	if (irsp->ulpStatus) {
+		/* Check for retry */
+		if (lpfc_els_retry(phba, cmdiocb, rspiocb)) {
+			/* ELS command is being retried */
+			goto out;
+		}
+		/* LOGO failed */
+		lpfc_disc_state_machine(phba, ndlp, (void *)cmdiocb,
+					NLP_EVT_CMPL_LOGO);
+	} else {
+		/* Good status, call state machine */
+		lpfc_disc_state_machine(phba, ndlp, (void *)cmdiocb,
+					NLP_EVT_CMPL_LOGO);
+	}
+      out:
+	lpfc_els_free_iocb(phba, cmdiocb);
+	return;
+}
+
+int
+lpfc_issue_els_scr(elxHBA_t * phba, uint32_t nportid, uint8_t retry)
+{
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+	LPFC_NODELIST_t *ndlp;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = (sizeof (uint32_t) + sizeof (SCR));
+	if ((ndlp = (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP)) == 0) {
+		return (1);
+	}
+	memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+	ndlp->nlp_DID = nportid;
+
+	if ((elsiocb = lpfc_prep_els_iocb(phba, TRUE, cmdsize, retry,
+					  ndlp, ELS_CMD_SCR)) == 0) {
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	*((uint32_t *) (pCmd)) = ELS_CMD_SCR;
+	pCmd += sizeof (uint32_t);
+
+	/* For SCR, remainder of payload is SCR parameter page */
+	memset((void *)pCmd, 0, sizeof (SCR));
+	((SCR *) pCmd)->Function = SCR_FUNC_FULL;
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitSCR++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_cmd;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (0);
+}
+
+int
+lpfc_issue_els_farp(elxHBA_t * phba, uint8_t * arg, LPFC_FARP_ADDR_TYPE argFlag)
+{
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	FARP *fp;
+	uint8_t *pCmd;
+	uint32_t *lp;
+	uint16_t cmdsize;
+	LPFC_NODELIST_t *ndlp;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = (sizeof (uint32_t) + sizeof (FARP));
+	if ((ndlp = (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP)) == 0) {
+		return (1);
+	}
+	memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+	ndlp->nlp_DID = Bcast_DID;
+	if ((elsiocb = lpfc_prep_els_iocb(phba, TRUE, cmdsize, 0,
+					  ndlp, ELS_CMD_RNID)) == 0) {
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		return (1);
+	}
+
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+	*((uint32_t *) (pCmd)) = ELS_CMD_FARP;
+	pCmd += sizeof (uint32_t);
+
+	/* Provide a timeout value, function, and context.  If the IP node on
+	 * far end never responds, this FARP and all IP bufs must be timed out.
+	 */
+	icmd = &elsiocb->iocb;
+	icmd->ulpTimeout = plhba->fc_ipfarp_timeout;
+	icmd->ulpContext = (uint16_t) ELS_CMD_FARP;
+
+	/* Fill in FARP payload */
+
+	fp = (FARP *) (pCmd);
+	memset((void *)fp, 0, sizeof (FARP));
+	lp = (uint32_t *) pCmd;
+	*lp++ = SWAP_DATA(plhba->fc_myDID);
+	fp->Mflags = FARP_MATCH_PORT;
+	fp->Rflags = FARP_REQUEST_PLOGI;
+	memcpy((void *)&fp->OportName, (void *)&plhba->fc_portname,
+	       sizeof (NAME_TYPE));
+	memcpy((void *)&fp->OnodeName, (void *)&plhba->fc_nodename,
+	       sizeof (NAME_TYPE));
+	switch (argFlag) {
+	case LPFC_FARP_BY_IEEE:
+		fp->Mflags = FARP_MATCH_PORT;
+		fp->RportName.nameType = NAME_IEEE;	/* IEEE name */
+		fp->RportName.IEEEextMsn = 0;
+		fp->RportName.IEEEextLsb = 0;
+		memcpy((void *)fp->RportName.IEEE, arg, 6);
+		fp->RnodeName.nameType = NAME_IEEE;	/* IEEE name */
+		fp->RnodeName.IEEEextMsn = 0;
+		fp->RnodeName.IEEEextLsb = 0;
+		memcpy((void *)fp->RnodeName.IEEE, arg, 6);
+		break;
+	case LPFC_FARP_BY_WWPN:
+		fp->Mflags = FARP_MATCH_PORT;
+		memcpy((void *)&fp->RportName, arg, sizeof (NAME_TYPE));
+		break;
+	case LPFC_FARP_BY_WWNN:
+		fp->Mflags = FARP_MATCH_NODE;
+		memcpy((void *)&fp->RnodeName, arg, sizeof (NAME_TYPE));
+		break;
+	}
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitFARP++;
+
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_cmd;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+
+	elx_printf_log(phba->brd_no, &elx_msgBlk0610,	/* ptr to msg structure */
+		       elx_mes0610,	/* ptr to msg */
+		       elx_msgBlk0610.msgPreambleStr,	/* begin varargs */
+		       plhba->fc_nodename.IEEE[0], plhba->fc_nodename.IEEE[1], plhba->fc_nodename.IEEE[2], plhba->fc_nodename.IEEE[3], plhba->fc_nodename.IEEE[4], plhba->fc_nodename.IEEE[5]);	/* end varargs */
+	return (0);
+}
+
+int
+lpfc_issue_els_farpr(elxHBA_t * phba, uint32_t nportid, uint8_t retry)
+{
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	FARP *fp;
+	uint8_t *pCmd;
+	uint32_t *lp;
+	uint16_t cmdsize;
+	LPFC_NODELIST_t *ondlp;
+	LPFC_NODELIST_t *ndlp;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = (sizeof (uint32_t) + sizeof (FARP));
+	if ((ndlp = (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP)) == 0) {
+		return (1);
+	}
+	memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+	ndlp->nlp_DID = nportid;
+
+	if ((elsiocb = lpfc_prep_els_iocb(phba, TRUE, cmdsize, retry,
+					  ndlp, ELS_CMD_RNID)) == 0) {
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	*((uint32_t *) (pCmd)) = ELS_CMD_FARPR;
+	pCmd += sizeof (uint32_t);
+
+	/* Fill in FARPR payload */
+	fp = (FARP *) (pCmd);
+	memset((void *)fp, 0, sizeof (FARP));
+	lp = (uint32_t *) pCmd;
+	*lp++ = SWAP_DATA(nportid);
+	*lp++ = SWAP_DATA(plhba->fc_myDID);
+	fp->Rflags = 0;
+	fp->Mflags = (FARP_MATCH_PORT | FARP_MATCH_NODE);
+
+	memcpy((void *)&fp->RportName, (void *)&plhba->fc_portname,
+	       sizeof (NAME_TYPE));
+	memcpy((void *)&fp->RnodeName, (void *)&plhba->fc_nodename,
+	       sizeof (NAME_TYPE));
+	if ((ondlp = lpfc_findnode_did(phba, NLP_SEARCH_ALL, nportid))) {
+		memcpy((void *)&fp->OportName, (void *)&ondlp->nlp_portname,
+		       sizeof (NAME_TYPE));
+		memcpy((void *)&fp->OnodeName, (void *)&ondlp->nlp_nodename,
+		       sizeof (NAME_TYPE));
+	}
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitFARPR++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_cmd;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (0);
+}
+
+void
+lpfc_cmpl_els_cmd(elxHBA_t * phba, ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	IOCB_t *irsp;
+
+	irsp = &rspiocb->iocb;
+
+	/* ELS cmd tag <ulpIoTag> completes */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0106,	/* ptr to msg structure */
+		       elx_mes0106,	/* ptr to msg */
+		       elx_msgBlk0106.msgPreambleStr,	/* begin varargs */
+		       irsp->ulpIoTag, irsp->ulpStatus, irsp->un.ulpWord[4]);	/* end varargs */
+
+	/* Check to see if link went down during discovery */
+	lpfc_els_chk_latt(phba, rspiocb);
+	lpfc_els_free_iocb(phba, cmdiocb);
+	return;
+}
+
+void
+lpfc_els_retry_delay(elxHBA_t * phba, void *l1, void *l2)
+{
+	LPFC_NODELIST_t *ndlp;
+	uint32_t cmd;
+	uint32_t did;
+	uint8_t retry;
+
+	did = (uint32_t) (unsigned long)l1;
+	cmd = (uint32_t) (unsigned long)l2;
+	if ((ndlp = lpfc_findnode_did(phba, NLP_SEARCH_ALL, did)) == 0) {
+		if ((ndlp =
+		     (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP)) == 0) {
+			return;
+		}
+		memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+		ndlp->nlp_DID = did;
+	}
+
+	ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+	ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+	ndlp->nlp_tmofunc = 0;
+	retry = ndlp->nlp_retry;
+
+	switch (cmd) {
+	case ELS_CMD_FLOGI:
+		lpfc_issue_els_flogi(phba, ndlp, retry);
+		return;
+	case ELS_CMD_PLOGI:
+		ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+		lpfc_nlp_plogi(phba, ndlp);
+		lpfc_issue_els_plogi(phba, ndlp, retry);
+		return;
+	case ELS_CMD_ADISC:
+		lpfc_issue_els_adisc(phba, ndlp, retry);
+		return;
+	case ELS_CMD_PRLI:
+		lpfc_issue_els_prli(phba, ndlp, retry);
+		return;
+	case ELS_CMD_LOGO:
+		lpfc_issue_els_logo(phba, ndlp, retry);
+		return;
+	}
+	return;
+}
+
+int
+lpfc_els_retry(elxHBA_t * phba, ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFCHBA_t *plhba;
+	IOCB_t *irsp;
+	DMABUF_t *pCmd;
+	LPFC_NODELIST_t *ndlp;
+	ELXSCSITARGET_t *targetp;
+	uint32_t *elscmd;
+	elxCfgParam_t *clp;
+	LS_RJT stat;
+	int retry, maxretry;
+	int delay;
+	uint32_t cmd;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+	retry = 0;
+	delay = 0;
+	maxretry = lpfc_max_els_tries;
+	irsp = &rspiocb->iocb;
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	cmd = 0;
+	/* Note: context2 may be 0 for internal driver abort 
+	 * of delays ELS command.
+	 */
+
+	if (pCmd && pCmd->virt) {
+		elscmd = (uint32_t *) (pCmd->virt);
+		cmd = *elscmd++;
+	}
+
+	switch (irsp->ulpStatus) {
+	case IOSTAT_FCP_RSP_ERROR:
+	case IOSTAT_REMOTE_STOP:
+		break;
+
+	case IOSTAT_LOCAL_REJECT:
+		if ((irsp->un.ulpWord[4] & 0xff) == IOERR_LINK_DOWN)
+			break;
+		if ((irsp->un.ulpWord[4] & 0xff) == IOERR_LOOP_OPEN_FAILURE) {
+			if (cmd == ELS_CMD_PLOGI) {
+				if (cmdiocb->retry == 0) {
+					delay = 1;
+				}
+			}
+			retry = 1;
+			break;
+		}
+		if ((irsp->un.ulpWord[4] & 0xff) == IOERR_SEQUENCE_TIMEOUT) {
+			retry = 1;
+			if ((cmd == ELS_CMD_FLOGI)
+			    && (plhba->fc_topology != TOPOLOGY_LOOP)) {
+				delay = 1;
+				maxretry = 48;
+			}
+			break;
+		}
+		if ((irsp->un.ulpWord[4] & 0xff) == IOERR_NO_RESOURCES) {
+			if (cmd == ELS_CMD_PLOGI) {
+				delay = 1;
+			}
+			retry = 1;
+			break;
+		}
+		if ((irsp->un.ulpWord[4] & 0xff) == IOERR_INVALID_RPI) {
+			retry = 1;
+			break;
+		}
+		break;
+
+	case IOSTAT_NPORT_RJT:
+	case IOSTAT_FABRIC_RJT:
+		if (irsp->un.ulpWord[4] & RJT_UNAVAIL_TEMP) {
+			retry = 1;
+			break;
+		}
+		break;
+
+	case IOSTAT_NPORT_BSY:
+	case IOSTAT_FABRIC_BSY:
+		retry = 1;
+		break;
+
+	case IOSTAT_LS_RJT:
+		stat.un.lsRjtError = SWAP_DATA(irsp->un.ulpWord[4]);
+		/* Added for Vendor specifc support
+		 * Just keep retrying for these Rsn / Exp codes
+		 */
+		switch (stat.un.b.lsRjtRsnCode) {
+		case LSRJT_UNABLE_TPC:
+			if (stat.un.b.lsRjtRsnCodeExp == LSEXP_CMD_IN_PROGRESS) {
+				if (cmd == ELS_CMD_PLOGI) {
+					delay = 1;
+					maxretry = 48;
+				}
+				retry = 1;
+				break;
+			}
+			if (cmd == ELS_CMD_PLOGI) {
+				delay = 1;
+				maxretry = lpfc_max_els_tries + 1;
+				retry = 1;
+				break;
+			}
+			break;
+
+		case LSRJT_LOGICAL_BSY:
+			if (cmd == ELS_CMD_PLOGI) {
+				delay = 1;
+				maxretry = 48;
+			}
+			retry = 1;
+			break;
+		}
+		break;
+
+	case IOSTAT_INTERMED_RSP:
+	case IOSTAT_BA_RJT:
+		break;
+
+	default:
+		break;
+	}
+
+	if (ndlp->nlp_DID == FDMI_DID) {
+		retry = 1;
+	}
+
+	if ((++cmdiocb->retry) >= maxretry) {
+		plhba->fc_stat.elsRetryExceeded++;
+		retry = 0;
+	}
+
+	if (retry) {
+
+		/* Retry ELS command <elsCmd> to remote NPORT <did> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0107,	/* ptr to msg structure */
+			       elx_mes0107,	/* ptr to msg */
+			       elx_msgBlk0107.msgPreambleStr,	/* begin varargs */
+			       cmd, ndlp->nlp_DID, cmdiocb->retry, delay);	/* end varargs */
+
+		if ((cmd == ELS_CMD_PLOGI) || (cmd == ELS_CMD_ADISC)) {
+			/* If discovery / RSCN timer is running, reset it */
+			if ((plhba->fc_disctmo)
+			    || (plhba->fc_flag & FC_RSCN_MODE)) {
+				lpfc_set_disctmo(phba);
+			}
+		}
+
+		plhba->fc_stat.elsXmitRetry++;
+		if (delay) {
+			plhba->fc_stat.elsDelayRetry++;
+			ndlp->nlp_retry = cmdiocb->retry;
+			if (ndlp->nlp_tmofunc) {
+				ndlp->nlp_flag &=
+				    ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+				elx_clk_can(phba, ndlp->nlp_tmofunc);
+				ndlp->nlp_tmofunc = 0;
+			}
+			ndlp->nlp_flag |= NLP_DELAY_TMO;
+			ndlp->nle.nlp_rflag |= NLP_NPR_ACTIVE;
+			ndlp->nlp_tmofunc = elx_clk_set(phba, 0,
+							lpfc_els_retry_delay,
+							(void *)((unsigned long)
+								 ndlp->nlp_DID),
+							(void *)((unsigned long)
+								 cmd));
+			targetp = ndlp->nlp_Target;
+			if (targetp) {
+				targetp->targetFlags |= FC_NPR_ACTIVE;
+				if (targetp->tmofunc) {
+					elx_clk_can(phba, targetp->tmofunc);
+				}
+				targetp->tmofunc = elx_clk_set(phba,
+							       (clp
+								[ELX_CFG_NODEV_TMO].
+								a_current +
+								clp
+								[ELX_CFG_LINKDOWN_TMO].
+								a_current),
+							       lpfc_npr_timeout,
+							       (void *)targetp,
+							       (void *)0);
+			}
+			return (1);
+		}
+		switch (cmd) {
+		case ELS_CMD_FLOGI:
+			lpfc_issue_els_flogi(phba, ndlp, cmdiocb->retry);
+			return (1);
+		case ELS_CMD_PLOGI:
+			lpfc_issue_els_plogi(phba, ndlp, cmdiocb->retry);
+			return (1);
+		case ELS_CMD_ADISC:
+			lpfc_issue_els_adisc(phba, ndlp, cmdiocb->retry);
+			return (1);
+		case ELS_CMD_PRLI:
+			lpfc_issue_els_prli(phba, ndlp, cmdiocb->retry);
+			return (1);
+		case ELS_CMD_LOGO:
+			lpfc_issue_els_logo(phba, ndlp, cmdiocb->retry);
+			return (1);
+		}
+	}
+
+	/* No retry ELS command <elsCmd> to remote NPORT <did> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0108,	/* ptr to msg structure */
+		       elx_mes0108,	/* ptr to msg */
+		       elx_msgBlk0108.msgPreambleStr,	/* begin varargs */
+		       cmd, ndlp->nlp_DID, cmdiocb->retry, ndlp->nlp_flag);	/* end varargs */
+
+	return (0);
+}
+
+ELX_IOCBQ_t *
+lpfc_prep_els_iocb(elxHBA_t * phba,
+		   uint8_t expectRsp,
+		   uint16_t cmdSize,
+		   uint8_t retry, LPFC_NODELIST_t * ndlp, uint32_t elscmd)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_IOCBQ_t *elsiocb;
+	LPFCHBA_t *plhba;
+	DMABUF_t *pCmd, *pRsp, *pBufList;
+	ULP_BDE64 *bpl;
+	IOCB_t *icmd;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if (phba->hba_state < ELX_LINK_UP) {
+		return (0);
+	}
+
+	/* Allocate buffer for  command iocb */
+	if ((elsiocb =
+	     (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB | MEM_PRI)) == 0) {
+		return (0);
+	}
+	memset((void *)elsiocb, 0, sizeof (ELX_IOCBQ_t));
+	icmd = &elsiocb->iocb;
+
+	/* fill in BDEs for command */
+	/* Allocate buffer for command payload */
+	if ((pCmd = (DMABUF_t *) elx_mem_get(phba, MEM_BUF | MEM_PRI)) == 0) {
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) elsiocb);
+		return (0);
+	}
+
+	/* Allocate buffer for response payload */
+	if (expectRsp) {
+		if ((pRsp =
+		     (DMABUF_t *) elx_mem_get(phba, MEM_BUF | MEM_PRI)) == 0) {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) elsiocb);
+			elx_mem_put(phba, MEM_BUF, (uint8_t *) pCmd);
+			return (0);
+		}
+	} else {
+		pRsp = 0;
+	}
+
+	/* Allocate buffer for Buffer ptr list */
+	if ((pBufList = (DMABUF_t *) elx_mem_get(phba, MEM_BPL | MEM_PRI)) == 0) {
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) elsiocb);
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) pCmd);
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) pRsp);
+		return (0);
+	}
+
+	icmd->un.elsreq64.bdl.addrHigh = putPaddrHigh(pBufList->phys);
+	icmd->un.elsreq64.bdl.addrLow = putPaddrLow(pBufList->phys);
+	icmd->un.elsreq64.bdl.bdeFlags = BUFF_TYPE_BDL;
+	if (expectRsp) {
+		icmd->un.elsreq64.bdl.bdeSize = (2 * sizeof (ULP_BDE64));
+		icmd->un.elsreq64.remoteID = ndlp->nlp_DID;	/* DID */
+		icmd->ulpCommand = CMD_ELS_REQUEST64_CR;
+	} else {
+		icmd->un.elsreq64.bdl.bdeSize = sizeof (ULP_BDE64);
+		icmd->ulpCommand = CMD_XMIT_ELS_RSP64_CX;
+	}
+
+	/* NOTE: we don't use ulpIoTag0 because it is a t2 structure */
+	icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+	icmd->un.elsreq64.bdl.ulpIoTag32 = (uint32_t) icmd->ulpIoTag;
+	icmd->ulpBdeCount = 1;
+	icmd->ulpLe = 1;
+	icmd->ulpClass = CLASS3;
+	icmd->ulpOwner = OWN_CHIP;
+
+	bpl = (ULP_BDE64 *) pBufList->virt;
+	bpl->addrLow = PCIMEM_LONG(putPaddrLow(pCmd->phys));
+	bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(pCmd->phys));
+	bpl->tus.f.bdeSize = cmdSize;
+	bpl->tus.f.bdeFlags = 0;
+	bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+
+	if (expectRsp) {
+		bpl++;
+		bpl->addrLow = PCIMEM_LONG(putPaddrLow(pRsp->phys));
+		bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(pRsp->phys));
+		bpl->tus.f.bdeSize = FCELSSIZE;
+		bpl->tus.f.bdeFlags = BUFF_USE_RCV;
+		bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+	}
+
+	/* Save for completion so we can release these resources */
+	elsiocb->context1 = (uint8_t *) ndlp;
+	elsiocb->context2 = (uint8_t *) pCmd;
+	elsiocb->context3 = (uint8_t *) pBufList;
+	elsiocb->retry = retry;
+	elsiocb->drvrTimeout = (plhba->fc_ratov << 1) + ELX_DRVR_TIMEOUT;
+	pCmd->next = pRsp;
+
+	elx_pci_dma_sync((void *)phba, (void *)pBufList,
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	if (expectRsp) {
+		/* Xmit ELS command <elsCmd> to remote NPORT <did> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0116,	/* ptr to msg structure */
+			       elx_mes0116,	/* ptr to msg */
+			       elx_msgBlk0116.msgPreambleStr,	/* begin varargs */
+			       elscmd, ndlp->nlp_DID,	/* did */
+			       icmd->ulpIoTag, phba->hba_state);	/* end varargs */
+	} else {
+		/* Xmit ELS response <elsCmd> to remote NPORT <did> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0117,	/* ptr to msg structure */
+			       elx_mes0117,	/* ptr to msg */
+			       elx_msgBlk0117.msgPreambleStr,	/* begin varargs */
+			       elscmd, ndlp->nlp_DID,	/* did */
+			       icmd->ulpIoTag, cmdSize);	/* end varargs */
+	}
+
+	return (elsiocb);
+}
+
+int
+lpfc_els_free_iocb(elxHBA_t * phba, ELX_IOCBQ_t * elsiocb)
+{
+	/* context2  = cmd,  context2->next = rsp, context3 = bpl */
+	if (elsiocb->context2) {
+		/* Free the response before processing the command.  */
+		if (((DMABUF_t *) (elsiocb->context2))->next) {
+			elx_mem_put(phba, MEM_BUF,
+				    (uint8_t
+				     *) (((DMABUF_t *) (elsiocb->context2))->
+					 next));
+		}
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) (elsiocb->context2));
+	}
+
+	if (elsiocb->context3) {
+		elx_mem_put(phba, MEM_BPL, (uint8_t *) (elsiocb->context3));
+	}
+
+	elx_mem_put(phba, MEM_IOCB, (uint8_t *) elsiocb);
+	return 0;
+}
+
+void
+lpfc_cmpl_els_logo_acc(elxHBA_t * phba,
+		       ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+	elxCfgParam_t *clp;
+	int delay;
+
+	clp = &phba->config[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+
+	/* ACC to LOGO completes to NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0109,	/* ptr to msg structure */
+		       elx_mes0109,	/* ptr to msg */
+		       elx_msgBlk0109.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+	delay = 1;
+	switch (ndlp->nlp_state) {
+	case NLP_STE_UNUSED_NODE:	/* node is just allocated */
+	case NLP_STE_PLOGI_ISSUE:	/* PLOGI was sent to NL_PORT */
+	case NLP_STE_REG_LOGIN_ISSUE:	/* REG_LOGIN was issued for NL_PORT */
+		break;
+	case NLP_STE_PRLI_ISSUE:	/* PRLI was sent to NL_PORT */
+		/* dequeue, cancel timeout, unreg login */
+		lpfc_freenode(phba, ndlp);
+
+		/* put back on plogi list and send a new plogi */
+		lpfc_nlp_plogi(phba, ndlp);
+		ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+		lpfc_issue_els_plogi(phba, ndlp, 0);
+		break;
+
+	case NLP_STE_PRLI_COMPL:	/* PRLI completed from NL_PORT */
+		delay = 0;
+
+	case NLP_STE_MAPPED_NODE:	/* Identified as a FCP Target */
+
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_DISCONNECTED,
+				  ELX_SET_BITMASK);
+		if (ndlp->nlp_flag & NLP_ADISC_SND) {
+			/* dequeue, cancel timeout, unreg login */
+			lpfc_freenode(phba, ndlp);
+
+			/* put back on plogi list and send a new plogi */
+			lpfc_nlp_plogi(phba, ndlp);
+			ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+			lpfc_issue_els_plogi(phba, ndlp, 0);
+		} else {
+			targetp = ndlp->nlp_Target;
+
+			/* dequeue, cancel timeout, unreg login */
+			lpfc_freenode(phba, ndlp);
+
+			if (targetp) {
+				targetp->targetFlags |= FC_NPR_ACTIVE;
+				if (targetp->rptlunfunc) {
+					elx_clk_can(phba, targetp->rptlunfunc);
+					targetp->targetFlags &=
+					    ~FC_RETRY_RPTLUN;
+				}
+				targetp->rptlunfunc = 0;
+				if (targetp->tmofunc) {
+					elx_clk_can(phba, targetp->tmofunc);
+				}
+				targetp->tmofunc = elx_clk_set(phba,
+							       (clp
+								[ELX_CFG_NODEV_TMO].
+								a_current +
+								clp
+								[ELX_CFG_LINKDOWN_TMO].
+								a_current),
+							       lpfc_npr_timeout,
+							       (void *)targetp,
+							       (void *)0);
+			}
+
+			if (ndlp->nlp_tmofunc) {
+				ndlp->nlp_flag &=
+				    ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+				elx_clk_can(phba, ndlp->nlp_tmofunc);
+				ndlp->nlp_tmofunc = 0;
+			}
+			lpfc_nlp_plogi(phba, ndlp);
+			ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+			ndlp->nlp_flag |= NLP_DELAY_TMO;
+			ndlp->nle.nlp_rflag |= NLP_NPR_ACTIVE;
+			ndlp->nlp_retry = 0;
+			ndlp->nlp_tmofunc = elx_clk_set(phba, delay,
+							lpfc_els_retry_delay,
+							(void *)((unsigned long)
+								 ndlp->nlp_DID),
+							(void *)((unsigned long)
+								 ELS_CMD_PLOGI));
+			targetp = ndlp->nlp_Target;
+			if (targetp) {
+				targetp->targetFlags |= FC_NPR_ACTIVE;
+				if (targetp->tmofunc) {
+					elx_clk_can(phba, targetp->tmofunc);
+				}
+				targetp->tmofunc = elx_clk_set(phba,
+							       (clp
+								[ELX_CFG_NODEV_TMO].
+								a_current +
+								clp
+								[ELX_CFG_LINKDOWN_TMO].
+								a_current),
+							       lpfc_npr_timeout,
+							       (void *)targetp,
+							       (void *)0);
+			}
+		}
+		break;
+	}
+	ndlp->nlp_flag &= ~NLP_LOGO_ACC;
+	lpfc_els_free_iocb(phba, cmdiocb);
+	return;
+}
+
+void
+lpfc_cmpl_els_acc(elxHBA_t * phba, ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFC_NODELIST_t *ndlp;
+	ELX_MBOXQ_t *mbox;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+
+	/* ELS response tag <ulpIoTag> completes */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0110,	/* ptr to msg structure */
+		       elx_mes0110,	/* ptr to msg */
+		       elx_msgBlk0110.msgPreambleStr,	/* begin varargs */
+		       cmdiocb->iocb.ulpIoTag, rspiocb->iocb.ulpStatus, rspiocb->iocb.un.ulpWord[4], ndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+	mbox = (ELX_MBOXQ_t *) ((DMABUF_t *) cmdiocb->context3)->next;
+	if ((rspiocb->iocb.ulpStatus == 0)
+	    && (ndlp->nlp_flag & NLP_ACC_REGLOGIN)) {
+		/* set_slim mailbox command needs to execute first,
+		 * queue this command to be processed later.
+		 */
+		mbox->mbox_cmpl = lpfc_mbx_cmpl_reg_login;
+		mbox->context2 = (void *)ndlp;
+		ndlp->nlp_state = NLP_STE_REG_LOGIN_ISSUE;
+		if (elx_sli_issue_mbox(phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+		    != MBX_NOT_FINISHED) {
+			goto out;
+		}
+		/* NOTE: we should have messages for unsuccessful reglogin */
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+	} else {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+	}
+      out:
+	ndlp->nlp_flag &= ~NLP_ACC_REGLOGIN;
+
+	/* Check to see if link went down during discovery */
+	lpfc_els_chk_latt(phba, rspiocb);
+
+	lpfc_els_free_iocb(phba, cmdiocb);
+	return;
+}
+
+int
+lpfc_els_rsp_acc(elxHBA_t * phba,
+		 uint32_t flag,
+		 ELX_IOCBQ_t * oldiocb,
+		 LPFC_NODELIST_t * ndlp, ELX_MBOXQ_t * mbox)
+{
+	IOCB_t *icmd;
+	IOCB_t *oldcmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	oldcmd = &oldiocb->iocb;
+
+	switch (flag) {
+	case ELS_CMD_ACC:
+		cmdsize = sizeof (uint32_t);
+		if ((elsiocb =
+		     lpfc_prep_els_iocb(phba, FALSE, cmdsize, oldiocb->retry,
+					ndlp, ELS_CMD_ACC)) == 0) {
+			return (1);
+		}
+		icmd = &elsiocb->iocb;
+		icmd->ulpContext = oldcmd->ulpContext;	/* Xri */
+		pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+		*((uint32_t *) (pCmd)) = ELS_CMD_ACC;
+		pCmd += sizeof (uint32_t);
+		break;
+	case ELS_CMD_PLOGI:
+		cmdsize = (sizeof (SERV_PARM) + sizeof (uint32_t));
+		if ((elsiocb =
+		     lpfc_prep_els_iocb(phba, FALSE, cmdsize, oldiocb->retry,
+					ndlp, ELS_CMD_ACC)) == 0) {
+			return (1);
+		}
+		icmd = &elsiocb->iocb;
+		icmd->ulpContext = oldcmd->ulpContext;	/* Xri */
+		pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+		if (elsiocb->context3 && mbox) {
+			((DMABUF_t *) elsiocb->context3)->next = (void *)mbox;
+		}
+		*((uint32_t *) (pCmd)) = ELS_CMD_ACC;
+		pCmd += sizeof (uint32_t);
+		memcpy((void *)pCmd, (void *)&plhba->fc_sparam,
+		       sizeof (SERV_PARM));
+		break;
+	default:
+		return (1);
+	}
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	if (ndlp->nlp_flag & NLP_LOGO_ACC) {
+		elsiocb->iocb_cmpl = lpfc_cmpl_els_logo_acc;
+	} else {
+		elsiocb->iocb_cmpl = lpfc_cmpl_els_acc;
+	}
+
+	plhba->fc_stat.elsXmitACC++;
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+int
+lpfc_els_rsp_reject(elxHBA_t * phba, uint32_t rejectError, ELX_IOCBQ_t * oldiocb,	/* requires */
+		    LPFC_NODELIST_t * ndlp)
+{
+	IOCB_t *icmd;
+	IOCB_t *oldcmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = 2 * sizeof (uint32_t);
+	if ((elsiocb = lpfc_prep_els_iocb(phba, FALSE, cmdsize, oldiocb->retry,
+					  ndlp, ELS_CMD_LS_RJT)) == 0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	oldcmd = &oldiocb->iocb;
+	icmd->ulpContext = oldcmd->ulpContext;	/* Xri */
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	*((uint32_t *) (pCmd)) = ELS_CMD_LS_RJT;
+	pCmd += sizeof (uint32_t);
+	*((uint32_t *) (pCmd)) = rejectError;
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitLSRJT++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_acc;
+
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+int
+lpfc_els_rsp_adisc_acc(elxHBA_t * phba,
+		       ELX_IOCBQ_t * oldiocb, LPFC_NODELIST_t * ndlp)
+{
+	ADISC *ap;
+	IOCB_t *icmd;
+	IOCB_t *oldcmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = sizeof (uint32_t) + sizeof (ADISC);
+	if ((elsiocb = lpfc_prep_els_iocb(phba, FALSE, cmdsize, oldiocb->retry,
+					  ndlp, ELS_CMD_ACC)) == 0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	oldcmd = &oldiocb->iocb;
+	icmd->ulpContext = oldcmd->ulpContext;	/* Xri */
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	*((uint32_t *) (pCmd)) = ELS_CMD_ACC;
+	pCmd += sizeof (uint32_t);
+
+	ap = (ADISC *) (pCmd);
+	ap->hardAL_PA = plhba->fc_pref_ALPA;
+	memcpy((void *)&ap->portName, (void *)&plhba->fc_portname,
+	       sizeof (NAME_TYPE));
+	memcpy((void *)&ap->nodeName, (void *)&plhba->fc_nodename,
+	       sizeof (NAME_TYPE));
+	ap->DID = SWAP_DATA(plhba->fc_myDID);
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitACC++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_acc;
+
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+int
+lpfc_els_rsp_prli_acc(elxHBA_t * phba,
+		      ELX_IOCBQ_t * oldiocb, LPFC_NODELIST_t * ndlp)
+{
+	PRLI *npr;
+	elx_vpd_t *vpd;
+	IOCB_t *icmd;
+	IOCB_t *oldcmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	cmdsize = sizeof (uint32_t) + sizeof (PRLI);
+	if ((elsiocb = lpfc_prep_els_iocb(phba, FALSE, cmdsize, oldiocb->retry,
+					  ndlp,
+					  (ELS_CMD_ACC |
+					   (ELS_CMD_PRLI & ~ELS_RSP_MASK)))) ==
+	    0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	oldcmd = &oldiocb->iocb;
+	icmd->ulpContext = oldcmd->ulpContext;	/* Xri */
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	*((uint32_t *) (pCmd)) = (ELS_CMD_ACC | (ELS_CMD_PRLI & ~ELS_RSP_MASK));
+	pCmd += sizeof (uint32_t);
+
+	/* For PRLI, remainder of payload is PRLI parameter page */
+	memset((void *)pCmd, 0, sizeof (PRLI));
+
+	npr = (PRLI *) pCmd;
+	vpd = &phba->vpd;
+	/*
+	 * If our firmware version is 3.20 or later, 
+	 * set the following bits for FC-TAPE support.
+	 */
+	if (vpd->rev.feaLevelHigh >= 0x02) {
+		npr->ConfmComplAllowed = 1;
+		npr->Retry = 1;
+		npr->TaskRetryIdReq = 1;
+	}
+
+	npr->acceptRspCode = PRLI_REQ_EXECUTED;
+	npr->estabImagePair = 1;
+	npr->readXferRdyDis = 1;
+	npr->ConfmComplAllowed = 1;
+
+	npr->prliType = PRLI_FCP_TYPE;
+	npr->initiatorFunc = 1;
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitACC++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_acc;
+
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+int
+lpfc_els_rsp_rnid_acc(elxHBA_t * phba,
+		      uint8_t format,
+		      ELX_IOCBQ_t * oldiocb, LPFC_NODELIST_t * ndlp)
+{
+	RNID *rn;
+	IOCB_t *icmd;
+	IOCB_t *oldcmd;
+	ELX_IOCBQ_t *elsiocb;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	uint8_t *pCmd;
+	uint16_t cmdsize;
+	elxCfgParam_t *clp;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];	/* ELS ring */
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	cmdsize =
+	    sizeof (uint32_t) + sizeof (uint32_t) + (2 * sizeof (NAME_TYPE));
+	if (format)
+		cmdsize += sizeof (RNID_TOP_DISC);
+
+	if ((elsiocb = lpfc_prep_els_iocb(phba, FALSE, cmdsize, oldiocb->retry,
+					  ndlp, ELS_CMD_ACC)) == 0) {
+		return (1);
+	}
+
+	icmd = &elsiocb->iocb;
+	oldcmd = &oldiocb->iocb;
+	icmd->ulpContext = oldcmd->ulpContext;	/* Xri */
+	pCmd = (uint8_t *) (((DMABUF_t *) elsiocb->context2)->virt);
+
+	*((uint32_t *) (pCmd)) = ELS_CMD_ACC;
+	pCmd += sizeof (uint32_t);
+
+	memset((void *)pCmd, 0, sizeof (RNID));
+	rn = (RNID *) (pCmd);
+	rn->Format = format;
+	rn->CommonLen = (2 * sizeof (NAME_TYPE));
+	memcpy((void *)&rn->portName, (void *)&plhba->fc_portname,
+	       sizeof (NAME_TYPE));
+	memcpy((void *)&rn->nodeName, (void *)&plhba->fc_nodename,
+	       sizeof (NAME_TYPE));
+	switch (format) {
+	case 0:
+		rn->SpecificLen = 0;
+		break;
+	case RNID_TOPOLOGY_DISC:
+		rn->SpecificLen = sizeof (RNID_TOP_DISC);
+		memcpy((void *)&rn->un.topologyDisc.portName,
+		       (void *)&plhba->fc_portname, sizeof (NAME_TYPE));
+		rn->un.topologyDisc.unitType = RNID_HBA;
+		rn->un.topologyDisc.physPort = 0;
+		rn->un.topologyDisc.attachedNodes = 0;
+
+		if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+			rn->un.topologyDisc.ipVersion = plhba->ipVersion;
+			rn->un.topologyDisc.UDPport = plhba->UDPport;
+			memcpy((void *)&rn->un.topologyDisc.ipAddr[0],
+			       (void *)&plhba->ipAddr[0], 16);
+		}
+		break;
+	default:
+		rn->CommonLen = 0;
+		rn->SpecificLen = 0;
+		break;
+	}
+
+	elx_pci_dma_sync((void *)phba, (void *)(elsiocb->context2),
+			 0, ELX_DMA_SYNC_FORDEV);
+
+	plhba->fc_stat.elsXmitACC++;
+	elsiocb->iocb_cmpl = lpfc_cmpl_els_acc;
+
+	if (elx_sli_issue_iocb(phba, pring, elsiocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		lpfc_els_free_iocb(phba, elsiocb);
+		return (1);
+	}
+	return (0);
+}
+
+void
+lpfc_els_unsol_event(elxHBA_t * phba,
+		     ELX_SLI_RING_t * pring, ELX_IOCBQ_t * elsiocb)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	DMABUF_t *mp;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	LS_RJT stat;
+	uint32_t cmd;
+	uint32_t did;
+	uint32_t newnode;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	icmd = &elsiocb->iocb;
+	if (icmd->ulpStatus) {
+		goto dropit;
+	}
+	/* type of ELS cmd is first 32bit word in packet */
+	mp = elx_sli_ringpostbuf_get(phba, pring,
+				     (elx_dma_addr_t) getPaddr(icmd->un.
+							       cont64[0].
+							       addrHigh,
+							       icmd->un.
+							       cont64[0].
+							       addrLow));
+	if (mp == 0) {
+	      dropit:
+		/* Dropping received ELS cmd */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0111,	/* ptr to msg structure */
+			       elx_mes0111,	/* ptr to msg */
+			       elx_msgBlk0111.msgPreambleStr,	/* begin varargs */
+			       icmd->ulpStatus, icmd->un.ulpWord[4]);	/* end varargs */
+		plhba->fc_stat.elsRcvDrop++;
+		return;
+	}
+
+	newnode = 0;
+	lp = (uint32_t *) mp->virt;
+	cmd = *lp++;
+	lpfc_post_buffer(phba, &psli->ring[LPFC_ELS_RING], 1, 1);
+
+	/* Check to see if link went down during discovery */
+	if (lpfc_els_chk_latt(phba, elsiocb)) {
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		goto dropit;
+	}
+
+	did = icmd->un.rcvels.remoteID;
+	if ((ndlp = lpfc_findnode_did(phba, NLP_SEARCH_ALL, did)) == 0) {
+		/* Cannot find existing Fabric ndlp, so allocate a new one */
+		if ((ndlp =
+		     (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP)) == 0) {
+			elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+			goto dropit;
+		}
+		newnode = 1;
+		memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+		ndlp->nlp_DID = did;
+		if ((did & Fabric_DID_MASK) == Fabric_DID_MASK) {
+			ndlp->nle.nlp_type |= NLP_FABRIC;
+		}
+	}
+
+	plhba->fc_stat.elsRcvFrame++;
+	elsiocb->context1 = ndlp;
+	elsiocb->context2 = mp;
+
+	if ((cmd & ELS_CMD_MASK) == ELS_CMD_RSCN) {
+		cmd &= ELS_CMD_MASK;
+	}
+	/* ELS command <elsCmd> received from NPORT <did> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0112,	/* ptr to msg structure */
+		       elx_mes0112,	/* ptr to msg */
+		       elx_msgBlk0112.msgPreambleStr,	/* begin varargs */
+		       cmd, did, phba->hba_state);	/* end varargs */
+
+	switch (cmd) {
+	case ELS_CMD_PLOGI:
+		plhba->fc_stat.elsRcvPLOGI++;
+		lpfc_disc_state_machine(phba, ndlp, (void *)elsiocb,
+					NLP_EVT_RCV_PLOGI);
+		break;
+	case ELS_CMD_FLOGI:
+		plhba->fc_stat.elsRcvFLOGI++;
+		lpfc_els_rcv_flogi(phba, elsiocb, ndlp);
+		if (newnode) {
+			elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		}
+		break;
+	case ELS_CMD_LOGO:
+		plhba->fc_stat.elsRcvLOGO++;
+		lpfc_disc_state_machine(phba, ndlp, (void *)elsiocb,
+					NLP_EVT_RCV_LOGO);
+		break;
+	case ELS_CMD_PRLO:
+		plhba->fc_stat.elsRcvPRLO++;
+		lpfc_disc_state_machine(phba, ndlp, (void *)elsiocb,
+					NLP_EVT_RCV_PRLO);
+		break;
+	case ELS_CMD_RSCN:
+		plhba->fc_stat.elsRcvRSCN++;
+		lpfc_els_rcv_rscn(phba, elsiocb, ndlp);
+		if (newnode) {
+			elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		}
+		break;
+	case ELS_CMD_ADISC:
+		plhba->fc_stat.elsRcvADISC++;
+		lpfc_disc_state_machine(phba, ndlp, (void *)elsiocb,
+					NLP_EVT_RCV_ADISC);
+		break;
+	case ELS_CMD_PDISC:
+		plhba->fc_stat.elsRcvPDISC++;
+		lpfc_disc_state_machine(phba, ndlp, (void *)elsiocb,
+					NLP_EVT_RCV_PDISC);
+		break;
+	case ELS_CMD_FARPR:
+		plhba->fc_stat.elsRcvFARPR++;
+		lpfc_els_rcv_farpr(phba, elsiocb, ndlp);
+		break;
+	case ELS_CMD_FARP:
+		plhba->fc_stat.elsRcvFARP++;
+		lpfc_els_rcv_farp(phba, elsiocb, ndlp);
+		break;
+	case ELS_CMD_FAN:
+		plhba->fc_stat.elsRcvFAN++;
+		lpfc_els_rcv_fan(phba, elsiocb, ndlp);
+		break;
+	case ELS_CMD_RRQ:
+		plhba->fc_stat.elsRcvRRQ++;
+		lpfc_els_rcv_rrq(phba, elsiocb, ndlp);
+		break;
+	case ELS_CMD_PRLI:
+		plhba->fc_stat.elsRcvPRLI++;
+		lpfc_disc_state_machine(phba, ndlp, (void *)elsiocb,
+					NLP_EVT_RCV_PRLI);
+		break;
+	case ELS_CMD_RNID:
+		plhba->fc_stat.elsRcvRNID++;
+		lpfc_els_rcv_rnid(phba, elsiocb, ndlp);
+		break;
+	default:
+		/* Unsupported ELS command, reject */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_CMD_UNSUPPORTED;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_NOTHING_MORE;
+		stat.un.b.vendorUnique = 0;
+
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, elsiocb, ndlp);
+
+		/* Unknown ELS command <elsCmd> received from NPORT <did> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0115,	/* ptr to msg structure */
+			       elx_mes0115,	/* ptr to msg */
+			       elx_msgBlk0115.msgPreambleStr,	/* begin varargs */
+			       cmd, did);	/* end varargs */
+		if (newnode) {
+			elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		}
+		break;
+	}
+	if (elsiocb->context2) {
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	}
+	return;
+}
+
+void
+lpfc_more_adisc(elxHBA_t * phba)
+{
+	int sentadisc;
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if (plhba->num_disc_nodes)
+		plhba->num_disc_nodes--;
+
+	/* Continue discovery with <num_disc_nodes> ADISCs to go */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0210,	/* ptr to msg structure */
+		       elx_mes0210,	/* ptr to msg */
+		       elx_msgBlk0210.msgPreambleStr,	/* begin varargs */
+		       plhba->num_disc_nodes, plhba->fc_adisc_cnt, plhba->fc_flag, phba->hba_state);	/* end varargs */
+
+	/* Check to see if there are more ADISCs to be sent */
+	if (plhba->fc_flag & FC_NLP_MORE) {
+		sentadisc = 0;
+		lpfc_set_disctmo(phba);
+
+		/* go thru ADISC list and issue any remaining ELS ADISCs */
+		ndlp = plhba->fc_adisc_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+			if (!(ndlp->nlp_flag & NLP_ADISC_SND)) {
+				/* If we haven't already sent an ADISC for this node,
+				 * send it.
+				 */
+				lpfc_issue_els_adisc(phba, ndlp, 0);
+				plhba->num_disc_nodes++;
+				ndlp->nlp_flag |= NLP_DISC_NODE;
+				sentadisc = 1;
+				break;
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+		if (sentadisc == 0) {
+			plhba->fc_flag &= ~FC_NLP_MORE;
+		}
+	}
+	return;
+}
+
+void
+lpfc_more_plogi(elxHBA_t * phba)
+{
+	int sentplogi;
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if (plhba->num_disc_nodes)
+		plhba->num_disc_nodes--;
+
+	/* Continue discovery with <num_disc_nodes> PLOGIs to go */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0232,	/* ptr to msg structure */
+		       elx_mes0232,	/* ptr to msg */
+		       elx_msgBlk0232.msgPreambleStr,	/* begin varargs */
+		       plhba->num_disc_nodes, plhba->fc_plogi_cnt, plhba->fc_flag, phba->hba_state);	/* end varargs */
+
+	/* Check to see if there are more PLOGIs to be sent */
+	if (plhba->fc_flag & FC_NLP_MORE) {
+		sentplogi = 0;
+		/* go thru PLOGI list and issue any remaining ELS PLOGIs */
+		ndlp = plhba->fc_plogi_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+			if ((!(ndlp->nlp_flag & NLP_PLOGI_SND)) &&
+			    (ndlp->nlp_state == NLP_STE_UNUSED_NODE)) {
+				/* If we haven't already sent an PLOGI for this node,
+				 * send it.
+				 */
+				ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+				lpfc_issue_els_plogi(phba, ndlp, 0);
+				plhba->num_disc_nodes++;
+				ndlp->nlp_flag |= NLP_DISC_NODE;
+				sentplogi = 1;
+				break;
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+		if (sentplogi == 0) {
+			plhba->fc_flag &= ~FC_NLP_MORE;
+		}
+	}
+	return;
+}
+
+int
+lpfc_els_flush_rscn(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	DMABUF_t *mp;
+	int i;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	for (i = 0; i < plhba->fc_rscn_id_cnt; i++) {
+		mp = plhba->fc_rscn_id_list[i];
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		plhba->fc_rscn_id_list[i] = 0;
+	}
+	plhba->fc_rscn_id_cnt = 0;
+	plhba->fc_flag &= ~(FC_RSCN_MODE | FC_RSCN_DISCOVERY);
+	lpfc_can_disctmo(phba);
+	return (0);
+}
+
+int
+lpfc_rscn_payload_check(elxHBA_t * phba, uint32_t did)
+{
+	D_ID ns_did;
+	D_ID rscn_did;
+	LPFCHBA_t *plhba;
+	DMABUF_t *mp;
+	uint32_t *lp;
+	uint32_t payload_len, cmd, i, match;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ns_did.un.word = did;
+	match = 0;
+
+	/* If we are doing a FULL RSCN rediscovery, match everything */
+	if (plhba->fc_flag & FC_RSCN_DISCOVERY) {
+		return (did);
+	}
+
+	for (i = 0; i < plhba->fc_rscn_id_cnt; i++) {
+		mp = plhba->fc_rscn_id_list[i];
+		lp = (uint32_t *) mp->virt;
+		cmd = *lp++;
+		payload_len = SWAP_DATA(cmd) & 0xffff;	/* payload length */
+		payload_len -= sizeof (uint32_t);	/* take off word 0 */
+		while (payload_len) {
+			rscn_did.un.word = *lp++;
+			rscn_did.un.word = SWAP_DATA(rscn_did.un.word);
+			payload_len -= sizeof (uint32_t);
+			switch (rscn_did.un.b.resv) {
+			case 0:	/* Single N_Port ID effected */
+				if (ns_did.un.word == rscn_did.un.word) {
+					match = did;
+				}
+				break;
+			case 1:	/* Whole N_Port Area effected */
+				if ((ns_did.un.b.domain == rscn_did.un.b.domain)
+				    && (ns_did.un.b.area ==
+					rscn_did.un.b.area)) {
+					match = did;
+				}
+				break;
+			case 2:	/* Whole N_Port Domain effected */
+				if (ns_did.un.b.domain == rscn_did.un.b.domain) {
+					match = did;
+				}
+				break;
+			case 3:	/* Whole Fabric effected */
+				match = did;
+				break;
+			default:
+				/* Unknown Identifier in RSCN list */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0217,	/* ptr to msg structure */
+					       elx_mes0217,	/* ptr to msg */
+					       elx_msgBlk0217.msgPreambleStr,	/* begin varargs */
+					       rscn_did.un.word);	/* end varargs */
+				break;
+			}
+			if (match) {
+				break;
+			}
+		}
+	}
+	return (match);
+}
+
+int
+lpfc_els_rcv_rscn(elxHBA_t * phba,
+		  ELX_IOCBQ_t * cmdiocb, LPFC_NODELIST_t * ndlp)
+{
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	LPFCHBA_t *plhba;
+	uint32_t payload_len, cmd;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	icmd = &cmdiocb->iocb;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	cmd = *lp++;
+	payload_len = SWAP_DATA(cmd) & 0xffff;	/* payload length */
+	payload_len -= sizeof (uint32_t);	/* take off word 0 */
+	cmd &= ELS_CMD_MASK;
+
+	/* RSCN received */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0214,	/* ptr to msg structure */
+		       elx_mes0214,	/* ptr to msg */
+		       elx_msgBlk0214.msgPreambleStr,	/* begin varargs */
+		       plhba->fc_flag, payload_len, *lp, plhba->fc_rscn_id_cnt);	/* end varargs */
+
+	/* if we are already processing an RSCN, save the received
+	 * RSCN payload buffer, cmdiocb->context2 to process later.
+	 * If we zero, cmdiocb->context2, the calling routine will
+	 * not try to free it.
+	 */
+	if (plhba->fc_flag & FC_RSCN_MODE) {
+		if ((plhba->fc_rscn_id_cnt < FC_MAX_HOLD_RSCN) &&
+		    !(plhba->fc_flag & FC_RSCN_DISCOVERY)) {
+			plhba->fc_rscn_id_list[plhba->fc_rscn_id_cnt++] = pCmd;
+			cmdiocb->context2 = 0;
+			/* Deferred RSCN */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0235,	/* ptr to msg structure */
+				       elx_mes0235,	/* ptr to msg */
+				       elx_msgBlk0235.msgPreambleStr,	/* begin varargs */
+				       plhba->fc_rscn_id_cnt, plhba->fc_flag, phba->hba_state);	/* end varargs */
+		} else {
+			plhba->fc_flag |= FC_RSCN_DISCOVERY;
+			/* ReDiscovery RSCN */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0234,	/* ptr to msg structure */
+				       elx_mes0234,	/* ptr to msg */
+				       elx_msgBlk0234.msgPreambleStr,	/* begin varargs */
+				       plhba->fc_rscn_id_cnt, plhba->fc_flag, phba->hba_state);	/* end varargs */
+		}
+		/* Send back ACC */
+		lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+		return (0);
+	}
+
+	plhba->fc_flag |= FC_RSCN_MODE;
+	plhba->fc_rscn_id_list[plhba->fc_rscn_id_cnt++] = pCmd;
+	/*
+	 * If we zero, cmdiocb->context2, the calling routine will
+	 * not try to free it.
+	 */
+	cmdiocb->context2 = 0;
+
+	lpfc_set_disctmo(phba);
+
+	/* Send back ACC */
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+
+	return (lpfc_els_handle_rscn(phba));
+}
+
+int
+lpfc_els_handle_rscn(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	dfc_hba_put_event(phba, HBA_EVENT_RSCN, plhba->fc_myDID,
+			  plhba->fc_myDID, 0, 0);
+	dfc_put_event(phba, FC_REG_RSCN_EVENT, plhba->fc_myDID, 0, 0);
+
+	/* RSCN processed */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0215,	/* ptr to msg structure */
+		       elx_mes0215,	/* ptr to msg */
+		       elx_msgBlk0215.msgPreambleStr,	/* begin varargs */
+		       plhba->fc_flag, 0, plhba->fc_rscn_id_cnt, phba->hba_state);	/* end varargs */
+
+	/* To process RSCN, first compare RSCN data with NameServer */
+	plhba->fc_ns_retry = 0;
+	if ((ndlp = lpfc_findnode_did(phba, NLP_SEARCH_UNMAPPED,
+				      NameServer_DID))) {
+		/* Good ndlp, issue CT Request to NameServer */
+		if (lpfc_ns_cmd(phba, ndlp, SLI_CTNS_GID_FT) == 0) {
+			/* Wait for NameServer query cmpl before we can continue */
+			return (1);
+		}
+	} else {
+		/* If login to NameServer does not exist, issue one */
+		/* Good status, issue PLOGI to NameServer */
+		if ((ndlp =
+		     lpfc_findnode_did(phba, NLP_SEARCH_ALL, NameServer_DID))) {
+			/* Wait for NameServer login cmpl before we can continue */
+			return (1);
+		}
+		if ((ndlp =
+		     (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP)) == 0) {
+			lpfc_els_flush_rscn(phba);
+			return (0);
+		} else {
+			memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+			ndlp->nle.nlp_type |= NLP_FABRIC;
+			ndlp->nlp_DID = NameServer_DID;
+			ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+			lpfc_issue_els_plogi(phba, ndlp, 0);
+			/* Wait for NameServer login cmpl before we can continue */
+			return (1);
+		}
+	}
+
+	lpfc_els_flush_rscn(phba);
+	return (0);
+}
+
+int
+lpfc_els_rcv_flogi(elxHBA_t * phba,
+		   ELX_IOCBQ_t * cmdiocb, LPFC_NODELIST_t * ndlp)
+{
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	LPFCHBA_t *plhba;
+	SERV_PARM *sp;
+	ELX_MBOXQ_t *mbox;
+	ELX_SLI_t *psli;
+	elxCfgParam_t *clp;
+	LS_RJT stat;
+	uint32_t cmd, did;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	clp = &phba->config[0];
+	icmd = &cmdiocb->iocb;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	cmd = *lp++;
+	sp = (SERV_PARM *) lp;
+
+	/* FLOGI received */
+
+	lpfc_set_disctmo(phba);
+
+	if (plhba->fc_topology == TOPOLOGY_LOOP) {
+		/* We should never receive a FLOGI in loop mode, ignore it */
+		did = icmd->un.elsreq64.remoteID;
+
+		/* An FLOGI ELS command <elsCmd> was received from DID <did> in Loop Mode */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0113,	/* ptr to msg structure */
+			       elx_mes0113,	/* ptr to msg */
+			       elx_msgBlk0113.msgPreambleStr,	/* begin varargs */
+			       cmd, did);	/* end varargs */
+		return (1);
+	}
+
+	did = Fabric_DID;
+
+	if ((lpfc_check_sparm(phba, ndlp, sp, CLASS3))) {
+		/* For a FLOGI we accept, then if our portname is greater
+		 * then the remote portname we initiate Nport login. 
+		 */
+		int rc;
+
+		rc = lpfc_geportname((NAME_TYPE *) & plhba->fc_portname,
+				     (NAME_TYPE *) & sp->portName);
+
+		if (rc == 2) {
+			if ((mbox =
+			     (ELX_MBOXQ_t *) elx_mem_get(phba,
+							 MEM_MBOX)) == 0) {
+				return (1);
+			}
+			lpfc_linkdown(phba);
+			lpfc_init_link(phba, mbox,
+				       clp[LPFC_CFG_TOPOLOGY].a_current,
+				       clp[LPFC_CFG_LINK_SPEED].a_current);
+			mbox->mb.un.varInitLnk.lipsr_AL_PA = 0;
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+			}
+			return (1);
+		}
+
+		if (rc == 1) {	/* greater than */
+			plhba->fc_flag |= FC_PT2PT_PLOGI;
+		}
+		plhba->fc_flag |= FC_PT2PT;
+		plhba->fc_flag &= ~(FC_FABRIC | FC_PUBLIC_LOOP);
+	} else {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+		return (1);
+	}
+
+	/* Send back ACC */
+	lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+
+	return (0);
+}
+
+int
+lpfc_els_rcv_rnid(elxHBA_t * phba,
+		  ELX_IOCBQ_t * cmdiocb, LPFC_NODELIST_t * ndlp)
+{
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	LPFCHBA_t *plhba;
+	RNID *rn;
+	LS_RJT stat;
+	uint32_t cmd, did;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	icmd = &cmdiocb->iocb;
+	did = icmd->un.elsreq64.remoteID;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	cmd = *lp++;
+	rn = (RNID *) lp;
+
+	/* RNID received */
+
+	switch (rn->Format) {
+	case 0:
+	case RNID_TOPOLOGY_DISC:
+		/* Send back ACC */
+		lpfc_els_rsp_rnid_acc(phba, rn->Format, cmdiocb, ndlp);
+		break;
+	default:
+		/* Reject this request because format not supported */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_CANT_GIVE_DATA;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	}
+	return (0);
+}
+
+int
+lpfc_els_rcv_rrq(elxHBA_t * phba, ELX_IOCBQ_t * cmdiocb, LPFC_NODELIST_t * ndlp)
+{
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	LPFCHBA_t *plhba;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	RRQ *rrq;
+	uint32_t cmd, did;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_FCP_RING];	/* FCP ring */
+	icmd = &cmdiocb->iocb;
+	did = icmd->un.elsreq64.remoteID;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	cmd = *lp++;
+	rrq = (RRQ *) lp;
+
+	/* RRQ received */
+	/* Get oxid / rxid from payload and abort it */
+	if ((rrq->SID == SWAP_DATA(plhba->fc_myDID))) {
+		elx_sli_abort_iocb_ctx(phba, pring, rrq->Oxid);
+	} else {
+		elx_sli_abort_iocb_ctx(phba, pring, rrq->Rxid);
+	}
+	/* ACCEPT the rrq request */
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+
+	return (0);
+}
+
+int
+lpfc_els_rcv_farp(elxHBA_t * phba,
+		  ELX_IOCBQ_t * cmdiocb, LPFC_NODELIST_t * ndlp)
+{
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	LPFCHBA_t *plhba;
+	FARP *fp;
+	uint32_t cmd, cnt, did;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	icmd = &cmdiocb->iocb;
+	did = icmd->un.elsreq64.remoteID;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+	cmd = *lp++;
+	fp = (FARP *) lp;
+
+	/* FARP-REQ received from DID <did> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0601,	/* ptr to msg structure */
+		       elx_mes0601,	/* ptr to msg */
+		       elx_msgBlk0601.msgPreambleStr,	/* begin varargs */
+		       did);	/* end varargs */
+
+	/* We will only support match on WWPN or WWNN */
+	if (fp->Mflags & ~(FARP_MATCH_NODE | FARP_MATCH_PORT)) {
+		return (0);
+	}
+
+	cnt = 0;
+	/* If this FARP command is searching for my portname */
+	if (fp->Mflags & FARP_MATCH_PORT) {
+		if (lpfc_geportname(&fp->RportName, &plhba->fc_portname) == 2)
+			cnt = 1;
+	}
+
+	/* If this FARP command is searching for my nodename */
+	if (fp->Mflags & FARP_MATCH_NODE) {
+		if (lpfc_geportname(&fp->RnodeName, &plhba->fc_nodename) == 2)
+			cnt = 1;
+	}
+
+	if (cnt) {
+		if ((ndlp->nle.nlp_failMask == 0) &&
+		    (!(ndlp->nlp_flag & NLP_ELS_SND_MASK))) {
+			/* Log back into the node before sending the FARP. */
+			if (fp->Rflags & FARP_REQUEST_PLOGI) {
+				lpfc_nlp_plogi(phba, ndlp);
+				ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+				lpfc_issue_els_plogi(phba, ndlp, 0);
+			}
+
+			/* Send a FARP response to that node */
+			if (fp->Rflags & FARP_REQUEST_FARPR) {
+				lpfc_issue_els_farpr(phba, did, 0);
+			}
+		}
+	}
+	return (0);
+}
+
+int
+lpfc_els_rcv_farpr(elxHBA_t * phba,
+		   ELX_IOCBQ_t * cmdiocb, LPFC_NODELIST_t * ndlp)
+{
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	LPFCHBA_t *plhba;
+	uint32_t cmd, did;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	icmd = &cmdiocb->iocb;
+	did = icmd->un.elsreq64.remoteID;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	cmd = *lp++;
+	/* FARP-RSP received from DID <did> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0600,	/* ptr to msg structure */
+		       elx_mes0600,	/* ptr to msg */
+		       elx_msgBlk0600.msgPreambleStr,	/* begin varargs */
+		       did);	/* end varargs */
+
+	/* ACCEPT the Farp resp request */
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+
+	return (0);
+}
+
+int
+lpfc_els_rcv_fan(elxHBA_t * phba, ELX_IOCBQ_t * cmdiocb, LPFC_NODELIST_t * ndlp)
+{
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	LPFCHBA_t *plhba;
+	FAN *fp;
+	uint32_t cmd, did;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	icmd = &cmdiocb->iocb;
+	did = icmd->un.elsreq64.remoteID;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	cmd = *lp++;
+	fp = (FAN *) lp;
+
+	/* FAN received */
+
+	/* ACCEPT the FAN request */
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+
+	if (phba->hba_state == ELX_LOCAL_CFG_LINK) {
+		/* The discovery state machine needs to take a different
+		 * action if this node has switched fabrics 
+		 */
+		if ((lpfc_geportname((NAME_TYPE *) & fp->FportName,
+				     (NAME_TYPE *) & plhba->fc_fabparam.
+				     portName) != 2)
+		    ||
+		    (lpfc_geportname
+		     ((NAME_TYPE *) & fp->FnodeName,
+		      (NAME_TYPE *) & plhba->fc_fabparam.nodeName) != 2)) {
+			/* This node has switched fabrics.  An FLOGI is required
+			 * after the timeout 
+			 */
+			return (0);
+		}
+
+		/* Start discovery */
+		lpfc_disc_start(phba);
+	}
+
+	return (0);
+}
+
+int
+lpfc_els_chk_latt(elxHBA_t * phba, ELX_IOCBQ_t * rspiocb)
+{
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	IOCB_t *irsp;
+	ELX_MBOXQ_t *mbox;
+	uint32_t ha_copy;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if (phba->hba_state < ELX_HBA_READY) {
+		uint32_t tag, stat, wd4;
+
+		/* Read the HBA Host Attention Register */
+		ha_copy = (psli->sliinit.elx_sli_read_HA) (phba);
+
+		if (ha_copy & HA_LATT) {	/* Link Attention interrupt */
+			if (rspiocb) {
+				irsp = &(rspiocb->iocb);
+				tag = irsp->ulpIoTag;
+				stat = irsp->ulpStatus;
+				wd4 = irsp->un.ulpWord[4];
+				irsp->ulpStatus = IOSTAT_DRIVER_REJECT;
+				irsp->un.ulpWord[4] = IOERR_SLI_ABORTED;
+			} else {
+				tag = 0;
+				stat = 0;
+				wd4 = 0;
+			}
+			/* Pending Link Event during Discovery */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0237,	/* ptr to msg structure */
+				       elx_mes0237,	/* ptr to msg */
+				       elx_msgBlk0237.msgPreambleStr,	/* begin varargs */
+				       phba->hba_state, tag, stat, wd4);	/* end varargs */
+
+			if (phba->hba_state != ELX_CLEAR_LA) {
+				if ((mbox =
+				     (ELX_MBOXQ_t *) elx_mem_get(phba,
+								 MEM_MBOX |
+								 MEM_PRI))) {
+					phba->hba_state = ELX_CLEAR_LA;
+					lpfc_clear_la(phba, mbox);
+					mbox->mbox_cmpl =
+					    lpfc_mbx_cmpl_clear_la;
+					if (elx_sli_issue_mbox
+					    (phba, mbox,
+					     (MBX_NOWAIT | MBX_STOP_IOCB))
+					    == MBX_NOT_FINISHED) {
+						elx_mem_put(phba, MEM_MBOX,
+							    (uint8_t *) mbox);
+						phba->hba_state = ELX_HBA_ERROR;
+					}
+				}
+			}
+			return (1);
+		}
+	}
+
+	return (0);
+}
+
+void
+lpfc_els_timeout_handler(elxHBA_t * phba, void *arg1, void *arg2)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_IOCBQ_t *next_iocb;
+	ELX_IOCBQ_t *piocb;
+	IOCB_t *cmd = NULL;
+	LPFCHBA_t *plhba;
+	DMABUF_t *pCmd;
+	ELX_DLINK_t *dlp;
+	uint32_t *elscmd;
+	uint32_t els_command;
+	uint32_t timeout;
+	uint32_t next_timeout;
+	uint32_t remote_ID;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];
+	dlp = &pring->txcmplq;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	timeout = (uint32_t) (unsigned long)arg1;
+	next_timeout = plhba->fc_ratov << 1;
+
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		piocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &piocb->iocb;
+
+		if (piocb->iocb_flag & ELX_IO_IOCTL) {
+			continue;
+		}
+		pCmd = (DMABUF_t *) piocb->context2;
+		elscmd = (uint32_t *) (pCmd->virt);
+		els_command = *elscmd;
+
+		if ((els_command == ELS_CMD_FARP)
+		    || (els_command == ELS_CMD_FARPR)) {
+			continue;
+		}
+
+		if (piocb->drvrTimeout > 0) {
+			if (piocb->drvrTimeout >= timeout) {
+				piocb->drvrTimeout -= timeout;
+			} else {
+				piocb->drvrTimeout = 0;
+			}
+			continue;
+		}
+
+		elx_deque(piocb);
+		dlp->q_cnt--;
+
+		if (cmd->ulpCommand == CMD_GEN_REQUEST64_CR) {
+			LPFC_NODELIST_t *ndlp;
+
+			ndlp = lpfc_findnode_rpi(phba, cmd->ulpContext);
+			remote_ID = ndlp->nlp_DID;
+		} else {
+			remote_ID = cmd->un.elsreq64.remoteID;
+		}
+
+		elx_printf_log(phba->brd_no, &elx_msgBlk0127,	/* ptr to msg structure */
+			       elx_mes0127,	/* ptr to msg */
+			       elx_msgBlk0127.msgPreambleStr,	/* begin varargs */
+			       els_command, remote_ID,	/* DID */
+			       cmd->ulpCommand, cmd->ulpIoTag);	/* end varargs */
+
+		/*
+		 * The iocb has timed out; driver abort it.
+		 */
+		cmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+		cmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+
+		if (piocb->iocb_cmpl) {
+			(piocb->iocb_cmpl) ((void *)phba, piocb, piocb);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) piocb);
+		}
+	}
+
+	phba->els_tmofunc =
+	    elx_clk_set(phba, next_timeout, lpfc_els_timeout_handler,
+			(void *)(unsigned long)next_timeout, 0);
+}
+
+void
+lpfc_els_flush_cmd(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_IOCBQ_t *next_iocb;
+	ELX_IOCBQ_t *piocb;
+	IOCB_t *cmd = NULL;
+	LPFCHBA_t *plhba;
+	DMABUF_t *pCmd;
+	ELX_DLINK_t *dlp;
+	uint32_t *elscmd;
+	uint32_t els_command;
+	uint32_t remote_ID;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];
+	dlp = &pring->txcmplq;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		piocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &piocb->iocb;
+
+		if (piocb->iocb_flag & ELX_IO_IOCTL) {
+			continue;
+		}
+		pCmd = (DMABUF_t *) piocb->context2;
+		elscmd = (uint32_t *) (pCmd->virt);
+		els_command = *elscmd;
+
+		if (cmd->ulpCommand == CMD_GEN_REQUEST64_CR) {
+			LPFC_NODELIST_t *ndlp;
+
+			ndlp = lpfc_findnode_rpi(phba, cmd->ulpContext);
+			remote_ID = ndlp->nlp_DID;
+			if (phba->hba_state == ELX_HBA_READY) {
+				continue;
+			}
+		} else {
+			remote_ID = cmd->un.elsreq64.remoteID;
+		}
+
+		elx_deque(piocb);
+		dlp->q_cnt--;
+
+		cmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+		cmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+
+		if (piocb->iocb_cmpl) {
+			(piocb->iocb_cmpl) ((void *)phba, piocb, piocb);
+		} else {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) piocb);
+		}
+	}
+	return;
+}
+
+int lpfc_matchdid(elxHBA_t *, LPFC_NODELIST_t *, uint32_t);
+void lpfc_free_tx(elxHBA_t *, LPFC_NODELIST_t *);
+void lpfc_put_buf(elxHBA_t *, void *, void *);
+void lpfc_disc_retry_rptlun(elxHBA_t *, void *, void *);
+
+/* Could be put in lpfc.conf; For now defined here */
+int lpfc_qfull_retry_count = 5;
+
+/* AlpaArray for assignment of scsid for scan-down and bind_method */
+uint8_t lpfcAlpaArray[] = {
+	0xEF, 0xE8, 0xE4, 0xE2, 0xE1, 0xE0, 0xDC, 0xDA, 0xD9, 0xD6,
+	0xD5, 0xD4, 0xD3, 0xD2, 0xD1, 0xCE, 0xCD, 0xCC, 0xCB, 0xCA,
+	0xC9, 0xC7, 0xC6, 0xC5, 0xC3, 0xBC, 0xBA, 0xB9, 0xB6, 0xB5,
+	0xB4, 0xB3, 0xB2, 0xB1, 0xAE, 0xAD, 0xAC, 0xAB, 0xAA, 0xA9,
+	0xA7, 0xA6, 0xA5, 0xA3, 0x9F, 0x9E, 0x9D, 0x9B, 0x98, 0x97,
+	0x90, 0x8F, 0x88, 0x84, 0x82, 0x81, 0x80, 0x7C, 0x7A, 0x79,
+	0x76, 0x75, 0x74, 0x73, 0x72, 0x71, 0x6E, 0x6D, 0x6C, 0x6B,
+	0x6A, 0x69, 0x67, 0x66, 0x65, 0x63, 0x5C, 0x5A, 0x59, 0x56,
+	0x55, 0x54, 0x53, 0x52, 0x51, 0x4E, 0x4D, 0x4C, 0x4B, 0x4A,
+	0x49, 0x47, 0x46, 0x45, 0x43, 0x3C, 0x3A, 0x39, 0x36, 0x35,
+	0x34, 0x33, 0x32, 0x31, 0x2E, 0x2D, 0x2C, 0x2B, 0x2A, 0x29,
+	0x27, 0x26, 0x25, 0x23, 0x1F, 0x1E, 0x1D, 0x1B, 0x18, 0x17,
+	0x10, 0x0F, 0x08, 0x04, 0x02, 0x01
+};
+
+int
+lpfc_linkdown(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_NODELIST_t *new_ndlp;
+	ELX_MBOXQ_t *mb;
+	ELXSCSITARGET_t *targetp;
+	elxCfgParam_t *clp;
+	int rc;
+
+	clp = &phba->config[0];
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	phba->hba_state = ELX_LINK_DOWN;
+	plhba->fc_flag |= FC_LNK_DOWN;
+
+	dfc_put_event(phba, FC_REG_LINK_EVENT, 0, 0, 0);
+
+	dfc_hba_put_event(phba, HBA_EVENT_LINK_DOWN, plhba->fc_myDID, 0, 0, 0);
+
+	/* Clean up any firmware default rpi's */
+	if ((mb = (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX))) {
+		lpfc_unreg_did(phba, 0xffffffff, mb);
+		if (elx_sli_issue_mbox(phba, mb, (MBX_NOWAIT | MBX_STOP_IOCB))
+		    == MBX_NOT_FINISHED) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) mb);
+		}
+	}
+
+	/* Cleanup any outstanding RSCN activity */
+	lpfc_els_flush_rscn(phba);
+
+	/* Cleanup any outstanding ELS commands */
+	lpfc_els_flush_cmd(phba);
+
+	/* Handle linkdown timer logic.   */
+
+	if (!(plhba->fc_flag & FC_LD_TIMER)) {
+		/* Should we start the link down watchdog timer */
+		if ((clp[ELX_CFG_LINKDOWN_TMO].a_current == 0) ||
+		    clp[ELX_CFG_HOLDIO].a_current) {
+			plhba->fc_flag |= (FC_LD_TIMER | FC_LD_TIMEOUT);
+			phba->hba_flag |= FC_LFR_ACTIVE;
+		} else {
+			plhba->fc_flag |= FC_LD_TIMER;
+			phba->hba_flag |= FC_LFR_ACTIVE;
+			if (plhba->fc_linkdown) {
+				elx_clk_res(phba,
+					    clp[ELX_CFG_LINKDOWN_TMO].a_current,
+					    plhba->fc_linkdown);
+			} else {
+				if (clp[ELX_CFG_HOLDIO].a_current == 0) {
+					plhba->fc_linkdown = elx_clk_set(phba,
+									 clp
+									 [ELX_CFG_LINKDOWN_TMO].
+									 a_current,
+									 lpfc_linkdown_timeout,
+									 0, 0);
+				}
+			}
+		}
+	}
+
+	/* Issue a LINK DOWN event to all nodes */
+	ndlp = plhba->fc_plogi_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+		ndlp = plhba->fc_adisc_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+			ndlp = plhba->fc_nlpunmap_start;
+			if (ndlp ==
+			    (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+				ndlp = plhba->fc_nlpmap_start;
+			}
+		}
+	}
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		new_ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+
+		/* Fabric nodes are not handled thru state machine for link down */
+		if (!(ndlp->nle.nlp_type & NLP_FABRIC)) {
+			lpfc_set_failmask(phba, ndlp, ELX_DEV_LINK_DOWN,
+					  ELX_SET_BITMASK);
+
+			rc = lpfc_disc_state_machine(phba, ndlp, (void *)0,
+						     NLP_EVT_DEVICE_UNK);
+			if ((rc != NLP_STE_FREED_NODE)
+			    && (clp[LPFC_CFG_USE_ADISC].a_current == 0)) {
+				/* If we are not using ADISC when the link comes back up, we might
+				 * as well free all the nodes right now.
+				 */
+				targetp = ndlp->nlp_Target;
+				/* If we were a FCP target, go into NPort Recovery mode to give
+				 * it a chance to come back.
+				 */
+				if (targetp) {
+					if ((clp[ELX_CFG_NODEV_TMO].a_current)
+					    && (clp[ELX_CFG_HOLDIO].a_current ==
+						0)) {
+						targetp->targetFlags |=
+						    FC_NPR_ACTIVE;
+						if (targetp->tmofunc) {
+							elx_clk_can(phba,
+								    targetp->
+								    tmofunc);
+						}
+						targetp->tmofunc =
+						    elx_clk_set(phba,
+								(clp
+								 [ELX_CFG_NODEV_TMO].
+								 a_current +
+								 clp
+								 [ELX_CFG_LINKDOWN_TMO].
+								 a_current),
+								lpfc_npr_timeout,
+								(void *)targetp,
+								(void *)0);
+					} else {
+						elx_sched_flush_target(phba,
+								       targetp,
+								       IOSTAT_DRIVER_REJECT,
+								       IOERR_SLI_ABORTED);
+					}
+				}
+
+				lpfc_findnode_did(phba,
+						  (NLP_SEARCH_ALL |
+						   NLP_SEARCH_DEQUE),
+						  ndlp->nlp_DID);
+				lpfc_freenode(phba, ndlp);
+				elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+			}
+		}
+		ndlp = new_ndlp;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+			ndlp = plhba->fc_adisc_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+			ndlp = plhba->fc_nlpunmap_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+			ndlp = plhba->fc_nlpmap_start;
+	}
+
+	/* Setup myDID for link up if we are in pt2pt mode */
+	if (plhba->fc_flag & FC_PT2PT) {
+		plhba->fc_myDID = 0;
+		if ((mb = (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX))) {
+			lpfc_config_link(phba, mb);
+			if (elx_sli_issue_mbox
+			    (phba, mb, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mb);
+			}
+		}
+		plhba->fc_flag &= ~(FC_PT2PT | FC_PT2PT_PLOGI);
+	}
+	plhba->fc_flag &= ~FC_LBIT;
+
+	/* Turn off discovery timer if its running */
+	lpfc_can_disctmo(phba);
+
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		plhba->fc_nlp_bcast.nle.nlp_failMask = ELX_DEV_LINK_DOWN;
+	}
+
+	/* Must process IOCBs on all rings to handle ABORTed I/Os */
+	return (0);
+}
+
+int
+lpfc_linkup(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_NODELIST_t *new_ndlp;
+	elxCfgParam_t *clp;
+	unsigned long iflag;
+
+	clp = &phba->config[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	phba->hba_state = ELX_LINK_UP;
+	phba->hba_flag |= FC_NDISC_ACTIVE;
+	plhba->fc_flag &= ~(FC_LNK_DOWN | FC_PT2PT | FC_PT2PT_PLOGI |
+			    FC_RSCN_MODE | FC_NLP_MORE | FC_DELAY_DISC |
+			    FC_RSCN_DISC_TMR | FC_RSCN_DISCOVERY | FC_LD_TIMER |
+			    FC_LD_TIMEOUT);
+	plhba->fc_ns_retry = 0;
+
+	dfc_put_event(phba, FC_REG_LINK_EVENT, 0, 0, 0);
+
+	dfc_hba_put_event(phba, HBA_EVENT_LINK_UP, plhba->fc_myDID,
+			  plhba->fc_topology, 0, plhba->fc_linkspeed);
+
+	if (plhba->fc_linkdown) {
+		elx_clk_can(phba, plhba->fc_linkdown);
+		plhba->fc_linkdown = 0;
+	}
+
+	/*
+	 * Clean up old Fabric, NameServer and other NLP_FABRIC logins.
+	 */
+	ELX_DISC_LOCK(phba, iflag);
+	ndlp = plhba->fc_nlpunmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+		new_ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		if (ndlp->nle.nlp_type & NLP_FABRIC) {
+			ndlp->nlp_flag &=
+			    ~(NLP_UNMAPPED_LIST | NLP_TGT_NO_SCSIID);
+			plhba->fc_unmap_cnt--;
+			elx_deque(ndlp);
+			ELX_DISC_UNLOCK(phba, iflag);
+			lpfc_freenode(phba, ndlp);
+			elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+			ELX_DISC_LOCK(phba, iflag);
+		}
+		ndlp = new_ndlp;
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* Mark all nodes for LINK UP */
+	ELX_DISC_LOCK(phba, iflag);
+	ndlp = plhba->fc_plogi_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+		ndlp = plhba->fc_adisc_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+		ndlp = plhba->fc_nlpunmap_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+		ndlp = plhba->fc_nlpmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		new_ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN, ELX_SET_BITMASK);
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_LINK_DOWN,
+				  ELX_CLR_BITMASK);
+
+		if (ndlp->nlp_flag & NLP_NODEV_TMO) {
+			if (elx_clk_rem(phba, ndlp->nlp_tmofunc) >
+			    clp[ELX_CFG_NODEV_TMO].a_current) {
+				elx_clk_res(phba,
+					    clp[ELX_CFG_NODEV_TMO].a_current,
+					    ndlp->nlp_tmofunc);
+			}
+		}
+
+		ndlp = new_ndlp;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+			ndlp = plhba->fc_adisc_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+			ndlp = plhba->fc_nlpunmap_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+			ndlp = plhba->fc_nlpmap_start;
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	return (0);
+}
+
+/*
+ * This routine handles processing a READ_LA mailbox
+ * command upon completion. It is setup in the ELX_MBOXQ
+ * as the completion routine when the command is
+ * handed off to the SLI layer.
+ */
+void
+lpfc_mbx_cmpl_read_la(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	DMABUF_t *mp;
+	ELX_SLI_t *psli;
+	READ_LA_VAR *la;
+	LPFCHBA_t *plhba;
+	ELX_MBOXQ_t *mbox;
+	MAILBOX_t *mb;
+	elxCfgParam_t *clp;
+	uint32_t control;
+	int i;
+
+	clp = &phba->config[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	mb = &pmb->mb;
+	/* Check for error */
+	if (mb->mbxStatus) {
+		/* READ_LA mbox error <mbxStatus> state <hba_state> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1307,	/* ptr to msg structure */
+			       elx_mes1307,	/* ptr to msg */
+			       elx_msgBlk1307.msgPreambleStr,	/* begin varargs */
+			       mb->mbxStatus, phba->hba_state);	/* end varargs */
+
+		lpfc_linkdown(phba);
+		phba->hba_state = ELX_HBA_ERROR;
+
+		/* turn on Link Attention interrupts */
+		psli->sliinit.sli_flag |= ELX_PROCESS_LA;
+		control = (psli->sliinit.elx_sli_read_HC) (phba);
+		control |= HC_LAINT_ENA;
+		(psli->sliinit.elx_sli_write_HC) (phba, control);
+		return;
+	}
+	la = (READ_LA_VAR *) & pmb->mb.un.varReadLA;
+
+	mp = (DMABUF_t *) (pmb->context1);
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORCPU);
+
+	/* Get Loop Map information */
+	if (mp) {
+		memcpy((void *)&plhba->alpa_map[0], (void *)mp->virt, 128);
+	} else {
+		memset((void *)&plhba->alpa_map[0], 0, 128);
+	}
+
+	if (la->pb)
+		plhba->fc_flag |= FC_BYPASSED_MODE;
+	else
+		plhba->fc_flag &= ~FC_BYPASSED_MODE;
+
+	if (((plhba->fc_eventTag + 1) < la->eventTag) ||
+	    (plhba->fc_eventTag == la->eventTag)) {
+		plhba->fc_stat.LinkMultiEvent++;
+		if (la->attType == AT_LINK_UP) {
+			if (plhba->fc_eventTag != 0) {
+
+				lpfc_linkdown(phba);
+			}
+		}
+	}
+
+	plhba->fc_eventTag = la->eventTag;
+
+	if (la->attType == AT_LINK_UP) {
+		plhba->fc_stat.LinkUp++;
+		/* Link Up Event <eventTag> received */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1303,	/* ptr to msg structure */
+			       elx_mes1303,	/* ptr to msg */
+			       elx_msgBlk1303.msgPreambleStr,	/* begin varargs */
+			       la->eventTag, plhba->fc_eventTag, la->granted_AL_PA, la->UlnkSpeed, plhba->alpa_map[0]);	/* end varargs */
+
+		if (la->UlnkSpeed == LA_2GHZ_LINK)
+			plhba->fc_linkspeed = LA_2GHZ_LINK;
+		else
+			plhba->fc_linkspeed = 0;
+
+		if ((plhba->fc_topology = la->topology) == TOPOLOGY_LOOP) {
+
+			if (la->il) {
+				plhba->fc_flag |= FC_LBIT;
+			}
+
+			plhba->fc_myDID = la->granted_AL_PA;
+
+			i = la->un.lilpBde64.tus.f.bdeSize;
+			if (i == 0) {
+				plhba->alpa_map[0] = 0;
+			} else {
+				if (clp[ELX_CFG_LOG_VERBOSE].
+				    a_current & LOG_LINK_EVENT) {
+					int numalpa, j, k;
+					union {
+						uint8_t pamap[16];
+						struct {
+							uint32_t wd1;
+							uint32_t wd2;
+							uint32_t wd3;
+							uint32_t wd4;
+						} pa;
+					} un;
+
+					numalpa = plhba->alpa_map[0];
+					j = 0;
+					while (j < numalpa) {
+						memset(un.pamap, 0, 16);
+						for (k = 1; j < numalpa; k++) {
+							un.pamap[k - 1] =
+							    plhba->alpa_map[j +
+									    1];
+							j++;
+							if (k == 16)
+								break;
+						}
+						/* Link Up Event ALPA map */
+						elx_printf_log(phba->brd_no, &elx_msgBlk1304,	/* ptr to msg struct */
+							       elx_mes1304,	/* ptr to msg */
+							       elx_msgBlk1304.msgPreambleStr,	/* begin varargs */
+							       un.pa.wd1, un.pa.wd2, un.pa.wd3, un.pa.wd4);	/* end varargs */
+					}
+				}
+			}
+		} else {
+			plhba->fc_myDID = plhba->fc_pref_DID;
+			plhba->fc_flag |= FC_LBIT;
+		}
+
+		lpfc_linkup(phba);
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			lpfc_read_sparam(phba, mbox);
+			mbox->mbox_cmpl = lpfc_mbx_cmpl_read_sparam;
+			elx_mbox_put(phba, mbox);
+		}
+
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			phba->hba_state = ELX_LOCAL_CFG_LINK;
+			lpfc_config_link(phba, mbox);
+			mbox->mbox_cmpl = lpfc_mbx_cmpl_config_link;
+			elx_mbox_put(phba, mbox);
+		}
+	} else {
+		plhba->fc_stat.LinkDown++;
+		/* Link Down Event <eventTag> received */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1305,	/* ptr to msg structure */
+			       elx_mes1305,	/* ptr to msg */
+			       elx_msgBlk1305.msgPreambleStr,	/* begin varargs */
+			       la->eventTag, plhba->fc_eventTag, phba->hba_state, plhba->fc_flag);	/* end varargs */
+
+		lpfc_linkdown(phba);
+
+		/* turn on Link Attention interrupts - no CLEAR_LA needed */
+		psli->sliinit.sli_flag |= ELX_PROCESS_LA;
+		control = (psli->sliinit.elx_sli_read_HC) (phba);
+		control |= HC_LAINT_ENA;
+		(psli->sliinit.elx_sli_write_HC) (phba, control);
+	}
+
+	pmb->context1 = 0;
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	return;
+}
+
+void
+lpfc_mbx_cmpl_config_link(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	mb = &pmb->mb;
+	/* Check for error */
+	if (mb->mbxStatus) {
+		/* CONFIG_LINK mbox error <mbxStatus> state <hba_state> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0306,	/* ptr to msg structure */
+			       elx_mes0306,	/* ptr to msg */
+			       elx_msgBlk0306.msgPreambleStr,	/* begin varargs */
+			       mb->mbxStatus, phba->hba_state);	/* end varargs */
+
+		lpfc_linkdown(phba);
+		phba->hba_state = ELX_HBA_ERROR;
+		goto out;
+	}
+
+	if (phba->hba_state == ELX_LOCAL_CFG_LINK) {
+		if (plhba->fc_topology == TOPOLOGY_LOOP) {
+			/* If we are public loop and L bit was set */
+			if ((plhba->fc_flag & FC_PUBLIC_LOOP) &&
+			    !(plhba->fc_flag & FC_LBIT)) {
+				/* Need to wait for FAN - use discovery timer for timeout.
+				 * hba_state is identically  ELX_LOCAL_CFG_LINK while waiting for FAN
+				 */
+				lpfc_set_disctmo(phba);
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+				return;
+			}
+		}
+
+		/* Start discovery by sending a FLOGI
+		 * hba_state is identically ELX_FLOGI while waiting for FLOGI cmpl
+		 */
+		phba->hba_state = ELX_FLOGI;
+		lpfc_set_disctmo(phba);
+		lpfc_initial_flogi(phba);
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		return;
+	}
+
+      out:
+	/* CONFIG_LINK bad hba state <hba_state> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0200,	/* ptr to msg structure */
+		       elx_mes0200,	/* ptr to msg */
+		       elx_msgBlk0200.msgPreambleStr,	/* begin varargs */
+		       phba->hba_state);	/* end varargs */
+
+	if (phba->hba_state != ELX_CLEAR_LA) {
+		lpfc_clear_la(phba, pmb);
+		pmb->mbox_cmpl = lpfc_mbx_cmpl_clear_la;
+		if (elx_sli_issue_mbox(phba, pmb, (MBX_NOWAIT | MBX_STOP_IOCB))
+		    == MBX_NOT_FINISHED) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			lpfc_disc_flush_list(phba);
+			psli->ring[(psli->ip_ring)].flag &=
+			    ~ELX_STOP_IOCB_EVENT;
+			psli->ring[(psli->fcp_ring)].flag &=
+			    ~ELX_STOP_IOCB_EVENT;
+			psli->ring[(psli->next_ring)].flag &=
+			    ~ELX_STOP_IOCB_EVENT;
+			phba->hba_state = ELX_HBA_READY;
+		}
+	} else {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	}
+	return;
+}
+
+void
+lpfc_mbx_cmpl_read_sparam(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+	DMABUF_t *mp;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	mb = &pmb->mb;
+	/* Check for error */
+	if (mb->mbxStatus) {
+		/* READ_SPARAM mbox error <mbxStatus> state <hba_state> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0319,	/* ptr to msg structure */
+			       elx_mes0319,	/* ptr to msg */
+			       elx_msgBlk0319.msgPreambleStr,	/* begin varargs */
+			       mb->mbxStatus, phba->hba_state);	/* end varargs */
+
+		lpfc_linkdown(phba);
+		phba->hba_state = ELX_HBA_ERROR;
+		goto out;
+	}
+
+	mp = (DMABUF_t *) pmb->context1;
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORCPU);
+
+	memcpy((uint8_t *) & plhba->fc_sparam, (uint8_t *) mp->virt,
+	       sizeof (SERV_PARM));
+	memcpy((uint8_t *) & plhba->fc_nodename,
+	       (uint8_t *) & plhba->fc_sparam.nodeName, sizeof (NAME_TYPE));
+	memcpy((uint8_t *) & plhba->fc_portname,
+	       (uint8_t *) & plhba->fc_sparam.portName, sizeof (NAME_TYPE));
+	memcpy(plhba->phys_addr, plhba->fc_portname.IEEE, 6);
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	return;
+
+      out:
+	if (phba->hba_state != ELX_CLEAR_LA) {
+		lpfc_clear_la(phba, pmb);
+		pmb->mbox_cmpl = lpfc_mbx_cmpl_clear_la;
+		if (elx_sli_issue_mbox(phba, pmb, (MBX_NOWAIT | MBX_STOP_IOCB))
+		    == MBX_NOT_FINISHED) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			lpfc_disc_flush_list(phba);
+			psli->ring[(psli->ip_ring)].flag &=
+			    ~ELX_STOP_IOCB_EVENT;
+			psli->ring[(psli->fcp_ring)].flag &=
+			    ~ELX_STOP_IOCB_EVENT;
+			psli->ring[(psli->next_ring)].flag &=
+			    ~ELX_STOP_IOCB_EVENT;
+			phba->hba_state = ELX_HBA_READY;
+		}
+	} else {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	}
+	return;
+}
+
+/*
+ * This routine handles processing a CLEAR_LA mailbox
+ * command upon completion. It is setup in the ELX_MBOXQ
+ * as the completion routine when the command is
+ * handed off to the SLI layer.
+ */
+void
+lpfc_mbx_cmpl_clear_la(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	LPFCHBA_t *plhba;
+	elxCfgParam_t *clp;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	MAILBOX_t *mb;
+	uint32_t control;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	clp = &phba->config[0];
+	mb = &pmb->mb;
+	/* Since we don't do discovery right now, turn these off here */
+	psli->ring[psli->ip_ring].flag &= ~ELX_STOP_IOCB_EVENT;
+	psli->ring[psli->fcp_ring].flag &= ~ELX_STOP_IOCB_EVENT;
+	psli->ring[psli->next_ring].flag &= ~ELX_STOP_IOCB_EVENT;
+	/* Check for error */
+	if ((mb->mbxStatus) && (mb->mbxStatus != 0x1601)) {
+		/* CLEAR_LA mbox error <mbxStatus> state <hba_state> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0320,	/* ptr to msg structure */
+			       elx_mes0320,	/* ptr to msg */
+			       elx_msgBlk0320.msgPreambleStr,	/* begin varargs */
+			       mb->mbxStatus, phba->hba_state);	/* end varargs */
+
+		phba->hba_state = ELX_HBA_ERROR;
+		goto out;
+	}
+
+	plhba->num_disc_nodes = 0;
+	/* go thru PLOGI list and issue ELS PLOGIs */
+	if (plhba->fc_plogi_cnt) {
+		ndlp = plhba->fc_plogi_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+			if (ndlp->nlp_state == NLP_STE_UNUSED_NODE) {
+				ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+				lpfc_issue_els_plogi(phba, ndlp, 0);
+				ndlp->nlp_flag |= NLP_DISC_NODE;
+				plhba->num_disc_nodes++;
+				if (plhba->num_disc_nodes >=
+				    clp[LPFC_CFG_DISC_THREADS].a_current) {
+					if (plhba->fc_plogi_cnt >
+					    plhba->num_disc_nodes)
+						plhba->fc_flag |= FC_NLP_MORE;
+					break;
+				}
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+	if (plhba->num_disc_nodes == 0) {
+		phba->hba_flag &= ~FC_NDISC_ACTIVE;
+	}
+	phba->hba_state = ELX_HBA_READY;
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		plhba->fc_nlp_bcast.nle.nlp_failMask = 0;
+	}
+      out:
+	/* Device Discovery completes */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0225,	/* ptr to msg structure */
+		       elx_mes0225,	/* ptr to msg */
+		       elx_msgBlk0225.msgPreambleStr);	/* begin & end varargs */
+
+	phba->hba_flag &= ~FC_LFR_ACTIVE;
+
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	if (plhba->fc_flag & FC_ESTABLISH_LINK) {
+		plhba->fc_flag &= ~FC_ESTABLISH_LINK;
+	}
+	if (plhba->fc_estabtmo) {
+		elx_clk_can(phba, plhba->fc_estabtmo);
+		plhba->fc_estabtmo = 0;
+	}
+	lpfc_can_disctmo(phba);
+
+	/* turn on Link Attention interrupts */
+	psli->sliinit.sli_flag |= ELX_PROCESS_LA;
+	control = (psli->sliinit.elx_sli_read_HC) (phba);
+	control |= HC_LAINT_ENA;
+	(psli->sliinit.elx_sli_write_HC) (phba, control);
+
+	/* If there are mapped FCP nodes still running, restart the scheduler 
+	 * to get any pending IOCBs out.
+	 */
+	if (plhba->fc_map_cnt) {
+		elx_sched_check(phba);
+	}
+	return;
+}
+
+/*
+ * This routine handles processing a REG_LOGIN mailbox
+ * command upon completion. It is setup in the ELX_MBOXQ
+ * as the completion routine when the command is
+ * handed off to the SLI layer.
+ */
+void
+lpfc_mbx_cmpl_reg_login(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+	DMABUF_t *mp;
+	LPFC_NODELIST_t *ndlp;
+
+	psli = &phba->sli;
+	mb = &pmb->mb;
+
+	ndlp = (LPFC_NODELIST_t *) pmb->context2;
+	mp = (DMABUF_t *) (pmb->context1);
+
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORCPU);
+	pmb->context1 = 0;
+
+	/* Good status, call state machine */
+	lpfc_disc_state_machine(phba, ndlp, (void *)pmb,
+				NLP_EVT_CMPL_REG_LOGIN);
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+
+	return;
+}
+
+/*
+ * This routine handles processing a Fabric REG_LOGIN mailbox
+ * command upon completion. It is setup in the ELX_MBOXQ
+ * as the completion routine when the command is
+ * handed off to the SLI layer.
+ */
+void
+lpfc_mbx_cmpl_fabric_reg_login(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+	DMABUF_t *mp;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_NODELIST_t *ndlp_fdmi;
+	elxCfgParam_t *clp;
+
+	clp = &phba->config[0];
+
+	psli = &phba->sli;
+	mb = &pmb->mb;
+
+	ndlp = (LPFC_NODELIST_t *) pmb->context2;
+	mp = (DMABUF_t *) (pmb->context1);
+
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORCPU);
+	pmb->context1 = 0;
+
+	if (ndlp->nle.nlp_rpi != 0)
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+	ndlp->nle.nlp_rpi = mb->un.varWords[0];
+	lpfc_addnode_rpi(phba, ndlp, ndlp->nle.nlp_rpi);
+	ndlp->nle.nlp_type |= NLP_FABRIC;
+	lpfc_nlp_unmapped(phba, ndlp);
+	ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+
+	if (phba->hba_state == ELX_FABRIC_CFG_LINK) {
+		/* This NPort has been assigned an NPort_ID by the fabric as a result
+		 * of the completed fabric login.  Issue a State Change Registration (SCR) 
+		 * ELS request to the fabric controller (SCR_DID) so that this
+		 * NPort gets RSCN events from the fabric.
+		 */
+		lpfc_issue_els_scr(phba, SCR_DID, 0);
+
+		/* Allocate a new node instance.  If the pool is empty, just start 
+		 * the discovery process and skip the Nameserver login process.  
+		 * This is attempted again later on.  Otherwise, issue a Port Login (PLOGI)
+		 * to the NameServer 
+		 */
+		if ((ndlp =
+		     (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP)) == 0) {
+			lpfc_disc_start(phba);
+		} else {
+			memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+			ndlp->nle.nlp_type |= NLP_FABRIC;
+			ndlp->nlp_DID = NameServer_DID;
+			ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+			lpfc_issue_els_plogi(phba, ndlp, 0);
+			if (clp[LPFC_CFG_FDMI_ON].a_current) {
+				if ((ndlp_fdmi =
+				     (LPFC_NODELIST_t *) elx_mem_get(phba,
+								     MEM_NLP)))
+				{
+					memset((void *)ndlp_fdmi, 0,
+					       sizeof (LPFC_NODELIST_t));
+					ndlp_fdmi->nle.nlp_type |= NLP_FABRIC;
+					ndlp_fdmi->nlp_DID = FDMI_DID;
+					ndlp_fdmi->nlp_state =
+					    NLP_STE_PLOGI_ISSUE;
+					lpfc_issue_els_plogi(phba, ndlp_fdmi,
+							     0);
+				}
+			}
+		}
+	}
+
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+
+	return;
+}
+
+/*
+ * This routine handles processing a NameServer REG_LOGIN mailbox
+ * command upon completion. It is setup in the ELX_MBOXQ
+ * as the completion routine when the command is
+ * handed off to the SLI layer.
+ */
+void
+lpfc_mbx_cmpl_ns_reg_login(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+	DMABUF_t *mp;
+	LPFC_NODELIST_t *ndlp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	mb = &pmb->mb;
+
+	ndlp = (LPFC_NODELIST_t *) pmb->context2;
+	mp = (DMABUF_t *) (pmb->context1);
+
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORCPU);
+	pmb->context1 = 0;
+
+	if (ndlp->nle.nlp_rpi != 0)
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+	ndlp->nle.nlp_rpi = mb->un.varWords[0];
+	lpfc_addnode_rpi(phba, ndlp, ndlp->nle.nlp_rpi);
+	ndlp->nle.nlp_type |= NLP_FABRIC;
+	lpfc_nlp_unmapped(phba, ndlp);
+	ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+
+	if (phba->hba_state < ELX_HBA_READY) {
+		/* Link up discovery requires Fabrib registration. */
+		lpfc_ns_cmd(phba, ndlp, SLI_CTNS_RNN_ID);
+		lpfc_ns_cmd(phba, ndlp, SLI_CTNS_RSNN_NN);
+		lpfc_ns_cmd(phba, ndlp, SLI_CTNS_RFT_ID);
+	}
+
+	plhba->fc_ns_retry = 0;
+	/* Good status, issue CT Request to NameServer */
+	if (lpfc_ns_cmd(phba, ndlp, SLI_CTNS_GID_FT)) {
+		/* Cannot issue NameServer Query, so finish up discovery */
+		lpfc_disc_start(phba);
+	}
+
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+
+	return;
+}
+
+/* Put blp on the bind list */
+int
+lpfc_nlp_bind(elxHBA_t * phba, LPFC_BINDLIST_t * blp)
+{
+	ELX_DLINK_t *end_blp;
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ELX_DISC_LOCK(phba, iflag);
+	/* Put it at the end of the bind list */
+	end_blp = (ELX_DLINK_t *) plhba->fc_nlpbind_end;
+	elx_enque(((ELX_DLINK_t *) blp), end_blp);
+	plhba->fc_bind_cnt++;
+	targetp =
+	    plhba->device_queue_hash[FC_SCSID(blp->nlp_pan, blp->nlp_sid)];
+	if (targetp) {
+		targetp->pcontext = 0;
+		lunp = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+		while (lunp) {
+			lunp->pnode = 0;
+			lunp = lunp->pnextLun;
+		}
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* Add scsiid <sid> to BIND list */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0903,	/* ptr to msg structure */
+		       elx_mes0903,	/* ptr to msg */
+		       elx_msgBlk0903.msgPreambleStr,	/* begin varargs */
+		       blp->nlp_sid, plhba->fc_bind_cnt, blp->nlp_DID, blp->nlp_bind_type, (unsigned long)blp);	/* end varargs */
+
+	return (0);
+}
+
+/* Put blp on the plogi list */
+int
+lpfc_nlp_plogi(elxHBA_t * phba, LPFC_NODELIST_t * nlp)
+{
+	ELX_DLINK_t *end_nlp;
+	LPFCHBA_t *plhba;
+	unsigned long iflag;
+	LPFC_BINDLIST_t *blp;
+	ELX_SLI_t *psli;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	blp = 0;
+
+	ELX_DISC_LOCK(phba, iflag);
+	/* Check to see if this node exists on any other list */
+	if (nlp->nlp_flag & NLP_LIST_MASK) {
+		if (nlp->nlp_flag & NLP_MAPPED_LIST) {
+			nlp->nlp_flag &= ~NLP_MAPPED_LIST;
+			plhba->fc_map_cnt--;
+			elx_deque(nlp);
+
+			/* Must call before binding is removed */
+			lpfc_set_failmask(phba, nlp, ELX_DEV_DISCONNECTED,
+					  ELX_SET_BITMASK);
+
+			blp = nlp->nlp_listp_bind;
+			if (blp) {
+				blp->nlp_Target = nlp->nlp_Target;
+			}
+			elx_sched_flush_target(phba, nlp->nlp_Target,
+					       IOSTAT_DRIVER_REJECT,
+					       IOERR_SLI_ABORTED);
+			nlp->nlp_listp_bind = 0;
+			nlp->nlp_pan = 0;
+			nlp->nlp_sid = 0;
+			nlp->nlp_Target = 0;
+			nlp->nlp_flag &= ~NLP_SEED_MASK;
+
+			/* This node is moving to the plogi list so something has happened.
+			 * Flush all pending IP bufs.
+			 */
+			if (nlp->nle.nlp_type & NLP_IP_NODE) {
+				lpfc_ip_flush_iocb(phba,
+						   &psli->ring[psli->ip_ring],
+						   nlp, FLUSH_NODE);
+			}
+		} else if (nlp->nlp_flag & NLP_UNMAPPED_LIST) {
+			nlp->nlp_flag &=
+			    ~(NLP_UNMAPPED_LIST | NLP_TGT_NO_SCSIID);
+			plhba->fc_unmap_cnt--;
+			elx_deque(nlp);
+
+			/* This node is moving to the plogi list so something has happened.
+			 * Flush all pending IP bufs.
+			 */
+			if (nlp->nle.nlp_type & NLP_IP_NODE) {
+				lpfc_ip_flush_iocb(phba,
+						   &psli->ring[psli->ip_ring],
+						   nlp, FLUSH_NODE);
+			}
+		} else if (nlp->nlp_flag & NLP_PLOGI_LIST) {
+			ELX_DISC_UNLOCK(phba, iflag);
+			return (0);	/* Already on plogi list */
+		} else if (nlp->nlp_flag & NLP_ADISC_LIST) {
+			nlp->nlp_flag &= ~NLP_ADISC_LIST;
+			plhba->fc_adisc_cnt--;
+			elx_deque(nlp);
+		}
+	}
+
+	/* Put it at the end of the plogi list */
+	end_nlp = (ELX_DLINK_t *) plhba->fc_plogi_end;
+	elx_enque(((ELX_DLINK_t *) nlp), end_nlp);
+	plhba->fc_plogi_cnt++;
+	nlp->nlp_flag |= NLP_PLOGI_LIST;
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* Add NPort <did> to PLOGI list */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0904,	/* ptr to msg structure */
+		       elx_mes0904,	/* ptr to msg */
+		       elx_msgBlk0904.msgPreambleStr,	/* begin varargs */
+		       nlp->nlp_DID, plhba->fc_plogi_cnt, (unsigned long)blp);	/* end varargs */
+
+	if (blp) {
+		lpfc_nlp_bind(phba, blp);
+	}
+	return (0);
+}
+
+/* Put nlp on the adisc list */
+int
+lpfc_nlp_adisc(elxHBA_t * phba, LPFC_NODELIST_t * nlp)
+{
+	ELX_DLINK_t *end_nlp;
+	LPFCHBA_t *plhba;
+	unsigned long iflag;
+	LPFC_BINDLIST_t *blp;
+	ELX_SLI_t *psli;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	blp = 0;
+	psli = &phba->sli;
+
+	ELX_DISC_LOCK(phba, iflag);
+
+	/* Check to see if this node exist on any other list */
+	if (nlp->nlp_flag & NLP_LIST_MASK) {
+		if (nlp->nlp_flag & NLP_MAPPED_LIST) {
+			nlp->nlp_flag &= ~NLP_MAPPED_LIST;
+			plhba->fc_map_cnt--;
+			elx_deque(nlp);
+
+			/* Must call before binding is removed */
+			lpfc_set_failmask(phba, nlp, ELX_DEV_DISAPPEARED,
+					  ELX_SET_BITMASK);
+
+			blp = nlp->nlp_listp_bind;
+			if (blp) {
+				blp->nlp_Target = nlp->nlp_Target;
+			}
+
+			if (nlp->nlp_Target) {
+				elx_sched_flush_target(phba, nlp->nlp_Target,
+						       IOSTAT_DRIVER_REJECT,
+						       IOERR_SLI_ABORTED);
+			}
+
+			nlp->nlp_listp_bind = 0;
+			nlp->nlp_Target = 0;
+
+			/* Keep pan and sid since ELX_DEV_DISAPPEARED
+			 * is a non-fatal error
+			 */
+			nlp->nlp_flag &= ~NLP_SEED_MASK;
+
+			/* This node is moving to the adisc list so something has happened.
+			 * Flush all pending IP bufs.
+			 */
+			if (nlp->nle.nlp_type & NLP_IP_NODE) {
+				lpfc_ip_flush_iocb(phba,
+						   &psli->ring[psli->ip_ring],
+						   nlp, FLUSH_NODE);
+			}
+		} else if (nlp->nlp_flag & NLP_UNMAPPED_LIST) {
+			nlp->nlp_flag &=
+			    ~(NLP_UNMAPPED_LIST | NLP_TGT_NO_SCSIID);
+			plhba->fc_unmap_cnt--;
+			elx_deque(nlp);
+
+			/* This node is moving to the adisc list so something has happened.
+			 * Flush all pending IP bufs.
+			 */
+			if (nlp->nle.nlp_type & NLP_IP_NODE) {
+				lpfc_ip_flush_iocb(phba,
+						   &psli->ring[psli->ip_ring],
+						   nlp, FLUSH_NODE);
+			}
+		} else if (nlp->nlp_flag & NLP_PLOGI_LIST) {
+			nlp->nlp_flag &= ~NLP_PLOGI_LIST;
+			plhba->fc_plogi_cnt--;
+			elx_deque(nlp);
+		} else if (nlp->nlp_flag & NLP_ADISC_LIST) {
+			ELX_DISC_UNLOCK(phba, iflag);
+			return (0);	/* Already on adisc list */
+		}
+	}
+
+	/* Put it at the end of the adisc list */
+	end_nlp = (ELX_DLINK_t *) plhba->fc_adisc_end;
+	elx_enque(((ELX_DLINK_t *) nlp), end_nlp);
+	plhba->fc_adisc_cnt++;
+	nlp->nlp_flag |= NLP_ADISC_LIST;
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* Add NPort <did> to ADISC list */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0905,	/* ptr to msg structure */
+		       elx_mes0905,	/* ptr to msg */
+		       elx_msgBlk0905.msgPreambleStr,	/* begin varargs */
+		       nlp->nlp_DID, plhba->fc_adisc_cnt, (unsigned long)blp);	/* end varargs */
+
+	if (blp) {
+		lpfc_nlp_bind(phba, blp);
+	}
+
+	return (0);
+}
+
+/*
+ * Put nlp on the unmapped list 
+ * NOTE: - update nlp_type to NLP_FC_NODE
+ */
+int
+lpfc_nlp_unmapped(elxHBA_t * phba, LPFC_NODELIST_t * nlp)
+{
+	ELX_DLINK_t *end_nlp;
+	LPFCHBA_t *plhba;
+	unsigned long iflag;
+	LPFC_BINDLIST_t *blp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	blp = 0;
+	ELX_DISC_LOCK(phba, iflag);
+	/* Check to see if this node exists on any other list */
+	if (nlp->nlp_flag & NLP_LIST_MASK) {
+		if (nlp->nlp_flag & NLP_MAPPED_LIST) {
+			nlp->nlp_flag &= ~NLP_MAPPED_LIST;
+			plhba->fc_map_cnt--;
+			elx_deque(nlp);
+
+			/* Must call before binding is removed */
+			lpfc_set_failmask(phba, nlp, ELX_DEV_DISAPPEARED,
+					  ELX_SET_BITMASK);
+
+			blp = nlp->nlp_listp_bind;
+			if (blp) {
+				blp->nlp_Target = nlp->nlp_Target;
+			}
+			elx_sched_flush_target(phba, nlp->nlp_Target,
+					       IOSTAT_DRIVER_REJECT,
+					       IOERR_SLI_ABORTED);
+			nlp->nlp_listp_bind = 0;
+			nlp->nlp_Target = 0;
+			/* Keep pan and sid since ELX_DEV_DISAPPEARED
+			 * is a non-fatal error
+			 */
+			nlp->nlp_flag &= ~NLP_SEED_MASK;
+		} else if (nlp->nlp_flag & NLP_UNMAPPED_LIST) {
+			ELX_DISC_UNLOCK(phba, iflag);
+			return (0);	/* Already on unmapped list */
+		} else if (nlp->nlp_flag & NLP_PLOGI_LIST) {
+			nlp->nlp_flag &= ~NLP_PLOGI_LIST;
+			plhba->fc_plogi_cnt--;
+			elx_deque(nlp);
+		} else if (nlp->nlp_flag & NLP_ADISC_LIST) {
+			nlp->nlp_flag &= ~NLP_ADISC_LIST;
+			plhba->fc_adisc_cnt--;
+			elx_deque(nlp);
+		}
+	}
+
+	/* Put it at the end of the unmapped list */
+	end_nlp = (ELX_DLINK_t *) plhba->fc_nlpunmap_end;
+	elx_enque(((ELX_DLINK_t *) nlp), end_nlp);
+	plhba->fc_unmap_cnt++;
+	nlp->nle.nlp_type |= NLP_FC_NODE;
+	nlp->nlp_flag |= NLP_UNMAPPED_LIST;
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* Add NPort <did> to UNMAP list */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0906,	/* ptr to msg structure */
+		       elx_mes0906,	/* ptr to msg */
+		       elx_msgBlk0906.msgPreambleStr,	/* begin varargs */
+		       nlp->nlp_DID, plhba->fc_unmap_cnt, (unsigned long)blp);	/* end varargs */
+
+	if (blp) {
+		lpfc_nlp_bind(phba, blp);
+	}
+	return (0);
+}
+
+/*
+ * Put nlp on the mapped list 
+ * NOTE: - update nlp_type to NLP_FCP_TARGET
+ *       - attach binding entry to context2 
+ */
+int
+lpfc_nlp_mapped(elxHBA_t * phba, LPFC_NODELIST_t * nlp, LPFC_BINDLIST_t * blp)
+{
+	ELX_DLINK_t *end_nlp;
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ELX_DISC_LOCK(phba, iflag);
+
+	/* Check to see if this node exists on any other list */
+	if (nlp->nlp_flag & NLP_LIST_MASK) {
+		if (nlp->nlp_flag & NLP_MAPPED_LIST) {
+			ELX_DISC_UNLOCK(phba, iflag);
+			return (0);	/* Already on mapped list */
+		} else if (nlp->nlp_flag & NLP_UNMAPPED_LIST) {
+			nlp->nlp_flag &=
+			    ~(NLP_UNMAPPED_LIST | NLP_TGT_NO_SCSIID);
+			plhba->fc_unmap_cnt--;
+			elx_deque(nlp);
+		} else if (nlp->nlp_flag & NLP_PLOGI_LIST) {
+			nlp->nlp_flag &= ~NLP_PLOGI_LIST;
+			plhba->fc_plogi_cnt--;
+			elx_deque(nlp);
+		} else if (nlp->nlp_flag & NLP_ADISC_LIST) {
+			nlp->nlp_flag &= ~NLP_ADISC_LIST;
+			plhba->fc_adisc_cnt--;
+			elx_deque(nlp);
+		}
+	}
+
+	/* Put it at the end of the mapped list */
+	end_nlp = (ELX_DLINK_t *) plhba->fc_nlpmap_end;
+	elx_enque(((ELX_DLINK_t *) nlp), end_nlp);
+	plhba->fc_map_cnt++;
+	nlp->nlp_flag |= NLP_MAPPED_LIST;
+	nlp->nle.nlp_type |= NLP_FCP_TARGET;
+	nlp->nlp_pan = blp->nlp_pan;
+	nlp->nlp_sid = blp->nlp_sid;
+	nlp->nlp_Target = blp->nlp_Target;
+	nlp->nlp_listp_bind = blp;
+	targetp =
+	    plhba->device_queue_hash[FC_SCSID(nlp->nlp_pan, nlp->nlp_sid)];
+
+	/* Add NPort <did> to MAPPED list scsiid <sid> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0907,	/* ptr to msg structure */
+		       elx_mes0907,	/* ptr to msg */
+		       elx_msgBlk0907.msgPreambleStr,	/* begin varargs */
+		       nlp->nlp_DID, nlp->nlp_sid, plhba->fc_map_cnt, (unsigned long)blp);	/* end varargs */
+
+	if (targetp) {
+		nlp->nlp_Target = targetp;
+		targetp->pcontext = (void *)nlp;
+		lunp = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+		while (lunp) {
+			lunp->pnode = (ELX_NODELIST_t *) nlp;
+			lunp = lunp->pnextLun;
+		}
+	}
+	/* Must call after binding is associated */
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	return (0);
+}
+
+/*
+ * Start / ReStart rescue timer for Discovery / RSCN handling
+ */
+void *
+lpfc_set_disctmo(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	uint32_t tmo;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	tmo = ((plhba->fc_ratov * 2) + 1);
+
+	/* Turn off discovery timer if its running */
+	if (plhba->fc_disctmo) {
+		elx_clk_can(phba, plhba->fc_disctmo);
+		plhba->fc_disctmo = 0;
+	}
+	plhba->fc_disctmo = elx_clk_set(phba, tmo, lpfc_disc_timeout, 0, 0);
+
+	/* Start Discovery Timer state <hba_state> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0247,	/* ptr to msg structure */
+		       elx_mes0247,	/* ptr to msg */
+		       elx_msgBlk0247.msgPreambleStr,	/* begin varargs */
+		       phba->hba_state, tmo, (unsigned long)plhba->fc_disctmo, plhba->fc_plogi_cnt, plhba->fc_adisc_cnt);	/* end varargs */
+
+	return ((void *)plhba->fc_disctmo);
+}
+
+/*
+ * Cancel rescue timer for Discovery / RSCN handling
+ */
+int
+lpfc_can_disctmo(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	int rc;
+
+	rc = 0;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* Turn off discovery timer if its running */
+	if (plhba->fc_disctmo) {
+		elx_clk_can(phba, plhba->fc_disctmo);
+		plhba->fc_disctmo = 0;
+		rc = 1;
+	}
+
+	/* Cancel Discovery Timer state <hba_state> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0248,	/* ptr to msg structure */
+		       elx_mes0248,	/* ptr to msg */
+		       elx_msgBlk0248.msgPreambleStr,	/* begin varargs */
+		       phba->hba_state, plhba->fc_flag, rc, plhba->fc_plogi_cnt, plhba->fc_adisc_cnt);	/* end varargs */
+
+	return (rc);
+}
+
+/*
+ * Check specified ring for outstanding IOCB on the SLI queue
+ * Return true if iocb matches the specified nport
+ */
+int
+lpfc_check_sli_ndlp(elxHBA_t * phba,
+		    ELX_SLI_RING_t * pring,
+		    ELX_IOCBQ_t * iocb, LPFC_NODELIST_t * ndlp)
+{
+	ELX_SLI_t *psli;
+	IOCB_t *icmd;
+
+	psli = &phba->sli;
+	icmd = &iocb->iocb;
+	if (pring->ringno == LPFC_ELS_RING) {
+		switch (icmd->ulpCommand) {
+		case CMD_GEN_REQUEST64_CR:
+			if (icmd->ulpContext ==
+			    (volatile ushort)ndlp->nle.nlp_rpi)
+				return (1);
+		case CMD_ELS_REQUEST64_CR:
+		case CMD_XMIT_ELS_RSP64_CX:
+			if (iocb->context1 == (uint8_t *) ndlp)
+				return (1);
+		}
+	} else if (pring->ringno == psli->ip_ring) {
+
+	} else if (pring->ringno == psli->fcp_ring) {
+		if (icmd->ulpContext == (volatile ushort)ndlp->nle.nlp_rpi)
+			return (1);
+	} else if (pring->ringno == psli->next_ring) {
+
+	}
+	return (0);
+}
+
+/*
+ * Free resources / clean up outstanding I/Os
+ * associated with nlp_rpi in the LPFC_NODELIST entry.
+ */
+int
+lpfc_no_rpi(elxHBA_t * phba, LPFC_NODELIST_t * ndlp)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	IOCB_t *icmd;
+	unsigned long iflag;
+	uint32_t rpi, i;
+
+	psli = &phba->sli;
+	rpi = ndlp->nle.nlp_rpi;
+	if (rpi) {
+		/* Now process each ring */
+		for (i = 0; i < psli->sliinit.num_rings; i++) {
+			pring = &psli->ring[i];
+
+			ELX_SLI_LOCK(phba, iflag);
+			next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+			while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+				iocb = next_iocb;
+				next_iocb = next_iocb->q_f;
+				/* Check to see if iocb matches the nport we are looking for */
+				if ((lpfc_check_sli_ndlp
+				     (phba, pring, iocb, ndlp))) {
+					/* It matches, so deque and call compl with an error */
+					elx_deque(iocb);
+					pring->txq.q_cnt--;
+					if (iocb->iocb_cmpl) {
+						icmd = &iocb->iocb;
+						icmd->ulpStatus =
+						    IOSTAT_DRIVER_REJECT;
+						icmd->un.ulpWord[4] =
+						    IOERR_SLI_ABORTED;
+						ELX_SLI_UNLOCK(phba, iflag);
+						(iocb->iocb_cmpl) ((void *)phba,
+								   iocb, iocb);
+						ELX_SLI_LOCK(phba, iflag);
+					} else {
+						elx_mem_put(phba, MEM_IOCB,
+							    (uint8_t *) iocb);
+					}
+				}
+			}
+			/* Everything that matches on txcmplq will be returned by 
+			 * firmware with a no rpi error.
+			 */
+			ELX_SLI_UNLOCK(phba, iflag);
+		}
+	}
+	return (0);
+}
+
+/*
+ * Free resources / clean up outstanding I/Os
+ * associated with a LPFC_NODELIST entry. This
+ * routine effectively results in a "software abort".
+ */
+int
+lpfc_driver_abort(elxHBA_t * phba, LPFC_NODELIST_t * ndlp)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	IOCB_t *icmd;
+	ELXCLOCK_t *clkp;
+	unsigned long iflag;
+	uint32_t i, cmd;
+
+	/* Abort outstanding I/O on NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0201,	/* ptr to msg structure */
+		       elx_mes0201,	/* ptr to msg */
+		       elx_msgBlk0201.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+	psli = &phba->sli;
+	/* Now process each ring */
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		pring = &psli->ring[i];
+
+		ELX_SLI_LOCK(phba, iflag);
+		/* First check the txq */
+		next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+		while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+			iocb = next_iocb;
+			next_iocb = next_iocb->q_f;
+			/* Check to see if iocb matches the nport we are looking for */
+			if ((lpfc_check_sli_ndlp(phba, pring, iocb, ndlp))) {
+				/* It matches, so deque and call compl with an error */
+				elx_deque(iocb);
+				pring->txq.q_cnt--;
+				if (iocb->iocb_cmpl) {
+					icmd = &iocb->iocb;
+					icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+					icmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+					ELX_SLI_UNLOCK(phba, iflag);
+					(iocb->iocb_cmpl) ((void *)phba, iocb,
+							   iocb);
+					ELX_SLI_LOCK(phba, iflag);
+				} else {
+					elx_mem_put(phba, MEM_IOCB,
+						    (uint8_t *) iocb);
+				}
+			}
+		}
+		/* Everything on txcmplq will be returned by 
+		 * firmware with a no rpi / linkdown / abort  error.
+		 * For ring 0, ELS discovery, we want to get rid of it right here.
+		 */
+		if (pring->ringno == LPFC_ELS_RING) {
+			/* Next check the txcmplq */
+			next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+			while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+				iocb = next_iocb;
+				next_iocb = next_iocb->q_f;
+				/* Check to see if iocb matches the nport we are looking for */
+				if ((lpfc_check_sli_ndlp
+				     (phba, pring, iocb, ndlp))) {
+					/* It matches, so deque and call compl with an error */
+					elx_deque(iocb);
+					pring->txcmplq.q_cnt--;
+
+					icmd = &iocb->iocb;
+					/* If the driver is completing an ELS command early, flush it out
+					 * of the firmware.
+					 */
+					if ((icmd->ulpCommand ==
+					     CMD_ELS_REQUEST64_CR)
+					    && (icmd->un.elsreq64.bdl.
+						ulpIoTag32)) {
+						ELX_SLI_UNLOCK(phba, iflag);
+						elx_sli_issue_abort_iotag32
+						    (phba, pring, iocb);
+						ELX_SLI_LOCK(phba, iflag);
+					}
+					if (iocb->iocb_cmpl) {
+						icmd->ulpStatus =
+						    IOSTAT_DRIVER_REJECT;
+						icmd->un.ulpWord[4] =
+						    IOERR_SLI_ABORTED;
+						ELX_SLI_UNLOCK(phba, iflag);
+						(iocb->iocb_cmpl) ((void *)phba,
+								   iocb, iocb);
+						ELX_SLI_LOCK(phba, iflag);
+					} else {
+						elx_mem_put(phba, MEM_IOCB,
+							    (uint8_t *) iocb);
+					}
+				}
+			}
+		}
+		ELX_SLI_UNLOCK(phba, iflag);
+	}
+
+	/* If we are delaying issuing an ELS command, cancel it */
+	if ((ndlp->nlp_tmofunc) && (ndlp->nlp_flag & NLP_DELAY_TMO)) {
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		clkp = (ELXCLOCK_t *) (ndlp->nlp_tmofunc);
+		cmd = (uint32_t) (unsigned long)clkp->cl_arg2;
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_tmofunc = 0;
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+
+		/* Allocate an IOCB and indicate an error completion */
+		/* Allocate a buffer for the command iocb */
+		if ((iocb =
+		     (ELX_IOCBQ_t *) elx_mem_get(phba,
+						 MEM_IOCB | MEM_PRI)) == 0) {
+			return (0);
+		}
+		memset((void *)iocb, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &iocb->iocb;
+		icmd->ulpStatus = IOSTAT_DRIVER_REJECT;
+		icmd->un.ulpWord[4] = IOERR_SLI_ABORTED;
+		iocb->context1 = (void *)ndlp;
+
+		switch (cmd) {
+		case ELS_CMD_FLOGI:
+			iocb->iocb_cmpl = lpfc_cmpl_els_flogi;
+			break;
+		case ELS_CMD_PLOGI:
+			iocb->iocb_cmpl = lpfc_cmpl_els_plogi;
+			break;
+		case ELS_CMD_ADISC:
+			iocb->iocb_cmpl = lpfc_cmpl_els_adisc;
+			break;
+		case ELS_CMD_PRLI:
+			iocb->iocb_cmpl = lpfc_cmpl_els_prli;
+			break;
+		case ELS_CMD_LOGO:
+			iocb->iocb_cmpl = lpfc_cmpl_els_logo;
+			break;
+		default:
+			iocb->iocb_cmpl = lpfc_cmpl_els_cmd;
+			break;
+		}
+		(iocb->iocb_cmpl) ((void *)phba, iocb, iocb);
+	}
+	return (0);
+}
+
+/*
+ * Free resources associated with LPFC_NODELIST entry
+ * so it can be freed.
+ */
+int
+lpfc_freenode(elxHBA_t * phba, LPFC_NODELIST_t * ndlp)
+{
+	ELX_MBOXQ_t *mbox;
+	ELX_SLI_t *psli;
+
+	/* The psli variable gets rid of the long pointer deference. */
+	psli = &phba->sli;
+
+	/* Cleanup node for NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0900,	/* ptr to msg structure */
+		       elx_mes0900,	/* ptr to msg */
+		       elx_msgBlk0900.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+	/* NLP_FREED_NODE flag is to protect the node from being freed
+	 * more then once. For driver_abort and other cases where the DSM 
+	 * calls itself recursively, its possible to free the node twice.
+	 */
+	if (ndlp->nle.nlp_rflag & NLP_FREED_NODE) {
+		return (0);
+	}
+
+	if (ndlp->nlp_flag & NLP_LIST_MASK) {
+		lpfc_findnode_did(phba, (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+				  ndlp->nlp_DID);
+	}
+
+	if (ndlp->nlp_tmofunc) {
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+		ndlp->nlp_tmofunc = 0;
+	}
+
+	if (ndlp->nle.nlp_type & NLP_IP_NODE) {
+		lpfc_ip_flush_iocb(phba, &psli->ring[psli->ip_ring], ndlp,
+				   FLUSH_NODE);
+	}
+
+	if (ndlp->nle.nlp_rpi) {
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			lpfc_unreg_login(phba, ndlp->nle.nlp_rpi, mbox);
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+			}
+		}
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+		lpfc_no_rpi(phba, ndlp);
+		ndlp->nle.nlp_rpi = 0;
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_DISCONNECTED,
+				  ELX_SET_BITMASK);
+	}
+	return (0);
+}
+
+int
+lpfc_matchdid(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, uint32_t did)
+{
+	D_ID mydid;
+	D_ID ndlpdid;
+	D_ID matchdid;
+	int zero_did;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	if (did == Bcast_DID)
+		return (0);
+
+	zero_did = 0;
+	if (ndlp->nlp_DID == 0) {
+		return (0);
+	}
+
+	/* First check for Direct match */
+	if (ndlp->nlp_DID == did)
+		return (1);
+
+	/* Next check for area/domain identically equals 0 match */
+	mydid.un.word = plhba->fc_myDID;
+	if ((mydid.un.b.domain == 0) && (mydid.un.b.area == 0)) {
+		goto out;
+	}
+
+	matchdid.un.word = did;
+	ndlpdid.un.word = ndlp->nlp_DID;
+	if (matchdid.un.b.id == ndlpdid.un.b.id) {
+		if ((mydid.un.b.domain == matchdid.un.b.domain) &&
+		    (mydid.un.b.area == matchdid.un.b.area)) {
+			if ((ndlpdid.un.b.domain == 0) &&
+			    (ndlpdid.un.b.area == 0)) {
+				if (ndlpdid.un.b.id)
+					return (1);
+			}
+			goto out;
+		}
+
+		matchdid.un.word = ndlp->nlp_DID;
+		if ((mydid.un.b.domain == ndlpdid.un.b.domain) &&
+		    (mydid.un.b.area == ndlpdid.un.b.area)) {
+			if ((matchdid.un.b.domain == 0) &&
+			    (matchdid.un.b.area == 0)) {
+				if (matchdid.un.b.id)
+					return (1);
+			}
+		}
+	}
+      out:
+	if (zero_did)
+		ndlp->nlp_DID = 0;
+	return (0);
+}
+
+/* Search for a nodelist entry on a specific list */
+LPFC_NODELIST_t *
+lpfc_findnode_scsiid(elxHBA_t * phba, uint32_t scsid)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ELX_DISC_LOCK(phba, iflag);
+
+	targetp = plhba->device_queue_hash[scsid];
+	/* First see if the SCSI ID has an allocated ELXSCSITARGET_t */
+	if (targetp) {
+		if (targetp->pcontext) {
+			ELX_DISC_UNLOCK(phba, iflag);
+			return ((LPFC_NODELIST_t *) targetp->pcontext);
+		}
+	}
+
+	/* Now try the hard way */
+	ndlp = plhba->fc_nlpmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		if (scsid == FC_SCSID(ndlp->nlp_pan, ndlp->nlp_sid)) {
+			ELX_DISC_UNLOCK(phba, iflag);
+			return (ndlp);
+		}
+		ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+	}
+
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* no match found */
+	return ((LPFC_NODELIST_t *) 0);
+}
+
+/* Search for a nodelist entry on a specific list */
+LPFC_NODELIST_t *
+lpfc_findnode_wwnn(elxHBA_t * phba, uint32_t order, NAME_TYPE * wwnn)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	uint32_t data1;
+	unsigned long iflag;
+	LPFC_BINDLIST_t *blp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	blp = 0;
+	ELX_DISC_LOCK(phba, iflag);
+	if (order & NLP_SEARCH_UNMAPPED) {
+		ndlp = plhba->fc_nlpunmap_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+			if (lpfc_geportname(&ndlp->nlp_nodename, wwnn) == 2) {
+
+				data1 = (((uint32_t) ndlp->nlp_state << 24) |
+					 ((uint32_t) ndlp->nlp_xri << 16) |
+					 ((uint32_t) ndlp->nle.nlp_type << 8) |
+					 ((uint32_t) ndlp->nle.nlp_rpi & 0xff));
+				/* FIND node DID unmapped */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0910,	/* ptr to msg structure */
+					       elx_mes0910,	/* ptr to msg */
+					       elx_msgBlk0910.msgPreambleStr,	/* begin varargs */
+					       (ulong) ndlp, ndlp->nlp_DID, ndlp->nlp_flag, data1);	/* end varargs */
+				if (order & NLP_SEARCH_DEQUE) {
+					ndlp->nlp_flag &=
+					    ~(NLP_UNMAPPED_LIST |
+					      NLP_TGT_NO_SCSIID);
+					plhba->fc_unmap_cnt--;
+					elx_deque(ndlp);
+				}
+				ELX_DISC_UNLOCK(phba, iflag);
+				return (ndlp);
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+
+	if (order & NLP_SEARCH_MAPPED) {
+		ndlp = plhba->fc_nlpmap_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+			if (lpfc_geportname(&ndlp->nlp_nodename, wwnn) == 2) {
+
+				data1 = (((uint32_t) ndlp->nlp_state << 24) |
+					 ((uint32_t) ndlp->nlp_xri << 16) |
+					 ((uint32_t) ndlp->nle.nlp_type << 8) |
+					 ((uint32_t) ndlp->nle.nlp_rpi & 0xff));
+				/* FIND node did mapped */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0902,	/* ptr to msg structure */
+					       elx_mes0902,	/* ptr to msg */
+					       elx_msgBlk0902.msgPreambleStr,	/* begin varargs */
+					       (ulong) ndlp, ndlp->nlp_DID, ndlp->nlp_flag, data1);	/* end varargs */
+				if (order & NLP_SEARCH_DEQUE) {
+					ndlp->nlp_flag &= ~NLP_MAPPED_LIST;
+					plhba->fc_map_cnt--;
+					elx_deque(ndlp);
+
+					/* Must call before binding is removed */
+					lpfc_set_failmask(phba, ndlp,
+							  ELX_DEV_DISAPPEARED,
+							  ELX_SET_BITMASK);
+
+					blp = ndlp->nlp_listp_bind;
+					ndlp->nlp_listp_bind = 0;
+					if (blp) {
+						blp->nlp_Target =
+						    ndlp->nlp_Target;
+					}
+					/* Keep Target, pan and sid since ELX_DEV_DISAPPEARED
+					 * is a non-fatal error
+					 */
+					ndlp->nlp_flag &= ~NLP_SEED_MASK;
+				}
+				ELX_DISC_UNLOCK(phba, iflag);
+				if (blp) {
+					lpfc_nlp_bind(phba, blp);
+				}
+				return (ndlp);
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* no match found */
+	return ((LPFC_NODELIST_t *) 0);
+}
+
+/* Search for a nodelist entry on a specific list */
+LPFC_NODELIST_t *
+lpfc_findnode_wwpn(elxHBA_t * phba, uint32_t order, NAME_TYPE * wwpn)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	uint32_t data1;
+	unsigned long iflag;
+	LPFC_BINDLIST_t *blp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	blp = 0;
+	ELX_DISC_LOCK(phba, iflag);
+	if (order & NLP_SEARCH_UNMAPPED) {
+		ndlp = plhba->fc_nlpunmap_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+			if (lpfc_geportname(&ndlp->nlp_portname, wwpn) == 2) {
+
+				data1 = (((uint32_t) ndlp->nlp_state << 24) |
+					 ((uint32_t) ndlp->nlp_xri << 16) |
+					 ((uint32_t) ndlp->nle.nlp_type << 8) |
+					 ((uint32_t) ndlp->nle.nlp_rpi & 0xff));
+				/* FIND node DID unmapped */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0911,	/* ptr to msg structure */
+					       elx_mes0911,	/* ptr to msg */
+					       elx_msgBlk0911.msgPreambleStr,	/* begin varargs */
+					       (ulong) ndlp, ndlp->nlp_DID, ndlp->nlp_flag, data1);	/* end varargs */
+				if (order & NLP_SEARCH_DEQUE) {
+					ndlp->nlp_flag &=
+					    ~(NLP_UNMAPPED_LIST |
+					      NLP_TGT_NO_SCSIID);
+					plhba->fc_unmap_cnt--;
+					elx_deque(ndlp);
+				}
+				ELX_DISC_UNLOCK(phba, iflag);
+				return (ndlp);
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+
+	if (order & NLP_SEARCH_MAPPED) {
+		ndlp = plhba->fc_nlpmap_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+			if (lpfc_geportname(&ndlp->nlp_portname, wwpn) == 2) {
+
+				data1 = (((uint32_t) ndlp->nlp_state << 24) |
+					 ((uint32_t) ndlp->nlp_xri << 16) |
+					 ((uint32_t) ndlp->nle.nlp_type << 8) |
+					 ((uint32_t) ndlp->nle.nlp_rpi & 0xff));
+				/* FIND node DID mapped */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0901,	/* ptr to msg structure */
+					       elx_mes0901,	/* ptr to msg */
+					       elx_msgBlk0901.msgPreambleStr,	/* begin varargs */
+					       (ulong) ndlp, ndlp->nlp_DID, ndlp->nlp_flag, data1);	/* end varargs */
+				if (order & NLP_SEARCH_DEQUE) {
+					ndlp->nlp_flag &= ~NLP_MAPPED_LIST;
+					plhba->fc_map_cnt--;
+					elx_deque(ndlp);
+
+					/* Must call before binding is removed */
+					lpfc_set_failmask(phba, ndlp,
+							  ELX_DEV_DISAPPEARED,
+							  ELX_SET_BITMASK);
+
+					blp = ndlp->nlp_listp_bind;
+					ndlp->nlp_listp_bind = 0;
+					if (blp) {
+						blp->nlp_Target =
+						    ndlp->nlp_Target;
+					}
+					/* Keep Target, pan and sid since ELX_DEV_DISAPPEARED
+					 * is a non-fatal error
+					 */
+					ndlp->nlp_flag &= ~NLP_SEED_MASK;
+				}
+				ELX_DISC_UNLOCK(phba, iflag);
+				if (blp) {
+					lpfc_nlp_bind(phba, blp);
+				}
+				return (ndlp);
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* no match found */
+	return ((LPFC_NODELIST_t *) 0);
+}
+
+/* Search for a nodelist entry on a specific list */
+LPFC_NODELIST_t *
+lpfc_findnode_did(elxHBA_t * phba, uint32_t order, uint32_t did)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	uint32_t data1;
+	unsigned long iflag;
+	LPFC_BINDLIST_t *blp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	blp = 0;
+	ELX_DISC_LOCK(phba, iflag);
+	if (order & NLP_SEARCH_UNMAPPED) {
+		ndlp = plhba->fc_nlpunmap_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+			if (lpfc_matchdid(phba, ndlp, did)) {
+
+				data1 = (((uint32_t) ndlp->nlp_state << 24) |
+					 ((uint32_t) ndlp->nlp_xri << 16) |
+					 ((uint32_t) ndlp->nle.nlp_type << 8) |
+					 ((uint32_t) ndlp->nle.nlp_rpi & 0xff));
+				/* FIND node DID unmapped */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0929,	/* ptr to msg structure */
+					       elx_mes0929,	/* ptr to msg */
+					       elx_msgBlk0929.msgPreambleStr,	/* begin varargs */
+					       (ulong) ndlp, ndlp->nlp_DID, ndlp->nlp_flag, data1);	/* end varargs */
+				if (order & NLP_SEARCH_DEQUE) {
+					ndlp->nlp_flag &=
+					    ~(NLP_UNMAPPED_LIST |
+					      NLP_TGT_NO_SCSIID);
+					plhba->fc_unmap_cnt--;
+					elx_deque(ndlp);
+				}
+				ELX_DISC_UNLOCK(phba, iflag);
+				return (ndlp);
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+
+	if (order & NLP_SEARCH_MAPPED) {
+		ndlp = plhba->fc_nlpmap_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+			if (lpfc_matchdid(phba, ndlp, did)) {
+
+				data1 = (((uint32_t) ndlp->nlp_state << 24) |
+					 ((uint32_t) ndlp->nlp_xri << 16) |
+					 ((uint32_t) ndlp->nle.nlp_type << 8) |
+					 ((uint32_t) ndlp->nle.nlp_rpi & 0xff));
+				/* FIND node DID mapped */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0930,	/* ptr to msg structure */
+					       elx_mes0930,	/* ptr to msg */
+					       elx_msgBlk0930.msgPreambleStr,	/* begin varargs */
+					       (ulong) ndlp, ndlp->nlp_DID, ndlp->nlp_flag, data1);	/* end varargs */
+				if (order & NLP_SEARCH_DEQUE) {
+					ndlp->nlp_flag &= ~NLP_MAPPED_LIST;
+					plhba->fc_map_cnt--;
+					elx_deque(ndlp);
+
+					/* Must call before binding is removed */
+					lpfc_set_failmask(phba, ndlp,
+							  ELX_DEV_DISAPPEARED,
+							  ELX_SET_BITMASK);
+
+					blp = ndlp->nlp_listp_bind;
+					ndlp->nlp_listp_bind = 0;
+					if (blp) {
+						blp->nlp_Target =
+						    ndlp->nlp_Target;
+					}
+					/* Keep Target, pan and sid since ELX_DEV_DISAPPEARED
+					 * is a non-fatal error
+					 */
+					ndlp->nlp_flag &= ~NLP_SEED_MASK;
+				}
+				ELX_DISC_UNLOCK(phba, iflag);
+				if (blp) {
+					lpfc_nlp_bind(phba, blp);
+				}
+				return (ndlp);
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+
+	if (order & NLP_SEARCH_PLOGI) {
+		ndlp = plhba->fc_plogi_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+			if (lpfc_matchdid(phba, ndlp, did)) {
+
+				data1 = (((uint32_t) ndlp->nlp_state << 24) |
+					 ((uint32_t) ndlp->nlp_xri << 16) |
+					 ((uint32_t) ndlp->nle.nlp_type << 8) |
+					 ((uint32_t) ndlp->nle.nlp_rpi & 0xff));
+				/* LOG change to PLOGI */
+				/* FIND node DID bind */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0908,	/* ptr to msg structure */
+					       elx_mes0908,	/* ptr to msg */
+					       elx_msgBlk0908.msgPreambleStr,	/* begin varargs */
+					       (ulong) ndlp, ndlp->nlp_DID, ndlp->nlp_flag, data1);	/* end varargs */
+				if (order & NLP_SEARCH_DEQUE) {
+					ndlp->nlp_flag &= ~NLP_PLOGI_LIST;
+					plhba->fc_plogi_cnt--;
+					elx_deque(ndlp);
+				}
+				ELX_DISC_UNLOCK(phba, iflag);
+				return (ndlp);
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+
+	if (order & NLP_SEARCH_ADISC) {
+		ndlp = plhba->fc_adisc_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+			if (lpfc_matchdid(phba, ndlp, did)) {
+
+				data1 = (((uint32_t) ndlp->nlp_state << 24) |
+					 ((uint32_t) ndlp->nlp_xri << 16) |
+					 ((uint32_t) ndlp->nle.nlp_type << 8) |
+					 ((uint32_t) ndlp->nle.nlp_rpi & 0xff));
+				/* LOG change to ADISC */
+				/* FIND node DID bind */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0931,	/* ptr to msg structure */
+					       elx_mes0931,	/* ptr to msg */
+					       elx_msgBlk0931.msgPreambleStr,	/* begin varargs */
+					       (ulong) ndlp, ndlp->nlp_DID, ndlp->nlp_flag, data1);	/* end varargs */
+				if (order & NLP_SEARCH_DEQUE) {
+					ndlp->nlp_flag &= ~NLP_ADISC_LIST;
+					plhba->fc_adisc_cnt--;
+					elx_deque(ndlp);
+				}
+				ELX_DISC_UNLOCK(phba, iflag);
+				return (ndlp);
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* FIND node did <did> NOT FOUND */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0932,	/* ptr to msg structure */
+		       elx_mes0932,	/* ptr to msg */
+		       elx_msgBlk0932.msgPreambleStr,	/* begin varargs */
+		       did, order);	/* end varargs */
+
+	/* no match found */
+	return ((LPFC_NODELIST_t *) 0);
+}
+
+/* Build a list of nodes to discover based on the loopmap */
+void
+lpfc_disc_list_loopmap(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+	elxCfgParam_t *clp;
+	int j;
+	uint32_t alpa, index;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	if (phba->hba_state <= ELX_LINK_DOWN) {
+		return;
+	}
+	if (plhba->fc_topology != TOPOLOGY_LOOP) {
+		return;
+	}
+
+	/* Check for loop map present or not */
+	if (plhba->alpa_map[0]) {
+		for (j = 1; j <= plhba->alpa_map[0]; j++) {
+			alpa = plhba->alpa_map[j];
+
+			if (((plhba->fc_myDID & 0xff) == alpa) || (alpa == 0)) {
+				continue;
+			}
+			if ((ndlp = lpfc_findnode_did(phba,
+						      (NLP_SEARCH_MAPPED |
+						       NLP_SEARCH_UNMAPPED |
+						       NLP_SEARCH_DEQUE),
+						      alpa))) {
+				/* Mark node for address authentication */
+				lpfc_disc_state_machine(phba, ndlp, 0,
+							NLP_EVT_DEVICE_ADD);
+				continue;
+			}
+			/* Skip if the node is already in the plogi / adisc list */
+			if ((ndlp = lpfc_findnode_did(phba,
+						      (NLP_SEARCH_PLOGI |
+						       NLP_SEARCH_ADISC),
+						      alpa))) {
+				continue;
+			}
+			/* Cannot find existing Fabric ndlp, so allocate a new one */
+			if ((ndlp =
+			     (LPFC_NODELIST_t *) elx_mem_get(phba,
+							     MEM_NLP)) == 0) {
+				continue;
+			}
+			memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+			ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+			ndlp->nlp_DID = alpa;
+			/* Mark node for address discovery */
+			lpfc_disc_state_machine(phba, ndlp, 0,
+						NLP_EVT_DEVICE_ADD);
+		}
+	} else {
+		/* No alpamap, so try all alpa's */
+		for (j = 0; j < FC_MAXLOOP; j++) {
+			if (clp[LPFC_CFG_SCAN_DOWN].a_current)
+				index = FC_MAXLOOP - j - 1;
+			else
+				index = j;
+			alpa = lpfcAlpaArray[index];
+			if ((plhba->fc_myDID & 0xff) == alpa) {
+				continue;
+			}
+
+			if ((ndlp = lpfc_findnode_did(phba,
+						      (NLP_SEARCH_MAPPED |
+						       NLP_SEARCH_UNMAPPED |
+						       NLP_SEARCH_DEQUE),
+						      alpa))) {
+				/* Mark node for address authentication */
+				lpfc_disc_state_machine(phba, ndlp, 0,
+							NLP_EVT_DEVICE_ADD);
+				continue;
+			}
+			/* Skip if the node is already in the plogi / adisc list */
+			if ((ndlp = lpfc_findnode_did(phba,
+						      (NLP_SEARCH_PLOGI |
+						       NLP_SEARCH_ADISC),
+						      alpa))) {
+				continue;
+			}
+			/* Cannot find existing ndlp, so allocate a new one */
+			if ((ndlp =
+			     (LPFC_NODELIST_t *) elx_mem_get(phba,
+							     MEM_NLP)) == 0) {
+				continue;
+			}
+			memset((void *)ndlp, 0, sizeof (LPFC_NODELIST_t));
+			ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+			ndlp->nlp_DID = alpa;
+			/* Mark node for address discovery */
+			lpfc_disc_state_machine(phba, ndlp, 0,
+						NLP_EVT_DEVICE_ADD);
+		}
+	}
+	return;
+}
+
+/* Start Link up / RSCN discovery on ADISC or PLOGI lists */
+void
+lpfc_disc_start(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	ELX_MBOXQ_t *mbox;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_NODELIST_t *new_ndlp;
+	uint32_t did_changed;
+	unsigned long iflag;
+	elxCfgParam_t *clp;
+	uint32_t clear_la_pending;
+
+	clp = &phba->config[0];
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	if (phba->hba_state <= ELX_LINK_DOWN) {
+		return;
+	}
+	if (phba->hba_state == ELX_CLEAR_LA)
+		clear_la_pending = 1;
+	else
+		clear_la_pending = 0;
+
+	if (phba->hba_state < ELX_HBA_READY) {
+		phba->hba_state = ELX_DISC_AUTH;
+	}
+	lpfc_set_disctmo(phba);
+
+	if (plhba->fc_prevDID == plhba->fc_myDID) {
+		did_changed = 0;
+	} else {
+		did_changed = 1;
+	}
+	plhba->fc_prevDID = plhba->fc_myDID;
+
+	/* Start Discovery state <hba_state> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0202,	/* ptr to msg structure */
+		       elx_mes0202,	/* ptr to msg */
+		       elx_msgBlk0202.msgPreambleStr,	/* begin varargs */
+		       phba->hba_state, plhba->fc_flag, plhba->fc_plogi_cnt, plhba->fc_adisc_cnt);	/* end varargs */
+
+	/* At this point, nothing should be on the mapped list, without
+	 * NODEV_TMO timer running on it, link up discovery only.
+	 */
+	ELX_DISC_LOCK(phba, iflag);
+	if (!(plhba->fc_flag & FC_RSCN_MODE)) {
+		ndlp = plhba->fc_nlpmap_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+			new_ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+
+			/* If nodev timer is not running, get rid of it */
+			if (!(ndlp->nlp_flag & NLP_NODEV_TMO)) {
+				lpfc_set_failmask(phba, ndlp,
+						  ELX_DEV_DISCONNECTED,
+						  ELX_SET_BITMASK);
+				ELX_DISC_UNLOCK(phba, iflag);
+				lpfc_freenode(phba, ndlp);
+				elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+				ELX_DISC_LOCK(phba, iflag);
+			}
+			ndlp = new_ndlp;
+		}
+
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+
+	/* First do ADISC for authenrication */
+	if (plhba->fc_adisc_cnt) {
+		ndlp = plhba->fc_adisc_start;
+		if (did_changed == 0) {
+			plhba->num_disc_nodes = 0;
+			/* go thru ADISC list and issue ELS ADISCs */
+			while (ndlp !=
+			       (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+				lpfc_issue_els_adisc(phba, ndlp, 0);
+				ndlp->nlp_flag |= NLP_DISC_NODE;
+				plhba->num_disc_nodes++;
+				if (plhba->num_disc_nodes >=
+				    clp[LPFC_CFG_DISC_THREADS].a_current) {
+					if (plhba->fc_adisc_cnt >
+					    plhba->num_disc_nodes)
+						plhba->fc_flag |= FC_NLP_MORE;
+					break;
+				}
+				ndlp =
+				    (LPFC_NODELIST_t *) ndlp->nle.
+				    nlp_listp_next;
+			}
+			return;
+		}
+		/* Move these to PLOGI list instead */
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+			new_ndlp = ndlp;
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+			lpfc_nlp_plogi(phba, new_ndlp);
+		}
+	}
+
+	if ((phba->hba_state < ELX_HBA_READY) && (!clear_la_pending)) {
+		/* If we get here, there is nothing to ADISC */
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			phba->hba_state = ELX_CLEAR_LA;
+			lpfc_clear_la(phba, mbox);
+			mbox->mbox_cmpl = lpfc_mbx_cmpl_clear_la;
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+				lpfc_disc_flush_list(phba);
+				psli->ring[(psli->ip_ring)].flag &=
+				    ~ELX_STOP_IOCB_EVENT;
+				psli->ring[(psli->fcp_ring)].flag &=
+				    ~ELX_STOP_IOCB_EVENT;
+				psli->ring[(psli->next_ring)].flag &=
+				    ~ELX_STOP_IOCB_EVENT;
+				phba->hba_state = ELX_HBA_READY;
+			}
+		}
+	} else {
+		/* go thru PLOGI list and issue ELS PLOGIs */
+		plhba->num_disc_nodes = 0;
+		if (plhba->fc_plogi_cnt) {
+			ndlp = plhba->fc_plogi_start;
+			while (ndlp !=
+			       (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+				if (ndlp->nlp_state == NLP_STE_UNUSED_NODE) {
+					ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+					lpfc_issue_els_plogi(phba, ndlp, 0);
+					ndlp->nlp_flag |= NLP_DISC_NODE;
+					plhba->num_disc_nodes++;
+					if (plhba->num_disc_nodes >=
+					    clp[LPFC_CFG_DISC_THREADS].
+					    a_current) {
+						if (plhba->fc_plogi_cnt >
+						    plhba->num_disc_nodes)
+							plhba->fc_flag |=
+							    FC_NLP_MORE;
+						break;
+					}
+				}
+				ndlp =
+				    (LPFC_NODELIST_t *) ndlp->nle.
+				    nlp_listp_next;
+			}
+		} else {
+			if (plhba->fc_flag & FC_RSCN_MODE) {
+				/* Check to see if more RSCNs came in while we were
+				 * processing this one.
+				 */
+				if ((plhba->fc_rscn_id_cnt == 0) &&
+				    (!(plhba->fc_flag & FC_RSCN_DISCOVERY))) {
+					lpfc_els_flush_rscn(phba);
+				} else {
+					lpfc_els_handle_rscn(phba);
+				}
+			}
+		}
+	}
+	return;
+}
+
+void
+lpfc_disc_flush_list(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+	uint8_t *ptr;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ELX_DISC_LOCK(phba, iflag);
+	if (plhba->fc_plogi_cnt) {
+		ndlp = plhba->fc_plogi_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+			ptr = (uint8_t *) ndlp;
+			lpfc_set_failmask(phba, ndlp, ELX_DEV_DISCONNECTED,
+					  ELX_SET_BITMASK);
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+			lpfc_free_tx(phba, (LPFC_NODELIST_t *) ptr);
+			lpfc_freenode(phba, (LPFC_NODELIST_t *) ptr);
+			elx_mem_put(phba, MEM_NLP, ptr);
+		}
+		plhba->fc_plogi_start =
+		    (LPFC_NODELIST_t *) & plhba->fc_plogi_start;
+		plhba->fc_plogi_end =
+		    (LPFC_NODELIST_t *) & plhba->fc_plogi_start;
+	}
+	if (plhba->fc_adisc_cnt) {
+		ndlp = plhba->fc_adisc_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+			ptr = (uint8_t *) ndlp;
+			lpfc_set_failmask(phba, ndlp, ELX_DEV_DISCONNECTED,
+					  ELX_SET_BITMASK);
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+			lpfc_free_tx(phba, (LPFC_NODELIST_t *) ptr);
+			lpfc_freenode(phba, (LPFC_NODELIST_t *) ptr);
+			elx_mem_put(phba, MEM_NLP, ptr);
+		}
+		plhba->fc_adisc_start =
+		    (LPFC_NODELIST_t *) & plhba->fc_adisc_start;
+		plhba->fc_adisc_end =
+		    (LPFC_NODELIST_t *) & plhba->fc_adisc_start;
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+	return;
+}
+
+/*****************************************************************************/
+/*
+ * NAME:     lpfc_disc_timeout
+ *
+ * FUNCTION: Fibre Channel driver discovery timeout routine.
+ *
+ * EXECUTION ENVIRONMENT: interrupt only
+ *
+ * CALLED FROM:
+ *      Timer function
+ *
+ * RETURNS:  
+ *      none
+ */
+/*****************************************************************************/
+void
+lpfc_disc_timeout(elxHBA_t * phba, void *l1, void *l2)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	ELX_MBOXQ_t *mbox;
+	elxCfgParam_t *clp;
+
+	if (!phba) {
+		return;
+	}
+	clp = &phba->config[0];
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	plhba->fc_disctmo = 0;	/* timer expired */
+
+	/* hba_state is identically ELX_LOCAL_CFG_LINK while waiting for FAN */
+	if (phba->hba_state == ELX_LOCAL_CFG_LINK) {
+		/* FAN timeout */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0221,	/* ptr to msg structure */
+			       elx_mes0221,	/* ptr to msg */
+			       elx_msgBlk0221.msgPreambleStr);	/* begin & end varargs */
+
+		/* Forget about FAN, Start discovery by sending a FLOGI
+		 * hba_state is identically ELX_FLOGI while waiting for FLOGI cmpl
+		 */
+		phba->hba_state = ELX_FLOGI;
+		lpfc_set_disctmo(phba);
+		lpfc_initial_flogi(phba);
+		goto out;
+	}
+
+	/* hba_state is identically ELX_FLOGI while waiting for FLOGI cmpl */
+	if (phba->hba_state == ELX_FLOGI) {
+		/* Initial FLOGI timeout */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0222,	/* ptr to msg structure */
+			       elx_mes0222,	/* ptr to msg */
+			       elx_msgBlk0222.msgPreambleStr);	/* begin & end varargs */
+
+		/* Assume no Fabric and go on with discovery.
+		 * Check for outstanding ELS FLOGI to abort.
+		 */
+
+		/* FLOGI failed, so just use loop map to make discovery list */
+		lpfc_disc_list_loopmap(phba);
+
+		/* Start discovery */
+		lpfc_disc_start(phba);
+		goto out;
+	}
+
+	/* hba_state is identically ELX_FABRIC_CFG_LINK while waiting for NameServer login */
+	if (phba->hba_state == ELX_FABRIC_CFG_LINK) {
+		/* Timeout while waiting for NameServer login */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0223,	/* ptr to msg structure */
+			       elx_mes0223,	/* ptr to msg */
+			       elx_msgBlk0223.msgPreambleStr);	/* begin & end varargs */
+
+		/* Next look for NameServer ndlp */
+		if ((ndlp =
+		     lpfc_findnode_did(phba,
+				       (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+				       NameServer_DID))) {
+			lpfc_freenode(phba, ndlp);
+			elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		}
+		/* Start discovery */
+		lpfc_disc_start(phba);
+		goto out;
+	}
+
+	/* Check for wait for NameServer Rsp timeout */
+	if (phba->hba_state == ELX_NS_QRY) {
+		/* NameServer Query timeout */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0224,	/* ptr to msg structure */
+			       elx_mes0224,	/* ptr to msg */
+			       elx_msgBlk0224.msgPreambleStr,	/* begin varargs */
+			       plhba->fc_ns_retry, LPFC_MAX_NS_RETRY);	/* end varargs */
+
+		if ((ndlp =
+		     lpfc_findnode_did(phba, NLP_SEARCH_UNMAPPED,
+				       NameServer_DID))) {
+			if (plhba->fc_ns_retry < LPFC_MAX_NS_RETRY) {
+				/* Try it one more time */
+				if (lpfc_ns_cmd(phba, ndlp, SLI_CTNS_GID_FT) ==
+				    0) {
+					goto out;
+				}
+			}
+			plhba->fc_ns_retry = 0;
+		}
+
+		/* Nothing to authenticate, so CLEAR_LA right now */
+		if (phba->hba_state != ELX_CLEAR_LA) {
+			if ((mbox =
+			     (ELX_MBOXQ_t *) elx_mem_get(phba,
+							 MEM_MBOX | MEM_PRI))) {
+				phba->hba_state = ELX_CLEAR_LA;
+				lpfc_clear_la(phba, mbox);
+				mbox->mbox_cmpl = lpfc_mbx_cmpl_clear_la;
+				if (elx_sli_issue_mbox
+				    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+				    == MBX_NOT_FINISHED) {
+					elx_mem_put(phba, MEM_MBOX,
+						    (uint8_t *) mbox);
+					goto clrlaerr;
+				}
+			} else {
+				/* Device Discovery completion error */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0226,	/* ptr to msg structure */
+					       elx_mes0226,	/* ptr to msg */
+					       elx_msgBlk0226.msgPreambleStr);	/* begin & end varargs */
+				phba->hba_state = ELX_HBA_ERROR;
+			}
+		}
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			/* Setup and issue mailbox INITIALIZE LINK command */
+			lpfc_linkdown(phba);
+			lpfc_init_link(phba, mbox,
+				       clp[LPFC_CFG_TOPOLOGY].a_current,
+				       clp[LPFC_CFG_LINK_SPEED].a_current);
+			mbox->mb.un.varInitLnk.lipsr_AL_PA = 0;
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+			}
+		}
+		goto out;
+	}
+
+	if (phba->hba_state == ELX_DISC_AUTH) {
+		/* Node Authentication timeout */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0227,	/* ptr to msg structure */
+			       elx_mes0227,	/* ptr to msg */
+			       elx_msgBlk0227.msgPreambleStr);	/* begin & end varargs */
+		lpfc_disc_flush_list(phba);
+		if (phba->hba_state != ELX_CLEAR_LA) {
+			if ((mbox =
+			     (ELX_MBOXQ_t *) elx_mem_get(phba,
+							 MEM_MBOX | MEM_PRI))) {
+				phba->hba_state = ELX_CLEAR_LA;
+				lpfc_clear_la(phba, mbox);
+				mbox->mbox_cmpl = lpfc_mbx_cmpl_clear_la;
+				if (elx_sli_issue_mbox
+				    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+				    == MBX_NOT_FINISHED) {
+					elx_mem_put(phba, MEM_MBOX,
+						    (uint8_t *) mbox);
+					goto clrlaerr;
+				}
+			}
+		}
+		goto out;
+	}
+
+	if (phba->hba_state == ELX_CLEAR_LA) {
+		/* CLEAR LA timeout */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0228,	/* ptr to msg structure */
+			       elx_mes0228,	/* ptr to msg */
+			       elx_msgBlk0228.msgPreambleStr);	/* begin & end varargs */
+	      clrlaerr:
+		lpfc_disc_flush_list(phba);
+		psli->ring[(psli->ip_ring)].flag &= ~ELX_STOP_IOCB_EVENT;
+		psli->ring[(psli->fcp_ring)].flag &= ~ELX_STOP_IOCB_EVENT;
+		psli->ring[(psli->next_ring)].flag &= ~ELX_STOP_IOCB_EVENT;
+		phba->hba_state = ELX_HBA_READY;
+		goto out;
+	}
+
+	if ((phba->hba_state == ELX_HBA_READY) &&
+	    (plhba->fc_flag & FC_RSCN_MODE)) {
+		/* RSCN timeout */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0231,	/* ptr to msg structure */
+			       elx_mes0231,	/* ptr to msg */
+			       elx_msgBlk0231.msgPreambleStr,	/* begin varargs */
+			       plhba->fc_ns_retry, LPFC_MAX_NS_RETRY);	/* end varargs */
+
+		/* Cleanup any outstanding ELS commands */
+		lpfc_els_flush_cmd(phba);
+
+		lpfc_els_flush_rscn(phba);
+		lpfc_disc_flush_list(phba);
+		goto out;
+	}
+
+      out:
+	return;
+}
+
+/*****************************************************************************/
+/*
+ * NAME:     lpfc_linkdown_timeout
+ *
+ * FUNCTION: Fibre Channel driver linkdown timeout routine.
+ *
+ * EXECUTION ENVIRONMENT: interrupt only
+ *
+ * CALLED FROM:
+ *      Timer function
+ *
+ * RETURNS:  
+ *      none
+ */
+/*****************************************************************************/
+void
+lpfc_linkdown_timeout(elxHBA_t * phba, void *l1, void *l2)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_NODELIST_t *new_ndlp;
+	ELXSCSITARGET_t *targetp;
+	elxCfgParam_t *clp;
+	uint32_t tgt;
+
+	if (!phba) {
+		return;
+	}
+
+	clp = &phba->config[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* Link Down timeout */
+	elx_printf_log(phba->brd_no, &elx_msgBlk1306,	/* ptr to msg structure */
+		       elx_mes1306,	/* ptr to msg */
+		       elx_msgBlk1306.msgPreambleStr,	/* begin varargs */
+		       phba->hba_state, plhba->fc_flag, plhba->fc_ns_retry);	/* end varargs */
+
+	plhba->fc_linkdown = 0;	/* timer expired */
+	plhba->fc_flag |= (FC_LD_TIMER | FC_LD_TIMEOUT);	/* indicate timeout */
+	phba->hba_flag &= ~FC_LFR_ACTIVE;
+
+	/* Issue a DEVICE REMOVE event to all nodes */
+	ndlp = plhba->fc_plogi_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+		ndlp = plhba->fc_adisc_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+		ndlp = plhba->fc_nlpunmap_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+		ndlp = plhba->fc_nlpmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		new_ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+
+		/* Fabric nodes are not handled thru state machine for link down tmo */
+		if (!(ndlp->nle.nlp_type & NLP_FABRIC)) {
+			lpfc_disc_state_machine(phba, ndlp, (void *)0,
+						NLP_EVT_DEVICE_RM);
+		}
+
+		ndlp = new_ndlp;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+			ndlp = plhba->fc_adisc_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+			ndlp = plhba->fc_nlpunmap_start;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+			ndlp = plhba->fc_nlpmap_start;
+	}
+	if ((clp[ELX_CFG_NODEV_TMO].a_current == 0) &&
+	    (clp[ELX_CFG_HOLDIO].a_current == 0)) {
+
+		for (tgt = 0; tgt < MAX_FCP_TARGET; tgt++) {
+			targetp = plhba->device_queue_hash[tgt];
+			if ((targetp) && (targetp->targetFlags & FC_NPR_ACTIVE)) {
+				targetp->targetFlags &= ~FC_NPR_ACTIVE;
+				elx_sched_flush_target(phba, targetp,
+						       IOSTAT_DRIVER_REJECT,
+						       IOERR_SLI_ABORTED);
+				if (targetp->tmofunc) {
+					elx_clk_can(phba, targetp->tmofunc);
+					targetp->tmofunc = 0;
+				}
+			}
+		}
+
+		/* Just to be sure */
+		elx_sched_flush_hba(phba, IOSTAT_DRIVER_REJECT,
+				    IOERR_SLI_ABORTED);
+	}
+	return;
+}
+
+void
+lpfc_nodev_timeout(elxHBA_t * phba, void *l1, void *l2)
+{
+	LPFC_NODELIST_t *ndlp;
+	ELXSCSITARGET_t *targetp;
+
+	ndlp = (LPFC_NODELIST_t *) l1;
+
+	/* Nodev timeout on NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0203,	/* ptr to msg structure */
+		       elx_mes0203,	/* ptr to msg */
+		       elx_msgBlk0203.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+	ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+	targetp = ndlp->nlp_Target;
+	if (targetp) {
+		targetp->targetFlags &= ~FC_NPR_ACTIVE;
+		elx_sched_flush_target(phba, targetp, IOSTAT_DRIVER_REJECT,
+				       IOERR_SLI_ABORTED);
+		if (targetp->tmofunc) {
+			elx_clk_can(phba, targetp->tmofunc);
+			targetp->tmofunc = 0;
+		}
+	}
+	ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+	ndlp->nlp_tmofunc = 0;
+	lpfc_disc_state_machine(phba, ndlp, (void *)0, NLP_EVT_DEVICE_RM);
+	return;
+}
+
+ELXSCSITARGET_t *
+lpfc_find_target(elxHBA_t * phba, uint32_t tgt)
+{
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	targetp = plhba->device_queue_hash[tgt];
+	return (targetp);
+}
+
+/*****************************************************************************/
+/*
+ * NAME:     lpfc_find_lun
+ *
+ * FUNCTION: Fibre Channel bus/target/LUN to ELXSCSILUN_t lookup
+ *
+ * EXECUTION ENVIRONMENT: 
+ *
+ * RETURNS:  
+ *      ptr to desired ELXSCSILUN_t
+ */
+/*****************************************************************************/
+ELXSCSILUN_t *
+lpfc_find_lun(elxHBA_t * phba, uint32_t tgt, uint64_t lun, int create_flag)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *nlp;
+	LPFC_BINDLIST_t *blp;
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp;
+	ELXSCSILUN_t *lastlunp;
+	elxCfgParam_t *clp;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+	targetp = plhba->device_queue_hash[tgt];
+
+	/* First see if the SCSI ID has an allocated ELXSCSITARGET_t */
+	if (targetp) {
+		lunp = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+		while (lunp) {
+			/* Finally see if the LUN ID has an allocated ELXSCSILUN_t */
+			if (lunp->lun_id == lun) {
+				return (lunp);
+			}
+			lunp = lunp->pnextLun;
+		}
+		if (create_flag) {
+			if (lun < targetp->max_lun) {
+				buf_info = &bufinfo;
+				goto lun_create;
+			}
+		}
+	} else {
+		if (create_flag) {
+			nlp = lpfc_findnode_scsiid(phba, tgt);
+			if (nlp == 0) {
+				return 0;
+			}
+
+			buf_info = &bufinfo;
+			memset(buf_info, 0, sizeof (MBUF_INFO_t));
+			buf_info->size = sizeof (ELXSCSITARGET_t);
+			buf_info->flags = ELX_MBUF_VIRT;
+			buf_info->align = sizeof (void *);
+			buf_info->dma_handle = 0;
+
+			elx_malloc(phba, buf_info);
+			if (buf_info->virt == 0) {
+				return (0);
+			}
+
+			targetp = (ELXSCSITARGET_t *) buf_info->virt;
+			memset(targetp, 0, sizeof (ELXSCSITARGET_t));
+			targetp->scsi_id = tgt;
+			if ((targetp->max_lun =
+			     clp[ELX_CFG_MAX_LUN].a_current) == 0) {
+				targetp->max_lun = 255;
+			}
+			targetp->pHba = phba;
+			plhba->device_queue_hash[tgt] = targetp;
+			targetp->pcontext = (void *)nlp;
+			if (nlp) {
+
+				/* Create SCSI Target <tgt> */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0204,	/* ptr to msg structure */
+					       elx_mes0204,	/* ptr to msg */
+					       elx_msgBlk0204.msgPreambleStr,	/* begin varargs */
+					       tgt);	/* end varargs */
+
+				nlp->nlp_Target = targetp;
+				if ((blp = nlp->nlp_listp_bind)) {
+					blp->nlp_Target = targetp;
+				}
+			}
+			if (clp[ELX_CFG_DFT_TGT_Q_DEPTH].a_current) {
+				elx_sched_target_init(targetp,
+						      (uint16_t)
+						      clp
+						      [ELX_CFG_DFT_TGT_Q_DEPTH].
+						      a_current);
+			} else {
+				elx_sched_target_init(targetp,
+						      (uint16_t)
+						      clp
+						      [ELX_CFG_DFT_HBA_Q_DEPTH].
+						      a_current);
+			}
+		      lun_create:
+			memset(buf_info, 0, sizeof (MBUF_INFO_t));
+			buf_info->size = sizeof (ELXSCSILUN_t);
+			buf_info->flags = ELX_MBUF_VIRT;
+			buf_info->align = sizeof (void *);
+			buf_info->dma_handle = 0;
+
+			elx_malloc(phba, buf_info);
+			if (buf_info->virt == 0) {
+				return (0);
+			}
+
+			/* Create SCSI LUN <lun> on Target <tgt> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0205,	/* ptr to msg structure */
+				       elx_mes0205,	/* ptr to msg */
+				       elx_msgBlk0205.msgPreambleStr,	/* begin varargs */
+				       (uint32_t) lun, tgt);	/* end varargs */
+
+			lunp = (ELXSCSILUN_t *) buf_info->virt;
+			memset(lunp, 0, sizeof (ELXSCSILUN_t));
+			lunp->lun_id = lun;
+			lunp->qfull_retries = lpfc_qfull_retry_count;	/* For Schedular to retry */
+			lunp->pTarget = targetp;
+			lunp->pHBA = phba;
+
+			lastlunp = (ELXSCSILUN_t *) targetp->lunlist.q_last;
+			if (lastlunp) {
+				lastlunp->pnextLun = lunp;
+			} else {
+				targetp->lunlist.q_first = (ELX_SLINK_t *) lunp;
+			}
+			lunp->pnextLun = 0;
+			targetp->lunlist.q_last = (ELX_SLINK_t *) lunp;
+			targetp->lunlist.q_cnt++;
+			elx_sched_lun_init(lunp,
+					   (uint16_t)
+					   clp[ELX_CFG_DFT_LUN_Q_DEPTH].
+					   a_current);
+			return (lunp);
+		}
+	}
+	return (0);
+}
+
+void
+lpfc_disc_cmpl_rptlun(elxHBA_t * phba,
+		      ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	DMABUF_t *mp;
+	ELX_SCSI_BUF_t *elx_cmd;
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp;
+	LPFC_NODELIST_t *ndlp;
+	elxCfgParam_t *clp;
+	FCP_RSP *fcprsp;
+	IOCB_t *iocb;
+	uint8_t *datap;
+	uint32_t *datap32;
+	uint32_t rptLunLen;
+	uint32_t max, lun, i;
+
+	elx_cmd = cmdiocb->context1;
+	mp = cmdiocb->context2;
+	targetp = elx_cmd->pLun->pTarget;
+	ndlp = (LPFC_NODELIST_t *) targetp->pcontext;
+	iocb = &elx_cmd->cur_iocbq.iocb;
+	fcprsp = elx_cmd->fcp_rsp;
+	clp = &phba->config[0];
+
+	if (ndlp == 0) {
+		targetp->rptLunState = REPORT_LUN_ERRORED;
+		targetp->targetFlags &= ~(FC_NPR_ACTIVE | FC_RETRY_RPTLUN);
+		if (targetp->tmofunc) {
+			elx_clk_can(phba, targetp->tmofunc);
+			targetp->tmofunc = 0;
+		}
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		elx_free_scsi_buf(elx_cmd);
+		return;
+	}
+
+	/* Report Lun completes on NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0206,	/* ptr to msg structure */
+		       elx_mes0206,	/* ptr to msg */
+		       elx_msgBlk0206.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, iocb->ulpStatus, fcprsp->rspStatus2, fcprsp->rspStatus3, ndlp->nle.nlp_failMask);	/* end varargs */
+
+	if (targetp) {
+
+		if (clp[ELX_CFG_MAX_LUN].a_current) {
+			targetp->max_lun = clp[ELX_CFG_MAX_LUN].a_current;
+		} else {
+			targetp->max_lun = 255;
+		}
+
+		if (((iocb->ulpStatus == IOSTAT_SUCCESS) &&
+		     (fcprsp->rspStatus3 == SCSI_STAT_GOOD)) ||
+		    ((iocb->ulpStatus == IOSTAT_FCP_RSP_ERROR) &&
+		     (fcprsp->rspStatus2 & RESID_UNDER) &&
+		     (fcprsp->rspStatus3 == SCSI_STAT_GOOD))) {
+
+			datap = (uint8_t *) mp->virt;
+			/*
+			 * if Lun0 uses VSA, we assume others use too.
+			 */
+			if ((datap[8] & 0xc0) == 0x40) {
+				targetp->addrMode = VOLUME_SET_ADDRESSING;
+			}
+
+			i = 0;
+			datap32 = (uint32_t *) mp->virt;
+			rptLunLen = *datap32;
+			rptLunLen = SWAP_DATA(rptLunLen);
+			/* search for the max lun */
+			max = 0;
+			for (i = 0; ((i < rptLunLen) && (i < 8 * 128)); i += 8) {
+				datap32 += 2;
+				lun = (((*datap32) >> FC_LUN_SHIFT) & 0xff);
+				if (lun > max)
+					max = lun;
+			}
+			if (i) {
+				targetp->max_lun = max + 1;
+			}
+
+			targetp->rptLunState = REPORT_LUN_COMPLETE;
+			ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+			targetp->targetFlags &=
+			    ~(FC_NPR_ACTIVE | FC_RETRY_RPTLUN);
+			if (targetp->tmofunc) {
+				elx_clk_can(phba, targetp->tmofunc);
+				targetp->tmofunc = 0;
+			}
+
+			/* The lpfc_issue_rptlun function does not re-use the buffer pointed to
+			 * by targetp->RptLunData.  It always allocates
+			 * a new one and frees the old buffer. 
+			 */
+			if (targetp->RptLunData) {
+				elx_mem_put(phba, MEM_BUF,
+					    (uint8_t *) targetp->RptLunData);
+			}
+			targetp->RptLunData = mp;
+
+			lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN,
+					  ELX_CLR_BITMASK);
+			lunp = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+			while (lunp) {
+				lunp->pnode = (ELX_NODELIST_t *) ndlp;
+				lunp = lunp->pnextLun;
+			}
+		} else {
+			/* Retry RPTLUN */
+			if (ndlp
+			    && (!(ndlp->nle.nlp_failMask & ELX_DEV_FATAL_ERROR))
+			    && (!(targetp->targetFlags & FC_RETRY_RPTLUN))) {
+				targetp->targetFlags |= FC_RETRY_RPTLUN;
+				targetp->rptlunfunc =
+				    elx_clk_set(phba, 1, lpfc_disc_retry_rptlun,
+						(void *)targetp, (void *)0);
+			} else {
+				targetp->rptLunState = REPORT_LUN_ERRORED;
+
+				/* If ReportLun failed, then we allow only lun 0 on this target.
+				 * This way, the driver won't create Processor devices when
+				 * JBOD failed ReportLun and lun-skip is turned ON.
+				 */
+				targetp->max_lun = 1;
+
+				ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+				targetp->targetFlags &=
+				    ~(FC_NPR_ACTIVE | FC_RETRY_RPTLUN);
+				if (targetp->tmofunc) {
+					elx_clk_can(phba, targetp->tmofunc);
+					targetp->tmofunc = 0;
+				}
+				lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN,
+						  ELX_CLR_BITMASK);
+				lunp =
+				    (ELXSCSILUN_t *) targetp->lunlist.q_first;
+				while (lunp) {
+					lunp->pnode = (ELX_NODELIST_t *) ndlp;
+					lunp = lunp->pnextLun;
+				}
+			}
+		}
+	}
+
+	/* We cannot free RptLunData buffer if we already save it in 
+	 * the target structure */
+	if (mp != targetp->RptLunData) {
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	}
+	elx_free_scsi_buf(elx_cmd);
+	return;
+}
+
+/*****************************************************************************/
+/*
+ * NAME:     lpfc_disc_retry_rptlun
+ *
+ * FUNCTION: Try to send report lun again.  Note that NODELIST could have
+ *           changed from the last failed repotlun cmd.  That's why we have
+ *           to get the latest ndlp before calling lpfc_disc_issue_rptlun. 
+ *
+ * EXECUTION ENVIRONMENT: 
+ *           During device discovery
+ *
+ */
+/*****************************************************************************/
+void
+lpfc_disc_retry_rptlun(elxHBA_t * phba, void *l1, void *l2)
+{
+	ELXSCSITARGET_t *targetp;
+	LPFC_NODELIST_t *ndlp;
+
+	targetp = (ELXSCSITARGET_t *) l1;
+	ndlp = (LPFC_NODELIST_t *) targetp->pcontext;
+	lpfc_disc_issue_rptlun(phba, ndlp);
+}
+
+/*****************************************************************************/
+/*
+ * NAME:     lpfc_disc_issue_rptlun
+ *
+ * FUNCTION: Issue a RPTLUN SCSI command to a newly mapped FCP device
+ *           to determine LUN addressing mode
+ *
+ * EXECUTION ENVIRONMENT: 
+ *           During device discovery
+ *
+ */
+/*****************************************************************************/
+int
+lpfc_disc_issue_rptlun(elxHBA_t * phba, LPFC_NODELIST_t * nlp)
+{
+	ELX_SLI_t *psli;
+	ELX_SCSI_BUF_t *elx_cmd;
+	ELX_IOCBQ_t *piocbq;
+
+	/* Issue Report LUN on NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0207,	/* ptr to msg structure */
+		       elx_mes0207,	/* ptr to msg */
+		       elx_msgBlk0207.msgPreambleStr,	/* begin varargs */
+		       nlp->nlp_DID, nlp->nle.nlp_failMask, nlp->nlp_state, nlp->nle.nlp_rpi);	/* end varargs */
+
+	psli = &phba->sli;
+	elx_cmd = lpfc_build_scsi_cmd(phba, nlp, FCP_SCSI_REPORT_LUNS, 0);
+	if (elx_cmd) {
+		piocbq = &elx_cmd->cur_iocbq;
+		piocbq->iocb_cmpl = lpfc_disc_cmpl_rptlun;
+
+		if (elx_sli_issue_iocb(phba, &psli->ring[psli->fcp_ring],
+				       piocbq,
+				       SLI_IOCB_USE_TXQ) == IOCB_ERROR) {
+			elx_mem_put(phba, MEM_BUF,
+				    (uint8_t *) piocbq->context2);
+			elx_free_scsi_buf(elx_cmd);
+			return (1);
+		}
+		if (elx_cmd->pLun->pTarget) {
+			elx_cmd->pLun->pTarget->rptLunState =
+			    REPORT_LUN_ONGOING;
+		}
+	}
+	return (0);
+}
+
+/*
+ *   lpfc_set_failmask
+ *   Set, or clear, failMask bits in LPFC_NODELIST_t
+ */
+void
+lpfc_set_failmask(elxHBA_t * phba,
+		  LPFC_NODELIST_t * ndlp, uint32_t bitmask, uint32_t flag)
+{
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp;
+	uint32_t oldmask;
+	uint32_t changed;
+
+	/* Failmask change on NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0208,	/* ptr to msg structure */
+		       elx_mes0208,	/* ptr to msg */
+		       elx_msgBlk0208.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, ndlp->nle.nlp_failMask, bitmask, flag);	/* end varargs */
+
+	targetp = ndlp->nlp_Target;
+	if (flag == ELX_SET_BITMASK) {
+		oldmask = ndlp->nle.nlp_failMask;
+		/* Set failMask event */
+		ndlp->nle.nlp_failMask |= bitmask;
+		if (oldmask != ndlp->nle.nlp_failMask) {
+			changed = 1;
+		} else {
+			changed = 0;
+		}
+
+		if (oldmask == 0) {
+			/* Pause the scheduler if this is a FCP node */
+			if (targetp) {
+				elx_sched_pause_target(targetp);
+			}
+		}
+	} else {
+		/* Clear failMask event */
+		ndlp->nle.nlp_failMask &= ~bitmask;
+		changed = 1;
+	}
+
+	/* If mask has changed, there may be more to do */
+	if (changed) {
+		/* If the map was / is a mapped target, probagate change to 
+		 * all ELXSCSILUN_t's
+		 */
+		if (targetp) {
+			lunp = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+			while (lunp) {
+				if (flag == ELX_SET_BITMASK) {
+					/* Set failMask event */
+					lunp->failMask |= bitmask;
+				} else {
+					/* Clear failMask event */
+					lunp->failMask &= ~bitmask;
+				}
+				lunp = lunp->pnextLun;
+			}
+
+			/* If the failMask changes to 0, resume the scheduler */
+			if (ndlp->nle.nlp_failMask == 0) {
+				elx_sched_continue_target(targetp);
+			}
+		}
+	}
+
+	/* Since its fatal, now we can clear pan and sid */
+	if ((flag == ELX_SET_BITMASK) && (bitmask & ELX_DEV_FATAL_ERROR)) {
+		ndlp->nlp_pan = 0;
+		ndlp->nlp_sid = 0;
+	}
+	return;
+}
+
+/*
+ *  Ignore completion for all IOCBs on tx and txcmpl queue for ELS 
+ *  ring the match the sppecified nodelist.
+ */
+void
+lpfc_free_tx(elxHBA_t * phba, LPFC_NODELIST_t * ndlp)
+{
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *iocb, *next_iocb;
+	IOCB_t *icmd;
+	ELX_SLI_RING_t *pring;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Error matching iocb on txq or txcmplq 
+	 * First check the txq.
+	 */
+	next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		if (iocb->context1 != ndlp) {
+			continue;
+		}
+		icmd = &iocb->iocb;
+		if ((icmd->ulpCommand == CMD_ELS_REQUEST64_CR) ||
+		    (icmd->ulpCommand == CMD_XMIT_ELS_RSP64_CX)) {
+
+			elx_deque(iocb);
+			pring->txq.q_cnt--;
+			lpfc_els_free_iocb(phba, iocb);
+		}
+	}
+
+	/* Next check the txcmplq */
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		iocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		if (iocb->context1 != ndlp) {
+			continue;
+		}
+		icmd = &iocb->iocb;
+		if ((icmd->ulpCommand == CMD_ELS_REQUEST64_CR) ||
+		    (icmd->ulpCommand == CMD_XMIT_ELS_RSP64_CX)) {
+
+			iocb->iocb_cmpl = 0;
+			/* context2  = cmd,  context2->next = rsp, context3 = bpl */
+			if (iocb->context2) {
+				/* Free the response IOCB before handling the command. */
+				if (((DMABUF_t *) (iocb->context2))->next) {
+
+					/* Delay before releasing rsp buffer to give UNREG mbox a 
+					 * chance to take effect.
+					 */
+					elx_clk_set(phba, 1,
+						    lpfc_put_buf,
+						    (void
+						     *)(((DMABUF_t *) (iocb->
+								       context2))->
+							next), (void *)0);
+				}
+				elx_mem_put(phba, MEM_BUF,
+					    (uint8_t *) (iocb->context2));
+			}
+
+			if (iocb->context3) {
+				elx_mem_put(phba, MEM_BPL,
+					    (uint8_t *) (iocb->context3));
+			}
+		}
+	}
+	ELX_SLI_UNLOCK(phba, iflag);
+
+	return;
+}
+
+/*****************************************************************************/
+/*
+ * NAME:     lpfc_put_buf
+ *
+ * FUNCTION: Fibre Channel driver delayed buffer release routine.
+ *
+ * EXECUTION ENVIRONMENT: interrupt only
+ *
+ * CALLED FROM:
+ *      Timer function
+ *
+ * RETURNS:  
+ *      none
+ */
+/*****************************************************************************/
+void
+lpfc_put_buf(elxHBA_t * phba, void *l1, void *l2)
+{
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) l1);
+	return;
+}
+
+/*
+ * This routine handles processing a NameServer REG_LOGIN mailbox
+ * command upon completion. It is setup in the ELX_MBOXQ
+ * as the completion routine when the command is
+ * handed off to the SLI layer.
+ */
+void
+lpfc_mbx_cmpl_fdmi_reg_login(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+	DMABUF_t *mp;
+	LPFC_NODELIST_t *ndlp;
+	elxCfgParam_t *clp;
+
+	clp = &phba->config[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	mb = &pmb->mb;
+
+	ndlp = (LPFC_NODELIST_t *) pmb->context2;
+	mp = (DMABUF_t *) (pmb->context1);
+
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORCPU);
+	pmb->context1 = 0;
+
+	if (ndlp->nle.nlp_rpi != 0)
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+	ndlp->nle.nlp_rpi = mb->un.varWords[0];
+	lpfc_addnode_rpi(phba, ndlp, ndlp->nle.nlp_rpi);
+	ndlp->nle.nlp_type |= NLP_FABRIC;
+	lpfc_nlp_unmapped(phba, ndlp);
+	ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+
+	/* Start issuing Fabric-Device Management Interface (FDMI)
+	 * command to 0xfffffa (FDMI well known port)
+	 */
+	if (clp[LPFC_CFG_FDMI_ON].a_current == 1) {
+		lpfc_fdmi_cmd(phba, ndlp, SLI_MGMT_DHBA);
+	} else {
+		/*
+		 * Delay issuing FDMI command if fdmi-on=2
+		 * (supporting RPA/hostnmae)
+		 */
+		plhba->fc_fdmitmo =
+		    elx_clk_set(phba, 60, lpfc_fdmi_tmo, ndlp, 0);
+	}
+
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+
+	return;
+}
+
+/*
+ * This routine looks up the ndlp hash 
+ * table for the given RPI. If rpi found
+ * it return the node list pointer
+ * else return NULL.
+ */
+LPFC_NODELIST_t *
+lpfc_findnode_rpi(elxHBA_t * phba, uint16_t rpi)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ret;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ret = plhba->fc_nlplookup[LPFC_RPI_HASH_FUNC(rpi)];
+	while ((ret != NULL) && (ret->nle.nlp_rpi != rpi)) {
+		ret = ret->nlp_rpi_hash_next;
+	}
+	return ret;
+}
+
+/*
+ * This routine looks up the ndlp hash table for the
+ * given RPI. If rpi found it return the node list 
+ * pointer else return NULL after deleting the entry 
+ * from hash table. 
+ */
+LPFC_NODELIST_t *
+lpfc_findnode_remove_rpi(elxHBA_t * phba, uint16_t rpi)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ret, *temp;;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ret = plhba->fc_nlplookup[LPFC_RPI_HASH_FUNC(rpi)];
+
+	if (ret == NULL) {
+		return NULL;
+	}
+
+	if (ret->nle.nlp_rpi == rpi) {
+		plhba->fc_nlplookup[LPFC_RPI_HASH_FUNC(rpi)] =
+		    ret->nlp_rpi_hash_next;
+		ret->nlp_rpi_hash_next = NULL;
+		return ret;
+	}
+
+	while ((ret->nlp_rpi_hash_next != NULL) &&
+	       (ret->nlp_rpi_hash_next->nle.nlp_rpi != rpi)) {
+		ret = ret->nlp_rpi_hash_next;
+	}
+
+	if (ret->nlp_rpi_hash_next != NULL) {
+		temp = ret->nlp_rpi_hash_next;
+		ret->nlp_rpi_hash_next = temp->nlp_rpi_hash_next;
+		temp->nlp_rpi_hash_next = NULL;
+		return temp;
+	} else {
+		return NULL;
+	}
+}
+
+/*
+ * This routine adds the node list entry to the
+ * ndlp hash table.
+ */
+void
+lpfc_addnode_rpi(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, uint16_t rpi)
+{
+
+	LPFCHBA_t *plhba;
+	uint32_t index;
+
+	index = LPFC_RPI_HASH_FUNC(rpi);
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ndlp->nlp_rpi_hash_next = plhba->fc_nlplookup[index];
+	plhba->fc_nlplookup[index] = ndlp;
+	return;
+}
+
+/*
+ * This routine deletes the node list entry from the
+ * ndlp hash table.
+ */
+LPFC_NODELIST_t *
+lpfc_removenode_rpihash(elxHBA_t * phba, LPFC_NODELIST_t * ndlp)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *node_list;
+	uint32_t index;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	for (index = 0; index < LPFC_RPI_HASH_SIZE; index++) {
+		node_list = plhba->fc_nlplookup[index];
+
+		if (!node_list)
+			continue;
+		if (node_list == ndlp) {
+			plhba->fc_nlplookup[index] =
+			    node_list->nlp_rpi_hash_next;
+			node_list->nlp_rpi_hash_next = NULL;
+			return node_list;
+		}
+		while ((node_list->nlp_rpi_hash_next != NULL) &&
+		       (node_list->nlp_rpi_hash_next != ndlp)) {
+			node_list = node_list->nlp_rpi_hash_next;
+		}
+		if (node_list->nlp_rpi_hash_next) {
+			node_list->nlp_rpi_hash_next = ndlp->nlp_rpi_hash_next;
+			ndlp->nlp_rpi_hash_next = NULL;
+			return ndlp;
+		}
+	}
+	return NULL;
+}
+
+extern elxDRVR_t elxDRVR;
+
+int lpfc_parse_vpd(elxHBA_t *, uint8_t *);
+int lpfc_post_rcv_buf(elxHBA_t *);
+void lpfc_establish_link_tmo(elxHBA_t *, void *, void *);
+int lpfc_check_for_vpd = 1;
+int lpfc_rdrev_wd30 = 0;
+
+#define LPFC_MAX_VPD_SIZE   0x100
+uint32_t lpfc_vpd_data[LPFC_MAX_VPD_SIZE];
+
+extern int lpfc_instance[MAX_ELX_BRDS];
+
+/************************************************************************/
+/*                                                                      */
+/*   lpfc_swap_bcopy                                                    */
+/*                                                                      */
+/************************************************************************/
+void
+lpfc_swap_bcopy(uint32_t * src, uint32_t * dest, uint32_t cnt)
+{
+	uint32_t ldata;
+	int i;
+
+	for (i = 0; i < (int)cnt; i += sizeof (uint32_t)) {
+		ldata = *src++;
+		ldata = cpu_to_be32(ldata);
+		*dest++ = ldata;
+	}
+}
+
+/************************************************************************/
+/*                                                                      */
+/*    lpfc_config_port_prep                                             */
+/*    This routine will do LPFC initialization prior to the             */
+/*    CONFIG_PORT mailbox command. This will be initialized             */
+/*    as a SLI layer callback routine.                                  */
+/*    This routine returns 0 on success or ERESTART if it wants         */
+/*    the SLI layer to reset the HBA and try again. Any                 */
+/*    other return value indicates an error.                            */
+/*                                                                      */
+/************************************************************************/
+int
+lpfc_config_port_prep(elxHBA_t * phba)
+{
+	ELX_MBOXQ_t *pmb;
+	MAILBOX_t *mb;
+	elx_vpd_t *vp;
+	uint32_t status;
+	int i;
+	char licensed[56] =
+	    "key unlock for use with gnu public licensed code only\0";
+	uint32_t *pText = (uint32_t *) licensed;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	vp = &phba->vpd;
+
+	/* Get a Mailbox buffer to setup mailbox commands for HBA initialization */
+	if ((pmb =
+	     (ELX_MBOXQ_t *) elx_mem_get(phba, (MEM_MBOX | MEM_PRI))) == 0) {
+		phba->hba_state = ELX_HBA_ERROR;
+		return (ENOMEM);
+	}
+	mb = &pmb->mb;
+
+#ifndef powerpc
+	if ((((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_TFLY) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_PFLY) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_LP101) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_RFLY)) {
+#else
+	if (((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_TFLY) ||
+	    ((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_PFLY) ||
+	    ((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_RFLY)) {
+#endif
+		/* Setup and issue mailbox READ NVPARAMS command */
+		phba->hba_state = ELX_INIT_MBX_CMDS;
+		lpfc_read_nv(phba, pmb);
+		memset((void *)mb->un.varRDnvp.rsvd3, 0,
+		       sizeof (mb->un.varRDnvp.rsvd3));
+		lpfc_swap_bcopy(pText, pText, 56);
+		memcpy((void *)mb->un.varRDnvp.rsvd3, licensed,
+		       sizeof (licensed));
+		if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+			/* Adapter initialization error, mbxCmd <cmd> READ_NVPARM, mbxStatus <status> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0324,	/* ptr to msg structure */
+				       elx_mes0324,	/* ptr to msg */
+				       elx_msgBlk0324.msgPreambleStr,	/* begin varargs */
+				       mb->mbxCommand, mb->mbxStatus);	/* end varargs */
+			return (ERESTART);
+		}
+		memcpy((uint8_t *) plhba->wwnn,
+		       (uint8_t *) mb->un.varRDnvp.nodename,
+		       sizeof (mb->un.varRDnvp.nodename));
+	}
+	/* Setup and issue mailbox READ REV command */
+	phba->hba_state = ELX_INIT_MBX_CMDS;
+	elx_read_rev(phba, pmb);
+	if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+		/* Adapter failed to init, mbxCmd <mbxCmd> READ_REV, mbxStatus <status> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0439,	/* ptr to msg structure */
+			       elx_mes0439,	/* ptr to msg */
+			       elx_msgBlk0439.msgPreambleStr,	/* begin varargs */
+			       mb->mbxCommand, mb->mbxStatus);	/* end varargs */
+
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		return (ERESTART);
+	}
+
+	/* The HBA's current state is provided by the ProgType and rr fields.  Read
+	 * and check the value of these fields before continuing to config this port.
+	 */
+	if (mb->un.varRdRev.rr == 0) {
+		/* Old firmware */
+		vp->rev.rBit = 0;
+		/* Adapter failed to init, mbxCmd <cmd> READ_REV detected outdated firmware */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0440,	/* ptr to msg structure */
+			       elx_mes0440,	/* ptr to msg */
+			       elx_msgBlk0440.msgPreambleStr,	/* begin varargs */
+			       mb->mbxCommand, 0);	/* end varargs */
+
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		return (ERESTART);
+	} else {
+		if (mb->un.varRdRev.un.b.ProgType != 2) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			return (ERESTART);
+		}
+		vp->rev.rBit = 1;
+		vp->rev.sli1FwRev = mb->un.varRdRev.sli1FwRev;
+		memcpy((uint8_t *) vp->rev.sli1FwName,
+		       (uint8_t *) mb->un.varRdRev.sli1FwName, 16);
+		vp->rev.sli2FwRev = mb->un.varRdRev.sli2FwRev;
+		memcpy((uint8_t *) vp->rev.sli2FwName,
+		       (uint8_t *) mb->un.varRdRev.sli2FwName, 16);
+	}
+
+	/* Save information as VPD data */
+	vp->rev.biuRev = mb->un.varRdRev.biuRev;
+	vp->rev.smRev = mb->un.varRdRev.smRev;
+	vp->rev.smFwRev = mb->un.varRdRev.un.smFwRev;
+	vp->rev.endecRev = mb->un.varRdRev.endecRev;
+	vp->rev.fcphHigh = mb->un.varRdRev.fcphHigh;
+	vp->rev.fcphLow = mb->un.varRdRev.fcphLow;
+	vp->rev.feaLevelHigh = mb->un.varRdRev.feaLevelHigh;
+	vp->rev.feaLevelLow = mb->un.varRdRev.feaLevelLow;
+	vp->rev.postKernRev = mb->un.varRdRev.postKernRev;
+	vp->rev.opFwRev = mb->un.varRdRev.opFwRev;
+	lpfc_rdrev_wd30 = mb->un.varWords[30];
+#ifndef powerpc
+	if ((((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_TFLY) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_PFLY) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_LP101) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_RFLY)) {
+#else
+	if (((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_TFLY) ||
+	    ((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_PFLY) ||
+	    ((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_RFLY)) {
+#endif
+		memcpy((uint8_t *) plhba->RandomData,
+		       (uint8_t *) & mb->un.varWords[24],
+		       sizeof (plhba->RandomData));
+	}
+
+	if (lpfc_check_for_vpd) {
+		/* Get adapter VPD information */
+		lpfc_dump_mem(phba, pmb);
+		if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+			/*
+			 * Let it go through even if failed.
+			 */
+			/* Adapter failed to init, mbxCmd <cmd> DUMP VPD, mbxStatus <status> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0441,	/* ptr to msg structure */
+				       elx_mes0441,	/* ptr to msg */
+				       elx_msgBlk0441.msgPreambleStr,	/* begin varargs */
+				       mb->mbxCommand, mb->mbxStatus);	/* end varargs */
+
+		} else {
+			if ((mb->un.varDmp.ra == 1) &&
+			    (mb->un.varDmp.word_cnt <= LPFC_MAX_VPD_SIZE)) {
+				uint32_t *lp1, *lp2;
+
+				lp1 = (uint32_t *) & mb->un.varDmp.resp_offset;
+				lp2 = (uint32_t *) & lpfc_vpd_data[0];
+				for (i = 0; i < mb->un.varDmp.word_cnt; i++) {
+					status = *lp1++;
+					*lp2++ = SWAP_LONG(status);
+				}
+				lpfc_parse_vpd(phba,
+					       (uint8_t *) & lpfc_vpd_data[0]);
+			}
+		}
+	}
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+	return (0);
+}
+
+/************************************************************************/
+/*                                                                      */
+/*    lpfc_config_port_post                                             */
+/*    This routine will do LPFC initialization after the                */
+/*    CONFIG_PORT mailbox command. This will be initialized             */
+/*    as a SLI layer callback routine.                                  */
+/*    This routine returns 0 on success. Any other return value         */
+/*    indicates an error.                                               */
+/*                                                                      */
+/************************************************************************/
+int
+lpfc_config_port_post(elxHBA_t * phba)
+{
+	ELX_MBOXQ_t *pmb;
+	MAILBOX_t *mb;
+	DMABUF_t *mp;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	ELXCLOCK_INFO_t *clock_info;
+	elxCfgParam_t *clp;
+	uint32_t status;
+	int i, j, flogi_sent;
+	unsigned long iflag, isr_cnt, clk_cnt;
+	uint32_t timeout;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	/* Get a Mailbox buffer to setup mailbox commands for HBA initialization */
+	if ((pmb =
+	     (ELX_MBOXQ_t *) elx_mem_get(phba, (MEM_MBOX | MEM_PRI))) == 0) {
+		phba->hba_state = ELX_HBA_ERROR;
+		return (ENOMEM);
+	}
+	mb = &pmb->mb;
+
+	/* Setup link timers */
+	lpfc_config_link(phba, pmb);
+	if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+		/* Adapter failed to init, mbxCmd <cmd> CONFIG_LINK mbxStatus <status> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0447,	/* ptr to msg structure */
+			       elx_mes0447,	/* ptr to msg */
+			       elx_msgBlk0447.msgPreambleStr,	/* begin varargs */
+			       mb->mbxCommand, mb->mbxStatus);	/* end varargs */
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		return (EIO);
+	}
+
+	/* Get login parameters for NID.  */
+	lpfc_read_sparam(phba, pmb);
+	if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+		/* Adapter failed to init, mbxCmd <cmd> READ_SPARM mbxStatus <status> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0448,	/* ptr to msg structure */
+			       elx_mes0448,	/* ptr to msg */
+			       elx_msgBlk0448.msgPreambleStr,	/* begin varargs */
+			       mb->mbxCommand, mb->mbxStatus);	/* end varargs */
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		return (EIO);
+	}
+
+	mp = (DMABUF_t *) pmb->context1;
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORCPU);
+
+	memcpy((uint8_t *) & plhba->fc_sparam, (uint8_t *) mp->virt,
+	       sizeof (SERV_PARM));
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	pmb->context1 = 0;
+
+	memcpy((uint8_t *) & plhba->fc_nodename,
+	       (uint8_t *) & plhba->fc_sparam.nodeName, sizeof (NAME_TYPE));
+	memcpy((uint8_t *) & plhba->fc_portname,
+	       (uint8_t *) & plhba->fc_sparam.portName, sizeof (NAME_TYPE));
+	memcpy(plhba->phys_addr, plhba->fc_portname.IEEE, 6);
+	/* If no serial number in VPD data, use low 6 bytes of WWNN */
+	if (phba->SerialNumber[0] == 0) {
+		uint8_t *outptr;
+
+		outptr = (uint8_t *) & plhba->fc_nodename.IEEE[0];
+		for (i = 0; i < 12; i++) {
+			status = *outptr++;
+			j = ((status & 0xf0) >> 4);
+			if (j <= 9)
+				phba->SerialNumber[i] =
+				    (char)((uint8_t) 0x30 + (uint8_t) j);
+			else
+				phba->SerialNumber[i] =
+				    (char)((uint8_t) 0x61 + (uint8_t) (j - 10));
+			i++;
+			j = (status & 0xf);
+			if (j <= 9)
+				phba->SerialNumber[i] =
+				    (char)((uint8_t) 0x30 + (uint8_t) j);
+			else
+				phba->SerialNumber[i] =
+				    (char)((uint8_t) 0x61 + (uint8_t) (j - 10));
+		}
+	}
+
+	/* This should turn on DELAYED ABTS for ELS timeouts */
+	lpfc_set_slim(phba, pmb, 0x052198, 0x1);
+	if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		return (EIO);
+	}
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		if ((plhba->fc_sparam.portName.nameType != NAME_IEEE) ||
+		    (plhba->fc_sparam.portName.IEEEextMsn != 0) ||
+		    (plhba->fc_sparam.portName.IEEEextLsb != 0)) {
+			clp[LPFC_CFG_NETWORK_ON].a_current = 0;
+
+			elx_printf_log(phba->brd_no, &elx_msgBlk0449,	/* ptr to msg structure */
+				       elx_mes0449,	/* ptr to msg */
+				       elx_msgBlk0449.msgPreambleStr,	/* begin varargs */
+				       plhba->fc_sparam.portName.nameType);	/* end varargs */
+		}
+
+		/* Issue CONFIG FARP NEW_FEATURE */
+		lpfc_config_farp(phba, pmb);
+		if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+			/*
+			 * Let it go through even if failed.
+			 */
+			/* Adapter failed to init, mbxCmd <cmd> FARP, mbxStatus <status> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0450,	/* ptr to msg structure */
+				       elx_mes0450,	/* ptr to msg */
+				       elx_msgBlk0450.msgPreambleStr,	/* begin varargs */
+				       mb->mbxCommand, mb->mbxStatus);	/* end varargs */
+		}
+	}
+
+	lpfc_read_config(phba, pmb);
+	if (elx_sli_issue_mbox(phba, pmb, MBX_POLL) != MBX_SUCCESS) {
+		/* Adapter failed to init, mbxCmd <cmd> READ_CONFIG, mbxStatus <status> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0453,	/* ptr to msg structure */
+			       elx_mes0453,	/* ptr to msg */
+			       elx_msgBlk0453.msgPreambleStr,	/* begin varargs */
+			       mb->mbxCommand, mb->mbxStatus);	/* end varargs */
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		return (EIO);
+	}
+	if (mb->un.varRdConfig.lmt & LMT_2125_10bit) {
+		/* HBA is 2G capable */
+		plhba->fc_flag |= FC_2G_CAPABLE;
+	} else {
+		/* If the HBA is not 2G capable, don't let link speed ask for it */
+		if (clp[LPFC_CFG_LINK_SPEED].a_current > 1) {
+			/* Reset link speed to auto. 1G HBA cfg'd for 2G */
+			elx_printf_log(phba->brd_no, &elx_msgBlk1302,	/* ptr to msg structure */
+				       elx_mes1302,	/* ptr to msg */
+				       elx_msgBlk1302.msgPreambleStr,	/* begin varargs */
+				       clp[LPFC_CFG_LINK_SPEED].a_current);	/* end varargs */
+			clp[LPFC_CFG_LINK_SPEED].a_current = LINK_SPEED_AUTO;
+		}
+	}
+
+	if (phba->intr_inited != 1) {
+		/* Add our interrupt routine to kernel's interrupt chain & enable it */
+
+		if ((psli->sliinit.elx_sli_register_intr) ((void *)phba) != 0) {
+			/* Enable interrupt handler failed */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0451,	/* ptr to msg structure */
+				       elx_mes0451,	/* ptr to msg */
+				       elx_msgBlk0451.msgPreambleStr);	/* begin & end varargs */
+			phba->hba_state = ELX_HBA_ERROR;
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			return (EIO);
+		}
+		phba->intr_inited = 1;
+	}
+
+	phba->hba_state = ELX_LINK_DOWN;
+	plhba->fc_flag |= FC_LNK_DOWN;
+
+	/* Only process IOCBs on ring 0 till hba_state is READY */
+	if (psli->ring[psli->ip_ring].cmdringaddr)
+		psli->ring[psli->ip_ring].flag |= ELX_STOP_IOCB_EVENT;
+	if (psli->ring[psli->fcp_ring].cmdringaddr)
+		psli->ring[psli->fcp_ring].flag |= ELX_STOP_IOCB_EVENT;
+	if (psli->ring[psli->next_ring].cmdringaddr)
+		psli->ring[psli->next_ring].flag |= ELX_STOP_IOCB_EVENT;
+
+	/* Post receive buffers for desired rings */
+	lpfc_post_rcv_buf(phba);
+
+	ELX_SLI_LOCK(phba, iflag);
+
+	/* Enable appropriate host interrupts */
+	status = (psli->sliinit.elx_sli_read_HC) (phba);
+	status |= (uint32_t) (HC_MBINT_ENA | HC_ERINT_ENA | HC_LAINT_ENA);
+	if (psli->sliinit.num_rings > 0)
+		status |= HC_R0INT_ENA;
+	if (psli->sliinit.num_rings > 1)
+		status |= HC_R1INT_ENA;
+	if (psli->sliinit.num_rings > 2)
+		status |= HC_R2INT_ENA;
+	if (psli->sliinit.num_rings > 3)
+		status |= HC_R3INT_ENA;
+
+	(psli->sliinit.elx_sli_write_HC) (phba, status);
+
+	/* Setup and issue mailbox INITIALIZE LINK command */
+	lpfc_init_link(phba, pmb, clp[LPFC_CFG_TOPOLOGY].a_current,
+		       clp[LPFC_CFG_LINK_SPEED].a_current);
+
+	clock_info = &elxDRVR.elx_clock_info;
+	isr_cnt = psli->slistat.sliIntr;
+	clk_cnt = clock_info->ticks;
+
+	ELX_SLI_UNLOCK(phba, iflag);
+	if (elx_sli_issue_mbox(phba, pmb, MBX_NOWAIT) != MBX_SUCCESS) {
+		/* Adapter failed to init, mbxCmd <cmd> INIT_LINK, mbxStatus <status> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0454,	/* ptr to msg structure */
+			       elx_mes0454,	/* ptr to msg */
+			       elx_msgBlk0454.msgPreambleStr,	/* begin varargs */
+			       mb->mbxCommand, mb->mbxStatus);	/* end varargs */
+		(psli->sliinit.elx_sli_unregister_intr) ((void *)phba);
+		phba->intr_inited = 0;
+		phba->hba_state = ELX_HBA_ERROR;
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		return (EIO);
+	}
+	/* MEM_MBOX buffer will be freed in mbox compl */
+
+	/*
+	 * Setup the ring 0 (els)  timeout handler
+	 */
+	timeout = plhba->fc_ratov << 1;
+	phba->els_tmofunc = elx_clk_set(phba, timeout, lpfc_els_timeout_handler,
+					(void *)(unsigned long)timeout, 0);
+
+	plhba->fc_prevDID = Mask_DID;
+	flogi_sent = 0;
+	i = 0;
+	while ((phba->hba_state != ELX_HBA_READY) ||
+	       (plhba->num_disc_nodes) || (plhba->fc_prli_sent) ||
+	       (plhba->fc_map_cnt == 0) ||
+	       (psli->sliinit.sli_flag & ELX_SLI_MBOX_ACTIVE)) {
+		/* Check every second for 30 retries. */
+		i++;
+		if (i > 30) {
+			break;
+		}
+		if ((i >= 15) && (phba->hba_state <= ELX_LINK_DOWN)) {
+			/* The link is down.  Set linkdown timeout */
+
+			if ((clp[ELX_CFG_LINKDOWN_TMO].a_current == 0) ||
+			    clp[ELX_CFG_HOLDIO].a_current) {
+				plhba->fc_flag |= (FC_LD_TIMER | FC_LD_TIMEOUT);
+				phba->hba_flag |= FC_LFR_ACTIVE;
+			} else {
+				plhba->fc_flag |= FC_LD_TIMER;
+				phba->hba_flag |= FC_LFR_ACTIVE;
+				if (plhba->fc_linkdown) {
+					elx_clk_res(phba,
+						    clp[ELX_CFG_LINKDOWN_TMO].
+						    a_current,
+						    plhba->fc_linkdown);
+				} else {
+					if (clp[ELX_CFG_HOLDIO].a_current == 0) {
+						plhba->fc_linkdown =
+						    elx_clk_set(phba,
+								clp
+								[ELX_CFG_LINKDOWN_TMO].
+								a_current,
+								lpfc_linkdown_timeout,
+								0, 0);
+					}
+				}
+			}
+			break;
+		}
+
+		/* 20 * 50ms is identically 1sec */
+		for (j = 0; j < 20; j++) {
+			mdelay(50);
+			/* On some systems hardware interrupts cannot interrupt the
+			 * attach / detect routine. If this is the case, manually call
+			 * the ISR every 50 ms to service any potential interrupt.
+			 */
+			ELX_DRVR_LOCK(phba, iflag);
+			if (isr_cnt == psli->slistat.sliIntr) {
+				elx_sli_intr(phba);
+				isr_cnt = psli->slistat.sliIntr;
+			}
+			lpfc_els_chk_latt(phba, 0);
+			ELX_DRVR_UNLOCK(phba, iflag);
+		}
+		isr_cnt = psli->slistat.sliIntr;
+
+		/* On some systems clock interrupts cannot interrupt the
+		 * attach / detect routine. If this is the case, manually call
+		 * the clock routine every sec to service any potential timeouts.
+		 */
+		if (clk_cnt == clock_info->ticks) {
+			elx_timer(0);
+			clk_cnt = clock_info->ticks;
+		}
+	}
+
+	/* Since num_disc_nodes keys off of PLOGI, delay a bit to let
+	 * any potential PRLIs to flush thru the SLI sub-system.
+	 */
+	mdelay(50);
+	ELX_DRVR_LOCK(phba, iflag);
+	if (isr_cnt == psli->slistat.sliIntr) {
+		elx_sli_intr(phba);
+	}
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+
+	return (0);
+}
+
+/************************************************************************/
+/*                                                                      */
+/*    lpfc_hba_down_prep                                                */
+/*    This routine will do LPFC uninitialization before the             */
+/*    HBA is reset when bringing down the SLI Layer. This will be       */
+/*    initialized as a SLI layer callback routine.                      */
+/*    This routine returns 0 on success. Any other return value         */
+/*    indicates an error.                                               */
+/*                                                                      */
+/************************************************************************/
+int
+lpfc_hba_down_prep(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_SLINK_t *dlp;
+	ELX_SLI_RING_t *pring;
+	DMABUF_t *mp;
+	DMABUFIP_t *mpip;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	ELX_SLI_LOCK(phba, iflag);
+	/* Disable interrupts */
+	(psli->sliinit.elx_sli_write_HC) (phba, 0);
+
+	/* Now cleanup posted buffers on each ring */
+	pring = &psli->ring[LPFC_ELS_RING];	/* RING 0 */
+	dlp = &pring->postbufq;
+	while (dlp->q_first) {
+		mp = (DMABUF_t *) dlp->q_first;
+		dlp->q_first = (ELX_SLINK_t *) mp->next;
+		dlp->q_cnt--;
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	}
+	dlp->q_last = 0;
+	pring = &psli->ring[psli->ip_ring];	/* RING 1 */
+	dlp = &pring->postbufq;
+	while (dlp->q_first) {
+		mpip = (DMABUFIP_t *) dlp->q_first;
+		dlp->q_first = (ELX_SLINK_t *) mpip->dma.next;
+		dlp->q_cnt--;
+		elx_mem_put(phba, MEM_IP_RCV_BUF, (uint8_t *) mpip);
+	}
+	dlp->q_last = 0;
+	pring = &psli->ring[psli->fcp_ring];	/* RING 2 */
+	pring = &psli->ring[psli->next_ring];	/* RING 3 */
+	dlp = &pring->postbufq;
+	while (dlp->q_first) {
+		mpip = (DMABUFIP_t *) dlp->q_first;
+		dlp->q_first = (ELX_SLINK_t *) mpip->dma.next;
+		dlp->q_cnt--;
+		elx_mem_put(phba, MEM_FCP_CMND_BUF, (uint8_t *) mpip);
+	}
+	dlp->q_last = 0;
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (0);
+}
+
+/************************************************************************/
+/*                                                                      */
+/*    lpfc_handle_eratt                                                 */
+/*    This routine will handle processing a Host Attention              */
+/*    Error Status event. This will be initialized                      */
+/*    as a SLI layer callback routine.                                  */
+/*                                                                      */
+/************************************************************************/
+void
+lpfc_handle_eratt(elxHBA_t * phba, uint32_t status)
+{
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	volatile uint32_t status1, status2;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	(psli->sliinit.elx_sli_read_slim) ((void *)phba, (void *)&status1,
+					   (int)0xa8, sizeof (uint32_t));
+	(psli->sliinit.elx_sli_read_slim) ((void *)phba, (void *)&status2,
+					   (int)0xac, sizeof (uint32_t));
+
+	if (status & HS_FFER6) {
+		/* Re-establishing Link */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1301,	/* ptr to msg structure */
+			       elx_mes1301,	/* ptr to msg */
+			       elx_msgBlk1301.msgPreambleStr,	/* begin varargs */
+			       status, status1, status2);	/* end varargs */
+		plhba->fc_flag |= FC_ESTABLISH_LINK;
+		lpfc_offline(phba);
+		if (lpfc_online(phba) == 0) {	/* Initialize the HBA */
+			if (plhba->fc_estabtmo) {
+				elx_clk_can(phba, plhba->fc_estabtmo);
+			}
+			plhba->fc_estabtmo =
+			    elx_clk_set(phba, 60, lpfc_establish_link_tmo, 0,
+					0);
+			return;
+		}
+	}
+	/* Adapter Hardware Error */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0457,	/* ptr to msg structure */
+		       elx_mes0457,	/* ptr to msg */
+		       elx_msgBlk0457.msgPreambleStr,	/* begin varargs */
+		       status, status1, status2);	/* end varargs */
+
+	lpfc_offline(phba);
+	return;
+}
+
+/************************************************************************/
+/*                                                                      */
+/*    lpfc_handle_latt                                                  */
+/*    This routine will handle processing a Host Attention              */
+/*    Link Status event. This will be initialized                       */
+/*    as a SLI layer callback routine.                                  */
+/*                                                                      */
+/************************************************************************/
+void
+lpfc_handle_latt(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_MBOXQ_t *pmb;
+	volatile uint32_t control;
+
+	/* called from host_interrupt, to process LATT */
+	psli = &phba->sli;
+
+	psli->slistat.linkEvent++;
+
+	/* Get a buffer which will be used for mailbox commands */
+	if ((pmb = (ELX_MBOXQ_t *) elx_mem_get(phba, (MEM_MBOX | MEM_PRI)))) {
+		if (lpfc_read_la(phba, pmb) == 0) {
+			pmb->mbox_cmpl = lpfc_mbx_cmpl_read_la;
+			if (elx_sli_issue_mbox
+			    (phba, pmb, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    != MBX_NOT_FINISHED) {
+				/* Turn off Link Attention interrupts until CLEAR_LA done */
+				psli->sliinit.sli_flag &= ~ELX_PROCESS_LA;
+				control =
+				    (psli->sliinit.elx_sli_read_HC) (phba);
+				control &= ~HC_LAINT_ENA;
+				(psli->sliinit.elx_sli_write_HC) (phba,
+								  control);
+
+				/* Clear Link Attention in HA REG */
+				(psli->sliinit.elx_sli_write_HA) (phba,
+								  HA_LATT);
+			} else {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+			}
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmb);
+		}
+	}
+	return;
+}
+
+/************************************************************************/
+/*                                                                      */
+/*   lpfc_parse_vpd                                                     */
+/*   This routine will parse the VPD data                               */
+/*                                                                      */
+/************************************************************************/
+int
+lpfc_parse_vpd(elxHBA_t * phba, uint8_t * vpd)
+{
+	uint8_t lenlo, lenhi;
+	uint8_t *Length;
+	int i, j;
+	int finished = 0;
+	int index = 0;
+
+	/* Vital Product */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0455,	/* ptr to msg structure */
+		       elx_mes0455,	/* ptr to msg */
+		       elx_msgBlk0455.msgPreambleStr,	/* begin varargs */
+		       (uint32_t) vpd[0], (uint32_t) vpd[1], (uint32_t) vpd[2], (uint32_t) vpd[3]);	/* end varargs */
+	do {
+		switch (vpd[index]) {
+		case 0x82:
+			index += 1;
+			lenlo = vpd[index];
+			index += 1;
+			lenhi = vpd[index];
+			index += 1;
+			i = ((((unsigned short)lenhi) << 8) + lenlo);
+			index += i;
+			break;
+		case 0x90:
+			index += 1;
+			lenlo = vpd[index];
+			index += 1;
+			lenhi = vpd[index];
+			index += 1;
+			i = ((((unsigned short)lenhi) << 8) + lenlo);
+			do {
+				/* Look for Serial Number */
+				if ((vpd[index] == 'S')
+				    && (vpd[index + 1] == 'N')) {
+					index += 2;
+					Length = &vpd[index];
+					index += 1;
+					i = *Length;
+					j = 0;
+					while (i--) {
+						phba->SerialNumber[j++] =
+						    vpd[index++];
+						if (j == 31)
+							break;
+					}
+					phba->SerialNumber[j] = 0;
+					return (1);
+				} else {
+					index += 2;
+					Length = &vpd[index];
+					index += 1;
+					j = (int)(*Length);
+					index += j;
+					i -= (3 + j);
+				}
+			} while (i > 0);
+			finished = 0;
+			break;
+		case 0x78:
+			finished = 1;
+			break;
+		default:
+			return (0);
+		}
+	} while (!finished);
+	return (1);
+}
+
+/**************************************************/
+/*   lpfc_post_buffer                             */
+/*                                                */
+/*   This routine will post count buffers to the  */
+/*   ring with the QUE_RING_BUF_CN command. This  */
+/*   allows 3 buffers / command to be posted.     */
+/*   Returns the number of buffers NOT posted.    */
+/**************************************************/
+int
+lpfc_post_buffer(elxHBA_t * phba, ELX_SLI_RING_t * pring, int cnt, int type)
+{
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *iocb;
+	DMABUF_t *mp1, *mp2;
+	int mem_flag;
+
+	cnt += pring->missbufcnt;
+	if (type == 2)
+		mem_flag = MEM_FCP_CMND_BUF;
+	else
+		mem_flag = MEM_BUF;
+
+	/* While there are buffers to post */
+	while (cnt > 0) {
+		/* Allocate buffer for  command iocb */
+		if ((iocb =
+		     (ELX_IOCBQ_t *) elx_mem_get(phba,
+						 MEM_IOCB | MEM_PRI)) == 0) {
+			pring->missbufcnt = cnt;
+			return (cnt);
+		}
+		memset((void *)iocb, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &iocb->iocb;
+
+		/* 2 buffers can be posted per command */
+		/* Allocate buffer to post */
+		if ((mp1 =
+		     (DMABUF_t *) elx_mem_get(phba,
+					      (mem_flag | MEM_PRI))) == 0) {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+			pring->missbufcnt = cnt;
+			return (cnt);
+		}
+		/* Allocate buffer to post */
+		if (cnt > 1) {
+			if ((mp2 =
+			     (DMABUF_t *) elx_mem_get(phba,
+						      (mem_flag | MEM_PRI))) ==
+			    0) {
+				elx_mem_put(phba, mem_flag, (uint8_t *) mp1);
+				elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+				pring->missbufcnt = cnt;
+				return (cnt);
+			}
+		} else {
+			mp2 = 0;
+		}
+
+		icmd->un.cont64[0].addrHigh = putPaddrHigh(mp1->phys);
+		icmd->un.cont64[0].addrLow = putPaddrLow(mp1->phys);
+		icmd->un.cont64[0].tus.f.bdeSize = FCELSSIZE;
+		icmd->ulpBdeCount = 1;
+		cnt--;
+		if (mp2) {
+			icmd->un.cont64[1].addrHigh = putPaddrHigh(mp2->phys);
+			icmd->un.cont64[1].addrLow = putPaddrLow(mp2->phys);
+			icmd->un.cont64[1].tus.f.bdeSize = FCELSSIZE;
+			cnt--;
+			icmd->ulpBdeCount = 2;
+		}
+
+		icmd->ulpCommand = CMD_QUE_RING_BUF64_CN;
+		icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+		icmd->ulpLe = 1;
+		icmd->ulpOwner = OWN_CHIP;
+
+		if (elx_sli_issue_iocb(phba, pring, iocb, SLI_IOCB_USE_TXQ) ==
+		    IOCB_ERROR) {
+			elx_mem_put(phba, mem_flag, (uint8_t *) mp1);
+			if (mp2) {
+				elx_mem_put(phba, mem_flag, (uint8_t *) mp2);
+			}
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+			pring->missbufcnt = cnt;
+			return (cnt);
+		}
+		elx_sli_ringpostbuf_put(phba, pring, mp1);
+		if (mp2) {
+			elx_sli_ringpostbuf_put(phba, pring, mp2);
+		}
+	}
+	pring->missbufcnt = 0;
+	return (0);
+}
+
+/************************************************************************/
+/*                                                                      */
+/*   lpfc_post_rcv_buf                                                  */
+/*   This routine post initial rcv buffers to the configured rings      */
+/*                                                                      */
+/************************************************************************/
+int
+lpfc_post_rcv_buf(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	elxCfgParam_t *clp;
+
+	psli = &phba->sli;
+	clp = &phba->config[0];
+
+	/* Ring 0, ELS / CT buffers */
+	lpfc_post_buffer(phba, &psli->ring[LPFC_ELS_RING], LPFC_BUF_RING0, 1);
+
+	/* Ring 1, IP Buffers */
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		lpfc_ip_post_buffer(phba, &psli->ring[LPFC_IP_RING],
+				    clp[LPFC_CFG_POST_IP_BUF].a_current);
+	}
+
+	/* Ring 2 - FCP no buffers needed */
+
+	return (0);
+}
+
+#define S(N,V) (((V)<<(N))|((V)>>(32-(N))))
+
+/************************************************************************/
+/*                                                                      */
+/*   lpfc_sha_init                                                      */
+/*                                                                      */
+/************************************************************************/
+void
+lpfc_sha_init(uint32_t * HashResultPointer)
+{
+	HashResultPointer[0] = 0x67452301;
+	HashResultPointer[1] = 0xEFCDAB89;
+	HashResultPointer[2] = 0x98BADCFE;
+	HashResultPointer[3] = 0x10325476;
+	HashResultPointer[4] = 0xC3D2E1F0;
+}
+
+/************************************************************************/
+/*                                                                      */
+/*   lpfc_sha_iterate                                                   */
+/*                                                                      */
+/************************************************************************/
+void
+lpfc_sha_iterate(uint32_t * HashResultPointer, uint32_t * HashWorkingPointer)
+{
+	int t;
+	uint32_t TEMP;
+	uint32_t A, B, C, D, E;
+	t = 16;
+	do {
+		HashWorkingPointer[t] =
+		    S(1,
+		      HashWorkingPointer[t - 3] ^ HashWorkingPointer[t -
+								     8] ^
+		      HashWorkingPointer[t - 14] ^ HashWorkingPointer[t - 16]);
+	} while (++t <= 79);
+	t = 0;
+	A = HashResultPointer[0];
+	B = HashResultPointer[1];
+	C = HashResultPointer[2];
+	D = HashResultPointer[3];
+	E = HashResultPointer[4];
+
+	do {
+		if (t < 20) {
+			TEMP = ((B & C) | ((~B) & D)) + 0x5A827999;
+		} else if (t < 40) {
+			TEMP = (B ^ C ^ D) + 0x6ED9EBA1;
+		} else if (t < 60) {
+			TEMP = ((B & C) | (B & D) | (C & D)) + 0x8F1BBCDC;
+		} else {
+			TEMP = (B ^ C ^ D) + 0xCA62C1D6;
+		}
+		TEMP += S(5, A) + E + HashWorkingPointer[t];
+		E = D;
+		D = C;
+		C = S(30, B);
+		B = A;
+		A = TEMP;
+	} while (++t <= 79);
+
+	HashResultPointer[0] += A;
+	HashResultPointer[1] += B;
+	HashResultPointer[2] += C;
+	HashResultPointer[3] += D;
+	HashResultPointer[4] += E;
+
+}
+
+/************************************************************************/
+/*                                                                      */
+/*   lpfc_challenge_key                                                 */
+/*                                                                      */
+/************************************************************************/
+void
+lpfc_challenge_key(uint32_t * RandomChallenge, uint32_t * HashWorking)
+{
+	*HashWorking = (*RandomChallenge ^ *HashWorking);
+}
+
+/************************************************************************/
+/*                                                                      */
+/*   lpfc_hba_init                                                      */
+/*                                                                      */
+/************************************************************************/
+void
+lpfc_hba_init(elxHBA_t * phba)
+{
+	int t;
+	uint32_t HashWorking[80];
+	uint32_t *pwwnn;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	pwwnn = plhba->wwnn;
+	memset(HashWorking, 0, sizeof (HashWorking));
+	HashWorking[0] = HashWorking[78] = *pwwnn++;
+	HashWorking[1] = HashWorking[79] = *pwwnn;
+	for (t = 0; t < 7; t++) {
+		lpfc_challenge_key(plhba->RandomData + t, HashWorking + t);
+	}
+	lpfc_sha_init(plhba->hbainitEx);
+	lpfc_sha_iterate(plhba->hbainitEx, HashWorking);
+}
+
+void
+lpfc_cleanup(elxHBA_t * phba, uint32_t save_bind)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_BINDLIST_t *bdlp;
+	uint8_t *ptr;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* clean up plhba - lpfc specific */
+	ELX_DISC_LOCK(phba, iflag);
+
+	lpfc_can_disctmo(phba);
+
+	ndlp = plhba->fc_nlpunmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+		ptr = (uint8_t *) ndlp;
+		ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		elx_mem_put(phba, MEM_NLP, ptr);
+	}
+	ndlp = plhba->fc_nlpmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		ptr = (uint8_t *) ndlp;
+		bdlp = (ndlp->nlp_listp_bind);
+		ndlp->nlp_listp_bind = 0;
+		ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		elx_mem_put(phba, MEM_NLP, ptr);
+		if (bdlp) {
+			if (save_bind == 0) {
+				elx_mem_put(phba, MEM_BIND, (uint8_t *) bdlp);
+			} else {
+				lpfc_nlp_bind(phba, bdlp);
+			}
+		}
+	}
+	ndlp = plhba->fc_plogi_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+		ptr = (uint8_t *) ndlp;
+		ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		elx_mem_put(phba, MEM_NLP, ptr);
+	}
+	ndlp = plhba->fc_adisc_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+		ptr = (uint8_t *) ndlp;
+		ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		elx_mem_put(phba, MEM_NLP, ptr);
+	}
+
+	if (save_bind == 0) {
+		bdlp = plhba->fc_nlpbind_start;
+		while (bdlp != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start) {
+			ptr = (uint8_t *) bdlp;
+			bdlp = (LPFC_BINDLIST_t *) bdlp->nlp_listp_next;
+			elx_mem_put(phba, MEM_BIND, ptr);
+		}
+		plhba->fc_nlpbind_start =
+		    (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start;
+		plhba->fc_nlpbind_end =
+		    (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start;
+		plhba->fc_bind_cnt = 0;
+	}
+	plhba->fc_nlpmap_start = (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start;
+	plhba->fc_nlpmap_end = (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start;
+	plhba->fc_map_cnt = 0;
+	plhba->fc_nlpunmap_start =
+	    (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start;
+	plhba->fc_nlpunmap_end = (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start;
+	plhba->fc_unmap_cnt = 0;
+	plhba->fc_plogi_start = (LPFC_NODELIST_t *) & plhba->fc_plogi_start;
+	plhba->fc_plogi_end = (LPFC_NODELIST_t *) & plhba->fc_plogi_start;
+	plhba->fc_plogi_cnt = 0;
+	plhba->fc_adisc_start = (LPFC_NODELIST_t *) & plhba->fc_adisc_start;
+	plhba->fc_adisc_end = (LPFC_NODELIST_t *) & plhba->fc_adisc_start;
+	plhba->fc_adisc_cnt = 0;
+	ELX_DISC_UNLOCK(phba, iflag);
+	return;
+}
+
+void
+lpfc_establish_link_tmo(elxHBA_t * phba, void *n1, void *n2)
+{
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* Re-establishing Link, timer expired */
+	elx_printf_log(phba->brd_no, &elx_msgBlk1300,	/* ptr to msg structure */
+		       elx_mes1300,	/* ptr to msg */
+		       elx_msgBlk1300.msgPreambleStr,	/* begin varargs */
+		       plhba->fc_flag, phba->hba_state);	/* end varargs */
+	plhba->fc_flag &= ~FC_ESTABLISH_LINK;
+}
+
+int
+lpfc_online(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+
+	if (phba) {
+		plhba = (LPFCHBA_t *) phba->pHbaProto;
+		if (!(plhba->fc_flag & FC_OFFLINE_MODE)) {
+			return (0);
+		}
+
+		/* Bring Adapter online */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0458,	/* ptr to msg structure */
+			       elx_mes0458,	/* ptr to msg */
+			       elx_msgBlk0458.msgPreambleStr);	/* begin & end varargs */
+		plhba->fc_flag &= ~FC_OFFLINE_MODE;
+
+		if (!elx_sli_setup(phba)) {
+			return (1);
+		}
+		if (elx_sli_hba_setup(phba)) {	/* Initialize the HBA */
+			return (1);
+		}
+
+		elx_unblock_requests(phba);
+		return (0);
+	}
+	return (0);
+}
+
+int
+lpfc_offline(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_RING_t *pring;
+	ELX_SLI_t *psli;
+	unsigned long iflag;
+	int i;
+
+	if (phba) {
+		plhba = (LPFCHBA_t *) phba->pHbaProto;
+		if (plhba->fc_flag & FC_OFFLINE_MODE) {
+			return (0);
+		}
+
+		psli = &phba->sli;
+		pring = &psli->ring[psli->fcp_ring];
+
+		elx_block_requests(phba);
+
+		lpfc_linkdown(phba);
+
+		i = 0;
+		while (pring->txcmplq.q_cnt) {
+			ELX_DRVR_UNLOCK(phba, iflag);
+			mdelay(10);
+			ELX_DRVR_LOCK(phba, iflag);
+			if (i++ > 3000)	/* 30 secs */
+				break;
+		}
+
+		/* Bring Adapter offline */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0460,	/* ptr to msg structure */
+			       elx_mes0460,	/* ptr to msg */
+			       elx_msgBlk0460.msgPreambleStr);	/* begin & end varargs */
+
+		elx_sli_hba_down(phba);	/* Bring down the SLI Layer */
+		lpfc_cleanup(phba, 1);	/* Save bindings */
+		plhba->fc_flag |= FC_OFFLINE_MODE;
+
+		/*
+		 * Cancel ELS timer
+		 */
+		if (phba->els_tmofunc) {
+			elx_clk_can(phba, phba->els_tmofunc);
+		}
+
+		return (0);
+	}
+	return (0);
+}
+
+/******************************************************************************
+* Function name : lpfc_scsi_free
+*
+* Description   : Called from fc_detach to free scsi tgt / lun resources
+* 
+******************************************************************************/
+int
+lpfc_scsi_free(elxHBA_t * phba)
+{
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp;
+	ELXSCSILUN_t *nextlunp;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+	int i;
+
+	buf_info = &bufinfo;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	for (i = 0; i < MAX_FCP_TARGET; i++) {
+		targetp = plhba->device_queue_hash[i];
+		if (targetp) {
+			lunp = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+			while (lunp) {
+				nextlunp = lunp->pnextLun;
+				memset(buf_info, 0, sizeof (MBUF_INFO_t));
+				buf_info->size = sizeof (ELXSCSILUN_t);
+				buf_info->flags = ELX_MBUF_VIRT;
+				buf_info->align = sizeof (void *);
+				buf_info->virt = lunp;
+				elx_free(phba, buf_info);
+				lunp = nextlunp;
+			}
+
+			if (targetp->RptLunData) {
+				elx_mem_put(phba, MEM_BUF,
+					    (uint8_t *) targetp->RptLunData);
+			}
+
+			memset(buf_info, 0, sizeof (MBUF_INFO_t));
+			buf_info->size = sizeof (ELXSCSITARGET_t);
+			buf_info->flags = ELX_MBUF_VIRT;
+			buf_info->align = sizeof (void *);
+			buf_info->virt = targetp;
+			elx_free(phba, buf_info);
+			plhba->device_queue_hash[i] = 0;
+		}
+	}
+	return (0);
+}
+
+/******************************************************************************
+* Function name : lpfc_parse_binding_entry
+*
+* Description   : Parse binding entry for WWNN & WWPN
+*
+* ASCII Input string example: 2000123456789abc:lpfc1t0
+* 
+* Return        :  0              = Success
+*                  Greater than 0 = Binding entry syntax error. SEE defs
+*                                   LPFC_SYNTAX_ERR_XXXXXX.
+******************************************************************************/
+int
+lpfc_parse_binding_entry(elxHBA_t * phba,
+			 uint8_t * inbuf,
+			 uint8_t * outbuf,
+			 int in_size,
+			 int out_size,
+			 int bind_type,
+			 unsigned int *sum, int entry, int *lpfc_num)
+{
+	int brd;
+	int c1, cvert_cnt, sumtmp;
+
+	char ds_lpfc[] = "lpfc";
+
+	*lpfc_num = -1;
+	if (bind_type == LPFC_BIND_DID) {
+		outbuf++;
+	}
+	/* Parse 16 digit ASC hex address */
+	cvert_cnt =
+	    elx_str_atox(phba, in_size, out_size, (char *)inbuf,
+			 (char *)outbuf);
+	if (cvert_cnt < 0)
+		return (LPFC_SYNTAX_ERR_ASC_CONVERT);
+	inbuf += (ulong) cvert_cnt;
+
+	/* Parse colon */
+	if (*inbuf++ != ':')
+		return (LPFC_SYNTAX_ERR_EXP_COLON);
+
+	/* Parse lpfc */
+	if (elx_str_ncmp((char *)inbuf, ds_lpfc, (sizeof (ds_lpfc) - 1)))
+		return (LPFC_SYNTAX_ERR_EXP_LPFC);
+	inbuf += sizeof (ds_lpfc) - 1;
+
+	/* Parse lpfc number */
+	/* Get 1st lpfc digit */
+	c1 = *inbuf++;
+	if (elx_is_digit(c1) == 0)
+		goto err_lpfc_num;
+	sumtmp = c1 - 0x30;
+
+	/* Get 2nd lpfc digit */
+	c1 = *inbuf;
+	if (elx_is_digit(c1) == 0)
+		goto convert_instance;
+	inbuf++;
+	sumtmp = (sumtmp * 10) + c1 - 0x30;
+
+	/* Get 3rd lpfc digit */
+	c1 = *inbuf;
+	if (elx_is_digit(c1) == 0)
+		goto convert_instance;
+	inbuf++;
+	sumtmp = (sumtmp * 10) + c1 - 0x30;
+
+	if ((sumtmp < 0) || (sumtmp > MAX_ELX_BRDS))
+		goto err_lpfc_num;
+	goto convert_instance;
+
+      err_lpfc_num:
+
+	return (LPFC_SYNTAX_ERR_INV_LPFC_NUM);
+
+	/* Convert from ddi instance number to adapter number */
+      convert_instance:
+	for (brd = 0; brd < MAX_ELX_BRDS; brd++) {
+		if (lpfc_instance[brd] == sumtmp)
+			break;
+	}
+	if (phba->brd_no != brd) {
+		/* Skip this entry */
+		return (LPFC_SYNTAX_OK_BUT_NOT_THIS_BRD);
+	}
+
+	/* Parse 't' */
+	if (*inbuf++ != 't')
+		return (LPFC_SYNTAX_ERR_EXP_T);
+
+	/* Parse target number */
+	/* Get 1st target digit */
+	c1 = *inbuf++;
+	if (elx_is_digit(c1) == 0)
+		goto err_target_num;
+	sumtmp = c1 - 0x30;
+
+	/* Get 2nd target digit */
+	c1 = *inbuf;
+	if (elx_is_digit(c1) == 0)
+		goto check_for_term;
+	inbuf++;
+	sumtmp = (sumtmp * 10) + c1 - 0x30;
+
+	/* Get 3nd target digit */
+	c1 = *inbuf;
+	if (elx_is_digit(c1) == 0)
+		goto check_for_term;
+	inbuf++;
+	sumtmp = (sumtmp * 10) + c1 - 0x30;
+	if (sumtmp > (LPFC_MAX_SCSI_ID_PER_PAN - 1))
+		goto err_target_num;
+	goto check_for_term;
+
+      err_target_num:
+	return (LPFC_SYNTAX_ERR_INV_TARGET_NUM);
+
+      check_for_term:
+
+	if (*inbuf != 0)
+		return (LPFC_SYNTAX_ERR_EXP_NULL_TERM);
+
+	*sum = sumtmp;
+	return (LPFC_SYNTAX_OK);	/* Success */
+}
+
+#include "lpfc_ioctl.h"
+
+extern elxDRVR_t elxDRVR;
+extern int lpfc_instcnt;
+extern char *lpfc_release_version;
+
+extern int elx_initpci(struct dfc_info *, elxHBA_t *);
+
+/*************************************************************************/
+/*  Global data structures                                               */
+/*************************************************************************/
+char lpfc_fwrev_short[16];
+
+uint32_t fc_dbg_flag;
+
+struct dfc dfc;
+
+struct dfc_mem {
+	uint32_t fc_outsz;
+	uint32_t fc_filler;
+	void *fc_dataout;
+};
+
+/******************************************************************************/
+/* NOTE: Allocate functions must make certain the last argument is            */
+/*       initialized to zero for all these Macros.                            */
+/******************************************************************************/
+#define RPTLUN_MIN_LEN 0x1000
+#define ELX_FREE(a, b) if (b) elx_free(a, b)
+#define ELX_MEM_PUT(a, b, c) if (c) elx_mem_put(a, b, c)
+#define DFC_CMD_DATA_FREE(a, b) if (b) dfc_cmd_data_free(a, b)
+
+#define LPFC_MAX_EVENT 4
+
+/* Routine Declaration - Local */
+int dfc_issue_mbox(elxHBA_t *, MAILBOX_t *);
+DMABUFEXT_t *dfc_cmd_data_alloc(elxHBA_t *, char *, ULP_BDE64 *, uint32_t);
+int dfc_cmd_data_free(elxHBA_t *, DMABUFEXT_t *);
+int dfc_rsp_data_copy(elxHBA_t *, uint8_t *, DMABUFEXT_t *, uint32_t);
+DMABUFEXT_t *dfc_fcp_data_alloc(elxHBA_t * p, ULP_BDE64 * bpl);
+int dfc_data_alloc(elxHBA_t *, struct dfc_mem *dm, uint32_t size);
+int dfc_data_free(elxHBA_t *, struct dfc_mem *dm);
+uint64_t dfc_getLunId(MBUF_INFO_t * bfrnfo, ELXSCSILUN_t * lun,
+		      uint64_t lunidx);
+int lpfc_issue_rptlun(elxHBA_t * phba, MBUF_INFO_t * pbfrnfo,
+		      ELXSCSITARGET_t * pscznod);
+int lpfc_reset_dev_q_depth(elxHBA_t * phba);
+
+int
+lpfc_ioctl_port_attrib(elxHBA_t * phba, LPFCHBA_t * plhba, struct dfc_mem *dm)
+{
+	elx_vpd_t *vp;
+	SERV_PARM *hsp;
+	HBA_PORTATTRIBUTES *hp;
+	HBA_OSDN *osdn;
+	elxCfgParam_t *clp = &phba->config[0];
+	uint32_t cnt;
+	int rc = 0;
+
+	vp = &phba->vpd;
+	hsp = (SERV_PARM *) (&plhba->fc_sparam);
+	hp = (HBA_PORTATTRIBUTES *) dm->fc_dataout;
+	memset(dm->fc_dataout, 0, (sizeof (HBA_PORTATTRIBUTES)));
+	memcpy((uint8_t *) & hp->NodeWWN,
+	       (uint8_t *) & plhba->fc_sparam.nodeName, sizeof (HBA_WWN));
+	memcpy((uint8_t *) & hp->PortWWN,
+	       (uint8_t *) & plhba->fc_sparam.portName, sizeof (HBA_WWN));
+
+	if (plhba->fc_linkspeed == LA_2GHZ_LINK)
+		hp->PortSpeed = HBA_PORTSPEED_2GBIT;
+	else
+		hp->PortSpeed = HBA_PORTSPEED_1GBIT;
+
+	if (FC_JEDEC_ID(vp->rev.biuRev) == VIPER_JEDEC_ID)
+		hp->PortSupportedSpeed = HBA_PORTSPEED_10GBIT;
+	else if ((FC_JEDEC_ID(vp->rev.biuRev) == CENTAUR_2G_JEDEC_ID) ||
+		 (FC_JEDEC_ID(vp->rev.biuRev) == PEGASUS_JEDEC_ID) ||
+		 (FC_JEDEC_ID(vp->rev.biuRev) == THOR_JEDEC_ID))
+		hp->PortSupportedSpeed = HBA_PORTSPEED_2GBIT;
+	else
+		hp->PortSupportedSpeed = HBA_PORTSPEED_1GBIT;
+
+	hp->PortFcId = plhba->fc_myDID;
+	hp->PortType = HBA_PORTTYPE_UNKNOWN;
+	if (plhba->fc_topology == TOPOLOGY_LOOP) {
+		if (plhba->fc_flag & FC_PUBLIC_LOOP) {
+			hp->PortType = HBA_PORTTYPE_NLPORT;
+			memcpy((uint8_t *) & hp->FabricName,
+			       (uint8_t *) & plhba->fc_fabparam.nodeName,
+			       sizeof (HBA_WWN));
+		} else {
+			hp->PortType = HBA_PORTTYPE_LPORT;
+		}
+	} else {
+		if (plhba->fc_flag & FC_FABRIC) {
+			hp->PortType = HBA_PORTTYPE_NPORT;
+			memcpy((uint8_t *) & hp->FabricName,
+			       (uint8_t *) & plhba->fc_fabparam.nodeName,
+			       sizeof (HBA_WWN));
+		} else {
+			hp->PortType = HBA_PORTTYPE_PTP;
+		}
+	}
+
+	if (plhba->fc_flag & FC_BYPASSED_MODE) {
+		hp->PortState = HBA_PORTSTATE_BYPASSED;
+	} else if (plhba->fc_flag & FC_OFFLINE_MODE) {
+		hp->PortState = HBA_PORTSTATE_DIAGNOSTICS;
+	} else {
+		switch (phba->hba_state) {
+		case ELX_INIT_START:
+		case ELX_INIT_MBX_CMDS:
+			hp->PortState = HBA_PORTSTATE_UNKNOWN;
+			break;
+
+		case ELX_LINK_DOWN:
+		case ELX_LINK_UP:
+		case ELX_LOCAL_CFG_LINK:
+		case ELX_FLOGI:
+		case ELX_FABRIC_CFG_LINK:
+		case ELX_NS_REG:
+		case ELX_NS_QRY:
+		case ELX_BUILD_DISC_LIST:
+		case ELX_DISC_AUTH:
+		case ELX_CLEAR_LA:
+			hp->PortState = HBA_PORTSTATE_LINKDOWN;
+			break;
+
+		case ELX_HBA_READY:
+			hp->PortState = HBA_PORTSTATE_ONLINE;
+			break;
+
+		case ELX_HBA_ERROR:
+		default:
+			hp->PortState = HBA_PORTSTATE_ERROR;
+			break;
+		}
+	}
+
+	cnt = plhba->fc_map_cnt + plhba->fc_unmap_cnt;
+	hp->NumberofDiscoveredPorts = cnt;
+	if (hsp->cls1.classValid) {
+		hp->PortSupportedClassofService |= 1;	/* bit 1 */
+	}
+
+	if (hsp->cls2.classValid) {
+		hp->PortSupportedClassofService |= 2;	/* bit 2 */
+	}
+
+	if (hsp->cls3.classValid) {
+		hp->PortSupportedClassofService |= 4;	/* bit 3 */
+	}
+
+	hp->PortMaxFrameSize = (((uint32_t) hsp->cmn.bbRcvSizeMsb) << 8) |
+	    (uint32_t) hsp->cmn.bbRcvSizeLsb;
+
+	hp->PortSupportedFc4Types.bits[2] = 0x1;
+	hp->PortSupportedFc4Types.bits[3] = 0x20;
+	hp->PortSupportedFc4Types.bits[7] = 0x1;
+	hp->PortActiveFc4Types.bits[2] = 0x1;
+
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		hp->PortActiveFc4Types.bits[3] = 0x20;
+	}
+
+	hp->PortActiveFc4Types.bits[7] = 0x1;
+
+	/* OSDeviceName is the device info filled into the HBA_OSDN structure */
+	osdn = (HBA_OSDN *) & hp->OSDeviceName[0];
+	memcpy(osdn->drvname, "lpfc", 4);
+	osdn->instance = lpfc_instance[phba->brd_no];
+	osdn->target = (uint32_t) (-1);
+	osdn->lun = (uint32_t) (-1);
+
+	return rc;
+}
+
+int
+lpfc_ioctl_found_port(elxHBA_t * phba,
+		      LPFCHBA_t * plhba,
+		      LPFC_NODELIST_t * pndl,
+		      struct dfc_mem *dm,
+		      MAILBOX_t * pmbox, HBA_PORTATTRIBUTES * hp)
+{
+	ELX_SLI_t *psli = &phba->sli;
+	SERV_PARM *hsp;
+	DMABUF_t *mp;
+	HBA_OSDN *osdn;
+	ELX_MBOXQ_t *mboxq;
+	unsigned long iflag;
+	int mbxstatus;
+	int rc = 0;
+
+	/* Check if its the local port */
+	if (plhba->fc_myDID == pndl->nlp_DID) {
+		/* handle localport */
+		rc = lpfc_ioctl_port_attrib(phba, plhba, dm);
+		return rc;
+	}
+
+	memset((void *)pmbox, 0, sizeof (MAILBOX_t));
+	pmbox->un.varRdRPI.reqRpi = (volatile uint16_t)pndl->nle.nlp_rpi;
+	pmbox->mbxCommand = MBX_READ_RPI64;
+	pmbox->mbxOwner = OWN_HOST;
+	if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+		return ENOMEM;
+	}
+
+	if ((mboxq = (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		return ENOMEM;
+	}
+
+	hsp = (SERV_PARM *) mp->virt;
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+		pmbox->un.varRdRPI.un.sp64.addrHigh = putPaddrHigh(mp->phys);
+		pmbox->un.varRdRPI.un.sp64.addrLow = putPaddrLow(mp->phys);
+		pmbox->un.varRdRPI.un.sp64.tus.f.bdeSize = sizeof (SERV_PARM);
+	} else {
+		pmbox->un.varRdRPI.un.sp.bdeAddress = putPaddrLow(mp->phys);
+		pmbox->un.varRdRPI.un.sp.bdeSize = sizeof (SERV_PARM);
+	}
+
+	memset((void *)mboxq, 0, sizeof (ELX_MBOXQ_t));
+	mboxq->mb.mbxCommand = pmbox->mbxCommand;
+	mboxq->mb.mbxOwner = pmbox->mbxOwner;
+	mboxq->mb.un = pmbox->un;
+	mboxq->mb.us = pmbox->us;
+	mboxq->context1 = (uint8_t *) 0;
+
+	if (plhba->fc_flag & FC_OFFLINE_MODE) {
+		ELX_DRVR_UNLOCK(phba, iflag);
+		mbxstatus = elx_sli_issue_mbox(phba, mboxq, MBX_POLL);
+		ELX_DRVR_LOCK(phba, iflag);
+	} else
+		mbxstatus =
+		    elx_sli_issue_mbox_wait(phba, mboxq, plhba->fc_ratov * 2);
+
+	if (mbxstatus != MBX_SUCCESS) {
+		if (mbxstatus == MBX_TIMEOUT) {
+			/*
+			 * Let SLI layer to release mboxq if mbox command completed after timeout.
+			 */
+			mboxq->mbox_cmpl = 0;
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) mboxq);
+		}
+		return ENODEV;
+	}
+
+	pmbox->mbxCommand = mboxq->mb.mbxCommand;
+	pmbox->mbxOwner = mboxq->mb.mbxOwner;
+	pmbox->un = mboxq->mb.un;
+	pmbox->us = mboxq->mb.us;
+
+	if (hsp->cls1.classValid) {
+		hp->PortSupportedClassofService |= 1;	/* bit 1 */
+	}
+	if (hsp->cls2.classValid) {
+		hp->PortSupportedClassofService |= 2;	/* bit 2 */
+	}
+	if (hsp->cls3.classValid) {
+		hp->PortSupportedClassofService |= 4;	/* bit 3 */
+	}
+
+	hp->PortMaxFrameSize = (((uint32_t) hsp->cmn.bbRcvSizeMsb) << 8) |
+	    (uint32_t) hsp->cmn.bbRcvSizeLsb;
+
+	elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+	elx_mem_put(phba, MEM_MBOX, (uint8_t *) mboxq);
+
+	memcpy((uint8_t *) & hp->NodeWWN, (uint8_t *) & pndl->nlp_nodename,
+	       sizeof (HBA_WWN));
+	memcpy((uint8_t *) & hp->PortWWN, (uint8_t *) & pndl->nlp_portname,
+	       sizeof (HBA_WWN));
+	hp->PortSpeed = 0;
+	/* We only know the speed if the device is on the same loop as us */
+	if (((plhba->fc_myDID & 0xffff00) == (pndl->nlp_DID & 0xffff00)) &&
+	    (plhba->fc_topology == TOPOLOGY_LOOP)) {
+		if (plhba->fc_linkspeed == LA_2GHZ_LINK)
+			hp->PortSpeed = HBA_PORTSPEED_2GBIT;
+		else
+			hp->PortSpeed = HBA_PORTSPEED_1GBIT;
+	}
+
+	hp->PortFcId = pndl->nlp_DID;
+	if ((plhba->fc_flag & FC_FABRIC) &&
+	    ((plhba->fc_myDID & 0xff0000) == (pndl->nlp_DID & 0xff0000))) {
+		/* If remote node is in the same domain we are in */
+		memcpy((uint8_t *) & hp->FabricName,
+		       (uint8_t *) & plhba->fc_fabparam.nodeName,
+		       sizeof (HBA_WWN));
+	}
+	hp->PortState = HBA_PORTSTATE_ONLINE;
+	if (pndl->nlp_flag & NLP_FCP_TARGET) {
+		hp->PortActiveFc4Types.bits[2] = 0x1;
+	}
+	if (pndl->nlp_flag & NLP_IP_NODE) {
+		hp->PortActiveFc4Types.bits[3] = 0x20;
+	}
+	hp->PortActiveFc4Types.bits[7] = 0x1;
+
+	hp->PortType = HBA_PORTTYPE_UNKNOWN;
+	if (plhba->fc_topology == TOPOLOGY_LOOP) {
+		if (plhba->fc_flag & FC_PUBLIC_LOOP) {
+			/* Check if Fabric port */
+			if (lpfc_geportname(&pndl->nlp_nodename,
+					    (NAME_TYPE *) & (plhba->fc_fabparam.
+							     nodeName)) == 2) {
+				hp->PortType = HBA_PORTTYPE_FLPORT;
+			} else {
+				/* Based on DID */
+				if ((pndl->nlp_DID & 0xff) == 0) {
+					hp->PortType = HBA_PORTTYPE_NPORT;
+				} else {
+					if ((pndl->nlp_DID & 0xff0000) !=
+					    0xff0000) {
+						hp->PortType =
+						    HBA_PORTTYPE_NLPORT;
+					}
+				}
+			}
+		} else {
+			hp->PortType = HBA_PORTTYPE_LPORT;
+		}
+	} else {
+		if (plhba->fc_flag & FC_FABRIC) {
+			/* Check if Fabric port */
+			if (lpfc_geportname(&pndl->nlp_nodename,
+					    (NAME_TYPE *) & (plhba->fc_fabparam.
+							     nodeName)) == 2) {
+				hp->PortType = HBA_PORTTYPE_FPORT;
+			} else {
+				/* Based on DID */
+				if ((pndl->nlp_DID & 0xff) == 0) {
+					hp->PortType = HBA_PORTTYPE_NPORT;
+				} else {
+					if ((pndl->nlp_DID & 0xff0000) !=
+					    0xff0000) {
+						hp->PortType =
+						    HBA_PORTTYPE_NLPORT;
+					}
+				}
+			}
+		} else {
+			hp->PortType = HBA_PORTTYPE_PTP;
+		}
+	}
+
+	/* for mapped devices OSDeviceName is device info filled into HBA_OSDN 
+	 * structure */
+	if (pndl->nlp_flag & NLP_MAPPED_LIST) {
+		osdn = (HBA_OSDN *) & hp->OSDeviceName[0];
+		memcpy(osdn->drvname, "lpfc", 4);
+		osdn->instance = lpfc_instance[phba->brd_no];
+		osdn->target = FC_SCSID(pndl->nlp_pan, pndl->nlp_sid);
+		osdn->lun = (uint32_t) (-1);
+	}
+
+	return rc;
+}
+
+int
+lpfc_ioctl_write_pci(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset, cnt;
+	LPFCHBA_t *plhba;
+	int rc = 0;
+	unsigned long iflag;
+	uint8_t *buffer;
+	struct dfc_mem dm_buf;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	cnt = (uint32_t) ((ulong) cip->elx_arg2);
+
+	if (!(plhba->fc_flag & FC_OFFLINE_MODE)) {
+		rc = EPERM;
+		return (rc);
+	}
+
+	if ((cnt + offset) > 256) {
+		rc = ERANGE;
+		return (rc);
+	}
+
+	dm_buf.fc_dataout = NULL;
+	if ((rc = dfc_data_alloc(phba, &dm_buf, 4096))) {
+		return (rc);
+	}
+	buffer = (uint8_t *) dm_buf.fc_dataout;
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) buffer, (uint8_t *) cip->elx_dataout,
+			   cnt)) {
+		ELX_DRVR_LOCK(phba, iflag);
+		rc = EIO;
+		dfc_data_free(phba, &dm_buf);
+		return (rc);
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+	elx_cnt_write_pci(phba, offset, cnt, (uint32_t *) buffer);
+	dfc_data_free(phba, &dm_buf);
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_pci(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset, cnt;
+	int rc = 0;
+
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	cnt = (uint32_t) ((ulong) cip->elx_arg2);
+	if ((cnt + offset) > 256) {
+		rc = ERANGE;
+		return (rc);
+	}
+
+	elx_cnt_read_pci(phba, offset, cnt, (uint32_t *) dm->fc_dataout);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_write_mem(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset, cnt;
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	int rc = 0;
+	unsigned long iflag;
+	struct dfc_mem dm_buf;
+	uint8_t *buffer;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	cnt = (uint32_t) ((ulong) cip->elx_arg2);
+
+	if (!(plhba->fc_flag & FC_OFFLINE_MODE)) {
+		if (offset != 256) {
+			rc = EPERM;
+			return (rc);
+		}
+		/* Allow writing of first 128 bytes after mailbox in online mode */
+		if (cnt > 128) {
+			rc = EPERM;
+			return (rc);
+		}
+	}
+	if (offset >= 4096) {
+		rc = ERANGE;
+		return (rc);
+	}
+	cnt = (uint32_t) ((ulong) cip->elx_arg2);
+	if ((cnt + offset) > 4096) {
+		rc = ERANGE;
+		return (rc);
+	}
+
+	dm_buf.fc_dataout = NULL;
+
+	if ((rc = dfc_data_alloc(phba, &dm_buf, 4096))) {
+		return (rc);
+	} else {
+		buffer = (uint8_t *) dm_buf.fc_dataout;
+	}
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) buffer, (uint8_t *) cip->elx_dataout,
+			   (ulong) cnt)) {
+		rc = EIO;
+		ELX_DRVR_LOCK(phba, iflag);
+		dfc_data_free(phba, &dm_buf);
+		return (rc);
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+		/* copy into SLIM2 */
+		elx_sli_pcimem_bcopy((uint32_t *) buffer,
+				     ((uint32_t *) phba->slim2p.virt + offset),
+				     cnt >> 2);
+	} else {
+		/* First copy command data */
+		(psli->sliinit.elx_sli_write_slim) ((void *)phba,
+						    (void *)buffer, 0, cnt);
+	}
+
+	dfc_data_free(phba, &dm_buf);
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_mem(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset, cnt;
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	int i, rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	cnt = (uint32_t) ((ulong) cip->elx_arg2);
+
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+		/* The SLIM2 size is stored in the next field */
+		i = (uint32_t) (unsigned long)phba->slim2p.next;
+	} else {
+		i = 4096;
+	}
+
+	if (offset >= i) {
+		rc = ERANGE;
+		return (rc);
+	}
+
+	if ((cnt + offset) > i) {
+		/* Adjust cnt instead of error ret */
+		cnt = (i - offset);
+	}
+
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+		/* copy results back to user */
+		elx_sli_pcimem_bcopy((uint32_t *) psli->MBhostaddr,
+				     (uint32_t *) dm->fc_dataout, cnt);
+	} else {
+		/* First copy command data */
+		(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+						   (void *)dm->fc_dataout, 0,
+						   cnt);
+	}
+	return (rc);
+}
+
+int
+lpfc_ioctl_write_ctlreg(elxHBA_t * phba,
+			ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset, incr;
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	incr = (uint32_t) ((ulong) cip->elx_arg2);
+
+	if (!(plhba->fc_flag & FC_OFFLINE_MODE)) {
+		rc = EPERM;
+		return (rc);
+	}
+
+	if (offset > 255) {
+		rc = ERANGE;
+		return (rc);
+	}
+
+	if (offset % 4) {
+		rc = EINVAL;
+		return (rc);
+	}
+
+	lpfc_write_hbaregs_plus_offset(phba, offset, incr);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_ctlreg(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset, incr;
+	int rc = 0;
+
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+
+	if (offset > 255) {
+		rc = ERANGE;
+		return (rc);
+	}
+
+	if (offset % 4) {
+		rc = EINVAL;
+		return (rc);
+	}
+
+	incr = lpfc_read_hbaregs_plus_offset(phba, offset);
+	*((uint32_t *) dm->fc_dataout) = incr;
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_setdiag(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset;
+	LPFCHBA_t *plhba;
+	int rc = 0;
+
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	switch (offset) {
+	case DDI_ONDI:
+		rc = ENXIO;
+		break;
+
+	case DDI_OFFDI:
+		rc = ENXIO;
+		break;
+
+	case DDI_SHOW:
+		rc = ENXIO;
+		break;
+
+	case DDI_BRD_ONDI:
+		if (plhba->fc_flag & FC_OFFLINE_MODE) {
+			lpfc_online(phba);
+		}
+		*((uint32_t *) (dm->fc_dataout)) = DDI_ONDI;
+		break;
+
+	case DDI_BRD_OFFDI:
+		if (!(plhba->fc_flag & FC_OFFLINE_MODE)) {
+			lpfc_offline(phba);
+		}
+		*((uint32_t *) (dm->fc_dataout)) = DDI_OFFDI;
+		break;
+
+	case DDI_BRD_SHOW:
+		if (plhba->fc_flag & FC_OFFLINE_MODE) {
+			*((uint32_t *) (dm->fc_dataout)) = DDI_OFFDI;
+		} else {
+			*((uint32_t *) (dm->fc_dataout)) = DDI_ONDI;
+		}
+		break;
+
+	default:
+		rc = ERANGE;
+		break;
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_lip(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	elxCfgParam_t *clp;
+	ELX_MBOXQ_t *pmboxq;
+	int mbxstatus;
+	int i, rc;
+	unsigned long iflag;
+
+	clp = &phba->config[0];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+
+	rc = 0;
+
+	if ((pmboxq = (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+		return ENOMEM;
+	}
+
+	mbxstatus = MBXERR_ERROR;
+	if (phba->hba_state == ELX_HBA_READY) {
+		/* The HBA is reporting ready.  Pause the scheduler so that
+		 * all outstanding I/Os complete before LIPing.
+		 */
+		elx_sched_pause_hba(phba);
+
+		i = 0;
+		pring = &psli->ring[psli->fcp_ring];
+		while (pring->txcmplq.q_cnt) {
+			if (i++ > 500) {	/* wait up to 5 seconds */
+				break;
+			}
+
+			ELX_DRVR_UNLOCK(phba, iflag);
+			mdelay(10);
+			ELX_DRVR_LOCK(phba, iflag);
+		}
+		memset((void *)pmboxq, 0, sizeof (ELX_MBOXQ_t));
+		lpfc_init_link(phba, pmboxq, clp[LPFC_CFG_TOPOLOGY].a_current,
+			       clp[LPFC_CFG_LINK_SPEED].a_current);
+
+		mbxstatus =
+		    elx_sli_issue_mbox_wait(phba, pmboxq, plhba->fc_ratov * 2);
+		if (mbxstatus == MBX_TIMEOUT) {
+			/*
+			 * Let SLI layer to release mboxq if mbox command completed after timeout.
+			 */
+			pmboxq->mbox_cmpl = 0;
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmboxq);
+		}
+		elx_sched_continue_hba(phba);
+	}
+	memcpy(dm->fc_dataout, (char *)&mbxstatus, sizeof (uint16_t));
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_outfcpio(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	ELXSCSILUN_t *lunp;
+	ELXSCSITARGET_t *targetp;
+	ELX_SCSI_BUF_t *elx_cmd;
+	ELX_SLI_RING_t *pring;
+	ELX_IOCBQ_t *iocb;
+	ELX_IOCBQ_t *next_iocb;
+	IOCB_t *cmd;
+	uint32_t tgt, lun;
+	struct out_fcp_devp *dp;
+	int max;
+	unsigned long iflag;
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+	pring = &psli->ring[psli->fcp_ring];
+
+	memcpy(dm->fc_dataout, (char *)psli, sizeof (ELX_SLI_t));
+	psli = (ELX_SLI_t *) dm->fc_dataout;
+
+	/* Use sliIntr to count number of out_fcp_devp entries */
+	psli->slistat.sliIntr = 0;
+	dp = (struct out_fcp_devp *)(psli + 1);
+	max = cip->elx_outsz - sizeof (ELX_SLI_t);
+	max = (max / sizeof (struct out_fcp_devp));
+
+	for (tgt = 0; tgt < MAX_FCP_TARGET; tgt++) {
+		if ((targetp = plhba->device_queue_hash[tgt])) {
+			lunp = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+			while (lunp) {
+				lun = lunp->lun_id;
+				if (psli->slistat.sliIntr++ >= max)
+					goto outio;
+
+				dp->target = tgt;
+				dp->lun = (ushort) lun;
+
+				dp->qfullcnt = lunp->qfullcnt;
+				dp->qcmdcnt = lunp->qcmdcnt;
+				dp->iodonecnt = lunp->iodonecnt;
+				dp->errorcnt = lunp->errorcnt;
+
+				dp->tx_count = 0;
+				dp->txcmpl_count = 0;
+				dp->delay_count = 0;
+				dp->sched_count =
+				    lunp->lunSched.commandList.q_cnt;
+				dp->lun_qdepth = lunp->lunSched.maxOutstanding;
+				dp->current_qdepth =
+				    lunp->lunSched.currentOutstanding;
+
+				ELX_SLI_LOCK(phba, iflag);
+
+				/* Error matching iocb on txq or txcmplq 
+				 * First check the txq.
+				 */
+				next_iocb = (ELX_IOCBQ_t *) pring->txq.q_f;
+				while (next_iocb !=
+				       (ELX_IOCBQ_t *) & pring->txq) {
+					iocb = next_iocb;
+					next_iocb = next_iocb->q_f;
+					cmd = &iocb->iocb;
+
+					/* Must be a FCP command */
+					if ((cmd->ulpCommand !=
+					     CMD_FCP_ICMND64_CR)
+					    && (cmd->ulpCommand !=
+						CMD_FCP_IWRITE64_CR)
+					    && (cmd->ulpCommand !=
+						CMD_FCP_IREAD64_CR)) {
+						continue;
+					}
+
+					/* context1 MUST be a ELX_SCSI_BUF_t */
+					elx_cmd =
+					    (ELX_SCSI_BUF_t *) (iocb->context1);
+					if ((elx_cmd == 0)
+					    || (elx_cmd->scsi_target != tgt)
+					    || (elx_cmd->scsi_lun != lun)) {
+						continue;
+					}
+					dp->tx_count++;
+				}
+
+				/* Next check the txcmplq */
+				next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+				while (next_iocb !=
+				       (ELX_IOCBQ_t *) & pring->txcmplq) {
+					iocb = next_iocb;
+					next_iocb = next_iocb->q_f;
+					cmd = &iocb->iocb;
+
+					/* Must be a FCP command */
+					if ((cmd->ulpCommand !=
+					     CMD_FCP_ICMND64_CR)
+					    && (cmd->ulpCommand !=
+						CMD_FCP_IWRITE64_CR)
+					    && (cmd->ulpCommand !=
+						CMD_FCP_IREAD64_CR)) {
+						continue;
+					}
+
+					/* context1 MUST be a ELX_SCSI_BUF_t */
+					elx_cmd =
+					    (ELX_SCSI_BUF_t *) (iocb->context1);
+					if ((elx_cmd == 0)
+					    || (elx_cmd->scsi_target != tgt)
+					    || (elx_cmd->scsi_lun != lun)) {
+						continue;
+					}
+
+					dp->txcmpl_count++;
+				}
+				ELX_SLI_UNLOCK(phba, iflag);
+				dp++;
+
+				lunp = lunp->pnextLun;
+			}
+		}
+	}
+      outio:
+	cip->elx_outsz = (sizeof (ELX_SLI_t) +
+			  (psli->slistat.sliIntr *
+			   sizeof (struct out_fcp_devp)));
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_send_scsi_fcp(elxHBA_t * phba,
+			 ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli = &phba->sli;
+	elxCfgParam_t *clp;
+	int reqbfrcnt;
+	int snsbfrcnt;
+	int j = 0;
+	HBA_WWN wwpn;
+	FCP_CMND *fcpcmd;
+	FCP_RSP *fcprsp;
+	ULP_BDE64 *bpl;
+	LPFC_NODELIST_t *pndl;
+	ELX_SLI_RING_t *pring = &psli->ring[LPFC_FCP_RING];
+	ELX_IOCBQ_t *cmdiocbq = 0;
+	ELX_IOCBQ_t *rspiocbq = 0;
+	DMABUFEXT_t *outdmp = 0;
+	IOCB_t *cmd = 0;
+	IOCB_t *rsp = 0;
+	DMABUF_t *mp = 0;
+	DMABUF_t *bmp = 0;
+	int i0;
+	char *outdta;
+	uint32_t clear_count;
+	int rc = 0;
+	unsigned long iflag;
+
+	struct {
+		/* this rspcnt is really data buffer size */
+		uint32_t rspcnt;
+		/* this is sense count in case of LPFC_HBA_SEND_SCSI.
+		 * It is fcp response size in case of LPFC_HBA_SEND_FCP
+		 */
+		uint32_t snscnt;
+	} count;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+    /************************************************************************/
+
+    /************************************************************************/
+	reqbfrcnt = cip->elx_arg4;
+	snsbfrcnt = cip->elx_flag;
+	if ((reqbfrcnt + cip->elx_outsz) > (80 * 4096)) {
+		/* lpfc_ioctl:error <idx> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1604,	/* ptr to msg structure */
+			       elx_mes1604,	/* ptr to msg */
+			       elx_msgBlk1604.msgPreambleStr,	/* begin varargs */
+			       0);	/* end varargs */
+		rc = ERANGE;
+		goto sndsczout;
+	}
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) & wwpn, (uint8_t *) cip->elx_arg3,
+			   (ulong) (sizeof (HBA_WWN)))) {
+		rc = EIO;
+		ELX_DRVR_LOCK(phba, iflag);
+		goto sndsczout;
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	pndl =
+	    lpfc_findnode_wwpn(phba, NLP_SEARCH_MAPPED, (NAME_TYPE *) & wwpn);
+	if (!pndl) {
+		if (!(pndl = lpfc_findnode_wwpn(phba, NLP_SEARCH_UNMAPPED,
+						(NAME_TYPE *) & wwpn))
+		    || !(pndl->nlp_flag & NLP_TGT_NO_SCSIID)) {
+			pndl = (LPFC_NODELIST_t *) 0;
+		}
+	}
+	if (!pndl || !(psli->sliinit.sli_flag & ELX_SLI2_ACTIVE)) {
+		rc = EACCES;
+		goto sndsczout;
+	}
+	if (pndl->nlp_flag & NLP_ELS_SND_MASK) {
+		rc = ENODEV;
+		goto sndsczout;
+	}
+	/* Allocate buffer for command iocb */
+	if ((cmdiocbq =
+	     (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB | MEM_PRI)) == 0) {
+		rc = ENOMEM;
+		goto sndsczout;
+	}
+	memset((void *)cmdiocbq, 0, sizeof (ELX_IOCBQ_t));
+	cmd = &(cmdiocbq->iocb);
+
+	/* Allocate buffer for response iocb */
+	if ((rspiocbq =
+	     (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB | MEM_PRI)) == 0) {
+		rc = ENOMEM;
+		goto sndsczout;
+	}
+	memset((void *)rspiocbq, 0, sizeof (ELX_IOCBQ_t));
+	rsp = &(rspiocbq->iocb);
+
+	/* Allocate buffer for Buffer ptr list */
+	if ((bmp = (DMABUF_t *) elx_mem_get(phba, MEM_BPL)) == 0) {
+		rc = ENOMEM;
+		goto sndsczout;
+	}
+	bpl = (ULP_BDE64 *) bmp->virt;
+
+	/* Allocate buffer for FCP CMND / FCP RSP */
+	if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF | MEM_PRI)) == 0) {
+		rc = ENOMEM;
+		goto sndsczout;
+	}
+	fcpcmd = (FCP_CMND *) mp->virt;
+	fcprsp = (FCP_RSP *) ((uint8_t *) mp->virt + sizeof (FCP_CMND));
+	memset((void *)fcpcmd, 0, sizeof (FCP_CMND) + sizeof (FCP_RSP));
+
+	/* Setup FCP CMND and FCP RSP */
+	bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(mp->phys));
+	bpl->addrLow = PCIMEM_LONG(putPaddrLow(mp->phys));
+	bpl->tus.f.bdeSize = sizeof (FCP_CMND);
+	bpl->tus.f.bdeFlags = BUFF_USE_CMND;
+	bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+	bpl++;
+	bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(mp->phys + sizeof (FCP_CMND)));
+	bpl->addrLow = PCIMEM_LONG(putPaddrLow(mp->phys + sizeof (FCP_CMND)));
+	bpl->tus.f.bdeSize = sizeof (FCP_RSP);
+	bpl->tus.f.bdeFlags = (BUFF_USE_CMND | BUFF_USE_RCV);
+	bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+	bpl++;
+
+    /************************************************************************/
+	/* Copy user data into fcpcmd buffer at this point to see if its a read */
+	/*  or a write.                                                         */
+    /************************************************************************/
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) fcpcmd, (uint8_t *) cip->elx_arg1,
+			   (ulong) (reqbfrcnt))) {
+		rc = EIO;
+		ELX_DRVR_LOCK(phba, iflag);
+		goto sndsczout;
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	outdta = (fcpcmd->fcpCntl3 == WRITE_DATA ? cip->elx_dataout : 0);
+
+	/* Allocate data buffer, and fill it if its a write */
+	if (cip->elx_outsz == 0) {
+		outdmp = dfc_cmd_data_alloc(phba, outdta, bpl, 512);
+	} else {
+		outdmp = dfc_cmd_data_alloc(phba, outdta, bpl, cip->elx_outsz);
+	}
+	if (outdmp == 0) {
+		rc = ENOMEM;
+		goto sndsczout;
+	}
+
+	cmd->un.fcpi64.bdl.ulpIoTag32 = 0;
+	cmd->un.fcpi64.bdl.addrHigh = putPaddrHigh(bmp->phys);
+	cmd->un.fcpi64.bdl.addrLow = putPaddrLow(bmp->phys);
+	cmd->un.fcpi64.bdl.bdeSize = (3 * sizeof (ULP_BDE64));
+	cmd->un.fcpi64.bdl.bdeFlags = BUFF_TYPE_BDL;
+	cmd->ulpBdeCount = 1;
+	cmd->ulpContext = pndl->nle.nlp_rpi;
+	cmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+	cmd->ulpClass = pndl->nle.nlp_fcp_info & 0x0f;
+	cmd->ulpOwner = OWN_CHIP;
+	cmd->ulpTimeout =
+	    clp[LPFC_CFG_SCSI_REQ_TMO].a_current + phba->fcp_timeout_offset;
+	cmd->ulpLe = 1;
+	if (pndl->nle.nlp_fcp_info & NLP_FCP_2_DEVICE) {
+		cmd->ulpFCP2Rcvy = 1;
+	}
+	switch (fcpcmd->fcpCntl3) {
+	case READ_DATA:	/* Set up for SCSI read */
+		cmd->ulpCommand = CMD_FCP_IREAD64_CR;
+		cmd->ulpPU = PARM_READ_CHECK;
+		cmd->un.fcpi.fcpi_parm = cip->elx_outsz;
+		cmd->un.fcpi64.bdl.bdeSize =
+		    ((outdmp->flag + 2) * sizeof (ULP_BDE64));
+		break;
+	case WRITE_DATA:	/* Set up for SCSI write */
+		cmd->ulpCommand = CMD_FCP_IWRITE64_CR;
+		cmd->un.fcpi64.bdl.bdeSize =
+		    ((outdmp->flag + 2) * sizeof (ULP_BDE64));
+		break;
+	default:		/* Set up for SCSI command */
+		cmd->ulpCommand = CMD_FCP_ICMND64_CR;
+		cmd->un.fcpi64.bdl.bdeSize = (2 * sizeof (ULP_BDE64));
+		break;
+	}
+	cmdiocbq->context1 = (uint8_t *) 0;
+	cmdiocbq->iocb_flag |= ELX_IO_IOCTL;
+
+    /************************************************************************/
+	/* send scsi command, retry 3 times on getting IOCB_BUSY, or            */
+	/*  or IOCB_TIMEOUT frm issue_iocb                                      */
+    /************************************************************************/
+	for (rc = -1, i0 = 0; i0 < 4 && rc != IOCB_SUCCESS; i0++) {
+		rc = elx_sli_issue_iocb_wait(phba, pring, cmdiocbq,
+					     SLI_IOCB_USE_TXQ, rspiocbq,
+					     clp[LPFC_CFG_SCSI_REQ_TMO].
+					     a_current +
+					     phba->fcp_timeout_offset +
+					     ELX_DRVR_TIMEOUT);
+		if (rc == IOCB_ERROR) {
+			rc = EACCES;
+			break;
+		}
+	}
+
+	if (rc != IOCB_SUCCESS) {
+		rc = EACCES;
+		goto sndsczout;
+	}
+
+	/* For LPFC_HBA_SEND_FCP, just return FCP_RSP unless we got
+	 * an IOSTAT_LOCAL_REJECT.
+	 *
+	 * For SEND_FCP case, snscnt is really FCP_RSP length. In the
+	 * switch statement below, the snscnt should not get destroyed.
+	 */
+	if (cmd->ulpCommand == CMD_FCP_IWRITE64_CX) {
+		clear_count = (rsp->ulpStatus == IOSTAT_SUCCESS ? 1 : 0);
+	} else {
+		clear_count = cmd->un.fcpi.fcpi_parm;
+	}
+	if ((cip->elx_cmd == LPFC_HBA_SEND_FCP) &&
+	    (rsp->ulpStatus != IOSTAT_LOCAL_REJECT)) {
+		if (snsbfrcnt < sizeof (FCP_RSP)) {
+			count.snscnt = snsbfrcnt;
+		} else {
+			count.snscnt = sizeof (FCP_RSP);
+		}
+		ELX_DRVR_UNLOCK(phba, iflag);
+		if (copy_to_user((uint8_t *) cip->elx_arg2, (uint8_t *) fcprsp,
+				 count.snscnt)) {
+			rc = EIO;
+			ELX_DRVR_LOCK(phba, iflag);
+			goto sndsczout;
+		}
+		ELX_DRVR_LOCK(phba, iflag);
+	}
+	switch (rsp->ulpStatus) {
+	case IOSTAT_SUCCESS:
+	      cpdata:
+		if (cip->elx_outsz < clear_count) {
+			cip->elx_outsz = 0;
+			rc = ERANGE;
+			break;
+		}
+		cip->elx_outsz = clear_count;
+		if (cip->elx_cmd == LPFC_HBA_SEND_SCSI) {
+			count.rspcnt = cip->elx_outsz;
+			count.snscnt = 0;
+		} else {	/* For LPFC_HBA_SEND_FCP, snscnt is already set */
+			count.rspcnt = cip->elx_outsz;
+		}
+		ELX_DRVR_UNLOCK(phba, iflag);
+		/* Return data length */
+		if (copy_to_user((uint8_t *) cip->elx_arg3, (uint8_t *) & count,
+				 (2 * sizeof (uint32_t)))) {
+			rc = EIO;
+			ELX_DRVR_LOCK(phba, iflag);
+			break;
+		}
+		ELX_DRVR_LOCK(phba, iflag);
+		cip->elx_outsz = 0;
+		if (count.rspcnt) {
+			if (dfc_rsp_data_copy
+			    (phba, (uint8_t *) cip->elx_dataout, outdmp,
+			     count.rspcnt)) {
+				rc = EIO;
+				break;
+			}
+		}
+		break;
+	case IOSTAT_LOCAL_REJECT:
+		cip->elx_outsz = 0;
+		if (rsp->un.grsp.perr.statLocalError == IOERR_SEQUENCE_TIMEOUT) {
+			rc = ETIMEDOUT;
+			break;
+		}
+		rc = EFAULT;
+		goto sndsczout;	/* count.rspcnt and count.snscnt is already 0 */
+	case IOSTAT_FCP_RSP_ERROR:
+		/* at this point, clear_count is the residual count. 
+		 * We are changing it to the amount actually xfered.
+		 */
+		if (fcpcmd->fcpCntl3 == READ_DATA) {
+			if ((fcprsp->rspStatus2 & RESID_UNDER)
+			    && (fcprsp->rspStatus3 == SCSI_STAT_GOOD)) {
+				goto cpdata;
+			}
+		} else {
+			clear_count = 0;
+		}
+		count.rspcnt = (uint32_t) clear_count;
+		cip->elx_outsz = 0;
+		if (fcprsp->rspStatus2 & RSP_LEN_VALID) {
+			j = SWAP_DATA(fcprsp->rspRspLen);
+		}
+		if (fcprsp->rspStatus2 & SNS_LEN_VALID) {
+			if (cip->elx_cmd == LPFC_HBA_SEND_SCSI) {
+				if (snsbfrcnt < SWAP_DATA(fcprsp->rspSnsLen))
+					count.snscnt = snsbfrcnt;
+				else
+					count.snscnt =
+					    SWAP_DATA(fcprsp->rspSnsLen);
+				/* Return sense info from rsp packet */
+				ELX_DRVR_UNLOCK(phba, iflag);
+				if (copy_to_user
+				    ((uint8_t *) cip->elx_arg2,
+				     ((uint8_t *) & fcprsp->rspInfo0) + j,
+				     count.snscnt)) {
+					rc = EIO;
+					ELX_DRVR_LOCK(phba, iflag);
+					break;
+				}
+				ELX_DRVR_LOCK(phba, iflag);
+			}
+		} else {
+			rc = EFAULT;
+			break;
+		}
+		ELX_DRVR_UNLOCK(phba, iflag);
+		if (copy_to_user(	/* return data length */
+					(uint8_t *) cip->elx_arg3,
+					(uint8_t *) & count,
+					(2 * sizeof (uint32_t)))) {
+			rc = EIO;
+			ELX_DRVR_LOCK(phba, iflag);
+			break;
+		}
+		ELX_DRVR_LOCK(phba, iflag);
+		if (count.rspcnt) {	/* return data for read */
+			if (dfc_rsp_data_copy
+			    (phba, (uint8_t *) cip->elx_dataout, outdmp,
+			     count.rspcnt)) {
+				rc = EIO;
+				break;
+			}
+		}
+		break;
+	default:
+		cip->elx_outsz = 0;
+		rc = EFAULT;
+		break;
+	}
+      sndsczout:
+	DFC_CMD_DATA_FREE(phba, outdmp);
+	ELX_MEM_PUT(phba, MEM_BUF, (uint8_t *) mp);
+	ELX_MEM_PUT(phba, MEM_BPL, (uint8_t *) bmp);
+	ELX_MEM_PUT(phba, MEM_IOCB, (uint8_t *) cmdiocbq);
+	ELX_MEM_PUT(phba, MEM_IOCB, (uint8_t *) rspiocbq);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_send_els(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	uint32_t did;
+	uint32_t opcode;
+	LPFC_BINDLIST_t *blp;
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *pndl;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	did = (uint32_t) ((ulong) cip->elx_arg1);
+	opcode = (uint32_t) ((ulong) cip->elx_arg2);
+	did = (did & Mask_DID);
+
+	if (((pndl = lpfc_findnode_did(phba, NLP_SEARCH_ALL, did))) == 0) {
+		if ((pndl = (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP))) {
+			memset((void *)pndl, 0, sizeof (LPFC_NODELIST_t));
+			pndl->nlp_DID = did;
+			pndl->nlp_state = NLP_STE_UNUSED_NODE;
+			blp = pndl->nlp_listp_bind;
+			if (blp) {
+				lpfc_nlp_bind(phba, blp);
+			}
+		} else {
+			rc = ENOMEM;
+			return (rc);
+		}
+	}
+
+	switch (opcode) {
+	case ELS_CMD_PLOGI:
+		lpfc_issue_els_plogi(phba, pndl, 0);
+		break;
+	case ELS_CMD_LOGO:
+		lpfc_issue_els_logo(phba, pndl, 0);
+		break;
+	case ELS_CMD_ADISC:
+		lpfc_issue_els_adisc(phba, pndl, 0);
+		break;
+	default:
+		break;
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_send_mgmt_rsp(elxHBA_t * phba,
+			 ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	ULP_BDE64 *bpl;
+	DMABUF_t *bmp;
+	DMABUFEXT_t *indmp;
+	LPFCHBA_t *plhba;
+	uint32_t tag;
+	int reqbfrcnt;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	tag = (uint32_t) cip->elx_flag;	/* XRI for XMIT_SEQUENCE */
+	reqbfrcnt = (uint32_t) ((ulong) cip->elx_arg2);
+
+	if ((reqbfrcnt == 0) || (reqbfrcnt > (80 * 4096))) {
+		rc = ERANGE;
+		return (rc);
+	}
+
+	/* Allocate buffer for Buffer ptr list */
+	if ((bmp = (DMABUF_t *) elx_mem_get(phba, MEM_BPL)) == 0) {
+		rc = ENOMEM;
+		return (rc);
+	}
+	bpl = (ULP_BDE64 *) bmp->virt;
+
+	if ((indmp =
+	     dfc_cmd_data_alloc(phba, (char *)cip->elx_arg1, bpl,
+				reqbfrcnt)) == 0) {
+		elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+		rc = ENOMEM;
+		return (rc);
+	}
+	/* flag contains total number of BPLs for xmit */
+	if ((rc = lpfc_issue_ct_rsp(phba, tag, bmp, indmp))) {
+		if (rc == IOCB_TIMEDOUT)
+			rc = ETIMEDOUT;
+		else if (rc == IOCB_ERROR)
+			rc = EACCES;
+	}
+
+	dfc_cmd_data_free(phba, indmp);
+	elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_send_mgmt_cmd(elxHBA_t * phba,
+			 ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *pndl;
+	ULP_BDE64 *bpl;
+	HBA_WWN findwwn;
+	uint32_t finddid;
+	ELX_IOCBQ_t *cmdiocbq = 0;	/* Initialize the command iocb queue to a NULL default. */
+	ELX_IOCBQ_t *rspiocbq = 0;	/* Initialize the response iocb queue to a NULL default. */
+	DMABUFEXT_t *indmp = 0;
+	DMABUFEXT_t *outdmp = 0;
+	IOCB_t *cmd = 0;
+	IOCB_t *rsp = 0;
+	DMABUF_t *mp = 0;
+	DMABUF_t *bmp = 0;
+	ELX_SLI_t *psli = &phba->sli;
+	ELX_SLI_RING_t *pring = &psli->ring[LPFC_ELS_RING];	/* els ring */
+	int i0, rc = 0;
+	int reqbfrcnt;
+	int snsbfrcnt;
+	uint32_t timeout;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	reqbfrcnt = cip->elx_arg4;
+	snsbfrcnt = cip->elx_arg5;
+
+	if (!(reqbfrcnt) || !(snsbfrcnt)
+	    || (reqbfrcnt + snsbfrcnt) > (80 * 4096)) {
+		rc = ERANGE;
+		goto sndmgtqwt;
+	}
+
+	if (cip->elx_cmd == LPFC_HBA_SEND_MGMT_CMD) {
+
+		ELX_DRVR_UNLOCK(phba, iflag);
+		if (copy_from_user
+		    ((uint8_t *) & findwwn, (uint8_t *) cip->elx_arg3,
+		     (ulong) (sizeof (HBA_WWN)))) {
+			rc = EIO;
+			ELX_DRVR_LOCK(phba, iflag);
+			goto sndmgtqwt;
+		}
+		ELX_DRVR_LOCK(phba, iflag);
+
+		pndl =
+		    lpfc_findnode_wwpn(phba,
+				       NLP_SEARCH_MAPPED | NLP_SEARCH_UNMAPPED,
+				       (NAME_TYPE *) & findwwn);
+		if (!pndl) {
+			rc = ENODEV;
+			goto sndmgtqwt;
+		}
+	} else {
+		finddid = (uint32_t) ((unsigned long)cip->elx_arg3);
+		if (!(pndl = lpfc_findnode_did(phba,
+					       NLP_SEARCH_MAPPED |
+					       NLP_SEARCH_UNMAPPED, finddid))) {
+			rc = ENODEV;
+			goto sndmgtqwt;
+		}
+	}
+	if (!pndl || !(psli->sliinit.sli_flag & ELX_SLI2_ACTIVE)) {
+		rc = EACCES;
+		goto sndmgtqwt;
+	}
+	if (pndl->nlp_flag & NLP_ELS_SND_MASK) {
+		rc = ENODEV;
+		goto sndmgtqwt;
+	}
+	if ((cmdiocbq =
+	     (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB | MEM_PRI)) == 0) {
+		rc = ENOMEM;
+		goto sndmgtqwt;
+	}
+	memset((void *)cmdiocbq, 0, sizeof (ELX_IOCBQ_t));
+	cmd = &(cmdiocbq->iocb);
+
+	if ((rspiocbq =
+	     (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB | MEM_PRI)) == 0) {
+		rc = ENOMEM;
+		goto sndmgtqwt;
+	}
+	memset((void *)rspiocbq, 0, sizeof (ELX_IOCBQ_t));
+	rsp = &(rspiocbq->iocb);
+
+	if ((bmp = (DMABUF_t *) elx_mem_get(phba, MEM_BPL)) == 0) {
+		rc = ENOMEM;
+		goto sndmgtqwt;
+	}
+	bpl = (ULP_BDE64 *) bmp->virt;
+	if ((indmp = dfc_cmd_data_alloc(phba, (char *)cip->elx_arg1, bpl,
+					reqbfrcnt)) == 0) {
+		elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+		rc = ENOMEM;
+		goto sndmgtqwt;
+	}
+	bpl += indmp->flag;	/* flag contains total number of BPLs for xmit */
+	if ((outdmp = dfc_cmd_data_alloc(phba, 0, bpl, snsbfrcnt)) == 0) {
+		dfc_cmd_data_free(phba, indmp);
+		elx_mem_put(phba, MEM_BPL, (uint8_t *) bmp);
+		rc = ENOMEM;
+		goto sndmgtqwt;
+	}
+
+	cmd->un.genreq64.bdl.ulpIoTag32 = 0;
+	cmd->un.genreq64.bdl.addrHigh = putPaddrHigh(bmp->phys);
+	cmd->un.genreq64.bdl.addrLow = putPaddrLow(bmp->phys);
+	cmd->un.genreq64.bdl.bdeFlags = BUFF_TYPE_BDL;
+	cmd->un.genreq64.bdl.bdeSize =
+	    (outdmp->flag + indmp->flag) * sizeof (ULP_BDE64);
+	cmd->ulpCommand = CMD_GEN_REQUEST64_CR;
+	cmd->un.genreq64.w5.hcsw.Fctl = (SI | LA);
+	cmd->un.genreq64.w5.hcsw.Dfctl = 0;
+	cmd->un.genreq64.w5.hcsw.Rctl = FC_UNSOL_CTL;
+	cmd->un.genreq64.w5.hcsw.Type = FC_COMMON_TRANSPORT_ULP;
+	cmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+	cmd->ulpTimeout = cip->elx_flag;
+	cmd->ulpBdeCount = 1;
+	cmd->ulpLe = 1;
+	cmd->ulpClass = CLASS3;
+	cmd->ulpContext = pndl->nle.nlp_rpi;
+	cmd->ulpOwner = OWN_CHIP;
+	cmdiocbq->context1 = (uint8_t *) 0;
+	cmdiocbq->context2 = (uint8_t *) 0;
+	cmdiocbq->iocb_flag |= ELX_IO_IOCTL;
+
+	if (cip->elx_flag < (plhba->fc_ratov * 2 + ELX_DRVR_TIMEOUT)) {
+		timeout = plhba->fc_ratov * 2 + ELX_DRVR_TIMEOUT;
+	} else {
+		timeout = cip->elx_flag;
+	}
+
+	for (rc = -1, i0 = 0; i0 < 4 && rc != IOCB_SUCCESS; i0++) {
+		rc = elx_sli_issue_iocb_wait(phba, pring, cmdiocbq,
+					     SLI_IOCB_USE_TXQ, rspiocbq,
+					     timeout);
+		if (rc == IOCB_ERROR) {
+			rc = EACCES;
+			goto sndmgtqwt;
+		}
+	}
+
+	if (rc != IOCB_SUCCESS) {
+		goto sndmgtqwt;
+	}
+	if (rsp->ulpStatus) {
+		if (rsp->ulpStatus == IOSTAT_LOCAL_REJECT) {
+			switch (rsp->un.ulpWord[4] & 0xff) {
+			case IOERR_SEQUENCE_TIMEOUT:
+				rc = ETIMEDOUT;
+				break;
+			case IOERR_INVALID_RPI:
+				rc = EFAULT;
+				break;
+			default:
+				rc = EACCES;
+				break;
+			}
+
+			goto sndmgtqwt;
+		}
+	} else {
+		outdmp->flag = rsp->un.genreq64.bdl.bdeSize;
+	}
+	if (outdmp->flag > snsbfrcnt) {	/* copy back response data */
+		rc = ERANGE;	/* C_CT Request error */
+		elx_printf_log(phba->brd_no, &elx_msgBlk1208,	/* ptr to msg structure */
+			       elx_mes1208,	/* ptr to msg */
+			       elx_msgBlk1208.msgPreambleStr,	/* begin varargs */
+			       outdmp->flag, 4096);	/* end varargs */
+		goto sndmgtqwt;
+	}
+	/* copy back size of response, and response itself */
+	memcpy(dm->fc_dataout, (char *)&outdmp->flag, sizeof (int));
+	if (dfc_rsp_data_copy
+	    (phba, (uint8_t *) cip->elx_arg2, outdmp, outdmp->flag)) {
+		rc = EIO;
+		goto sndmgtqwt;
+	}
+      sndmgtqwt:
+	DFC_CMD_DATA_FREE(phba, indmp);
+	DFC_CMD_DATA_FREE(phba, outdmp);
+	ELX_MEM_PUT(phba, MEM_BUF, (uint8_t *) mp);
+	ELX_MEM_PUT(phba, MEM_BPL, (uint8_t *) bmp);
+	ELX_MEM_PUT(phba, MEM_IOCB, (uint8_t *) cmdiocbq);
+	ELX_MEM_PUT(phba, MEM_IOCB, (uint8_t *) rspiocbq);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_mbox(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	MAILBOX_t *pmbox;
+	uint32_t size;
+	elx_dma_addr_t lptr;
+	struct dfc_info *di;
+	LPFCHBA_t *plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ELX_MBOXQ_t *pmboxq;
+	DMABUF_t *pbfrnfo;
+	unsigned long iflag;
+	int count = 0;
+	int rc = 0;
+	int mbxstatus = 0;
+
+	/* Allocate mbox structure */
+	if ((pmbox =
+	     (MAILBOX_t *) elx_mem_get(phba, (MEM_MBOX | MEM_PRI))) == 0) {
+		return (1);
+	}
+
+	/* Allocate mboxq structure */
+	if ((pmboxq =
+	     (ELX_MBOXQ_t *) elx_mem_get(phba, (MEM_MBOX | MEM_PRI))) == 0) {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmbox);
+		return (1);
+	}
+
+	/* Allocate mbuf structure */
+	if ((pbfrnfo = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmbox);
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmboxq);
+		return (1);
+	}
+
+	di = &dfc.dfc_info[cip->elx_brd];
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) pmbox, (uint8_t *) cip->elx_arg1,
+			   MAILBOX_CMD_WSIZE * sizeof (uint32_t))) {
+		ELX_DRVR_LOCK(phba, iflag);
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmbox);
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmboxq);
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) pbfrnfo);
+		rc = EIO;
+
+		return (rc);
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	while (di->fc_flag & DFC_MBOX_ACTIVE) {
+		ELX_DRVR_UNLOCK(phba, iflag);
+		elx_sleep_ms(phba, 5);
+		ELX_DRVR_LOCK(phba, iflag);
+		if (count++ == 200)
+			break;
+	}
+
+	if (count >= 200) {
+		pmbox->mbxStatus = MBXERR_ERROR;
+		rc = EBUSY;
+		goto mbout_err;
+	} else {
+#ifdef _LP64
+		if ((pmbox->mbxCommand == MBX_READ_SPARM) ||
+		    (pmbox->mbxCommand == MBX_READ_RPI) ||
+		    (pmbox->mbxCommand == MBX_REG_LOGIN) ||
+		    (pmbox->mbxCommand == MBX_READ_LA)) {
+			/* Must use 64 bit versions of these mbox cmds */
+			pmbox->mbxStatus = MBXERR_ERROR;
+			rc = ENODEV;
+			goto mbout_err;
+		}
+#endif
+		di->fc_flag |= DFC_MBOX_ACTIVE;
+		lptr = 0;
+		size = 0;
+		switch (pmbox->mbxCommand) {
+			/* Offline only */
+		case MBX_WRITE_NV:
+		case MBX_INIT_LINK:
+		case MBX_DOWN_LINK:
+		case MBX_CONFIG_LINK:
+		case MBX_CONFIG_RING:
+		case MBX_RESET_RING:
+		case MBX_UNREG_LOGIN:
+		case MBX_CLEAR_LA:
+		case MBX_DUMP_CONTEXT:
+		case MBX_RUN_DIAGS:
+		case MBX_RESTART:
+		case MBX_FLASH_WR_ULA:
+		case MBX_SET_MASK:
+		case MBX_SET_SLIM:
+		case MBX_SET_DEBUG:
+			if (!(plhba->fc_flag & FC_OFFLINE_MODE)) {
+				pmbox->mbxStatus = MBXERR_ERROR;
+				di->fc_flag &= ~DFC_MBOX_ACTIVE;
+				goto mbout_err;
+			}
+			break;
+
+			/* Online / Offline */
+		case MBX_LOAD_SM:
+		case MBX_READ_NV:
+		case MBX_READ_CONFIG:
+		case MBX_READ_RCONFIG:
+		case MBX_READ_STATUS:
+		case MBX_READ_XRI:
+		case MBX_READ_REV:
+		case MBX_READ_LNK_STAT:
+		case MBX_DUMP_MEMORY:
+		case MBX_DOWN_LOAD:
+		case MBX_UPDATE_CFG:
+		case MBX_LOAD_AREA:
+		case MBX_LOAD_EXP_ROM:
+			break;
+
+			/* Online / Offline - with DMA */
+		case MBX_READ_SPARM64:
+			lptr =
+			    (elx_dma_addr_t) getPaddr(pmbox->un.varRdSparm.un.
+						      sp64.addrHigh,
+						      pmbox->un.varRdSparm.un.
+						      sp64.addrLow);
+			size = (int)pmbox->un.varRdSparm.un.sp64.tus.f.bdeSize;
+			if (lptr) {
+				pmbox->un.varRdSparm.un.sp64.addrHigh =
+				    putPaddrHigh(pbfrnfo->phys);
+				pmbox->un.varRdSparm.un.sp64.addrLow =
+				    putPaddrLow(pbfrnfo->phys);
+			}
+			break;
+
+		case MBX_READ_RPI64:
+			/* This is only allowed when online is SLI2 mode */
+			lptr =
+			    (elx_dma_addr_t) getPaddr(pmbox->un.varRdRPI.un.
+						      sp64.addrHigh,
+						      pmbox->un.varRdRPI.un.
+						      sp64.addrLow);
+			size = (int)pmbox->un.varRdRPI.un.sp64.tus.f.bdeSize;
+			if (lptr) {
+				pmbox->un.varRdRPI.un.sp64.addrHigh =
+				    putPaddrHigh(pbfrnfo->phys);
+				pmbox->un.varRdRPI.un.sp64.addrLow =
+				    putPaddrLow(pbfrnfo->phys);
+			}
+			break;
+
+		case MBX_READ_LA:
+		case MBX_READ_LA64:
+		case MBX_REG_LOGIN:
+		case MBX_REG_LOGIN64:
+		case MBX_CONFIG_PORT:
+		case MBX_RUN_BIU_DIAG:
+			/* Do not allow SLI-2 commands */
+			pmbox->mbxStatus = MBXERR_ERROR;
+			di->fc_flag &= ~DFC_MBOX_ACTIVE;
+			goto mbout_err;
+
+		default:
+			/* Offline only
+			 * Let firmware return error for unsupported commands
+			 */
+			if (!(plhba->fc_flag & FC_OFFLINE_MODE)) {
+				pmbox->mbxStatus = MBXERR_ERROR;
+				di->fc_flag &= ~DFC_MBOX_ACTIVE;
+				goto mbout_err;
+			}
+			break;
+		}		/* switch pmbox->command */
+
+		{
+			MAILBOX_t *pmb = &pmboxq->mb;
+
+			memset((void *)pmboxq, 0, sizeof (ELX_MBOXQ_t));
+			pmb->mbxCommand = pmbox->mbxCommand;
+			pmb->mbxOwner = pmbox->mbxOwner;
+			pmb->un = pmbox->un;
+			pmb->us = pmbox->us;
+			pmboxq->context1 = (uint8_t *) 0;
+			if (plhba->fc_flag & FC_OFFLINE_MODE) {
+				ELX_DRVR_UNLOCK(phba, iflag);
+				mbxstatus =
+				    elx_sli_issue_mbox(phba, pmboxq, MBX_POLL);
+				ELX_DRVR_LOCK(phba, iflag);
+			} else
+				mbxstatus =
+				    elx_sli_issue_mbox_wait(phba, pmboxq,
+							    ELX_MBOX_TMO);
+			di->fc_flag &= ~DFC_MBOX_ACTIVE;
+			if (mbxstatus != MBX_SUCCESS) {
+				/* Not successful */
+				goto mbout;
+			}
+
+		}
+
+		if (lptr) {
+			ELX_DRVR_UNLOCK(phba, iflag);
+			if ((copy_to_user
+			     ((uint8_t *) & lptr, (uint8_t *) pbfrnfo->virt,
+			      (ulong) size))) {
+				rc = EIO;
+			}
+			ELX_DRVR_LOCK(phba, iflag);
+		}
+	}
+
+      mbout:
+	{
+		MAILBOX_t *pmb = &pmboxq->mb;
+
+		memcpy(dm->fc_dataout, (char *)pmb,
+		       MAILBOX_CMD_WSIZE * sizeof (uint32_t));
+	}
+
+	goto mbout_freemem;
+
+      mbout_err:
+	{
+		/* Jump here only if there is an error and copy the status */
+		memcpy(dm->fc_dataout, (char *)pmbox,
+		       MAILBOX_CMD_WSIZE * sizeof (uint32_t));
+	}
+
+      mbout_freemem:
+	/* Free allocated mbox memory */
+	if (pmbox)
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmbox);
+
+	/* Free allocated mboxq memory */
+	if (pmboxq) {
+		if (mbxstatus == MBX_TIMEOUT) {
+			/*
+			 * Let SLI layer to release mboxq if mbox command completed after timeout.
+			 */
+			pmboxq->mbox_cmpl = 0;
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmboxq);
+		}
+	}
+
+	/* Free allocated mbuf memory */
+	if (pbfrnfo)
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) pbfrnfo);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_display_pci_all(elxHBA_t * phba,
+			   ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	int cnt, offset, rc = 0;
+
+	cnt = 256;
+	offset = 0;
+	elx_cnt_read_pci(phba, offset, cnt, (uint32_t *) dm->fc_dataout);
+	return (rc);
+}
+
+int
+lpfc_ioctl_write_hc(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t incr;
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+
+	incr = (uint32_t) ((ulong) cip->elx_arg1);
+	(psli->sliinit.elx_sli_write_HC) (phba, incr);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_hc(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset;
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+
+	offset = (psli->sliinit.elx_sli_read_HC) (phba);
+	*((uint32_t *) dm->fc_dataout) = offset;
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_write_hs(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t incr;
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+
+	incr = (uint32_t) ((ulong) cip->elx_arg1);
+	(psli->sliinit.elx_sli_write_HS) (phba, incr);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_hs(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset;
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+
+	offset = (psli->sliinit.elx_sli_read_HS) (phba);
+	*((uint32_t *) dm->fc_dataout) = offset;
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_write_ha(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t incr;
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+
+	incr = (uint32_t) ((ulong) cip->elx_arg1);
+	(psli->sliinit.elx_sli_write_HA) (phba, incr);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_ha(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset;
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+
+	offset = (psli->sliinit.elx_sli_read_HA) (phba);
+	*((uint32_t *) dm->fc_dataout) = offset;
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_write_ca(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t incr;
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+
+	incr = (uint32_t) ((ulong) cip->elx_arg1);
+	(psli->sliinit.elx_sli_write_CA) (phba, incr);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_ca(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset;
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+
+	offset = (psli->sliinit.elx_sli_read_CA) (phba);
+	*((uint32_t *) dm->fc_dataout) = offset;
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_mb(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	ELX_SLI_t *psli = &phba->sli;
+	int rc = 0;
+	MAILBOX_t *pmbox;
+	struct dfc_mem mbox_dm;
+
+	/* Allocate mboxq structure */
+	mbox_dm.fc_dataout = NULL;
+	if ((rc = dfc_data_alloc(phba, &mbox_dm, sizeof (MAILBOX_t))))
+		return (rc);
+	else
+		pmbox = (MAILBOX_t *) mbox_dm.fc_dataout;
+
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+		/* copy results back to user */
+		elx_sli_pcimem_bcopy((uint32_t *) pmbox, dm->fc_dataout,
+				     (sizeof (uint32_t) * (MAILBOX_CMD_WSIZE)));
+		elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+				 sizeof (MAILBOX_t), ELX_DMA_SYNC_FORDEV);
+	} else {
+		/* First copy command data */
+		(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+						   (void *)dm->fc_dataout, 0,
+						   MAILBOX_CMD_WSIZE);
+	}
+
+	/* Free allocated mbox memory */
+	if (pmbox)
+		dfc_data_free(phba, &mbox_dm);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_dbg(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t offset;
+	int rc = 0;
+
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	switch (offset) {
+	case 0xffffffff:
+		break;
+	default:
+		fc_dbg_flag = offset;
+		break;
+	}
+
+	memcpy(dm->fc_dataout, (uint8_t *) & fc_dbg_flag, sizeof (uint32_t));
+	return (rc);
+}
+
+int
+lpfc_ioctl_inst(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	int rc = 0;
+
+	memcpy(dm->fc_dataout, (uint8_t *) & lpfc_instcnt, sizeof (int));
+	memcpy(((uint8_t *) dm->fc_dataout) + sizeof (int),
+	       (uint8_t *) lpfc_instance, sizeof (int) * MAX_ELX_BRDS);
+	return (rc);
+}
+
+int
+lpfc_ioctl_listn(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	LPFC_BINDLIST_t *bpp;
+	LPFC_BINDLIST_t *blp;
+	LPFC_NODELIST_t *npp;
+	LPFC_NODELIST_t *pndl;
+	LPFCHBA_t *plhba;
+	uint32_t offset;
+	ulong lcnt;
+	ulong *lcntp;
+	int rc = 0;
+	uint32_t total_mem = dm->fc_outsz;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	/* If the value of offset is 1, the driver is handling
+	 * the bindlist.  Correct the total memory to account for the 
+	 * bindlist's different size 
+	 */
+	if (offset == 1) {
+		total_mem -= sizeof (LPFC_BINDLIST_t);
+	} else {
+		total_mem -= sizeof (LPFC_NODELIST_t);
+	}
+
+	lcnt = 0;
+	switch (offset) {
+	case 1:		/* bind */
+		lcntp = dm->fc_dataout;
+		memcpy(dm->fc_dataout, (uint8_t *) & lcnt, sizeof (ulong));
+		bpp =
+		    (LPFC_BINDLIST_t *) ((uint8_t *) (dm->fc_dataout) +
+					 sizeof (ulong));
+		blp = plhba->fc_nlpbind_start;
+		while ((blp != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start)
+		       && (total_mem > 0)) {
+			memcpy(bpp, (uint8_t *) blp,
+			       (sizeof (LPFC_BINDLIST_t)));
+			total_mem -= sizeof (LPFC_BINDLIST_t);
+			bpp++;
+			lcnt++;
+			blp = (LPFC_BINDLIST_t *) blp->nlp_listp_next;
+		}
+		*lcntp = lcnt;
+		break;
+	case 2:		/* unmap */
+		lcntp = dm->fc_dataout;
+		memcpy(dm->fc_dataout, (uint8_t *) & lcnt, sizeof (ulong));
+		npp =
+		    (LPFC_NODELIST_t *) ((uint8_t *) (dm->fc_dataout) +
+					 sizeof (ulong));
+		pndl = plhba->fc_nlpunmap_start;
+		while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+		       && (total_mem > 0)) {
+			memcpy(npp, (uint8_t *) pndl,
+			       (sizeof (LPFC_NODELIST_t)));
+			total_mem -= sizeof (LPFC_NODELIST_t);
+			npp++;
+			lcnt++;
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		}
+		*lcntp = lcnt;
+		break;
+	case 3:		/* map */
+		lcntp = dm->fc_dataout;
+		memcpy(dm->fc_dataout, (uint8_t *) & lcnt, sizeof (ulong));
+		npp =
+		    (LPFC_NODELIST_t *) ((uint8_t *) (dm->fc_dataout) +
+					 sizeof (ulong));
+		pndl = plhba->fc_nlpmap_start;
+		while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)
+		       && (total_mem > 0)) {
+			memcpy(npp, (uint8_t *) pndl,
+			       (sizeof (LPFC_NODELIST_t)));
+			total_mem -= sizeof (LPFC_NODELIST_t);
+			npp++;
+			lcnt++;
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		}
+		*lcntp = lcnt;
+		break;
+	case 4:		/* plogi */
+		lcntp = dm->fc_dataout;
+		memcpy(dm->fc_dataout, (uint8_t *) & lcnt, sizeof (ulong));
+		npp =
+		    (LPFC_NODELIST_t *) ((uint8_t *) (dm->fc_dataout) +
+					 sizeof (ulong));
+		pndl = plhba->fc_plogi_start;
+		while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+		       && (total_mem > 0)) {
+			memcpy(npp, (uint8_t *) pndl,
+			       (sizeof (LPFC_NODELIST_t)));
+			total_mem -= sizeof (LPFC_NODELIST_t);
+			npp++;
+			lcnt++;
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		}
+		*lcntp = lcnt;
+		break;
+	case 5:		/* adisc */
+		lcntp = dm->fc_dataout;
+		memcpy(dm->fc_dataout, (uint8_t *) & lcnt, sizeof (ulong));
+		npp =
+		    (LPFC_NODELIST_t *) ((uint8_t *) (dm->fc_dataout) +
+					 sizeof (ulong));
+		pndl = plhba->fc_adisc_start;
+		while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+		       && (total_mem > 0)) {
+			memcpy(npp, (uint8_t *) pndl,
+			       (sizeof (LPFC_NODELIST_t)));
+			total_mem -= sizeof (LPFC_NODELIST_t);
+			npp++;
+			lcnt++;
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		}
+		*lcntp = lcnt;
+		break;
+	case 6:		/* all except bind list */
+		lcntp = dm->fc_dataout;
+		memcpy(dm->fc_dataout, (uint8_t *) & lcnt, sizeof (ulong));
+		npp =
+		    (LPFC_NODELIST_t *) ((uint8_t *) (dm->fc_dataout) +
+					 sizeof (ulong));
+		pndl = plhba->fc_plogi_start;
+		while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_plogi_start)
+		       && (total_mem > 0)) {
+			memcpy(npp, (uint8_t *) pndl,
+			       (sizeof (LPFC_NODELIST_t)));
+			total_mem -= sizeof (LPFC_NODELIST_t);
+			npp++;
+			lcnt++;
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		}
+		pndl = plhba->fc_adisc_start;
+		while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_adisc_start)
+		       && (total_mem > 0)) {
+			memcpy(npp, (uint8_t *) pndl,
+			       (sizeof (LPFC_NODELIST_t)));
+			total_mem -= sizeof (LPFC_NODELIST_t);
+			npp++;
+			lcnt++;
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		}
+		pndl = plhba->fc_nlpunmap_start;
+		while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+		       && (total_mem > 0)) {
+			memcpy(npp, (uint8_t *) pndl,
+			       (sizeof (LPFC_NODELIST_t)));
+			total_mem -= sizeof (LPFC_NODELIST_t);
+			npp++;
+			lcnt++;
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		}
+		pndl = plhba->fc_nlpmap_start;
+		while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)
+		       && (total_mem > 0)) {
+			memcpy(npp, (uint8_t *) pndl,
+			       (sizeof (LPFC_NODELIST_t)));
+			total_mem -= sizeof (LPFC_NODELIST_t);
+			npp++;
+			lcnt++;
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		}
+		*lcntp = lcnt;
+		break;
+	default:
+		rc = ERANGE;
+		break;
+	}
+	cip->elx_outsz = (sizeof (ulong) + (lcnt * sizeof (LPFC_NODELIST_t)));
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_bplist(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	ELX_SLI_RING_t *rp;
+	ELX_SLINK_t *dlp;
+	DMABUF_t *mm;
+	uint32_t *lptr;
+	ELX_SLI_t *psli;
+	int rc = 0;
+	uint32_t total_mem = dm->fc_outsz;
+
+	psli = &phba->sli;
+	rp = &psli->ring[LPFC_ELS_RING];	/* RING 0 */
+	dlp = &rp->postbufq;
+	mm = (DMABUF_t *) dlp->q_first;
+	lptr = (uint32_t *) dm->fc_dataout;
+	total_mem -= (3 * sizeof (ulong));
+	while ((mm) && (total_mem > 0)) {
+		if ((cip->elx_ring == LPFC_ELS_RING)
+		    || (cip->elx_ring == LPFC_FCP_NEXT_RING)) {
+			*lptr++ = (uint32_t) ((ulong) mm);
+			*lptr++ = (uint32_t) ((ulong) mm->virt);
+			*lptr++ = (uint32_t) ((ulong) mm->phys);
+			mm = (DMABUF_t *) mm->next;
+		}
+		total_mem -= (3 * sizeof (ulong));
+	}
+	*lptr++ = 0;
+
+	cip->elx_outsz = ((uint8_t *) lptr - (uint8_t *) (dm->fc_dataout));
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_reset(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t status;
+	uint32_t offset;
+	ELX_SLI_t *psli;
+	int rc = 0;
+
+	psli = &phba->sli;
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	switch (offset) {
+	case 1:		/* hba */
+		phba->hba_state = 0;	/* Don't skip post */
+		elx_sli_brdreset(phba);
+		phba->hba_state = ELX_INIT_START;
+		mdelay(2500);
+		/* Read the HBA Host Status Register */
+		status = (psli->sliinit.elx_sli_read_HS) (phba);
+		break;
+
+	case 3:		/* target */
+		lpfc_fcp_abort(phba, TARGET_RESET, (int)((ulong) cip->elx_arg2),
+			       -1);
+		break;
+	case 4:		/* lun */
+		lpfc_fcp_abort(phba, LUN_RESET, (int)((ulong) cip->elx_arg2),
+			       (int)((ulong) cip->elx_arg3));
+		break;
+	case 5:		/* task set */
+		lpfc_fcp_abort(phba, ABORT_TASK_SET,
+			       (int)((ulong) cip->elx_arg2),
+			       (int)((ulong) cip->elx_arg3));
+		break;
+	case 6:		/* bus */
+		lpfc_fcp_abort(phba, BUS_RESET, -1, -1);
+		break;
+
+	default:
+		rc = ERANGE;
+		break;
+	}
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_hba(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	ELX_SLI_t *psli;
+	int rc = 0;
+	int cnt = 0;
+	unsigned long iflag;
+
+	psli = &phba->sli;
+	if (cip->elx_arg1) {
+
+		if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+			/* The SLIM2 size is stored in the next field */
+			cnt = (uint32_t) (unsigned long)phba->slim2p.next;
+		} else {
+			cnt = 4096;
+		}
+
+		if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+			/* copy results back to user */
+			elx_sli_pcimem_bcopy((uint32_t *) psli->MBhostaddr,
+					     (uint32_t *) dm->fc_dataout, cnt);
+		} else {
+			/* First copy command data */
+			(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+							   (void *)dm->
+							   fc_dataout, 0, cnt);
+		}
+
+		ELX_DRVR_UNLOCK(phba, iflag);
+		if (copy_to_user
+		    ((uint8_t *) cip->elx_arg1, (uint8_t *) dm->fc_dataout,
+		     cnt)) {
+			rc = EIO;
+			ELX_DRVR_LOCK(phba, iflag);
+			return (rc);
+		}
+		ELX_DRVR_LOCK(phba, iflag);
+	}
+	memcpy(dm->fc_dataout, phba, sizeof (elxHBA_t));
+	return (rc);
+}
+
+int
+lpfc_ioctl_stat(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	LPFCHBA_t *plhba;
+	int rc = 0;
+
+	if ((unsigned long)cip->elx_arg1 == 1) {
+		memcpy(dm->fc_dataout, phba, sizeof (elxHBA_t));
+	}
+
+	/* Copy LPFC_STAT_t struct from LPFCHBA_t */
+	if ((unsigned long)cip->elx_arg1 == 2) {
+		plhba = (LPFCHBA_t *) phba->pHbaProto;
+		memcpy(dm->fc_dataout, &(plhba->fc_stat), sizeof (LPFC_STAT_t));
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_lhba(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	LPFCHBA_t *plhba;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	memcpy(dm->fc_dataout, plhba, sizeof (LPFCHBA_t));
+	return (rc);
+}
+
+int
+lpfc_ioctl_read_lxhba(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint8_t *lp;
+	struct dfc_mem lp_dm;
+	int rc = 0;
+
+	/* Allocate mboxq structure */
+	lp_dm.fc_dataout = NULL;
+	if ((rc = dfc_data_alloc(phba, &lp_dm, 256)))
+		return (rc);
+	else
+		lp = (uint8_t *) lp_dm.fc_dataout;
+
+	lp = lpfc_get_lpfchba_info(phba, lp);
+	memcpy(dm->fc_dataout, lp, 256);
+
+	/* Free allocated block of memory */
+	if (lp)
+		dfc_data_free(phba, &lp_dm);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_devp(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	LPFCHBA_t *plhba;
+	uint32_t offset, cnt;
+	ELXSCSILUN_t *dev_ptr;
+	LPFC_NODELIST_t *pndl;
+	ELXSCSITARGET_t *node_ptr;
+	int rc = 0;
+
+	cnt = 0;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	cnt = (uint32_t) ((ulong) cip->elx_arg2);
+	if ((offset >= (MAX_FCP_TARGET)) || (cnt >= 128)) {
+		rc = ERANGE;
+		return (rc);
+	}
+	node_ptr = 0;
+	dev_ptr = 0;
+	pndl = 0;
+	memset(dm->fc_dataout, 0,
+	       (sizeof (ELXSCSITARGET_t) + sizeof (ELXSCSILUN_t) +
+		sizeof (LPFC_NODELIST_t)));
+	rc = ENODEV;
+	node_ptr = plhba->device_queue_hash[offset];
+	if (node_ptr) {
+		rc = 0;
+		cip->elx_outsz = sizeof (ELXSCSITARGET_t);
+		memcpy((uint8_t *) dm->fc_dataout, (uint8_t *) node_ptr,
+		       (sizeof (ELXSCSITARGET_t)));
+
+		dev_ptr = (ELXSCSILUN_t *) node_ptr->lunlist.q_first;
+		while ((dev_ptr != 0)) {
+			if (dev_ptr->lun_id == (uint64_t) cnt)
+				break;
+			dev_ptr = dev_ptr->pnextLun;
+		}
+		if (dev_ptr) {
+			cip->elx_outsz += sizeof (ELXSCSILUN_t);
+			memcpy(((uint8_t *) dm->fc_dataout +
+				sizeof (ELXSCSITARGET_t)), (uint8_t *) dev_ptr,
+			       (sizeof (ELXSCSILUN_t)));
+			pndl = (LPFC_NODELIST_t *) node_ptr->pcontext;
+			if (pndl) {
+				cip->elx_outsz += sizeof (LPFC_NODELIST_t);
+				memcpy(((uint8_t *) dm->fc_dataout +
+					sizeof (ELXSCSILUN_t) +
+					sizeof (ELXSCSITARGET_t)),
+				       (uint8_t *) pndl,
+				       (sizeof (LPFC_NODELIST_t)));
+			}
+		}
+	}
+	return (rc);
+}
+
+int
+lpfc_ioctl_linkinfo(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	LPFCHBA_t *plhba;
+	LinkInfo *linkinfo;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	linkinfo = (LinkInfo *) dm->fc_dataout;
+	linkinfo->a_linkEventTag = plhba->fc_eventTag;
+	linkinfo->a_linkUp = plhba->fc_stat.LinkUp;
+	linkinfo->a_linkDown = plhba->fc_stat.LinkDown;
+	linkinfo->a_linkMulti = plhba->fc_stat.LinkMultiEvent;
+	linkinfo->a_DID = plhba->fc_myDID;
+	if (plhba->fc_topology == TOPOLOGY_LOOP) {
+		if (plhba->fc_flag & FC_PUBLIC_LOOP) {
+			linkinfo->a_topology = LNK_PUBLIC_LOOP;
+			memcpy((uint8_t *) linkinfo->a_alpaMap,
+			       (uint8_t *) plhba->alpa_map, 128);
+			linkinfo->a_alpaCnt = plhba->alpa_map[0];
+		} else {
+			linkinfo->a_topology = LNK_LOOP;
+			memcpy((uint8_t *) linkinfo->a_alpaMap,
+			       (uint8_t *) plhba->alpa_map, 128);
+			linkinfo->a_alpaCnt = plhba->alpa_map[0];
+		}
+	} else {
+		memset((uint8_t *) linkinfo->a_alpaMap, 0, 128);
+		linkinfo->a_alpaCnt = 0;
+		if (plhba->fc_flag & FC_FABRIC) {
+			linkinfo->a_topology = LNK_FABRIC;
+		} else {
+			linkinfo->a_topology = LNK_PT2PT;
+		}
+	}
+	linkinfo->a_linkState = 0;
+	switch (phba->hba_state) {
+	case ELX_INIT_START:
+
+	case ELX_LINK_DOWN:
+		linkinfo->a_linkState = LNK_DOWN;
+		memset((uint8_t *) linkinfo->a_alpaMap, 0, 128);
+		linkinfo->a_alpaCnt = 0;
+		break;
+	case ELX_LINK_UP:
+
+	case ELX_LOCAL_CFG_LINK:
+		linkinfo->a_linkState = LNK_UP;
+		break;
+	case ELX_FLOGI:
+		linkinfo->a_linkState = LNK_FLOGI;
+		break;
+	case ELX_DISC_AUTH:
+	case ELX_FABRIC_CFG_LINK:
+	case ELX_NS_REG:
+	case ELX_NS_QRY:
+
+	case ELX_CLEAR_LA:
+		linkinfo->a_linkState = LNK_DISCOVERY;
+		break;
+	case ELX_HBA_READY:
+		linkinfo->a_linkState = LNK_READY;
+		break;
+	}
+	linkinfo->a_alpa = (uint8_t) (plhba->fc_myDID & 0xff);
+	memcpy((uint8_t *) linkinfo->a_wwpName,
+	       (uint8_t *) & plhba->fc_portname, 8);
+	memcpy((uint8_t *) linkinfo->a_wwnName,
+	       (uint8_t *) & plhba->fc_nodename, 8);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_ioinfo(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	IOinfo *ioinfo;
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	int rc = 0;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	ioinfo = (IOinfo *) dm->fc_dataout;
+	ioinfo->a_mbxCmd = psli->slistat.mboxCmd;
+	ioinfo->a_mboxCmpl = psli->slistat.mboxEvent;
+	ioinfo->a_mboxErr = psli->slistat.mboxStatErr;
+	ioinfo->a_iocbCmd = psli->slistat.iocbCmd[cip->elx_ring];
+	ioinfo->a_iocbRsp = psli->slistat.iocbRsp[cip->elx_ring];
+	ioinfo->a_adapterIntr = (psli->slistat.linkEvent +
+				 psli->slistat.iocbRsp[cip->elx_ring] +
+				 psli->slistat.mboxEvent);
+	ioinfo->a_fcpCmd = plhba->fc_stat.fcpCmd;
+	ioinfo->a_fcpCmpl = plhba->fc_stat.fcpCmpl;
+	ioinfo->a_fcpErr = plhba->fc_stat.fcpRspErr +
+	    plhba->fc_stat.fcpRemoteStop + plhba->fc_stat.fcpPortRjt +
+	    plhba->fc_stat.fcpPortBusy + plhba->fc_stat.fcpError +
+	    plhba->fc_stat.fcpLocalErr;
+	ioinfo->a_bcastRcv = plhba->fc_stat.frameRcvBcast;
+	ioinfo->a_RSCNRcv = plhba->fc_stat.elsRcvRSCN;
+	ioinfo->a_cnt1 = 0;
+	ioinfo->a_cnt2 = 0;
+	ioinfo->a_cnt3 = 0;
+	ioinfo->a_cnt4 = 0;
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_nodeinfo(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	NodeInfo *np;
+	LPFC_NODELIST_t *pndl;
+	LPFC_BINDLIST_t *pbdl;
+	LPFCHBA_t *plhba;
+	uint32_t cnt;
+	int rc = 0;
+	uint32_t total_mem = dm->fc_outsz;
+
+	np = (NodeInfo *) dm->fc_dataout;
+	cnt = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* Since the size of bind & others are different,
+	   get the node list of bind first
+	 */
+	total_mem -= sizeof (LPFC_BINDLIST_t);
+	pbdl = plhba->fc_nlpbind_start;
+	while ((pbdl != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start)
+	       && (total_mem > 0)) {
+		memset((uint8_t *) np, 0, sizeof (LPFC_BINDLIST_t));
+		if (pbdl->nlp_bind_type & FCP_SEED_WWPN)
+			np->a_flag |= NODE_SEED_WWPN;
+		if (pbdl->nlp_bind_type & FCP_SEED_WWNN)
+			np->a_flag |= NODE_SEED_WWNN;
+		if (pbdl->nlp_bind_type & FCP_SEED_DID)
+			np->a_flag |= NODE_SEED_DID;
+		if (pbdl->nlp_bind_type & FCP_SEED_AUTO)
+			np->a_flag |= NODE_AUTOMAP;
+		np->a_state = NODE_SEED;
+		np->a_did = pbdl->nlp_DID;
+		np->a_targetid = FC_SCSID(pbdl->nlp_pan, pbdl->nlp_sid);
+		memcpy(np->a_wwpn, &pbdl->nlp_portname, 8);
+		memcpy(np->a_wwnn, &pbdl->nlp_nodename, 8);
+		total_mem -= sizeof (LPFC_BINDLIST_t);
+		np++;
+		cnt++;
+		pbdl = (LPFC_BINDLIST_t *) pbdl->nlp_listp_next;
+	}
+
+	/* Get the node list of unmap, map, plogi and adisc
+	 */
+	total_mem -= sizeof (LPFC_NODELIST_t);
+	pndl = plhba->fc_plogi_start;
+	if (pndl == (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+		pndl = plhba->fc_adisc_start;
+		if (pndl == (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+			pndl = plhba->fc_nlpunmap_start;
+			if (pndl ==
+			    (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+				pndl = plhba->fc_nlpmap_start;
+			}
+		}
+	}
+	while ((pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)
+	       && (total_mem > 0)) {
+		memset((uint8_t *) np, 0, sizeof (LPFC_NODELIST_t));
+		if (pndl->nlp_flag & NLP_ADISC_LIST) {
+			np->a_flag |= NODE_ADDR_AUTH;
+			np->a_state = NODE_LIMBO;
+		}
+		if (pndl->nlp_flag & NLP_PLOGI_LIST) {
+			np->a_state = NODE_PLOGI;
+		}
+		if (pndl->nlp_flag & NLP_MAPPED_LIST) {
+			np->a_state = NODE_ALLOC;
+		}
+		if (pndl->nlp_flag & NLP_UNMAPPED_LIST) {
+			np->a_state = NODE_PRLI;
+		}
+		if (pndl->nle.nlp_type & NLP_FABRIC)
+			np->a_flag |= NODE_FABRIC;
+		if (pndl->nle.nlp_type & NLP_FCP_TARGET)
+			np->a_flag |= NODE_FCP_TARGET;
+		if (pndl->nle.nlp_type & NLP_IP_NODE)
+			np->a_flag |= NODE_IP_NODE;
+		if (pndl->nlp_flag & NLP_ELS_SND_MASK)	/* Sent ELS mask  -- Check this */
+			np->a_flag |= NODE_REQ_SND;
+		if (pndl->nlp_flag & NLP_FARP_SND)
+			np->a_flag |= NODE_FARP_SND;
+		if (pndl->nlp_flag & NLP_SEED_WWPN)
+			np->a_flag |= NODE_SEED_WWPN;
+		if (pndl->nlp_flag & NLP_SEED_WWNN)
+			np->a_flag |= NODE_SEED_WWNN;
+		if (pndl->nlp_flag & NLP_SEED_DID)
+			np->a_flag |= NODE_SEED_DID;
+		if (pndl->nlp_flag & NLP_AUTOMAP)
+			np->a_flag |= NODE_AUTOMAP;
+		np->a_did = pndl->nlp_DID;
+		np->a_targetid = FC_SCSID(pndl->nlp_pan, pndl->nlp_sid);
+		memcpy(np->a_wwpn, &pndl->nlp_portname, 8);
+		memcpy(np->a_wwnn, &pndl->nlp_nodename, 8);
+		total_mem -= sizeof (LPFC_NODELIST_t);
+		np++;
+		cnt++;
+
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		if (pndl == (LPFC_NODELIST_t *) & plhba->fc_plogi_start) {
+			pndl = plhba->fc_adisc_start;
+		}
+		if (pndl == (LPFC_NODELIST_t *) & plhba->fc_adisc_start) {
+			pndl = plhba->fc_nlpunmap_start;
+		}
+		if (pndl == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+			pndl = plhba->fc_nlpmap_start;
+		}
+	}
+	if (cnt) {
+		cip->elx_outsz = (uint32_t) (cnt * sizeof (NodeInfo));
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_adapterattributes(elxHBA_t * phba,
+				 ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	HBA_ADAPTERATTRIBUTES *ha;
+	char *pNodeSymbolicName;
+	struct dfc_mem NodeSymbolicName_dm;
+	LPFCHBA_t *plhba;
+	uint32_t incr;
+	struct dfc_info *di;
+	elx_vpd_t *vp;
+	int rc = 0;
+	int i, j = 0;		/* loop index */
+
+	/* Allocate mboxq structure */
+	NodeSymbolicName_dm.fc_dataout = NULL;
+	if ((rc = dfc_data_alloc(phba, &NodeSymbolicName_dm, 256)))
+		return (rc);
+	else
+		pNodeSymbolicName = (char *)NodeSymbolicName_dm.fc_dataout;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	di = &dfc.dfc_info[cip->elx_brd];
+	vp = &phba->vpd;
+	ha = (HBA_ADAPTERATTRIBUTES *) dm->fc_dataout;
+	memset(dm->fc_dataout, 0, (sizeof (HBA_ADAPTERATTRIBUTES)));
+	ha->NumberOfPorts = 1;
+	ha->VendorSpecificID = di->fc_ba.a_pci;
+	memcpy(ha->DriverVersion, di->fc_ba.a_drvrid, 16);
+	memcpy(ha->FirmwareVersion, di->fc_ba.a_fwname, 32);
+	memcpy((uint8_t *) & ha->NodeWWN,
+	       (uint8_t *) & plhba->fc_sparam.nodeName, sizeof (HBA_WWN));
+	memcpy(ha->Manufacturer, "Emulex Corporation", 20);
+
+	lpfc_get_hba_model_desc(phba, (uint8_t *) ha->Model,
+				(uint8_t *) ha->ModelDescription);
+
+	memcpy(ha->DriverName, "lpfcdd", 7);
+	memcpy(ha->SerialNumber, phba->SerialNumber, 32);
+	memcpy(ha->OptionROMVersion, phba->OptionROMVersion, 32);
+	/* Convert JEDEC ID to ascii for hardware version */
+	incr = vp->rev.biuRev;
+	for (i = 0; i < 8; i++) {
+		j = (incr & 0xf);
+		if (j <= 9)
+			ha->HardwareVersion[7 - i] =
+			    (char)((uint8_t) 0x30 + (uint8_t) j);
+		else
+			ha->HardwareVersion[7 - i] =
+			    (char)((uint8_t) 0x61 + (uint8_t) (j - 10));
+		incr = (incr >> 4);
+	}
+	ha->HardwareVersion[8] = 0;
+
+	lpfc_get_hba_SymbNodeName(phba, (uint8_t *) pNodeSymbolicName);
+	memcpy(ha->NodeSymbolicName, pNodeSymbolicName, 256);
+
+	/* Free allocated block of memory */
+	if (pNodeSymbolicName)
+		dfc_data_free(phba, &NodeSymbolicName_dm);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_portattributes(elxHBA_t * phba,
+			      ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	HBA_PORTATTRIBUTES *hp;
+	LPFCHBA_t *plhba;
+	SERV_PARM *hsp;
+	HBA_OSDN *osdn;
+	elx_vpd_t *vp;
+	uint32_t cnt;
+	elxCfgParam_t *clp;
+	int rc = 0;
+
+	cnt = 0;
+	clp = &phba->config[0];
+	vp = &phba->vpd;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	hsp = (SERV_PARM *) (&plhba->fc_sparam);
+	hp = (HBA_PORTATTRIBUTES *) dm->fc_dataout;
+
+	memset(dm->fc_dataout, 0, (sizeof (HBA_PORTATTRIBUTES)));
+	memcpy((uint8_t *) & hp->NodeWWN,
+	       (uint8_t *) & plhba->fc_sparam.nodeName, sizeof (HBA_WWN));
+	memcpy((uint8_t *) & hp->PortWWN,
+	       (uint8_t *) & plhba->fc_sparam.portName, sizeof (HBA_WWN));
+	if (plhba->fc_linkspeed == LA_2GHZ_LINK)
+		hp->PortSpeed = HBA_PORTSPEED_2GBIT;
+	else
+		hp->PortSpeed = HBA_PORTSPEED_1GBIT;
+
+	if (FC_JEDEC_ID(vp->rev.biuRev) == VIPER_JEDEC_ID)
+		hp->PortSupportedSpeed = HBA_PORTSPEED_10GBIT;
+	else if ((FC_JEDEC_ID(vp->rev.biuRev) == CENTAUR_2G_JEDEC_ID) ||
+		 (FC_JEDEC_ID(vp->rev.biuRev) == PEGASUS_JEDEC_ID) ||
+		 (FC_JEDEC_ID(vp->rev.biuRev) == THOR_JEDEC_ID))
+		hp->PortSupportedSpeed = HBA_PORTSPEED_2GBIT;
+	else
+		hp->PortSupportedSpeed = HBA_PORTSPEED_1GBIT;
+
+	hp->PortFcId = plhba->fc_myDID;
+	hp->PortType = HBA_PORTTYPE_UNKNOWN;
+	if (plhba->fc_topology == TOPOLOGY_LOOP) {
+		if (plhba->fc_flag & FC_PUBLIC_LOOP) {
+			hp->PortType = HBA_PORTTYPE_NLPORT;
+			memcpy((uint8_t *) & hp->FabricName,
+			       (uint8_t *) & plhba->fc_fabparam.nodeName,
+			       sizeof (HBA_WWN));
+		} else {
+			hp->PortType = HBA_PORTTYPE_LPORT;
+		}
+	} else {
+		if (plhba->fc_flag & FC_FABRIC) {
+			hp->PortType = HBA_PORTTYPE_NPORT;
+			memcpy((uint8_t *) & hp->FabricName,
+			       (uint8_t *) & plhba->fc_fabparam.nodeName,
+			       sizeof (HBA_WWN));
+		} else {
+			hp->PortType = HBA_PORTTYPE_PTP;
+		}
+	}
+
+	if (plhba->fc_flag & FC_BYPASSED_MODE) {
+		hp->PortState = HBA_PORTSTATE_BYPASSED;
+	} else if (plhba->fc_flag & FC_OFFLINE_MODE) {
+		hp->PortState = HBA_PORTSTATE_DIAGNOSTICS;
+	} else {
+		switch (phba->hba_state) {
+		case ELX_INIT_START:
+		case ELX_INIT_MBX_CMDS:
+			hp->PortState = HBA_PORTSTATE_UNKNOWN;
+			break;
+		case ELX_LINK_DOWN:
+		case ELX_LINK_UP:
+		case ELX_LOCAL_CFG_LINK:
+		case ELX_FLOGI:
+		case ELX_FABRIC_CFG_LINK:
+		case ELX_NS_REG:
+		case ELX_NS_QRY:
+		case ELX_BUILD_DISC_LIST:
+		case ELX_DISC_AUTH:
+		case ELX_CLEAR_LA:
+			hp->PortState = HBA_PORTSTATE_LINKDOWN;
+			break;
+		case ELX_HBA_READY:
+			hp->PortState = HBA_PORTSTATE_ONLINE;
+			break;
+		case ELX_HBA_ERROR:
+		default:
+			hp->PortState = HBA_PORTSTATE_ERROR;
+			break;
+		}
+	}
+	cnt = plhba->fc_map_cnt + plhba->fc_unmap_cnt;
+	hp->NumberofDiscoveredPorts = cnt;
+	if (hsp->cls1.classValid) {
+		hp->PortSupportedClassofService |= 1;	/* bit 1 */
+	}
+	if (hsp->cls2.classValid) {
+		hp->PortSupportedClassofService |= 2;	/* bit 2 */
+	}
+	if (hsp->cls3.classValid) {
+		hp->PortSupportedClassofService |= 4;	/* bit 3 */
+	}
+	hp->PortMaxFrameSize = (((uint32_t) hsp->cmn.bbRcvSizeMsb) << 8) |
+	    (uint32_t) hsp->cmn.bbRcvSizeLsb;
+
+	hp->PortSupportedFc4Types.bits[2] = 0x1;
+	hp->PortSupportedFc4Types.bits[3] = 0x20;
+	hp->PortSupportedFc4Types.bits[7] = 0x1;
+	hp->PortActiveFc4Types.bits[2] = 0x1;
+
+	if (clp[LPFC_CFG_NETWORK_ON].a_current) {
+		hp->PortActiveFc4Types.bits[3] = 0x20;
+	}
+	hp->PortActiveFc4Types.bits[7] = 0x1;
+
+	/* OSDeviceName is the device info filled into the HBA_OSDN structure */
+	osdn = (HBA_OSDN *) & hp->OSDeviceName[0];
+	memcpy(osdn->drvname, "lpfc", 4);
+	osdn->instance = lpfc_instance[phba->brd_no];
+	osdn->target = (uint32_t) (-1);
+	osdn->lun = (uint32_t) (-1);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_portstatistics(elxHBA_t * phba,
+			      ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	HBA_PORTSTATISTICS *hs;
+	LPFCHBA_t *plhba;
+	ELX_MBOXQ_t *pmboxq;
+	MAILBOX_t *pmb;
+	unsigned long iflag;
+	int rc = 0;
+
+	if ((pmboxq = (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+		return ENOMEM;
+	}
+
+	pmb = &pmboxq->mb;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	hs = (HBA_PORTSTATISTICS *) dm->fc_dataout;
+	memset(dm->fc_dataout, 0, (sizeof (HBA_PORTSTATISTICS)));
+	memset((void *)pmboxq, 0, sizeof (ELX_MBOXQ_t));
+	pmb->mbxCommand = MBX_READ_STATUS;
+	pmb->mbxOwner = OWN_HOST;
+	pmboxq->context1 = (uint8_t *) 0;
+
+	if (plhba->fc_flag & FC_OFFLINE_MODE) {
+		ELX_DRVR_UNLOCK(phba, iflag);
+		rc = elx_sli_issue_mbox(phba, pmboxq, MBX_POLL);
+		ELX_DRVR_LOCK(phba, iflag);
+	} else
+		rc = elx_sli_issue_mbox_wait(phba, pmboxq, plhba->fc_ratov * 2);
+	if (rc != MBX_SUCCESS) {
+		if (pmboxq) {
+			if (rc == MBX_TIMEOUT) {
+				/*
+				 * Let SLI layer to release mboxq if mbox command completed after timeout.
+				 */
+				pmboxq->mbox_cmpl = 0;
+			} else {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmboxq);
+			}
+		}
+		rc = ENODEV;
+		return (rc);
+	}
+	hs->TxFrames = pmb->un.varRdStatus.xmitFrameCnt;
+	hs->RxFrames = pmb->un.varRdStatus.rcvFrameCnt;
+	/* Convert KBytes to words */
+	hs->TxWords = (pmb->un.varRdStatus.xmitByteCnt * 256);
+	hs->RxWords = (pmb->un.varRdStatus.rcvByteCnt * 256);
+	memset((void *)pmboxq, 0, sizeof (ELX_MBOXQ_t));
+	pmb->mbxCommand = MBX_READ_LNK_STAT;
+	pmb->mbxOwner = OWN_HOST;
+	pmboxq->context1 = (uint8_t *) 0;
+
+	if (plhba->fc_flag & FC_OFFLINE_MODE) {
+		ELX_DRVR_UNLOCK(phba, iflag);
+		rc = elx_sli_issue_mbox(phba, pmboxq, MBX_POLL);
+		ELX_DRVR_LOCK(phba, iflag);
+	} else
+		rc = elx_sli_issue_mbox_wait(phba, pmboxq, plhba->fc_ratov * 2);
+	if (rc != MBX_SUCCESS) {
+		if (pmboxq) {
+			if (rc == MBX_TIMEOUT) {
+				/*
+				 * Let SLI layer to release mboxq if mbox command completed after timeout.
+				 */
+				pmboxq->mbox_cmpl = 0;
+			} else {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmboxq);
+			}
+		}
+		rc = ENODEV;
+		return (rc);
+	}
+	hs->LinkFailureCount = pmb->un.varRdLnk.linkFailureCnt;
+	hs->LossOfSyncCount = pmb->un.varRdLnk.lossSyncCnt;
+	hs->LossOfSignalCount = pmb->un.varRdLnk.lossSignalCnt;
+	hs->PrimitiveSeqProtocolErrCount = pmb->un.varRdLnk.primSeqErrCnt;
+	hs->InvalidTxWordCount = pmb->un.varRdLnk.invalidXmitWord;
+	hs->InvalidCRCCount = pmb->un.varRdLnk.crcCnt;
+	hs->ErrorFrames = pmb->un.varRdLnk.crcCnt;
+
+	if (plhba->fc_topology == TOPOLOGY_LOOP) {
+		hs->LIPCount = (plhba->fc_eventTag >> 1);
+		hs->NOSCount = -1;
+	} else {
+		hs->LIPCount = -1;
+		hs->NOSCount = (plhba->fc_eventTag >> 1);
+	}
+
+	hs->DumpedFrames = -1;
+
+	hs->SecondsSinceLastReset = elxDRVR.elx_clock_info.ticks;
+
+	/* Free allocated mboxq memory */
+	if (pmboxq) {
+		elx_mem_put(phba, MEM_MBOX, (uint8_t *) pmboxq);
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_wwpnportattributes(elxHBA_t * phba,
+				  ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	HBA_WWN findwwn;
+	LPFC_NODELIST_t *pndl;
+	HBA_PORTATTRIBUTES *hp;
+	LPFCHBA_t *plhba;
+	elx_vpd_t *vp;
+	MAILBOX_t *pmbox;
+	struct dfc_mem mbox_dm;
+	int rc = 0;
+	unsigned long iflag;
+
+	/* Allocate mboxq structure */
+	mbox_dm.fc_dataout = NULL;
+	if ((rc = dfc_data_alloc(phba, &mbox_dm, sizeof (MAILBOX_t))))
+		return (rc);
+	else
+		pmbox = (MAILBOX_t *) mbox_dm.fc_dataout;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	hp = (HBA_PORTATTRIBUTES *) dm->fc_dataout;
+	vp = &phba->vpd;
+	memset(dm->fc_dataout, 0, (sizeof (HBA_PORTATTRIBUTES)));
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) & findwwn, (uint8_t *) cip->elx_arg1,
+			   (ulong) (sizeof (HBA_WWN)))) {
+		ELX_DRVR_LOCK(phba, iflag);
+		rc = EIO;
+		/* Free allocated mbox memory */
+		if (pmbox)
+			dfc_data_free(phba, &mbox_dm);
+		return (rc);
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	/* First Mapped ports, then unMapped ports */
+	pndl = plhba->fc_nlpmap_start;
+	if (pndl == (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)
+		pndl = plhba->fc_nlpunmap_start;
+	while (pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+		if (lpfc_geportname
+		    (&pndl->nlp_portname, (NAME_TYPE *) & findwwn) == 2) {
+			/* handle found port */
+			rc = lpfc_ioctl_found_port(phba, plhba, pndl, dm, pmbox,
+						   hp);
+			/* Free allocated mbox memory */
+			if (pmbox)
+				dfc_data_free(phba, &mbox_dm);
+			return (rc);
+		}
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		if (pndl == (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)
+			pndl = plhba->fc_nlpunmap_start;
+	}
+
+	/* Free allocated mbox memory */
+	if (pmbox)
+		dfc_data_free(phba, &mbox_dm);
+
+	rc = ERANGE;
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_discportattributes(elxHBA_t * phba,
+				  ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	HBA_PORTATTRIBUTES *hp;
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *pndl;
+	elx_vpd_t *vp;
+	ELX_SLI_t *psli;
+	uint32_t refresh, offset, cnt;
+	MAILBOX_t *pmbox;
+	struct dfc_mem mbox_dm;
+	int rc = 0;
+
+	/* Allocate mboxq structure */
+	mbox_dm.fc_dataout = NULL;
+	if ((rc = dfc_data_alloc(phba, &mbox_dm, sizeof (MAILBOX_t))))
+		return (rc);
+	else
+		pmbox = (MAILBOX_t *) mbox_dm.fc_dataout;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	hp = (HBA_PORTATTRIBUTES *) dm->fc_dataout;
+	vp = &phba->vpd;
+	memset(dm->fc_dataout, 0, (sizeof (HBA_PORTATTRIBUTES)));
+	offset = (uint32_t) ((ulong) cip->elx_arg2);
+	refresh = (uint32_t) ((ulong) cip->elx_arg3);
+	if (refresh != plhba->nlptimer) {
+		/* This is an error, need refresh, just return zero'ed out
+		 * portattr and FcID as -1.
+		 */
+		hp->PortFcId = 0xffffffff;
+		return (rc);
+	}
+	cnt = 0;
+	/* First Mapped ports, then unMapped ports */
+	pndl = plhba->fc_nlpmap_start;
+	if (pndl == (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)
+		pndl = plhba->fc_nlpunmap_start;
+	while (pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+		if (cnt == offset) {
+			/* handle found port */
+			rc = lpfc_ioctl_found_port(phba, plhba, pndl, dm, pmbox,
+						   hp);
+			/* Free allocated mbox memory */
+			if (pmbox)
+				dfc_data_free(phba, &mbox_dm);
+			return (rc);
+		}
+		cnt++;
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+		if (pndl == (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)
+			pndl = plhba->fc_nlpunmap_start;
+	}
+	rc = ERANGE;
+
+	/* Free allocated mbox memory */
+	if (pmbox)
+		dfc_data_free(phba, &mbox_dm);
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_indexportattributes(elxHBA_t * phba,
+				   ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	HBA_PORTATTRIBUTES *hp;
+	elx_vpd_t *vp;
+	LPFC_NODELIST_t *pndl;
+	uint32_t refresh, offset, cnt;
+	MAILBOX_t *pmbox;
+	struct dfc_mem mbox_dm;
+	LPFCHBA_t *plhba;
+	int rc = 0;
+
+	/* Allocate mboxq structure */
+	mbox_dm.fc_dataout = NULL;
+	if ((rc = dfc_data_alloc(phba, &mbox_dm, sizeof (MAILBOX_t))))
+		return (rc);
+	else
+		pmbox = (MAILBOX_t *) mbox_dm.fc_dataout;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	vp = &phba->vpd;
+	hp = (HBA_PORTATTRIBUTES *) dm->fc_dataout;
+	memset(dm->fc_dataout, 0, (sizeof (HBA_PORTATTRIBUTES)));
+	offset = (uint32_t) ((ulong) cip->elx_arg2);
+	refresh = (uint32_t) ((ulong) cip->elx_arg3);
+	if (refresh != plhba->nlptimer) {
+		/* This is an error, need refresh, just return zero'ed out
+		 * portattr and FcID as -1.
+		 */
+		hp->PortFcId = 0xffffffff;
+
+		/* Free allocated mbox memory */
+		if (pmbox)
+			dfc_data_free(phba, &mbox_dm);
+
+		return (rc);
+	}
+	cnt = 0;
+	/* Mapped NPorts only */
+	pndl = plhba->fc_nlpmap_start;
+	while (pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		if (cnt == offset) {
+			/* handle found port */
+			rc = lpfc_ioctl_found_port(phba, plhba, pndl, dm, pmbox,
+						   hp);
+			/* Free allocated mbox memory */
+			if (pmbox)
+				dfc_data_free(phba, &mbox_dm);
+			return (rc);
+		}
+		cnt++;
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+	}
+
+	/* Free allocated mbox memory */
+	if (pmbox)
+		dfc_data_free(phba, &mbox_dm);
+
+	rc = ERANGE;
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_setmgmtinfo(elxHBA_t * phba,
+			   ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	HBA_MGMTINFO *mgmtinfo;
+	LPFCHBA_t *plhba = (LPFCHBA_t *) phba->pHbaProto;
+	int rc = 0;
+	unsigned long iflag;
+	struct dfc_mem dm_buf;
+
+	dm_buf.fc_dataout = NULL;
+
+	if ((rc = dfc_data_alloc(phba, &dm_buf, 4096))) {
+		return (rc);
+	} else {
+		mgmtinfo = (HBA_MGMTINFO *) dm_buf.fc_dataout;
+	}
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user
+	    ((uint8_t *) mgmtinfo, (uint8_t *) cip->elx_arg1,
+	     sizeof (HBA_MGMTINFO))) {
+		ELX_DRVR_LOCK(phba, iflag);
+		rc = EIO;
+		dfc_data_free(phba, &dm_buf);
+		return (rc);
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	/* Can ONLY set UDP port and IP Address */
+	plhba->ipVersion = mgmtinfo->IPVersion;
+	plhba->UDPport = mgmtinfo->UDPPort;
+	if (plhba->ipVersion == RNID_IPV4) {
+		memcpy((uint8_t *) & plhba->ipAddr[0],
+		       (uint8_t *) & mgmtinfo->IPAddress[0], 4);
+	} else {
+		memcpy((uint8_t *) & plhba->ipAddr[0],
+		       (uint8_t *) & mgmtinfo->IPAddress[0], 16);
+	}
+
+	dfc_data_free(phba, &dm_buf);
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_getmgmtinfo(elxHBA_t * phba,
+			   ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	HBA_MGMTINFO *mgmtinfo;
+	LPFCHBA_t *plhba = (LPFCHBA_t *) phba->pHbaProto;
+	int rc = 0;
+
+	mgmtinfo = (HBA_MGMTINFO *) dm->fc_dataout;
+	memcpy((uint8_t *) & mgmtinfo->wwn, (uint8_t *) & plhba->fc_nodename,
+	       8);
+	mgmtinfo->unittype = RNID_HBA;
+	mgmtinfo->PortId = plhba->fc_myDID;
+	mgmtinfo->NumberOfAttachedNodes = 0;
+	mgmtinfo->TopologyDiscoveryFlags = 0;
+	mgmtinfo->IPVersion = plhba->ipVersion;
+	mgmtinfo->UDPPort = plhba->UDPport;
+	if (plhba->ipVersion == RNID_IPV4) {
+		memcpy((void *)&mgmtinfo->IPAddress[0],
+		       (void *)&plhba->ipAddr[0], 4);
+	} else {
+		memcpy((void *)&mgmtinfo->IPAddress[0],
+		       (void *)&plhba->ipAddr[0], 16);
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_refreshinfo(elxHBA_t * phba,
+			   ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	uint32_t *lptr;
+	LPFCHBA_t *plhba;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	lptr = (uint32_t *) dm->fc_dataout;
+	*lptr = plhba->nlptimer;
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_rnid(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	HBA_WWN idn;
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *cmdiocbq = 0;
+	ELX_IOCBQ_t *rspiocbq = 0;
+	RNID *prsp;
+	uint32_t *pcmd;
+	uint32_t *psta;
+	IOCB_t *rsp;
+	ELX_SLI_RING_t *pring;
+	void *context2;		/* both prep_iocb and iocb_wait use this */
+	int i0;
+	uint16_t siz;
+	unsigned long iflag;
+	int rtnbfrsiz;
+	LPFC_NODELIST_t *pndl;
+	LPFCHBA_t *plhba;
+	int rc = 0;
+
+	psli = &phba->sli;
+	pring = &psli->ring[LPFC_ELS_RING];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) & idn, (uint8_t *) cip->elx_arg1,
+			   (ulong) (sizeof (HBA_WWN)))) {
+		rc = EIO;
+		ELX_DRVR_LOCK(phba, iflag);
+		return (rc);
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	if (cip->elx_flag == NODE_WWN) {
+		pndl =
+		    lpfc_findnode_wwnn(phba,
+				       NLP_SEARCH_MAPPED | NLP_SEARCH_UNMAPPED,
+				       (NAME_TYPE *) & idn);
+	} else {
+		pndl =
+		    lpfc_findnode_wwpn(phba,
+				       NLP_SEARCH_MAPPED | NLP_SEARCH_UNMAPPED,
+				       (NAME_TYPE *) & idn);
+	}
+	if (!pndl) {
+		rc = ENODEV;
+		goto sndrndqwt;
+	}
+	for (i0 = 0;
+	     i0 < 10 && (pndl->nlp_flag & NLP_ELS_SND_MASK) == NLP_RNID_SND;
+	     i0++) {
+		iflag = phba->iflag;
+		ELX_DRVR_UNLOCK(phba, iflag);
+		mdelay(1000);
+		ELX_DRVR_LOCK(phba, iflag);
+	}
+	if (i0 == 10) {
+		rc = EACCES;
+		pndl->nlp_flag &= ~NLP_RNID_SND;
+		goto sndrndqwt;
+	}
+
+	siz = 2 * sizeof (uint32_t);
+	/*  lpfc_prep_els_iocb sets the following: */
+
+	if (!
+	    (cmdiocbq =
+	     lpfc_prep_els_iocb(phba, 1, siz, 0, pndl, ELS_CMD_RNID))) {
+		rc = ENOMEM;
+		goto sndrndqwt;
+	}
+    /************************************************************************/
+	/*  context2 is used by prep/free to locate cmd and rsp buffers,   */
+	/*  but context2 is also used by iocb_wait to hold a rspiocb ptr, so    */
+	/*  the rsp iocbq can be returned from the completion routine for       */
+	/*  iocb_wait, so, save the prep/free value locally ... it will be      */
+	/*  restored after returning from iocb_wait.                            */
+    /************************************************************************/
+	context2 = cmdiocbq->context2;	/* needed to use lpfc_els_free_iocb */
+	if ((rspiocbq =
+	     (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB | MEM_PRI)) == 0) {
+		rc = ENOMEM;
+		goto sndrndqwt;
+	}
+	memset((void *)rspiocbq, 0, sizeof (ELX_IOCBQ_t));
+	rsp = &(rspiocbq->iocb);
+
+	pcmd = (uint32_t *) (((DMABUF_t *) cmdiocbq->context2)->virt);
+	*pcmd++ = ELS_CMD_RNID;
+	memset((void *)pcmd, 0, sizeof (RNID));	/* fill in RNID payload */
+	((RNID *) pcmd)->Format = 0;	/* following makes it more interesting */
+	((RNID *) pcmd)->Format = RNID_TOPOLOGY_DISC;
+	cmdiocbq->context1 = (uint8_t *) 0;
+	cmdiocbq->context2 = (uint8_t *) 0;
+	cmdiocbq->iocb_flag |= ELX_IO_IOCTL;
+	for (rc = -1, i0 = 0; i0 < 4 && rc != IOCB_SUCCESS; i0++) {
+		pndl->nlp_flag |= NLP_RNID_SND;
+		rc = elx_sli_issue_iocb_wait(phba, pring, cmdiocbq,
+					     SLI_IOCB_USE_TXQ, rspiocbq,
+					     (plhba->fc_ratov * 2) +
+					     ELX_DRVR_TIMEOUT);
+		pndl->nlp_flag &= ~NLP_RNID_SND;
+		cmdiocbq->context2 = context2;
+		if (rc == IOCB_ERROR) {
+			rc = EACCES;
+			goto sndrndqwt;
+		}
+	}
+	if (rc != IOCB_SUCCESS) {
+		goto sndrndqwt;
+	}
+
+	if (rsp->ulpStatus) {
+		rc = EACCES;
+	} else {
+		psta =
+		    (uint32_t
+		     *) ((DMABUF_t *) (((DMABUF_t *) cmdiocbq->context2)->
+				       next)->virt);
+		prsp = (RNID *) (psta + 1);	/*  then rnid response data */
+		if (*psta != ELS_CMD_ACC) {
+			rc = EFAULT;
+			goto sndrndqwt;
+		}
+		rtnbfrsiz = prsp->CommonLen + prsp->SpecificLen;
+		memcpy((uint8_t *) dm->fc_dataout, (uint8_t *) prsp, rtnbfrsiz);
+		ELX_DRVR_UNLOCK(phba, iflag);
+		if (copy_to_user
+		    ((uint8_t *) cip->elx_arg2, (uint8_t *) & rtnbfrsiz,
+		     sizeof (int)))
+			rc = EIO;
+		ELX_DRVR_LOCK(phba, iflag);
+	}
+      sndrndqwt:
+	if (cmdiocbq)
+		lpfc_els_free_iocb(phba, cmdiocbq);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_getevent(elxHBA_t * phba,
+			ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	uint32_t outsize, size;
+	HBAEVT_t *rec;
+	HBAEVT_t *recout;
+	LPFCHBA_t *plhba;
+	int j, rc = 0;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	size = (uint32_t) ((ulong) cip->elx_arg1);	/* size is number of event entries */
+
+	recout = (HBAEVT_t *) dm->fc_dataout;
+	for (j = 0; j < MAX_HBAEVT; j++) {
+		if ((j == (int)size) ||
+		    (plhba->hba_event_get == plhba->hba_event_put))
+			return (rc);
+		rec = &plhba->hbaevt[plhba->hba_event_get];
+		memcpy((uint8_t *) recout, (uint8_t *) rec, sizeof (HBAEVT_t));
+		recout++;
+		plhba->hba_event_get++;
+		if (plhba->hba_event_get >= MAX_HBAEVT) {
+			plhba->hba_event_get = 0;
+		}
+	}
+	outsize = j;
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	/* copy back size of response */
+	if (copy_to_user((uint8_t *) cip->elx_arg2, (uint8_t *) & outsize,
+			 sizeof (uint32_t))) {
+		rc = EIO;
+		ELX_DRVR_LOCK(phba, iflag);
+		return (rc);
+	}
+
+	/* copy back number of missed records */
+	if (copy_to_user
+	    ((uint8_t *) cip->elx_arg3, (uint8_t *) & plhba->hba_event_missed,
+	     sizeof (uint32_t))) {
+		rc = EIO;
+		ELX_DRVR_LOCK(phba, iflag);
+		return (rc);
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	plhba->hba_event_missed = 0;
+	cip->elx_outsz = (uint32_t) (outsize * sizeof (HBA_EVENTINFO));
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_fcptargetmapping(elxHBA_t * phba,
+				ELXCMDINPUT_t * cip,
+				struct dfc_mem *dm, int *do_cp)
+{
+
+	uint32_t room = (uint32_t) ((ulong) cip->elx_arg1);
+	uint32_t total = 0;
+	uint64_t lunidx;
+	uint64_t lunidn;
+	uint32_t lunttl;
+	int rptlunlen;
+	int count = 0;
+	int pansid;
+	HBA_FCPTARGETMAPPING *hf = (HBA_FCPTARGETMAPPING *) dm->fc_dataout;
+	HBA_FCPSCSIENTRY *ep = &hf->entry[0];
+	ELXSCSILUN_t *plun;
+	ELXSCSITARGET_t *pscznod;
+	LPFCHBA_t *plhba;
+	MBUF_INFO_t *pbfrnfo;
+	LPFC_NODELIST_t *pndl;
+	int rc = 0;
+	struct dfc_mem mbuf_dm;
+
+	/* Allocate mbuf structure */
+	mbuf_dm.fc_dataout = NULL;
+	if ((rc = dfc_data_alloc(phba, &mbuf_dm, sizeof (MBUF_INFO_t))))
+		return (rc);
+	else
+		pbfrnfo = (MBUF_INFO_t *) mbuf_dm.fc_dataout;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* Mapped ports only */
+	memset(pbfrnfo, 0, sizeof (MBUF_INFO_t));
+	pndl = plhba->fc_nlpmap_start;
+	while (pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		pansid = FC_SCSID(pndl->nlp_pan, pndl->nlp_sid);
+		if (pansid > MAX_FCP_TARGET) {
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+			continue;
+		}
+		pscznod = plhba->device_queue_hash[pansid];
+		if (!pscznod) {
+			continue;
+		}
+
+		/* Detect a config change per device by issuing a REPORT_LUN for all 
+		 * devices on the map list. 
+		 */
+		if (lpfc_issue_rptlun(phba, pbfrnfo, pscznod)) {
+			ELX_FREE(phba, pbfrnfo);
+			pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+			continue;
+		}
+		rptlunlen = SWAP_DATA(*((uint32_t *) pbfrnfo->virt));
+		lunttl = (rptlunlen > 8) ? rptlunlen / 8 : 1;
+		for (lunidx = 0; lunidx < lunttl; lunidx++) {
+			lunidn = dfc_getLunId(pbfrnfo,
+					      (ELXSCSILUN_t *) & pscznod->
+					      lunlist.q_first, lunidx);
+			plun =
+			    lpfc_find_lun(phba, pansid, (uint64_t) lunidn, 0);
+			if (!plun || (plun && !plun->failMask)) {
+				if (count < room) {
+					HBA_OSDN *osdn;
+					uint32_t fcpLun[2];
+
+					memset((void *)ep->ScsiId.OSDeviceName,
+					       0, 256);
+					/* OSDeviceName is device info filled into HBA_OSDN */
+					osdn =
+					    (HBA_OSDN *) & ep->ScsiId.
+					    OSDeviceName[0];
+					memcpy(osdn->drvname, "lpfc", 4);
+					osdn->instance =
+					    lpfc_instance[phba->brd_no];
+					osdn->target = pansid;
+					osdn->lun = (uint32_t) (lunidn);
+					osdn->flags = 0;
+					ep->ScsiId.ScsiTargetNumber = pansid;
+					ep->ScsiId.ScsiOSLun =
+					    (uint32_t) (lunidn);
+					ep->ScsiId.ScsiBusNumber = 0;
+					ep->FcpId.FcId = pndl->nlp_DID;
+					memset((char *)fcpLun, 0,
+					       sizeof (HBA_UINT64));
+					fcpLun[0] = (lunidn << FC_LUN_SHIFT);
+					if (pscznod->addrMode ==
+					    VOLUME_SET_ADDRESSING) {
+						fcpLun[0] |=
+						    SWAP_DATA(0x40000000);
+					}
+					memcpy((char *)&ep->FcpId.FcpLun,
+					       (char *)&fcpLun[0],
+					       sizeof (HBA_UINT64));
+					memcpy((uint8_t *) & ep->FcpId.PortWWN,
+					       &pndl->nlp_portname,
+					       sizeof (HBA_WWN));
+					memcpy((uint8_t *) & ep->FcpId.NodeWWN,
+					       &pndl->nlp_nodename,
+					       sizeof (HBA_WWN));
+					count++;
+					ep++;
+				}
+				total++;
+			}
+		}
+		ELX_FREE(phba, pbfrnfo);
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+	}
+	hf->NumberOfEntries = (uint32_t) total;
+	cip->elx_outsz = count * sizeof (HBA_FCPSCSIENTRY) + sizeof (ulong);
+	if (total > room) {
+		rc = ERANGE;
+		*do_cp = 1;
+	}
+
+	/* Free allocated mbuf memory */
+	if (pbfrnfo)
+		dfc_data_free(phba, &mbuf_dm);
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_fcpbinding(elxHBA_t * phba,
+			  ELXCMDINPUT_t * cip, struct dfc_mem *dm, int *do_cp)
+{
+	struct lpfc_fcpbinding_context {
+
+		uint32_t room;
+		uint32_t ttl;
+		uint32_t lunidx;
+		uint32_t lunidn;
+		uint32_t lunttl;
+		uint32_t pansid;
+		uint32_t fcpLun[2];
+		int rptlunlen;
+		int memsz, cnt;
+		MBUF_INFO_t bfrnfo;
+	};
+
+	int rc;
+	char *appPtr = ((char *)cip->elx_dataout) + sizeof (ulong);
+	HBA_FCPBINDING *hb = (HBA_FCPBINDING *) dm->fc_dataout;
+	HBA_FCPBINDINGENTRY *ep = &hb->entry[0];
+	ELXSCSILUN_t *plun;
+	ELXSCSITARGET_t *pscznod;
+	LPFC_BINDLIST_t *pbdl;
+	LPFCHBA_t *plhba;
+	MBUF_INFO_t *pbfrnfo;
+	LPFC_NODELIST_t *pndl;
+	HBA_OSDN *osdn;
+	struct lpfc_fcpbinding_context *ctxt;
+	struct dfc_mem dfc_mem_struct;
+	uint32_t total_mem = dm->fc_outsz;
+	unsigned long iflag;
+
+	dfc_mem_struct.fc_dataout = 0;
+
+	if ((rc =
+	     dfc_data_alloc(phba, &dfc_mem_struct,
+			    sizeof (struct lpfc_fcpbinding_context))))
+		return (rc);
+	else
+		ctxt =
+		    (struct lpfc_fcpbinding_context *)dfc_mem_struct.fc_dataout;
+
+	ctxt->memsz = 0;
+	ctxt->cnt = 0;
+	ctxt->room = (uint32_t) ((ulong) cip->elx_arg1);
+	ctxt->ttl = 0;
+
+	pbfrnfo = &(ctxt->bfrnfo);
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* First Mapped ports */
+	memset(pbfrnfo, 0, sizeof (MBUF_INFO_t));
+	pndl = plhba->fc_nlpmap_start;
+	while (pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		if (pndl->nlp_flag & NLP_SEED_MASK) {
+			ctxt->pansid = FC_SCSID(pndl->nlp_pan, pndl->nlp_sid);
+			if (ctxt->pansid > MAX_FCP_TARGET) {
+				pndl =
+				    (LPFC_NODELIST_t *) pndl->nle.
+				    nlp_listp_next;
+				continue;
+			}
+			pscznod = plhba->device_queue_hash[ctxt->pansid];
+			if (!pscznod) {
+				continue;
+			}
+	  /******************************************************************/
+			/* do report lun scsi command in order to get fresh data on lun   */
+			/*  configuration for the particular target of interest;  such    */
+			/*  could have changed after driver discovery on certain arrays.  */
+	  /******************************************************************/
+			if ((lpfc_issue_rptlun(phba, pbfrnfo, pscznod))) {
+				ELX_FREE(phba, pbfrnfo);
+				pndl =
+				    (LPFC_NODELIST_t *) pndl->nle.
+				    nlp_listp_next;
+				continue;
+			}
+			ctxt->rptlunlen =
+			    SWAP_DATA(*((uint32_t *) pbfrnfo->virt));
+			ctxt->lunttl =
+			    (ctxt->rptlunlen >
+			     8 ? SWAP_DATA(*(uint32_t *) pbfrnfo->virt) /
+			     8 : 1);
+			for (ctxt->lunidx = 0; ctxt->lunidx < ctxt->lunttl;
+			     ctxt->lunidx++, ctxt->ttl++) {
+				ctxt->lunidn =
+				    dfc_getLunId(pbfrnfo,
+						 (ELXSCSILUN_t *) & pscznod->
+						 lunlist.q_first, ctxt->lunidx);
+				plun =
+				    lpfc_find_lun(phba, ctxt->pansid,
+						  (uint64_t) ctxt->lunidn, 0);
+				if (ctxt->cnt < ctxt->room) {
+					/* if not enuf space left then we have to copy what we 
+					 *  have now back to application space, before reusing 
+					 *  this buffer again.
+					 */
+					if (total_mem - ctxt->memsz <
+					    sizeof (HBA_FCPBINDINGENTRY)) {
+						ELX_DRVR_UNLOCK(phba, iflag);
+						if (copy_to_user
+						    ((uint8_t *) appPtr,
+						     (uint8_t *) (&hb->
+								  entry[0]),
+						     ctxt->memsz)) {
+							ELX_DRVR_LOCK(phba,
+								      iflag);
+							return EIO;
+						}
+						ELX_DRVR_LOCK(phba, iflag);
+						appPtr = appPtr + ctxt->memsz;
+						ep = &hb->entry[0];
+						ctxt->memsz = 0;
+					}
+					memset((void *)ep->ScsiId.OSDeviceName,
+					       0, 256);
+					/* OSDeviceName is device info filled into HBA_OSDN */
+					osdn =
+					    (HBA_OSDN *) & ep->ScsiId.
+					    OSDeviceName[0];
+					memcpy(osdn->drvname, "lpfc", 4);
+					osdn->instance =
+					    lpfc_instance[phba->brd_no];
+					osdn->target = ctxt->pansid;
+					osdn->lun = (uint32_t) (ctxt->lunidn);
+					ep->ScsiId.ScsiTargetNumber =
+					    ctxt->pansid;
+					ep->ScsiId.ScsiOSLun =
+					    (uint32_t) (ctxt->lunidn);
+					ep->ScsiId.ScsiBusNumber = 0;
+					memset((char *)ctxt->fcpLun, 0,
+					       sizeof (HBA_UINT64));
+					ctxt->fcpLun[0] =
+					    (ctxt->lunidn << FC_LUN_SHIFT);
+					if (pscznod->addrMode ==
+					    VOLUME_SET_ADDRESSING) {
+						ctxt->fcpLun[0] |=
+						    SWAP_DATA(0x40000000);
+					}
+					memcpy((char *)&ep->FcpId.FcpLun,
+					       (char *)&ctxt->fcpLun[0],
+					       sizeof (HBA_UINT64));
+
+					if (pndl->nlp_flag & NLP_SEED_DID) {
+						ep->type = TO_D_ID;
+						ep->FcpId.FcId = pndl->nlp_DID;
+						ep->FcId = pndl->nlp_DID;
+						memset((uint8_t *) & ep->FcpId.
+						       PortWWN, 0,
+						       sizeof (HBA_WWN));
+						memset((uint8_t *) & ep->FcpId.
+						       NodeWWN, 0,
+						       sizeof (HBA_WWN));
+					} else {
+						ep->type = TO_WWN;
+						ep->FcId = 0;
+						ep->FcpId.FcId = 0;
+						if (pndl->
+						    nlp_flag & NLP_SEED_WWPN) {
+							memcpy((uint8_t *) &
+							       ep->FcpId.
+							       PortWWN,
+							       &pndl->
+							       nlp_portname,
+							       sizeof
+							       (HBA_WWN));
+						} else {
+							memcpy((uint8_t *) &
+							       ep->FcpId.
+							       NodeWWN,
+							       &pndl->
+							       nlp_nodename,
+							       sizeof
+							       (HBA_WWN));
+						}
+					}
+					ep->FcpId.FcId = pndl->nlp_DID;
+					memcpy((uint8_t *) & ep->FcpId.PortWWN,
+					       &pndl->nlp_portname,
+					       sizeof (HBA_WWN));
+					memcpy((uint8_t *) & ep->FcpId.NodeWWN,
+					       &pndl->nlp_nodename,
+					       sizeof (HBA_WWN));
+					ep++;
+					ctxt->cnt++;
+					ctxt->memsz =
+					    ctxt->memsz +
+					    sizeof (HBA_FCPBINDINGENTRY);
+				}
+			}
+		}
+		ELX_FREE(phba, pbfrnfo);
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+	}			/* end searching mapped list */
+
+	/* then unmapped ports */
+	pndl = plhba->fc_nlpunmap_start;
+	while (pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+		if (pndl->nlp_flag & NLP_SEED_MASK) {
+			ctxt->pansid = FC_SCSID(pndl->nlp_pan, pndl->nlp_sid);
+			if (ctxt->pansid > MAX_FCP_TARGET) {
+				continue;
+			}
+			pscznod = plhba->device_queue_hash[ctxt->pansid];
+			if (!pscznod) {
+				continue;
+			}
+			for (plun = (ELXSCSILUN_t *) & pscznod->lunlist.q_first;
+			     plun != 0; plun = plun->pnextLun, ctxt->ttl++) {
+				ctxt->lunidn = plun->lun_id;
+				if (ctxt->cnt < ctxt->room) {
+					/* if not enuf space left then we have to copy what we 
+					 *  have now back to application space, before reusing 
+					 *  this buffer again.
+					 */
+					if (total_mem - ctxt->memsz <
+					    sizeof (HBA_FCPBINDINGENTRY)) {
+						ELX_DRVR_UNLOCK(phba, iflag);
+						if (copy_to_user
+						    ((uint8_t *) appPtr,
+						     (uint8_t *) (&hb->
+								  entry[0]),
+						     ctxt->memsz)) {
+							ELX_DRVR_LOCK(phba,
+								      iflag);
+							return EIO;
+						}
+						ELX_DRVR_LOCK(phba, iflag);
+						appPtr = appPtr + ctxt->memsz;
+						ep = &hb->entry[0];
+						ctxt->memsz = 0;
+					}
+					memset((void *)ep->ScsiId.OSDeviceName,
+					       0, 256);
+					/* OSDeviceName is device info filled into HBA_OSDN */
+					osdn =
+					    (HBA_OSDN *) & ep->ScsiId.
+					    OSDeviceName[0];
+					memcpy(osdn->drvname, "lpfc", 4);
+					osdn->instance =
+					    lpfc_instance[phba->brd_no];
+					osdn->target = ctxt->pansid;
+					osdn->lun = (uint32_t) (ctxt->lunidn);
+					ep->ScsiId.ScsiTargetNumber =
+					    ctxt->pansid;
+					ep->ScsiId.ScsiOSLun =
+					    (uint32_t) (ctxt->lunidn);
+					ep->ScsiId.ScsiBusNumber = 0;
+					memset((char *)ctxt->fcpLun, 0,
+					       sizeof (HBA_UINT64));
+					ctxt->fcpLun[0] =
+					    (ctxt->lunidn << FC_LUN_SHIFT);
+					if (pscznod->addrMode ==
+					    VOLUME_SET_ADDRESSING) {
+						ctxt->fcpLun[0] |=
+						    SWAP_DATA(0x40000000);
+					}
+					memcpy((char *)&ep->FcpId.FcpLun,
+					       (char *)&ctxt->fcpLun[0],
+					       sizeof (HBA_UINT64));
+
+					if (pndl->nlp_flag & NLP_SEED_DID) {
+						ep->type = TO_D_ID;
+						ep->FcpId.FcId = pndl->nlp_DID;
+						ep->FcId = pndl->nlp_DID;
+						memset((uint8_t *) & ep->FcpId.
+						       PortWWN, 0,
+						       sizeof (HBA_WWN));
+						memset((uint8_t *) & ep->FcpId.
+						       NodeWWN, 0,
+						       sizeof (HBA_WWN));
+					} else {
+						ep->type = TO_WWN;
+						ep->FcId = 0;
+						ep->FcpId.FcId = 0;
+						if (pndl->
+						    nlp_flag & NLP_SEED_WWPN) {
+							memcpy((uint8_t *) &
+							       ep->FcpId.
+							       PortWWN,
+							       &pndl->
+							       nlp_portname,
+							       sizeof
+							       (HBA_WWN));
+						} else {
+							memcpy((uint8_t *) &
+							       ep->FcpId.
+							       NodeWWN,
+							       &pndl->
+							       nlp_nodename,
+							       sizeof
+							       (HBA_WWN));
+						}
+					}
+					ep->FcpId.FcId = pndl->nlp_DID;
+					memcpy((uint8_t *) & ep->FcpId.PortWWN,
+					       &pndl->nlp_portname,
+					       sizeof (HBA_WWN));
+					memcpy((uint8_t *) & ep->FcpId.NodeWWN,
+					       &pndl->nlp_nodename,
+					       sizeof (HBA_WWN));
+					ep++;
+					ctxt->cnt++;
+					ctxt->memsz =
+					    ctxt->memsz +
+					    sizeof (HBA_FCPBINDINGENTRY);
+				}
+			}
+		}
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+	}			/* end searching unmapped list */
+
+	/* search binding list */
+	pbdl = plhba->fc_nlpbind_start;
+	while (pbdl != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start) {
+		if (pbdl->nlp_bind_type & FCP_SEED_MASK) {
+			ctxt->pansid = FC_SCSID(pbdl->nlp_pan, pbdl->nlp_sid);
+			if (ctxt->pansid > MAX_FCP_TARGET) {
+				pbdl = pbdl->nlp_listp_next;
+				continue;
+			}
+			if (ctxt->cnt < ctxt->room) {
+				/* if not enough space left then we have to copy what we 
+				 *  have now back to application space, before reusing 
+				 *  this buffer again.
+				 */
+				if (total_mem - ctxt->memsz <
+				    sizeof (HBA_FCPBINDINGENTRY)) {
+					ELX_DRVR_UNLOCK(phba, iflag);
+					if (copy_to_user
+					    ((uint8_t *) appPtr,
+					     (uint8_t *) (&hb->entry[0]),
+					     ctxt->memsz)) {
+						ELX_DRVR_LOCK(phba, iflag);
+						return EIO;
+					}
+					ELX_DRVR_LOCK(phba, iflag);
+					appPtr = appPtr + ctxt->memsz;
+					ep = &hb->entry[0];
+					ctxt->memsz = 0;
+				}
+				memset((void *)ep->ScsiId.OSDeviceName, 0, 256);
+				ep->ScsiId.ScsiTargetNumber = ctxt->pansid;
+				ep->ScsiId.ScsiBusNumber = 0;
+				memset((char *)ctxt->fcpLun, 0,
+				       sizeof (HBA_UINT64));
+				if (pbdl->nlp_bind_type & FCP_SEED_DID) {
+					ep->type = TO_D_ID;
+					ep->FcpId.FcId = pbdl->nlp_DID;
+					ep->FcId = pbdl->nlp_DID;
+					memset((uint8_t *) & ep->FcpId.PortWWN,
+					       0, sizeof (HBA_WWN));
+					memset((uint8_t *) & ep->FcpId.NodeWWN,
+					       0, sizeof (HBA_WWN));
+				} else {
+					ep->type = TO_WWN;
+					ep->FcId = 0;
+					ep->FcpId.FcId = 0;
+					if (pbdl->nlp_bind_type & FCP_SEED_WWPN) {
+						memcpy((uint8_t *) & ep->FcpId.
+						       PortWWN,
+						       &pbdl->nlp_portname,
+						       sizeof (HBA_WWN));
+					} else {
+						memcpy((uint8_t *) & ep->FcpId.
+						       NodeWWN,
+						       &pbdl->nlp_nodename,
+						       sizeof (HBA_WWN));
+					}
+				}
+				ep->FcpId.FcId = pbdl->nlp_DID;
+				memcpy((uint8_t *) & ep->FcpId.PortWWN,
+				       &pbdl->nlp_portname, sizeof (HBA_WWN));
+				memcpy((uint8_t *) & ep->FcpId.NodeWWN,
+				       &pbdl->nlp_nodename, sizeof (HBA_WWN));
+				ep++;
+				ctxt->cnt++;
+				ctxt->memsz =
+				    ctxt->memsz + sizeof (HBA_FCPBINDINGENTRY);
+			}
+			ctxt->ttl++;
+		}
+		pbdl = pbdl->nlp_listp_next;
+	}			/* end searching bindlist */
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_to_user
+	    ((uint8_t *) appPtr, (uint8_t *) (&hb->entry[0]), ctxt->memsz)) {
+		ELX_DRVR_LOCK(phba, iflag);
+		return EIO;
+	}
+	hb->NumberOfEntries = (uint32_t) ctxt->ttl;
+	if (copy_to_user
+	    ((uint8_t *) cip->elx_dataout, (uint8_t *) (&hb->NumberOfEntries),
+	     sizeof (ulong))) {
+		ELX_DRVR_LOCK(phba, iflag);
+		return EIO;
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+	cip->elx_outsz = 0;	/* no more copy needed */
+	if (ctxt->ttl > ctxt->room) {
+		rc = ERANGE;
+		*do_cp = 1;
+	}
+	dfc_data_free(phba, &dfc_mem_struct);
+	return (rc);
+}
+
+int
+lpfc_ioctl_getcfg(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	CfgParam *cp;
+	iCfgParam *icp;
+	uint32_t cnt;
+	elxCfgParam_t *clp;
+	int i, rc = 0;
+
+	clp = &phba->config[0];
+	/* First uint32_t word will be count */
+	cp = (CfgParam *) dm->fc_dataout;
+	cnt = 0;
+	for (i = 0; i < LPFC_TOTAL_NUM_OF_CFG_PARAM; i++) {
+		icp = (iCfgParam *) & clp[i];
+		if (!(icp->a_flag & CFG_EXPORT))
+			continue;
+		cp->a_low = icp->a_low;
+		cp->a_hi = icp->a_hi;
+		cp->a_flag = icp->a_flag;
+		cp->a_default = icp->a_default;
+		if ((i == LPFC_CFG_FCP_CLASS) || (i == LPFC_CFG_IP_CLASS)) {
+			switch (icp->a_current) {
+			case CLASS1:
+				cp->a_current = 1;
+				break;
+			case CLASS2:
+				cp->a_current = 2;
+				break;
+			case CLASS3:
+				cp->a_current = 3;
+				break;
+			}
+		} else {
+			cp->a_current = icp->a_current;
+		}
+		cp->a_changestate = icp->a_changestate;
+		memcpy(cp->a_string, icp->a_string, 32);
+		memcpy(cp->a_help, icp->a_help, 80);
+		cp++;
+		cnt++;
+	}
+	if (cnt) {
+		cip->elx_outsz = (uint32_t) (cnt * sizeof (CfgParam));
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_setcfg(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	iCfgParam *icp;
+	uint32_t offset, cnt;
+	elxCfgParam_t *clp;
+	ELX_SLI_t *psli;
+	int rc = 0;
+	int i, j;
+
+	psli = &phba->sli;
+	clp = &phba->config[0];
+	offset = (uint32_t) ((ulong) cip->elx_arg1);
+	cnt = (uint32_t) ((ulong) cip->elx_arg2);
+	if (offset >= LPFC_TOTAL_NUM_OF_CFG_PARAM) {
+		rc = ERANGE;
+		return (rc);
+	}
+	j = offset;
+	for (i = 0; i < LPFC_TOTAL_NUM_OF_CFG_PARAM; i++) {
+		icp = (iCfgParam *) & clp[i];
+		if (!(icp->a_flag & CFG_EXPORT))
+			continue;
+		if (j == 0)
+			break;
+		j--;
+	}
+	if (icp->a_changestate != CFG_DYNAMIC) {
+		rc = EPERM;
+		return (rc);
+	}
+	if (((icp->a_low != 0) && (cnt < icp->a_low)) || (cnt > icp->a_hi)) {
+		rc = ERANGE;
+		return (rc);
+	}
+	if (!(icp->a_flag & CFG_EXPORT)) {
+		rc = EPERM;
+		return (rc);
+	}
+	switch (offset) {
+	case LPFC_CFG_FCP_CLASS:
+		switch (cnt) {
+		case 1:
+			clp[LPFC_CFG_FCP_CLASS].a_current = CLASS1;
+			break;
+		case 2:
+			clp[LPFC_CFG_FCP_CLASS].a_current = CLASS2;
+			break;
+		case 3:
+			clp[LPFC_CFG_FCP_CLASS].a_current = CLASS3;
+			break;
+		}
+		icp->a_current = cnt;
+		break;
+
+	case LPFC_CFG_IP_CLASS:
+		switch (cnt) {
+		case 1:
+			clp[LPFC_CFG_IP_CLASS].a_current = CLASS1;
+			break;
+		case 2:
+			clp[LPFC_CFG_IP_CLASS].a_current = CLASS2;
+			break;
+		case 3:
+			clp[LPFC_CFG_IP_CLASS].a_current = CLASS3;
+			break;
+		}
+		icp->a_current = cnt;
+		break;
+
+	case ELX_CFG_LINKDOWN_TMO:
+		icp->a_current = cnt;
+		break;
+
+	default:
+		icp->a_current = cnt;
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_get_event(elxHBA_t * phba,
+			 ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	fcEVT_t *ep;
+	fcEVT_t *oep;
+	fcEVTHDR_t *ehp;
+	uint8_t *cp;
+	DMABUF_t *omm;
+	void *type;
+	uint32_t offset, incr, size, cnt, i, gstype;
+	DMABUF_t *mm;
+	struct dfc_info *di;
+	LPFCHBA_t *plhba;
+	int no_more;
+	int rc = 0;
+	uint32_t total_mem = dm->fc_outsz;
+	unsigned long iflag;
+
+	di = &dfc.dfc_info[cip->elx_brd];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	no_more = 1;
+
+	offset = ((uint32_t) ((ulong) cip->elx_arg3) &	/* event mask */
+		  FC_REG_EVENT_MASK);	/* event mask */
+	incr = (uint32_t) cip->elx_flag;	/* event id   */
+	size = (uint32_t) cip->elx_iocb;	/* process requesting evt  */
+
+	type = 0;
+	switch (offset) {
+	case FC_REG_CT_EVENT:
+		ELX_DRVR_UNLOCK(phba, iflag);
+		if (copy_from_user
+		    ((uint8_t *) & gstype, (uint8_t *) cip->elx_arg2,
+		     (ulong) (sizeof (uint32_t)))) {
+			rc = EIO;
+			ELX_DRVR_LOCK(phba, iflag);
+			return (rc);
+		}
+		ELX_DRVR_LOCK(phba, iflag);
+		type = (void *)(ulong) gstype;
+		break;
+	}
+
+	ehp = (fcEVTHDR_t *) plhba->fc_evt_head;
+
+	while (ehp) {
+		if ((ehp->e_mask == offset) && (ehp->e_type == type))
+			break;
+		ehp = (fcEVTHDR_t *) ehp->e_next_header;
+	}
+
+	if (!ehp) {
+		rc = ENOENT;
+		return (rc);
+	}
+
+	ep = ehp->e_head;
+	oep = 0;
+	while (ep) {
+		/* Find an event that matches the event mask */
+		if (ep->evt_sleep == 0) {
+			/* dequeue event from event list */
+			if (oep == 0) {
+				ehp->e_head = ep->evt_next;
+			} else {
+				oep->evt_next = ep->evt_next;
+			}
+			if (ehp->e_tail == ep)
+				ehp->e_tail = oep;
+
+			switch (offset) {
+			case FC_REG_LINK_EVENT:
+				break;
+			case FC_REG_RSCN_EVENT:
+				/* Return data length */
+				cnt = sizeof (uint32_t);
+				ELX_DRVR_UNLOCK(phba, iflag);
+				if (copy_to_user
+				    ((uint8_t *) cip->elx_arg1,
+				     (uint8_t *) & cnt, sizeof (uint32_t))) {
+					rc = EIO;
+				}
+				ELX_DRVR_LOCK(phba, iflag);
+				memcpy(dm->fc_dataout, (char *)&ep->evt_data0,
+				       cnt);
+				cip->elx_outsz = (uint32_t) cnt;
+				break;
+			case FC_REG_CT_EVENT:
+				/* Return data length */
+				cnt = (ulong) (ep->evt_data2);
+				ELX_DRVR_UNLOCK(phba, iflag);
+				if (copy_to_user
+				    ((uint8_t *) cip->elx_arg1,
+				     (uint8_t *) & cnt, sizeof (uint32_t))) {
+					rc = EIO;
+				} else {
+					if (copy_to_user
+					    ((uint8_t *) cip->elx_arg2,
+					     (uint8_t *) & ep->evt_data0,
+					     sizeof (uint32_t))) {
+						rc = EIO;
+					}
+				}
+				ELX_DRVR_LOCK(phba, iflag);
+
+				cip->elx_outsz = (uint32_t) cnt;
+				i = cnt;
+				mm = (DMABUF_t *) ep->evt_data1;
+				cp = (uint8_t *) dm->fc_dataout;
+				while (mm) {
+
+					if (cnt > FCELSSIZE)
+						i = FCELSSIZE;
+					else
+						i = cnt;
+
+					if (total_mem > 0) {
+						memcpy(cp, (char *)mm->virt, i);
+						total_mem -= i;
+					}
+
+					omm = mm;
+					mm = (DMABUF_t *) mm->next;
+					cp += i;
+					elx_mem_put(phba, MEM_BUF,
+						    (uint8_t *) omm);
+				}
+				break;
+			}
+
+			if ((offset == FC_REG_CT_EVENT) && (ep->evt_next) &&
+			    (((fcEVT_t *) (ep->evt_next))->evt_sleep == 0)) {
+				ep->evt_data0 |= 0x80000000;	/* More event r waiting */
+				ELX_DRVR_UNLOCK(phba, iflag);
+				if (copy_to_user
+				    ((uint8_t *) cip->elx_arg2,
+				     (uint8_t *) & ep->evt_data0,
+				     sizeof (uint32_t))) {
+					rc = EIO;
+				}
+				ELX_DRVR_LOCK(phba, iflag);
+				no_more = 0;
+			}
+
+			/* Requeue event entry */
+			ep->evt_next = 0;
+			ep->evt_data0 = 0;
+			ep->evt_data1 = 0;
+			ep->evt_data2 = 0;
+			ep->evt_sleep = 1;
+			ep->evt_flags = 0;
+
+			if (ehp->e_head == 0) {
+				ehp->e_head = ep;
+				ehp->e_tail = ep;
+			} else {
+				ehp->e_tail->evt_next = ep;
+				ehp->e_tail = ep;
+			}
+
+			if (offset == FC_REG_LINK_EVENT) {
+				ehp->e_flag &= ~E_GET_EVENT_ACTIVE;
+				rc = lpfc_ioctl_linkinfo(phba, cip, dm);
+				return (rc);
+			}
+
+			if (no_more)
+				ehp->e_flag &= ~E_GET_EVENT_ACTIVE;
+			return (rc);
+			/*
+			   break;
+			 */
+		}
+		oep = ep;
+		ep = ep->evt_next;
+	}
+	if (ep == 0) {
+		/* No event found */
+		rc = ENOENT;
+	}
+
+	return (rc);
+}
+
+int
+lpfc_ioctl_hba_set_event(elxHBA_t * phba,
+			 ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+	fcEVT_t *evp;
+	fcEVT_t *ep;
+	fcEVT_t *oep;
+	fcEVTHDR_t *ehp;
+	fcEVTHDR_t *oehp;
+	int found;
+	void *type;
+	uint32_t offset, incr;
+	LPFCHBA_t *plhba;
+	MBUF_INFO_t bfrnfo, *pbfrnfo = &bfrnfo;
+	int rc = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	offset = ((uint32_t) ((ulong) cip->elx_arg3) &	/* event mask */
+		  FC_REG_EVENT_MASK);
+	incr = (uint32_t) cip->elx_flag;	/* event id   */
+	switch (offset) {
+	case FC_REG_CT_EVENT:
+		type = (void *)cip->elx_arg2;
+		found = LPFC_MAX_EVENT;	/* Number of events we can queue up + 1, before
+					 * dropping events for this event id.  */
+		break;
+	case FC_REG_RSCN_EVENT:
+		type = (void *)0;
+		found = LPFC_MAX_EVENT;	/* Number of events we can queue up + 1, before
+					 * dropping events for this event id.  */
+		break;
+	case FC_REG_LINK_EVENT:
+		type = (void *)0;
+		found = 2;	/* Number of events we can queue up + 1, before
+				 * dropping events for this event id.  */
+		break;
+	default:
+		found = 0;
+		rc = EINTR;
+		return (rc);
+	}
+
+	/*
+	 * find the fcEVT_t header for this Event, allocate a header
+	 * if not found.
+	 */
+	oehp = 0;
+	ehp = (fcEVTHDR_t *) plhba->fc_evt_head;
+	while (ehp) {
+		if ((ehp->e_mask == offset) && (ehp->e_type == type)) {
+			found = 0;
+			break;
+		}
+		oehp = ehp;
+		ehp = (fcEVTHDR_t *) ehp->e_next_header;
+	}
+
+	if (!ehp) {
+		pbfrnfo->virt = 0;
+		pbfrnfo->phys = 0;
+		pbfrnfo->flags = ELX_MBUF_VIRT;
+		pbfrnfo->align = sizeof (void *);
+		pbfrnfo->size = sizeof (fcEVTHDR_t);
+		pbfrnfo->dma_handle = 0;
+		elx_malloc(phba, pbfrnfo);
+		if (pbfrnfo->virt == NULL) {
+			rc = EINTR;
+			return (rc);
+		}
+		ehp = (fcEVTHDR_t *) (pbfrnfo->virt);
+		memset((char *)ehp, 0, sizeof (fcEVTHDR_t));
+		if (plhba->fc_evt_head == 0) {
+			plhba->fc_evt_head = ehp;
+			plhba->fc_evt_tail = ehp;
+		} else {
+			((fcEVTHDR_t *) (plhba->fc_evt_tail))->e_next_header =
+			    ehp;
+			plhba->fc_evt_tail = (void *)ehp;
+		}
+		ehp->e_handle = incr;
+		ehp->e_mask = offset;
+		ehp->e_type = type;
+		ehp->e_refcnt++;
+	} else {
+		ehp->e_refcnt++;
+	}
+
+	while (found) {
+		/* Save event id for C_GET_EVENT */
+		pbfrnfo->virt = 0;
+		pbfrnfo->phys = 0;
+		pbfrnfo->flags = (ELX_MBUF_VIRT);
+		pbfrnfo->align = sizeof (void *);
+		pbfrnfo->size = sizeof (fcEVT_t);
+		pbfrnfo->dma_handle = 0;
+		elx_malloc(phba, pbfrnfo);
+		if (pbfrnfo->virt == NULL) {
+			rc = EINTR;
+			break;
+		}
+		oep = (fcEVT_t *) (pbfrnfo->virt);
+		memset((char *)oep, 0, sizeof (fcEVT_t));
+
+		oep->evt_sleep = 1;
+		oep->evt_handle = incr;
+		oep->evt_mask = offset;
+		oep->evt_type = type;
+
+		if (ehp->e_head == 0) {
+			ehp->e_head = oep;
+			ehp->e_tail = oep;
+		} else {
+			ehp->e_tail->evt_next = (void *)oep;
+			ehp->e_tail = oep;
+		}
+		oep->evt_next = 0;
+		found--;
+	}
+
+	switch (offset) {
+	case FC_REG_CT_EVENT:
+	case FC_REG_RSCN_EVENT:
+	case FC_REG_LINK_EVENT:
+
+		if (rc || lpfc_sleep(phba, ehp)) {
+			rc = EINTR;
+			ehp->e_mode &= ~E_SLEEPING_MODE;
+			ehp->e_refcnt--;
+			if (ehp->e_refcnt) {
+				goto setout;
+			}
+			/* Remove all eventIds from queue */
+			ep = ehp->e_head;
+			oep = 0;
+			found = 0;
+			while (ep) {
+				if (ep->evt_handle == incr) {
+					/* dequeue event from event list */
+					if (oep == 0) {
+						ehp->e_head = ep->evt_next;
+					} else {
+						oep->evt_next = ep->evt_next;
+					}
+					if (ehp->e_tail == ep)
+						ehp->e_tail = oep;
+					evp = ep;
+					ep = ep->evt_next;
+					pbfrnfo->virt = (uint8_t *) evp;
+					pbfrnfo->phys = 0;
+					pbfrnfo->size = sizeof (fcEVT_t);
+					pbfrnfo->flags = ELX_MBUF_VIRT;
+					pbfrnfo->align = 0;
+					pbfrnfo->dma_handle = 0;
+					elx_free(phba, pbfrnfo);
+				} else {
+					oep = ep;
+					ep = ep->evt_next;
+				}
+			}
+
+			/*
+			 * No more fcEVT_t pointer under this fcEVTHDR_t
+			 * Free the fcEVTHDR_t
+			 */
+			if (ehp->e_head == 0) {
+				oehp = 0;
+				ehp = (fcEVTHDR_t *) plhba->fc_evt_head;
+				while (ehp) {
+					if ((ehp->e_mask == offset) &&
+					    (ehp->e_type == type)) {
+						found = 0;
+						break;
+					}
+					oehp = ehp;
+					ehp = (fcEVTHDR_t *) ehp->e_next_header;
+				}
+				if (oehp == 0) {
+					plhba->fc_evt_head = ehp->e_next_header;
+				} else {
+					oehp->e_next_header =
+					    ehp->e_next_header;
+				}
+				if (plhba->fc_evt_tail == ehp)
+					plhba->fc_evt_tail = oehp;
+
+				pbfrnfo->virt = (uint8_t *) ehp;
+				pbfrnfo->size = sizeof (fcEVTHDR_t);
+				pbfrnfo->phys = 0;
+				pbfrnfo->flags = ELX_MBUF_VIRT;
+				pbfrnfo->align = 0;
+				pbfrnfo->dma_handle = 0;
+				elx_free(phba, pbfrnfo);
+			}
+			goto setout;
+		}
+		ehp->e_refcnt--;
+		break;
+	}
+      setout:
+	return (rc);
+}
+
+int
+lpfc_ioctl_add_bind(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	bind_ctl_t bind_ctl;
+	void *bind_id = 0;
+	uint8_t bind_type = FCP_SEED_WWNN;
+	int rc = 0;
+	unsigned long iflag;
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) & bind_ctl, (uint8_t *) cip->elx_arg1,
+			   (ulong) (sizeof (bind_ctl)))) {
+		rc = EIO;
+		ELX_DRVR_LOCK(phba, iflag);
+		return rc;
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	switch (bind_ctl.bind_type) {
+	case ELX_WWNN_BIND:
+		bind_type = FCP_SEED_WWNN;
+		bind_id = &bind_ctl.wwnn[0];
+		break;
+	case ELX_WWPN_BIND:
+		bind_type = FCP_SEED_WWPN;
+		bind_id = &bind_ctl.wwpn[0];
+		break;
+	case ELX_DID_BIND:
+		bind_type = FCP_SEED_DID;
+		bind_id = &bind_ctl.did;
+		break;
+	default:
+		rc = EIO;
+		break;
+	}
+
+	if (rc)
+		return rc;
+
+	rc = lpfc_add_bind(phba, bind_type, bind_id, bind_ctl.scsi_id);
+	return rc;
+}
+
+int
+lpfc_ioctl_del_bind(elxHBA_t * phba, ELXCMDINPUT_t * cip, struct dfc_mem *dm)
+{
+
+	bind_ctl_t bind_ctl;
+	void *bind_id = 0;
+	uint8_t bind_type = FCP_SEED_WWNN;
+	int rc = 0;
+	unsigned long iflag;
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	if (copy_from_user((uint8_t *) & bind_ctl, (uint8_t *) cip->elx_arg1,
+			   (ulong) (sizeof (bind_ctl)))) {
+		ELX_DRVR_LOCK(phba, iflag);
+		rc = EIO;
+		return rc;
+	}
+	ELX_DRVR_LOCK(phba, iflag);
+
+	switch (bind_ctl.bind_type) {
+
+	case ELX_WWNN_BIND:
+		bind_type = FCP_SEED_WWNN;
+		bind_id = &bind_ctl.wwnn[0];
+		break;
+
+	case ELX_WWPN_BIND:
+		bind_type = FCP_SEED_WWPN;
+		bind_id = &bind_ctl.wwpn[0];
+		break;
+
+	case ELX_DID_BIND:
+		bind_type = FCP_SEED_DID;
+		bind_id = &bind_ctl.did;
+		break;
+
+	case ELX_SCSI_ID:
+		bind_id = 0;
+		break;
+
+	default:
+		rc = EIO;
+		break;
+	}
+
+	if (rc)
+		return rc;
+
+	rc = lpfc_del_bind(phba, bind_type, bind_id, bind_ctl.scsi_id);
+
+	return rc;
+}
+
+int
+lpfc_ioctl_list_bind(elxHBA_t * phba,
+		     ELXCMDINPUT_t * cip, struct dfc_mem *dm, int *do_cp)
+{
+
+	unsigned long next_index = 0;
+	unsigned long max_index = (unsigned long)cip->elx_arg1;
+	HBA_BIND_LIST *bind_list;
+	HBA_BIND_ENTRY *bind_array;
+	LPFC_BINDLIST_t *pbdl;
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *pndl;
+	int rc;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	bind_list = (HBA_BIND_LIST *) dm->fc_dataout;
+	bind_array = &bind_list->entry[0];
+
+	/* Iterate through the mapped list */
+	pndl = plhba->fc_nlpmap_start;
+	while (pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		if (next_index >= max_index) {
+			rc = ERANGE;
+			*do_cp = 0;
+			return (rc);
+		}
+		memset(&bind_array[next_index], 0, sizeof (HBA_BIND_ENTRY));
+		bind_array[next_index].scsi_id = pndl->nlp_sid;
+		bind_array[next_index].did = pndl->nlp_DID;
+		memcpy(&bind_array[next_index].wwpn, &pndl->nlp_portname,
+		       sizeof (HBA_WWN));
+		memcpy(&bind_array[next_index].wwnn, &pndl->nlp_nodename,
+		       sizeof (HBA_WWN));
+		if (pndl->nlp_flag & NLP_AUTOMAP)
+			bind_array[next_index].flags |= HBA_BIND_AUTOMAP;
+		if (pndl->nlp_flag & NLP_SEED_WWNN)
+			bind_array[next_index].bind_type = BIND_WWNN;
+		if (pndl->nlp_flag & NLP_SEED_WWPN)
+			bind_array[next_index].bind_type = BIND_WWPN;
+		if (pndl->nlp_flag & NLP_SEED_ALPA)
+			bind_array[next_index].bind_type = BIND_ALPA;
+		else if (pndl->nlp_flag & NLP_SEED_DID)
+			bind_array[next_index].bind_type = BIND_DID;
+		bind_array[next_index].flags |= HBA_BIND_MAPPED;
+		if (pndl->nlp_flag & NLP_NODEV_TMO)
+			bind_array[next_index].flags |= HBA_BIND_NODEVTMO;
+		if (pndl && pndl->nlp_Target &&
+		    (pndl->nlp_Target->rptLunState == REPORT_LUN_COMPLETE))
+			bind_array[next_index].flags |= HBA_BIND_RPTLUNST;
+		next_index++;
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+	}
+
+	/* Iterate through the unmapped list */
+	pndl = plhba->fc_nlpunmap_start;
+	while (pndl != (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start) {
+		if (next_index >= max_index) {
+			rc = ERANGE;
+			*do_cp = 0;
+			return (rc);
+		}
+		memset(&bind_array[next_index], 0, sizeof (HBA_BIND_ENTRY));
+		bind_array[next_index].did = pndl->nlp_DID;
+		memcpy(&bind_array[next_index].wwpn, &pndl->nlp_portname,
+		       sizeof (HBA_WWN));
+		memcpy(&bind_array[next_index].wwnn, &pndl->nlp_nodename,
+		       sizeof (HBA_WWN));
+		bind_array[next_index].flags |= HBA_BIND_UNMAPPED;
+		if (pndl->nlp_flag & NLP_TGT_NO_SCSIID)
+			bind_array[next_index].flags |= HBA_BIND_NOSCSIID;
+		if (pndl->nlp_flag & NLP_NODEV_TMO)
+			bind_array[next_index].flags |= HBA_BIND_NODEVTMO;
+		if (pndl && pndl->nlp_Target &&
+		    (pndl->nlp_Target->rptLunState == REPORT_LUN_COMPLETE))
+			bind_array[next_index].flags |= HBA_BIND_RPTLUNST;
+
+		next_index++;
+		pndl = (LPFC_NODELIST_t *) pndl->nle.nlp_listp_next;
+	}
+
+	/* Iterate through the bind list */
+	pbdl = plhba->fc_nlpbind_start;
+	while (pbdl != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start) {
+		if (next_index >= max_index) {
+			rc = ERANGE;
+			*do_cp = 0;
+			return (rc);
+		}
+		memset(&bind_array[next_index], 0, sizeof (HBA_BIND_ENTRY));
+		bind_array[next_index].scsi_id = pbdl->nlp_sid;
+
+		if (pbdl->nlp_bind_type & FCP_SEED_DID) {
+			bind_array[next_index].bind_type = BIND_DID;
+			bind_array[next_index].did = pbdl->nlp_DID;
+
+		}
+
+		if (pbdl->nlp_bind_type & FCP_SEED_WWPN) {
+			bind_array[next_index].bind_type = BIND_WWPN;
+			memcpy((uint8_t *) & bind_array[next_index].wwpn,
+			       &pbdl->nlp_portname, sizeof (HBA_WWN));
+		}
+
+		if (pbdl->nlp_bind_type & FCP_SEED_WWNN) {
+			bind_array[next_index].bind_type = BIND_WWNN;
+			memcpy((uint8_t *) & bind_array[next_index].wwnn,
+			       &pbdl->nlp_nodename, sizeof (HBA_WWN));
+		}
+		bind_array[next_index].flags |= HBA_BIND_BINDLIST;
+		pbdl = pbdl->nlp_listp_next;
+		next_index++;
+	}
+	bind_list->NumberOfEntries = next_index;
+	return 0;
+}
+
+int
+lpfc_diag_ioctl(elxHBA_t * phba, ELXCMDINPUT_t * cip)
+{
+	int rc = 0;
+	int do_cp = 0;		/* copy data into user space even rc != 0 */
+	uint32_t cnt;
+	uint32_t outshift;
+	uint32_t total_mem;
+	LPFCHBA_t *plhba = (LPFCHBA_t *) phba->pHbaProto;
+	struct dfc_info *di;
+	struct dfc_mem *dm;
+	struct dfc_mem dmdata;
+	unsigned long iflag;
+
+	cnt = phba->brd_no;
+	di = &dfc.dfc_info[cip->elx_brd];
+	dm = &dmdata;
+	memset((void *)dm, 0, sizeof (struct dfc_mem));
+	/* dfc_ioctl entry */
+	elx_printf_log(phba->brd_no, &elx_msgBlk1600,	/* ptr to msg structure */
+		       elx_mes1600,	/* ptr to msg */
+		       elx_msgBlk1600.msgPreambleStr,	/* begin varargs */
+		       cip->elx_cmd, (uint32_t) ((ulong) cip->elx_arg1), (uint32_t) ((ulong) cip->elx_arg2), cip->elx_outsz);	/* end varargs */
+	outshift = 0;
+	if (cip->elx_outsz) {
+
+		/* Allocate memory for ioctl data. If buffer is bigger than 64k, then we
+		 * allocate 64k and re-use that buffer over and over to xfer the whole 
+		 * block. This is because Linux kernel has a problem allocating more than
+		 * 120k of kernel space memory. Saw problem with GET_FCPTARGETMAPPING...
+		 */
+		if (cip->elx_outsz <= (64 * 1024))
+			total_mem = cip->elx_outsz;
+		else
+			total_mem = 64 * 1024;
+
+		dm->fc_dataout = NULL;
+		if (dfc_data_alloc(phba, dm, total_mem)) {
+			return (ENOMEM);
+		}
+	} else {
+		/* Allocate memory for ioctl data */
+		dm->fc_dataout = NULL;
+		if (dfc_data_alloc(phba, dm, 4096)) {
+			return (ENOMEM);
+		}
+	}
+
+	/* Make sure driver instance is attached */
+	if (elxDRVR.pHba[cnt] != phba) {
+		return (ENODEV);
+	}
+	di->fc_refcnt++;
+
+	switch (cip->elx_cmd) {
+
+		/* Diagnostic Interface Library Support */
+
+	case ELX_WRITE_PCI:
+		rc = lpfc_ioctl_write_pci(phba, cip, dm);
+		break;
+
+	case ELX_READ_PCI:
+		rc = lpfc_ioctl_read_pci(phba, cip, dm);
+		break;
+
+	case ELX_WRITE_MEM:
+		rc = lpfc_ioctl_write_mem(phba, cip, dm);
+		break;
+
+	case ELX_READ_MEM:
+		rc = lpfc_ioctl_read_mem(phba, cip, dm);
+		break;
+
+	case ELX_WRITE_CTLREG:
+		rc = lpfc_ioctl_write_ctlreg(phba, cip, dm);
+		break;
+
+	case ELX_READ_CTLREG:
+		rc = lpfc_ioctl_read_ctlreg(phba, cip, dm);
+		break;
+
+	case ELX_INITBRDS:
+		ELX_DRVR_UNLOCK(phba, iflag);
+		if (copy_from_user
+		    ((uint8_t *) & di->fc_ba, (uint8_t *) cip->elx_dataout,
+		     sizeof (brdinfo))) {
+			rc = EIO;
+			ELX_DRVR_LOCK(phba, iflag);
+			break;
+		}
+		ELX_DRVR_LOCK(phba, iflag);
+
+		if (elx_initpci(di, phba)) {
+			rc = EIO;
+			break;
+		}
+		if (plhba->fc_flag & FC_OFFLINE_MODE)
+			di->fc_ba.a_offmask |= OFFDI_OFFLINE;
+
+		memcpy(dm->fc_dataout, (uint8_t *) & di->fc_ba,
+		       sizeof (brdinfo));
+		cip->elx_outsz = sizeof (brdinfo);
+		break;
+
+	case ELX_READ_MEMSEG:
+		memcpy(dm->fc_dataout, (uint8_t *) & phba->memseg,
+		       (sizeof (MEMSEG_t) * ELX_MAX_SEG));
+		cip->elx_outsz = sizeof (MEMSEG_t) * ELX_MAX_SEG;
+		break;
+
+	case ELX_SETDIAG:
+		rc = lpfc_ioctl_setdiag(phba, cip, dm);
+		break;
+
+	case LPFC_LIP:
+		rc = lpfc_ioctl_lip(phba, cip, dm);
+		break;
+
+	case LPFC_RESET_QDEPTH:
+		rc = lpfc_reset_dev_q_depth(phba);
+		break;
+
+	case LPFC_OUTFCPIO:
+		rc = lpfc_ioctl_outfcpio(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_SEND_SCSI:
+	case LPFC_HBA_SEND_FCP:
+		rc = lpfc_ioctl_send_scsi_fcp(phba, cip, dm);
+		break;
+
+	case LPFC_SEND_ELS:
+		rc = lpfc_ioctl_send_els(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_SEND_MGMT_RSP:
+		rc = lpfc_ioctl_send_mgmt_rsp(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_SEND_MGMT_CMD:
+	case LPFC_CT:
+		rc = lpfc_ioctl_send_mgmt_cmd(phba, cip, dm);
+		break;
+
+	case ELX_MBOX:
+		rc = lpfc_ioctl_mbox(phba, cip, dm);
+		break;
+
+	case ELX_DISPLAY_PCI_ALL:
+		rc = lpfc_ioctl_display_pci_all(phba, cip, dm);
+		break;
+
+	case ELX_WRITE_HC:
+		rc = lpfc_ioctl_write_hc(phba, cip, dm);
+		/* drop thru to read */
+	case ELX_READ_HC:
+		rc = lpfc_ioctl_read_hc(phba, cip, dm);
+		break;
+
+	case ELX_WRITE_HS:
+		rc = lpfc_ioctl_write_hs(phba, cip, dm);
+		/* drop thru to read */
+	case ELX_READ_HS:
+		/* Read the HBA Host Status Register */
+		rc = lpfc_ioctl_read_hs(phba, cip, dm);
+		break;
+
+	case ELX_WRITE_HA:
+		/* Write the HBA Host Attention Register */
+		rc = lpfc_ioctl_write_ha(phba, cip, dm);
+		/* drop thru to read */
+	case ELX_READ_HA:
+		/* Read the HBA Host Attention Register */
+		rc = lpfc_ioctl_read_ha(phba, cip, dm);
+		break;
+
+	case ELX_WRITE_CA:
+		rc = lpfc_ioctl_write_ca(phba, cip, dm);
+		/* drop thru to read */
+	case ELX_READ_CA:
+		rc = lpfc_ioctl_read_ca(phba, cip, dm);
+		break;
+
+	case ELX_READ_MB:
+		rc = lpfc_ioctl_read_mb(phba, cip, dm);
+		break;
+
+	case ELX_DBG:
+		rc = lpfc_ioctl_dbg(phba, cip, dm);
+		break;
+
+	case ELX_INST:
+		rc = lpfc_ioctl_inst(phba, cip, dm);
+		break;
+
+	case LPFC_LISTN:
+		rc = lpfc_ioctl_listn(phba, cip, dm);
+		break;
+
+	case ELX_READ_BPLIST:
+		rc = lpfc_ioctl_read_bplist(phba, cip, dm);
+		break;
+
+	case ELX_RESET:
+		rc = lpfc_ioctl_reset(phba, cip, dm);
+		break;
+
+	case ELX_READ_HBA:
+		rc = lpfc_ioctl_read_hba(phba, cip, dm);
+		break;
+
+	case LPFC_STAT:
+		rc = lpfc_ioctl_stat(phba, cip, dm);
+		break;
+
+	case ELX_READ_LHBA:
+		rc = lpfc_ioctl_read_lhba(phba, cip, dm);
+		break;
+
+	case ELX_READ_LXHBA:
+		rc = lpfc_ioctl_read_lxhba(phba, cip, dm);
+		break;
+
+	case ELX_DEVP:
+		rc = lpfc_ioctl_devp(phba, cip, dm);
+		break;
+
+	case ELX_LINKINFO:
+		rc = lpfc_ioctl_linkinfo(phba, cip, dm);
+		break;
+
+	case ELX_IOINFO:
+		rc = lpfc_ioctl_ioinfo(phba, cip, dm);
+		break;
+
+	case ELX_NODEINFO:
+		rc = lpfc_ioctl_nodeinfo(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_ADAPTERATTRIBUTES:
+		rc = lpfc_ioctl_hba_adapterattributes(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_PORTATTRIBUTES:
+		rc = lpfc_ioctl_hba_portattributes(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_PORTSTATISTICS:
+		rc = lpfc_ioctl_hba_portstatistics(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_WWPNPORTATTRIBUTES:
+		rc = lpfc_ioctl_hba_wwpnportattributes(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_DISCPORTATTRIBUTES:
+		rc = lpfc_ioctl_hba_discportattributes(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_INDEXPORTATTRIBUTES:
+		rc = lpfc_ioctl_hba_indexportattributes(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_SETMGMTINFO:
+		rc = lpfc_ioctl_hba_setmgmtinfo(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_GETMGMTINFO:
+		rc = lpfc_ioctl_hba_getmgmtinfo(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_REFRESHINFO:
+		rc = lpfc_ioctl_hba_refreshinfo(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_RNID:
+		rc = lpfc_ioctl_hba_rnid(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_GETEVENT:
+		rc = lpfc_ioctl_hba_getevent(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_FCPTARGETMAPPING:
+		rc = lpfc_ioctl_hba_fcptargetmapping(phba, cip, dm, &do_cp);
+		break;
+
+	case LPFC_HBA_FCPBINDING:
+		rc = lpfc_ioctl_hba_fcpbinding(phba, cip, dm, &do_cp);
+		break;
+
+	case LPFC_GETCFG:
+		rc = lpfc_ioctl_getcfg(phba, cip, dm);
+		break;
+
+	case LPFC_SETCFG:
+		rc = lpfc_ioctl_setcfg(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_GET_EVENT:
+		rc = lpfc_ioctl_hba_get_event(phba, cip, dm);
+		break;
+
+	case LPFC_HBA_SET_EVENT:
+		rc = lpfc_ioctl_hba_set_event(phba, cip, dm);
+		break;
+
+	case ELX_ADD_BIND:
+		rc = lpfc_ioctl_add_bind(phba, cip, dm);
+		break;
+
+	case ELX_DEL_BIND:
+		rc = lpfc_ioctl_del_bind(phba, cip, dm);
+		break;
+
+	case ELX_LIST_BIND:
+		rc = lpfc_ioctl_list_bind(phba, cip, dm, &do_cp);
+		break;
+
+	default:
+		rc = EINVAL;
+		break;
+	}
+
+	/* dfc_ioctl exit */
+	elx_printf_log(phba->brd_no, &elx_msgBlk1601,	/* ptr to msg structure */
+		       elx_mes1601,	/* ptr to msg */
+		       elx_msgBlk1601.msgPreambleStr,	/* begin varargs */
+		       rc, cip->elx_outsz, (uint32_t) ((ulong) cip->elx_dataout));	/* end varargs */
+
+	di->fc_refcnt--;
+
+	/* Copy data to user space config method */
+	if ((rc == 0) || (do_cp == 1)) {
+		if (cip->elx_outsz) {
+			ELX_DRVR_UNLOCK(phba, iflag);
+			if (copy_to_user
+			    ((uint8_t *) cip->elx_dataout,
+			     (uint8_t *) dm->fc_dataout, (int)cip->elx_outsz)) {
+				rc = EIO;
+			}
+			ELX_DRVR_LOCK(phba, iflag);
+		}
+	}
+
+	dfc_data_free(phba, dm);
+	return (rc);
+}
+
+uint64_t
+dfc_getLunId(MBUF_INFO_t * pbfrnfo, ELXSCSILUN_t * plun, uint64_t lunidx)
+{
+	uint64_t lun;
+	int i;
+	FCP_CMND *tmp;		/* tmp is not really an FCP_CMD. We jus need
+				 * to access fcpLunMsl field */
+
+	tmp = (FCP_CMND *) pbfrnfo->virt;
+
+	/* if there's no rptLunData, then we just return lunid from 
+	 * first dev_ptr.
+	 */
+	if (tmp == 0) {
+		lun = plun->lun_id;
+	} else {
+		i = (lunidx + 1) * 8;
+		tmp = (FCP_CMND *) (((uint8_t *) pbfrnfo->virt) + i);
+		lun = ((tmp->fcpLunMsl >> FC_LUN_SHIFT) & 0xff);
+	}
+	return lun;
+}
+
+int
+dfc_issue_mbox(elxHBA_t * phba, MAILBOX_t * pmbox)
+{
+	int j;
+	MAILBOX_t *pmboxlcl;
+	volatile uint32_t word0;
+	uint32_t ha_copy;
+	ulong iflag;
+	uint32_t dly = 1;
+	ELX_SLI_t *psli = &phba->sli;
+
+	if (phba->hba_state == ELX_HBA_ERROR) {
+		pmbox->mbxStatus = MBXERR_ERROR;
+		return (1);
+	}
+	j = 0;
+	while (psli->sliinit.sli_flag & ELX_SLI_MBOX_ACTIVE) {
+		if (j < 10) {
+			mdelay(1);
+		} else {
+			mdelay(50);
+		}
+		if (j++ >= 600) {
+			pmbox->mbxStatus = MBXERR_ERROR;
+			return (1);
+		}
+	}
+	ELX_SLI_LOCK(phba, iflag);
+
+      retrycmd:
+	psli->sliinit.sli_flag |= ELX_SLI_MBOX_ACTIVE;
+	pmbox->mbxOwner = OWN_CHIP;
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {	/* SLI2 mode */
+		elx_sli_pcimem_bcopy((uint32_t *) pmbox,
+				     (uint32_t *) psli->MBhostaddr,
+				     (sizeof (uint32_t) * (MAILBOX_CMD_WSIZE)));
+		elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+				 sizeof (MAILBOX_t), ELX_DMA_SYNC_FORDEV);
+	} else {		/* NOT SLI2 mode */
+		/* First copy mbox command data to HBA SLIM, skip past first word */
+		(psli->sliinit.elx_sli_write_slim) ((void *)phba,
+						    (void *)&pmbox->un.
+						    varWords[0],
+						    sizeof (uint32_t),
+						    ((MAILBOX_CMD_WSIZE -
+						      1) * sizeof (uint32_t)));
+		/* Next copy over first word, with mbxOwner set */
+		word0 = *((volatile uint32_t *)pmbox);
+		(psli->sliinit.elx_sli_write_slim) ((void *)phba,
+						    (void *)&word0, 0,
+						    sizeof (uint32_t));
+	}
+	/* interrupt board to doit right away */
+	(psli->sliinit.elx_sli_write_CA) (phba, CA_MBATT);
+	psli->slistat.mboxCmd++;
+
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {	/* SLI2 mode */
+		elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+				 sizeof (MAILBOX_t), ELX_DMA_SYNC_FORCPU);
+		/* First read mbox status word */
+		word0 =
+		    PCIMEM_LONG(*
+				((volatile uint32_t *)(MAILBOX_t *) psli->
+				 MBhostaddr));
+	} else {		/* NOT SLI2 mode */
+		/* First read mbox status word */
+		(psli->sliinit.elx_sli_read_slim) ((void *)phba, (void *)&word0,
+						   0, sizeof (uint32_t));
+	}
+	/* Read the HBA Host Attention Register */
+	ha_copy = (psli->sliinit.elx_sli_read_HA) (phba);
+
+	/* Wait for command to complete */
+	while (((word0 & OWN_CHIP) == OWN_CHIP) || !(ha_copy & HA_MBATT)) {
+		if (j > 20 || pmbox->mbxCommand == MBX_INIT_LINK) {
+			dly = 50;
+		}
+		ELX_SLI_UNLOCK(phba, iflag);
+		mdelay(dly);
+		ELX_SLI_LOCK(phba, iflag);
+		if (j++ >= 600) {
+			pmbox->mbxStatus = MBXERR_ERROR;
+			psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+			ELX_SLI_UNLOCK(phba, iflag);
+			return (1);
+		}
+
+		if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {	/* SLI2 mode */
+			elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+					 sizeof (MAILBOX_t),
+					 ELX_DMA_SYNC_FORCPU);
+			/* First copy command data */
+			word0 = PCIMEM_LONG(*((volatile uint32_t *)(MAILBOX_t *)
+					      psli->MBhostaddr));
+		} else {
+			/* First read mbox status word */
+			(psli->sliinit.elx_sli_read_slim) ((void *)phba,
+							   (void *)&word0, 0,
+							   sizeof (uint32_t));
+		}
+		ha_copy = HA_MBATT;
+	}
+
+	pmboxlcl = (MAILBOX_t *) & word0;
+	if (pmboxlcl->mbxCommand != pmbox->mbxCommand) {
+		j++;
+		if (pmbox->mbxCommand == MBX_INIT_LINK) {
+			/* Do not retry init_link's */
+			pmbox->mbxStatus = 0;
+			psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+			ELX_SLI_UNLOCK(phba, iflag);
+			return (1);
+		}
+		goto retrycmd;
+	}
+
+	/* copy results back to user */
+	if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {	/* SLI2 mode */
+		elx_sli_pcimem_bcopy((uint32_t *) psli->MBhostaddr,
+				     (uint32_t *) pmbox,
+				     (sizeof (uint32_t) * MAILBOX_CMD_WSIZE));
+	} else {		/* NOT SLI2 mode */
+		(psli->sliinit.elx_sli_read_slim) ((void *)phba, (void *)pmbox,
+						   0,
+						   sizeof (uint32_t) *
+						   MAILBOX_CMD_WSIZE);
+	}
+
+	(psli->sliinit.elx_sli_write_HA) (phba, HA_MBATT);
+	psli->sliinit.sli_flag &= ~ELX_SLI_MBOX_ACTIVE;
+	ELX_SLI_UNLOCK(phba, iflag);
+	return (0);
+}
+
+int
+dfc_put_event(elxHBA_t * phba,
+	      uint32_t evcode, uint32_t evdata0, void *evdata1, void *evdata2)
+{
+	fcEVT_t *ep;
+	fcEVT_t *oep;
+	fcEVTHDR_t *ehp = NULL;
+	int found;
+	DMABUF_t *mp;
+	void *fstype;
+	SLI_CT_REQUEST *ctp;
+	LPFCHBA_t *plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	ehp = (fcEVTHDR_t *) plhba->fc_evt_head;
+	fstype = 0;
+	switch (evcode) {
+	case FC_REG_CT_EVENT:
+		mp = (DMABUF_t *) evdata1;
+		ctp = (SLI_CT_REQUEST *) mp->virt;
+		fstype = (void *)(ulong) (ctp->FsType);
+		break;
+	}
+
+	while (ehp) {
+		if ((ehp->e_mask == evcode) && (ehp->e_type == fstype))
+			break;
+		ehp = (fcEVTHDR_t *) ehp->e_next_header;
+	}
+
+	if (!ehp) {
+		return (0);
+	}
+
+	ep = ehp->e_head;
+	oep = 0;
+	found = 0;
+
+	while (ep && !(found)) {
+		if (ep->evt_sleep) {
+			switch (evcode) {
+			case FC_REG_CT_EVENT:
+				if ((ep->evt_type ==
+				     (void *)(ulong) FC_FSTYPE_ALL)
+				    || (ep->evt_type == fstype)) {
+					found++;
+					ep->evt_data0 = evdata0;	/* tag */
+					ep->evt_data1 = evdata1;	/* buffer ptr */
+					ep->evt_data2 = evdata2;	/* count */
+					ep->evt_sleep = 0;
+					if (ehp->e_mode & E_SLEEPING_MODE) {
+						ehp->e_flag |=
+						    E_GET_EVENT_ACTIVE;
+						lpfc_wakeup(phba, ehp);
+					}
+					/* For FC_REG_CT_EVENT just give it to first one found */
+				}
+				break;
+			default:
+				found++;
+				ep->evt_data0 = evdata0;
+				ep->evt_data1 = evdata1;
+				ep->evt_data2 = evdata2;
+				ep->evt_sleep = 0;
+				if ((ehp->e_mode & E_SLEEPING_MODE)
+				    && !(ehp->e_flag & E_GET_EVENT_ACTIVE)) {
+					ehp->e_flag |= E_GET_EVENT_ACTIVE;
+					lpfc_wakeup(phba, ehp);
+				}
+				/* For all other events, give it to every one waiting */
+				break;
+			}
+		}
+		oep = ep;
+		ep = ep->evt_next;
+	}
+	return (found);
+}
+
+int
+dfc_hba_put_event(elxHBA_t * phba,
+		  uint32_t evcode,
+		  uint32_t evdata1,
+		  uint32_t evdata2, uint32_t evdata3, uint32_t evdata4)
+{
+	HBAEVT_t *rec;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	rec = &plhba->hbaevt[plhba->hba_event_put];
+	rec->fc_eventcode = evcode;
+
+	rec->fc_evdata1 = evdata1;
+	rec->fc_evdata2 = evdata2;
+	rec->fc_evdata3 = evdata3;
+	rec->fc_evdata4 = evdata4;
+	plhba->hba_event_put++;
+	if (plhba->hba_event_put >= MAX_HBAEVT) {
+		plhba->hba_event_put = 0;
+	}
+	if (plhba->hba_event_put == plhba->hba_event_get) {
+		plhba->hba_event_missed++;
+		plhba->hba_event_get++;
+		if (plhba->hba_event_get >= MAX_HBAEVT) {
+			plhba->hba_event_get = 0;
+		}
+	}
+
+	return (0);
+}
+
+int
+dfc_data_alloc(elxHBA_t * phba, struct dfc_mem *dm, uint32_t size)
+{
+	MBUF_INFO_t bfrnfo, *pbfrnfo = &bfrnfo;
+
+	if (dm->fc_dataout)
+		return (EACCES);
+
+	size = ((size + 0xfff) & 0xfffff000);
+	pbfrnfo->virt = 0;
+	pbfrnfo->phys = 0;
+	pbfrnfo->flags = ELX_MBUF_VIRT;
+	pbfrnfo->align = sizeof (void *);
+	pbfrnfo->size = (int)size;
+	pbfrnfo->dma_handle = 0;
+	elx_malloc(phba, pbfrnfo);
+	if (pbfrnfo->virt == NULL) {
+		return (ENOMEM);
+	}
+	dm->fc_dataout = pbfrnfo->virt;
+	dm->fc_outsz = size;
+	/* dfc_data_alloc */
+	elx_printf_log(phba->brd_no, &elx_msgBlk1602,	/* ptr to msg structure */
+		       elx_mes1602,	/* ptr to msg */
+		       elx_msgBlk1602.msgPreambleStr,	/* begin varargs */
+		       (uint32_t) ((ulong) dm->fc_dataout), dm->fc_outsz);	/* end varargs */
+
+	return (0);
+}
+
+int
+dfc_data_free(elxHBA_t * phba, struct dfc_mem *dm)
+{
+	MBUF_INFO_t bfrnfo, *pbfrnfo = &bfrnfo;
+
+	/* dfc_data_free */
+	elx_printf_log(phba->brd_no, &elx_msgBlk1603,	/* ptr to msg structure */
+		       elx_mes1603,	/* ptr to msg */
+		       elx_msgBlk1603.msgPreambleStr,	/* begin varargs */
+		       (uint32_t) ((ulong) dm->fc_dataout), dm->fc_outsz);	/* end varargs */
+	if (dm->fc_dataout == 0)
+		return (EACCES);
+
+	pbfrnfo->virt = dm->fc_dataout;
+	pbfrnfo->size = dm->fc_outsz;
+	pbfrnfo->phys = 0;
+	pbfrnfo->flags = ELX_MBUF_VIRT;
+	pbfrnfo->align = 0;
+	pbfrnfo->dma_handle = 0;
+	elx_free(phba, pbfrnfo);
+	dm->fc_dataout = 0;
+	dm->fc_outsz = 0;
+
+	return (0);
+}
+
+DMABUFEXT_t *
+dfc_cmd_data_alloc(elxHBA_t * phba,
+		   char *indataptr, ULP_BDE64 * bpl, uint32_t size)
+{
+	MBUF_INFO_t bfrnfo, *pbfrnfo = &bfrnfo;
+	DMABUFEXT_t *mlist = 0;
+	DMABUFEXT_t *mlast = 0;
+	DMABUFEXT_t *dmp;
+	int cnt, offset = 0, i = 0;
+	unsigned long iflag;
+
+	while (size) {
+		/* We get chucks of 4K */
+		if (size > 4096)
+			cnt = 4096;
+		else
+			cnt = size;
+
+		/* allocate DMABUFEXT_t buffer header */
+		pbfrnfo->virt = 0;
+		pbfrnfo->phys = 0;
+		pbfrnfo->flags = ELX_MBUF_VIRT;
+		pbfrnfo->align = (int)sizeof (long);
+		pbfrnfo->size = (int)sizeof (DMABUFEXT_t);
+		pbfrnfo->dma_handle = 0;
+		elx_malloc(phba, pbfrnfo);
+		if (pbfrnfo->virt == 0) {
+			goto out;
+		}
+		dmp = pbfrnfo->virt;
+		dmp->dma.next = 0;
+		dmp->dma.virt = 0;
+
+		/* Queue it to a linked list */
+		if (mlast == 0) {
+			mlist = dmp;
+			mlast = dmp;
+		} else {
+			mlast->dma.next = (DMABUF_t *) dmp;
+			mlast = dmp;
+		}
+		dmp->dma.next = 0;
+
+		/* allocate buffer */
+		pbfrnfo->virt = 0;
+		pbfrnfo->phys = 0;
+		pbfrnfo->flags = ELX_MBUF_DMA;
+		pbfrnfo->align = (int)4096;
+		pbfrnfo->size = (int)cnt;
+		pbfrnfo->dma_handle = 0;
+		elx_malloc(phba, pbfrnfo);
+		if (pbfrnfo->phys == 0) {
+			goto out;
+		}
+		dmp->dma.virt = pbfrnfo->virt;
+		if (pbfrnfo->dma_handle) {
+			dmp->dma.dma_handle = pbfrnfo->dma_handle;
+			dmp->dma.data_handle = pbfrnfo->data_handle;
+		}
+		dmp->dma.phys = pbfrnfo->phys;
+		dmp->size = cnt;
+
+		if (indataptr) {
+			/* Copy data from user space in */
+			ELX_DRVR_UNLOCK(phba, iflag);
+			if (copy_from_user
+			    ((uint8_t *) dmp->dma.virt,
+			     (uint8_t *) (indataptr + offset), (ulong) cnt)) {
+				ELX_DRVR_LOCK(phba, iflag);
+				goto out;
+			}
+			ELX_DRVR_LOCK(phba, iflag);
+			bpl->tus.f.bdeFlags = 0;
+			elx_pci_dma_sync((void *)phba, (void *)&dmp->dma, 0,
+					 ELX_DMA_SYNC_FORDEV);
+		} else {
+			bpl->tus.f.bdeFlags = BUFF_USE_RCV;
+		}
+
+		/* build buffer ptr list for IOCB */
+		bpl->addrLow = PCIMEM_LONG(putPaddrLow(dmp->dma.phys));
+		bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(dmp->dma.phys));
+		bpl->tus.f.bdeSize = (ushort) cnt;
+		bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+		bpl++;
+
+		i++;
+		offset += cnt;
+		size -= cnt;
+	}
+
+	mlist->flag = i;
+	return (mlist);
+      out:
+	dfc_cmd_data_free(phba, mlist);
+	return (0);
+}
+
+int
+dfc_rsp_data_copy(elxHBA_t * phba,
+		  uint8_t * outdataptr, DMABUFEXT_t * mlist, uint32_t size)
+{
+	DMABUFEXT_t *mlast = 0;
+	int cnt, offset = 0;
+	unsigned long iflag;
+
+	while (mlist && size) {
+		/* We copy chucks of 4K */
+		if (size > 4096)
+			cnt = 4096;
+		else
+			cnt = size;
+
+		mlast = mlist;
+		mlist = (DMABUFEXT_t *) mlist->dma.next;
+
+		if (outdataptr) {
+			elx_pci_dma_sync((void *)phba, (void *)&mlast->dma, 0,
+					 ELX_DMA_SYNC_FORDEV);
+			/* Copy data to user space */
+			ELX_DRVR_UNLOCK(phba, iflag);
+			if (copy_to_user
+			    ((uint8_t *) (outdataptr + offset),
+			     (uint8_t *) mlast->dma.virt, (ulong) cnt)) {
+				ELX_DRVR_LOCK(phba, iflag);
+				return (1);
+			}
+			ELX_DRVR_LOCK(phba, iflag);
+		}
+		offset += cnt;
+		size -= cnt;
+	}
+	return (0);
+}
+
+int
+dfc_cmd_data_free(elxHBA_t * phba, DMABUFEXT_t * mlist)
+{
+	MBUF_INFO_t bfrnfo, *pbfrnfo = &bfrnfo;
+	DMABUFEXT_t *mlast;
+
+	while (mlist) {
+		mlast = mlist;
+		mlist = (DMABUFEXT_t *) mlist->dma.next;
+		if (mlast->dma.virt) {
+			pbfrnfo->size = mlast->size;
+			pbfrnfo->virt = (uint32_t *) mlast->dma.virt;
+			pbfrnfo->phys = mlast->dma.phys;
+			pbfrnfo->flags = ELX_MBUF_DMA;
+			if (mlast->dma.dma_handle) {
+				pbfrnfo->dma_handle = mlast->dma.dma_handle;
+				pbfrnfo->data_handle = mlast->dma.data_handle;
+			}
+			elx_free(phba, pbfrnfo);
+		}
+		pbfrnfo->flags = ELX_MBUF_VIRT;
+		pbfrnfo->size = (int)sizeof (DMABUFEXT_t);
+		pbfrnfo->virt = (uint32_t *) mlast;
+		pbfrnfo->phys = 0;
+		pbfrnfo->dma_handle = 0;
+		pbfrnfo->data_handle = 0;
+		elx_free(phba, pbfrnfo);
+	}
+	return (0);
+}
+
+char lpfc_fwrevision[32];
+
+char *
+lpfc_decode_firmware_rev(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	elx_vpd_t *vp;
+	uint32_t b1, b2, b3, b4, ldata;
+	char c;
+	uint32_t i, rev;
+	uint32_t *ptr, str[4];
+
+	psli = &phba->sli;
+	vp = &phba->vpd;
+	if (vp->rev.rBit) {
+		if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE)
+			rev = vp->rev.sli2FwRev;
+		else
+			rev = vp->rev.sli1FwRev;
+
+		b1 = (rev & 0x0000f000) >> 12;
+		b2 = (rev & 0x00000f00) >> 8;
+		b3 = (rev & 0x000000c0) >> 6;
+		b4 = (rev & 0x00000030) >> 4;
+
+		switch (b4) {
+		case 0:
+			c = 'N';
+			break;
+		case 1:
+			c = 'A';
+			break;
+		case 2:
+			c = 'B';
+			break;
+		case 3:
+		default:
+			c = 0;
+			break;
+		}
+		b4 = (rev & 0x0000000f);
+
+		if (psli->sliinit.sli_flag & ELX_SLI2_ACTIVE) {
+			for (i = 0; i < 16; i++) {
+				if (vp->rev.sli2FwName[i] == 0x20) {
+					vp->rev.sli2FwName[i] = 0;
+				}
+			}
+			ptr = (uint32_t *) vp->rev.sli2FwName;
+		} else {
+			for (i = 0; i < 16; i++) {
+				if (vp->rev.sli1FwName[i] == 0x20) {
+					vp->rev.sli1FwName[i] = 0;
+				}
+			}
+			ptr = (uint32_t *) vp->rev.sli1FwName;
+		}
+		for (i = 0; i < 3; i++) {
+			ldata = *ptr++;
+			ldata = SWAP_DATA(ldata);
+			str[i] = ldata;
+		}
+
+		if (c == 0) {
+			elx_str_sprintf(lpfc_fwrev_short, "%d.%d%d", (int)b1,
+					(int)b2, (int)b3);
+			elx_str_sprintf(lpfc_fwrevision, "%d.%d%d (%s)",
+					(int)b1, (int)b2, (int)b3, (char *)str);
+		} else {
+			elx_str_sprintf(lpfc_fwrev_short, "%d.%d%d%c%d",
+					(int)b1, (int)b2, (int)b3, c, (int)b4);
+			elx_str_sprintf(lpfc_fwrevision, "%d.%d%d%c%d (%s)",
+					(int)b1, (int)b2, (int)b3, c, (int)b4,
+					(char *)str);
+		}
+	} else {
+		rev = vp->rev.smFwRev;
+
+		b1 = (rev & 0xff000000) >> 24;
+		b2 = (rev & 0x00f00000) >> 20;
+		b3 = (rev & 0x000f0000) >> 16;
+		c = (char)((rev & 0x0000ff00) >> 8);
+		b4 = (rev & 0x000000ff);
+
+		elx_str_sprintf(lpfc_fwrev_short, "%d.%d%d%c%d ", (int)b1,
+				(int)b2, (int)b3, c, (int)b4);
+		elx_str_sprintf(lpfc_fwrevision, "%d.%d%d%c%d ", (int)b1,
+				(int)b2, (int)b3, c, (int)b4);
+	}
+	return (lpfc_fwrevision);
+}
+
+int
+lpfc_issue_rptlun(elxHBA_t * phba,
+		  MBUF_INFO_t * pbfrnfo, ELXSCSITARGET_t * pscznod)
+{
+
+	ELX_SLI_t *psli = &phba->sli;
+	ELX_SLI_RING_t *pring = &psli->ring[LPFC_FCP_RING];
+	ELX_IOCBQ_t *rspiocbq = 0;
+	IOCB_t *cmd;
+	IOCB_t *rsp;
+	DMABUF_t *mp = 0;
+	FCP_RSP *fcprsp;
+	int rtnsta = 0;
+	int rc;
+	ELX_SCSI_BUF_t *elx_cmd = NULL;
+	ELX_IOCBQ_t *piocbq;
+	LPFC_NODELIST_t *nlp = (LPFC_NODELIST_t *) pscznod->pcontext;
+
+	if (phba->hba_state == ELX_INIT_START) {
+		rtnsta = 1;
+		goto rptlunxit;
+	}
+	elx_cmd = lpfc_build_scsi_cmd(phba, nlp, FCP_SCSI_REPORT_LUNS, 0);
+	if (elx_cmd) {
+		piocbq = &elx_cmd->cur_iocbq;
+		piocbq->iocb_cmpl = 0;
+		cmd = &(piocbq->iocb);
+		mp = (DMABUF_t *) (piocbq->context2);
+		piocbq->iocb_flag |= ELX_IO_IOCTL;
+
+		/* Allocate buffer for response iocb */
+		if ((rspiocbq =
+		     (ELX_IOCBQ_t *) elx_mem_get(phba,
+						 MEM_IOCB | MEM_PRI)) == 0) {
+			rtnsta = 3;
+			goto rptlunxit;
+		}
+		memset((void *)rspiocbq, 0, sizeof (ELX_IOCBQ_t));
+		rsp = &(rspiocbq->iocb);
+		piocbq->context2 = NULL;
+		piocbq->context1 = NULL;
+
+		memset(pbfrnfo, 0, sizeof (MBUF_INFO_t));
+		pbfrnfo->size = 4096;
+		pbfrnfo->flags = ELX_MBUF_DMA;
+		pbfrnfo->align = (int)4096;
+		pbfrnfo->dma_handle = 0;
+		elx_malloc(phba, pbfrnfo);
+		if (pbfrnfo->virt == 0) {
+			rtnsta = 6;
+			goto rptlunxit;
+		}
+
+		rc = elx_sli_issue_iocb_wait(phba, pring, piocbq,
+					     SLI_IOCB_USE_TXQ, rspiocbq,
+					     30 + phba->fcp_timeout_offset +
+					     ELX_DRVR_TIMEOUT);
+		if (rc != IOCB_SUCCESS) {
+			rtnsta = 7;
+			goto rptlunxit;
+		}
+
+		fcprsp = elx_cmd->fcp_rsp;
+
+		elx_printf_log(phba->brd_no, &elx_msgBlk1605,	/* ptr to msg structure */
+			       elx_mes1605,	/* ptr to msg */
+			       elx_msgBlk1605.msgPreambleStr,	/* begin varargs */
+			       nlp->nlp_DID, fcprsp->rspStatus2, fcprsp->rspStatus3, rsp->ulpStatus);	/* end varargs */
+
+		if (rsp->ulpStatus == IOSTAT_FCP_RSP_ERROR) {
+			if ((fcprsp->rspStatus2 & RESID_UNDER) &&
+			    (fcprsp->rspStatus3 == SCSI_STAT_GOOD)) {
+				rtnsta = 0;
+				goto rptlunxit;
+			}
+
+			if ((fcprsp->rspStatus2 & SNS_LEN_VALID) &&
+			    (fcprsp->rspStatus3 == SCSI_STAT_CHECK_COND)) {
+				uint8_t *SnsInfo =
+				    ((uint8_t *) & fcprsp->rspInfo0)
+				    + SWAP_DATA(fcprsp->rspRspLen);
+
+				/* some disks return check condition (sense = ILLEGAL REQUEST) on a SCSI */
+				/* REPORT_LUNS command. this isnt an error condition, report success */
+
+				if (((SnsInfo[2] & 0x0f) == SNS_ILLEGAL_REQ)
+				    && (SnsInfo[12] == SNSCOD_BADCMD)) {
+					/* zero out the data buffer */
+					memset((uint8_t *) mp->virt, 0, 1024);
+					rtnsta = 0;
+				} else {
+					rtnsta = 8;
+				}
+			} else {
+				rtnsta = 9;
+			}
+		}
+
+		if (!rtnsta) {
+			if ((*((uint8_t *) mp->virt + 8) & 0xc0) == 0x40) {
+				pscznod->addrMode = VOLUME_SET_ADDRESSING;
+			}
+		}
+	} else
+		rtnsta = 10;
+      rptlunxit:
+
+	if (elx_cmd) {
+		if (rtnsta == 0) {
+			memcpy(pbfrnfo->virt, mp->virt, 1024);
+		}
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) rspiocbq);
+		elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+		elx_free_scsi_buf(elx_cmd);
+	}
+	return (rtnsta);
+}
+
+int
+lpfc_reset_dev_q_depth(elxHBA_t * phba)
+{
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *dev_ptr;
+	int i;
+	LPFCHBA_t *plhba = (LPFCHBA_t *) phba->pHbaProto;
+	elxCfgParam_t *clp = &phba->config[0];
+
+	/*
+	 * Find the target and set it to default. 
+	 */
+
+	clp = &phba->config[0];
+	for (i = 0; i < MAX_FCP_TARGET; ++i) {
+		targetp = plhba->device_queue_hash[i];
+		if (targetp) {
+			dev_ptr = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+			while ((dev_ptr != 0)) {
+				dev_ptr->lunSched.maxOutstanding =
+				    (ushort) clp[LPFC_DFT_LUN_Q_DEPTH].
+				    a_current;
+				dev_ptr = dev_ptr->pnextLun;
+			}
+		}
+	}
+	return (0);
+}
+
+int
+lpfc_fcp_abort(elxHBA_t * phba, int cmd, int target, int lun)
+{
+	ELX_SCSI_BUF_t *elx_cmd;
+	LPFC_NODELIST_t *pndl;
+	uint32_t flag;
+	int ret = 0;
+	int i = 0;
+
+	flag = ELX_EXTERNAL_RESET;
+	switch (cmd) {
+	case BUS_RESET:
+
+		{
+			for (i = 0; i < MAX_FCP_TARGET; i++) {
+				pndl = lpfc_findnode_scsiid(phba, i);
+				if (pndl) {
+					elx_cmd = elx_get_scsi_buf(phba);
+					if (elx_cmd) {
+
+						elx_cmd->scsi_hba = phba;
+						elx_cmd->scsi_bus = 0;
+						elx_cmd->scsi_target = i;
+						elx_cmd->scsi_lun = 0;
+						ret =
+						    elx_scsi_tgt_reset(elx_cmd,
+								       phba, 0,
+								       i, flag);
+						elx_free_scsi_buf(elx_cmd);
+						elx_cmd = 0;
+					}
+				}
+			}
+		}
+		break;
+	case TARGET_RESET:
+		{
+			/* Obtain node ptr */
+			pndl = lpfc_findnode_scsiid(phba, target);
+			if (pndl) {
+				elx_cmd = elx_get_scsi_buf(phba);
+				if (elx_cmd) {
+
+					elx_cmd->scsi_hba = phba;
+					elx_cmd->scsi_bus = 0;
+					elx_cmd->scsi_target = target;
+					elx_cmd->scsi_lun = 0;
+
+					ret =
+					    elx_scsi_tgt_reset(elx_cmd, phba, 0,
+							       target, flag);
+					elx_free_scsi_buf(elx_cmd);
+					elx_cmd = 0;
+				}
+			}
+		}
+		break;
+	case LUN_RESET:
+		{
+			/* Obtain node ptr */
+			pndl = lpfc_findnode_scsiid(phba, target);
+			if (pndl) {
+				elx_cmd = elx_get_scsi_buf(phba);
+				if (elx_cmd) {
+					elx_cmd->scsi_hba = phba;
+					elx_cmd->scsi_bus = 0;
+					elx_cmd->scsi_target = target;
+					elx_cmd->scsi_lun = lun;
+					ret =
+					    elx_scsi_lun_reset(elx_cmd, phba, 0,
+							       target, lun,
+							       (flag |
+								ELX_ISSUE_LUN_RESET));
+					elx_free_scsi_buf(elx_cmd);
+					elx_cmd = 0;
+				}
+			}
+		}
+		break;
+	case ABORT_TASK_SET:
+		{
+			/* Obtain node ptr */
+			pndl = lpfc_findnode_scsiid(phba, target);
+			if (pndl) {
+				elx_cmd = elx_get_scsi_buf(phba);
+				if (elx_cmd) {
+					elx_cmd->scsi_hba = phba;
+					elx_cmd->scsi_bus = 0;
+					elx_cmd->scsi_target = target;
+					elx_cmd->scsi_lun = lun;
+					ret =
+					    elx_scsi_lun_reset(elx_cmd, phba, 0,
+							       target, lun,
+							       (flag |
+								ELX_ISSUE_ABORT_TSET));
+					elx_free_scsi_buf(elx_cmd);
+					elx_cmd = 0;
+				}
+			}
+		}
+		break;
+	}
+
+	return (ret);
+}
+
+void
+lpfc_get_hba_model_desc(elxHBA_t * phba, uint8_t * mdp, uint8_t * descp)
+{
+	LPFCHBA_t *plhba;
+	elx_vpd_t *vp;
+	uint32_t id;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	vp = &phba->vpd;
+
+	id = elx_read_pci(phba, PCI_VENDOR_ID_REGISTER);
+
+	switch ((id >> 16) & 0xffff) {
+	case PCI_DEVICE_ID_SUPERFLY:
+		if ((vp->rev.biuRev == 1) ||
+		    (vp->rev.biuRev == 2) || (vp->rev.biuRev == 3)) {
+			if (mdp) {
+				memcpy(mdp, "LP7000", 8);
+			}
+			if (descp) {
+				memcpy(descp,
+				       "Emulex LightPulse LP7000 1 Gigabit PCI Fibre Channel Adapter",
+				       62);
+			}
+		} else {
+			if (mdp) {
+				memcpy(mdp, "LP7000E", 9);
+			}
+			if (descp) {
+				memcpy(descp,
+				       "Emulex LightPulse LP7000E 1 Gigabit PCI Fibre Channel Adapter",
+				       62);
+			}
+		}
+		break;
+	case PCI_DEVICE_ID_DRAGONFLY:
+		if (mdp) {
+			memcpy(mdp, "LP8000", 8);
+		}
+		if (descp) {
+			memcpy(descp,
+			       "Emulex LightPulse LP8000 1 Gigabit PCI Fibre Channel Adapter",
+			       62);
+		}
+		break;
+	case PCI_DEVICE_ID_CENTAUR:
+		if (FC_JEDEC_ID(vp->rev.biuRev) == CENTAUR_2G_JEDEC_ID) {
+			if (mdp) {
+				memcpy(mdp, "LP9002", 8);
+			}
+			if (descp) {
+				memcpy(descp,
+				       "Emulex LightPulse LP9002 2 Gigabit PCI Fibre Channel Adapter",
+				       62);
+			}
+		} else {
+			if (mdp) {
+				memcpy(mdp, "LP9000", 8);
+			}
+			if (descp) {
+				memcpy(descp,
+				       "Emulex LightPulse LP9000 1 Gigabit PCI Fibre Channel Adapter",
+				       62);
+			}
+		}
+		break;
+	case PCI_DEVICE_ID_RFLY:
+		{
+			if (mdp) {
+				memcpy(mdp, "LP952", 7);
+			}
+			if (descp) {
+				memcpy(descp,
+				       "Emulex LightPulse LP952 2 Gigabit PCI Fibre Channel Adapter",
+				       62);
+			}
+		}
+		break;
+	case PCI_DEVICE_ID_PEGASUS:
+		if (mdp) {
+			memcpy(mdp, "LP9802", 8);
+		}
+		if (descp) {
+			memcpy(descp,
+			       "Emulex LightPulse LP9802 2 Gigabit PCI Fibre Channel Adapter",
+			       62);
+		}
+		break;
+	case PCI_DEVICE_ID_THOR:
+		if (mdp) {
+			memcpy(mdp, "LP10000", 9);
+		}
+		if (descp) {
+			memcpy(descp,
+			       "Emulex LightPulse LP10000 2 Gigabit PCI Fibre Channel Adapter",
+			       63);
+		}
+		break;
+	case PCI_DEVICE_ID_VIPER:
+		if (mdp) {
+			memcpy(mdp, "LPX1000", 9);
+		}
+		if (descp) {
+			memcpy(descp,
+			       "Emulex LightPulse LPX1000 10 Gigabit PCI Fibre Channel Adapter",
+			       63);
+		}
+		break;
+	case PCI_DEVICE_ID_PFLY:
+		if (mdp) {
+			memcpy(mdp, "LP982", 7);
+		}
+		if (descp) {
+			memcpy(descp,
+			       "Emulex LightPulse LP982 2 Gigabit PCI Fibre Channel Adapter",
+			       62);
+		}
+		break;
+	case PCI_DEVICE_ID_TFLY:
+		if (mdp) {
+			memcpy(mdp, "LP1050", 8);
+		}
+		if (descp) {
+			memcpy(descp,
+			       "Emulex LightPulse LP1050 2 Gigabit PCI Fibre Channel Adapter",
+			       63);
+		}
+		break;
+	case PCI_DEVICE_ID_LP101:
+		if (mdp) {
+			memcpy(mdp, "LP101", 7);
+		}
+		if (descp) {
+			memcpy(descp,
+			       "Emulex LightPulse LP101 2 Gigabit PCI Fibre Channel Adapter",
+			       62);
+		}
+		break;
+	}
+}
+
+void
+lpfc_get_hba_SymbNodeName(elxHBA_t * phba, uint8_t * symbp)
+{
+	uint8_t buf[16];
+
+	lpfc_decode_firmware_rev(phba);
+	lpfc_get_hba_model_desc(phba, buf, NULL);
+	elx_str_sprintf(symbp, "Emulex %s FV%s DV%s",
+			buf, lpfc_fwrev_short, lpfc_release_version);
+}
+
+#include "lpfc_ip.h"
+
+extern int lpfc_nethdr;
+
+static uint8_t fcbroadcastaddr[FC_MAC_ADDRLEN] = {
+	0xff, 0xff, 0xff, 0xff, 0xff, 0xff
+};
+
+void
+lpfc_free_ip_buf_list(elxHBA_t * phba, DMABUFIP_t * pktp)
+{
+
+	DMABUFIP_t *tmp, *to_free;
+	tmp = pktp;
+	while (tmp) {
+		to_free = tmp;
+		tmp = (DMABUFIP_t *) tmp->dma.next;
+		elx_mem_put(phba, MEM_IP_RCV_BUF, (uint8_t *) to_free);
+	}
+}
+
+void
+lpfc_ip_unsol_event(elxHBA_t * phba,
+		    ELX_SLI_RING_t * pring, ELX_IOCBQ_t * piocbq)
+{
+	LPFCHBA_t *plhba;
+	ELX_SLI_t *psli;
+	IOCB_t *icmd;
+	DMABUFIP_t *pktp, *tmp_pkt;
+	DMABUFIP_t *pktp_end;
+	int i, cnt, pktsize;
+	IOCB_t *savecmd;
+	LPFC_NETHDR_t *net_hdr;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_BINDLIST_t *blp;
+	ELX_MBOXQ_t *mb;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	icmd = &piocbq->iocb;
+	savecmd = icmd;
+
+	if (++plhba->ip_stat->lpfn_recvintr_lsw == 0) {
+		plhba->ip_stat->lpfn_recvintr_msw++;
+	}
+
+	if (icmd->ulpStatus) {
+		/* Handle error status */
+		if ((icmd->ulpStatus == IOSTAT_LOCAL_REJECT) &&
+		    ((icmd->un.ulpWord[4] & 0xff) ==
+		     IOERR_RCV_BUFFER_WAITING)) {
+
+			if (!(plhba->fc_flag & FC_NO_RCV_BUF)) {
+				plhba->ip_stat->lpfn_NoRcvBuf++;
+				/* IP Response Ring <num> out of posted buffers */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0602,	/* ptr to msg struct */
+					       elx_mes0602,	/* ptr to msg */
+					       elx_msgBlk0602.msgPreambleStr,	/* begin varargs */
+					       pring->ringno, pring->missbufcnt, plhba->ip_stat->lpfn_NoRcvBuf);	/* end varargs */
+			}
+		} else
+			plhba->ip_stat->lpfn_ierrors++;
+
+		plhba->fc_flag |= FC_NO_RCV_BUF;
+		lpfc_ip_post_buffer(phba, &psli->ring[LPFC_IP_RING], 0);
+		/* Update dropped packet statistics here . */
+		plhba->ip_stat->lpfn_rx_dropped++;
+		return;
+	}
+
+	/* piocbq is a ptr to the first rcv IOCB in a chain of IOCBs.
+	 * The first being a CMD_RCV_SEQUENCE64_CX followed by a bunch of
+	 * CMD_IOCB_CONTINUE64_CN. The IOCBs are chained by piocbq->q_f
+	 * in a single linked list. CMD_RCV_SEQUENCE64_CX hold one BDE while
+	 * CMD_IOCB_CONTINUE64_CN holds up to 2 BDEs. Each BDE represents
+	 * a buffer that was posted to the IP ring.
+	 */
+	pktp = 0;
+	pktp_end = 0;
+	pktsize = 0;
+	cnt = 0;
+
+	/* Now lets step thru all the CMD_IOCB_CONTINUE64_CN IOCBs, if any */
+	while (piocbq) {
+		icmd = &piocbq->iocb;
+		for (i = 0; i < (int)icmd->ulpBdeCount; i++) {
+			if (pktp_end) {
+				pktp_end->dma.next =
+				    elx_sli_ringpostbuf_get(phba, pring,
+							    (elx_dma_addr_t)
+							    getPaddr(icmd->un.
+								     cont64[i].
+								     addrHigh,
+								     icmd->un.
+								     cont64[i].
+								     addrLow));
+				if (pktp_end->dma.next == 0) {
+					/* Error, cannot match physical address to posted buffer
+					 * Clean up pktp chain.
+					 */
+					lpfc_free_ip_buf_list(phba, pktp);
+					plhba->ip_stat->lpfn_rx_dropped++;
+					return;
+				}
+				pktp_end = (DMABUFIP_t *) pktp_end->dma.next;
+			} else {
+				pktp =
+				    (DMABUFIP_t *) elx_sli_ringpostbuf_get(phba,
+									   pring,
+									   (elx_dma_addr_t)
+									   getPaddr
+									   (icmd->
+									    un.
+									    cont64
+									    [i].
+									    addrHigh,
+									    icmd->
+									    un.
+									    cont64
+									    [i].
+									    addrLow));
+				pktp_end = pktp;
+				if (pktp_end == 0) {
+					/* Error, cannot match physical address to posted buffer
+					 * Clean up pktp chain.
+					 */
+					plhba->ip_stat->lpfn_rx_dropped++;
+					return;
+				}
+			}
+			pktp_end->dma.next = 0;
+			lpfc_set_pkt_len(pktp_end->ipbuf,
+					 icmd->un.cont64[i].tus.f.bdeSize);
+			pktsize += icmd->un.cont64[i].tus.f.bdeSize;
+
+			cnt++;
+		}
+		piocbq = piocbq->q_f;
+	}
+
+	if (++plhba->ip_stat->lpfn_ipackets_lsw == 0)
+		plhba->ip_stat->lpfn_ipackets_msw++;
+
+	plhba->ip_stat->lpfn_rcvbytes_lsw += pktsize;
+	if (plhba->ip_stat->lpfn_rcvbytes_lsw < pktsize)
+		plhba->ip_stat->lpfn_rcvbytes_msw++;
+
+	/* repost new buffers to the HBA to replace these buffers.
+	 * When the upper layer is done processing the buffer in the pktp chain,
+	 * they should be put back in the MEM_IP_RCV_BUF pool.
+	 */
+	lpfc_ip_post_buffer(phba, &psli->ring[LPFC_IP_RING], cnt);
+
+	net_hdr = (LPFC_NETHDR_t *) lpfc_get_pkt_data(pktp->ipbuf);
+
+	/* If this is first broadcast received from that address */
+	if (savecmd->un.xrseq.w5.hcsw.Fctl & BC) {
+	      bcst:
+		if (++plhba->ip_stat->lpfn_brdcstrcv_lsw == 0) {
+			plhba->ip_stat->lpfn_brdcstrcv_msw++;
+		}
+		memcpy(net_hdr->fc_destname.IEEE, (char *)fcbroadcastaddr,
+		       FC_MAC_ADDRLEN);
+
+		if ((ndlp = lpfc_findnode_did(phba, NLP_SEARCH_ALL,
+					      (uint32_t) savecmd->un.xrseq.
+					      xrsqRo)) == 0) {
+
+			/* Need to cache the did / portname */
+			if ((ndlp =
+			     (LPFC_NODELIST_t *) elx_mem_get(phba, MEM_NLP))) {
+				memset((void *)ndlp, 0,
+				       sizeof (LPFC_NODELIST_t));
+				ndlp->nlp_DID = savecmd->un.xrseq.xrsqRo;
+				memcpy(&ndlp->nlp_portname,
+				       &net_hdr->fc_srcname,
+				       sizeof (NAME_TYPE));
+				ndlp->nlp_state = NLP_MAPPED_LIST;
+				blp = ndlp->nlp_listp_bind;
+				if (blp != NULL)
+					lpfc_nlp_bind(phba, blp);
+			} else {
+			      dropout:
+				lpfc_free_ip_buf_list(phba, pktp);
+				plhba->ip_stat->lpfn_rx_dropped++;
+				/* Update the statistics for dropped packets here. */
+				return;
+			}
+		}
+	} else {
+		if ((ndlp = lpfc_findnode_rpi(phba, savecmd->ulpIoTag)) == 0) {
+			if (net_hdr->fc_destname.IEEE[0] == 0xff) {
+				if ((net_hdr->fc_destname.IEEE[1] == 0xff) &&
+				    (net_hdr->fc_destname.IEEE[2] == 0xff) &&
+				    (net_hdr->fc_destname.IEEE[3] == 0xff) &&
+				    (net_hdr->fc_destname.IEEE[4] == 0xff) &&
+				    (net_hdr->fc_destname.IEEE[5] == 0xff)) {
+					goto bcst;
+				}
+			}
+			/* Need to send LOGOUT for this RPI */
+			if ((mb = (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX))) {
+				lpfc_read_rpi(phba,
+					      (uint32_t) savecmd->ulpIoTag,
+					      (ELX_MBOXQ_t *) mb,
+					      (uint32_t) ELS_CMD_LOGO);
+				if (elx_sli_issue_mbox
+				    (phba, (ELX_MBOXQ_t *) mb,
+				     MBX_NOWAIT) != MBX_BUSY) {
+					elx_mem_put(phba, MEM_MBOX,
+						    (uint8_t *) mb);
+				}
+			}
+			goto dropout;
+		}
+	}
+
+	if ((plhba->lpfn_ip_rcv)) {
+		(plhba->lpfn_ip_rcv) (phba, pktp, pktsize);
+	}
+
+	tmp_pkt = pktp;
+
+	/* Do not free the message block. Free only its DMA mapping. */
+	while (tmp_pkt) {
+		tmp_pkt->ipbuf = NULL;
+		tmp_pkt = (DMABUFIP_t *) tmp_pkt->dma.next;
+	}
+	lpfc_free_ip_buf_list(phba, pktp);
+
+}
+
+LPFC_IP_BUF_t *
+lpfc_get_ip_buf(elxHBA_t * phba)
+{
+	LPFC_IP_BUF_t *pib;
+	DMABUF_t *pdma;
+	ULP_BDE64 *bpl;
+	IOCB_t *cmd;
+	uint8_t *ptr;
+	uint32_t cnt;
+	elx_dma_addr_t dma;
+
+	/* Get a IP buffer for an I/O */
+	if ((pib = (LPFC_IP_BUF_t *) elx_mem_get(phba, MEM_IP_BUF)) == 0) {
+		return (0);
+	}
+	memset(pib, 0, sizeof (LPFC_IP_BUF_t));
+
+	/* Get a IP DMA extention for an I/O */
+	/*
+	 * The DMA buffer for FC Network Header and BPL use MEM_IP_DMA_EXT
+	 *  memory segment.
+	 *
+	 *    The size of MEM_BPL   = 1024 bytes.
+	 *
+	 *    The size of FC Header  = 24 bytes + 8 extra.
+	 *    The size of ULP_BDE64 = 12 bytes and driver can only support
+	 *       LPFC_IP_INITIAL_BPL_SIZE (80) S/G segments.
+	 *
+	 *    Total usage for each I/O use 992 bytes.
+	 */
+	if ((pdma = (DMABUF_t *) elx_mem_get(phba, MEM_IP_DMA_EXT)) == 0) {
+		elx_mem_put(phba, MEM_IP_BUF, (uint8_t *) pib);
+		return (0);
+	}
+	/* Save DMABUF ptr for put routine */
+	pib->dma_ext = pdma;
+
+	/* This is used to save extra BPLs that are chained to pdma.
+	 * Only used if I/O has more then 80 data segments.
+	 */
+	pdma->next = 0;
+
+	/* Save virtual ptr to BPL and phba */
+	cnt = 0;
+	ptr = (uint8_t *) pdma->virt;
+	memset(ptr, 0, sizeof (LPFC_IPHDR_t));
+	ptr += (sizeof (LPFC_IPHDR_t) + 0x8);	/* extra 8 to be safe */
+	pib->ip_bpl = (ULP_BDE64 *) ptr;
+	pib->ip_hba = phba;
+
+	dma = pdma->phys;
+	if (lpfc_nethdr == 0) {
+		pib->net_hdr = (LPFC_IPHDR_t *) pdma->virt;
+		bpl = pib->ip_bpl;
+
+		/* Setup FC Network Header */
+		bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(dma));
+		bpl->addrLow = PCIMEM_LONG(putPaddrLow(dma));
+		bpl->tus.f.bdeSize = sizeof (LPFC_IPHDR_t);
+		bpl->tus.f.bdeFlags = BDE64_SIZE_WORD;
+		bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+		bpl++;
+		cnt++;
+		pib->ip_bpl++;
+	}
+
+	dma += (sizeof (LPFC_IPHDR_t) + 0x8);
+
+	cmd = &pib->cur_iocbq.iocb;
+	cmd->un.xseq64.bdl.ulpIoTag32 = 0;
+	cmd->un.xseq64.bdl.addrHigh = putPaddrHigh(dma);
+	cmd->un.xseq64.bdl.addrLow = putPaddrLow(dma);
+	cmd->un.xseq64.bdl.bdeSize = (cnt * sizeof (ULP_BDE64));
+	cmd->un.xseq64.bdl.bdeFlags = BUFF_TYPE_BDL;
+	cmd->ulpBdeCount = 1;
+	cmd->ulpOwner = OWN_CHIP;
+	return (pib);
+}
+
+void
+lpfc_free_ip_buf(LPFC_IP_BUF_t * pib)
+{
+	elxHBA_t *phba;
+	DMABUF_t *pdma;
+	DMABUF_t *pbpl;
+	DMABUF_t *pnext;
+
+	if (pib) {
+		phba = pib->ip_hba;
+		if ((pdma = pib->dma_ext)) {
+			/* Check to see if there were any extra buffers used to chain BPLs */
+			pbpl = pdma->next;
+			while (pbpl) {
+				pnext = pbpl->next;
+				elx_mem_put(phba, MEM_BPL, (uint8_t *) pbpl);
+				pbpl = pnext;
+			}
+			elx_mem_put(phba, MEM_IP_DMA_EXT, (uint8_t *) pdma);
+		}
+		elx_mem_put(phba, MEM_IP_BUF, (uint8_t *) pib);
+	}
+	return;
+}
+
+void
+lpfc_ip_finish_cmd(elxHBA_t * phba,
+		   ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	LPFCHBA_t *plhba;
+	LPFC_IP_BUF_t *pib;
+	IOCB_t *irsp;
+	LPFC_NODELIST_t *ndlp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	irsp = &rspiocb->iocb;
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+	pib = (LPFC_IP_BUF_t *) cmdiocb->context2;
+
+	if (++plhba->ip_stat->lpfn_xmitintr_lsw == 0) {
+		plhba->ip_stat->lpfn_xmitintr_msw++;
+	}
+
+	plhba->ip_stat->lpfn_xmitque_cur--;
+
+	/* If the IP packet, XMIT_SEQUENCE64 returns an error, a new XRI
+	 * must be created for subsequent requests.
+	 */
+	if (irsp->ulpStatus) {
+		plhba->ip_stat->lpfn_oerrors++;
+		/* Xmit Sequence completion error */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0603,	/* ptr to msg struct */
+			       elx_mes0603,	/* ptr to msg */
+			       elx_msgBlk0603.msgPreambleStr,	/* begin varargs */
+			       irsp->ulpStatus, irsp->ulpIoTag, irsp->un.ulpWord[4], ndlp->nlp_DID);	/* end varargs */
+
+		if ((irsp->ulpContext == ndlp->nlp_xri) &&
+		    (!(ndlp->nlp_flag & NLP_CREATE_XRI_INP))) {
+			ndlp->nlp_xri = 0;
+			lpfc_ip_create_xri(phba, 0, ndlp);
+		}
+	} else {
+		/* Increment number of packets txmited */
+		if (++plhba->ip_stat->lpfn_opackets_lsw == 0)
+			plhba->ip_stat->lpfn_opackets_msw++;
+		/* Increment number of bytes txmited */
+
+	}
+	if (pib) {
+		lpfc_ip_unprep_io(phba, pib, 1);
+		lpfc_free_ip_buf(pib);
+	}
+	return;
+}
+
+int
+lpfc_ip_xri_wait(elxHBA_t * phba, LPFC_IP_BUF_t * pib, LPFC_NODELIST_t * ndlp)
+{
+	int ret_val;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ret_val = 0;
+
+	if (!(ndlp->nlp_flag & NLP_CREATE_XRI_INP)) {
+		/* pib, the initial packet, will be sent when create_xri completes */
+		ret_val = lpfc_ip_create_xri(phba, pib, ndlp);
+		if (ret_val) {
+			return (ret_val);
+		}
+	} else {
+		/* The XRI was sent previously.  Since the lpfc_ip_create_xri routine queues the 
+		 * first ip buffer into the xri create iocb command, queue this ip
+		 * buffer into the ndlp list.
+		 */
+		elx_tqs_enqueue(&ndlp->nlp_listp_ipbuf, pib, ip_buf_next);
+	}
+
+	return (0);
+}
+
+int
+lpfc_ip_xmit(LPFC_IP_BUF_t * pib)
+{
+	elxHBA_t *phba;
+	ELX_SLI_t *psli;
+	ELX_IOCBQ_t *piocbq;
+	IOCB_t *piocb;
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	ELX_SLI_RING_t *pring;
+	LPFC_NODE_FARP_PEND_t *pndlpfarp;
+	int room;
+	int farp_ret = 0;
+	uint8_t issue_farp = 0;
+
+	ndlp = lpfc_ip_find_device(pib, &phba);
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* various error checks: HBA online (cable plugged), this target
+	   not in error recovery of some sort */
+	if ((ndlp != 0) && (ndlp->nle.nlp_failMask & ELX_DEV_FATAL_ERROR)) {
+		plhba->ip_stat->lpfn_tx_dropped++;
+		return (ENXIO);
+	}
+
+	/* If a node was not found and there was no error, set the issue_farp flag
+	 * so that the routine properly initializes the iocb.
+	 */
+	if (ndlp == NULL)
+		issue_farp = 1;
+
+	/* allocate an iocb command */
+	piocbq = &(pib->cur_iocbq);
+	piocb = &piocbq->iocb;
+	psli = &phba->sli;
+
+	if (issue_farp == 0)
+		pib->ndlp = ndlp;
+
+	if (lpfc_ip_prep_io(phba, pib) == 1) {
+
+		plhba->ip_stat->lpfn_tx_dropped++;
+		return (ENXIO);
+	}
+
+	/* Setup fibre channel header information */
+	piocb->un.xrseq.w5.hcsw.Fctl = 0;
+	piocb->un.xrseq.w5.hcsw.Dfctl = FC_NET_HDR;	/* network headers */
+	piocb->un.xrseq.w5.hcsw.Rctl = FC_UNSOL_DATA;
+	piocb->un.xrseq.w5.hcsw.Type = FC_LLC_SNAP;
+
+	/* Get an iotag and finish setup of IOCB  */
+	piocb->ulpIoTag =
+	    elx_sli_next_iotag(phba, &phba->sli.ring[psli->ip_ring]);
+
+	/* Set the timeout value */
+	piocb->ulpTimeout = LPFC_IP_TOV;
+	piocbq->drvrTimeout = LPFC_IP_TOV + ELX_DRVR_TIMEOUT;
+
+	if (issue_farp == 0) {
+		piocb->ulpContext = ndlp->nle.nlp_rpi;
+		if (ndlp->nle.nlp_ip_info & NLP_FCP_2_DEVICE) {
+			piocb->ulpFCP2Rcvy = 1;
+		}
+	}
+
+	/* set up iocb return path by setting the context2 field to pib
+	 * and the completion function to lpfc_ip_finish_cmd function
+	 */
+	piocbq->iocb_cmpl = lpfc_ip_finish_cmd;
+
+	if (issue_farp == 0)
+		piocbq->context1 = ndlp;
+
+	piocbq->context2 = pib;
+
+	if (issue_farp == 0) {
+		if (ndlp->nlp_DID == Bcast_DID) {
+			piocb->ulpCommand = CMD_XMIT_BCAST64_CN;
+		} else {
+			piocb->ulpCommand = CMD_XMIT_SEQUENCE64_CX;
+			piocb->ulpClass = (ndlp->nle.nlp_ip_info & 0x0f);
+			if (ndlp->nlp_xri == 0) {
+				/* If we don't have an XRI, we must first create one */
+				if (lpfc_ip_xri_wait(phba, pib, ndlp)) {
+					plhba->ip_stat->lpfn_tx_dropped++;
+					return (ENXIO);
+				}
+				return (0);
+			}
+			piocb->ulpContext = ndlp->nlp_xri;
+		}
+	}
+
+	pring = &phba->sli.ring[psli->ip_ring];
+	room = pring->txq.q_max - plhba->ip_stat->lpfn_xmitque_cur;
+
+	if ((pring->txq.q_max > 0) && (room < 0)) {
+		/* No room on IP xmit queue */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0605,	/* ptr to msg struct */
+			       elx_mes0605,	/* ptr to msg */
+			       elx_msgBlk0605.msgPreambleStr,	/* begin varargs */
+			       pring->missbufcnt);	/* end varargs */
+		plhba->ip_stat->lpfn_tx_dropped++;
+		lpfc_ip_unprep_io(phba, pib, 0);
+		return (ENXIO);
+	}
+
+	/* Either issue a FARP Request or just issue the IOCB. */
+	if (issue_farp == 1) {
+		/* Allocate a new NODE_FARP_PEND structure, initialize it, and
+		 * issue the farp.  
+		 */
+		pndlpfarp =
+		    (LPFC_NODE_FARP_PEND_t *)
+		    elx_kmem_zalloc(sizeof (LPFC_NODE_FARP_PEND_t),
+				    ELX_MEM_NDELAY);
+		if (pndlpfarp == NULL)
+			return ENXIO;
+
+		memcpy((void *)&pndlpfarp->rnode_addr,
+		       (void *)&pib->net_hdr->fcnet.fc_destname,
+		       sizeof (NAME_TYPE));
+		elx_tqs_enqueue(&pndlpfarp->fc_ipbuf_list_farp_wait, pib,
+				ip_buf_next);
+
+		pndlpfarp->fc_ipfarp_tmo =
+		    elx_clk_set(phba, plhba->fc_ipfarp_timeout,
+				lpfc_ipfarp_timeout,
+				(void *)&pndlpfarp->rnode_addr, 0);
+		if (pndlpfarp->fc_ipfarp_tmo == NULL) {
+			farp_ret = ENXIO;
+			elx_kmem_free(pndlpfarp,
+				      sizeof (LPFC_NODE_FARP_PEND_t));
+			return (farp_ret);
+		}
+
+		/* Send a FARP to resolve this node's WWPN to Port ID and generate a PLOGI. */
+		farp_ret = 0;
+		farp_ret = lpfc_issue_els_farp(phba,
+					       (uint8_t *) & pib->net_hdr->
+					       fcnet.fc_destname,
+					       LPFC_FARP_BY_WWPN);
+		if (farp_ret != 0) {
+			farp_ret = ENXIO;
+			elx_clk_can(phba, pndlpfarp->fc_ipfarp_tmo);
+			pib =
+			    elx_tqs_dequeuefirst(&pndlpfarp->
+						 fc_ipbuf_list_farp_wait,
+						 ip_buf_next);
+			elx_kmem_free(pndlpfarp,
+				      sizeof (LPFC_NODE_FARP_PEND_t));
+		} else {
+			elx_tqs_enqueue(&plhba->fc_node_farp_list, pndlpfarp,
+					pnext);
+		}
+
+		return (farp_ret);
+	}
+
+	if (elx_sli_issue_iocb(phba, pring,
+			       piocbq, SLI_IOCB_USE_TXQ) == IOCB_ERROR) {
+		plhba->ip_stat->lpfn_tx_dropped++;
+		lpfc_ip_unprep_io(phba, pib, 0);
+		return (ENXIO);
+	}
+
+	plhba->ip_stat->lpfn_xmitque_cur++;
+	return (0);
+}
+
+LPFC_NODELIST_t *
+lpfc_ip_find_device(LPFC_IP_BUF_t * pib, elxHBA_t ** pphba)
+{
+	elxHBA_t *phba;
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	uint32_t j;
+	uint8_t *addr;
+
+	phba = pib->ip_hba;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	*pphba = phba;
+	addr = (uint8_t *) pib->net_hdr;
+	addr += 2;
+
+	ndlp = plhba->fc_nlpunmap_start;
+	if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+		ndlp = plhba->fc_nlpmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+
+		/* IF portname matches IEEE address, return LPFC_NODELIST_t entry */
+		if ((ndlp->nlp_portname.IEEE[0] == addr[0])) {
+			if ((ndlp->nlp_state < NLP_STE_REG_LOGIN_ISSUE) ||
+			    ((ndlp->nlp_DID != Bcast_DID) &&
+			     ((ndlp->nlp_DID & CT_DID_MASK) == CT_DID_MASK))) {
+				ndlp =
+				    (LPFC_NODELIST_t *) ndlp->nle.
+				    nlp_listp_next;
+				if (ndlp ==
+				    (LPFC_NODELIST_t *) & plhba->
+				    fc_nlpunmap_start)
+					ndlp = plhba->fc_nlpmap_start;
+				continue;
+			}
+
+			/*
+			 * Well-Known address ports have the same MAC address
+			 * as one of the IP port, skip all the well-known ports.
+			 */
+			if (((ndlp->nlp_DID & WELL_KNOWN_DID_MASK) ==
+			     WELL_KNOWN_DID_MASK)
+			    && (ndlp->nlp_DID != Bcast_DID)) {
+				continue;
+			}
+
+			/* check rest of bytes in address / portname */
+			for (j = 1; j < FC_MAC_ADDRLEN; j++) {
+				if (ndlp->nlp_portname.IEEE[j] != addr[j])
+					break;
+			}
+
+			if (j == FC_MAC_ADDRLEN) {
+				return (ndlp);
+			}
+		}
+		ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		if (ndlp == (LPFC_NODELIST_t *) & plhba->fc_nlpunmap_start)
+			ndlp = plhba->fc_nlpmap_start;
+	}
+
+	/* Not in unmap or map list. */
+	ndlp = 0;
+	if (ndlp == 0) {
+		/* If high bit is set, its either broadcast or multicast */
+		if (pib->net_hdr->fcnet.fc_destname.IEEE[0] & 0x80) {
+			ndlp = &plhba->fc_nlp_bcast;
+		}
+	}
+
+	return (ndlp);
+}
+
+/************************************************************************/
+/* lpfc_ip_create_xri: create an exchange for the IP traffice with the  */
+/* remote node                                                          */
+/************************************************************************/
+int
+lpfc_ip_create_xri(elxHBA_t * phba, LPFC_IP_BUF_t * pib, LPFC_NODELIST_t * ndlp)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *iocb;
+	LPFCHBA_t *plhba;
+
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	pring = &psli->ring[LPFC_IP_RING];	/* IP ring */
+
+	/* Allocate buffer for  command iocb */
+	if ((iocb = (ELX_IOCBQ_t *) elx_mem_get(phba, MEM_IOCB | MEM_PRI)) == 0) {
+		return (1);
+	}
+	memset((void *)iocb, 0, sizeof (ELX_IOCBQ_t));
+	ndlp->nlp_flag |= NLP_CREATE_XRI_INP;
+	ndlp->nle.nlp_type |= NLP_IP_NODE;
+	icmd = &iocb->iocb;
+
+	/* set up an iotag so we can match the completion to an iocb/mbuf */
+	icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+	icmd->ulpContext = ndlp->nle.nlp_rpi;
+	icmd->ulpLe = 1;
+	icmd->ulpCommand = CMD_CREATE_XRI_CR;
+	icmd->ulpOwner = OWN_CHIP;
+
+	iocb->context1 = (uint8_t *) ndlp;
+	iocb->context2 = (uint8_t *) pib;
+	iocb->iocb_cmpl = lpfc_ip_xri_cmpl;
+
+	/* The XRI create is on its way.  Start a timer that will flush the
+	 * pending IP buffers if the XRI is still 0.
+	 */
+	ndlp->nlp_xri_tmofunc =
+	    elx_clk_set(phba, plhba->fc_ipxri_timeout, lpfc_ip_xri_timeout,
+			(void *)iocb, 0);
+	if (ndlp->nlp_xri_tmofunc == NULL) {
+		return (1);
+	}
+
+	elx_printf_log(phba->brd_no, &elx_msgBlk0606, elx_mes0606, elx_msgBlk0606.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID);	/* end varargs */
+
+	if (elx_sli_issue_iocb(phba, pring, iocb, SLI_IOCB_USE_TXQ) ==
+	    IOCB_ERROR) {
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+	}
+	return (0);
+}
+
+void
+lpfc_ip_xri_cmpl(elxHBA_t * phba, ELX_IOCBQ_t * cmdiocb, ELX_IOCBQ_t * rspiocb)
+{
+	IOCB_t *irsp;
+	ELX_SLI_t *psli;
+	LPFC_NODELIST_t *ndlp;
+	LPFC_NODE_FARP_PEND_t *pndlpfarp;
+	LPFC_IP_BUF_t *pib;
+	ELX_IOCBQ_t *piocbq;
+	IOCB_t *piocb;
+	LPFCHBA_t *plhba;
+	uint16_t loop_cnt;
+
+	pndlpfarp = NULL;
+	psli = &phba->sli;
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	irsp = &rspiocb->iocb;
+	ndlp = (LPFC_NODELIST_t *) cmdiocb->context1;
+	ndlp->nlp_flag &= ~NLP_CREATE_XRI_INP;
+
+	/* Cancel the timer callback.  This routine will handle the completion
+	 * and pending ip buffers.
+	 */
+	if (ndlp->nlp_xri_tmofunc) {
+		elx_clk_can(phba, ndlp->nlp_xri_tmofunc);
+		ndlp->nlp_xri_tmofunc = 0;
+	}
+
+	elx_printf_log(phba->brd_no, &elx_msgBlk0607, elx_mes0607, elx_msgBlk0607.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, irsp->ulpStatus, irsp->ulpContext);	/* end varargs */
+
+	/* Look to see if this node depended on a FARP and has buffers pending in that list. 
+	 * The driver needs that information whether or not the XRI completed successfully.
+	 */
+	if (elx_tqs_getcount(&plhba->fc_node_farp_list)) {
+		pndlpfarp =
+		    elx_tqs_dequeuefirst(&plhba->fc_node_farp_list, pnext);
+		loop_cnt = 0;
+		while (pndlpfarp != NULL) {
+			if ((lpfc_geportname
+			     (&pndlpfarp->rnode_addr, &ndlp->nlp_portname) != 2)
+			    &&
+			    (lpfc_geportname
+			     (&pndlpfarp->rnode_addr,
+			      &ndlp->nlp_nodename) != 2)) {
+				elx_tqs_enqueue(&plhba->fc_node_farp_list,
+						pndlpfarp, pnext);
+				pndlpfarp =
+				    elx_tqs_dequeuefirst(&plhba->
+							 fc_node_farp_list,
+							 pnext);
+			} else
+				break;
+
+			loop_cnt += 1;
+			if (loop_cnt > plhba->fc_node_farp_list.q_cnt)
+				pndlpfarp = NULL;
+		}
+	}
+
+	if (irsp->ulpStatus) {
+		if (pndlpfarp) {
+			/* Free all ip buffers from the plhba list. */
+			pib =
+			    elx_tqs_dequeuefirst(&pndlpfarp->
+						 fc_ipbuf_list_farp_wait,
+						 ip_buf_next);
+			while (pib != NULL) {
+				lpfc_free_ip_buf(pib);
+				pib =
+				    elx_tqs_dequeuefirst(&pndlpfarp->
+							 fc_ipbuf_list_farp_wait,
+							 ip_buf_next);
+			}
+			/* The FARP is now done.  Free all resources allocated to it. */
+			elx_kmem_free(pndlpfarp,
+				      sizeof (LPFC_NODE_FARP_PEND_t));
+		}
+
+		/* If the response iocb has a ULP error status, free all pending IP buffers
+		 * starting with the xri command iocb. 
+		 */
+		pib = (LPFC_IP_BUF_t *) cmdiocb->context2;
+		if (pib) {
+			lpfc_free_ip_buf(pib);
+		}
+
+		/* Now free all ip buffers staged in the node's ip buffer linked list.  */
+		pib = elx_tqs_dequeuefirst(&ndlp->nlp_listp_ipbuf, ip_buf_next);
+		while (pib != NULL) {
+			lpfc_free_ip_buf(pib);
+			pib =
+			    elx_tqs_dequeuefirst(&ndlp->nlp_listp_ipbuf,
+						 ip_buf_next);
+		}
+
+		/* Reinitialize the list as empty and free the cmd iocb. */
+		ndlp->nlp_listp_ipbuf.q_first = ndlp->nlp_listp_ipbuf.q_last =
+		    NULL;
+		elx_mem_put(phba, MEM_IOCB, (uint8_t *) cmdiocb);
+		return;
+	}
+
+	ndlp->nlp_xri = irsp->ulpContext;
+
+	/* See if the driver has packets initially pending from a FARP request
+	 * and send them. 
+	 */
+	if (pndlpfarp) {
+		if (elx_tqs_getcount(&pndlpfarp->fc_ipbuf_list_farp_wait)) {
+			pib =
+			    elx_tqs_dequeuefirst(&pndlpfarp->
+						 fc_ipbuf_list_farp_wait,
+						 ip_buf_next);
+			while (pib != NULL) {
+				pib->ndlp = ndlp;
+				piocbq = &(pib->cur_iocbq);
+				piocb = &piocbq->iocb;
+
+				/* IOCBs for IP packets pended while the FARP process completes need more
+				 * initialization prior to issuing to the SLI because there was no node
+				 * information at the time of the transmit.
+				 */
+				piocbq->context1 = ndlp;
+				if (ndlp->nle.nlp_ip_info & NLP_FCP_2_DEVICE)
+					piocb->ulpFCP2Rcvy = 1;
+
+				if (ndlp->nlp_DID == Bcast_DID) {
+					piocb->ulpCommand = CMD_XMIT_BCAST64_CN;
+					piocb->ulpContext = ndlp->nle.nlp_rpi;
+				} else {
+					piocb->ulpCommand =
+					    CMD_XMIT_SEQUENCE64_CX;
+					piocb->ulpClass =
+					    (ndlp->nle.nlp_ip_info & 0x0f);
+					piocb->ulpContext = ndlp->nlp_xri;
+				}
+
+				elx_sli_issue_iocb(phba,
+						   &psli->ring[psli->ip_ring],
+						   piocbq, SLI_IOCB_USE_TXQ);
+				pib =
+				    elx_tqs_dequeuefirst(&pndlpfarp->
+							 fc_ipbuf_list_farp_wait,
+							 ip_buf_next);
+			}
+		}
+	}
+
+	/* Send the initial packet stored in the completed XRI_CREATE IOCB command. */
+	pib = (LPFC_IP_BUF_t *) cmdiocb->context2;
+	if (pib) {
+		piocbq = &(pib->cur_iocbq);
+		piocb = &piocbq->iocb;
+		piocb->ulpContext = ndlp->nlp_xri;
+		elx_sli_issue_iocb(phba, &psli->ring[psli->ip_ring], piocbq,
+				   SLI_IOCB_USE_TXQ);
+	}
+
+	/* Send all subsequent packets waiting for CREATE_XRI to finish.  These packets
+	 * are linked in the node's linked list of ip buffers to preserve any ordering
+	 * constraints. 
+	 */
+	pib = elx_tqs_dequeuefirst(&ndlp->nlp_listp_ipbuf, ip_buf_next);
+	while (pib != NULL) {
+		piocbq = &(pib->cur_iocbq);
+		piocb = &piocbq->iocb;
+		piocb->ulpContext = ndlp->nlp_xri;
+		elx_sli_issue_iocb(phba, &psli->ring[psli->ip_ring], piocbq,
+				   SLI_IOCB_USE_TXQ);
+		pib = elx_tqs_dequeuefirst(&ndlp->nlp_listp_ipbuf, ip_buf_next);
+	}
+
+	/* Recover the IOCB that carried the xri create request.  The command
+	 * has completed.
+	 */
+	elx_mem_put(phba, MEM_IOCB, (uint8_t *) cmdiocb);
+	return;
+}
+
+int
+lpfc_ip_flush_iocb(elxHBA_t * phba,
+		   ELX_SLI_RING_t * pring,
+		   LPFC_NODELIST_t * ndlp, LPFC_IP_FLUSH_EVENT flush_event)
+{
+	ELX_SLI_t *psli;
+	psli = &phba->sli;
+
+	if (flush_event == FLUSH_RING) {
+		/* This call aborts all iocbs on the specified ring. */
+		elx_sli_abort_iocb_ring(phba, &phba->sli.ring[psli->ip_ring],
+					ELX_SLI_ABORT_IMED);
+	} else if (flush_event == FLUSH_NODE) {
+		/* This call aborts all iocbs on the specified ring matching the given
+		 * ndlp.
+		 */
+		elx_sli_abort_iocb_context1(phba,
+					    &phba->sli.ring[psli->ip_ring],
+					    ndlp);
+	}
+
+	return (0);
+}
+
+int
+lpfc_ip_post_buffer(elxHBA_t * phba, ELX_SLI_RING_t * pring, int cnt)
+{
+	IOCB_t *icmd;
+	ELX_IOCBQ_t *iocb;
+	DMABUFIP_t *mp1, *mp2;
+
+	cnt += pring->missbufcnt;
+	/* While there are buffers to post */
+	while (cnt > 0) {
+		/* Allocate buffer for  command iocb */
+		if ((iocb =
+		     (ELX_IOCBQ_t *) elx_mem_get(phba,
+						 MEM_IOCB | MEM_PRI)) == 0) {
+			pring->missbufcnt = cnt;
+			goto out;
+		}
+		memset((void *)iocb, 0, sizeof (ELX_IOCBQ_t));
+		icmd = &iocb->iocb;
+
+		/* 2 buffers can be posted per command */
+		/* Allocate buffer to post */
+		if ((mp1 =
+		     (DMABUFIP_t *) elx_mem_get(phba, MEM_IP_RCV_BUF)) == 0) {
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+			pring->missbufcnt = cnt;
+			goto out;
+		}
+		/* Allocate buffer to post */
+		if (cnt > 1) {
+			if ((mp2 =
+			     (DMABUFIP_t *) elx_mem_get(phba,
+							MEM_IP_RCV_BUF)) == 0) {
+				elx_mem_put(phba, MEM_IP_RCV_BUF,
+					    (uint8_t *) mp1);
+				elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+				pring->missbufcnt = cnt;
+				goto out;
+			}
+		} else {
+			mp2 = 0;
+		}
+		icmd->un.cont64[0].addrHigh = putPaddrHigh(mp1->dma.phys);
+		icmd->un.cont64[0].addrLow = putPaddrLow(mp1->dma.phys);
+		icmd->un.cont64[0].tus.f.bdeSize = LPFC_IP_RCV_BUF_SIZE;
+		icmd->ulpBdeCount = 1;
+		cnt--;
+		if (mp2) {
+			icmd->un.cont64[1].addrHigh =
+			    putPaddrHigh(mp2->dma.phys);
+			icmd->un.cont64[1].addrLow = putPaddrLow(mp2->dma.phys);
+
+			icmd->un.cont64[1].tus.f.bdeSize = LPFC_IP_RCV_BUF_SIZE;
+			cnt--;
+			icmd->ulpBdeCount = 2;
+		}
+
+		icmd->ulpCommand = CMD_QUE_RING_BUF64_CN;
+		icmd->ulpIoTag = elx_sli_next_iotag(phba, pring);
+		icmd->ulpLe = 1;
+		icmd->ulpOwner = OWN_CHIP;
+
+		if (elx_sli_issue_iocb(phba, pring, iocb, SLI_IOCB_USE_TXQ) ==
+		    IOCB_ERROR) {
+			elx_mem_put(phba, MEM_IP_RCV_BUF, (uint8_t *) mp1);
+			if (mp2) {
+				elx_mem_put(phba, MEM_IP_RCV_BUF,
+					    (uint8_t *) mp2);
+			}
+			elx_mem_put(phba, MEM_IOCB, (uint8_t *) iocb);
+			pring->missbufcnt = cnt;
+			goto out;;
+		}
+
+		elx_sli_ringpostbuf_put(phba, pring, &mp1->dma);
+		if (mp2) {
+			elx_sli_ringpostbuf_put(phba, pring, &mp2->dma);
+		}
+	}
+	pring->missbufcnt = 0;
+	return (0);
+      out:
+	/* Post buffer for IP ring <num> failed */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0604,	/* ptr to msg struct */
+		       elx_mes0604,	/* ptr to msg */
+		       elx_msgBlk0604.msgPreambleStr,	/* begin varargs */
+		       pring->ringno, pring->missbufcnt);	/* end varargs */
+	return (cnt);
+
+}
+
+void
+lpfc_ipfarp_timeout(elxHBA_t * phba, void *l1, void *l2)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFC_IP_BUF_t *pib;
+	LPFCHBA_t *plhba;
+	LPFC_NODE_FARP_PEND_t *pndlpfarp;
+	NAME_TYPE rnode_addr;
+	uint16_t loop_cnt;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ndlp = NULL;
+	memcpy((void *)&rnode_addr, l1, sizeof (NAME_TYPE));
+
+	ndlp = lpfc_findnode_wwpn(phba, NLP_SEARCH_UNMAPPED, &rnode_addr);
+	if (ndlp == NULL) {
+		/* Look for an NDLP matching this remote node name.  Also look for a farp entry pending
+		 *  on the same remote node name.  Update all lists with the results.
+		 */
+		pndlpfarp =
+		    elx_tqs_dequeuefirst(&plhba->fc_node_farp_list, pnext);
+		loop_cnt = 0;
+		while (pndlpfarp != NULL) {
+			if (lpfc_geportname(&pndlpfarp->rnode_addr, &rnode_addr)
+			    != 2) {
+				elx_tqs_enqueue(&plhba->fc_node_farp_list,
+						pndlpfarp, pnext);
+				pndlpfarp =
+				    elx_tqs_dequeuefirst(&plhba->
+							 fc_node_farp_list,
+							 pnext);
+			} else
+				break;
+
+			loop_cnt += 1;
+			if (loop_cnt > plhba->fc_node_farp_list.q_cnt)
+				pndlpfarp = NULL;
+		}
+
+		if (pndlpfarp) {
+			pib =
+			    elx_tqs_dequeuefirst(&pndlpfarp->
+						 fc_ipbuf_list_farp_wait,
+						 ip_buf_next);
+			while (pib != NULL) {
+				lpfc_free_ip_buf(pib);
+				pib =
+				    elx_tqs_dequeuefirst(&pndlpfarp->
+							 fc_ipbuf_list_farp_wait,
+							 ip_buf_next);
+			}
+		}
+	}
+
+	return;
+}
+
+void
+lpfc_ip_xri_timeout(elxHBA_t * phba, void *l1, void *l2)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFC_IP_BUF_t *pib;
+	ELX_IOCBQ_t *iocb;
+	ELX_SLI_t *psli;
+
+	iocb = (ELX_IOCBQ_t *) l1;
+	ndlp = (LPFC_NODELIST_t *) iocb->context1;
+	psli = &phba->sli;
+
+	/* Just examine the node's xri value.  If it is nonzero, the exchange has
+	 * been created.  Just exit.  If not, flush the els command and flush the
+	 * pending ip buffers.
+	 */
+	if (ndlp->nlp_xri == 0) {
+		/* First, free the pib contained in the iocb. */
+		pib = (LPFC_IP_BUF_t *) iocb->context2;
+		lpfc_free_ip_buf(pib);
+
+		/* Flush the iocb from SLI. */
+		(void)lpfc_ip_flush_iocb(phba, &phba->sli.ring[psli->ip_ring],
+					 ndlp, FLUSH_NODE);
+
+		/* Now free all remaining IP buffers in the node's ipbuf list. */
+		pib = elx_tqs_dequeuefirst(&ndlp->nlp_listp_ipbuf, ip_buf_next);
+		while (pib != NULL) {
+			lpfc_free_ip_buf(pib);
+			pib =
+			    elx_tqs_dequeuefirst(&ndlp->nlp_listp_ipbuf,
+						 ip_buf_next);
+		}
+	}
+
+	return;
+}
+
+void
+lpfc_ip_timeout_handler(elxHBA_t * phba, void *arg1, void *arg2)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_IOCBQ_t *next_iocb;
+	ELX_IOCBQ_t *piocb;
+	IOCB_t *cmd = NULL;
+	LPFCHBA_t *plhba;
+	uint32_t timeout;
+	uint32_t next_timeout;
+	LPFC_NODELIST_t *ndlp;
+	uint32_t nlp_DID;
+
+	psli = &phba->sli;
+	pring = &psli->ring[psli->ip_ring];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	timeout = (uint32_t) (unsigned long)arg1;
+	next_timeout = timeout;
+
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		piocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &piocb->iocb;
+
+		if (piocb->drvrTimeout) {
+			if (piocb->drvrTimeout > timeout)
+				piocb->drvrTimeout -= timeout;
+			else
+				piocb->drvrTimeout = 0;
+
+			continue;
+		}
+		/*
+		 * The iocb has timed out; abort it.
+		 */
+		ndlp = (LPFC_NODELIST_t *) piocb->context1;
+		if (ndlp)
+			nlp_DID = ndlp->nlp_DID;
+		else
+			nlp_DID = 0;
+
+		/* IP packet timed out */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0608,	/* ptr to msg struct */
+			       elx_mes0608,	/* ptr to msg */
+			       elx_msgBlk0608.msgPreambleStr,	/* begin varargs */
+			       nlp_DID);	/* end varargs */
+
+		/*
+		 * If abort times out, simple throw away the iocb
+		 */
+
+		if (cmd->un.acxri.abortType == ABORT_TYPE_ABTS) {
+			elx_deque(piocb);
+			pring->txcmplq.q_cnt--;
+			(piocb->iocb_cmpl) ((void *)phba, piocb, piocb);
+		} else
+			elx_sli_abort_iocb(phba, pring, piocb);
+	}
+
+	phba->ip_tmofunc =
+	    elx_clk_set(phba, next_timeout, lpfc_ip_timeout_handler,
+			(void *)(unsigned long)next_timeout, 0);
+}
+
+/**********************************************/
+
+/*                mailbox command             */
+/**********************************************/
+void
+lpfc_dump_mem(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+
+	mb = &pmb->mb;
+	/* Setup to dump VPD region */
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+	mb->mbxCommand = MBX_DUMP_MEMORY;
+	mb->un.varDmp.cv = 1;
+	mb->un.varDmp.type = DMP_NV_PARAMS;
+	mb->un.varDmp.region_id = DMP_REGION_VPD;
+	mb->un.varDmp.word_cnt = (DMP_VPD_SIZE / sizeof (uint32_t));
+
+	mb->un.varDmp.co = 0;
+	mb->un.varDmp.resp_offset = 0;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/**********************************************/
+/*  lpfc_read_nv  Issue a READ NVPARAM        */
+/*                mailbox command             */
+/**********************************************/
+void
+lpfc_read_nv(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+	mb->mbxCommand = MBX_READ_NV;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/**********************************************/
+/*  lpfc_read_la  Issue a READ LA             */
+/*                mailbox command             */
+/**********************************************/
+int
+lpfc_read_la(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+	DMABUF_t *mp;
+	ELX_SLI_t *psli;
+
+	psli = &phba->sli;
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	/* Get a buffer to hold the loop map */
+	if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+		mb->mbxCommand = MBX_READ_LA64;
+		/* READ_LA: no buffers */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0300,	/* ptr to msg structure */
+			       elx_mes0300,	/* ptr to msg */
+			       elx_msgBlk0300.msgPreambleStr);	/* begin & end varargs */
+		return (1);
+	}
+
+	mb->mbxCommand = MBX_READ_LA64;
+	mb->un.varReadLA.un.lilpBde64.tus.f.bdeSize = 128;
+	mb->un.varReadLA.un.lilpBde64.addrHigh = putPaddrHigh(mp->phys);
+	mb->un.varReadLA.un.lilpBde64.addrLow = putPaddrLow(mp->phys);
+
+	/* Sync the mailbox data with its PCI memory address now. */
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORDEV);
+
+	/* Save address for later completion and set the owner to host so that
+	 * the FW knows this mailbox is available for processing. 
+	 */
+	pmb->context1 = (uint8_t *) mp;
+	mb->mbxOwner = OWN_HOST;
+	return (0);
+}
+
+/**********************************************/
+/*  lpfc_clear_la  Issue a CLEAR LA           */
+/*                 mailbox command            */
+/**********************************************/
+void
+lpfc_clear_la(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->un.varClearLA.eventTag = plhba->fc_eventTag;
+	mb->mbxCommand = MBX_CLEAR_LA;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/**************************************************/
+/*  lpfc_config_link  Issue a CONFIG LINK         */
+/*                    mailbox command             */
+/**************************************************/
+void
+lpfc_config_link(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+	LPFCHBA_t *plhba;
+	elxCfgParam_t *clp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	/* NEW_FEATURE
+	 * SLI-2, Coalescing Response Feature. 
+	 */
+	if (clp[LPFC_CFG_CR_DELAY].a_current) {
+		mb->un.varCfgLnk.cr = 1;
+		mb->un.varCfgLnk.ci = 1;
+		mb->un.varCfgLnk.cr_delay = clp[LPFC_CFG_CR_DELAY].a_current;
+		mb->un.varCfgLnk.cr_count = clp[LPFC_CFG_CR_COUNT].a_current;
+	}
+
+	mb->un.varCfgLnk.myId = plhba->fc_myDID;
+	mb->un.varCfgLnk.edtov = plhba->fc_edtov;
+	mb->un.varCfgLnk.arbtov = plhba->fc_arbtov;
+	mb->un.varCfgLnk.ratov = plhba->fc_ratov;
+	mb->un.varCfgLnk.rttov = plhba->fc_rttov;
+	mb->un.varCfgLnk.altov = plhba->fc_altov;
+	mb->un.varCfgLnk.crtov = plhba->fc_crtov;
+	mb->un.varCfgLnk.citov = plhba->fc_citov;
+
+	if (clp[LPFC_CFG_ACK0].a_current)
+		mb->un.varCfgLnk.ack0_enable = 1;
+
+	mb->mbxCommand = MBX_CONFIG_LINK;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/**********************************************/
+/*  lpfc_init_link  Issue an INIT LINK        */
+/*                  mailbox command           */
+/**********************************************/
+void
+lpfc_init_link(elxHBA_t * phba,
+	       ELX_MBOXQ_t * pmb, uint32_t topology, uint32_t linkspeed)
+{
+	elx_vpd_t *vpd;
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	psli = &phba->sli;
+	switch (topology) {
+	case FLAGS_TOPOLOGY_MODE_LOOP_PT:
+		mb->un.varInitLnk.link_flags = FLAGS_TOPOLOGY_MODE_LOOP;
+		mb->un.varInitLnk.link_flags |= FLAGS_TOPOLOGY_FAILOVER;
+		break;
+	case FLAGS_TOPOLOGY_MODE_PT_PT:
+		mb->un.varInitLnk.link_flags = FLAGS_TOPOLOGY_MODE_PT_PT;
+		break;
+	case FLAGS_TOPOLOGY_MODE_LOOP:
+		mb->un.varInitLnk.link_flags = FLAGS_TOPOLOGY_MODE_LOOP;
+		break;
+	case FLAGS_TOPOLOGY_MODE_PT_LOOP:
+		mb->un.varInitLnk.link_flags = FLAGS_TOPOLOGY_MODE_PT_PT;
+		mb->un.varInitLnk.link_flags |= FLAGS_TOPOLOGY_FAILOVER;
+		break;
+	}
+
+	/* NEW_FEATURE
+	 * Setting up the link speed
+	 */
+	vpd = &phba->vpd;
+	if (plhba->fc_flag & FC_2G_CAPABLE) {
+		if ((vpd->rev.feaLevelHigh >= 0x02) && (linkspeed > 0)) {
+			mb->un.varInitLnk.link_flags |= FLAGS_LINK_SPEED;
+			mb->un.varInitLnk.link_speed = linkspeed;
+		}
+	}
+
+	mb->mbxCommand = (volatile uint8_t)MBX_INIT_LINK;
+	mb->mbxOwner = OWN_HOST;
+	mb->un.varInitLnk.fabric_AL_PA = plhba->fc_pref_ALPA;
+	return;
+}
+
+/**********************************************/
+/*  lpfc_read_sparam  Issue a READ SPARAM     */
+/*                    mailbox command         */
+/**********************************************/
+int
+lpfc_read_sparam(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	DMABUF_t *mp;
+	MAILBOX_t *mb;
+	ELX_SLI_t *psli;
+
+	psli = &phba->sli;
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->mbxOwner = OWN_HOST;
+
+	/* Get a buffer to hold the HBAs Service Parameters */
+	if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+		mb->mbxCommand = MBX_READ_SPARM64;
+		/* READ_SPARAM: no buffers */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0301,	/* ptr to msg structure */
+			       elx_mes0301,	/* ptr to msg */
+			       elx_msgBlk0301.msgPreambleStr);	/* begin & end varargs */
+		return (1);
+	}
+
+	mb->mbxCommand = MBX_READ_SPARM64;
+	mb->un.varRdSparm.un.sp64.tus.f.bdeSize = sizeof (SERV_PARM);
+	mb->un.varRdSparm.un.sp64.addrHigh = putPaddrHigh(mp->phys);
+	mb->un.varRdSparm.un.sp64.addrLow = putPaddrLow(mp->phys);
+
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORDEV);
+
+	/* save address for completion */
+	pmb->context1 = (void *)mp;
+
+	return (0);
+}
+
+/**********************************************/
+/*  lpfc_read_rpi    Issue a READ RPI         */
+/*                   mailbox command          */
+/**********************************************/
+int
+lpfc_read_rpi(elxHBA_t * phba, uint32_t rpi, ELX_MBOXQ_t * pmb, uint32_t flag)
+{
+	MAILBOX_t *mb;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->un.varRdRPI.reqRpi = (volatile uint16_t)rpi;
+
+	mb->mbxCommand = MBX_READ_RPI64;
+	mb->mbxOwner = OWN_HOST;
+
+	mb->un.varWords[30] = flag;	/* Set flag to issue action on cmpl */
+
+	return (0);
+}
+
+/********************************************/
+/*  lpfc_unreg_did  Issue a UNREG_DID       */
+/*                  mailbox command         */
+/********************************************/
+void
+lpfc_unreg_did(elxHBA_t * phba, uint32_t did, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->un.varUnregDID.did = did;
+
+	mb->mbxCommand = MBX_UNREG_D_ID;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/***********************************************/
+
+/*                  command to write slim      */
+/***********************************************/
+void
+lpfc_set_slim(elxHBA_t * phba, ELX_MBOXQ_t * pmb, uint32_t addr, uint32_t value)
+{
+	MAILBOX_t *mb;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	/* addr = 0x090597 is AUTO ABTS disable for ELS commands */
+	/* addr = 0x052198 is DELAYED ABTS enable for ELS commands */
+
+	/*
+	 * Always turn on DELAYED ABTS for ELS timeouts 
+	 */
+	if ((addr == 0x052198) && (value == 0))
+		value = 1;
+
+	mb->un.varWords[0] = addr;
+	mb->un.varWords[1] = value;
+
+	mb->mbxCommand = MBX_SET_SLIM;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/**********************************************/
+/*  lpfc_config_farp  Issue a CONFIG FARP     */
+/*                    mailbox command         */
+/**********************************************/
+void
+lpfc_config_farp(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->un.varCfgFarp.filterEnable = 1;
+	mb->un.varCfgFarp.portName = 1;
+	mb->un.varCfgFarp.nodeName = 1;
+
+	memcpy((uint8_t *) & mb->un.varCfgFarp.portname,
+	       (uint8_t *) & plhba->fc_portname, sizeof (NAME_TYPE));
+	memcpy((uint8_t *) & mb->un.varCfgFarp.nodename,
+	       (uint8_t *) & plhba->fc_portname, sizeof (NAME_TYPE));
+	mb->mbxCommand = MBX_CONFIG_FARP;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/**********************************************/
+/*  lpfc_read_nv  Issue a READ CONFIG         */
+/*                mailbox command             */
+/**********************************************/
+void
+lpfc_read_config(elxHBA_t * phba, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->mbxCommand = MBX_READ_CONFIG;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/********************************************/
+/*  lpfc_reg_login  Issue a REG_LOGIN       */
+/*                  mailbox command         */
+/********************************************/
+int
+lpfc_reg_login(elxHBA_t * phba,
+	       uint32_t did, uint8_t * param, ELX_MBOXQ_t * pmb, uint32_t flag)
+{
+	uint8_t *sparam;
+	DMABUF_t *mp;
+	MAILBOX_t *mb;
+	ELX_SLI_t *psli;
+
+	psli = &phba->sli;
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->un.varRegLogin.rpi = 0;
+	mb->un.varRegLogin.did = did;
+	mb->un.varWords[30] = flag;	/* Set flag to issue action on cmpl */
+
+	mb->mbxOwner = OWN_HOST;
+
+	/* Get a buffer to hold NPorts Service Parameters */
+	if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+
+		mb->mbxCommand = MBX_REG_LOGIN64;
+		/* REG_LOGIN: no buffers */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0302,	/* ptr to msg structure */
+			       elx_mes0302,	/* ptr to msg */
+			       elx_msgBlk0302.msgPreambleStr,	/* begin varargs */
+			       (uint32_t) did, (uint32_t) flag);	/* end varargs */
+		return (1);
+	}
+
+	sparam = mp->virt;
+
+	/* Copy param's into a new buffer */
+	memcpy((void *)sparam, (void *)param, sizeof (SERV_PARM));
+
+	elx_pci_dma_sync((void *)phba, (void *)mp, 0, ELX_DMA_SYNC_FORDEV);
+
+	/* save address for completion */
+	pmb->context1 = (uint8_t *) mp;
+
+	mb->mbxCommand = MBX_REG_LOGIN64;
+	mb->un.varRegLogin.un.sp64.tus.f.bdeSize = sizeof (SERV_PARM);
+	mb->un.varRegLogin.un.sp64.addrHigh = putPaddrHigh(mp->phys);
+	mb->un.varRegLogin.un.sp64.addrLow = putPaddrLow(mp->phys);
+
+	return (0);
+}
+
+/**********************************************/
+/*  lpfc_unreg_login  Issue a UNREG_LOGIN     */
+/*                    mailbox command         */
+/**********************************************/
+void
+lpfc_unreg_login(elxHBA_t * phba, uint32_t rpi, ELX_MBOXQ_t * pmb)
+{
+	MAILBOX_t *mb;
+
+	mb = &pmb->mb;
+	memset((void *)pmb, 0, sizeof (ELX_MBOXQ_t));
+
+	mb->un.varUnregLogin.rpi = (uint16_t) rpi;
+	mb->un.varUnregLogin.rsvd1 = 0;
+
+	mb->mbxCommand = MBX_UNREG_LOGIN;
+	mb->mbxOwner = OWN_HOST;
+	return;
+}
+
+/***********************************************/
+/*  lpfc_config_pcb_setup  Issue a CONFIG_PORT */
+/*                   mailbox command           */
+/***********************************************/
+uint32_t *
+lpfc_config_pcb_setup(elxHBA_t * phba)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_RING_INIT_t *pringinit;
+	PCB_t *pcbp;
+	SLI2_SLIM_t *slim2p_virt;
+	elx_dma_addr_t pdma_addr;
+	uint32_t offset;
+	uint32_t iocbCnt;
+	int i;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	psli = &phba->sli;
+
+	slim2p_virt = ((SLI2_SLIM_t *) phba->slim2p.virt);
+	pcbp = &slim2p_virt->un.slim.pcb;
+	psli->MBhostaddr = (uint32_t *) (&slim2p_virt->un.slim.mbx);
+
+	pcbp->maxRing = (psli->sliinit.num_rings - 1);
+
+	iocbCnt = 0;
+	for (i = 0; i < psli->sliinit.num_rings; i++) {
+		pringinit = &psli->sliinit.ringinit[i];
+		pring = &psli->ring[i];
+		/* A ring MUST have both cmd and rsp entries defined to be valid */
+		if ((pringinit->numCiocb == 0) || (pringinit->numRiocb == 0)) {
+			pcbp->rdsc[i].cmdEntries = 0;
+			pcbp->rdsc[i].rspEntries = 0;
+			pcbp->rdsc[i].cmdAddrHigh = 0;
+			pcbp->rdsc[i].rspAddrHigh = 0;
+			pcbp->rdsc[i].cmdAddrLow = 0;
+			pcbp->rdsc[i].rspAddrLow = 0;
+			pring->cmdringaddr = (void *)0;
+			pring->rspringaddr = (void *)0;
+			continue;
+		}
+		/* Command ring setup for ring */
+		pring->cmdringaddr =
+		    (void *)&slim2p_virt->un.slim.IOCBs[iocbCnt];
+		pcbp->rdsc[i].cmdEntries = pringinit->numCiocb;
+
+		offset =
+		    (uint8_t *) & slim2p_virt->un.slim.IOCBs[iocbCnt] -
+		    (uint8_t *) slim2p_virt;
+		pdma_addr = phba->slim2p.phys + offset;
+		pcbp->rdsc[i].cmdAddrHigh = putPaddrHigh(pdma_addr);
+		pcbp->rdsc[i].cmdAddrLow = putPaddrLow(pdma_addr);
+		iocbCnt += pringinit->numCiocb;
+
+		/* Response ring setup for ring */
+		pring->rspringaddr =
+		    (void *)&slim2p_virt->un.slim.IOCBs[iocbCnt];
+
+		pcbp->rdsc[i].rspEntries = pringinit->numRiocb;
+		offset =
+		    (uint8_t *) & slim2p_virt->un.slim.IOCBs[iocbCnt] -
+		    (uint8_t *) slim2p_virt;
+		pdma_addr = phba->slim2p.phys + offset;
+		pcbp->rdsc[i].rspAddrHigh = putPaddrHigh(pdma_addr);
+		pcbp->rdsc[i].rspAddrLow = putPaddrLow(pdma_addr);
+		iocbCnt += pringinit->numRiocb;
+	}
+
+	elx_pci_dma_sync((void *)phba, (void *)&phba->slim2p,
+			 ELX_SLIM2_PAGE_AREA, ELX_DMA_SYNC_FORDEV);
+
+#ifndef powerpc
+	if ((((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_TFLY) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_PFLY) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_LP101) ||
+	    (((phba->pci_id >> 16) & 0xffff) == PCI_DEVICE_ID_RFLY)) {
+#else
+	if (((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_TFLY) ||
+	    ((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_PFLY) ||
+	    ((__swab16(phba->pci_id) & 0xffff) == PCI_DEVICE_ID_RFLY)) {
+#endif
+
+		lpfc_hba_init(phba);
+		return (plhba->hbainitEx);
+	} else
+		return (NULL);
+}
+
+/* This next section defines the NPort Discovery State Machine */
+
+/* There are 4 different double linked lists nodelist entries can reside on.
+ * The plogi list and adisc list are used when Link Up discovery or RSCN 
+ * processing is needed. Each list holds the nodes that we will send PLOGI
+ * or ADISC on. These lists will keep track of what nodes will be effected
+ * by an RSCN, or a Link Up (Typically, all nodes are effected on Link Up).
+ * The unmapped_list will contain all nodes that we have successfully logged
+ * into at the Fibre Channel level. The mapped_list will contain all nodes
+ * that are mapped FCP targets.
+ */
+/*
+ * The bind list is a list of undiscovered (potentially non-existent) nodes
+ * that we have saved binding information on. This information is used when
+ * nodes transition from the unmapped to the mapped list.
+ */
+/* For UNUSED_NODE state, the node has just been allocated from the MEM_NLP
+ * driver memory pool. For PLOGI_ISSUE and REG_LOGIN_ISSUE, the node is on
+ * the PLOGI list. For REG_LOGIN_COMPL, the node is taken off the PLOGI list
+ * and put on the unmapped list. For ADISC processing, the node is taken off 
+ * the ADISC list and placed on either the mapped or unmapped list (depending
+ * on its previous state). Once on the unmapped list, a PRLI is issued and the
+ * state changed to PRLI_ISSUE. When the PRLI completion occurs, the state is
+ * changed to PRLI_COMPL. If the completion indicates a mapped
+ * node, the node is taken off the unmapped list. The binding list is checked
+ * for a valid binding, or a binding is automatically assigned. If binding
+ * assignment is unsuccessful, the node is left on the unmapped list. If
+ * binding assignment is successful, the associated binding list entry (if
+ * any) is removed, and the node is placed on the mapped list. 
+ */
+/*
+ * For a Link Down, all nodes on the ADISC, PLOGI, unmapped or mapped
+ * lists will receive a DEVICE_UNK event. If the linkdown or nodev timers
+ * expire, all effected nodes will receive a DEVICE_RM event.
+ */
+/*
+ * For a Link Up or RSCN, all nodes will move from the mapped / unmapped 
+ * lists to either the ADISC or PLOGI list.  After a Nameserver
+ * query or ALPA loopmap check, additional nodes may be added (DEVICE_ADD)
+ * or removed (DEVICE_RM) to / from the PLOGI or ADISC lists. Once the PLOGI
+ * and ADISC lists are populated, we will first process the ADISC list.
+ * 32 entries are processed initially and ADISC is initited for each one.
+ * Completions / Events for each node are funnelled thru the state machine.
+ * As each node finishes ADISC processing, it starts ADISC for any nodes
+ * waiting for ADISC processing. If no nodes are waiting, and the ADISC
+ * list count is identically 0, then we are done. For Link Up discovery, since all nodes
+ * on the PLOGI list are UNREG_LOGIN'ed, we can issue a CLEAR_LA and reenable
+ * Link Events. Next we will process the PLOGI list.
+ * 32 entries are processed initially and PLOGI is initited for each one.
+ * Completions / Events for each node are funnelled thru the state machine.
+ * As each node finishes PLOGI processing, it starts PLOGI for any nodes
+ * waiting for PLOGI processing. If no nodes are waiting, and the PLOGI
+ * list count is indentically 0, then we are done. We have now completed discovery /
+ * RSCN handling. Upon completion, ALL nodes should be on either the mapped
+ * or unmapped lists.
+ */
+
+void *lpfc_disc_action[NLP_STE_MAX_STATE * NLP_EVT_MAX_EVENT] = {
+	/* Action routine                            Event       Current State   */
+	(void *)lpfc_rcv_plogi_unused_node,	/* RCV_PLOGI   UNUSED_NODE     */
+	(void *)lpfc_rcv_els_unused_node,	/* RCV_PRLI        */
+	(void *)lpfc_rcv_logo_unused_node,	/* RCV_LOGO        */
+	(void *)lpfc_rcv_els_unused_node,	/* RCV_ADISC       */
+	(void *)lpfc_rcv_els_unused_node,	/* RCV_PDISC       */
+	(void *)lpfc_rcv_els_unused_node,	/* RCV_PRLO        */
+	(void *)lpfc_cmpl_els_unused_node,	/* CMPL_PLOGI      */
+	(void *)lpfc_cmpl_els_unused_node,	/* CMPL_PRLI       */
+	(void *)lpfc_cmpl_els_unused_node,	/* CMPL_LOGO       */
+	(void *)lpfc_cmpl_els_unused_node,	/* CMPL_ADISC      */
+	(void *)lpfc_cmpl_reglogin_unused_node,	/* CMPL_REG_LOGIN  */
+	(void *)lpfc_device_rm_unused_node,	/* DEVICE_RM       */
+	(void *)lpfc_device_add_unused_node,	/* DEVICE_ADD      */
+	(void *)lpfc_device_unk_unused_node,	/* DEVICE_UNK      */
+	(void *)lpfc_rcv_plogi_plogi_issue,	/* RCV_PLOGI   PLOGI_ISSUE     */
+	(void *)lpfc_rcv_prli_plogi_issue,	/* RCV_PRLI        */
+	(void *)lpfc_rcv_logo_plogi_issue,	/* RCV_LOGO        */
+	(void *)lpfc_rcv_els_plogi_issue,	/* RCV_ADISC       */
+	(void *)lpfc_rcv_els_plogi_issue,	/* RCV_PDISC       */
+	(void *)lpfc_rcv_els_plogi_issue,	/* RCV_PRLO        */
+	(void *)lpfc_cmpl_plogi_plogi_issue,	/* CMPL_PLOGI      */
+	(void *)lpfc_cmpl_prli_plogi_issue,	/* CMPL_PRLI       */
+	(void *)lpfc_cmpl_logo_plogi_issue,	/* CMPL_LOGO       */
+	(void *)lpfc_cmpl_adisc_plogi_issue,	/* CMPL_ADISC      */
+	(void *)lpfc_cmpl_reglogin_plogi_issue,	/* CMPL_REG_LOGIN  */
+	(void *)lpfc_device_rm_plogi_issue,	/* DEVICE_RM       */
+	(void *)lpfc_disc_nodev,	/* DEVICE_ADD      */
+	(void *)lpfc_device_unk_plogi_issue,	/* DEVICE_UNK      */
+	(void *)lpfc_rcv_plogi_reglogin_issue,	/* RCV_PLOGI   REG_LOGIN_ISSUE */
+	(void *)lpfc_rcv_prli_reglogin_issue,	/* RCV_PLOGI       */
+	(void *)lpfc_rcv_logo_reglogin_issue,	/* RCV_LOGO        */
+	(void *)lpfc_rcv_padisc_reglogin_issue,	/* RCV_ADISC       */
+	(void *)lpfc_rcv_padisc_reglogin_issue,	/* RCV_PDISC       */
+	(void *)lpfc_rcv_prlo_reglogin_issue,	/* RCV_PRLO        */
+	(void *)lpfc_disc_neverdev,	/* CMPL_PLOGI      */
+	(void *)lpfc_disc_neverdev,	/* CMPL_PRLI       */
+	(void *)lpfc_cmpl_logo_reglogin_issue,	/* CMPL_LOGO       */
+	(void *)lpfc_cmpl_adisc_reglogin_issue,	/* CMPL_ADISC      */
+	(void *)lpfc_cmpl_reglogin_reglogin_issue,	/* CMPL_REG_LOGIN  */
+	(void *)lpfc_device_rm_reglogin_issue,	/* DEVICE_RM       */
+	(void *)lpfc_disc_nodev,	/* DEVICE_ADD      */
+	(void *)lpfc_device_unk_reglogin_issue,	/* DEVICE_UNK      */
+	(void *)lpfc_rcv_plogi_prli_issue,	/* RCV_PLOGI   PRLI_ISSUE      */
+	(void *)lpfc_rcv_prli_prli_issue,	/* RCV_PRLI        */
+	(void *)lpfc_rcv_logo_prli_issue,	/* RCV_LOGO        */
+	(void *)lpfc_rcv_padisc_prli_issue,	/* RCV_ADISC       */
+	(void *)lpfc_rcv_padisc_prli_issue,	/* RCV_PDISC       */
+	(void *)lpfc_rcv_prlo_prli_issue,	/* RCV_PRLO        */
+	(void *)lpfc_disc_neverdev,	/* CMPL_PLOGI      */
+	(void *)lpfc_cmpl_prli_prli_issue,	/* CMPL_PRLI       */
+	(void *)lpfc_cmpl_logo_prli_issue,	/* CMPL_LOGO       */
+	(void *)lpfc_cmpl_adisc_prli_issue,	/* CMPL_ADISC      */
+	(void *)lpfc_cmpl_reglogin_prli_issue,	/* CMPL_REG_LOGIN  */
+	(void *)lpfc_device_rm_prli_issue,	/* DEVICE_RM       */
+	(void *)lpfc_device_add_prli_issue,	/* DEVICE_ADD      */
+	(void *)lpfc_device_unk_prli_issue,	/* DEVICE_UNK      */
+	(void *)lpfc_rcv_plogi_prli_compl,	/* RCV_PLOGI   PRLI_COMPL      */
+	(void *)lpfc_rcv_prli_prli_compl,	/* RCV_PRLI        */
+	(void *)lpfc_rcv_logo_prli_compl,	/* RCV_LOGO        */
+	(void *)lpfc_rcv_padisc_prli_compl,	/* RCV_ADISC       */
+	(void *)lpfc_rcv_padisc_prli_compl,	/* RCV_PDISC       */
+	(void *)lpfc_rcv_prlo_prli_compl,	/* RCV_PRLO        */
+	(void *)lpfc_disc_neverdev,	/* CMPL_PLOGI      */
+	(void *)lpfc_disc_neverdev,	/* CMPL_PRLI       */
+	(void *)lpfc_cmpl_logo_prli_compl,	/* CMPL_LOGO       */
+	(void *)lpfc_cmpl_adisc_prli_compl,	/* CMPL_ADISC      */
+	(void *)lpfc_cmpl_reglogin_prli_compl,	/* CMPL_REG_LOGIN  */
+	(void *)lpfc_device_rm_prli_compl,	/* DEVICE_RM       */
+	(void *)lpfc_device_add_prli_compl,	/* DEVICE_ADD      */
+	(void *)lpfc_device_unk_prli_compl,	/* DEVICE_UNK      */
+	(void *)lpfc_rcv_plogi_mapped_node,	/* RCV_PLOGI   MAPPED_NODE     */
+	(void *)lpfc_rcv_prli_mapped_node,	/* RCV_PRLI        */
+	(void *)lpfc_rcv_logo_mapped_node,	/* RCV_LOGO        */
+	(void *)lpfc_rcv_padisc_mapped_node,	/* RCV_ADISC       */
+	(void *)lpfc_rcv_padisc_mapped_node,	/* RCV_PDISC       */
+	(void *)lpfc_rcv_prlo_mapped_node,	/* RCV_PRLO        */
+	(void *)lpfc_disc_neverdev,	/* CMPL_PLOGI      */
+	(void *)lpfc_disc_neverdev,	/* CMPL_PRLI       */
+	(void *)lpfc_cmpl_logo_mapped_node,	/* CMPL_LOGO       */
+	(void *)lpfc_cmpl_adisc_mapped_node,	/* CMPL_ADISC      */
+	(void *)lpfc_cmpl_reglogin_mapped_node,	/* CMPL_REG_LOGIN  */
+	(void *)lpfc_device_rm_mapped_node,	/* DEVICE_RM       */
+	(void *)lpfc_device_add_mapped_node,	/* DEVICE_ADD      */
+	(void *)lpfc_device_unk_mapped_node,	/* DEVICE_UNK      */
+};
+
+int lpfc_check_adisc(elxHBA_t *, LPFC_NODELIST_t *, NAME_TYPE *, NAME_TYPE *);
+int lpfc_geportname(NAME_TYPE *, NAME_TYPE *);
+LPFC_BINDLIST_t *lpfc_assign_scsid(elxHBA_t *, LPFC_NODELIST_t *);
+
+int
+lpfc_disc_state_machine(elxHBA_t * phba,
+			LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	uint32_t cur_state, rc;
+	uint32_t(*func) (elxHBA_t *, LPFC_NODELIST_t *, void *, uint32_t);
+
+	cur_state = ndlp->nlp_state;
+
+	/* DSM in event <evt> on NPort <nlp_DID> in state <cur_state> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0211,	/* ptr to msg structure */
+		       elx_mes0211,	/* ptr to msg */
+		       elx_msgBlk0211.msgPreambleStr,	/* begin varargs */
+		       evt, ndlp->nlp_DID, cur_state, ndlp->nlp_flag);	/* end varargs */
+
+	func = (uint32_t(*)(elxHBA_t *, LPFC_NODELIST_t *, void *, uint32_t))
+	    lpfc_disc_action[(cur_state * NLP_EVT_MAX_EVENT) + evt];
+	rc = (func) (phba, ndlp, arg, evt);
+
+	/* DSM out state <rc> on NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0212,	/* ptr to msg structure */
+		       elx_mes0212,	/* ptr to msg */
+		       elx_msgBlk0212.msgPreambleStr,	/* begin varargs */
+		       rc, ndlp->nlp_DID, ndlp->nlp_flag);	/* end varargs */
+
+	if (rc == NLP_STE_FREED_NODE)
+		return (NLP_STE_FREED_NODE);
+	ndlp->nlp_state = rc;
+	return (rc);
+}
+
+uint32_t
+lpfc_rcv_plogi_unused_node(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	SERV_PARM *sp;
+	ELX_MBOXQ_t *mbox;
+	elxCfgParam_t *clp;
+	LS_RJT stat;
+	LPFC_NODE_FARP_PEND_t *pndlpfarp;
+	FARP *pfarp;
+	uint16_t loop_cnt;
+
+	plhba = phba->pHbaProto;
+	clp = &phba->config[0];
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	icmd = &cmdiocb->iocb;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	if ((phba->hba_state <= ELX_FLOGI) ||
+	    ((lpfc_check_sparm(phba, ndlp, sp, CLASS3) == 0))) {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		if (phba->hba_state <= ELX_FLOGI) {
+			stat.un.b.lsRjtRsnCodeExp = LSRJT_LOGICAL_BSY;
+		} else {
+			stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		}
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	} else {
+		/* PLOGI chkparm OK */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0114,	/* ptr to msg structure */
+			       elx_mes0114,	/* ptr to msg */
+			       elx_msgBlk0114.msgPreambleStr,	/* begin varargs */
+			       ndlp->nlp_DID, ndlp->nlp_state, ndlp->nlp_flag, ndlp->nle.nlp_rpi);	/* end varargs */
+
+		if ((clp[LPFC_CFG_FCP_CLASS].a_current == CLASS2) &&
+		    (sp->cls2.classValid)) {
+			ndlp->nle.nlp_fcp_info |= CLASS2;
+		} else {
+			ndlp->nle.nlp_fcp_info |= CLASS3;
+		}
+
+		if ((clp[LPFC_CFG_IP_CLASS].a_current == CLASS2) &&
+		    (sp->cls2.classValid)) {
+			ndlp->nle.nlp_ip_info = CLASS2;
+		} else {
+			ndlp->nle.nlp_ip_info = CLASS3;
+		}
+
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba,
+						 MEM_MBOX | MEM_PRI)) == 0) {
+			goto out;
+		}
+		if ((plhba->fc_flag & FC_PT2PT)
+		    && !(plhba->fc_flag & FC_PT2PT_PLOGI)) {
+			/* The rcv'ed PLOGI determines what our NPortId will be */
+			plhba->fc_myDID = icmd->un.rcvels.parmRo;
+			lpfc_config_link(phba, mbox);
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+				goto out;
+			}
+			if ((mbox =
+			     (ELX_MBOXQ_t *) elx_mem_get(phba,
+							 MEM_MBOX | MEM_PRI)) ==
+			    0) {
+				goto out;
+			}
+		}
+		if (lpfc_reg_login(phba, icmd->un.rcvels.remoteID,
+				   (uint8_t *) sp, mbox, 0) == 0) {
+			/* set_slim mailbox command needs to execute first,
+			 * queue this command to be processed later.
+			 */
+			pfarp = (FARP *) pCmd;
+			if ((pfarp->Rflags == FARP_REQUEST_PLOGI)
+			    && (pfarp->Mflags == FARP_MATCH_PORT)) {
+				pndlpfarp =
+				    elx_tqs_dequeuefirst(&plhba->
+							 fc_node_farp_list,
+							 pnext);
+				loop_cnt = 0;
+				while (pndlpfarp != NULL) {
+					if ((lpfc_geportname
+					     (&pndlpfarp->rnode_addr,
+					      &ndlp->nlp_portname) != 2)
+					    &&
+					    (lpfc_geportname
+					     (&pndlpfarp->rnode_addr,
+					      &ndlp->nlp_nodename) != 2)) {
+						elx_tqs_enqueue(&plhba->
+								fc_node_farp_list,
+								pndlpfarp,
+								pnext);
+						pndlpfarp =
+						    elx_tqs_dequeuefirst
+						    (&plhba->fc_node_farp_list,
+						     pnext);
+					} else
+						break;
+
+					loop_cnt += 1;
+					if (loop_cnt >
+					    plhba->fc_node_farp_list.q_cnt)
+						pndlpfarp = NULL;
+				}
+
+				if (pndlpfarp->fc_ipfarp_tmo) {
+					elx_clk_can(phba,
+						    pndlpfarp->fc_ipfarp_tmo);
+					pndlpfarp->fc_ipfarp_tmo = 0;
+				}
+			}
+
+			mbox->mbox_cmpl = lpfc_mbx_cmpl_reg_login;
+			mbox->context2 = (void *)ndlp;
+			ndlp->nlp_state = NLP_STE_REG_LOGIN_ISSUE;
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    != MBX_NOT_FINISHED) {
+				lpfc_nlp_plogi(phba, ndlp);
+				lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb,
+						 ndlp, 0);
+				return (ndlp->nlp_state);	/* HAPPY PATH */
+			}
+			/* NOTE: we should have messages for unsuccessful reglogin */
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+		} else {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+		}
+	}
+      out:
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_FREED_NODE);
+}
+
+uint32_t
+lpfc_rcv_els_unused_node(elxHBA_t * phba,
+			 LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	lpfc_issue_els_logo(phba, ndlp, 0);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_logo_unused_node(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_FREED_NODE);
+}
+
+uint32_t
+lpfc_cmpl_els_unused_node(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_FREED_NODE);
+}
+
+uint32_t
+lpfc_cmpl_reglogin_unused_node(elxHBA_t * phba,
+			       LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_device_rm_unused_node(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_UNUSED_NODE);
+}
+
+uint32_t
+lpfc_device_add_unused_node(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	if (ndlp->nlp_tmofunc) {
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_tmofunc = 0;
+	}
+	ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+	lpfc_nlp_plogi(phba, ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_device_unk_unused_node(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_UNUSED_NODE);
+}
+
+uint32_t
+lpfc_rcv_plogi_plogi_issue(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	IOCB_t *icmd;
+	SERV_PARM *sp;
+	ELX_MBOXQ_t *mbox;
+	elxCfgParam_t *clp;
+	LS_RJT stat;
+	int port_cmp;
+
+	plhba = phba->pHbaProto;
+	clp = &phba->config[0];
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	icmd = &cmdiocb->iocb;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	/* For a PLOGI, we only accept if our portname is less
+	 * than the remote portname. 
+	 */
+	plhba->fc_stat.elsLogiCol++;
+	port_cmp = lpfc_geportname((NAME_TYPE *) & plhba->fc_portname,
+				   (NAME_TYPE *) & sp->portName);
+
+	if (!port_cmp) {
+		if (lpfc_check_sparm(phba, ndlp, sp, CLASS3) == 0) {
+			/* Reject this request because invalid parameters */
+			stat.un.b.lsRjtRsvd0 = 0;
+			stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+			stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+			stat.un.b.vendorUnique = 0;
+			lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb,
+					    ndlp);
+		} else {
+			/* PLOGI chkparm OK */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0120,	/* ptr to msg structure */
+				       elx_mes0120,	/* ptr to msg */
+				       elx_msgBlk0120.msgPreambleStr,	/* begin varargs */
+				       ndlp->nlp_DID, ndlp->nlp_state, ndlp->nlp_flag, ((ELX_NODELIST_t *) ndlp)->nlp_rpi);	/* end varargs */
+
+			if ((clp[LPFC_CFG_FCP_CLASS].a_current == CLASS2) &&
+			    (sp->cls2.classValid)) {
+				ndlp->nle.nlp_fcp_info |= CLASS2;
+			} else {
+				ndlp->nle.nlp_fcp_info |= CLASS3;
+			}
+
+			if ((clp[LPFC_CFG_IP_CLASS].a_current == CLASS2) &&
+			    (sp->cls2.classValid)) {
+				ndlp->nle.nlp_ip_info = CLASS2;
+			} else {
+				ndlp->nle.nlp_ip_info = CLASS3;
+			}
+
+			if ((mbox =
+			     (ELX_MBOXQ_t *) elx_mem_get(phba,
+							 MEM_MBOX | MEM_PRI))) {
+				if (lpfc_reg_login
+				    (phba, icmd->un.rcvels.remoteID,
+				     (uint8_t *) sp, mbox, 0) == 0) {
+					mbox->mbox_cmpl =
+					    lpfc_mbx_cmpl_reg_login;
+					mbox->context2 = (void *)ndlp;
+					ndlp->nlp_flag |= NLP_ACC_REGLOGIN;	/* Issue Reg Login after successful ACC */
+
+					if (port_cmp != 2) {
+						/* Abort outstanding PLOGI */
+						lpfc_driver_abort(phba, ndlp);
+					}
+					lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI,
+							 cmdiocb, ndlp, mbox);
+					return (ndlp->nlp_state);
+
+				} else {
+					elx_mem_put(phba, MEM_MBOX,
+						    (uint8_t *) mbox);
+				}
+			}
+		}		/* if valid sparm */
+	} /* if our portname was less */
+	else {
+		/* Reject this request because the remote node will accept ours */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_CMD_IN_PROGRESS;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	}
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_prli_plogi_issue(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* software abort outstanding plogi, then send logout */
+	if (ndlp->nlp_tmofunc) {
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_tmofunc = 0;
+	} else {
+		lpfc_driver_abort(phba, ndlp);
+	}
+	lpfc_issue_els_logo(phba, ndlp, 0);
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_logo_plogi_issue(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	ELXSCSITARGET_t *targetp;
+	elxCfgParam_t *clp;
+
+	clp = &phba->config[0];
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	/* software abort outstanding plogi before sending acc */
+	if (ndlp->nlp_tmofunc) {
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_tmofunc = 0;
+	} else {
+		lpfc_driver_abort(phba, ndlp);
+	}
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+
+	/* resend plogi after 1 sec delay */
+	targetp = ndlp->nlp_Target;
+	if (targetp) {
+		targetp->targetFlags |= FC_NPR_ACTIVE;
+		if (targetp->tmofunc) {
+			elx_clk_can(phba, targetp->tmofunc);
+		}
+		targetp->tmofunc = elx_clk_set(phba,
+					       (clp[ELX_CFG_NODEV_TMO].
+						a_current +
+						clp[ELX_CFG_LINKDOWN_TMO].
+						a_current), lpfc_npr_timeout,
+					       (void *)targetp, (void *)0);
+	}
+	ndlp->nle.nlp_rflag |= NLP_NPR_ACTIVE;
+	ndlp->nlp_flag |= NLP_DELAY_TMO;
+	ndlp->nlp_retry = 0;
+	ndlp->nlp_tmofunc = elx_clk_set(phba, 1,
+					lpfc_els_retry_delay,
+					(void *)((unsigned long)ndlp->nlp_DID),
+					(void *)((unsigned long)ELS_CMD_PLOGI));
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_els_plogi_issue(elxHBA_t * phba,
+			 LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* software abort outstanding plogi, then send logout */
+	if (ndlp->nlp_tmofunc) {
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_tmofunc = 0;
+	} else {
+		lpfc_driver_abort(phba, ndlp);
+	}
+	lpfc_issue_els_logo(phba, ndlp, 0);
+	return (ndlp->nlp_state);
+}
+
+/*! lpfc_cmpl_plogi_plogi_issue
+  * 
+  * \pre
+  * \post
+  * \param   phba
+  * \param   ndlp
+  * \param   arg
+  * \param   evt
+  * \return  uint32_t
+  *
+  * \b Description:
+  *     This routine is envoked when we rcv a PLOGI completion from a node
+  *     we tried to log into. We check the CSPs, and the ulpStatus. If successful
+  *     change the state to REG_LOGIN_ISSUE and issue a REG_LOGIN. For failure, we
+  *     free the nodelist entry.
+  */
+
+uint32_t
+lpfc_cmpl_plogi_plogi_issue(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	ELX_IOCBQ_t *cmdiocb, *rspiocb;
+	DMABUF_t *pCmd, *pRsp;
+	uint32_t *lp;
+	IOCB_t *irsp;
+	SERV_PARM *sp;
+	ELX_MBOXQ_t *mbox;
+	elxCfgParam_t *clp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	rspiocb = cmdiocb->q_f;
+
+	if (ndlp->nlp_flag & NLP_ACC_REGLOGIN) {
+		return (ndlp->nlp_state);
+	}
+
+	irsp = &rspiocb->iocb;
+
+	if (irsp->ulpStatus == 0) {
+		pCmd = (DMABUF_t *) cmdiocb->context2;
+		pRsp = (DMABUF_t *) pCmd->next;
+		lp = (uint32_t *) pRsp->virt;
+
+		elx_pci_dma_sync((void *)phba, (void *)pRsp, 0,
+				 ELX_DMA_SYNC_FORCPU);
+
+		sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+		if ((lpfc_check_sparm(phba, ndlp, sp, CLASS3))) {
+			/* PLOGI chkparm OK */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0121,	/* ptr to msg structure */
+				       elx_mes0121,	/* ptr to msg */
+				       elx_msgBlk0121.msgPreambleStr,	/* begin varargs */
+				       ndlp->nlp_DID, ndlp->nlp_state, ndlp->nlp_flag, ((ELX_NODELIST_t *) ndlp)->nlp_rpi);	/* end varargs */
+
+			if ((clp[LPFC_CFG_FCP_CLASS].a_current == CLASS2) &&
+			    (sp->cls2.classValid)) {
+				ndlp->nle.nlp_fcp_info |= CLASS2;
+			} else {
+				ndlp->nle.nlp_fcp_info |= CLASS3;
+			}
+
+			if ((clp[LPFC_CFG_IP_CLASS].a_current == CLASS2) &&
+			    (sp->cls2.classValid)) {
+				ndlp->nle.nlp_ip_info = CLASS2;
+			} else {
+				ndlp->nle.nlp_ip_info = CLASS3;
+			}
+
+			if ((mbox =
+			     (ELX_MBOXQ_t *) elx_mem_get(phba,
+							 MEM_MBOX | MEM_PRI))) {
+				if (lpfc_reg_login
+				    (phba, irsp->un.elsreq64.remoteID,
+				     (uint8_t *) sp, mbox, 0) == 0) {
+					/* set_slim mailbox command needs to execute first,
+					 * queue this command to be processed later.
+					 */
+					if (ndlp->nlp_DID == NameServer_DID) {
+						mbox->mbox_cmpl =
+						    lpfc_mbx_cmpl_ns_reg_login;
+					} else if (ndlp->nlp_DID == FDMI_DID) {
+						mbox->mbox_cmpl =
+						    lpfc_mbx_cmpl_fdmi_reg_login;
+					} else {
+						mbox->mbox_cmpl =
+						    lpfc_mbx_cmpl_reg_login;
+					}
+					mbox->context2 = (void *)ndlp;
+					ndlp->nlp_state =
+					    NLP_STE_REG_LOGIN_ISSUE;
+					if (elx_sli_issue_mbox
+					    (phba, mbox,
+					     (MBX_NOWAIT | MBX_STOP_IOCB))
+					    != MBX_NOT_FINISHED) {
+						return (ndlp->nlp_state);
+					}
+					elx_mem_put(phba, MEM_MBOX,
+						    (uint8_t *) mbox);
+				} else {
+					elx_mem_put(phba, MEM_MBOX,
+						    (uint8_t *) mbox);
+				}
+			}
+		}
+	}
+
+	/* If we are in the middle of discovery,
+	 * take necessary actions to finish up.
+	 */
+	if (ndlp->nlp_DID == NameServer_DID) {
+		/* Link up / RSCN discovery */
+		lpfc_disc_start(phba);
+	}
+	ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+
+	/* Free this node since the driver cannot login or has the wrong sparm */
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_FREED_NODE);
+}
+
+uint32_t
+lpfc_cmpl_prli_plogi_issue(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* First ensure ndlp is on the plogi list */
+	if (ndlp->nlp_flag & NLP_LIST_MASK) {
+		lpfc_findnode_did(phba, (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+				  ndlp->nlp_DID);
+	}
+	lpfc_nlp_plogi(phba, ndlp);
+
+	/* If a PLOGI is not already pending, issue one */
+	if (!(ndlp->nlp_flag & NLP_PLOGI_SND)) {
+		ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+		lpfc_issue_els_plogi(phba, ndlp, 0);
+		ndlp->nlp_flag |= NLP_DISC_NODE;
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_logo_plogi_issue(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	if (!(ndlp->nlp_flag & NLP_PLOGI_SND)) {
+
+		ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+		lpfc_issue_els_plogi(phba, ndlp, 0);
+	}
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_adisc_plogi_issue(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* First ensure ndlp is on the plogi list */
+	if (ndlp->nlp_flag & NLP_LIST_MASK) {
+		lpfc_findnode_did(phba, (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+				  ndlp->nlp_DID);
+	}
+	lpfc_nlp_plogi(phba, ndlp);
+
+	/* If a PLOGI is not already pending, issue one */
+	if (!(ndlp->nlp_flag & NLP_PLOGI_SND)) {
+		ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+		lpfc_issue_els_plogi(phba, ndlp, 0);
+		ndlp->nlp_flag |= NLP_DISC_NODE;
+	}
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_reglogin_plogi_issue(elxHBA_t * phba,
+			       LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_MBOXQ_t *pmb, *mbox;
+	MAILBOX_t *mb;
+	uint32_t ldata;
+	uint16_t rpi;
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	pmb = (ELX_MBOXQ_t *) arg;
+	mb = &pmb->mb;
+	ldata = mb->un.varWords[0];	/* rpi */
+	rpi = (uint16_t) (PCIMEM_LONG(ldata) & 0xFFFF);
+
+	/* first unreg node's rpi */
+	if ((mbox = (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+		/* now unreg rpi just got back from reg_login */
+		lpfc_unreg_login(phba, rpi, mbox);
+		if (elx_sli_issue_mbox(phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+		    == MBX_NOT_FINISHED) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+		}
+	}
+
+	/* software abort outstanding plogi */
+	lpfc_driver_abort(phba, ndlp);
+	/* send a new plogi */
+	ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+	lpfc_issue_els_plogi(phba, ndlp, 0);
+
+	return (ndlp->nlp_state);
+}
+
+/*! lpfc_device_rm_plogi_issue
+  * 
+  * \pre
+  * \post
+  * \param   phba
+  * \param   ndlp
+  * \param   arg
+  * \param   evt
+  * \return  uint32_t
+  *
+  * \b Description:
+  *     This routine is envoked when we a request to remove a nport we are in the
+  *     process of PLOGIing. We should issue a software abort on the outstanding 
+  *     PLOGI request, then issue a LOGO request. Change node state to
+  *     UNUSED_NODE so it can be freed when LOGO completes.
+  *
+  */
+
+uint32_t
+lpfc_device_rm_plogi_issue(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* software abort outstanding plogi, before sending LOGO */
+	lpfc_driver_abort(phba, ndlp);
+
+	/* If discovery processing causes us to remove a device, it is important
+	 * that nothing gets sent to the device (soft zoning issues).
+	 */
+	lpfc_freenode(phba, ndlp);
+	ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_device_unk_plogi_issue(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* software abort outstanding plogi */
+	lpfc_driver_abort(phba, ndlp);
+
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_UNUSED_NODE);
+}
+
+uint32_t
+lpfc_rcv_plogi_reglogin_issue(elxHBA_t * phba,
+			      LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	SERV_PARM *sp;
+	LS_RJT stat;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	if ((lpfc_check_sparm(phba, ndlp, sp, CLASS3) == 0)) {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	} else {
+		/* PLOGI chkparm OK */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0122,	/* ptr to msg structure */
+			       elx_mes0122,	/* ptr to msg */
+			       elx_msgBlk0122.msgPreambleStr,	/* begin varargs */
+			       ndlp->nlp_DID, ndlp->nlp_state, ndlp->nlp_flag, ((ELX_NODELIST_t *) ndlp)->nlp_rpi);	/* end varargs */
+
+		lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_prli_reglogin_issue(elxHBA_t * phba,
+			     LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	lpfc_els_rsp_prli_acc(phba, cmdiocb, ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_logo_reglogin_issue(elxHBA_t * phba,
+			     LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+
+	/* resend plogi */
+	ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+	lpfc_issue_els_plogi(phba, ndlp, 0);
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_padisc_reglogin_issue(elxHBA_t * phba,
+			       LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	SERV_PARM *sp;
+	LS_RJT stat;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	if ((lpfc_check_sparm(phba, ndlp, sp, CLASS3) == 0)) {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	} else {
+		/* PLOGI chkparm OK */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0123,	/* ptr to msg structure */
+			       elx_mes0123,	/* ptr to msg */
+			       elx_msgBlk0123.msgPreambleStr,	/* begin varargs */
+			       ndlp->nlp_DID, ndlp->nlp_state, ndlp->nlp_flag, ((ELX_NODELIST_t *) ndlp)->nlp_rpi);	/* end varargs */
+
+		lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_prlo_reglogin_issue(elxHBA_t * phba,
+			     LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_logo_reglogin_issue(elxHBA_t * phba,
+			      LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* 
+	 * don't really want to do anything since reglogin has not finished,
+	 * and we won't let any els happen until the mb is finished. 
+	 */
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_adisc_reglogin_issue(elxHBA_t * phba,
+			       LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* First ensure ndlp is on the plogi list */
+	if (ndlp->nlp_flag & NLP_LIST_MASK) {
+		lpfc_findnode_did(phba, (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+				  ndlp->nlp_DID);
+	}
+	lpfc_nlp_plogi(phba, ndlp);
+
+	return (ndlp->nlp_state);
+}
+
+/*! lpfc_cmpl_reglogin_reglogin_issue
+  * 
+  * \pre
+  * \post
+  * \param   phba
+  * \param   ndlp
+  * \param   arg
+  * \param   evt
+  * \return  uint32_t
+  *
+  * \b Description:
+  *     This routine is envoked when the REG_LOGIN completes. If unsuccessful,
+  *     we should send a LOGO ELS request and free the node entry. If successful,
+  *     save the RPI assigned, then issue a PRLI request. The nodelist entry should
+  *     be moved to the unmapped list.  If the NPortID indicates a Fabric entity,
+  *     don't issue PRLI, just go straight into PRLI_COMPL.
+  *              PRLI_COMPL - for fabric entity
+  */
+uint32_t
+lpfc_cmpl_reglogin_reglogin_issue(elxHBA_t * phba,
+				  LPFC_NODELIST_t * ndlp,
+				  void *arg, uint32_t evt)
+{
+	ELX_MBOXQ_t *pmb;
+	MAILBOX_t *mb;
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *plogi_ndlp;
+	uint32_t did;
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	pmb = (ELX_MBOXQ_t *) arg;
+	mb = &pmb->mb;
+	did = mb->un.varWords[1];
+	if (mb->mbxStatus ||
+	    ((plogi_ndlp = lpfc_findnode_did(phba,
+					     (NLP_SEARCH_PLOGI |
+					      NLP_SEARCH_DEQUE), did)) == 0)
+	    || (ndlp != plogi_ndlp)) {
+		/* RegLogin failed */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0246,	/* ptr to msg structure */
+			       elx_mes0246,	/* ptr to msg */
+			       elx_msgBlk0246.msgPreambleStr,	/* begin varargs */
+			       did, mb->mbxStatus, phba->hba_state);	/* end varargs */
+
+		if (ndlp->nlp_flag & NLP_LIST_MASK) {
+			lpfc_findnode_did(phba,
+					  (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+					  ndlp->nlp_DID);
+		}
+		ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+		lpfc_freenode(phba, ndlp);
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		return (NLP_STE_FREED_NODE);
+	}
+
+	if (ndlp->nle.nlp_rpi != 0)
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+
+	ndlp->nle.nlp_rpi = mb->un.varWords[0];
+	lpfc_addnode_rpi(phba, ndlp, ndlp->nle.nlp_rpi);
+	lpfc_nlp_unmapped(phba, ndlp);
+
+	/* Only if we are not a fabric nport do we issue PRLI */
+	if (!(ndlp->nle.nlp_type & NLP_FABRIC)) {
+		lpfc_issue_els_prli(phba, ndlp, 0);
+		ndlp->nlp_state = NLP_STE_PRLI_ISSUE;
+	} else {
+		ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+	}
+
+	return (ndlp->nlp_state);
+}
+
+/*! lpfc_device_rm_reglogin_issue
+  * 
+  * \pre
+  * \post
+  * \param   phba
+  * \param   ndlp
+  * \param   arg
+  * \param   evt
+  * \return  uint32_t
+  *
+  * \b Description:
+  *     This routine is envoked when we a request to remove a nport we are in the
+  *     process of REG_LOGINing. We should issue a UNREG_LOGIN by did, then
+  *     issue a LOGO request. Change node state to NODE_UNUSED, so it will be
+  *     freed when LOGO completes.
+  *
+  */
+
+uint32_t
+lpfc_device_rm_reglogin_issue(elxHBA_t * phba,
+			      LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_MBOXQ_t *mbox;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	if (ndlp->nle.nlp_rpi) {
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			lpfc_unreg_login(phba, ndlp->nle.nlp_rpi, mbox);
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+			}
+		}
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+		lpfc_no_rpi(phba, ndlp);
+		ndlp->nle.nlp_rpi = 0;
+	}
+
+	/* If discovery processing causes us to remove a device, it is important
+	 * that nothing gets sent to the device (soft zoning issues).
+	 */
+	lpfc_freenode(phba, ndlp);
+	ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (ndlp->nlp_state);
+}
+
+/* DEVICE_ADD for REG_LOGIN_ISSUE is nodev */
+
+uint32_t
+lpfc_device_unk_reglogin_issue(elxHBA_t * phba,
+			       LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_UNUSED_NODE);
+}
+
+uint32_t
+lpfc_rcv_plogi_prli_issue(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	SERV_PARM *sp;
+	LS_RJT stat;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	if ((lpfc_check_sparm(phba, ndlp, sp, CLASS3) == 0)) {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	} else {
+		/* PLOGI chkparm OK */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0124,	/* ptr to msg structure */
+			       elx_mes0124,	/* ptr to msg */
+			       elx_msgBlk0124.msgPreambleStr,	/* begin varargs */
+			       ndlp->nlp_DID, ndlp->nlp_state, ndlp->nlp_flag, ((ELX_NODELIST_t *) ndlp)->nlp_rpi);	/* end varargs */
+
+		lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_prli_prli_issue(elxHBA_t * phba,
+			 LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	lpfc_els_rsp_prli_acc(phba, cmdiocb, ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_logo_prli_issue(elxHBA_t * phba,
+			 LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	/* Software abort outstanding prli before sending acc */
+	lpfc_driver_abort(phba, ndlp);
+
+	/* Only call LOGO ACC for first LOGO, this avoids sending unnecessary
+	 * PLOGIs during LOGO storms from a device.
+	 */
+	if (ndlp->nlp_flag & NLP_LOGO_ACC) {
+		ndlp->nlp_flag &= ~NLP_LOGO_ACC;
+		lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+		ndlp->nlp_flag |= NLP_LOGO_ACC;
+	} else {
+		ndlp->nlp_flag |= NLP_LOGO_ACC;
+		lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+	}
+
+	/* The driver has to wait until the ACC completes before it continues
+	 * processing the LOGO.  The action will resume in lpfc_cmpl_els_logo_acc
+	 * routine. Since part of processing includes an unreg_login, the driver waits
+	 * so the ACC does not get aborted.
+	 */
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_padisc_prli_issue(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	SERV_PARM *sp;		/* used for PDISC */
+	ADISC *ap;		/* used for ADISC */
+	uint32_t *lp;
+	uint32_t cmd;
+	NAME_TYPE *pnn, *ppn;
+	LS_RJT stat;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+	cmd = *lp++;
+
+	if (cmd == ELS_CMD_ADISC) {
+		ap = (ADISC *) lp;
+		pnn = (NAME_TYPE *) & ap->nodeName;
+		ppn = (NAME_TYPE *) & ap->portName;
+	} else {
+		sp = (SERV_PARM *) lp;
+		pnn = (NAME_TYPE *) & sp->nodeName;
+		ppn = (NAME_TYPE *) & sp->portName;
+	}
+
+	if (lpfc_check_adisc(phba, ndlp, pnn, ppn)) {
+		if (cmd == ELS_CMD_ADISC) {
+			lpfc_els_rsp_adisc_acc(phba, cmdiocb, ndlp);
+		} else {
+			lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+		}
+	} else {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+/* This routine is envoked when we rcv a PRLO request from a nport
+ * we are logged into.  We should send back a PRLO rsp setting the
+ * appropriate bits.
+ * NEXT STATE = PRLI_ISSUE
+ */
+uint32_t
+lpfc_rcv_prlo_prli_issue(elxHBA_t * phba,
+			 LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_prli_prli_issue(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	ELX_IOCBQ_t *cmdiocb, *rspiocb;
+	DMABUF_t *pCmd, *pRsp;
+	uint32_t *lp;
+	IOCB_t *irsp;
+	PRLI *npr;
+	LPFC_BINDLIST_t *blp;
+	ELXSCSILUN_t *lunp;
+	ELXSCSITARGET_t *targetp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	rspiocb = cmdiocb->q_f;
+	irsp = &rspiocb->iocb;
+	if (irsp->ulpStatus) {
+		ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN, ELX_CLR_BITMASK);
+		return (ndlp->nlp_state);
+	}
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	pRsp = (DMABUF_t *) pCmd->next;
+	lp = (uint32_t *) pRsp->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pRsp, 0, ELX_DMA_SYNC_FORCPU);
+
+	npr = (PRLI *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	/* Check out PRLI rsp */
+	if ((npr->acceptRspCode != PRLI_REQ_EXECUTED) ||
+	    (npr->prliType != PRLI_FCP_TYPE) || (npr->targetFunc != 1)) {
+		ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN, ELX_CLR_BITMASK);
+		return (ndlp->nlp_state);
+	}
+	if (npr->Retry == 1) {
+		ndlp->nle.nlp_fcp_info |= NLP_FCP_2_DEVICE;
+	}
+
+	/* Can we assign a SCSI Id to this NPort */
+	if ((blp = lpfc_assign_scsid(phba, ndlp))) {
+		lpfc_nlp_mapped(phba, ndlp, blp);
+		ndlp->nle.nlp_failMask = 0;
+		targetp = ndlp->nlp_Target;
+		if (targetp) {
+			lunp = (ELXSCSILUN_t *) (targetp->lunlist.q_first);
+			while (lunp) {
+				lunp->failMask = 0;
+				lunp = lunp->pnextLun;
+			}
+			if (targetp->tmofunc) {
+				elx_clk_can(phba, targetp->tmofunc);
+				targetp->tmofunc = 0;
+			}
+		} else {
+			/* new target to driver, allocate space to target <sid> lun 0 */
+			if (blp->nlp_Target == 0) {
+				lpfc_find_lun(phba, blp->nlp_sid, 0, 1);
+				blp->nlp_Target =
+				    plhba->device_queue_hash[blp->nlp_sid];
+			}
+		}
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN, ELX_SET_BITMASK);
+
+		ndlp->nlp_state = NLP_STE_MAPPED_NODE;
+		lpfc_disc_issue_rptlun(phba, ndlp);
+	} else {
+		ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+		ndlp->nlp_flag |= NLP_TGT_NO_SCSIID;
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN, ELX_CLR_BITMASK);
+	}
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_logo_prli_issue(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+
+	/* software abort outstanding prli, then send logout */
+	lpfc_driver_abort(phba, ndlp);
+	lpfc_issue_els_logo(phba, ndlp, 0);
+
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_UNUSED_NODE);
+}
+
+uint32_t
+lpfc_cmpl_adisc_prli_issue(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* First ensure ndlp is on the unmap list */
+	if (ndlp->nlp_flag & NLP_LIST_MASK) {
+		lpfc_findnode_did(phba, (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+				  ndlp->nlp_DID);
+	}
+	lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN, ELX_CLR_BITMASK);
+	lpfc_nlp_unmapped(phba, ndlp);
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_reglogin_prli_issue(elxHBA_t * phba,
+			      LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_MBOXQ_t *pmb, *mbox;
+	MAILBOX_t *mb;
+	uint32_t ldata;
+	uint16_t rpi;
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	pmb = (ELX_MBOXQ_t *) arg;
+	mb = &pmb->mb;
+	ldata = mb->un.varWords[0];	/* rpi */
+	rpi = (uint16_t) (PCIMEM_LONG(ldata) & 0xFFFF);
+
+	if (ndlp->nle.nlp_rpi != rpi) {
+		/* first unreg node's rpi */
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			lpfc_unreg_login(phba, ndlp->nle.nlp_rpi, mbox);
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+			}
+		}
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+		lpfc_no_rpi(phba, ndlp);
+		ndlp->nle.nlp_rpi = 0;
+
+		/* now unreg rpi just got back from reg_login */
+		lpfc_unreg_login(phba, rpi, mbox);
+		if (elx_sli_issue_mbox(phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+		    == MBX_NOT_FINISHED) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+		}
+
+		/* software abort outstanding prli */
+		lpfc_driver_abort(phba, ndlp);
+
+		/* send logout and put this node on plogi list */
+		lpfc_issue_els_logo(phba, ndlp, 0);
+		ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+		lpfc_nlp_plogi(phba, ndlp);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+/*! lpfc_device_rm_prli_issue
+  * 
+  * \pre
+  * \post
+  * \param   phba
+  * \param   ndlp
+  * \param   arg
+  * \param   evt
+  * \return  uint32_t
+  *
+  * \b Description:
+  *    This routine is envoked when we a request to remove a nport we are in the
+  *    process of PRLIing. We should software abort outstanding prli, unreg
+  *    login, send a logout. We will change node state to UNUSED_NODE, put it
+  *    on plogi list so it can be freed when LOGO completes. 
+  *
+  */
+uint32_t
+lpfc_device_rm_prli_issue(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* software abort outstanding prli */
+	lpfc_driver_abort(phba, ndlp);
+
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+
+	ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_device_add_prli_issue(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	if (ndlp->nlp_tmofunc) {
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_tmofunc = 0;
+	}
+	/* software abort outstanding prli */
+	lpfc_driver_abort(phba, ndlp);
+
+	lpfc_nlp_adisc(phba, ndlp);
+	return (ndlp->nlp_state);
+}
+
+/*! lpfc_device_unk_prli_issue
+  * 
+  * \pre
+  * \post
+  * \param   phba
+  * \param   ndlp
+  * \param   arg
+  * \param   evt
+  * \return  uint32_t
+  *
+  * \b Description:
+  *    The routine is envoked when the state of a device is unknown, like
+  *    during a link down. We should remove the nodelist entry from the
+  *    unmapped list, issue a UNREG_LOGIN, do a software abort of the
+  *    outstanding PRLI command, then free the node entry.
+  */
+uint32_t
+lpfc_device_unk_prli_issue(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* software abort outstanding prli */
+	lpfc_driver_abort(phba, ndlp);
+
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_UNUSED_NODE);
+}
+
+uint32_t
+lpfc_rcv_plogi_prli_compl(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	SERV_PARM *sp;
+	LS_RJT stat;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	if ((phba->hba_state <= ELX_FLOGI) ||
+	    ((lpfc_check_sparm(phba, ndlp, sp, CLASS3) == 0))) {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		if (phba->hba_state <= ELX_FLOGI) {
+			stat.un.b.lsRjtRsnCodeExp = LSRJT_LOGICAL_BSY;
+		} else {
+			stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		}
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	} else {
+		/* PLOGI chkparm OK */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0125,	/* ptr to msg structure */
+			       elx_mes0125,	/* ptr to msg */
+			       elx_msgBlk0125.msgPreambleStr,	/* begin varargs */
+			       ndlp->nlp_DID, ndlp->nlp_state, ndlp->nlp_flag, ((ELX_NODELIST_t *) ndlp)->nlp_rpi);	/* end varargs */
+
+		lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_prli_prli_compl(elxHBA_t * phba,
+			 LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	lpfc_els_rsp_prli_acc(phba, cmdiocb, ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_logo_prli_compl(elxHBA_t * phba,
+			 LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	/* software abort outstanding adisc before sending acc */
+	if (ndlp->nlp_flag & NLP_ADISC_SND) {
+		lpfc_driver_abort(phba, ndlp);
+	}
+	/* Only call LOGO ACC for first LOGO, this avoids sending unnecessary
+	 * PLOGIs during LOGO storms from a device.
+	 */
+	if (ndlp->nlp_flag & NLP_LOGO_ACC) {
+		ndlp->nlp_flag &= ~NLP_LOGO_ACC;
+		lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+		ndlp->nlp_flag |= NLP_LOGO_ACC;
+	} else {
+		ndlp->nlp_flag |= NLP_LOGO_ACC;
+		lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+	}
+
+	/* The driver has to wait until the ACC completes before we can continue
+	 * processing the LOGO, the action will resume in lpfc_cmpl_els_logo_acc.
+	 * Since part of processing includes an unreg_login, the driver waits
+	 * so the ACC does not get aborted.
+	 */
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_padisc_prli_compl(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	SERV_PARM *sp;		/* used for PDISC */
+	ADISC *ap;		/* used for ADISC */
+	uint32_t *lp;
+	uint32_t cmd;
+	NAME_TYPE *pnn, *ppn;
+	LS_RJT stat;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+	cmd = *lp++;
+
+	if (cmd == ELS_CMD_ADISC) {
+		ap = (ADISC *) lp;
+		pnn = (NAME_TYPE *) & ap->nodeName;
+		ppn = (NAME_TYPE *) & ap->portName;
+	} else {
+		sp = (SERV_PARM *) lp;
+		pnn = (NAME_TYPE *) & sp->nodeName;
+		ppn = (NAME_TYPE *) & sp->portName;
+	}
+
+	if (lpfc_check_adisc(phba, ndlp, pnn, ppn)) {
+		if (cmd == ELS_CMD_ADISC) {
+			lpfc_els_rsp_adisc_acc(phba, cmdiocb, ndlp);
+		} else {
+			lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+		}
+	} else {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_prlo_prli_compl(elxHBA_t * phba,
+			 LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_logo_prli_compl(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+
+	if (ndlp->nlp_flag & NLP_ADISC_SND) {
+		/* software abort outstanding adisc */
+		lpfc_driver_abort(phba, ndlp);
+	}
+
+	ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_UNUSED_NODE);
+}
+
+uint32_t
+lpfc_cmpl_adisc_prli_compl(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	ELX_IOCBQ_t *cmdiocb, *rspiocb;
+	DMABUF_t *pCmd, *pRsp;
+	uint32_t *lp;
+	IOCB_t *irsp;
+	ADISC *ap;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	rspiocb = cmdiocb->q_f;
+	irsp = &rspiocb->iocb;
+
+	/* First remove the ndlp from any list */
+	if (ndlp->nlp_flag & NLP_LIST_MASK) {
+		lpfc_findnode_did(phba, (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+				  ndlp->nlp_DID);
+	}
+
+	if (irsp->ulpStatus) {
+		lpfc_freenode(phba, ndlp);
+		ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+		lpfc_nlp_plogi(phba, ndlp);
+		return (ndlp->nlp_state);
+	}
+
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	pRsp = (DMABUF_t *) pCmd->next;
+	lp = (uint32_t *) pRsp->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pRsp, 0, ELX_DMA_SYNC_FORCPU);
+
+	ap = (ADISC *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	/* Check out ADISC rsp */
+	if ((lpfc_check_adisc(phba, ndlp, &ap->nodeName, &ap->portName) == 0)) {
+		lpfc_freenode(phba, ndlp);
+		ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+		lpfc_nlp_plogi(phba, ndlp);
+		return (ndlp->nlp_state);
+	}
+	lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN, ELX_CLR_BITMASK);
+	lpfc_nlp_unmapped(phba, ndlp);
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_reglogin_prli_compl(elxHBA_t * phba,
+			      LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_MBOXQ_t *pmb, *mbox;
+	MAILBOX_t *mb;
+	uint32_t ldata;
+	uint16_t rpi;
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	pmb = (ELX_MBOXQ_t *) arg;
+	mb = &pmb->mb;
+	ldata = mb->un.varWords[0];	/* rpi */
+	rpi = (uint16_t) (PCIMEM_LONG(ldata) & 0xFFFF);
+
+	if (ndlp->nle.nlp_rpi != rpi) {
+		/* first unreg node's rpi */
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			lpfc_unreg_login(phba, ndlp->nle.nlp_rpi, mbox);
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+			}
+		}
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+		lpfc_no_rpi(phba, ndlp);
+		ndlp->nle.nlp_rpi = 0;
+
+		/* now unreg rpi just got back from reg_login */
+		lpfc_unreg_login(phba, rpi, mbox);
+		if (elx_sli_issue_mbox(phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+		    == MBX_NOT_FINISHED) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+		}
+
+		if (ndlp->nlp_flag & NLP_ADISC_SND) {
+			/* software abort outstanding adisc */
+			lpfc_driver_abort(phba, ndlp);
+		}
+
+		/* send logout and put this node on plogi list */
+		lpfc_issue_els_logo(phba, ndlp, 0);
+		ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+		lpfc_nlp_plogi(phba, ndlp);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+/*! lpfc_device_rm_prli_compl
+  * 
+  * \pre
+  * \post
+  * \param   phba
+  * \param   ndlp
+  * \param   arg
+  * \param   evt
+  * \return  uint32_t
+  *
+  * \b Description:
+  *    This routine is envoked when we a request to remove a nport.
+  *    It could be called when linkdown or nodev timer expires.
+  *    If nodev timer is still running, we just want to exit.
+  *    If this node timed out, we want to abort outstanding ADISC,
+  *    unreg login, send logout, change state to UNUSED_NODE and
+  *    place node on plogi list so it can be freed when LOGO completes.
+  *
+  */
+uint32_t
+lpfc_device_rm_prli_compl(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* if nodev timer is running, then we just exit */
+	if (!(ndlp->nlp_flag & NLP_NODEV_TMO)) {
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_DISCONNECTED,
+				  ELX_SET_BITMASK);
+		if (ndlp->nlp_flag & NLP_ADISC_SND) {
+			/* software abort outstanding adisc */
+			lpfc_driver_abort(phba, ndlp);
+		}
+		/* dequeue, cancel timeout, unreg login */
+		lpfc_freenode(phba, ndlp);
+
+		/* If discovery processing causes us to remove a device, it is important
+		 * that nothing gets sent to the device (soft zoning issues).
+		 */
+		ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		return (NLP_STE_UNUSED_NODE);
+	}
+	lpfc_set_failmask(phba, ndlp, ELX_DEV_DISAPPEARED, ELX_SET_BITMASK);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_device_add_prli_compl(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	if (ndlp->nlp_tmofunc) {
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_tmofunc = 0;
+	}
+	lpfc_nlp_adisc(phba, ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_device_unk_prli_compl(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	elxCfgParam_t *clp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	/* If we are in pt2pt mode, free node */
+	if (plhba->fc_flag & FC_PT2PT) {
+		/* dequeue, cancel timeout, unreg login */
+		lpfc_freenode(phba, ndlp);
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		return (NLP_STE_UNUSED_NODE);
+	}
+
+	/* linkdown timer should be running at this time.  Check to 
+	 * see if the driver needs to start a nodev timer
+	 */
+	if ((clp[ELX_CFG_NODEV_TMO].a_current) &&
+	    (clp[ELX_CFG_HOLDIO].a_current == 0)) {
+		/* if some timer's running, cancel it whether it's nodev timer
+		 * or delay timer
+		 */
+		if (ndlp->nlp_tmofunc) {
+			ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+			ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+			elx_clk_can(phba, ndlp->nlp_tmofunc);
+			ndlp->nlp_tmofunc = 0;
+		}
+
+		/* now start a nodev timer */
+		ndlp->nlp_flag |= NLP_NODEV_TMO;
+		ndlp->nle.nlp_rflag |= NLP_NPR_ACTIVE;
+		ndlp->nlp_tmofunc = elx_clk_set(phba,
+						clp[ELX_CFG_LINKDOWN_TMO].
+						a_current +
+						clp[ELX_CFG_NODEV_TMO].
+						a_current, lpfc_nodev_timeout,
+						(void *)ndlp, (void *)0);
+
+		/* Start nodev timer */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0706,	/* ptr to msg structure */
+			       elx_mes0706,	/* ptr to msg */
+			       elx_msgBlk0706.msgPreambleStr,	/* begin varargs */
+			       ndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_state, ndlp);	/* end varargs */
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_plogi_mapped_node(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	uint32_t *lp;
+	SERV_PARM *sp;
+	LS_RJT stat;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	sp = (SERV_PARM *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	if ((phba->hba_state <= ELX_FLOGI) ||
+	    ((lpfc_check_sparm(phba, ndlp, sp, CLASS3) == 0))) {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		if (phba->hba_state <= ELX_FLOGI) {
+			stat.un.b.lsRjtRsnCodeExp = LSRJT_LOGICAL_BSY;
+		} else {
+			stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		}
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	} else {
+		/* PLOGI chkparm OK */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0126,	/* ptr to msg structure */
+			       elx_mes0126,	/* ptr to msg */
+			       elx_msgBlk0126.msgPreambleStr,	/* begin varargs */
+			       ndlp->nlp_DID, ndlp->nlp_state, ndlp->nlp_flag, ((ELX_NODELIST_t *) ndlp)->nlp_rpi);	/* end varargs */
+
+		lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_prli_mapped_node(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	lpfc_els_rsp_prli_acc(phba, cmdiocb, ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_logo_mapped_node(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	/* software abort outstanding adisc before sending acc */
+	if (ndlp->nlp_flag & NLP_ADISC_SND) {
+		lpfc_driver_abort(phba, ndlp);
+	}
+	/* Only call LOGO ACC for first LOGO, this avoids sending unnecessary
+	 * PLOGIs during LOGO storms from a device.
+	 */
+	if (ndlp->nlp_flag & NLP_LOGO_ACC) {
+		ndlp->nlp_flag &= ~NLP_LOGO_ACC;
+		lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+		ndlp->nlp_flag |= NLP_LOGO_ACC;
+	} else {
+		ndlp->nlp_flag |= NLP_LOGO_ACC;
+		lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+	}
+
+	/* The driver has to wait until the ACC completes before we can continue
+	 * processing the LOGO, the action will resume in lpfc_cmpl_els_logo_acc.
+	 * Since part of processing includes an unreg_login, the driver waits
+	 * so the ACC does not get aborted.
+	 */
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_padisc_mapped_node(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+	SERV_PARM *sp;		/* used for PDISC */
+	ADISC *ap;		/* used for ADISC */
+	uint32_t *lp;
+	uint32_t cmd;
+	NAME_TYPE *pnn, *ppn;
+	LS_RJT stat;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	lp = (uint32_t *) pCmd->virt;
+	cmd = *lp++;
+
+	if (cmd == ELS_CMD_ADISC) {
+		ap = (ADISC *) lp;
+		pnn = (NAME_TYPE *) & ap->nodeName;
+		ppn = (NAME_TYPE *) & ap->portName;
+	} else {
+		sp = (SERV_PARM *) lp;
+		pnn = (NAME_TYPE *) & sp->nodeName;
+		ppn = (NAME_TYPE *) & sp->portName;
+	}
+
+	if (lpfc_check_adisc(phba, ndlp, pnn, ppn)) {
+		if (cmd == ELS_CMD_ADISC) {
+			lpfc_els_rsp_adisc_acc(phba, cmdiocb, ndlp);
+		} else {
+			lpfc_els_rsp_acc(phba, ELS_CMD_PLOGI, cmdiocb, ndlp, 0);
+		}
+	} else {
+		/* Reject this request because invalid parameters */
+		stat.un.b.lsRjtRsvd0 = 0;
+		stat.un.b.lsRjtRsnCode = LSRJT_UNABLE_TPC;
+		stat.un.b.lsRjtRsnCodeExp = LSEXP_SPARM_OPTIONS;
+		stat.un.b.vendorUnique = 0;
+		lpfc_els_rsp_reject(phba, stat.un.lsRjtError, cmdiocb, ndlp);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_rcv_prlo_mapped_node(elxHBA_t * phba,
+			  LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_IOCBQ_t *cmdiocb;
+	DMABUF_t *pCmd;
+
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+
+	elx_pci_dma_sync((void *)phba, (void *)pCmd, 0, ELX_DMA_SYNC_FORCPU);
+
+	lpfc_els_rsp_acc(phba, ELS_CMD_ACC, cmdiocb, ndlp, 0);
+
+	/* save binding on binding list */
+	if (ndlp->nlp_listp_bind) {
+		lpfc_nlp_bind(phba, ndlp->nlp_listp_bind);
+
+		elx_sched_flush_target(phba, ndlp->nlp_Target,
+				       IOSTAT_DRIVER_REJECT, IOERR_SLI_ABORTED);
+		ndlp->nlp_listp_bind = 0;
+		ndlp->nlp_pan = 0;
+		ndlp->nlp_sid = 0;
+		ndlp->nlp_Target = 0;
+		ndlp->nlp_flag &= ~NLP_SEED_MASK;
+	}
+
+	ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+	lpfc_nlp_unmapped(phba, ndlp);
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_logo_mapped_node(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* save binding on binding list */
+	if (ndlp->nlp_listp_bind) {
+		lpfc_nlp_bind(phba, ndlp->nlp_listp_bind);
+
+		elx_sched_flush_target(phba, ndlp->nlp_Target,
+				       IOSTAT_DRIVER_REJECT, IOERR_SLI_ABORTED);
+		ndlp->nlp_listp_bind = 0;
+		ndlp->nlp_pan = 0;
+		ndlp->nlp_sid = 0;
+		ndlp->nlp_Target = 0;
+		ndlp->nlp_flag &= ~NLP_SEED_MASK;
+	}
+
+	/* dequeue, cancel timeout, unreg login */
+	lpfc_freenode(phba, ndlp);
+
+	/* software abort outstanding adisc */
+	if (ndlp->nlp_flag & NLP_ADISC_SND) {
+		lpfc_driver_abort(phba, ndlp);
+	}
+
+	elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+	return (NLP_STE_UNUSED_NODE);
+}
+
+uint32_t
+lpfc_cmpl_adisc_mapped_node(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	ELX_IOCBQ_t *cmdiocb, *rspiocb;
+	DMABUF_t *pCmd, *pRsp;
+	uint32_t *lp;
+	IOCB_t *irsp;
+	LPFC_BINDLIST_t *blp;
+	ELXSCSILUN_t *lunp;
+	ELXSCSITARGET_t *targetp;
+	ADISC *ap;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	cmdiocb = (ELX_IOCBQ_t *) arg;
+	rspiocb = cmdiocb->q_f;
+	irsp = &rspiocb->iocb;
+
+	/* First remove the ndlp from any list */
+	if (ndlp->nlp_flag & NLP_LIST_MASK) {
+		lpfc_findnode_did(phba, (NLP_SEARCH_ALL | NLP_SEARCH_DEQUE),
+				  ndlp->nlp_DID);
+	}
+	if (irsp->ulpStatus) {
+		/* If this is not a driver aborted ADISC, handle the recovery here */
+		if (irsp->ulpStatus != IOSTAT_DRIVER_REJECT) {
+			lpfc_freenode(phba, ndlp);
+			ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+			lpfc_nlp_plogi(phba, ndlp);
+		}
+		return (ndlp->nlp_state);
+	}
+
+	pCmd = (DMABUF_t *) cmdiocb->context2;
+	pRsp = (DMABUF_t *) pCmd->next;
+	lp = (uint32_t *) pRsp->virt;
+
+	elx_pci_dma_sync((void *)phba, (void *)pRsp, 0, ELX_DMA_SYNC_FORCPU);
+
+	ap = (ADISC *) ((uint8_t *) lp + sizeof (uint32_t));
+
+	/* Check out ADISC rsp */
+	if ((lpfc_check_adisc(phba, ndlp, &ap->nodeName, &ap->portName) == 0)) {
+		/* This is not a driver aborted ADISC, so handle the recovery here */
+		lpfc_freenode(phba, ndlp);
+		ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+		lpfc_nlp_plogi(phba, ndlp);
+		return (ndlp->nlp_state);
+	}
+
+	/* Can we reassign a SCSI Id to this NPort */
+	if ((blp = lpfc_assign_scsid(phba, ndlp))) {
+		lpfc_nlp_mapped(phba, ndlp, blp);
+
+		ndlp->nlp_state = NLP_STE_MAPPED_NODE;
+		targetp = ndlp->nlp_Target;
+		if (targetp) {
+			targetp->targetFlags &= ~FC_NPR_ACTIVE;
+			if (targetp->tmofunc) {
+				elx_clk_can(phba, targetp->tmofunc);
+				targetp->tmofunc = 0;
+			}
+			lunp = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+			while (lunp) {
+				lunp->pnode = (ELX_NODELIST_t *) ndlp;
+				lunp = lunp->pnextLun;
+			}
+		} else {
+			/* new target to driver, allocate space to target <sid> lun 0 */
+			if (blp->nlp_Target == 0) {
+				lpfc_find_lun(phba, blp->nlp_sid, 0, 1);
+				blp->nlp_Target =
+				    plhba->device_queue_hash[blp->nlp_sid];
+			}
+		}
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_ALL_BITS,
+				  ELX_CLR_BITMASK);
+	} else {
+		lpfc_nlp_unmapped(phba, ndlp);
+		ndlp->nlp_state = NLP_STE_PRLI_COMPL;
+		ndlp->nlp_flag |= NLP_TGT_NO_SCSIID;
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN, ELX_CLR_BITMASK);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_cmpl_reglogin_mapped_node(elxHBA_t * phba,
+			       LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	ELX_MBOXQ_t *pmb, *mbox;
+	ELX_SLI_t *psli;
+	MAILBOX_t *mb;
+	uint32_t ldata;
+	uint16_t rpi;
+
+	if (ndlp->nlp_flag & NLP_LOGO_SND) {
+		return (ndlp->nlp_state);
+	}
+
+	pmb = (ELX_MBOXQ_t *) arg;
+	mb = &pmb->mb;
+	ldata = mb->un.varWords[0];	/* rpi */
+	rpi = (uint16_t) (PCIMEM_LONG(ldata) & 0xFFFF);
+
+	if (ndlp->nle.nlp_rpi != rpi) {
+		/* first unreg node's rpi */
+		if ((mbox =
+		     (ELX_MBOXQ_t *) elx_mem_get(phba, MEM_MBOX | MEM_PRI))) {
+			lpfc_unreg_login(phba, ndlp->nle.nlp_rpi, mbox);
+			if (elx_sli_issue_mbox
+			    (phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+			    == MBX_NOT_FINISHED) {
+				elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+			}
+		}
+		lpfc_findnode_remove_rpi(phba, ndlp->nle.nlp_rpi);
+		lpfc_no_rpi(phba, ndlp);
+		ndlp->nle.nlp_rpi = 0;
+
+		/* now unreg rpi just got back from reg_login */
+		lpfc_unreg_login(phba, rpi, mbox);
+		if (elx_sli_issue_mbox(phba, mbox, (MBX_NOWAIT | MBX_STOP_IOCB))
+		    == MBX_NOT_FINISHED) {
+			elx_mem_put(phba, MEM_MBOX, (uint8_t *) mbox);
+		}
+
+		/* save binding on binding list */
+		if (ndlp->nlp_listp_bind) {
+			lpfc_nlp_bind(phba, ndlp->nlp_listp_bind);
+
+			elx_sched_flush_target(phba, ndlp->nlp_Target,
+					       IOSTAT_DRIVER_REJECT,
+					       IOERR_SLI_ABORTED);
+			ndlp->nlp_listp_bind = 0;
+			ndlp->nlp_pan = 0;
+			ndlp->nlp_sid = 0;
+			ndlp->nlp_Target = 0;
+			ndlp->nlp_flag &= ~NLP_SEED_MASK;
+		}
+
+		/* If this node is running IPFC, flush any pending IP bufs.  An explicit
+		 * call is made since the node is not getting returned to the free list.
+		 */
+		psli = &phba->sli;
+		if (ndlp->nle.nlp_type & NLP_IP_NODE) {
+			lpfc_ip_flush_iocb(phba, &psli->ring[psli->ip_ring],
+					   ndlp, FLUSH_NODE);
+		}
+
+		/* software abort outstanding adisc */
+		if (ndlp->nlp_flag & NLP_ADISC_SND) {
+			lpfc_driver_abort(phba, ndlp);
+		}
+
+		/* send logout and put this node on plogi list */
+		lpfc_issue_els_logo(phba, ndlp, 0);
+		ndlp->nlp_state = NLP_STE_PLOGI_ISSUE;
+		lpfc_nlp_plogi(phba, ndlp);
+	}
+
+	return (ndlp->nlp_state);
+}
+
+/*! lpfc_device_rm_mapped_node
+  * 
+  * \pre
+  * \post
+  * \param   phba
+  * \param   ndlp
+  * \param   arg
+  * \param   evt
+  * \return  uint32_t
+  *
+  * \b Description:
+  *    This routine is envoked when we a request to remove a nport.
+  *    It could be called when linkdown or nodev timer expires.
+  *    If nodev timer is still running, we just want to exit.
+  *    If this node timed out, we want to abort outstanding ADISC,
+  *    save its binding, unreg login, send logout, change state to 
+  *    UNUSED_NODE and place node on plogi list so it can be freed 
+  *    when LOGO completes.
+  *
+  */
+uint32_t
+lpfc_device_rm_mapped_node(elxHBA_t * phba,
+			   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+	elxCfgParam_t *clp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+	/* if nodev timer is running, then we just exit */
+	if (!(ndlp->nlp_flag & NLP_NODEV_TMO)) {
+		lpfc_set_failmask(phba, ndlp, ELX_DEV_DISCONNECTED,
+				  ELX_SET_BITMASK);
+
+		if (ndlp->nlp_flag & NLP_ADISC_SND) {
+			/* software abort outstanding adisc */
+			lpfc_driver_abort(phba, ndlp);
+		}
+
+		/* save binding info */
+		if (ndlp->nlp_listp_bind) {
+			targetp = ndlp->nlp_Target;
+			lpfc_nlp_bind(phba, ndlp->nlp_listp_bind);
+			if (targetp) {
+				targetp->targetFlags &= ~FC_NPR_ACTIVE;
+				if (targetp->tmofunc) {
+					elx_clk_can(phba, targetp->tmofunc);
+					targetp->tmofunc = 0;
+				}
+				elx_sched_flush_target(phba, targetp,
+						       IOSTAT_DRIVER_REJECT,
+						       IOERR_SLI_ABORTED);
+			}
+
+			ndlp->nlp_listp_bind = 0;
+			ndlp->nlp_pan = 0;
+			ndlp->nlp_sid = 0;
+			ndlp->nlp_Target = 0;
+			ndlp->nlp_flag &= ~NLP_SEED_MASK;
+		}
+
+		/* dequeue, cancel timeout, unreg login */
+		lpfc_freenode(phba, ndlp);
+
+		/* If discovery processing causes us to remove a device, it is important
+		 * that nothing gets sent to the device (soft zoning issues).
+		 */
+		ndlp->nlp_state = NLP_STE_UNUSED_NODE;
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		return (NLP_STE_UNUSED_NODE);
+	}
+	targetp = ndlp->nlp_Target;
+	if (targetp) {
+		targetp->targetFlags |= FC_NPR_ACTIVE;
+		if (targetp->tmofunc) {
+			elx_clk_can(phba, targetp->tmofunc);
+		}
+		targetp->tmofunc = elx_clk_set(phba,
+					       (clp[ELX_CFG_NODEV_TMO].
+						a_current +
+						clp[ELX_CFG_LINKDOWN_TMO].
+						a_current), lpfc_npr_timeout,
+					       (void *)targetp, (void *)0);
+	}
+	lpfc_set_failmask(phba, ndlp, ELX_DEV_DISAPPEARED, ELX_SET_BITMASK);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_device_add_mapped_node(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	if (ndlp->nlp_tmofunc) {
+		ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+		ndlp->nle.nlp_rflag &= ~NLP_NPR_ACTIVE;
+		elx_clk_can(phba, ndlp->nlp_tmofunc);
+		ndlp->nlp_tmofunc = 0;
+	}
+	lpfc_nlp_adisc(phba, ndlp);
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_device_unk_mapped_node(elxHBA_t * phba,
+			    LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+	elxCfgParam_t *clp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	/* If we are in pt2pt mode, free node */
+	if (plhba->fc_flag & FC_PT2PT) {
+		/* dequeue, cancel timeout, unreg login */
+		lpfc_freenode(phba, ndlp);
+		elx_mem_put(phba, MEM_NLP, (uint8_t *) ndlp);
+		return (NLP_STE_UNUSED_NODE);
+	}
+
+	targetp = ndlp->nlp_Target;
+	if (targetp) {
+		targetp->targetFlags |= FC_NPR_ACTIVE;
+		if (targetp->tmofunc) {
+			elx_clk_can(phba, targetp->tmofunc);
+		}
+		targetp->tmofunc = elx_clk_set(phba,
+					       (clp[ELX_CFG_NODEV_TMO].
+						a_current +
+						clp[ELX_CFG_LINKDOWN_TMO].
+						a_current), lpfc_npr_timeout,
+					       (void *)targetp, (void *)0);
+	}
+
+	ndlp->nle.nlp_rflag |= NLP_NPR_ACTIVE;
+	/* linkdown timer should be running at this time.  Check to 
+	 * see if the driver has to start a nodev timer
+	 */
+	if ((clp[ELX_CFG_NODEV_TMO].a_current) &&
+	    (clp[ELX_CFG_HOLDIO].a_current == 0)) {
+		/* if some timer's running, cancel it whether it's nodev timer
+		 * or delay timer
+		 */
+		if (ndlp->nlp_tmofunc) {
+			ndlp->nlp_flag &= ~(NLP_NODEV_TMO | NLP_DELAY_TMO);
+			elx_clk_can(phba, ndlp->nlp_tmofunc);
+			ndlp->nlp_tmofunc = 0;
+		}
+
+		/* now start a nodev timer */
+		ndlp->nlp_flag |= NLP_NODEV_TMO;
+		ndlp->nlp_tmofunc = elx_clk_set(phba,
+						clp[ELX_CFG_LINKDOWN_TMO].
+						a_current +
+						clp[ELX_CFG_NODEV_TMO].
+						a_current, lpfc_nodev_timeout,
+						(void *)ndlp, (void *)0);
+
+		/* Start nodev timer */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0700,	/* ptr to msg structure */
+			       elx_mes0700,	/* ptr to msg */
+			       elx_msgBlk0700.msgPreambleStr,	/* begin varargs */
+			       ndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_state, ndlp);	/* end varargs */
+	}
+
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_disc_nodev(elxHBA_t * phba,
+		LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* This routine does nothing, just return the current state */
+	return (ndlp->nlp_state);
+}
+
+uint32_t
+lpfc_disc_neverdev(elxHBA_t * phba,
+		   LPFC_NODELIST_t * ndlp, void *arg, uint32_t evt)
+{
+	/* This routine does nothing, just return the current state */
+	return (ndlp->nlp_state);
+}
+
+int
+lpfc_geportname(NAME_TYPE * pn1, NAME_TYPE * pn2)
+{
+	int i;
+	uint8_t *cp1, *cp2;
+
+	i = sizeof (NAME_TYPE);
+	cp1 = (uint8_t *) pn1;
+	cp2 = (uint8_t *) pn2;
+	while (i--) {
+		if (*cp1 < *cp2) {
+			return (0);
+		}
+		if (*cp1 > *cp2) {
+			return (1);
+		}
+		cp1++;
+		cp2++;
+	}
+
+	return (2);		/* equal */
+}
+
+int
+lpfc_check_sparm(elxHBA_t * phba,
+		 LPFC_NODELIST_t * ndlp, SERV_PARM * sp, uint32_t class)
+{
+	volatile SERV_PARM *hsp;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	hsp = &plhba->fc_sparam;
+	/* First check for supported version */
+
+	/* Next check for class validity */
+	if (sp->cls1.classValid) {
+
+		if (sp->cls1.rcvDataSizeMsb > hsp->cls1.rcvDataSizeMsb)
+			sp->cls1.rcvDataSizeMsb = hsp->cls1.rcvDataSizeMsb;
+		if (sp->cls1.rcvDataSizeLsb > hsp->cls1.rcvDataSizeLsb)
+			sp->cls1.rcvDataSizeLsb = hsp->cls1.rcvDataSizeLsb;
+	} else if (class == CLASS1) {
+		return (0);
+	}
+
+	if (sp->cls2.classValid) {
+
+		if (sp->cls2.rcvDataSizeMsb > hsp->cls2.rcvDataSizeMsb)
+			sp->cls2.rcvDataSizeMsb = hsp->cls2.rcvDataSizeMsb;
+		if (sp->cls2.rcvDataSizeLsb > hsp->cls2.rcvDataSizeLsb)
+			sp->cls2.rcvDataSizeLsb = hsp->cls2.rcvDataSizeLsb;
+	} else if (class == CLASS2) {
+		return (0);
+	}
+
+	if (sp->cls3.classValid) {
+
+		if (sp->cls3.rcvDataSizeMsb > hsp->cls3.rcvDataSizeMsb)
+			sp->cls3.rcvDataSizeMsb = hsp->cls3.rcvDataSizeMsb;
+		if (sp->cls3.rcvDataSizeLsb > hsp->cls3.rcvDataSizeLsb)
+			sp->cls3.rcvDataSizeLsb = hsp->cls3.rcvDataSizeLsb;
+	} else if (class == CLASS3) {
+		return (0);
+	}
+
+	if (sp->cmn.bbRcvSizeMsb > hsp->cmn.bbRcvSizeMsb)
+		sp->cmn.bbRcvSizeMsb = hsp->cmn.bbRcvSizeMsb;
+	if (sp->cmn.bbRcvSizeLsb > hsp->cmn.bbRcvSizeLsb)
+		sp->cmn.bbRcvSizeLsb = hsp->cmn.bbRcvSizeLsb;
+
+	/* If check is good, copy wwpn wwnn into ndlp */
+	memcpy(&ndlp->nlp_nodename, &sp->nodeName, sizeof (NAME_TYPE));
+	memcpy(&ndlp->nlp_portname, &sp->portName, sizeof (NAME_TYPE));
+	return (1);
+}
+
+int
+lpfc_check_adisc(elxHBA_t * phba,
+		 LPFC_NODELIST_t * ndlp, NAME_TYPE * nn, NAME_TYPE * pn)
+{
+	if (lpfc_geportname((NAME_TYPE *) nn, &ndlp->nlp_nodename) != 2) {
+		return (0);
+	}
+
+	if (lpfc_geportname((NAME_TYPE *) pn, &ndlp->nlp_portname) != 2) {
+		return (0);
+	}
+
+	return (1);
+}
+
+int
+lpfc_binding_found(LPFC_BINDLIST_t * blp, LPFC_NODELIST_t * ndlp)
+{
+	uint16_t bindtype;
+
+	bindtype = blp->nlp_bind_type;
+	if ((bindtype & FCP_SEED_DID) && (ndlp->nlp_DID == blp->nlp_DID)) {
+		return (1);
+	} else if ((bindtype & FCP_SEED_WWPN) &&
+		   (lpfc_geportname(&ndlp->nlp_portname, &blp->nlp_portname) ==
+		    2)) {
+		return (1);
+	} else if ((bindtype & FCP_SEED_WWNN) &&
+		   (lpfc_geportname(&ndlp->nlp_nodename, &blp->nlp_nodename) ==
+		    2)) {
+		return (1);
+	}
+	return (0);
+}
+
+int
+lpfc_binding_useid(elxHBA_t * phba, uint16_t pan, uint16_t sid)
+{
+	LPFCHBA_t *plhba;
+	LPFC_BINDLIST_t *blp;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ELX_DISC_LOCK(phba, iflag);
+	blp = plhba->fc_nlpbind_start;
+	while ((blp) && (blp != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start)) {
+		if ((blp->nlp_pan == pan) && (blp->nlp_sid == sid)) {
+			ELX_DISC_UNLOCK(phba, iflag);
+			return (1);
+		}
+		blp = blp->nlp_listp_next;
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+	return (0);
+}
+
+int
+lpfc_mapping_useid(elxHBA_t * phba, uint16_t pan, uint16_t sid)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *mapnode;
+	LPFC_BINDLIST_t *blp;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ELX_DISC_LOCK(phba, iflag);
+	mapnode = plhba->fc_nlpmap_start;
+
+	while ((mapnode)
+	       && (mapnode != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start)) {
+		blp = mapnode->nlp_listp_bind;
+		if ((blp->nlp_pan == pan) && (blp->nlp_sid == sid)) {
+			ELX_DISC_UNLOCK(phba, iflag);
+			return (1);
+		}
+		mapnode = (LPFC_NODELIST_t *) (mapnode->nle.nlp_listp_next);
+	}
+	ELX_DISC_UNLOCK(phba, iflag);
+	return (0);
+}
+
+LPFC_BINDLIST_t *
+lpfc_create_binding(elxHBA_t * phba,
+		    LPFC_NODELIST_t * ndlp, uint16_t index, uint16_t bindtype)
+{
+	LPFC_BINDLIST_t *blp;
+	LPFCHBA_t *plhba;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	if ((blp = (LPFC_BINDLIST_t *) elx_mem_get(phba, MEM_BIND))) {
+		memset((void *)blp, 0, sizeof (LPFC_BINDLIST_t));
+		switch (bindtype) {
+		case FCP_SEED_WWPN:
+			blp->nlp_bind_type = FCP_SEED_WWPN;
+			break;
+		case FCP_SEED_WWNN:
+			blp->nlp_bind_type = FCP_SEED_WWNN;
+			break;
+		case FCP_SEED_DID:
+			blp->nlp_bind_type = FCP_SEED_DID;
+			break;
+		}
+		blp->nlp_sid = DEV_SID(index);
+		blp->nlp_pan = DEV_PAN(index);
+		blp->nlp_DID = ndlp->nlp_DID;
+		blp->nlp_Target = plhba->device_queue_hash[index];
+		memcpy(&blp->nlp_nodename, &ndlp->nlp_nodename,
+		       sizeof (NAME_TYPE));
+		memcpy(&blp->nlp_portname, &ndlp->nlp_portname,
+		       sizeof (NAME_TYPE));
+
+		return (blp);
+	}
+
+	return (0);
+}
+
+uint32_t
+lpfc_add_bind(elxHBA_t * phba, uint8_t bind_type,	/* NN/PN/DID */
+	      void *bind_id,	/* pointer to the bind id value */
+	      uint32_t scsi_id)
+{
+	LPFC_NODELIST_t *ndlp;
+	LPFCHBA_t *plhba;
+	LPFC_BINDLIST_t *blp;
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	/* Check if the SCSI ID is currently mapped */
+	ndlp = lpfc_findnode_scsiid(phba, scsi_id);
+	if (ndlp && (ndlp != &plhba->fc_fcpnodev)) {
+		return ENOENT;
+	}
+	/* Check if the SCSI ID is currently in the bind list. */
+	blp = plhba->fc_nlpbind_start;
+	while ((blp) && (blp != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start)) {
+		if (blp->nlp_sid == scsi_id) {
+			return ENOENT;
+		}
+		switch (bind_type) {
+		case FCP_SEED_WWPN:
+			if ((blp->nlp_bind_type & FCP_SEED_WWPN) &&
+			    (lpfc_geportname(bind_id, &blp->nlp_portname) ==
+			     2)) {
+				return EBUSY;
+			}
+			break;
+		case FCP_SEED_WWNN:
+			if ((blp->nlp_bind_type & FCP_SEED_WWNN) &&
+			    (lpfc_geportname(bind_id, &blp->nlp_nodename) ==
+			     2)) {
+				return EBUSY;
+			}
+			break;
+		case FCP_SEED_DID:
+			if ((blp->nlp_bind_type & FCP_SEED_DID) &&
+			    (*((uint32_t *) bind_id) == blp->nlp_DID)) {
+				return EBUSY;
+			}
+			break;
+		}
+
+		blp = (LPFC_BINDLIST_t *) blp->nlp_listp_next;
+	}
+	if (plhba->fcp_mapping != bind_type) {
+		return EINVAL;
+	}
+	switch (bind_type) {
+	case FCP_SEED_WWNN:
+		{
+			/* Check if the node name present in the mapped list */
+			ndlp =
+			    lpfc_findnode_wwnn(phba, NLP_SEARCH_MAPPED,
+					       bind_id);
+			if (ndlp) {
+				return EBUSY;
+			}
+			ndlp =
+			    lpfc_findnode_wwnn(phba, NLP_SEARCH_UNMAPPED,
+					       bind_id);
+			break;
+		}
+	case FCP_SEED_WWPN:
+		{
+			/* Check if the port name present in the mapped list */
+			ndlp =
+			    lpfc_findnode_wwpn(phba, NLP_SEARCH_MAPPED,
+					       bind_id);
+			if (ndlp)
+				return EBUSY;
+			ndlp =
+			    lpfc_findnode_wwpn(phba, NLP_SEARCH_UNMAPPED,
+					       bind_id);
+			break;
+		}
+	case FCP_SEED_DID:
+		{
+			/* Check if the DID present in the mapped list */
+			ndlp =
+			    lpfc_findnode_did(phba, NLP_SEARCH_MAPPED,
+					      *((uint32_t *) bind_id));
+			if (ndlp)
+				return EBUSY;
+			ndlp =
+			    lpfc_findnode_did(phba, NLP_SEARCH_UNMAPPED,
+					      *((uint32_t *) bind_id));
+			break;
+		}
+	}
+
+	/* Add to the bind list */
+	if ((blp = (LPFC_BINDLIST_t *) elx_mem_get(phba, MEM_BIND)) == NULL) {
+		return EIO;
+	}
+	memset((void *)blp, 0, sizeof (LPFC_BINDLIST_t));
+	blp->nlp_bind_type = bind_type;
+	blp->nlp_sid = (scsi_id & 0xff);
+
+	switch (bind_type) {
+	case FCP_SEED_WWNN:
+		memcpy(&blp->nlp_nodename, (uint8_t *) bind_id,
+		       sizeof (NAME_TYPE));
+		break;
+
+	case FCP_SEED_WWPN:
+		memcpy(&blp->nlp_portname, (uint8_t *) bind_id,
+		       sizeof (NAME_TYPE));
+		break;
+
+	case FCP_SEED_DID:
+		blp->nlp_DID = *((uint32_t *) bind_id);
+		break;
+
+	}
+
+	lpfc_nlp_bind(phba, blp);
+	/* 
+	   If the newly added node is in the unmapped list, assign a
+	   SCSI ID to the node.
+	 */
+
+	if (ndlp) {
+		if ((blp = lpfc_assign_scsid(phba, ndlp))) {
+			lpfc_nlp_mapped(phba, ndlp, blp);
+			ndlp->nle.nlp_failMask = 0;
+			targetp = ndlp->nlp_Target;
+			if (targetp) {
+				lunp =
+				    (ELXSCSILUN_t *) (targetp->lunlist.q_first);
+				while (lunp) {
+					lunp->failMask = 0;
+					lunp = lunp->pnextLun;
+				}
+				if (targetp->tmofunc) {
+					elx_clk_can(phba, targetp->tmofunc);
+					targetp->tmofunc = 0;
+				}
+			} else {
+				/* new target to driver, allocate space to target <sid> lun 0 */
+				if (blp->nlp_Target == 0) {
+					lpfc_find_lun(phba, blp->nlp_sid, 0, 1);
+					blp->nlp_Target =
+					    plhba->device_queue_hash[blp->
+								     nlp_sid];
+				}
+			}
+			lpfc_set_failmask(phba, ndlp, ELX_DEV_RPTLUN,
+					  ELX_SET_BITMASK);
+			ndlp->nlp_state = NLP_STE_MAPPED_NODE;
+			lpfc_disc_issue_rptlun(phba, ndlp);
+		} else {
+
+		}
+	}
+	return (0);
+}
+
+uint32_t
+lpfc_del_bind(elxHBA_t * phba, uint8_t bind_type,	/* NN/PN/DID */
+	      void *bind_id,	/* pointer to the bind id value */
+	      uint32_t scsi_id)
+{
+	LPFC_BINDLIST_t *blp;
+	LPFCHBA_t *plhba;
+	uint32_t found = 0;
+	unsigned long iflag;
+	LPFC_NODELIST_t *ndlp = 0;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	/* Search the mapped list for the bind_id */
+	if (!bind_id) {
+		ndlp = lpfc_findnode_scsiid(phba, scsi_id);
+		if ((ndlp == &plhba->fc_fcpnodev) ||
+		    (ndlp && (!(ndlp->nlp_flag & NLP_MAPPED_LIST))))
+			ndlp = NULL;
+	} else {
+
+		if (bind_type != plhba->fcp_mapping)
+			return EINVAL;
+
+		switch (bind_type) {
+		case FCP_SEED_WWNN:
+			ndlp =
+			    lpfc_findnode_wwnn(phba, NLP_SEARCH_MAPPED,
+					       bind_id);
+			break;
+
+		case FCP_SEED_WWPN:
+			ndlp =
+			    lpfc_findnode_wwpn(phba, NLP_SEARCH_MAPPED,
+					       bind_id);
+			break;
+
+		case FCP_SEED_DID:
+			ndlp =
+			    lpfc_findnode_did(phba, NLP_SEARCH_MAPPED,
+					      *((uint32_t *) bind_id));
+			break;
+		}
+	}
+
+	/* If there is a mapped target for this bing unmap it */
+	if (ndlp) {
+		return EBUSY;
+	}
+
+	/* check binding list */
+	blp = plhba->fc_nlpbind_start;
+
+	/* Search the bind list for the bind_id */
+	while ((blp) && (blp != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start)) {
+		if (!bind_id) {
+			/* Search binding based on SCSI ID */
+			if (blp->nlp_sid == scsi_id) {
+				found = 1;
+				break;
+			} else {
+				blp = blp->nlp_listp_next;
+				continue;
+			}
+		}
+
+		switch (bind_type) {
+		case FCP_SEED_WWPN:
+			if ((blp->nlp_bind_type & FCP_SEED_WWPN) &&
+			    (lpfc_geportname(bind_id, &blp->nlp_portname) ==
+			     2)) {
+				found = 1;
+			}
+			break;
+		case FCP_SEED_WWNN:
+			if ((blp->nlp_bind_type & FCP_SEED_WWNN) &&
+			    (lpfc_geportname(bind_id, &blp->nlp_nodename) ==
+			     2)) {
+				found = 1;
+			}
+			break;
+		case FCP_SEED_DID:
+			if ((blp->nlp_bind_type & FCP_SEED_DID) &&
+			    (*((uint32_t *) bind_id) == blp->nlp_DID)) {
+				found = 1;
+			}
+			break;
+		}
+		if (found)
+			break;
+
+		blp = blp->nlp_listp_next;
+	}
+
+	if (found) {
+		/* take it off the bind list */
+		ELX_DISC_LOCK(phba, iflag);
+		plhba->fc_bind_cnt--;
+		elx_deque(blp);
+		ELX_DISC_UNLOCK(phba, iflag);
+
+		return 0;
+	}
+
+	return ENOENT;
+}
+
+LPFC_BINDLIST_t *
+lpfc_assign_scsid(elxHBA_t * phba, LPFC_NODELIST_t * ndlp)
+{
+	LPFCHBA_t *plhba;
+	LPFC_BINDLIST_t *blp;
+	elxCfgParam_t *clp;
+	uint16_t index;
+	unsigned long iflag;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	clp = &phba->config[0];
+
+	/* check binding list */
+	blp = plhba->fc_nlpbind_start;
+	while ((blp) && (blp != (LPFC_BINDLIST_t *) & plhba->fc_nlpbind_start)) {
+		if (lpfc_binding_found(blp, ndlp)) {
+			ndlp->nlp_pan = blp->nlp_pan;
+			ndlp->nlp_sid = blp->nlp_sid;
+			ndlp->nlp_Target = blp->nlp_Target;
+			ndlp->nlp_flag &= ~NLP_SEED_MASK;
+			switch ((blp->nlp_bind_type & FCP_SEED_MASK)) {
+			case FCP_SEED_WWPN:
+				ndlp->nlp_flag |= NLP_SEED_WWPN;
+				break;
+			case FCP_SEED_WWNN:
+				ndlp->nlp_flag |= NLP_SEED_WWNN;
+				break;
+			case FCP_SEED_DID:
+				ndlp->nlp_flag |= NLP_SEED_DID;
+				break;
+			}
+			if (blp->nlp_bind_type & FCP_SEED_AUTO) {
+				ndlp->nlp_flag |= NLP_AUTOMAP;
+			}
+
+			/* take it off the binding list */
+			ELX_DISC_LOCK(phba, iflag);
+			plhba->fc_bind_cnt--;
+			elx_deque(blp);
+			ELX_DISC_UNLOCK(phba, iflag);
+
+			/* Reassign scsi id <sid> to NPort <nlp_DID> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0213,	/* ptr to msg structure */
+				       elx_mes0213,	/* ptr to msg */
+				       elx_msgBlk0213.msgPreambleStr,	/* begin varargs */
+				       blp->nlp_sid, ndlp->nlp_DID, blp->nlp_bind_type, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+			return (blp);
+		}
+
+		blp = blp->nlp_listp_next;
+	}
+
+	/* NOTE: if scan-down = 2 and we have private loop, then we use
+	 * AlpaArray to determine sid/pan.
+	 */
+	if ((clp[LPFC_CFG_BINDMETHOD].a_current == 4) &&
+	    ((plhba->fc_flag & (FC_PUBLIC_LOOP | FC_FABRIC)) ||
+	     (plhba->fc_topology != TOPOLOGY_LOOP))) {
+		/* Log message: ALPA based binding used on a non loop topology */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0245,	/* ptr to msg structure */
+			       elx_mes0245,	/* ptr to msg */
+			       elx_msgBlk0245.msgPreambleStr,	/* begin varargs */
+			       plhba->fc_topology);	/* end varargs */
+	}
+
+	if ((clp[LPFC_CFG_BINDMETHOD].a_current == 4) &&
+	    !(plhba->fc_flag & (FC_PUBLIC_LOOP | FC_FABRIC)) &&
+	    (plhba->fc_topology == TOPOLOGY_LOOP)) {
+		for (index = 0; index < FC_MAXLOOP; index++) {
+			if (ndlp->nlp_DID == (uint32_t) lpfcAlpaArray[index]) {
+				if ((blp =
+				     lpfc_create_binding(phba, ndlp, index,
+							 FCP_SEED_DID))) {
+
+					ndlp->nlp_pan = DEV_PAN(index);
+					ndlp->nlp_sid = DEV_SID(index);
+					ndlp->nlp_Target =
+					    plhba->device_queue_hash[index];
+					ndlp->nlp_flag &= ~NLP_SEED_MASK;
+					ndlp->nlp_flag |= NLP_SEED_DID;
+					ndlp->nlp_flag |= NLP_SEED_ALPA;
+
+					/* Assign scandown scsi id <sid> to NPort <nlp_DID> */
+					elx_printf_log(phba->brd_no, &elx_msgBlk0216,	/* ptr to msg structure */
+						       elx_mes0216,	/* ptr to msg */
+						       elx_msgBlk0216.msgPreambleStr,	/* begin varargs */
+						       blp->nlp_sid, ndlp->nlp_DID, blp->nlp_bind_type, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+					return (blp);
+				}
+				goto errid;
+			}
+		}
+	}
+
+	if (clp[LPFC_CFG_AUTOMAP].a_current) {
+		while (1) {
+			if ((lpfc_binding_useid
+			     (phba, plhba->pan_cnt, plhba->sid_cnt))
+			    ||
+			    (lpfc_mapping_useid
+			     (phba, plhba->pan_cnt, plhba->sid_cnt))) {
+
+				plhba->sid_cnt++;
+				if (plhba->sid_cnt > LPFC_MAX_SCSI_ID_PER_PAN) {
+					plhba->sid_cnt = 0;
+					plhba->pan_cnt++;
+				}
+			} else {
+				if ((blp =
+				     lpfc_create_binding(phba, ndlp,
+							 plhba->sid_cnt,
+							 plhba->fcp_mapping))) {
+					ndlp->nlp_pan = blp->nlp_pan;
+					ndlp->nlp_sid = blp->nlp_sid;
+					ndlp->nlp_Target = blp->nlp_Target;
+					ndlp->nlp_flag &= ~NLP_SEED_MASK;
+					switch ((blp->
+						 nlp_bind_type & FCP_SEED_MASK))
+					{
+					case FCP_SEED_WWPN:
+						ndlp->nlp_flag |= NLP_SEED_WWPN;
+						break;
+					case FCP_SEED_WWNN:
+						ndlp->nlp_flag |= NLP_SEED_WWNN;
+						break;
+					case FCP_SEED_DID:
+						ndlp->nlp_flag |= NLP_SEED_DID;
+						break;
+					}
+					blp->nlp_bind_type |= FCP_SEED_AUTO;
+					ndlp->nlp_flag |= NLP_AUTOMAP;
+
+					plhba->sid_cnt++;
+					if (plhba->sid_cnt >
+					    LPFC_MAX_SCSI_ID_PER_PAN) {
+						plhba->sid_cnt = 0;
+						plhba->pan_cnt++;
+					}
+
+					/* Assign scsi id <sid> to NPort <nlp_DID> */
+					elx_printf_log(phba->brd_no, &elx_msgBlk0229,	/* ptr to msg structure */
+						       elx_mes0229,	/* ptr to msg */
+						       elx_msgBlk0229.msgPreambleStr,	/* begin varargs */
+						       blp->nlp_sid, ndlp->nlp_DID, blp->nlp_bind_type, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+					return (blp);
+				}
+				goto errid;
+			}
+		}
+	}
+	/* if automap on */
+      errid:
+	/* Cannot assign scsi id on NPort <nlp_DID> */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0230,	/* ptr to msg structure */
+		       elx_mes0230,	/* ptr to msg */
+		       elx_msgBlk0230.msgPreambleStr,	/* begin varargs */
+		       ndlp->nlp_DID, ndlp->nlp_flag, ndlp->nlp_state, ndlp->nle.nlp_rpi);	/* end varargs */
+
+	return (0);
+}
+
+void
+lpfc_qthrottle_up(elxHBA_t * phba, void *n1, void *n2)
+{
+	LPFCHBA_t *plhba;
+	LPFC_NODELIST_t *ndlp;
+	ELXSCSITARGET_t *ptarget;
+	ELXSCSILUN_t *plun;
+	elxCfgParam_t *clp;
+	int reset_clock = 0;
+
+	clp = &phba->config[0];
+	if (clp[ELX_CFG_DFT_LUN_Q_DEPTH].a_current <= ELX_MIN_QFULL) {
+		return;
+	}
+
+	if (phba->hba_state != ELX_HBA_READY) {
+		plhba = (LPFCHBA_t *) phba->pHbaProto;
+		ndlp = plhba->fc_nlpmap_start;
+		while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+			ptarget = ndlp->nlp_Target;
+			if (ptarget) {
+				plun =
+				    (ELXSCSILUN_t *) ptarget->lunlist.q_first;
+				while (plun) {
+					plun->lunSched.maxOutstanding =
+					    plun->fcp_lun_queue_depth;
+					plun->stop_send_io = 0;
+					plun = plun->pnextLun;
+				}
+			}
+			ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+		}
+		return;
+	}
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	ndlp = plhba->fc_nlpmap_start;
+	while (ndlp != (LPFC_NODELIST_t *) & plhba->fc_nlpmap_start) {
+		ptarget = ndlp->nlp_Target;
+		if (ptarget) {
+			plun = (ELXSCSILUN_t *) ptarget->lunlist.q_first;
+			while (plun) {
+				if ((plun->stop_send_io == 0) &&
+				    (plun->lunSched.maxOutstanding <
+				     plun->fcp_lun_queue_depth)) {
+					/* 
+					 * update lun q throttle 
+					 */
+					plun->lunSched.maxOutstanding +=
+					    clp[ELX_CFG_DQFULL_THROTTLE_UP_INC].
+					    a_current;
+					if (plun->lunSched.maxOutstanding >
+					    plun->fcp_lun_queue_depth) {
+						plun->lunSched.maxOutstanding =
+						    plun->fcp_lun_queue_depth;
+					}
+					elx_printf
+					    ("lpfc_qthrottle_up: maxOutstanding=%d %x %x %x",
+					     plun->lunSched.maxOutstanding, 0,
+					     0, 0);
+					reset_clock = 1;
+				} else {
+					/* 
+					 * Try to reset stop_send_io 
+					 */
+					if (plun->stop_send_io) {
+						plun->stop_send_io--;
+						reset_clock = 1;
+					}
+				}
+				plun = plun->pnextLun;
+			}
+		}
+		ndlp = (LPFC_NODELIST_t *) ndlp->nle.nlp_listp_next;
+	}
+
+	if (reset_clock) {
+		phba->dqfull_clk = elx_clk_set(phba,
+					       clp
+					       [ELX_CFG_DQFULL_THROTTLE_UP_TIME].
+					       a_current, lpfc_qthrottle_up, 0,
+					       0);
+	}
+
+	return;
+}
+
+void
+lpfc_npr_timeout(elxHBA_t * phba, void *l1, void *l2)
+{
+	ELXSCSITARGET_t *targetp;
+
+	targetp = (ELXSCSITARGET_t *) l1;
+	targetp->targetFlags &= ~FC_NPR_ACTIVE;
+	targetp->tmofunc = 0;
+	elx_sched_flush_target(phba, targetp, IOSTAT_DRIVER_REJECT,
+			       IOERR_SLI_ABORTED);
+	return;
+}
+
+int
+lpfc_scsi_hba_reset(elxHBA_t * phba, ELX_SCSI_BUF_t * elx_cmd)
+{
+	ELXSCSITARGET_t *ptarget;
+	LPFCHBA_t *plhba;
+	int ret;
+	int i;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+
+	for (i = 0; i < MAX_FCP_TARGET; i++) {
+		ptarget = plhba->device_queue_hash[i];
+		if (ptarget) {
+			elx_cmd->scsi_hba = phba;
+			elx_cmd->scsi_bus = 0;
+			elx_cmd->scsi_target = i;
+			elx_cmd->scsi_lun = 0;
+
+			ret = elx_scsi_tgt_reset(elx_cmd,
+						 phba,
+						 0, i, ELX_EXTERNAL_RESET);
+			if (!ret) {
+				return (0);
+			}
+		}
+	}
+
+	return (1);
+}
+
+ELX_SCSI_BUF_t *
+lpfc_build_scsi_cmd(elxHBA_t * phba,
+		    LPFC_NODELIST_t * nlp, uint32_t scsi_cmd, uint64_t lun)
+{
+	ELX_SLI_t *psli;
+	LPFCHBA_t *plhba;
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp;
+	DMABUF_t *mp;
+	ELX_SCSI_BUF_t *elx_cmd;
+	ELX_IOCBQ_t *piocbq;
+	IOCB_t *piocb;
+	FCP_CMND *fcpCmnd;
+	ULP_BDE64 *bpl;
+	uint32_t tgt;
+
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	tgt = FC_SCSID(nlp->nlp_pan, nlp->nlp_sid);
+	lunp = lpfc_find_lun(phba, tgt, lun, 1);
+	elx_cmd = 0;
+	/* First see if the SCSI ID has an allocated ELXSCSITARGET_t */
+	if (lunp && lunp->pTarget) {
+		targetp = lunp->pTarget;
+		psli = &phba->sli;
+
+		/* Get a buffer to hold SCSI data */
+		if ((mp = (DMABUF_t *) elx_mem_get(phba, MEM_BUF)) == 0) {
+			return (0);
+		}
+		/* Get resources to send a SCSI command */
+		elx_cmd = elx_get_scsi_buf(phba);
+		if (elx_cmd == 0) {
+			elx_mem_put(phba, MEM_BUF, (uint8_t *) mp);
+			return (0);
+		}
+		elx_cmd->pLun = lunp;
+		elx_cmd->scsi_target = tgt;
+		elx_cmd->scsi_lun = lun;
+		elx_cmd->timeout = 30 + phba->fcp_timeout_offset;
+
+		/* Finish building BPL with the I/O dma ptrs.
+		 * setup FCP CMND, and setup IOCB.
+		 */
+
+		fcpCmnd = elx_cmd->fcp_cmnd;
+
+		putLunHigh(fcpCmnd->fcpLunMsl, lun);	/* LUN */
+		putLunLow(fcpCmnd->fcpLunLsl, lun);	/* LUN */
+
+		switch (scsi_cmd) {
+		case FCP_SCSI_REPORT_LUNS:
+			fcpCmnd->fcpCdb[0] = scsi_cmd;
+			fcpCmnd->fcpCdb[8] = 0x04;	/* 0x400 = ELX_SCSI_BUF_SZ */
+			fcpCmnd->fcpCdb[9] = 0x00;
+			fcpCmnd->fcpCntl3 = READ_DATA;
+			fcpCmnd->fcpDl = SWAP_DATA(ELX_SCSI_BUF_SZ);
+
+			break;
+		case FCP_SCSI_INQUIRY:
+			fcpCmnd->fcpCdb[0] = scsi_cmd;	/* SCSI Inquiry Command */
+			fcpCmnd->fcpCdb[4] = 0xff;	/* allocation length */
+			fcpCmnd->fcpCntl3 = READ_DATA;
+			fcpCmnd->fcpDl = SWAP_DATA(ELX_SCSI_BUF_SZ);
+			break;
+		}
+
+		bpl = elx_cmd->fcp_bpl;
+		bpl += 2;	/* Bump past FCP CMND and FCP RSP */
+
+		/* no scatter-gather list case */
+		bpl->addrLow = PCIMEM_LONG(putPaddrLow(mp->phys));
+		bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(mp->phys));
+		bpl->tus.f.bdeSize = ELX_SCSI_BUF_SZ;
+		bpl->tus.f.bdeFlags = BUFF_USE_RCV;
+		bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+		bpl++;
+		bpl->addrHigh = 0;
+		bpl->addrLow = 0;
+		bpl->tus.w = 0;
+
+		piocbq = &elx_cmd->cur_iocbq;
+		piocb = &piocbq->iocb;
+		piocb->ulpCommand = CMD_FCP_IREAD64_CR;
+		piocb->ulpPU = PARM_READ_CHECK;
+		piocb->un.fcpi.fcpi_parm = ELX_SCSI_BUF_SZ;
+		piocb->un.fcpi64.bdl.bdeSize += sizeof (ULP_BDE64);
+		piocb->ulpBdeCount = 1;
+		piocb->ulpLe = 1;	/* Set the LE bit in the iocb */
+
+		/* Get an iotag and finish setup of IOCB  */
+		piocb->ulpIoTag = elx_sli_next_iotag(phba,
+						     &phba->sli.ring[psli->
+								     fcp_ring]);
+		piocb->ulpContext = nlp->nle.nlp_rpi;
+		if (nlp->nle.nlp_fcp_info & NLP_FCP_2_DEVICE) {
+			piocb->ulpFCP2Rcvy = 1;
+		}
+		piocb->ulpClass = (nlp->nle.nlp_fcp_info & 0x0f);
+
+		/* ulpTimeout is only one byte */
+		if (elx_cmd->timeout > 0xff) {
+			/*
+			 * Do not timeout the command at the firmware level.
+			 * The driver will provide the timeout mechanism.
+			 */
+			piocb->ulpTimeout = 0;
+		} else {
+			piocb->ulpTimeout = elx_cmd->timeout;
+		}
+
+		/*
+		 * Setup driver timeout, in case the command does not complete
+		 * Driver timeout should be greater than ulpTimeout
+		 */
+
+		piocbq->drvrTimeout = elx_cmd->timeout + ELX_DRVR_TIMEOUT;
+
+		/* set up iocb return path by setting the context fields
+		 * and the completion function.
+		 */
+		piocbq->context1 = elx_cmd;
+		piocbq->context2 = mp;
+
+	}
+	return (elx_cmd);
+}
+
+void
+lpfc_scsi_timeout_handler(elxHBA_t * phba, void *arg1, void *arg2)
+{
+	ELX_SLI_t *psli;
+	ELX_SLI_RING_t *pring;
+	ELX_IOCBQ_t *next_iocb;
+	ELX_IOCBQ_t *piocb;
+	IOCB_t *cmd = NULL;
+	LPFCHBA_t *plhba;
+	ELX_SCSI_BUF_t *elx_cmd;
+	uint32_t timeout;
+	uint32_t next_timeout;
+
+	psli = &phba->sli;
+	pring = &psli->ring[psli->fcp_ring];
+	plhba = (LPFCHBA_t *) phba->pHbaProto;
+	timeout = (uint32_t) (unsigned long)arg1;
+	next_timeout = (plhba->fc_ratov << 1) > 5 ? (plhba->fc_ratov << 1) : 5;
+
+	next_iocb = (ELX_IOCBQ_t *) pring->txcmplq.q_f;
+	while (next_iocb != (ELX_IOCBQ_t *) & pring->txcmplq) {
+		piocb = next_iocb;
+		next_iocb = next_iocb->q_f;
+		cmd = &piocb->iocb;
+		elx_cmd = (ELX_SCSI_BUF_t *) piocb->context1;
+
+		if (piocb->iocb_flag & ELX_IO_IOCTL) {
+			continue;
+		}
+
+		if (piocb->drvrTimeout) {
+			if (piocb->drvrTimeout > timeout)
+				piocb->drvrTimeout -= timeout;
+			else
+				piocb->drvrTimeout = 0;
+
+			continue;
+		}
+
+		/*
+		 * The iocb has timed out; abort it.
+		 */
+
+		if (cmd->un.acxri.abortType == ABORT_TYPE_ABTS) {
+			/*
+			 * If abort times out, simply throw away the iocb
+			 */
+
+			elx_deque(piocb);
+			pring->txcmplq.q_cnt--;
+			(piocb->iocb_cmpl) ((void *)phba, piocb, piocb);
+		} else {
+			elx_printf_log(phba->brd_no, &elx_msgBlk0754,	/* ptr to msg structure */
+				       elx_mes0754,	/* ptr to msg */
+				       elx_msgBlk0754.msgPreambleStr,	/* begin varargs */
+				       elx_cmd->pLun->pTarget->un.dev_did, elx_cmd->pLun->pTarget->scsi_id, elx_cmd->fcp_cmnd->fcpCdb[0], cmd->ulpIoTag);	/* end varargs */
+
+			elx_sli_abort_iocb(phba, pring, piocb);
+		}
+	}
+
+	phba->scsi_tmofunc =
+	    elx_clk_set(phba, next_timeout, lpfc_scsi_timeout_handler,
+			(void *)(unsigned long)next_timeout, 0);
+}
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_crtn.h linux-2.6.3/drivers/scsi/lpfc/lpfc_crtn.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_crtn.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_crtn.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,372 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_LPFC_CRTN
+#define _H_LPFC_CRTN
+
+#include "elx_sli.h"
+#include "elx_scsi.h"
+#include "elx_logmsg.h"
+#include "lpfc_ioctl.h"
+#include "lpfc_ip.h"
+#include "lpfc_diag.h"
+
+/* For lpfc_mbox.c */
+void lpfc_dump_mem(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_read_nv(elxHBA_t *, ELX_MBOXQ_t *);
+int lpfc_read_la(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_clear_la(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_config_link(elxHBA_t *, ELX_MBOXQ_t *);
+int lpfc_read_sparam(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_read_config(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_set_slim(elxHBA_t *, ELX_MBOXQ_t *, uint32_t, uint32_t);
+void lpfc_config_farp(elxHBA_t *, ELX_MBOXQ_t *);
+int lpfc_reg_login(elxHBA_t *, uint32_t, uint8_t *, ELX_MBOXQ_t *, uint32_t);
+void lpfc_unreg_login(elxHBA_t *, uint32_t, ELX_MBOXQ_t *);
+void lpfc_unreg_did(elxHBA_t *, uint32_t, ELX_MBOXQ_t *);
+void lpfc_init_link(elxHBA_t *, ELX_MBOXQ_t *, uint32_t, uint32_t);
+uint32_t *lpfc_config_pcb_setup(elxHBA_t *);
+int lpfc_read_rpi(elxHBA_t *, uint32_t, ELX_MBOXQ_t *, uint32_t);
+
+/* For lpfc_hbadisc.c */
+int lpfc_linkdown(elxHBA_t *);
+int lpfc_linkup(elxHBA_t *);
+void lpfc_mbx_cmpl_read_la(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_mbx_cmpl_config_link(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_mbx_cmpl_read_sparam(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_mbx_cmpl_clear_la(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_mbx_cmpl_reg_login(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_mbx_cmpl_fabric_reg_login(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_mbx_cmpl_ns_reg_login(elxHBA_t *, ELX_MBOXQ_t *);
+void lpfc_mbx_cmpl_fdmi_reg_login(elxHBA_t *, ELX_MBOXQ_t *);
+int lpfc_nlp_bind(elxHBA_t *, LPFC_BINDLIST_t *);
+int lpfc_nlp_plogi(elxHBA_t *, LPFC_NODELIST_t *);
+int lpfc_nlp_adisc(elxHBA_t *, LPFC_NODELIST_t *);
+int lpfc_nlp_unmapped(elxHBA_t *, LPFC_NODELIST_t *);
+int lpfc_nlp_mapped(struct elxHBA *, LPFC_NODELIST_t *, LPFC_BINDLIST_t *);
+void *lpfc_set_disctmo(elxHBA_t *);
+int lpfc_can_disctmo(elxHBA_t *);
+int lpfc_driver_abort(elxHBA_t *, LPFC_NODELIST_t *);
+int lpfc_no_rpi(elxHBA_t *, LPFC_NODELIST_t *);
+int lpfc_freenode(elxHBA_t *, LPFC_NODELIST_t *);
+LPFC_NODELIST_t *lpfc_findnode_did(elxHBA_t *, uint32_t, uint32_t);
+LPFC_NODELIST_t *lpfc_findnode_scsiid(elxHBA_t *, uint32_t);
+LPFC_NODELIST_t *lpfc_findnode_wwpn(elxHBA_t *, uint32_t, NAME_TYPE *);
+LPFC_NODELIST_t *lpfc_findnode_wwnn(elxHBA_t *, uint32_t, NAME_TYPE *);
+void lpfc_disc_list_loopmap(elxHBA_t *);
+void lpfc_disc_start(elxHBA_t *);
+void lpfc_disc_flush_list(elxHBA_t *);
+void lpfc_disc_timeout(elxHBA_t *, void *, void *);
+void lpfc_linkdown_timeout(elxHBA_t *, void *, void *);
+void lpfc_nodev_timeout(elxHBA_t *, void *, void *);
+ELXSCSILUN_t *lpfc_find_lun(elxHBA_t *, uint32_t, uint64_t, int);
+ELX_SCSI_BUF_t *lpfc_build_scsi_cmd(elxHBA_t *, LPFC_NODELIST_t *, uint32_t,
+				    uint64_t);
+int lpfc_disc_issue_rptlun(elxHBA_t *, LPFC_NODELIST_t *);
+void lpfc_set_failmask(elxHBA_t *, LPFC_NODELIST_t *, uint32_t, uint32_t);
+
+/* These functions implement node hash table hashed on RPIs */
+LPFC_NODELIST_t *lpfc_findnode_rpi(elxHBA_t * phba, uint16_t rpi);
+LPFC_NODELIST_t *lpfc_findnode_remove_rpi(elxHBA_t * phba, uint16_t rpi);
+void lpfc_addnode_rpi(elxHBA_t * phba, LPFC_NODELIST_t * ndlp, uint16_t rpi);
+LPFC_NODELIST_t *lpfc_removenode_rpihash(elxHBA_t * phba,
+					 LPFC_NODELIST_t * ndlp);
+
+/* For lpfc_nportdisc.c */
+int lpfc_disc_state_machine(elxHBA_t *, LPFC_NODELIST_t *, void *, uint32_t);
+uint32_t lpfc_disc_nodev(elxHBA_t *, LPFC_NODELIST_t *, void *, uint32_t);
+uint32_t lpfc_disc_neverdev(elxHBA_t *, LPFC_NODELIST_t *, void *, uint32_t);
+/* UNUSED_NODE state */
+uint32_t lpfc_rcv_plogi_unused_node(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_rcv_els_unused_node(elxHBA_t *, LPFC_NODELIST_t *,
+				  void *, uint32_t);
+uint32_t lpfc_rcv_logo_unused_node(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_cmpl_els_unused_node(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_cmpl_reglogin_unused_node(elxHBA_t *, LPFC_NODELIST_t *,
+					void *, uint32_t);
+uint32_t lpfc_device_rm_unused_node(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_device_add_unused_node(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+uint32_t lpfc_device_unk_unused_node(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+/* PLOGI_ISSUE state */
+uint32_t lpfc_rcv_plogi_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_rcv_prli_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_rcv_logo_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_rcv_els_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				  void *, uint32_t);
+uint32_t lpfc_cmpl_plogi_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+uint32_t lpfc_cmpl_prli_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_cmpl_logo_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_cmpl_adisc_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+uint32_t lpfc_cmpl_reglogin_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+					void *, uint32_t);
+uint32_t lpfc_device_rm_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_device_unk_plogi_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+/* REG_LOGIN_ISSUE state */
+uint32_t lpfc_rcv_plogi_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				       void *, uint32_t);
+uint32_t lpfc_rcv_prli_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				      void *, uint32_t);
+uint32_t lpfc_rcv_logo_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				      void *, uint32_t);
+uint32_t lpfc_rcv_padisc_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+					void *, uint32_t);
+uint32_t lpfc_rcv_prlo_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				      void *, uint32_t);
+uint32_t lpfc_cmpl_plogi_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+					void *, uint32_t);
+uint32_t lpfc_cmpl_prli_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				       void *, uint32_t);
+uint32_t lpfc_cmpl_logo_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				       void *, uint32_t);
+uint32_t lpfc_cmpl_adisc_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+					void *, uint32_t);
+uint32_t lpfc_cmpl_reglogin_reglogin_issue(elxHBA_t *,
+					   LPFC_NODELIST_t *, void *, uint32_t);
+uint32_t lpfc_device_rm_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				       void *, uint32_t);
+uint32_t lpfc_device_unk_reglogin_issue(elxHBA_t *, LPFC_NODELIST_t *,
+					void *, uint32_t);
+/* PRLI_ISSUE state */
+uint32_t lpfc_rcv_plogi_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_rcv_prli_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				  void *, uint32_t);
+uint32_t lpfc_rcv_logo_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				  void *, uint32_t);
+uint32_t lpfc_rcv_padisc_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_rcv_prlo_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				  void *, uint32_t);
+uint32_t lpfc_cmpl_plogi_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_cmpl_prli_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_cmpl_logo_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_cmpl_adisc_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_cmpl_reglogin_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				       void *, uint32_t);
+uint32_t lpfc_device_rm_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_device_add_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_device_unk_prli_issue(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+/* PRLI_COMPL state */
+uint32_t lpfc_rcv_plogi_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_rcv_prli_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				  void *, uint32_t);
+uint32_t lpfc_rcv_logo_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				  void *, uint32_t);
+uint32_t lpfc_rcv_padisc_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_rcv_prlo_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				  void *, uint32_t);
+uint32_t lpfc_cmpl_logo_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_cmpl_adisc_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_cmpl_reglogin_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				       void *, uint32_t);
+uint32_t lpfc_device_rm_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_device_add_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_device_unk_prli_compl(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+/* MAPPED_NODE state */
+uint32_t lpfc_rcv_plogi_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_rcv_prli_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_rcv_logo_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_rcv_padisc_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+uint32_t lpfc_rcv_prlo_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				   void *, uint32_t);
+uint32_t lpfc_cmpl_logo_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_cmpl_adisc_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+uint32_t lpfc_cmpl_reglogin_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+					void *, uint32_t);
+uint32_t lpfc_device_rm_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				    void *, uint32_t);
+uint32_t lpfc_device_add_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+uint32_t lpfc_device_unk_mapped_node(elxHBA_t *, LPFC_NODELIST_t *,
+				     void *, uint32_t);
+int lpfc_check_sparm(elxHBA_t *, LPFC_NODELIST_t *, SERV_PARM *, uint32_t);
+int lpfc_geportname(NAME_TYPE *, NAME_TYPE *);
+uint32_t lpfc_add_bind(elxHBA_t * phba, uint8_t bind_type,
+		       void *bind_id, uint32_t scsi_id);
+uint32_t lpfc_del_bind(elxHBA_t * phba, uint8_t bind_type,
+		       void *bind_id, uint32_t scsi_id);
+
+/* For lpfc_els.c */
+int lpfc_initial_flogi(elxHBA_t *);
+int lpfc_issue_els_flogi(elxHBA_t *, LPFC_NODELIST_t *, uint8_t);
+int lpfc_issue_els_plogi(elxHBA_t *, LPFC_NODELIST_t *, uint8_t);
+int lpfc_issue_els_prli(elxHBA_t *, LPFC_NODELIST_t *, uint8_t);
+int lpfc_issue_els_adisc(elxHBA_t *, LPFC_NODELIST_t *, uint8_t);
+int lpfc_issue_els_logo(elxHBA_t *, LPFC_NODELIST_t *, uint8_t);
+int lpfc_issue_els_scr(elxHBA_t *, uint32_t, uint8_t);
+int lpfc_issue_els_farp(elxHBA_t *, uint8_t *, LPFC_FARP_ADDR_TYPE);
+int lpfc_issue_els_farpr(elxHBA_t *, uint32_t, uint8_t);
+ELX_IOCBQ_t *lpfc_prep_els_iocb(elxHBA_t *, uint8_t expectRsp,
+				uint16_t, uint8_t, LPFC_NODELIST_t *, uint32_t);
+int lpfc_els_free_iocb(elxHBA_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_els_flogi(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_els_plogi(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_els_prli(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_els_adisc(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_els_logo(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_els_cmd(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_els_acc(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_els_logo_acc(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+int lpfc_els_rsp_acc(elxHBA_t *, uint32_t, ELX_IOCBQ_t *,
+		     LPFC_NODELIST_t *, ELX_MBOXQ_t *);
+int lpfc_els_rsp_reject(elxHBA_t *, uint32_t, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_rsp_adisc_acc(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_rsp_prli_acc(elxHBA_t *, ELX_IOCBQ_t *, LPFC_NODELIST_t *);
+int lpfc_els_retry(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_els_retry_delay(elxHBA_t *, void *, void *);
+void lpfc_els_unsol_event(elxHBA_t *, ELX_SLI_RING_t *, ELX_IOCBQ_t *);
+int lpfc_els_chk_latt(elxHBA_t *, ELX_IOCBQ_t *);
+int lpfc_els_handle_rscn(elxHBA_t *);
+void lpfc_more_adisc(elxHBA_t *);
+void lpfc_more_plogi(elxHBA_t *);
+int lpfc_els_flush_rscn(elxHBA_t *);
+void lpfc_els_flush_cmd(elxHBA_t *);
+int lpfc_rscn_payload_check(elxHBA_t *, uint32_t);
+void lpfc_els_timeout_handler(elxHBA_t * phba, void *arg1, void *arg2);
+
+/* For lpfc_ipport.c */
+void lpfc_ip_unsol_event(elxHBA_t *, ELX_SLI_RING_t *, ELX_IOCBQ_t *);
+LPFC_IP_BUF_t *lpfc_get_ip_buf(elxHBA_t *);
+void lpfc_free_ip_buf(LPFC_IP_BUF_t *);
+int lpfc_ip_post_buffer(elxHBA_t *, ELX_SLI_RING_t *, int);
+int lpfc_ip_xmit(LPFC_IP_BUF_t *);
+LPFC_NODELIST_t *lpfc_ip_find_device(LPFC_IP_BUF_t *, elxHBA_t **);
+int lpfc_ip_create_xri(elxHBA_t *, LPFC_IP_BUF_t *, LPFC_NODELIST_t *);
+void lpfc_ip_xri_cmpl(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+int lpfc_ip_flush_iocb(elxHBA_t *, ELX_SLI_RING_t *, LPFC_NODELIST_t *,
+		       LPFC_IP_FLUSH_EVENT);
+void lpfc_ipfarp_timeout(elxHBA_t *, void *, void *);
+void lpfc_ip_xri_timeout(elxHBA_t *, void *, void *);
+
+/* For lpfc_ct.c */
+void lpfc_ct_unsol_event(elxHBA_t *, ELX_SLI_RING_t *, ELX_IOCBQ_t *);
+int lpfc_ns_cmd(elxHBA_t *, LPFC_NODELIST_t *, int);
+int lpfc_ct_cmd(elxHBA_t *, DMABUF_t *, DMABUF_t *,
+		LPFC_NODELIST_t *, void (*cmpl) (struct elxHBA *,
+						 ELX_IOCBQ_t *, ELX_IOCBQ_t *));
+int lpfc_free_ct_rsp(elxHBA_t *, DMABUF_t *);
+int lpfc_ns_rsp(elxHBA_t *, DMABUF_t *, uint32_t);
+int lpfc_issue_ct_rsp(elxHBA_t *, uint32_t, DMABUF_t *, DMABUFEXT_t *);
+int lpfc_gen_req(elxHBA_t *, DMABUF_t *, DMABUF_t *, DMABUF_t *,
+		 void (*cmpl) (struct elxHBA *, ELX_IOCBQ_t *, ELX_IOCBQ_t *),
+		 uint32_t, uint32_t, uint32_t, uint32_t);
+void lpfc_cmpl_ct_cmd_gid_ft(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_ct_cmd_rft_id(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_ct_cmd_rnn_id(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_cmpl_ct_cmd_rsnn_nn(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+int lpfc_fdmi_cmd(elxHBA_t *, LPFC_NODELIST_t *, int);
+void lpfc_cmpl_ct_cmd_fdmi(elxHBA_t *, ELX_IOCBQ_t *, ELX_IOCBQ_t *);
+void lpfc_fdmi_tmo(elxHBA_t *, void *, void *);
+
+/* For lpfc_init.c */
+int lpfc_config_port_prep(elxHBA_t *);
+int lpfc_config_port_post(elxHBA_t *);
+int lpfc_hba_down_prep(elxHBA_t *);
+void lpfc_handle_eratt(elxHBA_t *, uint32_t);
+void lpfc_handle_latt(elxHBA_t *);
+int lpfc_post_buffer(elxHBA_t *, ELX_SLI_RING_t *, int, int);
+void lpfc_cleanup(elxHBA_t *, uint32_t);
+int lpfc_online(elxHBA_t *);
+int lpfc_offline(elxHBA_t *);
+int lpfc_scsi_free(elxHBA_t *);
+int lpfc_parse_binding_entry(elxHBA_t *, uint8_t *, uint8_t *,
+			     int, int, int, unsigned int *, int, int *);
+
+void fcptst(elxHBA_t *, void *, void *);
+void iptst(elxHBA_t *, void *, void *);
+
+/* For lpfc_ioctl.c */
+int lpfc_diag_ioctl(elxHBA_t *, ELXCMDINPUT_t *);
+char *lpfc_decode_firmware_rev(elxHBA_t *);
+int lpfc_sleep(elxHBA_t *, fcEVTHDR_t *);
+void lpfc_wakeup(elxHBA_t *, fcEVTHDR_t *);
+int lpfc_read_flash(elxHBA_t * phba, ELXCMDINPUT_t * cip, uint8_t * data);
+int lpfc_write_flash(elxHBA_t * phba, ELXCMDINPUT_t * cip, uint8_t * data);
+uint8_t *lpfc_get_lpfchba_info(elxHBA_t *, uint8_t *);
+int lpfc_fcp_abort(elxHBA_t *, int, int, int);
+int dfc_put_event(elxHBA_t *, uint32_t, uint32_t, void *, void *);
+int dfc_hba_put_event(elxHBA_t *, uint32_t, uint32_t, uint32_t, uint32_t,
+		      uint32_t);
+void lpfc_get_hba_model_desc(elxHBA_t *, uint8_t *, uint8_t *);
+void lpfc_get_hba_SymbNodeName(elxHBA_t *, uint8_t *);
+
+int lpfc_sli_setup(elxHBA_t *);
+void lpfc_DELAYMS(elxHBA_t *, int);
+void lpfc_slim_access(elxHBA_t *);
+uint32_t lpfc_read_HA(elxHBA_t *);
+uint32_t lpfc_read_CA(elxHBA_t *);
+uint32_t lpfc_read_hbaregs_plus_offset(elxHBA_t *, uint32_t);
+uint32_t lpfc_read_HS(elxHBA_t *);
+uint32_t lpfc_read_HC(elxHBA_t *);
+void lpfc_write_HA(elxHBA_t *, uint32_t);
+void lpfc_write_CA(elxHBA_t *, uint32_t);
+void lpfc_write_hbaregs_plus_offset(elxHBA_t *, uint32_t, uint32_t);
+void lpfc_write_HS(elxHBA_t *, uint32_t);
+void lpfc_write_HC(elxHBA_t *, uint32_t);
+int lpfc_ip_prep_io(elxHBA_t *, LPFC_IP_BUF_t *);
+char *lpfc_get_OsNameVersion(int);
+int lpfc_utsname_nodename_check(void);
+int lpfc_ip_unprep_io(elxHBA_t *, LPFC_IP_BUF_t *, uint32_t free_msg);
+void lpfc_ip_timeout_handler(elxHBA_t *, void *, void *);
+void *fc_get_cfg_param(int, int);
+/* For lpfc_scsiport.c */
+void lpfc_qthrottle_up(elxHBA_t *, void *, void *);
+void lpfc_npr_timeout(elxHBA_t *, void *, void *);
+int lpfc_scsi_hba_reset(elxHBA_t *, ELX_SCSI_BUF_t *);
+void lpfc_scsi_issue_inqsn(elxHBA_t *, void *, void *);
+void lpfc_scsi_issue_inqp0(elxHBA_t *, void *, void *);
+void lpfc_scsi_timeout_handler(elxHBA_t *, void *, void *);
+
+#endif				/* _H_LPFC_CRTN */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_diag.h linux-2.6.3/drivers/scsi/lpfc/lpfc_diag.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_diag.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_diag.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,329 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_LPFC_DIAG
+#define _H_LPFC_DIAG
+
+/* the brdinfo structure */
+typedef struct BRDINFO {
+	uint32_t a_mem_hi;	/* memory identifier for adapter access */
+	uint32_t a_mem_low;	/* memory identifier for adapter access */
+	uint32_t a_flash_hi;	/* memory identifier for adapter access */
+	uint32_t a_flash_low;	/* memory identifier for adapter access */
+	uint32_t a_ctlreg_hi;	/* memory identifier for adapter access */
+	uint32_t a_ctlreg_low;	/* memory identifier for adapter access */
+	uint32_t a_intrlvl;	/* interrupt level for adapter */
+	uint32_t a_pci;		/* PCI identifier (device / vendor id) */
+	uint32_t a_busid;	/* identifier of PCI bus adapter is on */
+	uint32_t a_devid;	/* identifier of PCI device number */
+	uint8_t a_rsvd1;	/* reserved for future use */
+	uint8_t a_rsvd2;	/* reserved for future use */
+	uint8_t a_siglvl;	/* signal handler used by library */
+	uint8_t a_ddi;		/* identifier device driver instance number */
+	uint32_t a_onmask;	/* mask of ONDI primatives supported */
+	uint32_t a_offmask;	/* mask of OFFDI primatives supported */
+	uint8_t a_drvrid[16];	/* driver version */
+	uint8_t a_fwname[32];	/* firmware version */
+} brdinfo;
+
+   /*
+      Define interface for the dynamic persistent binding ioctl
+    */
+#define       ELX_WWNN_BIND 0x0
+#define       ELX_WWPN_BIND 0x1
+#define       ELX_DID_BIND  0x2
+#define       ELX_SCSI_ID   0x3
+
+typedef struct {
+	uint8_t bind_type;
+	uint8_t wwpn[8];
+	uint8_t wwnn[8];
+	uint32_t did;
+	uint32_t scsi_id;
+} bind_ctl_t;
+
+/* bits in a_onmask */
+#define ONDI_MBOX       0x1	/* allows non-destructive mailbox commands */
+#define ONDI_IOINFO     0x2	/* supports retrieval of I/O info */
+#define ONDI_LNKINFO    0x4	/* supports retrieval of link info */
+#define ONDI_NODEINFO   0x8	/* supports retrieval of node info */
+#define ONDI_TRACEINFO  0x10	/* supports retrieval of trace info */
+#define ONDI_SETTRACE   0x20	/* supports configuration of trace info */
+#define ONDI_SLI1       0x40	/* hardware supports SLI-1 interface */
+#define ONDI_SLI2       0x80	/* hardware supports SLI-2 interface */
+#define ONDI_BIG_ENDIAN 0x100	/* DDI interface is BIG Endian */
+#define ONDI_LTL_ENDIAN 0x200	/* DDI interface is LITTLE Endian */
+#define ONDI_RMEM       0x400	/* allows reading of adapter shared memory */
+#define ONDI_RFLASH     0x800	/* allows reading of adapter flash */
+#define ONDI_RPCI       0x1000	/* allows reading of adapter pci registers */
+#define ONDI_RCTLREG    0x2000	/* allows reading of adapter cntrol registers */
+#define ONDI_CFGPARAM   0x4000	/* supports get/set configuration parameters */
+#define ONDI_CT         0x8000	/* supports passthru CT interface */
+#define ONDI_HBAAPI     0x10000	/* supports HBA API interface */
+
+/* bits in a_offmask */
+#define OFFDI_MBOX      0x1	/* allows all mailbox commands */
+#define OFFDI_RMEM      0x2	/* allows reading of adapter shared memory */
+#define OFFDI_WMEM      0x4	/* allows writing of adapter shared memory */
+#define OFFDI_RFLASH    0x8	/* allows reading of adapter flash */
+#define OFFDI_WFLASH    0x10	/* allows writing of adapter flash */
+#define OFFDI_RPCI      0x20	/* allows reading of adapter pci registers */
+#define OFFDI_WPCI      0x40	/* allows writing of adapter pci registers */
+#define OFFDI_RCTLREG   0x80	/* allows reading of adapter cntrol registers */
+#define OFFDI_WCTLREG   0x100	/* allows writing of adapter cntrol registers */
+#define OFFDI_OFFLINE   0x80000000	/* if set, adapter is in offline state */
+
+/* values for flag in SetDiagEnv */
+#define DDI_SHOW        0x0
+#define DDI_ONDI        0x1
+#define DDI_OFFDI       0x2
+
+#define DDI_BRD_SHOW    0x10
+#define DDI_BRD_ONDI    0x11
+#define DDI_BRD_OFFDI   0x12
+
+#define DDI_UNUSED      0xFFFFFFFFL
+
+/* the ioinfo structure */
+typedef struct IOINFO {
+	uint32_t a_mbxCmd;	/* mailbox commands issued */
+	uint32_t a_mboxCmpl;	/* mailbox commands completed */
+	uint32_t a_mboxErr;	/* mailbox commands completed, error status */
+	uint32_t a_iocbCmd;	/* iocb command ring issued */
+	uint32_t a_iocbRsp;	/* iocb rsp ring received */
+	uint32_t a_adapterIntr;	/* adapter interrupt events */
+	uint32_t a_fcpCmd;	/* FCP commands issued */
+	uint32_t a_fcpCmpl;	/* FCP command completions received */
+	uint32_t a_fcpErr;	/* FCP command completions errors */
+	uint32_t a_seqXmit;	/* IP xmit sequences sent */
+	uint32_t a_seqRcv;	/* IP sequences received */
+	uint32_t a_bcastXmit;	/* cnt of successful xmit bcast cmds issued */
+	uint32_t a_bcastRcv;	/* cnt of receive bcast cmds received */
+	uint32_t a_elsXmit;	/* cnt of successful ELS req cmds issued */
+	uint32_t a_elsRcv;	/* cnt of ELS request commands received */
+	uint32_t a_RSCNRcv;	/* cnt of RSCN commands received */
+	uint32_t a_seqXmitErr;	/* cnt of unsuccessful xmit bcast cmds issued */
+	uint32_t a_elsXmitErr;	/* cnt of unsuccessful ELS req cmds issued  */
+	uint32_t a_elsBufPost;	/* cnt of ELS buffers posted to adapter */
+	uint32_t a_ipBufPost;	/* cnt of IP buffers posted to adapter */
+	uint32_t a_cnt1;	/* generic counter */
+	uint32_t a_cnt2;	/* generic counter */
+	uint32_t a_cnt3;	/* generic counter */
+	uint32_t a_cnt4;	/* generic counter */
+} IOinfo;
+
+/* the linkinfo structure */
+typedef struct LINKINFO {
+	uint32_t a_linkEventTag;
+	uint32_t a_linkUp;
+	uint32_t a_linkDown;
+	uint32_t a_linkMulti;
+	uint32_t a_DID;
+	uint8_t a_topology;
+	uint8_t a_linkState;
+	uint8_t a_alpa;
+	uint8_t a_alpaCnt;
+	uint8_t a_alpaMap[128];
+	uint8_t a_wwpName[8];
+	uint8_t a_wwnName[8];
+} LinkInfo;
+
+/* values for a_topology */
+#define LNK_LOOP                0x1
+#define LNK_PUBLIC_LOOP         0x2
+#define LNK_FABRIC              0x3
+#define LNK_PT2PT               0x4
+
+/* values for a_linkState */
+#define LNK_DOWN                0x1
+#define LNK_UP                  0x2
+#define LNK_FLOGI               0x3
+#define LNK_DISCOVERY           0x4
+#define LNK_REDISCOVERY         0x5
+#define LNK_READY               0x6
+
+/* the traceinfo structure */
+typedef struct TRACEINFO {
+	uint8_t a_event;
+	uint8_t a_cmd;
+	uint16_t a_status;
+	uint32_t a_information;
+} TraceInfo;
+
+/* values for flag */
+#define TRC_SHOW        0x0
+#define TRC_MBOX        0x1
+#define TRC_IOCB        0x2
+#define TRC_INTR        0x4
+#define TRC_EVENT       0x8
+
+/* values for a_event */
+#define TRC_MBOX_CMD    0x1
+#define TRC_MBOX_CMPL   0x2
+#define TRC_IOCB_CMD    0x3
+#define TRC_IOCB_RSP    0x4
+#define TRC_INTR_RCV    0x5
+#define TRC_EVENT1      0x6
+#define TRC_EVENT2      0x7
+#define TRC_EVENT_MASK  0x7
+#define TRC_RING0       0x0
+#define TRC_RING1       0x40
+#define TRC_RING2       0x80
+#define TRC_RING3       0xC0
+#define TRC_RING_MASK   0xC0
+
+/* the cfgparam structure */
+typedef struct CFGPARAM {
+	char a_string[32];
+	uint32_t a_low;
+	uint32_t a_hi;
+	uint32_t a_default;
+	uint32_t a_current;
+	uint16_t a_flag;
+	uint16_t a_changestate;
+	char a_help[80];
+} CfgParam;
+
+#define MAX_CFG_PARAM 64
+
+/* values for a_flag */
+#define CFG_EXPORT      0x1	/* Export this parameter to the end user */
+#define CFG_IGNORE      0x2	/* Ignore this parameter */
+#define CFG_DEFAULT     0x8000	/* Reestablishing Link */
+
+/* values for a_changestate */
+#define CFG_REBOOT      0x0	/* Changes effective after ystem reboot */
+#define CFG_DYNAMIC     0x1	/* Changes effective immediately */
+#define CFG_RESTART     0x2	/* Changes effective after driver restart */
+
+/* the icfgparam structure - internal use only */
+typedef struct ICFGPARAM {
+	char *a_string;
+	uint32_t a_low;
+	uint32_t a_hi;
+	uint32_t a_default;
+	uint32_t a_current;
+	uint16_t a_flag;
+	uint16_t a_changestate;
+	char *a_help;
+} iCfgParam;
+
+/* the nodeinfo structure */
+typedef struct NODEINFO {
+	uint16_t a_flag;
+	uint16_t a_state;
+	uint32_t a_did;
+	uint8_t a_wwpn[8];
+	uint8_t a_wwnn[8];
+	uint32_t a_targetid;
+} NodeInfo;
+
+#define MAX_NODES 512
+
+/* Defines for a_state */
+#define NODE_UNUSED     0
+#define NODE_LIMBO      0x1	/* entry needs to hang around for wwpn / sid */
+#define NODE_LOGOUT     0x2	/* NL_PORT is not logged in - entry is cached */
+#define NODE_PLOGI      0x3	/* PLOGI was sent to NL_PORT */
+#define NODE_LOGIN      0x4	/* NL_PORT is logged in / login REG_LOGINed */
+#define NODE_PRLI       0x5	/* PRLI was sent to NL_PORT */
+#define NODE_ALLOC      0x6	/* NL_PORT is  ready to initiate adapter I/O */
+#define NODE_SEED       0x7	/* seed scsi id bind in table */
+
+/* Defines for a_flag */
+#define NODE_RPI_XRI        0x1	/* creating xri for entry */
+#define NODE_REQ_SND        0x2	/* sent ELS request for this entry */
+#define NODE_ADDR_AUTH      0x4	/* Authenticating addr for this entry */
+#define NODE_RM_ENTRY       0x8	/* Remove this entry */
+#define NODE_FARP_SND       0x10	/* sent FARP request for this entry */
+#define NODE_FABRIC         0x20	/* this entry represents the Fabric */
+#define NODE_FCP_TARGET     0x40	/* this entry is an FCP target */
+#define NODE_IP_NODE        0x80	/* this entry is an IP node */
+#define NODE_DISC_START     0x100	/* start discovery on this entry */
+#define NODE_SEED_WWPN      0x200	/* Entry scsi id is seeded for WWPN */
+#define NODE_SEED_WWNN      0x400	/* Entry scsi id is seeded for WWNN */
+#define NODE_SEED_DID       0x800	/* Entry scsi id is seeded for DID */
+#define NODE_SEED_MASK      0xe00	/* mask for seeded flags */
+#define NODE_AUTOMAP        0x1000	/* This entry was automap'ed */
+#define NODE_NS_REMOVED     0x2000	/* This entry removed from NameServer */
+
+/* Defines for RegisterForEvent mask */
+#define FC_REG_LINK_EVENT       0x1	/* Register for link up / down events */
+#define FC_REG_RSCN_EVENT       0x2	/* Register for RSCN events */
+#define FC_REG_CT_EVENT         0x4	/* Register for CT request events */
+
+#define FC_REG_EVENT_MASK       0x2f	/* event mask */
+#define FC_REG_ALL_PORTS        0x80	/* Register for all ports */
+
+#define MAX_FC_EVENTS 8		/* max events user process can wait for per HBA */
+#define FC_FSTYPE_ALL 0xffff	/* match on all fsTypes */
+
+/* Defines for error codes */
+#define FC_ERROR_BUFFER_OVERFLOW          0xff
+#define FC_ERROR_RESPONSE_TIMEOUT         0xfe
+#define FC_ERROR_LINK_UNAVAILABLE         0xfd
+#define FC_ERROR_INSUFFICIENT_RESOURCES   0xfc
+#define FC_ERROR_EXISTING_REGISTRATION    0xfb
+#define FC_ERROR_INVALID_TAG              0xfa
+#define FC_ERROR_INVALID_WWN              0xf9
+#define FC_ERROR_CREATEVENT_FAILED        0xf8
+
+/* User Library level Event structure */
+typedef struct reg_evt {
+	uint32_t e_mask;
+	uint32_t e_gstype;
+	uint32_t e_pid;
+	uint32_t e_firstchild;
+	uint32_t e_outsz;
+	uint32_t e_pad;
+	void (*e_func) (uint32_t, ...);
+	void *e_ctx;
+	void *e_out;
+} RegEvent;
+
+/* Defines for portid for CT interface */
+#define CT_FabricCntlServer ((uint32_t)0xfffffd)
+#define CT_NameServer       ((uint32_t)0xfffffc)
+#define CT_TimeServer       ((uint32_t)0xfffffb)
+#define CT_MgmtServer       ((uint32_t)0xfffffa)
+
+struct dfc_info {
+	brdinfo fc_ba;
+	char *fc_iomap_io;	/* starting address for registers */
+	char *fc_iomap_mem;	/* starting address for SLIM */
+	uint8_t *fc_hmap;	/* handle for mapping memory */
+	uint32_t fc_refcnt;
+	uint32_t fc_flag;
+};
+
+struct dfc {
+	uint32_t dfc_init;
+	uint32_t dfc_pad;
+	struct dfc_info dfc_info[MAX_ELX_BRDS];
+};
+
+/* Define for fc_flag */
+#define DFC_STOP_IOCTL   1	/* Stop processing dfc ioctls */
+#define DFC_MBOX_ACTIVE  2	/* mailbox is active thru dfc */
+
+/* Define for dfc 'riocb' function */
+#define FC_RING(ringoff,sa)     ((volatile uint8_t *)((volatile uint8_t *)sa + (unsigned long)(ringoff)))
+
+#endif				/* _H_LPFC_DIAG */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_disc.h linux-2.6.3/drivers/scsi/lpfc/lpfc_disc.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_disc.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_disc.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,222 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef  _H_LPFC_DISC
+#define  _H_LPFC_DISC
+
+#include "elx_clock.h"
+#include "elx_disc.h"
+#include "elx_scsi.h"
+#include "lpfc_hw.h"
+
+#define FC_MAX_HOLD_RSCN     32	/* max number of deferred RSCNs */
+#define FC_MAX_NS_RSP        65536	/* max size NameServer rsp */
+
+#define FC_MAXLOOP           126	/* max devices supported on a single fc loop */
+
+#define LPFC_DISC_FLOGI_TMO  15	/* Discovery FLOGI ratov */
+
+/* Provide an enumeration for the Types of addresses a FARP can resolve. */
+typedef enum lpfc_farp_addr_type {
+	LPFC_FARP_BY_IEEE,
+	LPFC_FARP_BY_WWPN,
+	LPFC_FARP_BY_WWNN,
+} LPFC_FARP_ADDR_TYPE;
+
+/* This is the protocol dependent definition for a Node List Entry.
+ * This is used by Fibre Channel protocol to support FCP and IP.
+ */
+
+struct lpfc_bindlist {
+	struct lpfc_bindlist *nlp_listp_next;
+	struct lpfc_bindlist *nlp_listp_prev;
+	ELXSCSITARGET_t *nlp_Target;	/* Pointer to the target structure */
+	NAME_TYPE nlp_portname;	/* port name */
+	NAME_TYPE nlp_nodename;	/* node name */
+	uint16_t nlp_bind_type;
+	uint16_t nlp_pan;	/* pseudo adapter number */
+	uint16_t nlp_sid;	/* scsi id */
+	uint32_t nlp_DID;	/* fibre channel D_ID of entry */
+};
+typedef struct lpfc_bindlist LPFC_BINDLIST_t;
+
+struct lpfc_nodelist {
+	ELX_NODELIST_t nle;	/* This MUST be first. Common information */
+	uint16_t nlp_state;	/* state transition indicator */
+	uint16_t nlp_xri;	/* output exchange id for RPI */
+	uint32_t nlp_flag;	/* entry  flags */
+	uint32_t nlp_DID;	/* fibre channel D_ID of entry */
+	uint32_t nlp_oldDID;	/* old fibre channel D_ID */
+	NAME_TYPE nlp_portname;	/* port name */
+	NAME_TYPE nlp_nodename;	/* node name */
+	uint16_t nlp_pan;	/* pseudo adapter number */
+	uint16_t nlp_sid;	/* scsi id */
+	uint8_t nlp_retry;	/* used for ELS retries */
+	ELXCLOCK_t *nlp_tmofunc;	/* Used for delayed ELS cmds, nodev tmo */
+	ELXSCSITARGET_t *nlp_Target;	/* Pointer to the target structure */
+	ELXCLOCK_t *nlp_xri_tmofunc;	/* Timer function for XRI create timeout. */
+	 ELX_TQS_LINK(lpfc_ip_buf) nlp_listp_ipbuf;	/* Linked list of IP Buffers waiting for an XRI Create to Finish */
+	LPFC_BINDLIST_t *nlp_listp_bind;	/* Linked list of bounded remote ports */
+	struct lpfc_nodelist *nlp_rpi_hash_next;
+};
+
+typedef struct lpfc_nodelist LPFC_NODELIST_t;
+
+/* Defines for nlp_flag (uint32) */
+#define NLP_MAPPED_LIST    0x1	/* Node is now mapped */
+#define NLP_UNMAPPED_LIST  0x2	/* Node is now unmapped */
+#define NLP_PLOGI_LIST     0x4	/* Flg to indicate send PLOGI */
+#define NLP_ADISC_LIST     0x8	/* Flg to indicate send PLOGI */
+#define NLP_LIST_MASK      0xf	/* mask to see what list node is on */
+#define NLP_BIND_ASSOC     0x10	/* Node is now bound */
+#define NLP_PLOGI_SND      0x20	/* sent PLOGI request for this entry */
+#define NLP_PRLI_SND       0x40	/* sent PRLI request for this entry */
+#define NLP_ADISC_SND      0x80	/* sent ADISC request for this entry */
+#define NLP_LOGO_SND       0x100	/* sent LOGO request for this entry */
+#define NLP_FARP_SND       0x200	/* sent FARP request for this entry */
+#define NLP_RNID_SND       0x400	/* sent RNID request for this entry */
+#define NLP_ELS_SND_MASK   0x7e0	/* sent ELS request for this entry */
+#define NLP_AUTOMAP        0x800	/* Entry was automap'ed */
+#define NLP_SEED_WWPN      0x1000	/* Entry scsi id is seeded for WWPN */
+#define NLP_SEED_WWNN      0x2000	/* Entry scsi id is seeded for WWNN */
+#define NLP_SEED_DID       0x4000	/* Entry scsi id is seeded for DID */
+#define NLP_SEED_MASK      0x807000	/* mask for seeded flags */
+#define NLP_NS_NODE        0x8000	/* Authenticated entry by NameServer */
+#define NLP_NODEV_TMO      0x10000	/* nodev timeout is running for node */
+#define NLP_DELAY_TMO      0x20000	/* delay timeout is running for node */
+#define NLP_DISC_NODE      0x40000	/* node is included in num_disc_nodes */
+#define NLP_RCV_PLOGI      0x80000	/* Rcv'ed PLOGI from remote system */
+#define NLP_LOGO_ACC       0x100000	/* Process LOGO after ACC completes */
+#define NLP_TGT_NO_SCSIID  0x200000	/* good PRLI but no binding for scsid */
+#define NLP_CREATE_XRI_INP 0x400000	/* in process of creating an XRI */
+#define NLP_SEED_ALPA      0x800000	/* SCSI id is derived from alpa array */
+#define NLP_ACC_REGLOGIN   0x1000000	/* Issue Reg Login after successful ACC */
+
+/* Defines for list searchs */
+#define NLP_SEARCH_MAPPED    0x1	/* search mapped */
+#define NLP_SEARCH_UNMAPPED  0x2	/* search unmapped */
+#define NLP_SEARCH_PLOGI     0x4	/* search plogi */
+#define NLP_SEARCH_ADISC     0x8	/* search adisc */
+#define NLP_SEARCH_ALL       0xf	/* search all lists */
+#define NLP_SEARCH_DEQUE     0x10	/* deque node if found */
+
+/* There are 4 different double linked lists nodelist entries can reside on.
+ * The Port Login (PLOGI) list and Address Discovery (ADISC) list are used 
+ * when Link Up discovery or Registered State Change Notification (RSCN) 
+ * processing is needed.  Each list holds the nodes that require a PLOGI or 
+ * ADISC Extended Link Service (ELS) request.  These lists keep track of the
+ * nodes affected by an RSCN, or a Link Up (Typically, all nodes are effected 
+ * by Link Up) event.  The unmapped_list contains all nodes that have 
+ * successfully logged into at the Fibre Channel level.  The
+ * mapped_list will contain all nodes that are mapped FCP targets.
+ *
+ * The bind list is a list of undiscovered (potentially non-existent) nodes
+ * that we have saved binding information on. This information is used when
+ * nodes transition from the unmapped to the mapped list.
+ */
+
+/* Defines for nlp_state */
+#define NLP_STE_UNUSED_NODE       0x0	/* node is just allocated */
+#define NLP_STE_PLOGI_ISSUE       0x1	/* PLOGI was sent to NL_PORT */
+#define NLP_STE_REG_LOGIN_ISSUE   0x2	/* REG_LOGIN was issued for NL_PORT */
+#define NLP_STE_PRLI_ISSUE        0x3	/* PRLI was sent to NL_PORT */
+#define NLP_STE_PRLI_COMPL        0x4	/* PRLI completed from NL_PORT */
+#define NLP_STE_MAPPED_NODE       0x5	/* Identified as a FCP Target */
+#define NLP_STE_MAX_STATE         0x6
+#define NLP_STE_FREED_NODE        0xff	/* node entry was freed to MEM_NLP */
+
+/* For UNUSED_NODE state, the node has just been allocated from the MEM_NLP
+ * driver memory pool. For PLOGI_ISSUE and REG_LOGIN_ISSUE, the node is on
+ * the PLOGI list. For REG_LOGIN_COMPL, the node is taken off the PLOGI list
+ * and put on the unmapped list. For ADISC processing, the node is taken off 
+ * the ADISC list and placed on either the mapped or unmapped list (depending
+ * on its previous state). Once on the unmapped list, a PRLI is issued and the
+ * state changed to PRLI_ISSUE. When the PRLI completion occurs, the state is
+ * changed to PRLI_COMPL. If the completion indicates a mapped
+ * node, the node is taken off the unmapped list. The binding list is checked
+ * for a valid binding, or a binding is automatically assigned. If binding
+ * assignment is unsuccessful, the node is left on the unmapped list. If
+ * binding assignment is successful, the associated binding list entry (if
+ * any) is removed, and the node is placed on the mapped list. 
+ */
+/*
+ * For a Link Down, all nodes on the ADISC, PLOGI, unmapped or mapped
+ * lists will receive a DEVICE_UNK event. If the linkdown or nodev timers
+ * expire, all effected nodes will receive a DEVICE_RM event.
+ */
+/*
+ * For a Link Up or RSCN, all nodes will move from the mapped / unmapped 
+ * lists to either the ADISC or PLOGI list.  After a Nameserver
+ * query or ALPA loopmap check, additional nodes may be added (DEVICE_ADD)
+ * or removed (DEVICE_RM) to / from the PLOGI or ADISC lists. Once the PLOGI
+ * and ADISC lists are populated, we will first process the ADISC list.
+ * 32 entries are processed initially and ADISC is initited for each one.
+ * Completions / Events for each node are funnelled thru the state machine.
+ * As each node finishes ADISC processing, it starts ADISC for any nodes
+ * waiting for ADISC processing. If no nodes are waiting, and the ADISC
+ * list count is identically 0, then we are done. For Link Up discovery, since all nodes
+ * on the PLOGI list are UNREG_LOGIN'ed, we can issue a CLEAR_LA and reenable
+ * Link Events. Next we will process the PLOGI list.
+ * 32 entries are processed initially and PLOGI is initited for each one.
+ * Completions / Events for each node are funnelled thru the state machine.
+ * As each node finishes PLOGI processing, it starts PLOGI for any nodes
+ * waiting for PLOGI processing. If no nodes are waiting, and the PLOGI
+ * list count is identically 0, then we are done. We have now completed discovery /
+ * RSCN handling. Upon completion, ALL nodes should be on either the mapped
+ * or unmapped lists.
+ */
+
+/* Defines for Node List Entry Events that could happen */
+#define NLP_EVT_RCV_PLOGI         0x0	/* Rcv'd an ELS PLOGI command */
+#define NLP_EVT_RCV_PRLI          0x1	/* Rcv'd an ELS PRLI  command */
+#define NLP_EVT_RCV_LOGO          0x2	/* Rcv'd an ELS LOGO  command */
+#define NLP_EVT_RCV_ADISC         0x3	/* Rcv'd an ELS ADISC command */
+#define NLP_EVT_RCV_PDISC         0x4	/* Rcv'd an ELS PDISC command */
+#define NLP_EVT_RCV_PRLO          0x5	/* Rcv'd an ELS PRLO  command */
+#define NLP_EVT_CMPL_PLOGI        0x6	/* Sent an ELS PLOGI command */
+#define NLP_EVT_CMPL_PRLI         0x7	/* Sent an ELS PRLI  command */
+#define NLP_EVT_CMPL_LOGO         0x8	/* Sent an ELS LOGO  command */
+#define NLP_EVT_CMPL_ADISC        0x9	/* Sent an ELS ADISC command */
+#define NLP_EVT_CMPL_REG_LOGIN    0xa	/* REG_LOGIN mbox cmd completed */
+#define NLP_EVT_DEVICE_RM         0xb	/* Device not found in NS / ALPAmap */
+#define NLP_EVT_DEVICE_ADD        0xc	/* Device found in NS / ALPAmap */
+#define NLP_EVT_DEVICE_UNK        0xd	/* Device existence unknown */
+#define NLP_EVT_MAX_EVENT         0xe
+
+#define LPFC_SYNTAX_OK                      0
+#define LPFC_SYNTAX_OK_BUT_NOT_THIS_BRD     1
+#define LPFC_SYNTAX_ERR_ASC_CONVERT         2
+#define LPFC_SYNTAX_ERR_EXP_COLON           3
+#define LPFC_SYNTAX_ERR_EXP_LPFC            4
+#define LPFC_SYNTAX_ERR_INV_LPFC_NUM        5
+#define LPFC_SYNTAX_ERR_EXP_T               6
+#define LPFC_SYNTAX_ERR_INV_TARGET_NUM      7
+#define LPFC_SYNTAX_ERR_EXP_D               8
+#define LPFC_SYNTAX_ERR_INV_DEVICE_NUM      9
+#define LPFC_SYNTAX_ERR_INV_TRAFFIC_RATIO  10
+#define LPFC_SYNTAX_ERR_INV_ROUTE_FLAGS    11
+#define LPFC_SYNTAX_ERR_TOO_MANY_PATHS     12
+#define LPFC_SYNTAX_ERR_EXP_NULL_TERM      13
+
+/* Definitions for Binding Entry Type for lpfc_parse_binding_entry()  */
+#define LPFC_BIND_WW_NN_PN   0
+#define LPFC_BIND_DID        1
+
+#endif				/* _H_LPFC_DISC */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_hba.h linux-2.6.3/drivers/scsi/lpfc/lpfc_hba.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_hba.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_hba.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,340 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_LPFC_HBA
+#define _H_LPFC_HBA
+
+#include "elx_clock.h"
+#include "elx_util.h"
+#include "elx_sli.h"
+#include "elx_scsi.h"
+#include "lpfc_disc.h"
+
+/* Check if WWN is 0 */
+#define isWWNzero(wwn) ((wwn.nameType == 0) && (wwn.IEEE[0] == 0) && (wwn.IEEE[1] == 0) && (wwn.IEEE[2] == 0) && (wwn.IEEE[3] == 0) && (wwn.IEEE[4] == 0) && (wwn.IEEE[5] == 0))
+
+#define FC_MAX_HOLD_RSCN      32
+#define FC_MAX_MCAST          16
+
+#define MAX_HBAEVT 32
+
+/* This should correspond with the HBA API event structure */
+typedef struct hbaevt {
+	uint32_t fc_eventcode;
+	uint32_t fc_evdata1;
+	uint32_t fc_evdata2;
+	uint32_t fc_evdata3;
+	uint32_t fc_evdata4;
+} HBAEVT_t;
+
+/*
+ * lpfc stat counters
+ */
+struct lpfc_stats {
+	/* Statistics for ELS commands */
+	uint32_t elsLogiCol;
+	uint32_t elsRetryExceeded;
+	uint32_t elsXmitRetry;
+	uint32_t elsDelayRetry;
+	uint32_t elsRcvDrop;
+	uint32_t elsRcvFrame;
+	uint32_t elsRcvRSCN;
+	uint32_t elsRcvRNID;
+	uint32_t elsRcvFARP;
+	uint32_t elsRcvFARPR;
+	uint32_t elsRcvFLOGI;
+	uint32_t elsRcvPLOGI;
+	uint32_t elsRcvADISC;
+	uint32_t elsRcvPDISC;
+	uint32_t elsRcvFAN;
+	uint32_t elsRcvLOGO;
+	uint32_t elsRcvPRLO;
+	uint32_t elsRcvPRLI;
+	uint32_t elsRcvRRQ;
+	uint32_t elsXmitFLOGI;
+	uint32_t elsXmitPLOGI;
+	uint32_t elsXmitPRLI;
+	uint32_t elsXmitADISC;
+	uint32_t elsXmitLOGO;
+	uint32_t elsXmitSCR;
+	uint32_t elsXmitRNID;
+	uint32_t elsXmitFARP;
+	uint32_t elsXmitFARPR;
+	uint32_t elsXmitACC;
+	uint32_t elsXmitLSRJT;
+
+	uint32_t frameRcvBcast;
+	uint32_t frameRcvMulti;
+	uint32_t strayXmitCmpl;
+	uint32_t frameXmitDelay;
+	uint32_t xriCmdCmpl;
+	uint32_t xriStatErr;
+	uint32_t LinkUp;
+	uint32_t LinkDown;
+	uint32_t LinkMultiEvent;
+	uint32_t NoRcvBuf;
+	uint32_t fcpCmd;
+	uint32_t fcpCmpl;
+	uint32_t fcpRspErr;
+	uint32_t fcpRemoteStop;
+	uint32_t fcpPortRjt;
+	uint32_t fcpPortBusy;
+	uint32_t fcpError;
+	uint32_t fcpLocalErr;
+};
+typedef struct lpfc_stats LPFC_STAT_t;
+
+/*
+ * IP stat counters
+ */
+struct lpip_stats {
+	uint32_t lpfn_ipackets_lsw;	/* # packets received */
+	uint32_t lpfn_ipackets_msw;
+	uint32_t lpfn_ierrors;	/* # total input errors */
+	uint32_t lpfn_opackets_lsw;	/* # packets sent */
+	uint32_t lpfn_opackets_msw;
+	uint32_t lpfn_oerrors;	/* # total output errors */
+	uint32_t lpfn_rx_dropped;	/* # dropped receive packets. */
+	uint32_t lpfn_tx_dropped;	/* # dropped txmit packets.   */
+	uint32_t lpfn_rcvbytes_lsw;	/* # bytes received */
+	uint32_t lpfn_rcvbytes_msw;
+	uint32_t lpfn_xmtbytes_lsw;	/* # bytes transmitted */
+	uint32_t lpfn_xmtbytes_msw;
+	uint32_t lpfn_multircv_lsw;	/* # multicast packets received */
+	uint32_t lpfn_multircv_msw;
+	uint32_t lpfn_multixmt_lsw;	/* # multicast packets for xmit */
+	uint32_t lpfn_multixmt_msw;
+	uint32_t lpfn_brdcstrcv_lsw;	/* # broadcast packets received */
+	uint32_t lpfn_brdcstrcv_msw;
+	uint32_t lpfn_brdcstxmt_lsw;	/* # broadcast packets for xmit */
+	uint32_t lpfn_brdcstxmt_msw;
+	uint32_t lpfn_Ucstxmt_lsw;	/* # Unicast packets for xmit */
+	uint32_t lpfn_Ucstxmt_msw;
+	uint32_t lpfn_xmitintr_lsw;	/* number of transmit interrupts(lsw) */
+	uint32_t lpfn_xmitintr_msw;	/* number of transmit interrupts(msw) */
+	uint32_t lpfn_recvintr_lsw;	/* number of receive interrupts(lsw) */
+	uint32_t lpfn_recvintr_msw;	/* number of receive interrupts(msw) */
+	uint32_t lpfn_NoRcvBuf;
+	uint32_t lpfn_xmitque_cur;
+};
+
+typedef struct lpip_stats LPIP_STAT_t;
+
+/*++
+ * lpfc_node_farp_list: 
+ *   This data structure defines the attributes associated with
+ *   an outstanding FARP REQ to a remote node.
+ *
+ *   rnode_addr - The address of the remote node.  Either the IEEE, WWPN, or WWNN.
+ *                Used in the FARP request.
+ *   fc_ipfarp_tmo - The timer associated with the FARP request.  This
+ *                   timer limits the amount of time spent waiting for
+ *                   the FARP to complete.
+ *   fc_ipbuf_list_farp_wait - A list of IP buffers waiting for the FARP
+ *                             request to complete.
+ *
+ --*/
+struct lpfc_node_farp_pend {
+	struct lpfc_node_farp_pend *pnext;
+	NAME_TYPE rnode_addr;
+	ELXCLOCK_t *fc_ipfarp_tmo;
+	 ELX_TQS_LINK(lpfc_ip_buf) fc_ipbuf_list_farp_wait;
+};
+
+typedef struct lpfc_node_farp_pend LPFC_NODE_FARP_PEND_t;
+
+typedef struct lpfcHba {
+	uint8_t fc_linkspeed;	/* Link speed after last READ_LA */
+	uint8_t fc_max_data_rate;	/* max_data_rate                 */
+
+	uint8_t fc_process_LA;	/* flag to process Link Attention */
+	uint32_t fc_eventTag;	/* event tag for link attention */
+	uint32_t fc_prli_sent;	/* cntr for outstanding PRLIs */
+
+	LPIP_STAT_t *ip_stat;
+	uint8_t phys_addr[8];	/* actual network address in use */
+
+	uint32_t disc_state;	/*in addition to hba_state */
+	uint32_t num_disc_nodes;	/*in addition to hba_state */
+
+	uint8_t fcp_mapping;	/* Map FCP devices based on WWNN WWPN or DID */
+#define FCP_SEED_WWNN   0x1
+#define FCP_SEED_WWPN   0x2
+#define FCP_SEED_DID    0x4
+#define FCP_SEED_MASK   0x7
+#define FCP_SEED_AUTO   0x8	/* binding was created by auto mapping */
+
+	uint32_t power_up;
+	ELXCLOCK_t *fc_estabtmo;	/* link establishment timer */
+	ELXCLOCK_t *fc_disctmo;	/* Discovery rescue timer */
+	ELXCLOCK_t *fc_linkdown;	/* link down timer */
+	ELXCLOCK_t *fc_fdmitmo;	/* fdmi timer */
+
+	void *lpfn_dev;
+	int lpfn_max_mtu;
+	int lpfn_rcv_buf_size;
+	void (*lpfn_ip_rcv) (struct elxHBA *, void *, uint32_t);
+
+	void *fc_evt_head;	/* waiting for event queue */
+	void *fc_evt_tail;	/* waiting for event queue */
+
+	struct buf *timeout_head;	/* bufs to iodone after RLIP done */
+
+	uint16_t timeout_count;
+	uint16_t init_eventTag;	/* initial READ_LA eventtag from cfg */
+	uint16_t hba_event_put;	/* hbaevent event put word anchor */
+	uint16_t hba_event_get;	/* hbaevent event get word anchor */
+	uint32_t hba_event_missed;	/* hbaevent missed event word anchor */
+	uint8_t pan_cnt;	/* pseudo adapter number counter */
+	uint16_t sid_cnt;	/* SCSI ID counter */
+
+	HBAEVT_t hbaevt[MAX_HBAEVT];
+
+#define FC_CPQ_LUNMAP   0x1	/* SCSI passthru interface LUN 0 mapping */
+
+	/* These fields used to be binfo */
+	NAME_TYPE fc_nodename;	/* fc nodename */
+	NAME_TYPE fc_portname;	/* fc portname */
+	uint32_t fc_pref_DID;	/* preferred D_ID */
+	uint8_t fc_pref_ALPA;	/* preferred AL_PA */
+	uint8_t fc_deferip;	/* defer IP processing */
+	uint8_t ipAddr[16];	/* For RNID support */
+	uint16_t ipVersion;	/* For RNID support */
+	uint16_t UDPport;	/* For RNID support */
+	uint32_t fc_edtov;	/* E_D_TOV timer value */
+	uint32_t fc_arbtov;	/* ARB_TOV timer value */
+	uint32_t fc_ratov;	/* R_A_TOV timer value */
+	uint32_t fc_rttov;	/* R_T_TOV timer value */
+	uint32_t fc_altov;	/* AL_TOV timer value */
+	uint32_t fc_crtov;	/* C_R_TOV timer value */
+	uint32_t fc_citov;	/* C_I_TOV timer value */
+	uint32_t fc_myDID;	/* fibre channel S_ID */
+	uint32_t fc_prevDID;	/* previous fibre channel S_ID */
+
+	/* The next three structures get DMA'ed directly into,
+	 * so they must be in the first page of the adapter structure!
+	 */
+	volatile SERV_PARM fc_sparam;	/* buffer for our service parameters */
+	volatile SERV_PARM fc_fabparam;	/* fabric service parameters buffer */
+	volatile uint8_t alpa_map[128];	/* AL_PA map from READ_LA */
+
+	uint8_t fc_ns_retry;	/* retries for fabric nameserver */
+	uint32_t fc_nlp_cnt;	/* outstanding NODELIST requests */
+	uint32_t fc_rscn_id_cnt;	/* count of RSCNs payloads in list */
+	DMABUF_t *fc_rscn_id_list[FC_MAX_HOLD_RSCN];
+	ELX_SLINK_t fc_plogi;	/* ELS PLOGI cmd queue */
+	ELX_SLINK_t fc_rscn;	/* RSCN cmd queue */
+	ELX_SLINK_t fc_defer_rscn;	/* deferred RSCN cmd queue */
+
+	uint32_t fc_flag;	/* FC flags */
+#define FC_FCP_WWNN             0x0	/* Match FCP targets on WWNN */
+#define FC_FCP_WWPN             0x1	/* Match FCP targets on WWPN */
+#define FC_FCP_DID              0x2	/* Match FCP targets on DID */
+#define FC_FCP_MATCH            0x3	/* Mask for match FCP targets */
+#define FC_PENDING_RING0        0x4	/* Defer ring 0 IOCB processing */
+#define FC_LNK_DOWN             0x8	/* Link is down */
+#define FC_PT2PT                0x10	/* pt2pt with no fabric */
+#define FC_PT2PT_PLOGI          0x20	/* pt2pt initiate PLOGI */
+#define FC_DELAY_DISC           0x40	/* Delay discovery till after cfglnk */
+#define FC_PUBLIC_LOOP          0x80	/* Public loop */
+#define FC_INTR_THREAD          0x100	/* In interrupt code */
+#define FC_LBIT                 0x200	/* LOGIN bit in loopinit set */
+#define FC_RSCN_MODE            0x400	/* RSCN cmd rcv'ed */
+#define FC_RSCN_DISC_TMR        0x800	/* wait edtov before processing RSCN */
+#define FC_NLP_MORE             0x1000	/* More node to process in node tbl */
+#define FC_OFFLINE_MODE         0x2000	/* Interface is offline for diag */
+#define FC_LD_TIMER             0x4000	/* Linkdown timer has been started */
+#define FC_LD_TIMEOUT           0x8000	/* Linkdown timeout has occurred */
+#define FC_FABRIC               0x10000	/* We are fabric attached */
+#define FC_DELAY_PLOGI          0x20000	/* Delay login till unreglogin */
+#define FC_SLI2                 0x40000	/* SLI-2 CONFIG_PORT cmd completed */
+#define FC_INTR_WORK            0x80000	/* Was there work last intr */
+#define FC_NO_ROOM_IP           0x100000	/* No room on IP xmit queue */
+#define FC_NO_RCV_BUF           0x200000	/* No Rcv Buffers posted IP ring */
+#define FC_BUS_RESET            0x400000	/* SCSI BUS RESET */
+#define FC_ESTABLISH_LINK       0x800000	/* Reestablish Link */
+#define FC_SCSI_RLIP            0x1000000	/* SCSI rlip routine called */
+#define FC_DELAY_NSLOGI         0x2000000	/* Delay NameServer till ureglogin */
+#define FC_NSLOGI_TMR           0x4000000	/* NameServer in process of logout */
+#define FC_DELAY_RSCN           0x8000000	/* Delay RSCN till ureg/reg login */
+#define FC_RSCN_DISCOVERY       0x10000000	/* Authenticate all devices after RSCN */
+#define FC_2G_CAPABLE           0x20000000	/* HBA is 2 Gig capable */
+#define FC_POLL_MODE        0x40000000	/* [SYNC] I/O is in the polling mode */
+#define FC_BYPASSED_MODE        0x80000000	/* Interface is offline for diag */
+
+/* CHECK */
+	uint32_t fc_open_count;	/* count of devices opened */
+#define FC_LAN_OPEN 0x1		/* LAN open completed */
+#define FC_FCP_OPEN 0x2		/* FCP open completed */
+
+	uint32_t fc_cnt;	/* generic counter for board */
+	uint32_t fc_msgidx;	/* current index to adapter msg buf */
+	volatile uint32_t fc_BCregaddr;	/* virtual offset for BIU config reg */
+	uint16_t fc_rpi_used;
+
+	uint32_t fc_topology;	/* link topology, from LINK INIT */
+	uint32_t fc_fabrictmo;	/* timeout for fabric timer */
+	LPFC_NODELIST_t fc_nlp_bcast;	/* used for IP bcast's */
+
+	ELXCLOCK_t *fc_fabric_wdt;	/* timer for fabric    */
+	ELXCLOCK_t *fc_rscn_disc_wdt;	/* timer for RSCN discovery */
+	LPFC_STAT_t fc_stat;
+
+	uint32_t fc_ipfarp_timeout;	/* timeout in seconds for farp req completion. */
+	uint32_t fc_ipxri_timeout;	/* timeout in seconds for ip XRI create completions. */
+	 ELX_TQS_LINK(lpfc_node_farp_pend) fc_node_farp_list;
+
+	LPFC_BINDLIST_t *fc_nlpbind_start;	/* ptr to bind list */
+	LPFC_BINDLIST_t *fc_nlpbind_end;	/* ptr to bind list */
+	LPFC_NODELIST_t *fc_plogi_start;	/* ptr to plogi list */
+	LPFC_NODELIST_t *fc_plogi_end;	/* ptr to plogi list */
+	LPFC_NODELIST_t *fc_adisc_start;	/* ptr to adisc list */
+	LPFC_NODELIST_t *fc_adisc_end;	/* ptr to adisc list */
+	LPFC_NODELIST_t *fc_nlpunmap_start;	/* ptr to unmap list */
+	LPFC_NODELIST_t *fc_nlpunmap_end;	/* ptr to unmap list */
+	LPFC_NODELIST_t *fc_nlpmap_start;	/* ptr to map list */
+	LPFC_NODELIST_t *fc_nlpmap_end;	/* ptr to map list */
+	uint16_t fc_bind_cnt;
+	uint16_t fc_plogi_cnt;
+	uint16_t fc_adisc_cnt;
+	uint16_t fc_unmap_cnt;
+	uint16_t fc_map_cnt;
+	LPFC_NODELIST_t fc_fcpnodev;	/* nodelist entry for no device */
+	uint32_t nlptimer;	/* timestamp for nlplist entry */
+	uint16_t fc_capabilities;	/* default value for NODELIST caps */
+	uint16_t fc_sync;	/* default value for NODELIST sync */
+
+	ELX_IOCBQ_t *fc_delayxmit;	/* List of IOCBs for delayed xmit */
+
+	ELXSCSITARGET_t *device_queue_hash[MAX_FCP_TARGET];
+#define LPFC_RPI_HASH_SIZE     64
+#define LPFC_RPI_HASH_FUNC(x)  ((x) & (0x3f))
+	LPFC_NODELIST_t *fc_nlplookup[LPFC_RPI_HASH_SIZE];	/* ptr to active 
+								   D_ID / RPIs */
+	uint32_t wwnn[2];
+	uint32_t RandomData[7];
+	uint32_t hbainitEx[5];
+} LPFCHBA_t;
+
+typedef struct lpfcTarget {
+	ELXCLOCK_t *nodevTmr;	/* Timer for nodev-tmo */
+} LPFCTARGET_t;
+
+#endif				/* _H_LPFC_HBA */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_hw.h linux-2.6.3/drivers/scsi/lpfc/lpfc_hw.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_hw.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_hw.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,978 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef  _H_LPFC_HW
+#define _H_LPFC_HW
+
+#define FDMI_DID        ((uint32_t)0xfffffa)
+#define NameServer_DID  ((uint32_t)0xfffffc)
+#define SCR_DID         ((uint32_t)0xfffffd)
+#define Fabric_DID      ((uint32_t)0xfffffe)
+#define Bcast_DID       ((uint32_t)0xffffff)
+#define Mask_DID        ((uint32_t)0xffffff)
+#define CT_DID_MASK     ((uint32_t)0xffff00)
+#define Fabric_DID_MASK ((uint32_t)0xfff000)
+#define WELL_KNOWN_DID_MASK ((uint32_t)0xfffff0)
+
+#define PT2PT_LocalID   ((uint32_t)1)
+#define PT2PT_RemoteID  ((uint32_t)2)
+
+#define FF_DEF_EDTOV          2000	/* Default E_D_TOV (2000ms) */
+#define FF_DEF_ALTOV            15	/* Default AL_TIME (15ms) */
+#define FF_DEF_RATOV             2	/* Default RA_TOV (2s) */
+#define FF_DEF_ARBTOV         1900	/* Default ARB_TOV (1900ms) */
+
+#define LPFC_BUF_RING0      128	/* Number of buffers to post to RING 0 */
+
+#define FCELSSIZE             1024	/* maximum ELS transfer size */
+
+#define LPFC_ELS_RING            0	/* use ring 0 for ELS commands */
+#define LPFC_IP_RING             1	/* use ring 1 for IP commands */
+#define LPFC_FCP_RING            2	/* use ring 2 for FCP initiator commands */
+#define LPFC_FCP_NEXT_RING       3
+
+#define SLI2_IOCB_CMD_R0_ENTRIES     16	/* SLI-2 ELS command ring entries */
+#define SLI2_IOCB_RSP_R0_ENTRIES     16	/* SLI-2 ELS response ring entries */
+#define SLI2_IOCB_CMD_R1_ENTRIES      4	/* SLI-2 IP command ring entries */
+#define SLI2_IOCB_RSP_R1_ENTRIES      4	/* SLI-2 IP response ring entries */
+#define SLI2_IOCB_CMD_R1XTRA_ENTRIES 32	/* SLI-2 extra FCP cmd ring entries */
+#define SLI2_IOCB_RSP_R1XTRA_ENTRIES 48	/* SLI-2 extra FCP rsp ring entries */
+#define SLI2_IOCB_CMD_R2_ENTRIES     32	/* SLI-2 FCP command ring entries */
+#define SLI2_IOCB_RSP_R2_ENTRIES     32	/* SLI-2 FCP response ring entries */
+#define SLI2_IOCB_CMD_R3_ENTRIES      0
+#define SLI2_IOCB_RSP_R3_ENTRIES      0
+#define SLI2_IOCB_CMD_R3XTRA_ENTRIES 24
+#define SLI2_IOCB_RSP_R3XTRA_ENTRIES 32
+
+/* Common Transport structures and definitions */
+
+union CtRevisionId {
+	/* Structure is in Big Endian format */
+	struct {
+		uint32_t Revision:8;
+		uint32_t InId:24;
+	} bits;
+	uint32_t word;
+};
+
+union CtCommandResponse {
+	/* Structure is in Big Endian format */
+	struct {
+		uint32_t CmdRsp:16;
+		uint32_t Size:16;
+	} bits;
+	uint32_t word;
+};
+
+typedef struct SliCtRequest {
+	/* Structure is in Big Endian format */
+	union CtRevisionId RevisionId;
+	uint8_t FsType;
+	uint8_t FsSubType;
+	uint8_t Options;
+	uint8_t Rsrvd1;
+	union CtCommandResponse CommandResponse;
+	uint8_t Rsrvd2;
+	uint8_t ReasonCode;
+	uint8_t Explanation;
+	uint8_t VendorUnique;
+
+	union {
+		uint32_t PortID;
+		struct gid {
+			uint8_t PortType;	/* for GID_PT requests */
+			uint8_t DomainScope;
+			uint8_t AreaScope;
+			uint8_t Fc4Type;	/* for GID_FT requests */
+		} gid;
+		struct rft {
+			uint32_t PortId;	/* For RFT_ID requests */
+#if BIG_ENDIAN_HW
+			uint32_t rsvd0:16;
+			uint32_t rsvd1:7;
+			uint32_t fcpReg:1;	/* Type 8 */
+			uint32_t rsvd2:2;
+			uint32_t ipReg:1;	/* Type 5 */
+			uint32_t rsvd3:5;
+#endif
+#if LITTLE_ENDIAN_HW
+			uint32_t rsvd0:16;
+			uint32_t fcpReg:1;	/* Type 8 */
+			uint32_t rsvd1:7;
+			uint32_t rsvd3:5;
+			uint32_t ipReg:1;	/* Type 5 */
+			uint32_t rsvd2:2;
+#endif
+			uint32_t rsvd[7];
+		} rft;
+		struct rnn {
+			uint32_t PortId;	/* For RNN_ID requests */
+			uint8_t wwnn[8];
+		} rnn;
+		struct rsnn {	/* For RSNN_ID requests */
+			uint8_t wwnn[8];
+			uint8_t len;
+			uint8_t symbname[255];
+		} rsnn;
+	} un;
+} SLI_CT_REQUEST, *PSLI_CT_REQUEST;
+
+#define  SLI_CT_REVISION        1
+#define  GID_REQUEST_SZ         (sizeof(SLI_CT_REQUEST) - 260)
+#define  RFT_REQUEST_SZ         (sizeof(SLI_CT_REQUEST) - 228)
+#define  RNN_REQUEST_SZ         (sizeof(SLI_CT_REQUEST) - 252)
+#define  RSNN_REQUEST_SZ        (sizeof(SLI_CT_REQUEST))
+
+/*
+ * FsType Definitions
+ */
+
+#define  SLI_CT_MANAGEMENT_SERVICE        0xFA
+#define  SLI_CT_TIME_SERVICE              0xFB
+#define  SLI_CT_DIRECTORY_SERVICE         0xFC
+#define  SLI_CT_FABRIC_CONTROLLER_SERVICE 0xFD
+
+/*
+ * Directory Service Subtypes
+ */
+
+#define  SLI_CT_DIRECTORY_NAME_SERVER     0x02
+
+/*
+ * Response Codes
+ */
+
+#define  SLI_CT_RESPONSE_FS_RJT           0x8001
+#define  SLI_CT_RESPONSE_FS_ACC           0x8002
+
+/*
+ * Reason Codes
+ */
+
+#define  SLI_CT_NO_ADDITIONAL_EXPL	  0x0
+#define  SLI_CT_INVALID_COMMAND           0x01
+#define  SLI_CT_INVALID_VERSION           0x02
+#define  SLI_CT_LOGICAL_ERROR             0x03
+#define  SLI_CT_INVALID_IU_SIZE           0x04
+#define  SLI_CT_LOGICAL_BUSY              0x05
+#define  SLI_CT_PROTOCOL_ERROR            0x07
+#define  SLI_CT_UNABLE_TO_PERFORM_REQ     0x09
+#define  SLI_CT_REQ_NOT_SUPPORTED         0x0b
+#define  SLI_CT_HBA_INFO_NOT_REGISTERED	  0x10
+#define  SLI_CT_MULTIPLE_HBA_ATTR_OF_SAME_TYPE  0x11
+#define  SLI_CT_INVALID_HBA_ATTR_BLOCK_LEN      0x12
+#define  SLI_CT_HBA_ATTR_NOT_PRESENT	  0x13
+#define  SLI_CT_PORT_INFO_NOT_REGISTERED  0x20
+#define  SLI_CT_MULTIPLE_PORT_ATTR_OF_SAME_TYPE 0x21
+#define  SLI_CT_INVALID_PORT_ATTR_BLOCK_LEN     0x22
+#define  SLI_CT_VENDOR_UNIQUE             0xff
+
+/*
+ * Name Server SLI_CT_UNABLE_TO_PERFORM_REQ Explanations
+ */
+
+#define  SLI_CT_NO_PORT_ID                0x01
+#define  SLI_CT_NO_PORT_NAME              0x02
+#define  SLI_CT_NO_NODE_NAME              0x03
+#define  SLI_CT_NO_CLASS_OF_SERVICE       0x04
+#define  SLI_CT_NO_IP_ADDRESS             0x05
+#define  SLI_CT_NO_IPA                    0x06
+#define  SLI_CT_NO_FC4_TYPES              0x07
+#define  SLI_CT_NO_SYMBOLIC_PORT_NAME     0x08
+#define  SLI_CT_NO_SYMBOLIC_NODE_NAME     0x09
+#define  SLI_CT_NO_PORT_TYPE              0x0A
+#define  SLI_CT_ACCESS_DENIED             0x10
+#define  SLI_CT_INVALID_PORT_ID           0x11
+#define  SLI_CT_DATABASE_EMPTY            0x12
+
+/*
+ * Name Server Command Codes
+ */
+
+#define  SLI_CTNS_GA_NXT      0x0100
+#define  SLI_CTNS_GPN_ID      0x0112
+#define  SLI_CTNS_GNN_ID      0x0113
+#define  SLI_CTNS_GCS_ID      0x0114
+#define  SLI_CTNS_GFT_ID      0x0117
+#define  SLI_CTNS_GSPN_ID     0x0118
+#define  SLI_CTNS_GPT_ID      0x011A
+#define  SLI_CTNS_GID_PN      0x0121
+#define  SLI_CTNS_GID_NN      0x0131
+#define  SLI_CTNS_GIP_NN      0x0135
+#define  SLI_CTNS_GIPA_NN     0x0136
+#define  SLI_CTNS_GSNN_NN     0x0139
+#define  SLI_CTNS_GNN_IP      0x0153
+#define  SLI_CTNS_GIPA_IP     0x0156
+#define  SLI_CTNS_GID_FT      0x0171
+#define  SLI_CTNS_GID_PT      0x01A1
+#define  SLI_CTNS_RPN_ID      0x0212
+#define  SLI_CTNS_RNN_ID      0x0213
+#define  SLI_CTNS_RCS_ID      0x0214
+#define  SLI_CTNS_RFT_ID      0x0217
+#define  SLI_CTNS_RSPN_ID     0x0218
+#define  SLI_CTNS_RPT_ID      0x021A
+#define  SLI_CTNS_RIP_NN      0x0235
+#define  SLI_CTNS_RIPA_NN     0x0236
+#define  SLI_CTNS_RSNN_NN     0x0239
+#define  SLI_CTNS_DA_ID       0x0300
+
+/*
+ * Port Types
+ */
+
+#define  SLI_CTPT_N_PORT      0x01
+#define  SLI_CTPT_NL_PORT     0x02
+#define  SLI_CTPT_FNL_PORT    0x03
+#define  SLI_CTPT_IP          0x04
+#define  SLI_CTPT_FCP         0x08
+#define  SLI_CTPT_NX_PORT     0x7F
+#define  SLI_CTPT_F_PORT      0x81
+#define  SLI_CTPT_FL_PORT     0x82
+#define  SLI_CTPT_E_PORT      0x84
+
+#define SLI_CT_LAST_ENTRY     0x80000000
+
+#define FL_ALPA    0x00		/* AL_PA of FL_Port */
+
+/* Fibre Channel Service Parameter definitions */
+
+#define FC_PH_4_0   6		/* FC-PH version 4.0 */
+#define FC_PH_4_1   7		/* FC-PH version 4.1 */
+#define FC_PH_4_2   8		/* FC-PH version 4.2 */
+#define FC_PH_4_3   9		/* FC-PH version 4.3 */
+
+#define FC_PH_LOW   8		/* Lowest supported FC-PH version */
+#define FC_PH_HIGH  9		/* Highest supported FC-PH version */
+#define FC_PH3   0x20		/* FC-PH-3 version */
+
+#define FF_FRAME_SIZE     2048
+
+typedef struct _NAME_TYPE {
+#if BIG_ENDIAN_HW
+	uint8_t nameType:4;	/* FC Word 0, bit 28:31 */
+	uint8_t IEEEextMsn:4;	/* FC Word 0, bit 24:27, bit 8:11 of IEEE ext */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t IEEEextMsn:4;	/* FC Word 0, bit 24:27, bit 8:11 of IEEE ext */
+	uint8_t nameType:4;	/* FC Word 0, bit 28:31 */
+#endif
+#define NAME_IEEE           0x1	/* IEEE name - nameType */
+#define NAME_IEEE_EXT       0x2	/* IEEE extended name */
+#define NAME_FC_TYPE        0x3	/* FC native name type */
+#define NAME_IP_TYPE        0x4	/* IP address */
+#define NAME_CCITT_TYPE     0xC
+#define NAME_CCITT_GR_TYPE  0xE
+	uint8_t IEEEextLsb;	/* FC Word 0, bit 16:23, IEEE extended Lsb */
+	uint8_t IEEE[6];	/* FC IEEE address */
+} NAME_TYPE;
+
+typedef struct _CSP {
+	uint8_t fcphHigh;	/* FC Word 0, byte 0 */
+	uint8_t fcphLow;
+	uint8_t bbCreditMsb;
+	uint8_t bbCreditlsb;	/* FC Word 0, byte 3 */
+#if BIG_ENDIAN_HW
+	uint16_t increasingOffset:1;	/* FC Word 1, bit 31 */
+	uint16_t randomOffset:1;	/* FC Word 1, bit 30 */
+	uint16_t word1Reserved2:1;	/* FC Word 1, bit 29 */
+	uint16_t fPort:1;	/* FC Word 1, bit 28 */
+	uint16_t altBbCredit:1;	/* FC Word 1, bit 27 */
+	uint16_t edtovResolution:1;	/* FC Word 1, bit 26 */
+	uint16_t multicast:1;	/* FC Word 1, bit 25 */
+	uint16_t broadcast:1;	/* FC Word 1, bit 24 */
+
+	uint16_t huntgroup:1;	/* FC Word 1, bit 23 */
+	uint16_t simplex:1;	/* FC Word 1, bit 22 */
+	uint16_t word1Reserved1:3;	/* FC Word 1, bit 21:19 */
+	uint16_t dhd:1;		/* FC Word 1, bit 18 */
+	uint16_t contIncSeqCnt:1;	/* FC Word 1, bit 17 */
+	uint16_t payloadlength:1;	/* FC Word 1, bit 16 */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t broadcast:1;	/* FC Word 1, bit 24 */
+	uint16_t multicast:1;	/* FC Word 1, bit 25 */
+	uint16_t edtovResolution:1;	/* FC Word 1, bit 26 */
+	uint16_t altBbCredit:1;	/* FC Word 1, bit 27 */
+	uint16_t fPort:1;	/* FC Word 1, bit 28 */
+	uint16_t word1Reserved2:1;	/* FC Word 1, bit 29 */
+	uint16_t randomOffset:1;	/* FC Word 1, bit 30 */
+	uint16_t increasingOffset:1;	/* FC Word 1, bit 31 */
+
+	uint16_t payloadlength:1;	/* FC Word 1, bit 16 */
+	uint16_t contIncSeqCnt:1;	/* FC Word 1, bit 17 */
+	uint16_t dhd:1;		/* FC Word 1, bit 18 */
+	uint16_t word1Reserved1:3;	/* FC Word 1, bit 21:19 */
+	uint16_t simplex:1;	/* FC Word 1, bit 22 */
+	uint16_t huntgroup:1;	/* FC Word 1, bit 23 */
+#endif
+	uint8_t bbRcvSizeMsb;	/* Upper nibble is reserved */
+
+	uint8_t bbRcvSizeLsb;	/* FC Word 1, byte 3 */
+	union {
+		struct {
+			uint8_t word2Reserved1;	/* FC Word 2 byte 0 */
+
+			uint8_t totalConcurrSeq;	/* FC Word 2 byte 1 */
+			uint8_t roByCategoryMsb;	/* FC Word 2 byte 2 */
+
+			uint8_t roByCategoryLsb;	/* FC Word 2 byte 3 */
+		} nPort;
+		uint32_t r_a_tov;	/* R_A_TOV must be in B.E. format */
+	} w2;
+
+	uint32_t e_d_tov;	/* E_D_TOV must be in B.E. format */
+} CSP;
+
+typedef struct _CLASS_PARMS {
+#if BIG_ENDIAN_HW
+	uint8_t classValid:1;	/* FC Word 0, bit 31 */
+	uint8_t intermix:1;	/* FC Word 0, bit 30 */
+	uint8_t stackedXparent:1;	/* FC Word 0, bit 29 */
+	uint8_t stackedLockDown:1;	/* FC Word 0, bit 28 */
+	uint8_t seqDelivery:1;	/* FC Word 0, bit 27 */
+	uint8_t word0Reserved1:3;	/* FC Word 0, bit 24:26 */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t word0Reserved1:3;	/* FC Word 0, bit 24:26 */
+	uint8_t seqDelivery:1;	/* FC Word 0, bit 27 */
+	uint8_t stackedLockDown:1;	/* FC Word 0, bit 28 */
+	uint8_t stackedXparent:1;	/* FC Word 0, bit 29 */
+	uint8_t intermix:1;	/* FC Word 0, bit 30 */
+	uint8_t classValid:1;	/* FC Word 0, bit 31 */
+
+#endif
+	uint8_t word0Reserved2;	/* FC Word 0, bit 16:23 */
+#if BIG_ENDIAN_HW
+	uint8_t iCtlXidReAssgn:2;	/* FC Word 0, Bit 14:15 */
+	uint8_t iCtlInitialPa:2;	/* FC Word 0, bit 12:13 */
+	uint8_t iCtlAck0capable:1;	/* FC Word 0, bit 11 */
+	uint8_t iCtlAckNcapable:1;	/* FC Word 0, bit 10 */
+	uint8_t word0Reserved3:2;	/* FC Word 0, bit  8: 9 */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t word0Reserved3:2;	/* FC Word 0, bit  8: 9 */
+	uint8_t iCtlAckNcapable:1;	/* FC Word 0, bit 10 */
+	uint8_t iCtlAck0capable:1;	/* FC Word 0, bit 11 */
+	uint8_t iCtlInitialPa:2;	/* FC Word 0, bit 12:13 */
+	uint8_t iCtlXidReAssgn:2;	/* FC Word 0, Bit 14:15 */
+#endif
+	uint8_t word0Reserved4;	/* FC Word 0, bit  0: 7 */
+#if BIG_ENDIAN_HW
+	uint8_t rCtlAck0capable:1;	/* FC Word 1, bit 31 */
+	uint8_t rCtlAckNcapable:1;	/* FC Word 1, bit 30 */
+	uint8_t rCtlXidInterlck:1;	/* FC Word 1, bit 29 */
+	uint8_t rCtlErrorPolicy:2;	/* FC Word 1, bit 27:28 */
+	uint8_t word1Reserved1:1;	/* FC Word 1, bit 26 */
+	uint8_t rCtlCatPerSeq:2;	/* FC Word 1, bit 24:25 */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t rCtlCatPerSeq:2;	/* FC Word 1, bit 24:25 */
+	uint8_t word1Reserved1:1;	/* FC Word 1, bit 26 */
+	uint8_t rCtlErrorPolicy:2;	/* FC Word 1, bit 27:28 */
+	uint8_t rCtlXidInterlck:1;	/* FC Word 1, bit 29 */
+	uint8_t rCtlAckNcapable:1;	/* FC Word 1, bit 30 */
+	uint8_t rCtlAck0capable:1;	/* FC Word 1, bit 31 */
+#endif
+	uint8_t word1Reserved2;	/* FC Word 1, bit 16:23 */
+	uint8_t rcvDataSizeMsb;	/* FC Word 1, bit  8:15 */
+	uint8_t rcvDataSizeLsb;	/* FC Word 1, bit  0: 7 */
+
+	uint8_t concurrentSeqMsb;	/* FC Word 2, bit 24:31 */
+	uint8_t concurrentSeqLsb;	/* FC Word 2, bit 16:23 */
+	uint8_t EeCreditSeqMsb;	/* FC Word 2, bit  8:15 */
+	uint8_t EeCreditSeqLsb;	/* FC Word 2, bit  0: 7 */
+
+	uint8_t openSeqPerXchgMsb;	/* FC Word 3, bit 24:31 */
+	uint8_t openSeqPerXchgLsb;	/* FC Word 3, bit 16:23 */
+	uint8_t word3Reserved1;	/* Fc Word 3, bit  8:15 */
+	uint8_t word3Reserved2;	/* Fc Word 3, bit  0: 7 */
+} CLASS_PARMS;
+
+typedef struct _SERV_PARM {	/* Structure is in Big Endian format */
+	CSP cmn;
+	NAME_TYPE portName;
+	NAME_TYPE nodeName;
+	CLASS_PARMS cls1;
+	CLASS_PARMS cls2;
+	CLASS_PARMS cls3;
+	CLASS_PARMS cls4;
+	uint8_t vendorVersion[16];
+} SERV_PARM, *PSERV_PARM;
+
+/*
+ *  Extended Link Service LS_COMMAND codes (Payload Word 0)
+ */
+#if BIG_ENDIAN_HW
+#define ELS_CMD_MASK      0xffff0000
+#define ELS_RSP_MASK      0xff000000
+#define ELS_CMD_LS_RJT    0x01000000
+#define ELS_CMD_ACC       0x02000000
+#define ELS_CMD_PLOGI     0x03000000
+#define ELS_CMD_FLOGI     0x04000000
+#define ELS_CMD_LOGO      0x05000000
+#define ELS_CMD_ABTX      0x06000000
+#define ELS_CMD_RCS       0x07000000
+#define ELS_CMD_RES       0x08000000
+#define ELS_CMD_RSS       0x09000000
+#define ELS_CMD_RSI       0x0A000000
+#define ELS_CMD_ESTS      0x0B000000
+#define ELS_CMD_ESTC      0x0C000000
+#define ELS_CMD_ADVC      0x0D000000
+#define ELS_CMD_RTV       0x0E000000
+#define ELS_CMD_RLS       0x0F000000
+#define ELS_CMD_ECHO      0x10000000
+#define ELS_CMD_TEST      0x11000000
+#define ELS_CMD_RRQ       0x12000000
+#define ELS_CMD_PRLI      0x20100014
+#define ELS_CMD_PRLO      0x21100014
+#define ELS_CMD_PDISC     0x50000000
+#define ELS_CMD_FDISC     0x51000000
+#define ELS_CMD_ADISC     0x52000000
+#define ELS_CMD_FARP      0x54000000
+#define ELS_CMD_FARPR     0x55000000
+#define ELS_CMD_FAN       0x60000000
+#define ELS_CMD_RSCN      0x61040000
+#define ELS_CMD_SCR       0x62000000
+#define ELS_CMD_RNID      0x78000000
+#endif
+#if LITTLE_ENDIAN_HW
+#define ELS_CMD_MASK      0xffff
+#define ELS_RSP_MASK      0xff
+#define ELS_CMD_LS_RJT    0x01
+#define ELS_CMD_ACC       0x02
+#define ELS_CMD_PLOGI     0x03
+#define ELS_CMD_FLOGI     0x04
+#define ELS_CMD_LOGO      0x05
+#define ELS_CMD_ABTX      0x06
+#define ELS_CMD_RCS       0x07
+#define ELS_CMD_RES       0x08
+#define ELS_CMD_RSS       0x09
+#define ELS_CMD_RSI       0x0A
+#define ELS_CMD_ESTS      0x0B
+#define ELS_CMD_ESTC      0x0C
+#define ELS_CMD_ADVC      0x0D
+#define ELS_CMD_RTV       0x0E
+#define ELS_CMD_RLS       0x0F
+#define ELS_CMD_ECHO      0x10
+#define ELS_CMD_TEST      0x11
+#define ELS_CMD_RRQ       0x12
+#define ELS_CMD_PRLI      0x14001020
+#define ELS_CMD_PRLO      0x14001021
+#define ELS_CMD_PDISC     0x50
+#define ELS_CMD_FDISC     0x51
+#define ELS_CMD_ADISC     0x52
+#define ELS_CMD_FARP      0x54
+#define ELS_CMD_FARPR     0x55
+#define ELS_CMD_FAN       0x60
+#define ELS_CMD_RSCN      0x0461
+#define ELS_CMD_SCR       0x62
+#define ELS_CMD_RNID      0x78
+#endif
+
+/*
+ *  LS_RJT Payload Definition
+ */
+
+typedef struct _LS_RJT {	/* Structure is in Big Endian format */
+	union {
+		uint32_t lsRjtError;
+		struct {
+			uint8_t lsRjtRsvd0;	/* FC Word 0, bit 24:31 */
+
+			uint8_t lsRjtRsnCode;	/* FC Word 0, bit 16:23 */
+			/* LS_RJT reason codes */
+#define LSRJT_INVALID_CMD     0x01
+#define LSRJT_LOGICAL_ERR     0x03
+#define LSRJT_LOGICAL_BSY     0x05
+#define LSRJT_PROTOCOL_ERR    0x07
+#define LSRJT_UNABLE_TPC      0x09	/* Unable to perform command */
+#define LSRJT_CMD_UNSUPPORTED 0x0B
+#define LSRJT_VENDOR_UNIQUE   0xFF	/* See Byte 3 */
+
+			uint8_t lsRjtRsnCodeExp;	/* FC Word 0, bit  8:15 */
+			/* LS_RJT reason explanation */
+#define LSEXP_NOTHING_MORE      0x00
+#define LSEXP_SPARM_OPTIONS     0x01
+#define LSEXP_SPARM_ICTL        0x03
+#define LSEXP_SPARM_RCTL        0x05
+#define LSEXP_SPARM_RCV_SIZE    0x07
+#define LSEXP_SPARM_CONCUR_SEQ  0x09
+#define LSEXP_SPARM_CREDIT      0x0B
+#define LSEXP_INVALID_PNAME     0x0D
+#define LSEXP_INVALID_NNAME     0x0E
+#define LSEXP_INVALID_CSP       0x0F
+#define LSEXP_INVALID_ASSOC_HDR 0x11
+#define LSEXP_ASSOC_HDR_REQ     0x13
+#define LSEXP_INVALID_O_SID     0x15
+#define LSEXP_INVALID_OX_RX     0x17
+#define LSEXP_CMD_IN_PROGRESS   0x19
+#define LSEXP_INVALID_NPORT_ID  0x1F
+#define LSEXP_INVALID_SEQ_ID    0x21
+#define LSEXP_INVALID_XCHG      0x23
+#define LSEXP_INACTIVE_XCHG     0x25
+#define LSEXP_RQ_REQUIRED       0x27
+#define LSEXP_OUT_OF_RESOURCE   0x29
+#define LSEXP_CANT_GIVE_DATA    0x2A
+#define LSEXP_REQ_UNSUPPORTED   0x2C
+			uint8_t vendorUnique;	/* FC Word 0, bit  0: 7 */
+		} b;
+	} un;
+} LS_RJT;
+
+/*
+ *  N_Port Login (FLOGO/PLOGO Request) Payload Definition
+ */
+
+typedef struct _LOGO {		/* Structure is in Big Endian format */
+	union {
+		uint32_t nPortId32;	/* Access nPortId as a word */
+		struct {
+			uint8_t word1Reserved1;	/* FC Word 1, bit 31:24 */
+			uint8_t nPortIdByte0;	/* N_port  ID bit 16:23 */
+			uint8_t nPortIdByte1;	/* N_port  ID bit  8:15 */
+			uint8_t nPortIdByte2;	/* N_port  ID bit  0: 7 */
+		} b;
+	} un;
+	NAME_TYPE portName;	/* N_port name field */
+} LOGO;
+
+/*
+ *  FCP Login (PRLI Request / ACC) Payload Definition
+ */
+
+#define PRLX_PAGE_LEN   0x10
+#define TPRLO_PAGE_LEN  0x14
+
+typedef struct _PRLI {		/* Structure is in Big Endian format */
+	uint8_t prliType;	/* FC Parm Word 0, bit 24:31 */
+
+#define PRLI_FCP_TYPE 0x08
+	uint8_t word0Reserved1;	/* FC Parm Word 0, bit 16:23 */
+
+#if BIG_ENDIAN_HW
+	uint8_t origProcAssocV:1;	/* FC Parm Word 0, bit 15 */
+	uint8_t respProcAssocV:1;	/* FC Parm Word 0, bit 14 */
+	uint8_t estabImagePair:1;	/* FC Parm Word 0, bit 13 */
+
+	/*    ACC = imagePairEstablished */
+	uint8_t word0Reserved2:1;	/* FC Parm Word 0, bit 12 */
+	uint8_t acceptRspCode:4;	/* FC Parm Word 0, bit 8:11, ACC ONLY */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t acceptRspCode:4;	/* FC Parm Word 0, bit 8:11, ACC ONLY */
+	uint8_t word0Reserved2:1;	/* FC Parm Word 0, bit 12 */
+	uint8_t estabImagePair:1;	/* FC Parm Word 0, bit 13 */
+	uint8_t respProcAssocV:1;	/* FC Parm Word 0, bit 14 */
+	uint8_t origProcAssocV:1;	/* FC Parm Word 0, bit 15 */
+	/*    ACC = imagePairEstablished */
+#endif
+#define PRLI_REQ_EXECUTED     0x1	/* acceptRspCode */
+#define PRLI_NO_RESOURCES     0x2
+#define PRLI_INIT_INCOMPLETE  0x3
+#define PRLI_NO_SUCH_PA       0x4
+#define PRLI_PREDEF_CONFIG    0x5
+#define PRLI_PARTIAL_SUCCESS  0x6
+#define PRLI_INVALID_PAGE_CNT 0x7
+	uint8_t word0Reserved3;	/* FC Parm Word 0, bit 0:7 */
+
+	uint32_t origProcAssoc;	/* FC Parm Word 1, bit 0:31 */
+
+	uint32_t respProcAssoc;	/* FC Parm Word 2, bit 0:31 */
+
+	uint8_t word3Reserved1;	/* FC Parm Word 3, bit 24:31 */
+	uint8_t word3Reserved2;	/* FC Parm Word 3, bit 16:23 */
+#if BIG_ENDIAN_HW
+	uint16_t Word3bit15Resved:1;	/* FC Parm Word 3, bit 15 */
+	uint16_t Word3bit14Resved:1;	/* FC Parm Word 3, bit 14 */
+	uint16_t Word3bit13Resved:1;	/* FC Parm Word 3, bit 13 */
+	uint16_t Word3bit12Resved:1;	/* FC Parm Word 3, bit 12 */
+	uint16_t Word3bit11Resved:1;	/* FC Parm Word 3, bit 11 */
+	uint16_t Word3bit10Resved:1;	/* FC Parm Word 3, bit 10 */
+	uint16_t TaskRetryIdReq:1;	/* FC Parm Word 3, bit  9 */
+	uint16_t Retry:1;	/* FC Parm Word 3, bit  8 */
+	uint16_t ConfmComplAllowed:1;	/* FC Parm Word 3, bit  7 */
+	uint16_t dataOverLay:1;	/* FC Parm Word 3, bit  6 */
+	uint16_t initiatorFunc:1;	/* FC Parm Word 3, bit  5 */
+	uint16_t targetFunc:1;	/* FC Parm Word 3, bit  4 */
+	uint16_t cmdDataMixEna:1;	/* FC Parm Word 3, bit  3 */
+	uint16_t dataRspMixEna:1;	/* FC Parm Word 3, bit  2 */
+	uint16_t readXferRdyDis:1;	/* FC Parm Word 3, bit  1 */
+	uint16_t writeXferRdyDis:1;	/* FC Parm Word 3, bit  0 */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint16_t Retry:1;	/* FC Parm Word 3, bit  8 */
+	uint16_t TaskRetryIdReq:1;	/* FC Parm Word 3, bit  9 */
+	uint16_t Word3bit10Resved:1;	/* FC Parm Word 3, bit 10 */
+	uint16_t Word3bit11Resved:1;	/* FC Parm Word 3, bit 11 */
+	uint16_t Word3bit12Resved:1;	/* FC Parm Word 3, bit 12 */
+	uint16_t Word3bit13Resved:1;	/* FC Parm Word 3, bit 13 */
+	uint16_t Word3bit14Resved:1;	/* FC Parm Word 3, bit 14 */
+	uint16_t Word3bit15Resved:1;	/* FC Parm Word 3, bit 15 */
+	uint16_t writeXferRdyDis:1;	/* FC Parm Word 3, bit  0 */
+	uint16_t readXferRdyDis:1;	/* FC Parm Word 3, bit  1 */
+	uint16_t dataRspMixEna:1;	/* FC Parm Word 3, bit  2 */
+	uint16_t cmdDataMixEna:1;	/* FC Parm Word 3, bit  3 */
+	uint16_t targetFunc:1;	/* FC Parm Word 3, bit  4 */
+	uint16_t initiatorFunc:1;	/* FC Parm Word 3, bit  5 */
+	uint16_t dataOverLay:1;	/* FC Parm Word 3, bit  6 */
+	uint16_t ConfmComplAllowed:1;	/* FC Parm Word 3, bit  7 */
+#endif
+} PRLI;
+
+/*
+ *  FCP Logout (PRLO Request / ACC) Payload Definition
+ */
+
+typedef struct _PRLO {		/* Structure is in Big Endian format */
+	uint8_t prloType;	/* FC Parm Word 0, bit 24:31 */
+
+#define PRLO_FCP_TYPE  0x08
+	uint8_t word0Reserved1;	/* FC Parm Word 0, bit 16:23 */
+
+#if BIG_ENDIAN_HW
+	uint8_t origProcAssocV:1;	/* FC Parm Word 0, bit 15 */
+	uint8_t respProcAssocV:1;	/* FC Parm Word 0, bit 14 */
+	uint8_t word0Reserved2:2;	/* FC Parm Word 0, bit 12:13 */
+	uint8_t acceptRspCode:4;	/* FC Parm Word 0, bit 8:11, ACC ONLY */
+#endif
+#if LITTLE_ENDIAN_HW
+	uint8_t acceptRspCode:4;	/* FC Parm Word 0, bit 8:11, ACC ONLY */
+	uint8_t word0Reserved2:2;	/* FC Parm Word 0, bit 12:13 */
+	uint8_t respProcAssocV:1;	/* FC Parm Word 0, bit 14 */
+	uint8_t origProcAssocV:1;	/* FC Parm Word 0, bit 15 */
+#endif
+#define PRLO_REQ_EXECUTED     0x1	/* acceptRspCode */
+#define PRLO_NO_SUCH_IMAGE    0x4
+#define PRLO_INVALID_PAGE_CNT 0x7
+
+	uint8_t word0Reserved3;	/* FC Parm Word 0, bit 0:7 */
+
+	uint32_t origProcAssoc;	/* FC Parm Word 1, bit 0:31 */
+
+	uint32_t respProcAssoc;	/* FC Parm Word 2, bit 0:31 */
+
+	uint32_t word3Reserved1;	/* FC Parm Word 3, bit 0:31 */
+} PRLO;
+
+typedef struct _ADISC {		/* Structure is in Big Endian format */
+	uint32_t hardAL_PA;
+	NAME_TYPE portName;
+	NAME_TYPE nodeName;
+	uint32_t DID;
+} ADISC;
+
+typedef struct _FARP {		/* Structure is in Big Endian format */
+	uint32_t Mflags:8;
+	uint32_t Odid:24;
+#define FARP_NO_ACTION          0	/* FARP information enclosed, no action */
+#define FARP_MATCH_PORT         0x1	/* Match on Responder Port Name */
+#define FARP_MATCH_NODE         0x2	/* Match on Responder Node Name */
+#define FARP_MATCH_IP           0x4	/* Match on IP address, not supported */
+#define FARP_MATCH_IPV4         0x5	/* Match on IPV4 address, not supported */
+#define FARP_MATCH_IPV6         0x6	/* Match on IPV6 address, not supported */
+	uint32_t Rflags:8;
+	uint32_t Rdid:24;
+#define FARP_REQUEST_PLOGI      0x1	/* Request for PLOGI */
+#define FARP_REQUEST_FARPR      0x2	/* Request for FARP Response */
+	NAME_TYPE OportName;
+	NAME_TYPE OnodeName;
+	NAME_TYPE RportName;
+	NAME_TYPE RnodeName;
+	uint8_t Oipaddr[16];
+	uint8_t Ripaddr[16];
+} FARP;
+
+typedef struct _FAN {		/* Structure is in Big Endian format */
+	uint32_t Fdid;
+	NAME_TYPE FportName;
+	NAME_TYPE FnodeName;
+} FAN;
+
+typedef struct _SCR {		/* Structure is in Big Endian format */
+	uint8_t resvd1;
+	uint8_t resvd2;
+	uint8_t resvd3;
+	uint8_t Function;
+#define  SCR_FUNC_FABRIC     0x01
+#define  SCR_FUNC_NPORT      0x02
+#define  SCR_FUNC_FULL       0x03
+#define  SCR_CLEAR           0xff
+} SCR;
+
+typedef struct _RNID_TOP_DISC {
+	NAME_TYPE portName;
+	uint8_t resvd[8];
+	uint32_t unitType;
+#define RNID_HBA            0x7
+#define RNID_HOST           0xa
+#define RNID_DRIVER         0xd
+	uint32_t physPort;
+	uint32_t attachedNodes;
+	uint16_t ipVersion;
+#define RNID_IPV4           0x1
+#define RNID_IPV6           0x2
+	uint16_t UDPport;
+	uint8_t ipAddr[16];
+	uint16_t resvd1;
+	uint16_t flags;
+#define RNID_TD_SUPPORT     0x1
+#define RNID_LP_VALID       0x2
+} RNID_TOP_DISC;
+
+typedef struct _RNID {		/* Structure is in Big Endian format */
+	uint8_t Format;
+#define RNID_TOPOLOGY_DISC  0xdf
+	uint8_t CommonLen;
+	uint8_t resvd1;
+	uint8_t SpecificLen;
+	NAME_TYPE portName;
+	NAME_TYPE nodeName;
+	union {
+		RNID_TOP_DISC topologyDisc;	/* topology disc (0xdf) */
+	} un;
+} RNID;
+
+typedef struct _RRQ {		/* Structure is in Big Endian format */
+	uint32_t SID;
+	uint16_t Oxid;
+	uint16_t Rxid;
+	uint8_t resv[32];	/* optional association hdr */
+} RRQ;
+
+/* This is used for RSCN command */
+typedef struct _D_ID {		/* Structure is in Big Endian format */
+	union {
+		uint32_t word;
+		struct {
+#if BIG_ENDIAN_HW
+			uint8_t resv;
+			uint8_t domain;
+			uint8_t area;
+			uint8_t id;
+#endif
+#if LITTLE_ENDIAN_HW
+			uint8_t id;
+			uint8_t area;
+			uint8_t domain;
+			uint8_t resv;
+#endif
+		} b;
+	} un;
+} D_ID;
+
+/*
+ *  Structure to define all ELS Payload types
+ */
+
+typedef struct _ELS_PKT {	/* Structure is in Big Endian format */
+	uint8_t elsCode;	/* FC Word 0, bit 24:31 */
+	uint8_t elsByte1;
+	uint8_t elsByte2;
+	uint8_t elsByte3;
+	union {
+		LS_RJT lsRjt;	/* Payload for LS_RJT ELS response */
+		SERV_PARM logi;	/* Payload for PLOGI/FLOGI/PDISC/ACC */
+		LOGO logo;	/* Payload for PLOGO/FLOGO/ACC */
+		PRLI prli;	/* Payload for PRLI/ACC */
+		PRLO prlo;	/* Payload for PRLO/ACC */
+		ADISC adisc;	/* Payload for ADISC/ACC */
+		FARP farp;	/* Payload for FARP/ACC */
+		FAN fan;	/* Payload for FAN */
+		SCR scr;	/* Payload for SCR/ACC */
+		RRQ rrq;	/* Payload for RRQ */
+		RNID rnid;	/* Payload for RNID */
+		uint8_t pad[128 - 4];	/* Pad out to payload of 128 bytes */
+	} un;
+} ELS_PKT;
+
+/*
+ * FDMI
+ * HBA MAnagement Operations Command Codes
+ */
+#define  SLI_MGMT_GRHL     0x100	/* Get registered HBA list */
+#define  SLI_MGMT_GHAT     0x101	/* Get HBA attributes */
+#define  SLI_MGMT_GRPL     0x102	/* Get registered Port list */
+#define  SLI_MGMT_GPAT     0x110	/* Get Port attributes */
+#define  SLI_MGMT_RHBA     0x200	/* Register HBA */
+#define  SLI_MGMT_RHAT     0x201	/* Register HBA atttributes */
+#define  SLI_MGMT_RPRT     0x210	/* Register Port */
+#define  SLI_MGMT_RPA      0x211	/* Register Port attributes */
+#define  SLI_MGMT_DHBA     0x300	/* De-register HBA */
+#define  SLI_MGMT_DPRT     0x310	/* De-register Port */
+
+/*
+ * Management Service Subtypes
+ */
+#define  SLI_CT_FDMI_Subtypes     0x10
+
+/*
+ * HBA Management Service Reject Code
+ */
+#define  REJECT_CODE             0x9	/* Unable to perform command request */
+
+/*
+ * HBA Management Service Reject Reason Code
+ * Please refer to the Reason Codes above
+ */
+
+/*
+ * HBA Attribute Types
+ */
+#define  NODE_NAME               0x1
+#define  MANUFACTURER            0x2
+#define  SERIAL_NUMBER           0x3
+#define  MODEL                   0x4
+#define  MODEL_DESCRIPTION       0x5
+#define  HARDWARE_VERSION        0x6
+#define  DRIVER_VERSION          0x7
+#define  OPTION_ROM_VERSION      0x8
+#define  FIRMWARE_VERSION        0x9
+#define  OS_NAME_VERSION	 0xa
+#define  MAX_CT_PAYLOAD_LEN	 0xb
+
+/*
+ * Port Attrubute Types
+ */
+#define  SUPPORTED_FC4_TYPES     0x1
+#define  SUPPORTED_SPEED         0x2
+#define  PORT_SPEED              0x3
+#define  MAX_FRAME_SIZE          0x4
+#define  OS_DEVICE_NAME          0x5
+#define  HOST_NAME               0x6
+
+union AttributesDef {
+	/* Structure is in Big Endian format */
+	struct {
+		uint32_t AttrType:16;
+		uint32_t AttrLen:16;
+	} bits;
+	uint32_t word;
+};
+
+#define GET_OS_VERSION          1
+#define GET_HOST_NAME           2
+
+/*
+ * HBA Attribute Entry (8 - 260 bytes)
+ */
+typedef struct {
+	union AttributesDef ad;
+	union {
+		uint32_t VendorSpecific;
+		uint8_t Manufacturer[64];
+		uint8_t SerialNumber[64];
+		uint8_t Model[256];
+		uint8_t ModelDescription[256];
+		uint8_t HardwareVersion[256];
+		uint8_t DriverVersion[256];
+		uint8_t OptionROMVersion[256];
+		uint8_t FirmwareVersion[256];
+		NAME_TYPE NodeName;
+		uint8_t SupportFC4Types[32];
+		uint32_t SupportSpeed;
+		uint32_t PortSpeed;
+		uint32_t MaxFrameSize;
+		uint8_t OsDeviceName[256];
+		uint8_t OsNameVersion[256];
+		uint32_t MaxCTPayloadLen;
+		uint8_t HostName[256];
+	} un;
+} ATTRIBUTE_ENTRY, *PATTRIBUTE_ENTRY;
+
+/*
+ * HBA Attribute Block
+ */
+typedef struct {
+	uint32_t EntryCnt;	/* Number of HBA attribute entries */
+	ATTRIBUTE_ENTRY Entry;	/* Variable-length array */
+} ATTRIBUTE_BLOCK, *PATTRIBUTE_BLOCK;
+
+/*
+ * Port Entry
+ */
+typedef struct {
+	NAME_TYPE PortName;
+} PORT_ENTRY, *PPORT_ENTRY;
+
+/*
+ * HBA Identifier
+ */
+typedef struct {
+	NAME_TYPE PortName;
+} HBA_IDENTIFIER, *PHBA_IDENTIFIER;
+
+/*
+ * Registered Port List Format
+ */
+typedef struct {
+	uint32_t EntryCnt;
+	PORT_ENTRY pe;		/* Variable-length array */
+} REG_PORT_LIST, *PREG_PORT_LIST;
+
+/*
+ * Register HBA(RHBA)
+ */
+typedef struct {
+	HBA_IDENTIFIER hi;
+	REG_PORT_LIST rpl;	/* variable-length array */
+/* ATTRIBUTE_BLOCK   ab; */
+} REG_HBA, *PREG_HBA;
+
+/*
+ * Register HBA Attributes (RHAT)
+ */
+typedef struct {
+	NAME_TYPE HBA_PortName;
+	ATTRIBUTE_BLOCK ab;
+} REG_HBA_ATTRIBUTE, *PREG_HBA_ATTRIBUTE;
+
+/*
+ * Register Port Attributes (RPA)
+ */
+typedef struct {
+	NAME_TYPE PortName;
+	ATTRIBUTE_BLOCK ab;
+} REG_PORT_ATTRIBUTE, *PREG_PORT_ATTRIBUTE;
+
+/*
+ * Get Registered HBA List (GRHL) Accept Payload Format
+ */
+typedef struct {
+	uint32_t HBA__Entry_Cnt;	/* Number of Registered HBA Identifiers */
+	NAME_TYPE HBA_PortName;	/* Variable-length array */
+} GRHL_ACC_PAYLOAD, *PGRHL_ACC_PAYLOAD;
+
+/*
+ * Get Registered Port List (GRPL) Accept Payload Format
+ */
+typedef struct {
+	uint32_t RPL_Entry_Cnt;	/* Number of Registered Port Entries */
+	PORT_ENTRY Reg_Port_Entry[1];	/* Variable-length array */
+} GRPL_ACC_PAYLOAD, *PGRPL_ACC_PAYLOAD;
+
+/*
+ * Get Port Attributes (GPAT) Accept Payload Format
+ */
+
+typedef struct {
+	ATTRIBUTE_BLOCK pab;
+} GPAT_ACC_PAYLOAD, *PGPAT_ACC_PAYLOAD;
+
+#endif				/* _H_LPFC_HW */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_ioctl.h linux-2.6.3/drivers/scsi/lpfc/lpfc_ioctl.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_ioctl.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_ioctl.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,129 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_LPFC_IOCTL
+#define _H_LPFC_IOCTL
+
+#include "elx_ioctl.h"
+
+/* LPFC Ioctls() 0x40 - 0x7F */
+
+/* LPFC_FIRST_IOCTL_USED         0x40     First defines Ioctl used  */
+#define LPFC_LIP                       0x41	/* Issue a LIP */
+#define LPFC_CT            0x42	/* Send CT passthru command */
+#define LPFC_LISTN                     0x43	/* List nodes for adapter (by WWPN, WWNN and DID) */
+
+/*  HBA API specific Ioctls() */
+
+#define LPFC_HBA_ADAPTERATTRIBUTES     0x48	/* Get attributes of the adapter */
+#define LPFC_HBA_PORTATTRIBUTES           0x49	/* Get attributes of  the adapter  Port */
+#define LPFC_HBA_PORTSTATISTICS        0x4a	/* Get statistics of  the adapter  Port */
+#define LPFC_HBA_DISCPORTATTRIBUTES       0x4b	/* Get attibutes of the discovered adapter Ports */
+#define LPFC_HBA_WWPNPORTATTRIBUTES       0x4c	/* Get attributes of  the Port specified by WWPN */
+#define LPFC_HBA_INDEXPORTATTRIBUTES      0x4d	/* Get attributes of  the Port specified by index */
+#define LPFC_HBA_FCPTARGETMAPPING      0x4e	/* Get device info for each FCP target */
+#define LPFC_HBA_FCPBINDING            0x4f	/* Get binding info for each FCP target */
+#define LPFC_HBA_SETMGMTINFO           0x50	/* Sets driver values with HBA_MGMTINFO vals */
+#define LPFC_HBA_GETMGMTINFO           0x51	/* Get driver values for HBA_MGMTINFO vals */
+#define LPFC_HBA_RNID                  0x52	/* Send an RNID request */
+#define LPFC_HBA_GETEVENT              0x53	/* Get event data */
+#define LPFC_HBA_RESETSTAT          0x54	/* Resets counters for the specified board */
+#define LPFC_HBA_SEND_SCSI             0x55	/* Send SCSI requests to target */
+#define LPFC_HBA_REFRESHINFO           0x56	/* Do a refresh (read) of the values */
+#define LPFC_SEND_ELS               0x57	/* Send out an ELS command */
+#define LPFC_HBA_SEND_FCP              0x58	/* Send out a FCP command */
+#define LPFC_HBA_SET_EVENT                0x59	/* Set FCP event(s) */
+#define LPFC_HBA_GET_EVENT                0x5a	/* Get  FCP event(s) */
+#define LPFC_HBA_SEND_MGMT_CMD            0x5b	/* Send a management command */
+#define LPFC_HBA_SEND_MGMT_RSP            0x5c	/* Send a management response */
+
+#define LPFC_UNUSED           0x61	/* Report statistics on failed I/O */
+#define LPFC_RESET_QDEPTH        0x62	/* Reset adapter Q depth */
+#define LPFC_OUTFCPIO            0x63	/* Number of outstanding I/Os */
+#define LPFC_GETCFG                     0x64	/* Get configuration parameters */
+#define LPFC_SETCFG                 0x65	/* Set configuration parameters */
+#define LPFC_TRACE                     0x66
+#define LPFC_STAT                   0x67	/* Statistics for SLI/FC/IP */
+
+/*  LPFC_LAST_IOCTL_USED         0x67  Last LPFC Ioctl used  */
+
+/* Structure for OUTFCPIO command */
+
+struct out_fcp_devp {
+	uint16_t target;
+	uint16_t lun;
+	uint16_t tx_count;
+	uint16_t txcmpl_count;
+	uint16_t delay_count;
+	uint16_t sched_count;
+	uint16_t lun_qdepth;
+	uint16_t current_qdepth;
+	uint32_t qfullcnt;
+	uint32_t qcmdcnt;
+	uint32_t iodonecnt;
+	uint32_t errorcnt;
+};
+
+#define MREC_MAX 16
+#define arecord(a, b, c, d)
+
+struct rec {
+	void *arg0;
+	void *arg1;
+	void *arg2;
+	void *arg3;
+};
+
+/*
+ * This structure needs to fit in di->fc_dataout alloc'ed memory
+ * array in dfc_un for dfc.c / C_TRACE
+ */
+struct mrec {
+	ulong reccnt;
+	struct rec rectbl[MREC_MAX];
+};
+
+typedef struct fcEVT {		/* Kernel level Event structure */
+	uint32_t evt_handle;
+	uint32_t evt_mask;
+	uint32_t evt_data0;
+	uint16_t evt_sleep;
+	uint16_t evt_flags;
+	void *evt_type;
+	void *evt_next;
+	void *evt_data1;
+	void *evt_data2;
+} fcEVT_t;
+
+typedef struct fcEVTHDR {	/* Kernel level Event Header */
+	uint32_t e_handle;
+	uint32_t e_mask;
+	uint16_t e_mode;
+#define E_SLEEPING_MODE     0x0001
+	uint16_t e_refcnt;
+	uint16_t e_flag;
+#define E_GET_EVENT_ACTIVE  0x0001
+	fcEVT_t *e_head;
+	fcEVT_t *e_tail;
+	void *e_next_header;
+	void *e_type;
+} fcEVTHDR_t;
+
+#endif				/* _H_LPFC_IOCTL */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_ip.h linux-2.6.3/drivers/scsi/lpfc/lpfc_ip.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_ip.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_ip.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,122 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef  _H_LPFC_IP
+#define _H_LPFC_IP
+
+#include  "lpfc_hw.h"
+#include  "lpfc_disc.h"
+
+#define  LPFC_IP_TOV 32
+
+/* Defines Structures used to support IP profile */
+typedef struct fc_networkhdr {
+	NAME_TYPE fc_destname;	/* destination port name */
+	NAME_TYPE fc_srcname;	/* source port name */
+} LPFC_NETHDR_t;
+
+#define FC_MIN_MTU      0	/* minimum size FC message */
+#define FC_MAX_MTU      65280	/* maximum size FC message */
+#ifndef FC_MAC_ADDRLEN
+#define FC_MAC_ADDRLEN  6
+#endif
+
+typedef enum {
+	FLUSH_NODE,
+	FLUSH_RING,
+	FLUSH_XRI
+} LPFC_IP_FLUSH_EVENT;
+
+/* structure for MAC header */
+typedef struct {
+	uint8_t dest_addr[FC_MAC_ADDRLEN];	/* 48 bit unique address */
+	uint8_t src_addr[FC_MAC_ADDRLEN];	/* 48 bit unique address */
+	uint16_t llc_len;	/* length of LLC data */
+} LPFC_EMAC_t;
+
+#define HDR_LEN         14	/* MAC header size */
+
+/* structure for LLC/SNAP header */
+typedef struct {
+	uint8_t dsap;		/* DSAP                         */
+	uint8_t ssap;		/* SSAP                         */
+	uint8_t ctrl;		/* control field                */
+	uint8_t prot_id[3];	/* protocol id                  */
+	uint16_t type;		/* type field                   */
+} LPFC_SNAPHDR_t;
+
+typedef struct lpfc_hdr {
+	LPFC_EMAC_t mac;
+	LPFC_SNAPHDR_t llc;
+} LPFC_EMACHDR_t;
+
+typedef struct lpfc_iphdr {
+	LPFC_NETHDR_t fcnet;
+	LPFC_SNAPHDR_t llc;
+} LPFC_IPHDR_t;
+
+#define FC_LLC_SSAP             0xaa	/* specifies LLC SNAP header */
+#define FC_LLC_DSAP             0xaa	/* specifies LLC SNAP header */
+#define FC_LLC_CTRL             3	/* UI */
+
+/*
+ * The lpfc_ip_buf structure is used to communicate IP commands
+ * to the ip transport module.
+ */
+struct lpfc_ip_buf {
+	struct lpfc_ip_buf *ip_buf_next;
+	uint32_t timeout;	/* IN */
+	elxHBA_t *ip_hba;	/* IN */
+
+	/* Pointer to OS-specific area of lpfc_ip_buf. It could just be
+	 * the cmd OS pass to us or another structure if we have other
+	 * OS-specific info we want to maintain. 
+	 */
+	void *pOSCmd;		/* IN */
+
+	uint32_t status;	/* From IOCB Word 7- ulpStatus */
+	uint32_t result;	/* From IOCB Word 4. */
+	uint32_t totalSize;	/* total size of packet */
+
+	LPFC_NODELIST_t *ndlp;	/* ptr to NPort I/O is destined for */
+
+	/* Dma_ext has both virt, phys to dma-able buffer
+	 * which contains FCNET header and scatter gather list for
+	 * a maximum of 80 (LPFC_IP_BPL_SIZE) BDE entries,
+	 */
+	DMABUF_t *dma_ext;
+	LPFC_IPHDR_t *net_hdr;
+	ULP_BDE64 *ip_bpl;
+
+	 ELX_TQS_LINK(elx_phys_net_map) elx_phys_net_map_list;
+	ELX_PHYS_NET_MAP_t elx_phys_net_map;
+
+	/* Cur_iocbq has phys of the dma-able buffer.
+	 * Iotag is in here 
+	 */
+	ELX_IOCBQ_t cur_iocbq;
+};
+
+typedef struct lpfc_ip_buf LPFC_IP_BUF_t;
+
+#define LPFC_IP_INITIAL_BPL_SIZE  80	/* Number of ip buf BDEs in ip_bpl */
+#define LPFC_IP_RCV_BUF_SIZE      4096	/* IP rcv buffer size */
+
+#endif				/* _H_LPFC_IP */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_module_param.h linux-2.6.3/drivers/scsi/lpfc/lpfc_module_param.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/lpfc_module_param.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/lpfc_module_param.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,1178 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+MODULE_PARM(lpfc0_log_verbose, "i");
+MODULE_PARM(lpfc0_lun_queue_depth, "i");
+MODULE_PARM(lpfc0_tgt_queue_depth, "i");
+MODULE_PARM(lpfc0_no_device_delay, "i");
+MODULE_PARM(lpfc0_network_on, "i");
+MODULE_PARM(lpfc0_xmt_que_size, "i");
+MODULE_PARM(lpfc0_scan_down, "i");
+MODULE_PARM(lpfc0_linkdown_tmo, "i");
+MODULE_PARM(lpfc0_nodev_tmo, "i");
+MODULE_PARM(lpfc0_delay_rsp_err, "i");
+MODULE_PARM(lpfc0_nodev_holdio, "i");
+MODULE_PARM(lpfc0_check_cond_err, "i");
+MODULE_PARM(lpfc0_num_iocbs, "i");
+MODULE_PARM(lpfc0_num_bufs, "i");
+MODULE_PARM(lpfc0_topology, "i");
+MODULE_PARM(lpfc0_link_speed, "i");
+MODULE_PARM(lpfc0_ip_class, "i");
+MODULE_PARM(lpfc0_fcp_class, "i");
+MODULE_PARM(lpfc0_use_adisc, "i");
+MODULE_PARM(lpfc0_extra_io_tmo, "i");
+MODULE_PARM(lpfc0_post_ip_buf, "i");
+MODULE_PARM(lpfc0_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc0_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc0_ack0, "i");
+MODULE_PARM(lpfc0_automap, "i");
+MODULE_PARM(lpfc0_fcp_bind_method, "i");
+MODULE_PARM(lpfc0_cr_delay, "i");
+MODULE_PARM(lpfc0_cr_count, "i");
+MODULE_PARM(lpfc0_fdmi_on, "i");
+MODULE_PARM(lpfc0_max_lun, "i");
+MODULE_PARM(lpfc0_discovery_threads, "i");
+MODULE_PARM(lpfc0_max_target, "i");
+MODULE_PARM(lpfc0_scsi_req_tmo, "i");
+MODULE_PARM(lpfc0_lun_skip, "i");
+
+MODULE_PARM(lpfc1_log_verbose, "i");
+MODULE_PARM(lpfc1_lun_queue_depth, "i");
+MODULE_PARM(lpfc1_tgt_queue_depth, "i");
+MODULE_PARM(lpfc1_no_device_delay, "i");
+MODULE_PARM(lpfc1_network_on, "i");
+MODULE_PARM(lpfc1_xmt_que_size, "i");
+MODULE_PARM(lpfc1_scan_down, "i");
+MODULE_PARM(lpfc1_linkdown_tmo, "i");
+MODULE_PARM(lpfc1_nodev_tmo, "i");
+MODULE_PARM(lpfc1_delay_rsp_err, "i");
+MODULE_PARM(lpfc1_nodev_holdio, "i");
+MODULE_PARM(lpfc1_check_cond_err, "i");
+MODULE_PARM(lpfc1_num_iocbs, "i");
+MODULE_PARM(lpfc1_num_bufs, "i");
+MODULE_PARM(lpfc1_topology, "i");
+MODULE_PARM(lpfc1_link_speed, "i");
+MODULE_PARM(lpfc1_ip_class, "i");
+MODULE_PARM(lpfc1_fcp_class, "i");
+MODULE_PARM(lpfc1_use_adisc, "i");
+MODULE_PARM(lpfc1_extra_io_tmo, "i");
+MODULE_PARM(lpfc1_post_ip_buf, "i");
+MODULE_PARM(lpfc1_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc1_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc1_ack0, "i");
+MODULE_PARM(lpfc1_automap, "i");
+MODULE_PARM(lpfc1_fcp_bind_method, "i");
+MODULE_PARM(lpfc1_cr_delay, "i");
+MODULE_PARM(lpfc1_cr_count, "i");
+MODULE_PARM(lpfc1_fdmi_on, "i");
+MODULE_PARM(lpfc1_max_lun, "i");
+MODULE_PARM(lpfc1_discovery_threads, "i");
+MODULE_PARM(lpfc1_max_target, "i");
+MODULE_PARM(lpfc1_scsi_req_tmo, "i");
+MODULE_PARM(lpfc1_lun_skip, "i");
+
+MODULE_PARM(lpfc2_log_verbose, "i");
+MODULE_PARM(lpfc2_lun_queue_depth, "i");
+MODULE_PARM(lpfc2_tgt_queue_depth, "i");
+MODULE_PARM(lpfc2_no_device_delay, "i");
+MODULE_PARM(lpfc2_network_on, "i");
+MODULE_PARM(lpfc2_xmt_que_size, "i");
+MODULE_PARM(lpfc2_scan_down, "i");
+MODULE_PARM(lpfc2_linkdown_tmo, "i");
+MODULE_PARM(lpfc2_nodev_tmo, "i");
+MODULE_PARM(lpfc2_delay_rsp_err, "i");
+MODULE_PARM(lpfc2_nodev_holdio, "i");
+MODULE_PARM(lpfc2_check_cond_err, "i");
+MODULE_PARM(lpfc2_num_iocbs, "i");
+MODULE_PARM(lpfc2_num_bufs, "i");
+MODULE_PARM(lpfc2_topology, "i");
+MODULE_PARM(lpfc2_link_speed, "i");
+MODULE_PARM(lpfc2_ip_class, "i");
+MODULE_PARM(lpfc2_fcp_class, "i");
+MODULE_PARM(lpfc2_use_adisc, "i");
+MODULE_PARM(lpfc2_extra_io_tmo, "i");
+MODULE_PARM(lpfc2_post_ip_buf, "i");
+MODULE_PARM(lpfc2_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc2_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc2_ack0, "i");
+MODULE_PARM(lpfc2_automap, "i");
+MODULE_PARM(lpfc2_fcp_bind_method, "i");
+MODULE_PARM(lpfc2_cr_delay, "i");
+MODULE_PARM(lpfc2_cr_count, "i");
+MODULE_PARM(lpfc2_fdmi_on, "i");
+MODULE_PARM(lpfc2_max_lun, "i");
+MODULE_PARM(lpfc2_discovery_threads, "i");
+MODULE_PARM(lpfc2_max_target, "i");
+MODULE_PARM(lpfc2_scsi_req_tmo, "i");
+MODULE_PARM(lpfc2_lun_skip, "i");
+
+MODULE_PARM(lpfc3_log_verbose, "i");
+MODULE_PARM(lpfc3_lun_queue_depth, "i");
+MODULE_PARM(lpfc3_tgt_queue_depth, "i");
+MODULE_PARM(lpfc3_no_device_delay, "i");
+MODULE_PARM(lpfc3_network_on, "i");
+MODULE_PARM(lpfc3_xmt_que_size, "i");
+MODULE_PARM(lpfc3_scan_down, "i");
+MODULE_PARM(lpfc3_linkdown_tmo, "i");
+MODULE_PARM(lpfc3_nodev_tmo, "i");
+MODULE_PARM(lpfc3_delay_rsp_err, "i");
+MODULE_PARM(lpfc3_nodev_holdio, "i");
+MODULE_PARM(lpfc3_check_cond_err, "i");
+MODULE_PARM(lpfc3_num_iocbs, "i");
+MODULE_PARM(lpfc3_num_bufs, "i");
+MODULE_PARM(lpfc3_topology, "i");
+MODULE_PARM(lpfc3_link_speed, "i");
+MODULE_PARM(lpfc3_ip_class, "i");
+MODULE_PARM(lpfc3_fcp_class, "i");
+MODULE_PARM(lpfc3_use_adisc, "i");
+MODULE_PARM(lpfc3_extra_io_tmo, "i");
+MODULE_PARM(lpfc3_post_ip_buf, "i");
+MODULE_PARM(lpfc3_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc3_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc3_ack0, "i");
+MODULE_PARM(lpfc3_automap, "i");
+MODULE_PARM(lpfc3_fcp_bind_method, "i");
+MODULE_PARM(lpfc3_cr_delay, "i");
+MODULE_PARM(lpfc3_cr_count, "i");
+MODULE_PARM(lpfc3_fdmi_on, "i");
+MODULE_PARM(lpfc3_max_lun, "i");
+MODULE_PARM(lpfc3_discovery_threads, "i");
+MODULE_PARM(lpfc3_max_target, "i");
+MODULE_PARM(lpfc3_scsi_req_tmo, "i");
+MODULE_PARM(lpfc3_lun_skip, "i");
+
+MODULE_PARM(lpfc4_log_verbose, "i");
+MODULE_PARM(lpfc4_lun_queue_depth, "i");
+MODULE_PARM(lpfc4_tgt_queue_depth, "i");
+MODULE_PARM(lpfc4_no_device_delay, "i");
+MODULE_PARM(lpfc4_network_on, "i");
+MODULE_PARM(lpfc4_xmt_que_size, "i");
+MODULE_PARM(lpfc4_scan_down, "i");
+MODULE_PARM(lpfc4_linkdown_tmo, "i");
+MODULE_PARM(lpfc4_nodev_tmo, "i");
+MODULE_PARM(lpfc4_delay_rsp_err, "i");
+MODULE_PARM(lpfc4_nodev_holdio, "i");
+MODULE_PARM(lpfc4_check_cond_err, "i");
+MODULE_PARM(lpfc4_num_iocbs, "i");
+MODULE_PARM(lpfc4_num_bufs, "i");
+MODULE_PARM(lpfc4_topology, "i");
+MODULE_PARM(lpfc4_link_speed, "i");
+MODULE_PARM(lpfc4_ip_class, "i");
+MODULE_PARM(lpfc4_fcp_class, "i");
+MODULE_PARM(lpfc4_use_adisc, "i");
+MODULE_PARM(lpfc4_extra_io_tmo, "i");
+MODULE_PARM(lpfc4_post_ip_buf, "i");
+MODULE_PARM(lpfc4_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc4_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc4_ack0, "i");
+MODULE_PARM(lpfc4_automap, "i");
+MODULE_PARM(lpfc4_fcp_bind_method, "i");
+MODULE_PARM(lpfc4_cr_delay, "i");
+MODULE_PARM(lpfc4_cr_count, "i");
+MODULE_PARM(lpfc4_fdmi_on, "i");
+MODULE_PARM(lpfc4_max_lun, "i");
+MODULE_PARM(lpfc4_discovery_threads, "i");
+MODULE_PARM(lpfc4_max_target, "i");
+MODULE_PARM(lpfc4_scsi_req_tmo, "i");
+MODULE_PARM(lpfc4_lun_skip, "i");
+
+MODULE_PARM(lpfc5_log_verbose, "i");
+MODULE_PARM(lpfc5_lun_queue_depth, "i");
+MODULE_PARM(lpfc5_tgt_queue_depth, "i");
+MODULE_PARM(lpfc5_no_device_delay, "i");
+MODULE_PARM(lpfc5_network_on, "i");
+MODULE_PARM(lpfc5_xmt_que_size, "i");
+MODULE_PARM(lpfc5_scan_down, "i");
+MODULE_PARM(lpfc5_linkdown_tmo, "i");
+MODULE_PARM(lpfc5_nodev_tmo, "i");
+MODULE_PARM(lpfc5_delay_rsp_err, "i");
+MODULE_PARM(lpfc5_nodev_holdio, "i");
+MODULE_PARM(lpfc5_check_cond_err, "i");
+MODULE_PARM(lpfc5_num_iocbs, "i");
+MODULE_PARM(lpfc5_num_bufs, "i");
+MODULE_PARM(lpfc5_topology, "i");
+MODULE_PARM(lpfc5_link_speed, "i");
+MODULE_PARM(lpfc5_ip_class, "i");
+MODULE_PARM(lpfc5_fcp_class, "i");
+MODULE_PARM(lpfc5_use_adisc, "i");
+MODULE_PARM(lpfc5_extra_io_tmo, "i");
+MODULE_PARM(lpfc5_post_ip_buf, "i");
+MODULE_PARM(lpfc5_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc5_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc5_ack0, "i");
+MODULE_PARM(lpfc5_automap, "i");
+MODULE_PARM(lpfc5_fcp_bind_method, "i");
+MODULE_PARM(lpfc5_cr_delay, "i");
+MODULE_PARM(lpfc5_cr_count, "i");
+MODULE_PARM(lpfc5_fdmi_on, "i");
+MODULE_PARM(lpfc5_max_lun, "i");
+MODULE_PARM(lpfc5_discovery_threads, "i");
+MODULE_PARM(lpfc5_max_target, "i");
+MODULE_PARM(lpfc5_scsi_req_tmo, "i");
+MODULE_PARM(lpfc5_lun_skip, "i");
+
+MODULE_PARM(lpfc6_log_verbose, "i");
+MODULE_PARM(lpfc6_lun_queue_depth, "i");
+MODULE_PARM(lpfc6_tgt_queue_depth, "i");
+MODULE_PARM(lpfc6_no_device_delay, "i");
+MODULE_PARM(lpfc6_network_on, "i");
+MODULE_PARM(lpfc6_xmt_que_size, "i");
+MODULE_PARM(lpfc6_scan_down, "i");
+MODULE_PARM(lpfc6_linkdown_tmo, "i");
+MODULE_PARM(lpfc6_nodev_tmo, "i");
+MODULE_PARM(lpfc6_delay_rsp_err, "i");
+MODULE_PARM(lpfc6_nodev_holdio, "i");
+MODULE_PARM(lpfc6_check_cond_err, "i");
+MODULE_PARM(lpfc6_num_iocbs, "i");
+MODULE_PARM(lpfc6_num_bufs, "i");
+MODULE_PARM(lpfc6_topology, "i");
+MODULE_PARM(lpfc6_link_speed, "i");
+MODULE_PARM(lpfc6_ip_class, "i");
+MODULE_PARM(lpfc6_fcp_class, "i");
+MODULE_PARM(lpfc6_use_adisc, "i");
+MODULE_PARM(lpfc6_extra_io_tmo, "i");
+MODULE_PARM(lpfc6_post_ip_buf, "i");
+MODULE_PARM(lpfc6_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc6_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc6_ack0, "i");
+MODULE_PARM(lpfc6_automap, "i");
+MODULE_PARM(lpfc6_fcp_bind_method, "i");
+MODULE_PARM(lpfc6_cr_delay, "i");
+MODULE_PARM(lpfc6_cr_count, "i");
+MODULE_PARM(lpfc6_fdmi_on, "i");
+MODULE_PARM(lpfc6_max_lun, "i");
+MODULE_PARM(lpfc6_discovery_threads, "i");
+MODULE_PARM(lpfc6_max_target, "i");
+MODULE_PARM(lpfc6_scsi_req_tmo, "i");
+MODULE_PARM(lpfc6_lun_skip, "i");
+
+MODULE_PARM(lpfc7_log_verbose, "i");
+MODULE_PARM(lpfc7_lun_queue_depth, "i");
+MODULE_PARM(lpfc7_tgt_queue_depth, "i");
+MODULE_PARM(lpfc7_no_device_delay, "i");
+MODULE_PARM(lpfc7_network_on, "i");
+MODULE_PARM(lpfc7_xmt_que_size, "i");
+MODULE_PARM(lpfc7_scan_down, "i");
+MODULE_PARM(lpfc7_linkdown_tmo, "i");
+MODULE_PARM(lpfc7_nodev_tmo, "i");
+MODULE_PARM(lpfc7_delay_rsp_err, "i");
+MODULE_PARM(lpfc7_nodev_holdio, "i");
+MODULE_PARM(lpfc7_check_cond_err, "i");
+MODULE_PARM(lpfc7_num_iocbs, "i");
+MODULE_PARM(lpfc7_num_bufs, "i");
+MODULE_PARM(lpfc7_topology, "i");
+MODULE_PARM(lpfc7_link_speed, "i");
+MODULE_PARM(lpfc7_ip_class, "i");
+MODULE_PARM(lpfc7_fcp_class, "i");
+MODULE_PARM(lpfc7_use_adisc, "i");
+MODULE_PARM(lpfc7_extra_io_tmo, "i");
+MODULE_PARM(lpfc7_post_ip_buf, "i");
+MODULE_PARM(lpfc7_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc7_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc7_ack0, "i");
+MODULE_PARM(lpfc7_automap, "i");
+MODULE_PARM(lpfc7_fcp_bind_method, "i");
+MODULE_PARM(lpfc7_cr_delay, "i");
+MODULE_PARM(lpfc7_cr_count, "i");
+MODULE_PARM(lpfc7_fdmi_on, "i");
+MODULE_PARM(lpfc7_max_lun, "i");
+MODULE_PARM(lpfc7_discovery_threads, "i");
+MODULE_PARM(lpfc7_max_target, "i");
+MODULE_PARM(lpfc7_scsi_req_tmo, "i");
+MODULE_PARM(lpfc7_lun_skip, "i");
+
+MODULE_PARM(lpfc8_log_verbose, "i");
+MODULE_PARM(lpfc8_lun_queue_depth, "i");
+MODULE_PARM(lpfc8_tgt_queue_depth, "i");
+MODULE_PARM(lpfc8_no_device_delay, "i");
+MODULE_PARM(lpfc8_network_on, "i");
+MODULE_PARM(lpfc8_xmt_que_size, "i");
+MODULE_PARM(lpfc8_scan_down, "i");
+MODULE_PARM(lpfc8_linkdown_tmo, "i");
+MODULE_PARM(lpfc8_nodev_tmo, "i");
+MODULE_PARM(lpfc8_delay_rsp_err, "i");
+MODULE_PARM(lpfc8_nodev_holdio, "i");
+MODULE_PARM(lpfc8_check_cond_err, "i");
+MODULE_PARM(lpfc8_num_iocbs, "i");
+MODULE_PARM(lpfc8_num_bufs, "i");
+MODULE_PARM(lpfc8_topology, "i");
+MODULE_PARM(lpfc8_link_speed, "i");
+MODULE_PARM(lpfc8_ip_class, "i");
+MODULE_PARM(lpfc8_fcp_class, "i");
+MODULE_PARM(lpfc8_use_adisc, "i");
+MODULE_PARM(lpfc8_extra_io_tmo, "i");
+MODULE_PARM(lpfc8_post_ip_buf, "i");
+MODULE_PARM(lpfc8_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc8_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc8_ack0, "i");
+MODULE_PARM(lpfc8_automap, "i");
+MODULE_PARM(lpfc8_fcp_bind_method, "i");
+MODULE_PARM(lpfc8_cr_delay, "i");
+MODULE_PARM(lpfc8_cr_count, "i");
+MODULE_PARM(lpfc8_fdmi_on, "i");
+MODULE_PARM(lpfc8_max_lun, "i");
+MODULE_PARM(lpfc8_discovery_threads, "i");
+MODULE_PARM(lpfc8_max_target, "i");
+MODULE_PARM(lpfc8_scsi_req_tmo, "i");
+MODULE_PARM(lpfc8_lun_skip, "i");
+
+MODULE_PARM(lpfc9_log_verbose, "i");
+MODULE_PARM(lpfc9_lun_queue_depth, "i");
+MODULE_PARM(lpfc9_tgt_queue_depth, "i");
+MODULE_PARM(lpfc9_no_device_delay, "i");
+MODULE_PARM(lpfc9_network_on, "i");
+MODULE_PARM(lpfc9_xmt_que_size, "i");
+MODULE_PARM(lpfc9_scan_down, "i");
+MODULE_PARM(lpfc9_linkdown_tmo, "i");
+MODULE_PARM(lpfc9_nodev_tmo, "i");
+MODULE_PARM(lpfc9_delay_rsp_err, "i");
+MODULE_PARM(lpfc9_nodev_holdio, "i");
+MODULE_PARM(lpfc9_check_cond_err, "i");
+MODULE_PARM(lpfc9_num_iocbs, "i");
+MODULE_PARM(lpfc9_num_bufs, "i");
+MODULE_PARM(lpfc9_topology, "i");
+MODULE_PARM(lpfc9_link_speed, "i");
+MODULE_PARM(lpfc9_ip_class, "i");
+MODULE_PARM(lpfc9_fcp_class, "i");
+MODULE_PARM(lpfc9_use_adisc, "i");
+MODULE_PARM(lpfc9_extra_io_tmo, "i");
+MODULE_PARM(lpfc9_post_ip_buf, "i");
+MODULE_PARM(lpfc9_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc9_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc9_ack0, "i");
+MODULE_PARM(lpfc9_automap, "i");
+MODULE_PARM(lpfc9_fcp_bind_method, "i");
+MODULE_PARM(lpfc9_cr_delay, "i");
+MODULE_PARM(lpfc9_cr_count, "i");
+MODULE_PARM(lpfc9_fdmi_on, "i");
+MODULE_PARM(lpfc9_max_lun, "i");
+MODULE_PARM(lpfc9_discovery_threads, "i");
+MODULE_PARM(lpfc9_max_target, "i");
+MODULE_PARM(lpfc9_scsi_req_tmo, "i");
+MODULE_PARM(lpfc9_lun_skip, "i");
+
+MODULE_PARM(lpfc10_log_verbose, "i");
+MODULE_PARM(lpfc10_lun_queue_depth, "i");
+MODULE_PARM(lpfc10_tgt_queue_depth, "i");
+MODULE_PARM(lpfc10_no_device_delay, "i");
+MODULE_PARM(lpfc10_network_on, "i");
+MODULE_PARM(lpfc10_xmt_que_size, "i");
+MODULE_PARM(lpfc10_scan_down, "i");
+MODULE_PARM(lpfc10_linkdown_tmo, "i");
+MODULE_PARM(lpfc10_nodev_tmo, "i");
+MODULE_PARM(lpfc10_delay_rsp_err, "i");
+MODULE_PARM(lpfc10_nodev_holdio, "i");
+MODULE_PARM(lpfc10_check_cond_err, "i");
+MODULE_PARM(lpfc10_num_iocbs, "i");
+MODULE_PARM(lpfc10_num_bufs, "i");
+MODULE_PARM(lpfc10_topology, "i");
+MODULE_PARM(lpfc10_link_speed, "i");
+MODULE_PARM(lpfc10_ip_class, "i");
+MODULE_PARM(lpfc10_fcp_class, "i");
+MODULE_PARM(lpfc10_use_adisc, "i");
+MODULE_PARM(lpfc10_extra_io_tmo, "i");
+MODULE_PARM(lpfc10_post_ip_buf, "i");
+MODULE_PARM(lpfc10_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc10_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc10_ack0, "i");
+MODULE_PARM(lpfc10_automap, "i");
+MODULE_PARM(lpfc10_fcp_bind_method, "i");
+MODULE_PARM(lpfc10_cr_delay, "i");
+MODULE_PARM(lpfc10_cr_count, "i");
+MODULE_PARM(lpfc10_fdmi_on, "i");
+MODULE_PARM(lpfc10_max_lun, "i");
+MODULE_PARM(lpfc10_discovery_threads, "i");
+MODULE_PARM(lpfc10_max_target, "i");
+MODULE_PARM(lpfc10_scsi_req_tmo, "i");
+MODULE_PARM(lpfc10_lun_skip, "i");
+
+MODULE_PARM(lpfc11_log_verbose, "i");
+MODULE_PARM(lpfc11_lun_queue_depth, "i");
+MODULE_PARM(lpfc11_tgt_queue_depth, "i");
+MODULE_PARM(lpfc11_no_device_delay, "i");
+MODULE_PARM(lpfc11_network_on, "i");
+MODULE_PARM(lpfc11_xmt_que_size, "i");
+MODULE_PARM(lpfc11_scan_down, "i");
+MODULE_PARM(lpfc11_linkdown_tmo, "i");
+MODULE_PARM(lpfc11_nodev_tmo, "i");
+MODULE_PARM(lpfc11_delay_rsp_err, "i");
+MODULE_PARM(lpfc11_nodev_holdio, "i");
+MODULE_PARM(lpfc11_check_cond_err, "i");
+MODULE_PARM(lpfc11_num_iocbs, "i");
+MODULE_PARM(lpfc11_num_bufs, "i");
+MODULE_PARM(lpfc11_topology, "i");
+MODULE_PARM(lpfc11_link_speed, "i");
+MODULE_PARM(lpfc11_ip_class, "i");
+MODULE_PARM(lpfc11_fcp_class, "i");
+MODULE_PARM(lpfc11_use_adisc, "i");
+MODULE_PARM(lpfc11_extra_io_tmo, "i");
+MODULE_PARM(lpfc11_post_ip_buf, "i");
+MODULE_PARM(lpfc11_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc11_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc11_ack0, "i");
+MODULE_PARM(lpfc11_automap, "i");
+MODULE_PARM(lpfc11_fcp_bind_method, "i");
+MODULE_PARM(lpfc11_cr_delay, "i");
+MODULE_PARM(lpfc11_cr_count, "i");
+MODULE_PARM(lpfc11_fdmi_on, "i");
+MODULE_PARM(lpfc11_max_lun, "i");
+MODULE_PARM(lpfc11_discovery_threads, "i");
+MODULE_PARM(lpfc11_max_target, "i");
+MODULE_PARM(lpfc11_scsi_req_tmo, "i");
+MODULE_PARM(lpfc11_lun_skip, "i");
+
+MODULE_PARM(lpfc12_log_verbose, "i");
+MODULE_PARM(lpfc12_lun_queue_depth, "i");
+MODULE_PARM(lpfc12_tgt_queue_depth, "i");
+MODULE_PARM(lpfc12_no_device_delay, "i");
+MODULE_PARM(lpfc12_network_on, "i");
+MODULE_PARM(lpfc12_xmt_que_size, "i");
+MODULE_PARM(lpfc12_scan_down, "i");
+MODULE_PARM(lpfc12_linkdown_tmo, "i");
+MODULE_PARM(lpfc12_nodev_tmo, "i");
+MODULE_PARM(lpfc12_delay_rsp_err, "i");
+MODULE_PARM(lpfc12_nodev_holdio, "i");
+MODULE_PARM(lpfc12_check_cond_err, "i");
+MODULE_PARM(lpfc12_num_iocbs, "i");
+MODULE_PARM(lpfc12_num_bufs, "i");
+MODULE_PARM(lpfc12_topology, "i");
+MODULE_PARM(lpfc12_link_speed, "i");
+MODULE_PARM(lpfc12_ip_class, "i");
+MODULE_PARM(lpfc12_fcp_class, "i");
+MODULE_PARM(lpfc12_use_adisc, "i");
+MODULE_PARM(lpfc12_extra_io_tmo, "i");
+MODULE_PARM(lpfc12_post_ip_buf, "i");
+MODULE_PARM(lpfc12_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc12_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc12_ack0, "i");
+MODULE_PARM(lpfc12_automap, "i");
+MODULE_PARM(lpfc12_fcp_bind_method, "i");
+MODULE_PARM(lpfc12_cr_delay, "i");
+MODULE_PARM(lpfc12_cr_count, "i");
+MODULE_PARM(lpfc12_fdmi_on, "i");
+MODULE_PARM(lpfc12_max_lun, "i");
+MODULE_PARM(lpfc12_discovery_threads, "i");
+MODULE_PARM(lpfc12_max_target, "i");
+MODULE_PARM(lpfc12_scsi_req_tmo, "i");
+MODULE_PARM(lpfc12_lun_skip, "i");
+
+MODULE_PARM(lpfc13_log_verbose, "i");
+MODULE_PARM(lpfc13_lun_queue_depth, "i");
+MODULE_PARM(lpfc13_tgt_queue_depth, "i");
+MODULE_PARM(lpfc13_no_device_delay, "i");
+MODULE_PARM(lpfc13_network_on, "i");
+MODULE_PARM(lpfc13_xmt_que_size, "i");
+MODULE_PARM(lpfc13_scan_down, "i");
+MODULE_PARM(lpfc13_linkdown_tmo, "i");
+MODULE_PARM(lpfc13_nodev_tmo, "i");
+MODULE_PARM(lpfc13_delay_rsp_err, "i");
+MODULE_PARM(lpfc13_nodev_holdio, "i");
+MODULE_PARM(lpfc13_check_cond_err, "i");
+MODULE_PARM(lpfc13_num_iocbs, "i");
+MODULE_PARM(lpfc13_num_bufs, "i");
+MODULE_PARM(lpfc13_topology, "i");
+MODULE_PARM(lpfc13_link_speed, "i");
+MODULE_PARM(lpfc13_ip_class, "i");
+MODULE_PARM(lpfc13_fcp_class, "i");
+MODULE_PARM(lpfc13_use_adisc, "i");
+MODULE_PARM(lpfc13_extra_io_tmo, "i");
+MODULE_PARM(lpfc13_post_ip_buf, "i");
+MODULE_PARM(lpfc13_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc13_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc13_ack0, "i");
+MODULE_PARM(lpfc13_automap, "i");
+MODULE_PARM(lpfc13_fcp_bind_method, "i");
+MODULE_PARM(lpfc13_cr_delay, "i");
+MODULE_PARM(lpfc13_cr_count, "i");
+MODULE_PARM(lpfc13_fdmi_on, "i");
+MODULE_PARM(lpfc13_max_lun, "i");
+MODULE_PARM(lpfc13_discovery_threads, "i");
+MODULE_PARM(lpfc13_max_target, "i");
+MODULE_PARM(lpfc13_scsi_req_tmo, "i");
+MODULE_PARM(lpfc13_lun_skip, "i");
+
+MODULE_PARM(lpfc14_log_verbose, "i");
+MODULE_PARM(lpfc14_lun_queue_depth, "i");
+MODULE_PARM(lpfc14_tgt_queue_depth, "i");
+MODULE_PARM(lpfc14_no_device_delay, "i");
+MODULE_PARM(lpfc14_network_on, "i");
+MODULE_PARM(lpfc14_xmt_que_size, "i");
+MODULE_PARM(lpfc14_scan_down, "i");
+MODULE_PARM(lpfc14_linkdown_tmo, "i");
+MODULE_PARM(lpfc14_nodev_tmo, "i");
+MODULE_PARM(lpfc14_delay_rsp_err, "i");
+MODULE_PARM(lpfc14_nodev_holdio, "i");
+MODULE_PARM(lpfc14_check_cond_err, "i");
+MODULE_PARM(lpfc14_num_iocbs, "i");
+MODULE_PARM(lpfc14_num_bufs, "i");
+MODULE_PARM(lpfc14_topology, "i");
+MODULE_PARM(lpfc14_link_speed, "i");
+MODULE_PARM(lpfc14_ip_class, "i");
+MODULE_PARM(lpfc14_fcp_class, "i");
+MODULE_PARM(lpfc14_use_adisc, "i");
+MODULE_PARM(lpfc14_extra_io_tmo, "i");
+MODULE_PARM(lpfc14_post_ip_buf, "i");
+MODULE_PARM(lpfc14_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc14_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc14_ack0, "i");
+MODULE_PARM(lpfc14_automap, "i");
+MODULE_PARM(lpfc14_fcp_bind_method, "i");
+MODULE_PARM(lpfc14_cr_delay, "i");
+MODULE_PARM(lpfc14_cr_count, "i");
+MODULE_PARM(lpfc14_fdmi_on, "i");
+MODULE_PARM(lpfc14_max_lun, "i");
+MODULE_PARM(lpfc14_discovery_threads, "i");
+MODULE_PARM(lpfc14_max_target, "i");
+MODULE_PARM(lpfc14_scsi_req_tmo, "i");
+MODULE_PARM(lpfc14_lun_skip, "i");
+
+MODULE_PARM(lpfc15_log_verbose, "i");
+MODULE_PARM(lpfc15_lun_queue_depth, "i");
+MODULE_PARM(lpfc15_tgt_queue_depth, "i");
+MODULE_PARM(lpfc15_no_device_delay, "i");
+MODULE_PARM(lpfc15_network_on, "i");
+MODULE_PARM(lpfc15_xmt_que_size, "i");
+MODULE_PARM(lpfc15_scan_down, "i");
+MODULE_PARM(lpfc15_linkdown_tmo, "i");
+MODULE_PARM(lpfc15_nodev_tmo, "i");
+MODULE_PARM(lpfc15_delay_rsp_err, "i");
+MODULE_PARM(lpfc15_nodev_holdio, "i");
+MODULE_PARM(lpfc15_check_cond_err, "i");
+MODULE_PARM(lpfc15_num_iocbs, "i");
+MODULE_PARM(lpfc15_num_bufs, "i");
+MODULE_PARM(lpfc15_topology, "i");
+MODULE_PARM(lpfc15_link_speed, "i");
+MODULE_PARM(lpfc15_ip_class, "i");
+MODULE_PARM(lpfc15_fcp_class, "i");
+MODULE_PARM(lpfc15_use_adisc, "i");
+MODULE_PARM(lpfc15_extra_io_tmo, "i");
+MODULE_PARM(lpfc15_post_ip_buf, "i");
+MODULE_PARM(lpfc15_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc15_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc15_ack0, "i");
+MODULE_PARM(lpfc15_automap, "i");
+MODULE_PARM(lpfc15_fcp_bind_method, "i");
+MODULE_PARM(lpfc15_cr_delay, "i");
+MODULE_PARM(lpfc15_cr_count, "i");
+MODULE_PARM(lpfc15_fdmi_on, "i");
+MODULE_PARM(lpfc15_max_lun, "i");
+MODULE_PARM(lpfc15_discovery_threads, "i");
+MODULE_PARM(lpfc15_max_target, "i");
+MODULE_PARM(lpfc15_scsi_req_tmo, "i");
+MODULE_PARM(lpfc15_lun_skip, "i");
+
+MODULE_PARM(lpfc16_log_verbose, "i");
+MODULE_PARM(lpfc16_lun_queue_depth, "i");
+MODULE_PARM(lpfc16_tgt_queue_depth, "i");
+MODULE_PARM(lpfc16_no_device_delay, "i");
+MODULE_PARM(lpfc16_network_on, "i");
+MODULE_PARM(lpfc16_xmt_que_size, "i");
+MODULE_PARM(lpfc16_scan_down, "i");
+MODULE_PARM(lpfc16_linkdown_tmo, "i");
+MODULE_PARM(lpfc16_nodev_tmo, "i");
+MODULE_PARM(lpfc16_delay_rsp_err, "i");
+MODULE_PARM(lpfc16_nodev_holdio, "i");
+MODULE_PARM(lpfc16_check_cond_err, "i");
+MODULE_PARM(lpfc16_num_iocbs, "i");
+MODULE_PARM(lpfc16_num_bufs, "i");
+MODULE_PARM(lpfc16_topology, "i");
+MODULE_PARM(lpfc16_link_speed, "i");
+MODULE_PARM(lpfc16_ip_class, "i");
+MODULE_PARM(lpfc16_fcp_class, "i");
+MODULE_PARM(lpfc16_use_adisc, "i");
+MODULE_PARM(lpfc16_extra_io_tmo, "i");
+MODULE_PARM(lpfc16_post_ip_buf, "i");
+MODULE_PARM(lpfc16_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc16_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc16_ack0, "i");
+MODULE_PARM(lpfc16_automap, "i");
+MODULE_PARM(lpfc16_fcp_bind_method, "i");
+MODULE_PARM(lpfc16_cr_delay, "i");
+MODULE_PARM(lpfc16_cr_count, "i");
+MODULE_PARM(lpfc16_fdmi_on, "i");
+MODULE_PARM(lpfc16_max_lun, "i");
+MODULE_PARM(lpfc16_discovery_threads, "i");
+MODULE_PARM(lpfc16_max_target, "i");
+MODULE_PARM(lpfc16_scsi_req_tmo, "i");
+MODULE_PARM(lpfc16_lun_skip, "i");
+
+MODULE_PARM(lpfc17_log_verbose, "i");
+MODULE_PARM(lpfc17_lun_queue_depth, "i");
+MODULE_PARM(lpfc17_tgt_queue_depth, "i");
+MODULE_PARM(lpfc17_no_device_delay, "i");
+MODULE_PARM(lpfc17_network_on, "i");
+MODULE_PARM(lpfc17_xmt_que_size, "i");
+MODULE_PARM(lpfc17_scan_down, "i");
+MODULE_PARM(lpfc17_linkdown_tmo, "i");
+MODULE_PARM(lpfc17_nodev_tmo, "i");
+MODULE_PARM(lpfc17_delay_rsp_err, "i");
+MODULE_PARM(lpfc17_nodev_holdio, "i");
+MODULE_PARM(lpfc17_check_cond_err, "i");
+MODULE_PARM(lpfc17_num_iocbs, "i");
+MODULE_PARM(lpfc17_num_bufs, "i");
+MODULE_PARM(lpfc17_topology, "i");
+MODULE_PARM(lpfc17_link_speed, "i");
+MODULE_PARM(lpfc17_ip_class, "i");
+MODULE_PARM(lpfc17_fcp_class, "i");
+MODULE_PARM(lpfc17_use_adisc, "i");
+MODULE_PARM(lpfc17_extra_io_tmo, "i");
+MODULE_PARM(lpfc17_post_ip_buf, "i");
+MODULE_PARM(lpfc17_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc17_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc17_ack0, "i");
+MODULE_PARM(lpfc17_automap, "i");
+MODULE_PARM(lpfc17_fcp_bind_method, "i");
+MODULE_PARM(lpfc17_cr_delay, "i");
+MODULE_PARM(lpfc17_cr_count, "i");
+MODULE_PARM(lpfc17_fdmi_on, "i");
+MODULE_PARM(lpfc17_max_lun, "i");
+MODULE_PARM(lpfc17_discovery_threads, "i");
+MODULE_PARM(lpfc17_max_target, "i");
+MODULE_PARM(lpfc17_scsi_req_tmo, "i");
+MODULE_PARM(lpfc17_lun_skip, "i");
+
+MODULE_PARM(lpfc18_log_verbose, "i");
+MODULE_PARM(lpfc18_lun_queue_depth, "i");
+MODULE_PARM(lpfc18_tgt_queue_depth, "i");
+MODULE_PARM(lpfc18_no_device_delay, "i");
+MODULE_PARM(lpfc18_network_on, "i");
+MODULE_PARM(lpfc18_xmt_que_size, "i");
+MODULE_PARM(lpfc18_scan_down, "i");
+MODULE_PARM(lpfc18_linkdown_tmo, "i");
+MODULE_PARM(lpfc18_nodev_tmo, "i");
+MODULE_PARM(lpfc18_delay_rsp_err, "i");
+MODULE_PARM(lpfc18_nodev_holdio, "i");
+MODULE_PARM(lpfc18_check_cond_err, "i");
+MODULE_PARM(lpfc18_num_iocbs, "i");
+MODULE_PARM(lpfc18_num_bufs, "i");
+MODULE_PARM(lpfc18_topology, "i");
+MODULE_PARM(lpfc18_link_speed, "i");
+MODULE_PARM(lpfc18_ip_class, "i");
+MODULE_PARM(lpfc18_fcp_class, "i");
+MODULE_PARM(lpfc18_use_adisc, "i");
+MODULE_PARM(lpfc18_extra_io_tmo, "i");
+MODULE_PARM(lpfc18_post_ip_buf, "i");
+MODULE_PARM(lpfc18_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc18_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc18_ack0, "i");
+MODULE_PARM(lpfc18_automap, "i");
+MODULE_PARM(lpfc18_fcp_bind_method, "i");
+MODULE_PARM(lpfc18_cr_delay, "i");
+MODULE_PARM(lpfc18_cr_count, "i");
+MODULE_PARM(lpfc18_fdmi_on, "i");
+MODULE_PARM(lpfc18_max_lun, "i");
+MODULE_PARM(lpfc18_discovery_threads, "i");
+MODULE_PARM(lpfc18_max_target, "i");
+MODULE_PARM(lpfc18_scsi_req_tmo, "i");
+MODULE_PARM(lpfc18_lun_skip, "i");
+
+MODULE_PARM(lpfc19_log_verbose, "i");
+MODULE_PARM(lpfc19_lun_queue_depth, "i");
+MODULE_PARM(lpfc19_tgt_queue_depth, "i");
+MODULE_PARM(lpfc19_no_device_delay, "i");
+MODULE_PARM(lpfc19_network_on, "i");
+MODULE_PARM(lpfc19_xmt_que_size, "i");
+MODULE_PARM(lpfc19_scan_down, "i");
+MODULE_PARM(lpfc19_linkdown_tmo, "i");
+MODULE_PARM(lpfc19_nodev_tmo, "i");
+MODULE_PARM(lpfc19_delay_rsp_err, "i");
+MODULE_PARM(lpfc19_nodev_holdio, "i");
+MODULE_PARM(lpfc19_check_cond_err, "i");
+MODULE_PARM(lpfc19_num_iocbs, "i");
+MODULE_PARM(lpfc19_num_bufs, "i");
+MODULE_PARM(lpfc19_topology, "i");
+MODULE_PARM(lpfc19_link_speed, "i");
+MODULE_PARM(lpfc19_ip_class, "i");
+MODULE_PARM(lpfc19_fcp_class, "i");
+MODULE_PARM(lpfc19_use_adisc, "i");
+MODULE_PARM(lpfc19_extra_io_tmo, "i");
+MODULE_PARM(lpfc19_post_ip_buf, "i");
+MODULE_PARM(lpfc19_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc19_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc19_ack0, "i");
+MODULE_PARM(lpfc19_automap, "i");
+MODULE_PARM(lpfc19_fcp_bind_method, "i");
+MODULE_PARM(lpfc19_cr_delay, "i");
+MODULE_PARM(lpfc19_cr_count, "i");
+MODULE_PARM(lpfc19_fdmi_on, "i");
+MODULE_PARM(lpfc19_max_lun, "i");
+MODULE_PARM(lpfc19_discovery_threads, "i");
+MODULE_PARM(lpfc19_max_target, "i");
+MODULE_PARM(lpfc19_scsi_req_tmo, "i");
+MODULE_PARM(lpfc19_lun_skip, "i");
+
+MODULE_PARM(lpfc20_log_verbose, "i");
+MODULE_PARM(lpfc20_lun_queue_depth, "i");
+MODULE_PARM(lpfc20_tgt_queue_depth, "i");
+MODULE_PARM(lpfc20_no_device_delay, "i");
+MODULE_PARM(lpfc20_network_on, "i");
+MODULE_PARM(lpfc20_xmt_que_size, "i");
+MODULE_PARM(lpfc20_scan_down, "i");
+MODULE_PARM(lpfc20_linkdown_tmo, "i");
+MODULE_PARM(lpfc20_nodev_tmo, "i");
+MODULE_PARM(lpfc20_delay_rsp_err, "i");
+MODULE_PARM(lpfc20_nodev_holdio, "i");
+MODULE_PARM(lpfc20_check_cond_err, "i");
+MODULE_PARM(lpfc20_num_iocbs, "i");
+MODULE_PARM(lpfc20_num_bufs, "i");
+MODULE_PARM(lpfc20_topology, "i");
+MODULE_PARM(lpfc20_link_speed, "i");
+MODULE_PARM(lpfc20_ip_class, "i");
+MODULE_PARM(lpfc20_fcp_class, "i");
+MODULE_PARM(lpfc20_use_adisc, "i");
+MODULE_PARM(lpfc20_extra_io_tmo, "i");
+MODULE_PARM(lpfc20_post_ip_buf, "i");
+MODULE_PARM(lpfc20_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc20_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc20_ack0, "i");
+MODULE_PARM(lpfc20_automap, "i");
+MODULE_PARM(lpfc20_fcp_bind_method, "i");
+MODULE_PARM(lpfc20_cr_delay, "i");
+MODULE_PARM(lpfc20_cr_count, "i");
+MODULE_PARM(lpfc20_fdmi_on, "i");
+MODULE_PARM(lpfc20_max_lun, "i");
+MODULE_PARM(lpfc20_discovery_threads, "i");
+MODULE_PARM(lpfc20_max_target, "i");
+MODULE_PARM(lpfc20_scsi_req_tmo, "i");
+MODULE_PARM(lpfc20_lun_skip, "i");
+
+MODULE_PARM(lpfc21_log_verbose, "i");
+MODULE_PARM(lpfc21_lun_queue_depth, "i");
+MODULE_PARM(lpfc21_tgt_queue_depth, "i");
+MODULE_PARM(lpfc21_no_device_delay, "i");
+MODULE_PARM(lpfc21_network_on, "i");
+MODULE_PARM(lpfc21_xmt_que_size, "i");
+MODULE_PARM(lpfc21_scan_down, "i");
+MODULE_PARM(lpfc21_linkdown_tmo, "i");
+MODULE_PARM(lpfc21_nodev_tmo, "i");
+MODULE_PARM(lpfc21_delay_rsp_err, "i");
+MODULE_PARM(lpfc21_nodev_holdio, "i");
+MODULE_PARM(lpfc21_check_cond_err, "i");
+MODULE_PARM(lpfc21_num_iocbs, "i");
+MODULE_PARM(lpfc21_num_bufs, "i");
+MODULE_PARM(lpfc21_topology, "i");
+MODULE_PARM(lpfc21_link_speed, "i");
+MODULE_PARM(lpfc21_ip_class, "i");
+MODULE_PARM(lpfc21_fcp_class, "i");
+MODULE_PARM(lpfc21_use_adisc, "i");
+MODULE_PARM(lpfc21_extra_io_tmo, "i");
+MODULE_PARM(lpfc21_post_ip_buf, "i");
+MODULE_PARM(lpfc21_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc21_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc21_ack0, "i");
+MODULE_PARM(lpfc21_automap, "i");
+MODULE_PARM(lpfc21_fcp_bind_method, "i");
+MODULE_PARM(lpfc21_cr_delay, "i");
+MODULE_PARM(lpfc21_cr_count, "i");
+MODULE_PARM(lpfc21_fdmi_on, "i");
+MODULE_PARM(lpfc21_max_lun, "i");
+MODULE_PARM(lpfc21_discovery_threads, "i");
+MODULE_PARM(lpfc21_max_target, "i");
+MODULE_PARM(lpfc21_scsi_req_tmo, "i");
+MODULE_PARM(lpfc21_lun_skip, "i");
+
+MODULE_PARM(lpfc22_log_verbose, "i");
+MODULE_PARM(lpfc22_lun_queue_depth, "i");
+MODULE_PARM(lpfc22_tgt_queue_depth, "i");
+MODULE_PARM(lpfc22_no_device_delay, "i");
+MODULE_PARM(lpfc22_network_on, "i");
+MODULE_PARM(lpfc22_xmt_que_size, "i");
+MODULE_PARM(lpfc22_scan_down, "i");
+MODULE_PARM(lpfc22_linkdown_tmo, "i");
+MODULE_PARM(lpfc22_nodev_tmo, "i");
+MODULE_PARM(lpfc22_delay_rsp_err, "i");
+MODULE_PARM(lpfc22_nodev_holdio, "i");
+MODULE_PARM(lpfc22_check_cond_err, "i");
+MODULE_PARM(lpfc22_num_iocbs, "i");
+MODULE_PARM(lpfc22_num_bufs, "i");
+MODULE_PARM(lpfc22_topology, "i");
+MODULE_PARM(lpfc22_link_speed, "i");
+MODULE_PARM(lpfc22_ip_class, "i");
+MODULE_PARM(lpfc22_fcp_class, "i");
+MODULE_PARM(lpfc22_use_adisc, "i");
+MODULE_PARM(lpfc22_extra_io_tmo, "i");
+MODULE_PARM(lpfc22_post_ip_buf, "i");
+MODULE_PARM(lpfc22_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc22_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc22_ack0, "i");
+MODULE_PARM(lpfc22_automap, "i");
+MODULE_PARM(lpfc22_fcp_bind_method, "i");
+MODULE_PARM(lpfc22_cr_delay, "i");
+MODULE_PARM(lpfc22_cr_count, "i");
+MODULE_PARM(lpfc22_fdmi_on, "i");
+MODULE_PARM(lpfc22_max_lun, "i");
+MODULE_PARM(lpfc22_discovery_threads, "i");
+MODULE_PARM(lpfc22_max_target, "i");
+MODULE_PARM(lpfc22_scsi_req_tmo, "i");
+MODULE_PARM(lpfc22_lun_skip, "i");
+
+MODULE_PARM(lpfc23_log_verbose, "i");
+MODULE_PARM(lpfc23_lun_queue_depth, "i");
+MODULE_PARM(lpfc23_tgt_queue_depth, "i");
+MODULE_PARM(lpfc23_no_device_delay, "i");
+MODULE_PARM(lpfc23_network_on, "i");
+MODULE_PARM(lpfc23_xmt_que_size, "i");
+MODULE_PARM(lpfc23_scan_down, "i");
+MODULE_PARM(lpfc23_linkdown_tmo, "i");
+MODULE_PARM(lpfc23_nodev_tmo, "i");
+MODULE_PARM(lpfc23_delay_rsp_err, "i");
+MODULE_PARM(lpfc23_nodev_holdio, "i");
+MODULE_PARM(lpfc23_check_cond_err, "i");
+MODULE_PARM(lpfc23_num_iocbs, "i");
+MODULE_PARM(lpfc23_num_bufs, "i");
+MODULE_PARM(lpfc23_topology, "i");
+MODULE_PARM(lpfc23_link_speed, "i");
+MODULE_PARM(lpfc23_ip_class, "i");
+MODULE_PARM(lpfc23_fcp_class, "i");
+MODULE_PARM(lpfc23_use_adisc, "i");
+MODULE_PARM(lpfc23_extra_io_tmo, "i");
+MODULE_PARM(lpfc23_post_ip_buf, "i");
+MODULE_PARM(lpfc23_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc23_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc23_ack0, "i");
+MODULE_PARM(lpfc23_automap, "i");
+MODULE_PARM(lpfc23_fcp_bind_method, "i");
+MODULE_PARM(lpfc23_cr_delay, "i");
+MODULE_PARM(lpfc23_cr_count, "i");
+MODULE_PARM(lpfc23_fdmi_on, "i");
+MODULE_PARM(lpfc23_max_lun, "i");
+MODULE_PARM(lpfc23_discovery_threads, "i");
+MODULE_PARM(lpfc23_max_target, "i");
+MODULE_PARM(lpfc23_scsi_req_tmo, "i");
+MODULE_PARM(lpfc23_lun_skip, "i");
+
+MODULE_PARM(lpfc24_log_verbose, "i");
+MODULE_PARM(lpfc24_lun_queue_depth, "i");
+MODULE_PARM(lpfc24_tgt_queue_depth, "i");
+MODULE_PARM(lpfc24_no_device_delay, "i");
+MODULE_PARM(lpfc24_network_on, "i");
+MODULE_PARM(lpfc24_xmt_que_size, "i");
+MODULE_PARM(lpfc24_scan_down, "i");
+MODULE_PARM(lpfc24_linkdown_tmo, "i");
+MODULE_PARM(lpfc24_nodev_tmo, "i");
+MODULE_PARM(lpfc24_delay_rsp_err, "i");
+MODULE_PARM(lpfc24_nodev_holdio, "i");
+MODULE_PARM(lpfc24_check_cond_err, "i");
+MODULE_PARM(lpfc24_num_iocbs, "i");
+MODULE_PARM(lpfc24_num_bufs, "i");
+MODULE_PARM(lpfc24_topology, "i");
+MODULE_PARM(lpfc24_link_speed, "i");
+MODULE_PARM(lpfc24_ip_class, "i");
+MODULE_PARM(lpfc24_fcp_class, "i");
+MODULE_PARM(lpfc24_use_adisc, "i");
+MODULE_PARM(lpfc24_extra_io_tmo, "i");
+MODULE_PARM(lpfc24_post_ip_buf, "i");
+MODULE_PARM(lpfc24_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc24_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc24_ack0, "i");
+MODULE_PARM(lpfc24_automap, "i");
+MODULE_PARM(lpfc24_fcp_bind_method, "i");
+MODULE_PARM(lpfc24_cr_delay, "i");
+MODULE_PARM(lpfc24_cr_count, "i");
+MODULE_PARM(lpfc24_fdmi_on, "i");
+MODULE_PARM(lpfc24_max_lun, "i");
+MODULE_PARM(lpfc24_discovery_threads, "i");
+MODULE_PARM(lpfc24_max_target, "i");
+MODULE_PARM(lpfc24_scsi_req_tmo, "i");
+MODULE_PARM(lpfc24_lun_skip, "i");
+
+MODULE_PARM(lpfc25_log_verbose, "i");
+MODULE_PARM(lpfc25_lun_queue_depth, "i");
+MODULE_PARM(lpfc25_tgt_queue_depth, "i");
+MODULE_PARM(lpfc25_no_device_delay, "i");
+MODULE_PARM(lpfc25_network_on, "i");
+MODULE_PARM(lpfc25_xmt_que_size, "i");
+MODULE_PARM(lpfc25_scan_down, "i");
+MODULE_PARM(lpfc25_linkdown_tmo, "i");
+MODULE_PARM(lpfc25_nodev_tmo, "i");
+MODULE_PARM(lpfc25_delay_rsp_err, "i");
+MODULE_PARM(lpfc25_nodev_holdio, "i");
+MODULE_PARM(lpfc25_check_cond_err, "i");
+MODULE_PARM(lpfc25_num_iocbs, "i");
+MODULE_PARM(lpfc25_num_bufs, "i");
+MODULE_PARM(lpfc25_topology, "i");
+MODULE_PARM(lpfc25_link_speed, "i");
+MODULE_PARM(lpfc25_ip_class, "i");
+MODULE_PARM(lpfc25_fcp_class, "i");
+MODULE_PARM(lpfc25_use_adisc, "i");
+MODULE_PARM(lpfc25_extra_io_tmo, "i");
+MODULE_PARM(lpfc25_post_ip_buf, "i");
+MODULE_PARM(lpfc25_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc25_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc25_ack0, "i");
+MODULE_PARM(lpfc25_automap, "i");
+MODULE_PARM(lpfc25_fcp_bind_method, "i");
+MODULE_PARM(lpfc25_cr_delay, "i");
+MODULE_PARM(lpfc25_cr_count, "i");
+MODULE_PARM(lpfc25_fdmi_on, "i");
+MODULE_PARM(lpfc25_max_lun, "i");
+MODULE_PARM(lpfc25_discovery_threads, "i");
+MODULE_PARM(lpfc25_max_target, "i");
+MODULE_PARM(lpfc25_scsi_req_tmo, "i");
+MODULE_PARM(lpfc25_lun_skip, "i");
+
+MODULE_PARM(lpfc26_log_verbose, "i");
+MODULE_PARM(lpfc26_lun_queue_depth, "i");
+MODULE_PARM(lpfc26_tgt_queue_depth, "i");
+MODULE_PARM(lpfc26_no_device_delay, "i");
+MODULE_PARM(lpfc26_network_on, "i");
+MODULE_PARM(lpfc26_xmt_que_size, "i");
+MODULE_PARM(lpfc26_scan_down, "i");
+MODULE_PARM(lpfc26_linkdown_tmo, "i");
+MODULE_PARM(lpfc26_nodev_tmo, "i");
+MODULE_PARM(lpfc26_delay_rsp_err, "i");
+MODULE_PARM(lpfc26_nodev_holdio, "i");
+MODULE_PARM(lpfc26_check_cond_err, "i");
+MODULE_PARM(lpfc26_num_iocbs, "i");
+MODULE_PARM(lpfc26_num_bufs, "i");
+MODULE_PARM(lpfc26_topology, "i");
+MODULE_PARM(lpfc26_link_speed, "i");
+MODULE_PARM(lpfc26_ip_class, "i");
+MODULE_PARM(lpfc26_fcp_class, "i");
+MODULE_PARM(lpfc26_use_adisc, "i");
+MODULE_PARM(lpfc26_extra_io_tmo, "i");
+MODULE_PARM(lpfc26_post_ip_buf, "i");
+MODULE_PARM(lpfc26_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc26_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc26_ack0, "i");
+MODULE_PARM(lpfc26_automap, "i");
+MODULE_PARM(lpfc26_fcp_bind_method, "i");
+MODULE_PARM(lpfc26_cr_delay, "i");
+MODULE_PARM(lpfc26_cr_count, "i");
+MODULE_PARM(lpfc26_fdmi_on, "i");
+MODULE_PARM(lpfc26_max_lun, "i");
+MODULE_PARM(lpfc26_discovery_threads, "i");
+MODULE_PARM(lpfc26_max_target, "i");
+MODULE_PARM(lpfc26_scsi_req_tmo, "i");
+MODULE_PARM(lpfc26_lun_skip, "i");
+
+MODULE_PARM(lpfc27_log_verbose, "i");
+MODULE_PARM(lpfc27_lun_queue_depth, "i");
+MODULE_PARM(lpfc27_tgt_queue_depth, "i");
+MODULE_PARM(lpfc27_no_device_delay, "i");
+MODULE_PARM(lpfc27_network_on, "i");
+MODULE_PARM(lpfc27_xmt_que_size, "i");
+MODULE_PARM(lpfc27_scan_down, "i");
+MODULE_PARM(lpfc27_linkdown_tmo, "i");
+MODULE_PARM(lpfc27_nodev_tmo, "i");
+MODULE_PARM(lpfc27_delay_rsp_err, "i");
+MODULE_PARM(lpfc27_nodev_holdio, "i");
+MODULE_PARM(lpfc27_check_cond_err, "i");
+MODULE_PARM(lpfc27_num_iocbs, "i");
+MODULE_PARM(lpfc27_num_bufs, "i");
+MODULE_PARM(lpfc27_topology, "i");
+MODULE_PARM(lpfc27_link_speed, "i");
+MODULE_PARM(lpfc27_ip_class, "i");
+MODULE_PARM(lpfc27_fcp_class, "i");
+MODULE_PARM(lpfc27_use_adisc, "i");
+MODULE_PARM(lpfc27_extra_io_tmo, "i");
+MODULE_PARM(lpfc27_post_ip_buf, "i");
+MODULE_PARM(lpfc27_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc27_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc27_ack0, "i");
+MODULE_PARM(lpfc27_automap, "i");
+MODULE_PARM(lpfc27_fcp_bind_method, "i");
+MODULE_PARM(lpfc27_cr_delay, "i");
+MODULE_PARM(lpfc27_cr_count, "i");
+MODULE_PARM(lpfc27_fdmi_on, "i");
+MODULE_PARM(lpfc27_max_lun, "i");
+MODULE_PARM(lpfc27_discovery_threads, "i");
+MODULE_PARM(lpfc27_max_target, "i");
+MODULE_PARM(lpfc27_scsi_req_tmo, "i");
+MODULE_PARM(lpfc27_lun_skip, "i");
+
+MODULE_PARM(lpfc28_log_verbose, "i");
+MODULE_PARM(lpfc28_lun_queue_depth, "i");
+MODULE_PARM(lpfc28_tgt_queue_depth, "i");
+MODULE_PARM(lpfc28_no_device_delay, "i");
+MODULE_PARM(lpfc28_network_on, "i");
+MODULE_PARM(lpfc28_xmt_que_size, "i");
+MODULE_PARM(lpfc28_scan_down, "i");
+MODULE_PARM(lpfc28_linkdown_tmo, "i");
+MODULE_PARM(lpfc28_nodev_tmo, "i");
+MODULE_PARM(lpfc28_delay_rsp_err, "i");
+MODULE_PARM(lpfc28_nodev_holdio, "i");
+MODULE_PARM(lpfc28_check_cond_err, "i");
+MODULE_PARM(lpfc28_num_iocbs, "i");
+MODULE_PARM(lpfc28_num_bufs, "i");
+MODULE_PARM(lpfc28_topology, "i");
+MODULE_PARM(lpfc28_link_speed, "i");
+MODULE_PARM(lpfc28_ip_class, "i");
+MODULE_PARM(lpfc28_fcp_class, "i");
+MODULE_PARM(lpfc28_use_adisc, "i");
+MODULE_PARM(lpfc28_extra_io_tmo, "i");
+MODULE_PARM(lpfc28_post_ip_buf, "i");
+MODULE_PARM(lpfc28_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc28_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc28_ack0, "i");
+MODULE_PARM(lpfc28_automap, "i");
+MODULE_PARM(lpfc28_fcp_bind_method, "i");
+MODULE_PARM(lpfc28_cr_delay, "i");
+MODULE_PARM(lpfc28_cr_count, "i");
+MODULE_PARM(lpfc28_fdmi_on, "i");
+MODULE_PARM(lpfc28_max_lun, "i");
+MODULE_PARM(lpfc28_discovery_threads, "i");
+MODULE_PARM(lpfc28_max_target, "i");
+MODULE_PARM(lpfc28_scsi_req_tmo, "i");
+MODULE_PARM(lpfc28_lun_skip, "i");
+
+MODULE_PARM(lpfc29_log_verbose, "i");
+MODULE_PARM(lpfc29_lun_queue_depth, "i");
+MODULE_PARM(lpfc29_tgt_queue_depth, "i");
+MODULE_PARM(lpfc29_no_device_delay, "i");
+MODULE_PARM(lpfc29_network_on, "i");
+MODULE_PARM(lpfc29_xmt_que_size, "i");
+MODULE_PARM(lpfc29_scan_down, "i");
+MODULE_PARM(lpfc29_linkdown_tmo, "i");
+MODULE_PARM(lpfc29_nodev_tmo, "i");
+MODULE_PARM(lpfc29_delay_rsp_err, "i");
+MODULE_PARM(lpfc29_nodev_holdio, "i");
+MODULE_PARM(lpfc29_check_cond_err, "i");
+MODULE_PARM(lpfc29_num_iocbs, "i");
+MODULE_PARM(lpfc29_num_bufs, "i");
+MODULE_PARM(lpfc29_topology, "i");
+MODULE_PARM(lpfc29_link_speed, "i");
+MODULE_PARM(lpfc29_ip_class, "i");
+MODULE_PARM(lpfc29_fcp_class, "i");
+MODULE_PARM(lpfc29_use_adisc, "i");
+MODULE_PARM(lpfc29_extra_io_tmo, "i");
+MODULE_PARM(lpfc29_post_ip_buf, "i");
+MODULE_PARM(lpfc29_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc29_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc29_ack0, "i");
+MODULE_PARM(lpfc29_automap, "i");
+MODULE_PARM(lpfc29_fcp_bind_method, "i");
+MODULE_PARM(lpfc29_cr_delay, "i");
+MODULE_PARM(lpfc29_cr_count, "i");
+MODULE_PARM(lpfc29_fdmi_on, "i");
+MODULE_PARM(lpfc29_max_lun, "i");
+MODULE_PARM(lpfc29_discovery_threads, "i");
+MODULE_PARM(lpfc29_max_target, "i");
+MODULE_PARM(lpfc29_scsi_req_tmo, "i");
+MODULE_PARM(lpfc29_lun_skip, "i");
+
+MODULE_PARM(lpfc30_log_verbose, "i");
+MODULE_PARM(lpfc30_lun_queue_depth, "i");
+MODULE_PARM(lpfc30_tgt_queue_depth, "i");
+MODULE_PARM(lpfc30_no_device_delay, "i");
+MODULE_PARM(lpfc30_network_on, "i");
+MODULE_PARM(lpfc30_xmt_que_size, "i");
+MODULE_PARM(lpfc30_scan_down, "i");
+MODULE_PARM(lpfc30_linkdown_tmo, "i");
+MODULE_PARM(lpfc30_nodev_tmo, "i");
+MODULE_PARM(lpfc30_delay_rsp_err, "i");
+MODULE_PARM(lpfc30_nodev_holdio, "i");
+MODULE_PARM(lpfc30_check_cond_err, "i");
+MODULE_PARM(lpfc30_num_iocbs, "i");
+MODULE_PARM(lpfc30_num_bufs, "i");
+MODULE_PARM(lpfc30_topology, "i");
+MODULE_PARM(lpfc30_link_speed, "i");
+MODULE_PARM(lpfc30_ip_class, "i");
+MODULE_PARM(lpfc30_fcp_class, "i");
+MODULE_PARM(lpfc30_use_adisc, "i");
+MODULE_PARM(lpfc30_extra_io_tmo, "i");
+MODULE_PARM(lpfc30_post_ip_buf, "i");
+MODULE_PARM(lpfc30_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc30_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc30_ack0, "i");
+MODULE_PARM(lpfc30_automap, "i");
+MODULE_PARM(lpfc30_fcp_bind_method, "i");
+MODULE_PARM(lpfc30_cr_delay, "i");
+MODULE_PARM(lpfc30_cr_count, "i");
+MODULE_PARM(lpfc30_fdmi_on, "i");
+MODULE_PARM(lpfc30_max_lun, "i");
+MODULE_PARM(lpfc30_discovery_threads, "i");
+MODULE_PARM(lpfc30_max_target, "i");
+MODULE_PARM(lpfc30_scsi_req_tmo, "i");
+MODULE_PARM(lpfc30_lun_skip, "i");
+
+MODULE_PARM(lpfc31_log_verbose, "i");
+MODULE_PARM(lpfc31_lun_queue_depth, "i");
+MODULE_PARM(lpfc31_tgt_queue_depth, "i");
+MODULE_PARM(lpfc31_no_device_delay, "i");
+MODULE_PARM(lpfc31_network_on, "i");
+MODULE_PARM(lpfc31_xmt_que_size, "i");
+MODULE_PARM(lpfc31_scan_down, "i");
+MODULE_PARM(lpfc31_linkdown_tmo, "i");
+MODULE_PARM(lpfc31_nodev_tmo, "i");
+MODULE_PARM(lpfc31_delay_rsp_err, "i");
+MODULE_PARM(lpfc31_nodev_holdio, "i");
+MODULE_PARM(lpfc31_check_cond_err, "i");
+MODULE_PARM(lpfc31_num_iocbs, "i");
+MODULE_PARM(lpfc31_num_bufs, "i");
+MODULE_PARM(lpfc31_topology, "i");
+MODULE_PARM(lpfc31_link_speed, "i");
+MODULE_PARM(lpfc31_ip_class, "i");
+MODULE_PARM(lpfc31_fcp_class, "i");
+MODULE_PARM(lpfc31_use_adisc, "i");
+MODULE_PARM(lpfc31_extra_io_tmo, "i");
+MODULE_PARM(lpfc31_post_ip_buf, "i");
+MODULE_PARM(lpfc31_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc31_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc31_ack0, "i");
+MODULE_PARM(lpfc31_automap, "i");
+MODULE_PARM(lpfc31_fcp_bind_method, "i");
+MODULE_PARM(lpfc31_cr_delay, "i");
+MODULE_PARM(lpfc31_cr_count, "i");
+MODULE_PARM(lpfc31_fdmi_on, "i");
+MODULE_PARM(lpfc31_max_lun, "i");
+MODULE_PARM(lpfc31_discovery_threads, "i");
+MODULE_PARM(lpfc31_max_target, "i");
+MODULE_PARM(lpfc31_scsi_req_tmo, "i");
+MODULE_PARM(lpfc31_lun_skip, "i");
+
+MODULE_PARM(lpfc_log_verbose, "i");
+MODULE_PARM(lpfc_lun_queue_depth, "i");
+MODULE_PARM(lpfc_tgt_queue_depth, "i");
+MODULE_PARM(lpfc_no_device_delay, "i");
+MODULE_PARM(lpfc_network_on, "i");
+MODULE_PARM(lpfc_xmt_que_size, "i");
+MODULE_PARM(lpfc_scan_down, "i");
+MODULE_PARM(lpfc_linkdown_tmo, "i");
+MODULE_PARM(lpfc_nodev_tmo, "i");
+MODULE_PARM(lpfc_delay_rsp_err, "i");
+MODULE_PARM(lpfc_nodev_holdio, "i");
+MODULE_PARM(lpfc_check_cond_err, "i");
+MODULE_PARM(lpfc_num_iocbs, "i");
+MODULE_PARM(lpfc_num_bufs, "i");
+MODULE_PARM(lpfc_topology, "i");
+MODULE_PARM(lpfc_link_speed, "i");
+MODULE_PARM(lpfc_ip_class, "i");
+MODULE_PARM(lpfc_fcp_class, "i");
+MODULE_PARM(lpfc_use_adisc, "i");
+MODULE_PARM(lpfc_extra_io_tmo, "i");
+MODULE_PARM(lpfc_post_ip_buf, "i");
+MODULE_PARM(lpfc_dqfull_throttle_up_time, "i");
+MODULE_PARM(lpfc_dqfull_throttle_up_inc, "i");
+MODULE_PARM(lpfc_ack0, "i");
+MODULE_PARM(lpfc_automap, "i");
+MODULE_PARM(lpfc_fcp_bind_method, "i");
+MODULE_PARM(lpfc_cr_delay, "i");
+MODULE_PARM(lpfc_cr_count, "i");
+MODULE_PARM(lpfc_fdmi_on, "i");
+MODULE_PARM(lpfc_max_lun, "i");
+MODULE_PARM(lpfc_discovery_threads, "i");
+MODULE_PARM(lpfc_scsi_req_tmo, "i");
+MODULE_PARM(lpfc_max_target, "i");
+MODULE_PARM(lpfc_fcp_bind_WWPN, "1-" __MODULE_STRING(MAX_FC_BINDINGS) "s");
+MODULE_PARM(lpfc_fcp_bind_WWNN, "1-" __MODULE_STRING(MAX_FC_BINDINGS) "s");
+MODULE_PARM(lpfc_fcp_bind_DID, "1-" __MODULE_STRING(MAX_FC_BINDINGS) "s");
+MODULE_PARM(lpfc_lun_skip, "i");
+MODULE_PARM(lpfc_use_data_direction, "i");
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/prod_crtn.h linux-2.6.3/drivers/scsi/lpfc/prod_crtn.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/prod_crtn.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/prod_crtn.h	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,94 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#ifndef _H_PROD_CRTN
+#define _H_PROD_CRTN
+
+#include <linux/delay.h>
+#include <asm/uaccess.h>
+
+#include "elx_sli.h"
+#include "elx_logmsg.h"
+
+/* Function prototypes. */
+
+uint8_t *elx_malloc(elxHBA_t *, struct mbuf_info *);
+void elx_free(elxHBA_t *, struct mbuf_info *);
+int elx_print(char *, void *, void *);
+int elx_printf_log_msgblk(int, msgLogDef *, char *, int);
+void elx_sleep_ms(elxHBA_t *, int);
+void elx_pci_dma_sync(void *, void *, int, int);
+void *elx_kmem_alloc(unsigned int, int);
+void elx_kmem_free(void *, unsigned int);
+void *elx_kmem_zalloc(unsigned int, int);
+void elx_sli_init_lock(elxHBA_t *);
+void elx_sli_lock(elxHBA_t *, unsigned long *);
+void elx_sli_unlock(elxHBA_t *, unsigned long *);
+void elx_mem_init_lock(elxHBA_t *);
+void elx_mem_lock(elxHBA_t *, unsigned long *);
+void elx_mem_unlock(elxHBA_t *, unsigned long *);
+void elx_sch_init_lock(elxHBA_t *);
+void elx_sch_lock(elxHBA_t *, unsigned long *);
+void elx_sch_unlock(elxHBA_t *, unsigned long *);
+void elx_ioc_init_lock(elxHBA_t *);
+void elx_ioc_lock(elxHBA_t *, unsigned long *);
+void elx_ioc_unlock(elxHBA_t *, unsigned long *);
+void elx_drvr_init_lock(elxHBA_t *);
+void elx_drvr_lock(elxHBA_t *, unsigned long *);
+void elx_drvr_unlock(elxHBA_t *, unsigned long *);
+void elx_clk_init_lock(elxHBA_t *);
+void elx_clk_lock(elxHBA_t *, unsigned long *);
+void elx_clk_unlock(elxHBA_t *, unsigned long *);
+void elx_disc_init_lock(elxHBA_t *);
+void elx_disc_lock(elxHBA_t *, unsigned long *);
+void elx_disc_unlock(elxHBA_t *, unsigned long *);
+void elx_hipri_init_lock(elxHBA_t *);
+void elx_hipri_lock(elxHBA_t *, unsigned long *);
+void elx_hipri_unlock(elxHBA_t *, unsigned long *);
+uint16_t elx_read_pci_cmd(elxHBA_t *);
+uint32_t elx_read_pci(elxHBA_t *, int);
+void elx_cnt_read_pci(elxHBA_t *, uint32_t, uint32_t, uint32_t *);
+void elx_cnt_write_pci(elxHBA_t *, uint32_t, uint32_t, uint32_t *);
+void elx_write_pci_cmd(elxHBA_t *, uint16_t);
+void elx_write_cnt_pci_cmd(elxHBA_t *, int, uint16_t);
+void *elx_remap_pci_mem(unsigned long, unsigned long);
+void elx_unmap_pci_mem(unsigned long);
+void elx_write_toio(uint32_t *, uint32_t *, uint32_t);
+void elx_read_fromio(uint32_t *, uint32_t *, uint32_t);
+int elx_in_intr(void);
+
+void *elx_alloc_bigbuf(elxHBA_t *, elx_dma_addr_t *, uint32_t);
+void elx_free_bigbuf(elxHBA_t *, void *, elx_dma_addr_t, uint32_t);
+void elx_nodev(unsigned long);
+
+void elx_ip_get_rcv_buf(elxHBA_t *, DMABUFIP_t *, uint32_t);
+void elx_ip_free_rcv_buf(elxHBA_t *, DMABUFIP_t *, uint32_t);
+
+void elx_iodone(elxHBA_t *, ELX_SCSI_BUF_t *);
+int elx_scsi_delay_iodone(elxHBA_t *, ELX_SCSI_BUF_t *);
+void elx_unblock_requests(elxHBA_t *);
+void elx_block_requests(elxHBA_t *);
+uint64_t elx_pci_map(elxHBA_t *, void *, int, int);
+void myprint(char *, void *, void *, void *, void *);
+
+void lpfc_set_pkt_len(void *, uint32_t);
+void *lpfc_get_pkt_data(void *);
+
+#endif				/* _H_PROD_CRTN */
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/prod_linux.c linux-2.6.3/drivers/scsi/lpfc/prod_linux.c
--- linux-2.6.3.emulex/drivers/scsi/lpfc/prod_linux.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/prod_linux.c	2004-02-27 19:18:52.000000000 +0100
@@ -0,0 +1,2654 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/fcntl.h>
+#include <linux/sched.h>
+#include <linux/interrupt.h>
+#include <linux/ptrace.h>
+#include <linux/ioport.h>
+#include <linux/in.h>
+#include <linux/slab.h>
+#include <linux/string.h>
+#include <linux/init.h>
+#include <linux/errno.h>
+#include <linux/blkdev.h>
+#include <linux/string.h>
+#include <linux/ioport.h>
+#include <linux/pci.h>
+#include <linux/unistd.h>
+#include <linux/timex.h>
+#include <linux/timer.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/if_arp.h>
+#include <asm/system.h>
+#include <asm/bitops.h>
+#include <asm/io.h>
+#include <asm/dma.h>
+#include <asm/irq.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+#include <scsi/scsi_device.h>
+#include <asm/pci.h>
+#else
+#include "sd.h"			/* From drivers/scsi */
+#endif
+
+#include "hosts.h"
+
+#include "elx_os.h"
+#include "prod_os.h"
+#include "elx_util.h"
+#include "elx_clock.h"
+#include "elx_hw.h"
+#include "elx_mem.h"
+#include "elx_sli.h"
+#include "elx_sched.h"
+#include "elx.h"
+#include "elx_logmsg.h"
+#include "elx_disc.h"
+#include "elx_scsi.h"
+#include "elx_crtn.h"
+#include "prod_crtn.h"
+
+#define ScsiResult(host_code, scsi_code) (((host_code) << 16) | scsi_code)
+
+#include <linux/spinlock.h>
+#include <linux/rtnetlink.h>
+
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <asm/byteorder.h>
+
+int prodMallocCnt = 0;
+int prodMallocByte = 0;
+int prodFreeCnt = 0;
+int prodFreeByte = 0;
+int virtMallocCnt = 0;
+int virtMallocByte = 0;
+int virtFreeCnt = 0;
+int virtFreeByte = 0;
+int pciMallocCnt = 0;
+int pciMallocByte = 0;
+int pciFreeCnt = 0;
+int pciFreeByte = 0;
+int dmaGrowMallocCnt = 0;
+int dmaGrowMallocByte = 0;
+int dmaGrowFreeCnt = 0;
+int dmaGrowFreeByte = 0;
+
+struct elx_mem_pool *elx_mem_dmapool[MAX_ELX_BRDS];
+int elx_idx_dmapool[MAX_ELX_BRDS];
+int elx_size_dmapool[MAX_ELX_BRDS];
+spinlock_t elx_kmem_lock;
+
+uint32_t elx_po2(uint32_t);
+void *linux_kmalloc(uint32_t, uint32_t, elx_dma_addr_t *, elxHBA_t *);
+void linux_kfree(uint32_t, void *, elx_dma_addr_t, elxHBA_t *);
+
+extern char *elx_drvr_name;
+extern int lpfc_isr;
+extern int lpfc_tmr;
+elxDRVR_t elxDRVR;
+
+void *
+linux_kmalloc(uint32_t size,
+	      uint32_t type, elx_dma_addr_t * pphys, elxHBA_t * phba)
+{
+	void *pcidev;
+	void *virt;
+	struct elx_mem_pool *fmp;
+	LINUX_HBA_t *plxhba;
+	elx_dma_addr_t phys;
+	dma_addr_t physical = INVALID_PHYS;
+	int i, instance;
+	unsigned long iflag;
+	int elx_size_previous, elx_size_new;
+
+	if (pphys == 0) {
+		virt = kmalloc(size, type);
+		if (virt) {
+			virtMallocCnt++;
+			virtMallocByte += size;
+		}
+
+		return (virt);
+	}
+
+	if (phba == 0) {
+		/* linux_kmalloc: Bad phba */
+		elx_printf_log(0,	/* force brd 0, no p_dev_ctl */
+			       &elx_msgBlk1201,	/* ptr to msg structure */
+			       elx_mes1201,	/* ptr to msg */
+			       elx_msgBlk1201.msgPreambleStr,	/* begin varargs */
+			       size, type, elx_idx_dmapool[0]);	/* end varargs */
+		return (0);
+	}
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	instance = phba->brd_no;
+	pcidev = plxhba->pcidev;
+
+	if (size > FC_MAX_SEGSZ) {
+		/* linux_kmalloc: Bad size */
+		elx_printf_log(instance, &elx_msgBlk1202,	/* ptr to msg structure */
+			       elx_mes1202,	/* ptr to msg */
+			       elx_msgBlk1202.msgPreambleStr,	/* begin varargs */
+			       size, type, elx_idx_dmapool[instance]);	/* end varargs */
+		return (0);
+	}
+	spin_lock_irqsave(&elx_kmem_lock, iflag);
+
+      top:
+	fmp = elx_mem_dmapool[instance];
+	for (i = 0; i <= elx_idx_dmapool[instance]; i++) {
+		fmp = (elx_mem_dmapool[instance] + i);
+		if ((fmp->p_virt == 0) || (fmp->p_left >= size))
+			break;
+	}
+
+	if (i == (elx_size_dmapool[instance] - 2)) {
+		/* Lets make it bigger */
+		elx_size_previous = elx_size_dmapool[instance];
+		elx_size_new =
+		    (sizeof (struct elx_mem_pool) * elx_size_dmapool[instance]);
+		elx_size_dmapool[instance] += FC_MAX_POOL;
+		fmp =
+		    kmalloc((sizeof (struct elx_mem_pool) *
+			     elx_size_dmapool[instance]), GFP_ATOMIC);
+		if (fmp) {
+			dmaGrowMallocCnt++;
+			dmaGrowMallocByte += elx_size_new;
+			memset((void *)fmp, 0,
+			       (sizeof (struct elx_mem_pool) *
+				elx_size_dmapool[instance]));
+			memcpy(fmp, (void *)elx_mem_dmapool[instance],
+			       (sizeof (struct elx_mem_pool) *
+				(elx_size_dmapool[instance] - FC_MAX_POOL)));
+			kfree(elx_mem_dmapool[instance]);
+			dmaGrowFreeCnt++;
+			dmaGrowFreeByte += elx_size_previous;
+			elx_mem_dmapool[instance] = fmp;
+			goto top;
+		}
+		goto out;
+	}
+
+	if (fmp->p_virt == 0) {
+		virt = pci_alloc_consistent(pcidev, FC_MAX_SEGSZ, &physical);
+		if (virt) {
+			pciMallocCnt++;
+			pciMallocByte += FC_MAX_SEGSZ;
+			fmp->p_phys = phys = physical;
+			fmp->p_virt = virt;
+			fmp->p_refcnt = 0;
+			fmp->p_left = (ushort) FC_MAX_SEGSZ;
+			if (i == elx_idx_dmapool[instance])
+				if (i < (elx_size_dmapool[instance] - 2))
+					elx_idx_dmapool[instance]++;
+		} else {
+			/* linux_kmalloc: Bad virtual addr */
+			elx_printf_log(instance, &elx_msgBlk1204,	/* ptr to msg structure */
+				       elx_mes1204,	/* ptr to msg */
+				       elx_msgBlk1204.msgPreambleStr,	/* begin varargs */
+				       i, size, type, elx_idx_dmapool[instance]);	/* end varargs */
+			spin_unlock_irqrestore(&elx_kmem_lock, iflag);
+			return (0);
+		}
+	}
+
+	if (fmp->p_left >= size) {
+		fmp->p_refcnt++;
+		virt =
+		    (void *)((uint8_t *) fmp->p_virt + FC_MAX_SEGSZ -
+			     fmp->p_left);
+		phys = fmp->p_phys + FC_MAX_SEGSZ - fmp->p_left;
+		*pphys = phys;
+		fmp->p_left -= size;
+		spin_unlock_irqrestore(&elx_kmem_lock, iflag);
+		return (virt);
+	}
+      out:
+	spin_unlock_irqrestore(&elx_kmem_lock, iflag);
+	/* linux_kmalloc: dmapool FULL */
+	elx_printf_log(instance, &elx_msgBlk1205,	/* ptr to msg structure */
+		       elx_mes1205,	/* ptr to msg */
+		       elx_msgBlk1205.msgPreambleStr,	/* begin varargs */
+		       i, size, type, elx_idx_dmapool[instance]);	/* end varargs */
+	return (0);
+}
+
+void
+linux_kfree(uint32_t size, void *virt, elx_dma_addr_t phys, elxHBA_t * phba)
+{
+	struct elx_mem_pool *fmp;
+	LINUX_HBA_t *plxhba;
+	void *pcidev;
+	int i, instance;
+
+	if (phys == INVALID_PHYS) {
+		virtFreeCnt++;
+		virtFreeByte += size;
+		kfree(virt);
+		return;
+	}
+
+	if (phba == 0) {
+		/* linux_kfree: Bad phba */
+		elx_printf_log(0,	/* force brd 0, no p_dev_ctl */
+			       &elx_msgBlk1206,	/* ptr to msg structure */
+			       elx_mes1206,	/* ptr to msg */
+			       elx_msgBlk1206.msgPreambleStr,	/* begin varargs */
+			       size, elx_idx_dmapool[0]);	/* end varargs */
+		return;
+	}
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	instance = phba->brd_no;
+	pcidev = plxhba->pcidev;
+
+	for (i = 0; i < elx_idx_dmapool[instance]; i++) {
+		fmp = (elx_mem_dmapool[instance] + i);
+		if ((virt >= fmp->p_virt) &&
+		    (virt < (void *)((uint8_t *) fmp->p_virt + FC_MAX_SEGSZ))) {
+			fmp->p_refcnt--;
+			if (fmp->p_refcnt == 0) {
+				pci_free_consistent(pcidev, FC_MAX_SEGSZ,
+						    fmp->p_virt, fmp->p_phys);
+				memset((void *)fmp, 0,
+				       sizeof (struct elx_mem_pool));
+				pciFreeCnt++;
+				pciFreeByte += FC_MAX_SEGSZ;
+			}
+			return;
+		}
+	}
+	/* linux_kfree: NOT in dmapool */
+	elx_printf_log(instance, &elx_msgBlk1207,	/* ptr to msg structure */
+		       elx_mes1207,	/* ptr to msg */
+		       elx_msgBlk1207.msgPreambleStr,	/* begin varargs */
+		       (uint32_t) ((unsigned long)virt), size, elx_idx_dmapool[instance]);	/* end varargs */
+	return;
+}
+
+void
+elx_sleep_ms(elxHBA_t * phba, int cnt)
+{
+	set_current_state(TASK_UNINTERRUPTIBLE);
+	schedule_timeout((cnt * HZ / 1000) + 1);
+	return;
+}
+
+int
+elx_in_intr()
+{
+	uint32_t cur_cpu;
+
+	cur_cpu = (uint32_t) (1 << smp_processor_id());
+	if ((lpfc_isr | lpfc_tmr) & cur_cpu) {
+		return (1);
+	}
+	return (0);
+}
+
+void
+elx_pci_dma_sync(void *phbarg, void *arg, int size, int direction)
+{
+	DMABUF_t *pdma;
+	LINUX_HBA_t *plxhba;
+	elxHBA_t *phba;
+
+	phba = (elxHBA_t *) phbarg;
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	pdma = (DMABUF_t *) arg;
+	if (size < PAGE_SIZE)
+		size = PAGE_SIZE;
+	if (direction == ELX_DMA_SYNC_FORDEV) {
+		pci_dma_sync_single(plxhba->pcidev,
+				    pdma->phys, size, PCI_DMA_TODEVICE);
+	} else {
+		pci_dma_sync_single(plxhba->pcidev,
+				    pdma->phys, size, PCI_DMA_FROMDEVICE);
+	}
+	return;
+}
+
+int
+elx_print(char *str, void *a1, void *a2)
+{
+	printk((const char *)str, a1, a2);
+	return (1);
+}
+
+int
+elx_printf_log_msgblk(int brdno, msgLogDef * msg, char *str,	/* String formatted by caller */
+		      int log_only)
+{
+	int ddiinst;
+	elxHBA_t *phba;
+	LINUX_HBA_t *plxhba;
+
+	phba = elxDRVR.pHba[brdno];
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	ddiinst = brdno;	/* Board number = instance in LINUX */
+	switch (msg->msgType) {
+	case ELX_LOG_MSG_TYPE_INFO:
+	case ELX_LOG_MSG_TYPE_WARN:
+		/* These LOG messages appear in LOG file only */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+		printk(KERN_INFO "%s%d:%04d:%s\n", elx_drvr_name, ddiinst,
+		       msg->msgNum, str);
+#else
+		dev_info(&((plxhba->pcidev)->dev), "%d:%04d:%s\n", ddiinst,
+			 msg->msgNum, str);
+#endif
+		break;
+	case ELX_LOG_MSG_TYPE_ERR_CFG:
+	case ELX_LOG_MSG_TYPE_ERR:
+		/* These LOG messages appear on the monitor and in the LOG file */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+		printk(KERN_WARNING "%s%d:%04d:%s\n", elx_drvr_name, ddiinst,
+		       msg->msgNum, str);
+#else
+		dev_warn(&((plxhba->pcidev)->dev), "%d:%04d:%s\n", ddiinst,
+			 msg->msgNum, str);
+#endif
+		break;
+	case ELX_LOG_MSG_TYPE_PANIC:
+		panic("%s%d:%04d:%s\n", elx_drvr_name, ddiinst, msg->msgNum,
+		      str);
+		break;
+	default:
+		return (0);
+	}
+	return (1);
+}
+
+uint8_t *
+elx_malloc(elxHBA_t * phba, MBUF_INFO_t * buf_info)
+{
+	uint32_t size;
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	buf_info->phys = INVALID_PHYS;
+	buf_info->dma_handle = 0;
+	switch (buf_info->flags & ELX_MBUF_MASK) {
+	case ELX_MBUF_VIRT:	/* LNX - plain virtual memory allocation */
+		buf_info->size = ((buf_info->size + 7) & 0xfffffff8);
+		buf_info->virt =
+		    linux_kmalloc(buf_info->size, GFP_ATOMIC, 0, 0);
+		if (buf_info->virt)
+			memset(buf_info->virt, 0, buf_info->size);
+		buf_info->phys = INVALID_PHYS;
+		break;
+	case ELX_MBUF_DMA:	/* LNX - dma-able memory from scratch */
+		size = elx_po2(buf_info->size);
+		if (size > FC_MAX_SEGSZ) {
+			buf_info->virt =
+			    elx_alloc_bigbuf(phba, &buf_info->phys, size);
+			if (buf_info->virt) {
+				if (buf_info->phys == INVALID_PHYS) {
+					elx_free_bigbuf(phba, buf_info->virt,
+							buf_info->phys, size);
+					buf_info->virt = 0;
+				}
+			}
+		} else {
+			buf_info->phys = INVALID_PHYS;
+			buf_info->virt =
+			    linux_kmalloc(size, GFP_ATOMIC, &buf_info->phys,
+					  phba);
+			if (buf_info->virt) {
+				if (buf_info->phys == INVALID_PHYS) {
+					linux_kfree(size, buf_info->virt,
+						    buf_info->phys, phba);
+					buf_info->virt = 0;
+				}
+			}
+		}
+
+		buf_info->dma_handle = buf_info->phys;
+
+		if (buf_info->virt == 0) {
+			buf_info->phys = INVALID_PHYS;
+			buf_info->dma_handle = 0;
+		}
+		break;
+	case ELX_MBUF_PHYSONLY:	/* LNX - convert virtual to dma-able */
+		if (buf_info->virt == NULL)
+			break;
+
+		buf_info->phys =
+		    (elx_dma_addr_t) elx_pci_map(phba, buf_info->virt,
+						 buf_info->size,
+						 PCI_DMA_BIDIRECTIONAL);
+
+		buf_info->dma_handle = buf_info->phys;
+
+		break;
+	}
+	return ((uint8_t *) buf_info->virt);
+}
+
+uint32_t
+elx_po2(uint32_t size)
+{
+	uint32_t order;
+
+	for (order = 1; order < size; order <<= 1) ;
+	return (order);
+}
+
+void
+elx_free(elxHBA_t * phba, MBUF_INFO_t * buf_info)
+{
+	uint32_t size;
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	switch (buf_info->flags & ELX_MBUF_MASK) {
+	case ELX_MBUF_VIRT:	/* LNX - plain virtual memory allocation */
+		buf_info->size = ((buf_info->size + 7) & 0xfffffff8);
+		linux_kfree(buf_info->size, buf_info->virt, INVALID_PHYS, 0);
+		break;
+	case ELX_MBUF_DMA:	/* LNX - dma-able memory from scratch */
+		size = elx_po2(buf_info->size);
+		if (size > FC_MAX_SEGSZ) {
+			elx_free_bigbuf(phba, buf_info->virt, buf_info->phys,
+					size);
+		} else {
+			linux_kfree(buf_info->size, buf_info->virt,
+				    buf_info->phys, phba);
+		}
+		break;
+	case ELX_MBUF_PHYSONLY:	/* LNX - convert virtual to dma-able */
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,12)
+		pci_unmap_single(plxhba->pcidev,
+				 buf_info->phys, buf_info->size,
+				 PCI_DMA_BIDIRECTIONAL);
+#else
+		pci_unmap_page(plxhba->pcidev,
+			       buf_info->phys, buf_info->size,
+			       PCI_DMA_BIDIRECTIONAL);
+#endif
+		break;
+	}
+}
+
+void *
+elx_kmem_alloc(unsigned int size, int flag)
+{
+	void *ptr;
+
+	if (flag == ELX_MEM_DELAY) {
+		ptr = kmalloc(size, GFP_KERNEL);
+	} else {
+		ptr = kmalloc(size, GFP_ATOMIC);
+	}
+	if (ptr) {
+		prodMallocCnt++;
+		prodMallocByte += size;
+	}
+	return (ptr);
+}
+
+void
+elx_kmem_free(void *obj, unsigned int size)
+{
+	if (obj) {
+		prodFreeCnt++;
+		prodFreeByte += size;
+		kfree(obj);
+	}
+}
+
+void *
+elx_kmem_zalloc(unsigned int size, int flag)
+{
+	void *ptr = elx_kmem_alloc(size, flag);
+	if (ptr)
+		memset(ptr, 0, size);
+	return (ptr);
+}
+
+void
+elx_sli_init_lock(elxHBA_t * phba)
+{
+	LINUX_HBA_t *lhba;
+
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_init(&lhba->slilock.elx_lock);
+	return;
+}
+
+void
+elx_sli_lock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = 0;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_irqsave(&lhba->slilock.elx_lock, flag);
+	*iflag = flag;
+	return;
+}
+
+void
+elx_sli_unlock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = *iflag;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_unlock_irqrestore(&lhba->slilock.elx_lock, flag);
+	return;
+}
+
+void
+elx_mem_init_lock(elxHBA_t * phba)
+{
+	LINUX_HBA_t *lhba;
+
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_init(&lhba->memlock.elx_lock);
+	return;
+}
+
+void
+elx_mem_lock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = 0;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_irqsave(&lhba->memlock.elx_lock, flag);
+	*iflag = flag;
+	return;
+}
+
+void
+elx_mem_unlock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = *iflag;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_unlock_irqrestore(&lhba->memlock.elx_lock, flag);
+	return;
+}
+
+void
+elx_sch_init_lock(elxHBA_t * phba)
+{
+	LINUX_HBA_t *lhba;
+
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_init(&lhba->schlock.elx_lock);
+	return;
+}
+
+void
+elx_sch_lock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = 0;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_irqsave(&lhba->schlock.elx_lock, flag);
+	*iflag = flag;
+	return;
+}
+
+void
+elx_sch_unlock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = *iflag;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_unlock_irqrestore(&lhba->schlock.elx_lock, flag);
+	return;
+}
+
+void
+elx_ioc_init_lock(elxHBA_t * phba)
+{
+	LINUX_HBA_t *lhba;
+
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_init(&lhba->ioclock.elx_lock);
+	return;
+}
+
+void
+elx_ioc_lock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = 0;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_irqsave(&lhba->ioclock.elx_lock, flag);
+	*iflag = flag;
+	return;
+}
+
+void
+elx_ioc_unlock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = *iflag;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_unlock_irqrestore(&lhba->ioclock.elx_lock, flag);
+	return;
+}
+
+void
+elx_drvr_init_lock(elxHBA_t * phba)
+{
+	LINUX_HBA_t *lhba;
+
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_init(&lhba->drvrlock.elx_lock);
+	return;
+}
+
+void
+elx_drvr_lock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+	int i;
+
+	if (phba) {
+		flag = 0;
+		lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+		spin_lock_irqsave(&lhba->drvrlock.elx_lock, flag);
+		*iflag = flag;
+		phba->iflag = flag;
+	} else {
+
+		flag = 0;
+		for (i = 0; i < elxDRVR.num_devs; i++) {
+			if ((phba = elxDRVR.pHba[i]) != 0) {
+				flag = 0;
+				lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+				spin_lock_irqsave(&lhba->drvrlock.elx_lock,
+						  flag);
+				*iflag++ = flag;
+				phba->iflag = flag;
+			}
+		}
+	}
+	return;
+}
+
+void
+elx_drvr_unlock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+	int i;
+
+	if (phba) {
+		flag = phba->iflag;
+		lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+		spin_unlock_irqrestore(&lhba->drvrlock.elx_lock, flag);
+	} else {
+
+		iflag += (elxDRVR.num_devs - 1);
+		for (i = (elxDRVR.num_devs - 1); i >= 0; i--) {
+			if ((phba = elxDRVR.pHba[i]) != 0) {
+				flag = phba->iflag;
+				lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+				spin_unlock_irqrestore(&lhba->drvrlock.elx_lock,
+						       flag);
+			}
+		}
+	}
+	return;
+}
+
+void
+elx_clk_init_lock(elxHBA_t * phba)
+{
+	LINUX_DRVR_t *ldrvr;
+
+	/* This lock is per driver */
+	ldrvr = (LINUX_DRVR_t *) elxDRVR.pDrvrOSEnv;
+	spin_lock_init(&ldrvr->clklock.elx_lock);
+	return;
+}
+
+void
+elx_clk_lock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_DRVR_t *ldrvr;
+
+	/* This lock is per driver */
+	flag = 0;
+	ldrvr = (LINUX_DRVR_t *) elxDRVR.pDrvrOSEnv;
+	spin_lock_irqsave(&ldrvr->clklock.elx_lock, flag);
+	elxDRVR.cflag = flag;
+	*iflag = flag;
+	return;
+}
+
+void
+elx_clk_unlock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_DRVR_t *ldrvr;
+
+	flag = elxDRVR.cflag;
+	ldrvr = (LINUX_DRVR_t *) elxDRVR.pDrvrOSEnv;
+	spin_unlock_irqrestore(&ldrvr->clklock.elx_lock, flag);
+	return;
+}
+
+void
+elx_disc_init_lock(elxHBA_t * phba)
+{
+	LINUX_HBA_t *lhba;
+
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_init(&lhba->disclock.elx_lock);
+	return;
+}
+
+void
+elx_hipri_init_lock(elxHBA_t * phba)
+{
+	LINUX_HBA_t *lhba;
+
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_init(&lhba->hiprilock.elx_lock);
+	return;
+}
+
+void
+elx_hipri_lock(elxHBA_t * phba, unsigned long *iflag)
+{
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = 0;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_irqsave(&lhba->hiprilock.elx_lock, flag);
+	*iflag = flag;
+	return;
+}
+
+void
+elx_hipri_unlock(elxHBA_t * phba, unsigned long *iflag)
+{
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = *iflag;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_unlock_irqrestore(&lhba->hiprilock.elx_lock, flag);
+	return;
+}
+
+void
+elx_disc_lock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = 0;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_lock_irqsave(&lhba->disclock.elx_lock, flag);
+	*iflag = flag;
+	return;
+}
+
+void
+elx_disc_unlock(elxHBA_t * phba, unsigned long *iflag)
+{
+
+	unsigned long flag;
+	LINUX_HBA_t *lhba;
+
+	flag = *iflag;
+	lhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	spin_unlock_irqrestore(&lhba->disclock.elx_lock, flag);
+	return;
+}
+
+uint16_t
+elx_read_pci_cmd(elxHBA_t * phba)
+{
+	uint16_t cmd;
+	struct pci_dev *pdev;
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	/*
+	 * PCI device
+	 */
+	pdev = plxhba->pcidev;
+	if (!pdev) {
+		panic("no dev in elx_read_pci_cmd\n");
+		return ((uint16_t) 0);
+	}
+	pci_read_config_word(pdev, PCI_COMMAND, &cmd);
+	return ((uint16_t) cmd);
+}
+
+uint32_t
+elx_read_pci(elxHBA_t * phba, int offset)
+{
+	uint32_t cmd;
+	struct pci_dev *pdev;
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	/*
+	 * PCI device
+	 */
+	pdev = plxhba->pcidev;
+	if (!pdev) {
+		panic("no dev in elx_read_pci\n");
+		return ((ushort) 0);
+	}
+	pci_read_config_dword(pdev, offset, &cmd);
+	return (cmd);
+}
+
+void
+elx_write_pci_cmd(elxHBA_t * phba, uint16_t cfg_value)
+{
+	struct pci_dev *pdev;
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	/*
+	 * PCI device
+	 */
+	pdev = plxhba->pcidev;
+	if (!pdev) {
+		panic("no dev in elx_write_pci_cmd\n");
+		return;
+	}
+	pci_write_config_word(pdev, PCI_COMMAND, cfg_value);
+}
+
+void
+elx_cnt_read_pci(elxHBA_t * phba,
+		 uint32_t offset, uint32_t cnt, uint32_t * pci_space)
+{
+	int i;
+
+	for (i = offset; i < (offset + cnt); i += 4) {
+		*pci_space = elx_read_pci(phba, i);
+		pci_space++;
+	}
+}
+
+void
+elx_cnt_write_pci(elxHBA_t * phba,
+		  uint32_t offset, uint32_t cnt, uint32_t * cfg_value)
+{
+	struct pci_dev *pdev;
+	LINUX_HBA_t *plxhba;
+	int i;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	/*
+	 * PCI device
+	 */
+	pdev = plxhba->pcidev;
+	if (!pdev) {
+		panic("no dev in elx_write_pci_cmd\n");
+		return;
+	}
+
+	for (i = offset; i < (offset + cnt); i += 4) {
+		pci_write_config_dword(pdev, i, *cfg_value);
+		cfg_value++;
+	}
+}
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+int
+elx_biosparam(struct scsi_device *psdev,
+	      struct block_device *pbdev, sector_t capacity, int ip[])
+{
+	int size = capacity;
+#else
+int
+elx_biosparam(Disk * disk, kdev_t n, int ip[])
+{
+	int size = disk->capacity;
+#endif
+
+	ip[0] = 64;
+	ip[1] = 32;
+	ip[2] = size >> 11;
+	if (ip[2] > 1024) {
+		ip[0] = 255;
+		ip[1] = 63;
+		ip[2] = size / (ip[0] * ip[1]);
+#ifndef FC_EXTEND_TRANS_A
+		if (ip[2] > 1023)
+			ip[2] = 1023;
+#endif
+	}
+	return (0);
+}
+
+void *
+elx_remap_pci_mem(unsigned long base, unsigned long size)
+{
+	void *ptr;
+
+	ptr = ioremap(base, size);
+	return (ptr);
+}
+
+void
+elx_unmap_pci_mem(unsigned long vaddr)
+{
+	if (vaddr) {
+		iounmap((void *)(vaddr));
+		/* For some bizarre reason, LINUX used to hang in this
+		 * call when running insmod / rmmod in a loop overnight.
+		 * In later versions of the kernel, this appears to be fixed.
+		 */
+	}
+	return;
+}
+
+int
+elx_pci_getadd(struct pci_dev *pdev, int reg, unsigned long *base)
+{
+	*base = pci_resource_start(pdev, reg);
+	reg++;
+	return (++reg);
+}
+
+void
+elx_write_toio(uint32_t * src, uint32_t * dest_io, uint32_t cnt)
+{
+	uint32_t ldata;
+	int i;
+
+	for (i = 0; i < (int)cnt; i += sizeof (uint32_t)) {
+		ldata = *src++;
+		writel(ldata, dest_io);
+		dest_io++;
+	}
+	return;
+}
+
+void
+elx_read_fromio(uint32_t * src_io, uint32_t * dest, uint32_t cnt)
+{
+	uint32_t ldata;
+	int i;
+
+	for (i = 0; i < (int)cnt; i += sizeof (uint32_t)) {
+		ldata = readl(src_io);
+		src_io++;
+		*dest++ = ldata;
+	}
+	return;
+}
+
+void *
+elx_alloc_bigbuf(elxHBA_t * phba, elx_dma_addr_t * pphys, uint32_t size)
+{
+	void *pcidev;
+	void *virt;
+	LINUX_HBA_t *plxhba;
+	/* pci_alloc_consistent always takes a pointer to dma_addr_t */
+	dma_addr_t phys;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	pcidev = plxhba->pcidev;
+	virt = pci_alloc_consistent(pcidev, size, &phys);
+	if (virt) {
+		prodMallocCnt++;
+		prodMallocByte += size;
+
+		*pphys = phys;
+		return (virt);
+	}
+	return (0);
+}
+
+void
+elx_free_bigbuf(elxHBA_t * phba, void *virt, elx_dma_addr_t phys, uint32_t size)
+{
+	struct pci_dev *pcidev;
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	pcidev = plxhba->pcidev;
+	pci_free_consistent(pcidev, size, virt, phys);
+	prodFreeCnt++;
+	prodFreeByte += size;
+	return;
+}
+
+void
+elx_nodev(unsigned long l)
+{
+	return;
+}
+
+void
+elx_ip_get_rcv_buf(elxHBA_t * phba, DMABUFIP_t * matip, uint32_t size)
+{
+	struct sk_buff *skb;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+
+	skb = alloc_skb(size, GFP_ATOMIC);
+	if (skb) {
+
+		buf_info = &bufinfo;
+		buf_info->phys = INVALID_PHYS;
+		buf_info->virt = skb->data;
+		buf_info->size = size;
+		buf_info->flags = ELX_MBUF_PHYSONLY;
+		elx_malloc(phba, buf_info);
+
+		matip->ipbuf = skb;
+		if (buf_info->phys != INVALID_PHYS) {
+			matip->dma.virt = skb->data;
+			matip->dma.phys = buf_info->phys;
+		} else {
+			elx_ip_free_rcv_buf(phba, matip, size);
+			matip->ipbuf = 0;
+		}
+	}
+	return;
+}
+
+void
+elx_ip_free_rcv_buf(elxHBA_t * phba, DMABUFIP_t * matip, uint32_t size)
+{
+	struct sk_buff *skb;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+
+	while (matip) {
+		skb = matip->ipbuf;
+		if (skb) {
+			if (matip->dma.phys != INVALID_PHYS) {
+				buf_info = &bufinfo;
+				buf_info->phys = matip->dma.phys;
+				buf_info->virt = 0;
+				buf_info->size = size;
+				buf_info->flags = ELX_MBUF_PHYSONLY;
+				elx_free(phba, buf_info);
+			}
+
+			if (in_irq()) {
+				dev_kfree_skb_irq(skb);
+			} else {
+				dev_kfree_skb(skb);
+			}
+		}
+		matip = (DMABUFIP_t *) matip->dma.next;
+	}
+	return;
+}
+
+void
+elx_wakeup(elxHBA_t * phba, void *wait_q_head)
+{
+	wake_up_interruptible((wait_queue_head_t *) wait_q_head);
+	return;
+}
+
+int
+elx_sleep(elxHBA_t * phba, void *wait_q_head, long tmo)
+{
+	wait_queue_t wq_entry;
+	unsigned long iflag = phba->iflag;
+	int rc = 1;
+	long left;
+
+	init_waitqueue_entry(&wq_entry, current);
+	/* start to sleep before we wait, to avoid races */
+	set_current_state(TASK_INTERRUPTIBLE);
+	add_wait_queue((wait_queue_head_t *) wait_q_head, &wq_entry);
+	if (tmo > 0) {
+		ELX_DRVR_UNLOCK(phba, iflag);
+		left = schedule_timeout(tmo * HZ);
+		ELX_DRVR_LOCK(phba, iflag);
+	} else {
+		ELX_DRVR_UNLOCK(phba, iflag);
+		schedule();
+		ELX_DRVR_LOCK(phba, iflag);
+		left = 0;
+	}
+	remove_wait_queue((wait_queue_head_t *) wait_q_head, &wq_entry);
+
+	if (signal_pending(current))
+		return (EINTR);
+	if (rc > 0)
+		return (0);
+	else
+		return (ETIMEDOUT);
+}
+
+uint8_t *
+lpfc_get_lpfchba_info(elxHBA_t * phba, uint8_t * buf)
+{
+
+	LINUX_HBA_t *plxhba;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	elx_str_sprintf(buf,
+			"LINUX_HBA_t structure : \n\n  pci_bar0: 0x%08lx  pci_bar1: 0x%08lx \n HAregaddr: 0x%08lx CAregaddr: 0x%08lx\n HSregaddr: 0x%8lx HCregaddr: 0x%08lx \n",
+			(long unsigned int)plxhba->pci_bar0_map,
+			(long unsigned int)plxhba->pci_bar1_map,
+			(long unsigned int)plxhba->HAregaddr,
+			(long unsigned int)plxhba->CAregaddr,
+			(long unsigned int)plxhba->HSregaddr,
+			(long unsigned int)plxhba->HCregaddr);
+
+	return (buf);
+}
+
+uint64_t
+elx_pci_map(elxHBA_t * phba, void *virt, int size, int dir)
+{
+	dma_addr_t physaddr;
+	LINUX_HBA_t *plxhba;
+#ifdef KERNEL_HAS_PCI_MAP_PAGE
+	struct page *page;
+	unsigned long offset;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	page = virt_to_page(virt);
+	offset = ((unsigned long)virt & ~PAGE_MASK);
+	physaddr = 0;
+	while (physaddr == 0) {
+		physaddr =
+		    pci_map_page(plxhba->pcidev, page, offset, size, dir);
+#ifndef powerpc
+		break;
+#endif				/* endif powerpc */
+	}
+#else
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	physaddr = pci_map_single(plxhba->pcidev, virt, size, dir);
+#endif				/* KERNEL_HAS_PCI_MAP_PAGE */
+	return (uint64_t) physaddr;
+}
+
+void
+lpfc_set_pkt_len(void *buf, uint32_t length)
+{
+	((struct sk_buff *)(buf))->len = length;
+	return;
+}
+
+void *
+lpfc_get_pkt_data(void *buf)
+{
+	return ((void *)(((struct sk_buff *)(buf))->data));
+}
+
+/* Includes. */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+#include <linux/blk.h>
+#else
+#endif
+#include <scsi/scsi.h>
+#include <scsi.h>
+
+#include "elx_os_scsiport.h"
+#include "elx_cfgparm.h"
+
+typedef struct elx_xlat_err {
+	uint16_t iocb_status;
+	uint16_t host_status;
+	uint16_t action_flag;
+} elx_xlat_err_t;
+
+/* Defines for action flags */
+#define ELX_DELAY_IODONE    0x1
+#define ELX_FCPRSP_ERROR    0x2
+#define ELX_IOERR_TABLE     0x4
+#define ELX_STAT_ACTION     0x8
+#define ELX_REQUEUE         0x10
+
+#define ELX_CMD_BEING_RETRIED  0xFFFF
+
+/* This table is indexed by the IOCB ulpStatus */
+
+elx_xlat_err_t elx_iostat_tbl[IOSTAT_CNT] = {
+/* f/w code            host_status   flag */
+
+	{IOSTAT_SUCCESS, DID_OK, 0},	/* 0x0 */
+	{IOSTAT_FCP_RSP_ERROR, DID_OK, ELX_FCPRSP_ERROR},	/* 0x1 */
+	{IOSTAT_REMOTE_STOP, DID_ERROR, 0},	/* 0x2 */
+	{IOSTAT_LOCAL_REJECT, DID_ERROR, ELX_IOERR_TABLE},	/* 0x3 */
+	{IOSTAT_NPORT_RJT, DID_ERROR, ELX_STAT_ACTION},	/* 0x4 */
+	{IOSTAT_FABRIC_RJT, DID_ERROR, ELX_STAT_ACTION},	/* 0x5 */
+	{IOSTAT_NPORT_BSY, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x6 */
+	{IOSTAT_FABRIC_BSY, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x7 */
+	{IOSTAT_INTERMED_RSP, DID_ERROR, 0},	/* 0x8 */
+	{IOSTAT_LS_RJT, DID_ERROR, 0},	/* 0x9 */
+	{IOSTAT_BA_RJT, DID_ERROR, 0},	/* 0xa */
+	{IOSTAT_DRIVER_REJECT, DID_ERROR, ELX_DELAY_IODONE},	/* 0xb */
+	{IOSTAT_ISCSI_REJECT, DID_OK, ELX_REQUEUE},	/* 0xc */
+	{IOSTAT_DEFAULT, DID_ERROR, 0}	/* 0xd */
+};
+
+/* This table is indexed by the IOCB perr.statLocalError */
+
+elx_xlat_err_t elx_ioerr_tbl[IOERR_CNT] = {
+
+/* f/w code                     host_status     flag */
+	{0, DID_ERROR, ELX_DELAY_IODONE},
+	{IOERR_MISSING_CONTINUE, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x1  */
+	{IOERR_SEQUENCE_TIMEOUT, DID_ERROR, ELX_DELAY_IODONE},	/* 0x2  */
+	{IOERR_INTERNAL_ERROR, DID_ERROR, ELX_DELAY_IODONE},	/* 0x3  */
+	{IOERR_INVALID_RPI, DID_ERROR, ELX_DELAY_IODONE},	/* 0x4  */
+	{IOERR_NO_XRI, DID_ERROR, ELX_DELAY_IODONE},	/* 0x5  */
+	{IOERR_ILLEGAL_COMMAND, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x6  */
+	{IOERR_XCHG_DROPPED, DID_ERROR, ELX_DELAY_IODONE},	/* 0x7  */
+	{IOERR_ILLEGAL_FIELD, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x8  */
+	{IOERR_BAD_CONTINUE, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x9  */
+	{IOERR_TOO_MANY_BUFFERS, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0xA  */
+	{IOERR_RCV_BUFFER_WAITING, DID_ERROR, ELX_DELAY_IODONE},	/* 0xB  */
+	{IOERR_NO_CONNECTION, DID_ERROR, ELX_DELAY_IODONE},	/* 0xC  */
+	{IOERR_TX_DMA_FAILED, DID_ERROR, ELX_DELAY_IODONE},	/* 0xD  */
+	{IOERR_RX_DMA_FAILED, DID_ERROR, ELX_DELAY_IODONE},	/* 0xE  */
+	{IOERR_ILLEGAL_FRAME, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0xF  */
+	{IOERR_EXTRA_DATA, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x10 */
+	{IOERR_NO_RESOURCES, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x11 */
+	{0, DID_ERROR, ELX_DELAY_IODONE},	/* 0x12 */
+	{IOERR_ILLEGAL_LENGTH, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x13 */
+	{IOERR_UNSUPPORTED_FEATURE, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x14 */
+	{IOERR_ABORT_IN_PROGRESS, DID_ERROR, ELX_DELAY_IODONE},	/* 0x15 */
+	{IOERR_ABORT_REQUESTED, DID_ERROR, ELX_DELAY_IODONE},	/* 0x16 */
+	{IOERR_RECEIVE_BUFFER_TIMEOUT, DID_ERROR, ELX_DELAY_IODONE},	/* 0x17 */
+	{IOERR_LOOP_OPEN_FAILURE, DID_ERROR, ELX_DELAY_IODONE},	/* 0x18 */
+	{IOERR_RING_RESET, DID_ERROR, ELX_DELAY_IODONE},	/* 0x19 */
+	{IOERR_LINK_DOWN, DID_ERROR, ELX_DELAY_IODONE},	/* 0x1A */
+	{IOERR_CORRUPTED_DATA, DID_ERROR, ELX_DELAY_IODONE},	/* 0x1B */
+	{IOERR_CORRUPTED_RPI, DID_ERROR, ELX_DELAY_IODONE},	/* 0x1C */
+	{IOERR_OUT_OF_ORDER_DATA, DID_ERROR, ELX_DELAY_IODONE},	/* 0x1D */
+	{IOERR_OUT_OF_ORDER_ACK, DID_ERROR, ELX_DELAY_IODONE},	/* 0x1E */
+	{IOERR_DUP_FRAME, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x1F */
+	{IOERR_LINK_CONTROL_FRAME, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x20 */
+	{IOERR_BAD_HOST_ADDRESS, DID_ERROR, ELX_DELAY_IODONE},	/* 0x21 */
+	{IOERR_RCV_HDRBUF_WAITING, DID_ERROR, ELX_DELAY_IODONE},	/* 0x22 */
+	{IOERR_MISSING_HDR_BUFFER, DID_ERROR, ELX_DELAY_IODONE},	/* 0x23 */
+	{IOERR_MSEQ_CHAIN_CORRUPTED, DID_ERROR, ELX_DELAY_IODONE},	/* 0x24 */
+	{IOERR_ABORTMULT_REQUESTED, DID_ERROR, ELX_DELAY_IODONE},	/* 0x25 */
+	{0, DID_ERROR, ELX_DELAY_IODONE},	/* 0x26 */
+	{0, DID_ERROR, ELX_DELAY_IODONE},	/* 0x27 */
+	{IOERR_BUFFER_SHORTAGE, DID_BUS_BUSY, ELX_DELAY_IODONE},	/* 0x28 */
+	{IOERR_DEFAULT, DID_ERROR, ELX_DELAY_IODONE}	/* 0x29 */
+
+};
+
+#define ScsiResult(host_code, scsi_code) (((host_code) << 16) | scsi_code)
+
+#define scsi_sg_dma_address(sc)         sg_dma_address(sc)
+#define scsi_sg_dma_len(sc)             sg_dma_len(sc)
+
+ELXSCSITARGET_t *lpfc_find_target(elxHBA_t *, uint32_t);
+int lpfc_ValidLun(ELXSCSITARGET_t *, uint64_t);
+
+extern int lpfc_use_data_direction;
+
+void elx_scsi_add_timer(Scsi_Cmnd *, int);
+int elx_scsi_delete_timer(Scsi_Cmnd *);
+uint32_t elx_os_fcp_err_handle(ELX_SCSI_BUF_t *, elx_xlat_err_t *);
+
+int
+elx_data_direction(Scsi_Cmnd * Cmnd)
+{
+	int ret_code;
+
+	switch (Cmnd->cmnd[0]) {
+	case WRITE_6:
+	case WRITE_10:
+	case WRITE_12:
+	case CHANGE_DEFINITION:
+	case LOG_SELECT:
+	case MODE_SELECT:
+	case MODE_SELECT_10:
+	case WRITE_BUFFER:
+	case VERIFY:
+	case WRITE_VERIFY:
+	case WRITE_VERIFY_12:
+	case WRITE_LONG:
+	case WRITE_LONG_2:
+	case WRITE_SAME:
+	case SEND_DIAGNOSTIC:
+	case FORMAT_UNIT:
+	case REASSIGN_BLOCKS:
+	case FCP_SCSI_RELEASE_LUNR:
+	case FCP_SCSI_RELEASE_LUNV:
+	case HPVA_SETPASSTHROUGHMODE:
+	case HPVA_EXECUTEPASSTHROUGH:
+	case HPVA_CREATELUN:
+	case HPVA_SETLUNSECURITYLIST:
+	case HPVA_SETCLOCK:
+	case HPVA_RECOVER:
+	case HPVA_GENERICSERVICEOUT:
+	case DMEP_EXPORT_OUT:
+		ret_code = SCSI_DATA_WRITE;
+		break;
+	case MDACIOCTL_DIRECT_CMD:
+		switch (Cmnd->cmnd[2]) {
+		case MDACIOCTL_STOREIMAGE:
+		case MDACIOCTL_WRITESIGNATURE:
+		case MDACIOCTL_SETREALTIMECLOCK:
+		case MDACIOCTL_PASS_THRU_CDB:
+		case MDACIOCTL_CREATENEWCONF:
+		case MDACIOCTL_ADDNEWCONF:
+		case MDACIOCTL_MORE:
+		case MDACIOCTL_SETPHYSDEVPARAMETER:
+		case MDACIOCTL_SETLOGDEVPARAMETER:
+		case MDACIOCTL_SETCONTROLLERPARAMETER:
+		case MDACIOCTL_WRITESANMAP:
+		case MDACIOCTL_SETMACADDRESS:
+			ret_code = SCSI_DATA_WRITE;
+			break;
+		case MDACIOCTL_PASS_THRU_INITIATE:
+			if (Cmnd->cmnd[3] & 0x80) {
+				ret_code = SCSI_DATA_WRITE;
+			} else {
+				ret_code = SCSI_DATA_READ;
+			}
+			break;
+		default:
+			ret_code = SCSI_DATA_READ;
+		}
+		break;
+	default:
+		if (Cmnd->sc_data_direction == SCSI_DATA_WRITE)
+			ret_code = SCSI_DATA_WRITE;
+		else
+			ret_code = SCSI_DATA_READ;
+	}
+
+	Cmnd->sc_data_direction = ret_code;
+	return (ret_code);
+}
+
+int
+elx_os_prep_io(elxHBA_t * phba, ELX_SCSI_BUF_t * elx_cmd)
+{
+	LINUX_HBA_t *plxhba;
+	FCP_CMND *fcp_cmnd;
+	ULP_BDE64 *topbpl;
+	ULP_BDE64 *bpl;
+	DMABUF_t *bmp;
+	DMABUF_t *last_bmp;
+	IOCB_t *cmd;
+	Scsi_Cmnd *cmnd;
+	struct scatterlist *sgel_p;
+#ifdef powerpc
+	struct scatterlist *sgel_p_t0;
+#endif				/* endif powerpc */
+	elx_dma_addr_t physaddr;
+	uint32_t seg_cnt, cnt, i;
+	uint32_t num_bmps, num_bde, max_bde;
+	uint16_t use_sg;
+	int datadir;
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	bpl = elx_cmd->fcp_bpl;
+	fcp_cmnd = elx_cmd->fcp_cmnd;
+
+	bpl += 2;		/* Bump past FCP CMND and FCP RSP */
+	max_bde = ELX_SCSI_INITIAL_BPL_SIZE;
+
+	cmnd = (Scsi_Cmnd *) elx_cmd->pOSCmd;
+	cmd = &elx_cmd->cur_iocbq.iocb;
+
+	/* These are needed if we chain BPLs */
+	last_bmp = elx_cmd->dma_ext;
+	num_bmps = 1;
+	topbpl = 0;
+
+	use_sg = cmnd->use_sg;
+	num_bde = 0;
+	sgel_p = 0;
+
+	/*
+	 * Fill in the FCP CMND
+	 */
+	memcpy((void *)&fcp_cmnd->fcpCdb[0], (void *)cmnd->cmnd, 16);
+
+	if (cmnd->device->tagged_supported) {
+		switch (cmnd->tag) {
+		case HEAD_OF_QUEUE_TAG:
+			fcp_cmnd->fcpCntl1 = HEAD_OF_Q;
+			break;
+		case ORDERED_QUEUE_TAG:
+			fcp_cmnd->fcpCntl1 = ORDERED_Q;
+			break;
+		default:
+			fcp_cmnd->fcpCntl1 = SIMPLE_Q;
+			break;
+		}
+	} else {
+		fcp_cmnd->fcpCntl1 = 0;
+	}
+
+	if (cmnd->cmnd[0] == TEST_UNIT_READY) {
+		goto nodata;
+	}
+
+	if (lpfc_use_data_direction) {
+		datadir = cmnd->sc_data_direction;
+	} else {
+		datadir = elx_data_direction(cmnd);
+	}
+	elx_cmd->OS_io_info.datadir = datadir;
+
+	/* This next section finishes building the BPL for the I/O from the
+	 * scsi_cmnd and updates the IOCB accordingly.
+	 */
+	if (use_sg) {
+		sgel_p = (struct scatterlist *)cmnd->request_buffer;
+#ifdef powerpc			/* remap to get different set of phys adds that xclud zero */
+	      remapsgl:
+#endif				/* endif powerpc */
+		seg_cnt = pci_map_sg(plxhba->pcidev, sgel_p, use_sg,
+				     scsi_to_pci_dma_dir(datadir));
+#ifdef powerpc			/* check for zero phys address, then remap to get diff ones */
+		for (sgel_p_t0 = sgel_p, i = 0; i < seg_cnt; sgel_p_t0++, i++) {
+			if (!scsi_sg_dma_address(sgel_p_t0)) {
+				goto remapsgl;
+			}
+		}
+#endif				/* endif powerpc */
+		cnt = 0;
+		/* scatter-gather list case */
+		for (i = 0; i < seg_cnt; i++) {
+			/* Check to see if current BPL is full of BDEs */
+			if (num_bde == max_bde) {
+				if ((bmp =
+				     (DMABUF_t *) elx_mem_get(phba,
+							      MEM_BPL)) == 0) {
+					break;
+				}
+				max_bde = ((1024 / sizeof (ULP_BDE64)) - 3);
+				/* Fill in continuation entry to next bpl */
+				bpl->addrHigh = putPaddrHigh(bmp->phys);
+				bpl->addrHigh = PCIMEM_LONG(bpl->addrHigh);
+				bpl->addrLow = putPaddrLow(bmp->phys);
+				bpl->addrLow = PCIMEM_LONG(bpl->addrLow);
+				bpl->tus.f.bdeFlags = BPL64_SIZE_WORD;
+				num_bde++;
+				if (num_bmps == 1) {
+					cmd->un.fcpi64.bdl.bdeSize +=
+					    (num_bde * sizeof (ULP_BDE64));
+				} else {
+					topbpl->tus.f.bdeSize =
+					    (num_bde * sizeof (ULP_BDE64));
+					topbpl->tus.w =
+					    PCIMEM_LONG(topbpl->tus.w);
+				}
+				topbpl = bpl;
+				bpl = (ULP_BDE64 *) bmp->virt;
+				last_bmp->next = (void *)bmp;
+				last_bmp = bmp;
+				num_bde = 0;
+				num_bmps++;
+			}
+
+			physaddr = scsi_sg_dma_address(sgel_p);
+
+			bpl->addrLow = PCIMEM_LONG(putPaddrLow(physaddr));
+			bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(physaddr));
+			bpl->tus.f.bdeSize = scsi_sg_dma_len(sgel_p);
+			cnt += bpl->tus.f.bdeSize;
+			if (datadir == SCSI_DATA_WRITE) {
+				bpl->tus.f.bdeFlags = 0;
+			} else {
+				bpl->tus.f.bdeFlags = BUFF_USE_RCV;
+			}
+			bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+			bpl++;
+			sgel_p++;
+			num_bde++;
+		}		/* end for loop */
+
+		if (datadir == SCSI_DATA_WRITE) {
+			cmd->ulpCommand = CMD_FCP_IWRITE64_CR;
+			fcp_cmnd->fcpCntl3 = WRITE_DATA;
+
+			phba->fc4OutputRequests++;
+		} else {
+			cmd->ulpCommand = CMD_FCP_IREAD64_CR;
+			cmd->ulpPU = PARM_READ_CHECK;
+			cmd->un.fcpi.fcpi_parm = cnt;
+			fcp_cmnd->fcpCntl3 = READ_DATA;
+
+			phba->fc4InputRequests++;
+		}
+	} else {
+		if (cmnd->request_buffer && cmnd->request_bufflen) {
+
+			physaddr =
+			    (elx_dma_addr_t) elx_pci_map(phba,
+							 cmnd->request_buffer,
+							 cmnd->request_bufflen,
+							 scsi_to_pci_dma_dir
+							 (datadir));
+
+			/* no scatter-gather list case */
+			elx_cmd->OS_io_info.nonsg_phys = physaddr;
+			bpl->addrLow = PCIMEM_LONG(putPaddrLow(physaddr));
+			bpl->addrHigh = PCIMEM_LONG(putPaddrHigh(physaddr));
+			bpl->tus.f.bdeSize = cmnd->request_bufflen;
+			cnt = cmnd->request_bufflen;
+			if (datadir == SCSI_DATA_WRITE) {
+				cmd->ulpCommand = CMD_FCP_IWRITE64_CR;
+				fcp_cmnd->fcpCntl3 = WRITE_DATA;
+				bpl->tus.f.bdeFlags = 0;
+
+				phba->fc4OutputRequests++;
+			} else {
+				cmd->ulpCommand = CMD_FCP_IREAD64_CR;
+				cmd->ulpPU = PARM_READ_CHECK;
+				cmd->un.fcpi.fcpi_parm = cnt;
+				fcp_cmnd->fcpCntl3 = READ_DATA;
+				bpl->tus.f.bdeFlags = BUFF_USE_RCV;
+
+				phba->fc4InputRequests++;
+			}
+			bpl->tus.w = PCIMEM_LONG(bpl->tus.w);
+			num_bde = 1;
+			bpl++;
+		} else {
+		      nodata:
+			cnt = 0;
+			cmd->ulpCommand = CMD_FCP_ICMND64_CR;
+			cmd->un.fcpi.fcpi_parm = 0;
+			fcp_cmnd->fcpCntl3 = 0;
+
+			phba->fc4ControlRequests++;
+		}
+	}
+	bpl->addrHigh = 0;
+	bpl->addrLow = 0;
+	bpl->tus.w = 0;
+	if (num_bmps == 1) {
+		cmd->un.fcpi64.bdl.bdeSize += (num_bde * sizeof (ULP_BDE64));
+	} else {
+		topbpl->tus.f.bdeSize = (num_bde * sizeof (ULP_BDE64));
+		topbpl->tus.w = PCIMEM_LONG(topbpl->tus.w);
+	}
+	cmd->ulpBdeCount = 1;
+	cmd->ulpLe = 1;		/* Set the LE bit in the iocb */
+
+	/* set the Data Length field in the FCP CMND accordingly */
+	fcp_cmnd->fcpDl = SWAP_DATA(cnt);
+
+	return (0);
+}
+
+int
+elx_queuecommand(Scsi_Cmnd * cmnd, void (*done) (Scsi_Cmnd *))
+{
+	elxHBA_t *phba;
+	LINUX_HBA_t *plxhba;
+	ELX_SCSI_BUF_t *elx_cmd;
+	int ret;
+	void (*old_done) (Scsi_Cmnd *);
+	unsigned long iflag;
+	ELXSCSITARGET_t *targetp;
+	elxCfgParam_t *clp;
+	struct Scsi_Host *host;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+	host = cmnd->device->host;
+#else
+	host = cmnd->host;
+#endif
+
+	phba = (elxHBA_t *) host->hostdata[0];
+	clp = &phba->config[0];
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	ELX_DRVR_LOCK(phba, iflag);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	/* 
+	   if the hba is in blocked state and the command is a retry 
+	   queue the command and retry success 
+	 */
+	if (plxhba->in_retry) {
+		cmnd->scsi_done = done;
+		cmnd->reset_chain = plxhba->cmnd_retry_list;
+		plxhba->cmnd_retry_list = cmnd;
+		cmnd->host_scribble = 0;
+		ELX_DRVR_UNLOCK(phba, iflag);
+		return (0);
+	}
+#endif
+
+	elx_cmd = elx_get_scsi_buf(phba);
+	if (elx_cmd == 0) {
+		if (atomic_read(&plxhba->cmnds_in_flight) == 0
+		    && (host->host_self_blocked == FALSE)) {
+			ELX_DRVR_UNLOCK(phba, iflag);
+			/* there are no other commands which will complete to flush
+			   the queue, so retry */
+			cmnd->result = ScsiResult(DID_BUS_BUSY, 0);
+			done(cmnd);
+			return (0);
+		} else {
+			ELX_DRVR_UNLOCK(phba, iflag);
+			/* tell the midlayer we can't take commands right now */
+			return (1);
+		}
+	}
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+	elx_cmd->scsi_bus = cmnd->device->channel;
+	elx_cmd->scsi_target = cmnd->device->id;
+	elx_cmd->scsi_lun = cmnd->device->lun;
+#else
+	elx_cmd->scsi_bus = cmnd->channel;
+	elx_cmd->scsi_target = cmnd->target;
+	elx_cmd->scsi_lun = cmnd->lun;
+#endif
+
+	targetp = lpfc_find_target(phba, elx_cmd->scsi_target);
+	if ((targetp) && (elx_cmd->scsi_lun >= targetp->max_lun)) {
+		elx_free_scsi_buf(elx_cmd);
+		ELX_DRVR_UNLOCK(phba, iflag);
+		/* error-out this command */
+		cmnd->result = ScsiResult(DID_NO_CONNECT, 0);
+		done(cmnd);
+		return (0);
+	}
+	if ((targetp) && (cmnd->cmnd[0] == FCP_SCSI_INQUIRY) &&
+	    (!lpfc_ValidLun(targetp, elx_cmd->scsi_lun))) {
+		int retcod;
+		uint8_t *buf;
+
+		elx_free_scsi_buf(elx_cmd);
+		if (clp[ELX_CFG_LUN_SKIP].a_current) {
+			buf = (uint8_t *) cmnd->request_buffer;
+			*buf = 0x3;
+			retcod = DID_OK;
+		} else {
+			retcod = DID_NO_CONNECT;
+		}
+
+		ELX_DRVR_UNLOCK(phba, iflag);
+		/* error-out this command */
+		cmnd->result = ScsiResult(retcod, 0);
+		done(cmnd);
+		return (0);
+	}
+
+	/* store our command structure for later */
+	elx_cmd->pOSCmd = (void *)cmnd;
+	cmnd->host_scribble = (unsigned char *)elx_cmd;
+	/* Let the driver time I/Os out, NOT the upper layer */
+	elx_cmd->scsitmo = elx_scsi_delete_timer(cmnd);
+	elx_cmd->timeout = (uint32_t) (cmnd->timeout_per_command / HZ) +
+	    phba->fcp_timeout_offset;
+	/* save original done function in case we can not issue this
+	   command */
+	old_done = cmnd->scsi_done;
+
+	cmnd->scsi_done = done;
+
+	ret = elx_scsi_cmd_start(elx_cmd);
+	if (ret) {
+
+		elx_scsi_add_timer(cmnd, cmnd->timeout_per_command);
+
+		elx_free_scsi_buf(elx_cmd);
+
+		/* restore original done function in command */
+		cmnd->scsi_done = old_done;
+		if (ret < 0) {
+			/* permanent failure -- error out command */
+			cmnd->result = ScsiResult(DID_BAD_TARGET, 0);
+			ELX_DRVR_UNLOCK(phba, iflag);
+			done(cmnd);
+			return (0);
+		} else {
+			if (atomic_read(&plxhba->cmnds_in_flight) == 0) {
+				/* there are no other commands which will complete to
+				   flush the queue, so retry */
+				cmnd->result = ScsiResult(DID_BUS_BUSY, 0);
+				ELX_DRVR_UNLOCK(phba, iflag);
+				done(cmnd);
+				return (0);
+			} else {
+				/* tell the midlayer we can't take commands right now */
+				ELX_DRVR_UNLOCK(phba, iflag);
+				return (1);
+			}
+		}
+	}
+
+	atomic_inc(&plxhba->cmnds_in_flight);
+	ELX_DRVR_UNLOCK(phba, iflag);
+
+	/* Return the error code. */
+	return (0);
+}
+
+int
+elx_abort_handler(Scsi_Cmnd * cmnd)
+{
+	elxHBA_t *phba;
+	ELX_SCSI_BUF_t *elx_cmd;
+	unsigned long iflag;
+	int rc;
+	LINUX_HBA_t *plxhba;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	Scsi_Cmnd *prev_cmnd;
+
+	/* release io_request_lock */
+	spin_unlock_irq(&io_request_lock);
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+	phba = (elxHBA_t *) cmnd->device->host->hostdata[0];
+#else
+	phba = (elxHBA_t *) cmnd->host->hostdata[0];
+#endif
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+
+	ELX_DRVR_LOCK(phba, iflag);
+
+	elx_cmd = (ELX_SCSI_BUF_t *) cmnd->host_scribble;
+
+	/* 
+	   If the command is in retry cahin. delete the command from the
+	   list.
+	 */
+	if (!elx_cmd) {
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+		if (plxhba->cmnd_retry_list) {
+			if (plxhba->cmnd_retry_list == cmnd) {
+				plxhba->cmnd_retry_list = cmnd->reset_chain;
+
+			} else {
+				prev_cmnd = plxhba->cmnd_retry_list;
+
+				while ((prev_cmnd->reset_chain != NULL) &&
+				       (prev_cmnd->reset_chain != cmnd))
+					prev_cmnd = prev_cmnd->reset_chain;
+
+				if (prev_cmnd->reset_chain)
+					prev_cmnd->reset_chain =
+					    cmnd->reset_chain;
+			}
+
+		}
+#endif
+		return (0);
+	}
+
+	/* SCSI layer issued abort device */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0712,	/* ptr to msg structure */
+		       elx_mes0712,	/* ptr to msg */
+		       elx_msgBlk0712.msgPreambleStr,	/* begin varargs */
+		       elx_cmd->scsi_target, elx_cmd->scsi_lun);	/* end varargs */
+
+	/* tell low layer to abort it */
+	rc = elx_scsi_cmd_abort(phba, elx_cmd);
+
+	/* SCSI layer issued abort device */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0749,	/* ptr to msg structure */
+		       elx_mes0749,	/* ptr to msg */
+		       elx_msgBlk0749.msgPreambleStr,	/* begin varargs */
+		       elx_cmd->scsi_target, elx_cmd->scsi_lun, elx_cmd->status, elx_cmd->result);	/* end varargs */
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+	/* reacquire io_request_lock for midlayer */
+	spin_lock_irq(&io_request_lock);
+#endif
+
+	return ((rc == 0) ? SUCCESS : FAILURE);
+
+}
+
+/* This function is now OS-specific and driver-specific */
+
+int
+elx_reset_lun_handler(Scsi_Cmnd * cmnd)
+{
+	elxHBA_t *phba;
+	ELX_SCSI_BUF_t *elx_cmd;
+	unsigned long iflag;
+	int rc;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+	/* release io_request_lock */
+	spin_unlock_irq(&io_request_lock);
+#endif
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,0)
+	phba = (elxHBA_t *) cmnd->device->host->hostdata[0];
+#else
+	phba = (elxHBA_t *) cmnd->host->hostdata[0];
+#endif
+	ELX_DRVR_LOCK(phba, iflag);
+	elx_cmd = (ELX_SCSI_BUF_t *) cmnd->host_scribble;
+
+	/* SCSI layer issued abort device */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0713,	/* ptr to msg structure */
+		       elx_mes0713,	/* ptr to msg */
+		       elx_msgBlk0713.msgPreambleStr,	/* begin varargs */
+		       elx_cmd->scsi_target, elx_cmd->scsi_lun);	/* end varargs */
+
+	rc = elx_scsi_lun_reset(elx_cmd, phba, elx_cmd->scsi_bus,
+				elx_cmd->scsi_target, elx_cmd->scsi_lun,
+				ELX_EXTERNAL_RESET | ELX_ISSUE_ABORT_TSET);
+
+	/* SCSI layer issued abort device */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0747,	/* ptr to msg structure */
+		       elx_mes0747,	/* ptr to msg */
+		       elx_msgBlk0747.msgPreambleStr,	/* begin varargs */
+		       elx_cmd->scsi_target, elx_cmd->scsi_lun, elx_cmd->status, elx_cmd->result);	/* end varargs */
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+
+	/* reacquire io_request_lock for midlayer */
+	spin_lock_irq(&io_request_lock);
+#endif
+
+	return ((rc == 0) ? SUCCESS : FAILURE);
+
+}
+
+void
+freeLun(elxHBA_t * phba, ELX_SCSI_BUF_t * elx_cmd)
+{
+	ELXSCSITARGET_t *targetp;
+	ELXSCSILUN_t *lunp, *curLun, *prevLun;
+	MBUF_INFO_t *buf_info;
+	MBUF_INFO_t bufinfo;
+
+	lunp = elx_cmd->pLun;
+	if (lunp == 0) {
+		return;
+	}
+
+	targetp = lunp->pTarget;
+	if (targetp == 0) {
+		return;
+	}
+
+	elx_sched_remove_lun_from_ring(phba, lunp);
+
+	prevLun = 0;
+	curLun = (ELXSCSILUN_t *) targetp->lunlist.q_first;
+
+	while ((curLun != 0) && (curLun != lunp)) {
+		prevLun = curLun;
+		curLun = prevLun->pnextLun;
+	}
+
+	if (curLun) {
+		if (prevLun) {
+			prevLun->pnextLun = curLun->pnextLun;
+		}
+		if (curLun == (ELXSCSILUN_t *) targetp->lunlist.q_first) {
+			targetp->lunlist.q_first =
+			    (ELX_SLINK_t *) curLun->pnextLun;
+		}
+		if (curLun == (ELXSCSILUN_t *) targetp->lunlist.q_last) {
+			targetp->lunlist.q_last = (ELX_SLINK_t *) prevLun;
+		}
+		targetp->lunlist.q_cnt--;
+
+		buf_info = &bufinfo;
+		memset(buf_info, 0, sizeof (MBUF_INFO_t));
+		buf_info->size = sizeof (ELXSCSILUN_t);
+		buf_info->flags = ELX_MBUF_VIRT;
+		buf_info->align = sizeof (void *);
+		buf_info->virt = lunp;
+		elx_free(phba, buf_info);
+	}
+}
+
+void
+elx_os_return_scsi_cmd(elxHBA_t * phba, ELX_SCSI_BUF_t * elx_cmd)
+{
+	Scsi_Cmnd *lnx_cmnd = (Scsi_Cmnd *) elx_cmd->pOSCmd;
+	elx_xlat_err_t resultdata;
+	elx_xlat_err_t *presult;
+	PARM_ERR *perr;
+	uint32_t host_status;
+	uint32_t scsi_status;
+
+	FCP_CMND *fcp_cmnd;
+
+	if (elx_cmd->status >= IOSTAT_CNT)
+		elx_cmd->status = IOSTAT_DEFAULT;
+	presult = &elx_iostat_tbl[elx_cmd->status];
+
+	host_status = presult->host_status;
+	scsi_status = 0;
+
+	/* Now check if there are any special actions to perform */
+	if (presult->action_flag) {
+
+		/* FCP cmd <cmnd> failed <target>/<lun> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0729,	/* ptr to msg structure */
+			       elx_mes0729,	/* ptr to msg */
+			       elx_msgBlk0729.msgPreambleStr,	/* begin varargs */
+			       lnx_cmnd->cmnd[0], elx_cmd->scsi_target, (uint32_t) elx_cmd->scsi_lun, elx_cmd->status, elx_cmd->result, elx_cmd->IOxri, elx_cmd->cur_iocbq.iocb.ulpIoTag);	/* end varargs */
+
+		if (presult->action_flag & ELX_FCPRSP_ERROR) {
+			presult = &resultdata;
+			presult->host_status = DID_OK;
+			presult->action_flag = 0;
+			/* Call FCP RSP handler to determine result */
+			scsi_status = elx_os_fcp_err_handle(elx_cmd, presult);
+			if (scsi_status == ELX_CMD_BEING_RETRIED) {
+				return;
+			}
+		} else if (presult->action_flag & ELX_REQUEUE) {
+			/* set the Session Failure Recovery flag for this target */
+			elx_cmd->pLun->pnode->nlp_rflag |= NLP_SFR_ACTIVE;
+			/* pause scheduler queue for this device/LUN */
+			elx_sched_pause_target(elx_cmd->pLun->pTarget);
+			/* bypass OS error handling by deleting command's timer */
+			elx_scsi_delete_timer((Scsi_Cmnd *) elx_cmd->pOSCmd);
+			/* put this command back in the scheduler queue */
+			elx_sched_queue_command(phba, elx_cmd);
+			return;
+		} else {
+			elx_cmd->fcp_rsp->rspSnsLen = 0;
+			if (presult->action_flag & ELX_IOERR_TABLE) {
+
+				perr = (PARM_ERR *) & elx_cmd->result;
+				if (perr->statLocalError >= IOERR_CNT)
+					perr->statLocalError = IOERR_DEFAULT;
+				presult = &elx_ioerr_tbl[perr->statLocalError];
+			}
+		}
+		host_status = presult->host_status;
+
+		if (presult->action_flag & ELX_STAT_ACTION) {
+			perr = (PARM_ERR *) & elx_cmd->result;
+			if (perr->statAction == RJT_RETRYABLE) {
+				host_status = DID_BUS_BUSY;
+			}
+		}
+
+		if (presult->action_flag & ELX_DELAY_IODONE) {
+			lnx_cmnd->result = ScsiResult(host_status, scsi_status);
+			elx_scsi_delay_iodone(phba, elx_cmd);
+			return;
+		}
+	} else {
+		elx_cmd->fcp_rsp->rspSnsLen = 0;
+	}
+
+	fcp_cmnd = elx_cmd->fcp_cmnd;
+	if (fcp_cmnd->fcpCdb[0] == FCP_SCSI_INQUIRY) {
+		unsigned char *buf;
+		elxCfgParam_t *clp;
+
+		buf = (unsigned char *)lnx_cmnd->request_buffer;
+		if ((*buf == 0x7f) || ((*buf & 0xE0) == 0x20)) {
+			freeLun(phba, elx_cmd);
+
+			/* If a LINUX OS patch to support, LUN skipping / no LUN 0, is not present,
+			 * this code will fake out the LINUX scsi layer to allow it to detect
+			 * all LUNs if there are LUN holes on a device.
+			 */
+			clp = &phba->config[0];
+			if (clp[ELX_CFG_LUN_SKIP].a_current) {
+				/* Make lun unassigned and wrong type */
+				*buf = 0x3;
+			}
+		}
+	}
+
+	lnx_cmnd->result = ScsiResult(host_status, scsi_status);
+	elx_iodone(phba, elx_cmd);
+
+	return;
+}
+
+void
+elx_scsi_add_timer(Scsi_Cmnd * SCset, int timeout)
+{
+
+	if (SCset->eh_timeout.function != NULL) {
+		del_timer(&SCset->eh_timeout);
+	}
+
+	if (SCset->eh_timeout.data != (unsigned long)SCset) {
+		SCset->eh_timeout.data = (unsigned long)SCset;
+		SCset->eh_timeout.function = (void (*)(unsigned long))elx_nodev;
+	}
+	SCset->eh_timeout.expires = jiffies + timeout;
+
+	add_timer(&SCset->eh_timeout);
+	return;
+}
+
+int
+elx_scsi_delete_timer(Scsi_Cmnd * SCset)
+{
+	int rtn;
+
+	rtn = SCset->eh_timeout.expires - jiffies;
+	del_timer(&SCset->eh_timeout);
+	SCset->eh_timeout.data = (unsigned long)NULL;
+	SCset->eh_timeout.function = NULL;
+	return (rtn);
+}
+
+uint32_t
+elx_os_fcp_err_handle(ELX_SCSI_BUF_t * elx_cmd, elx_xlat_err_t * presult)
+{
+	Scsi_Cmnd *cmnd = (Scsi_Cmnd *) elx_cmd->pOSCmd;
+	FCP_CMND *fcpcmd;
+	FCP_RSP *fcprsp;
+	elxHBA_t *phba;
+	ELXSCSILUN_t *plun;
+	IOCB_t *iocb;
+	elxCfgParam_t *clp;
+	int datadir;
+	uint8_t iostat;
+	uint32_t scsi_status;
+
+	phba = elx_cmd->scsi_hba;
+	plun = elx_cmd->pLun;
+	clp = &phba->config[0];
+	iocb = &elx_cmd->cur_iocbq.iocb;
+	fcpcmd = elx_cmd->fcp_cmnd;
+	fcprsp = elx_cmd->fcp_rsp;
+	iostat = (uint8_t) (elx_cmd->status);
+
+	/* Make sure presult->host_status is identically DID_OK and scsi_status
+	 * is identically 0.  The driver alters this value later on an as-needed
+	 * basis.
+	 */
+	presult->host_status = DID_OK;
+	scsi_status = 0;
+
+	/*
+	 *  If this is a task management command, there is no
+	 *  scsi packet associated with it.  Return here.
+	 */
+	if ((cmnd == NULL) || (fcpcmd->fcpCntl2)) {
+		return (scsi_status);
+	}
+
+	/* FCP cmd failed: RSP */
+	elx_printf_log(phba->brd_no, &elx_msgBlk0730,	/* ptr to msg structure */
+		       elx_mes0730,	/* ptr to msg */
+		       elx_msgBlk0730.msgPreambleStr,	/* begin varargs */
+		       fcprsp->rspStatus2, fcprsp->rspStatus3, SWAP_DATA(fcprsp->rspResId), SWAP_DATA(fcprsp->rspSnsLen), SWAP_DATA(fcprsp->rspRspLen), fcprsp->rspInfo3);	/* end varargs */
+
+	if (fcprsp->rspStatus2 & RSP_LEN_VALID) {
+		if (fcprsp->rspInfo3 != RSP_NO_FAILURE) {
+			presult->host_status = DID_ERROR;
+			scsi_status = (uint32_t) (fcprsp->rspStatus3);
+
+			fcprsp->rspSnsLen = 0;
+			return (scsi_status);
+		}
+	}
+
+	/*
+	 * In the Tape Env., there is an early WARNNING  right before EOM without 
+	 * data xfer error. We should set b_resid to be 0 before we check all other 
+	 * cases.
+	 */
+
+	cmnd->resid = 0;
+
+	if (fcprsp->rspStatus2 & (RESID_UNDER | RESID_OVER)) {
+		if (fcprsp->rspStatus2 & RESID_UNDER) {
+			/* 
+			 * This is not an error! Just setup the resid field. 
+			 */
+			cmnd->resid = SWAP_DATA(fcprsp->rspResId);
+
+			/* FCP Read Underrun, expected <len>, residual <resid> */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0716,	/* ptr to msg structure */
+				       elx_mes0716,	/* ptr to msg */
+				       elx_msgBlk0716.msgPreambleStr,	/* begin varargs */
+				       SWAP_DATA(fcpcmd->fcpDl), cmnd->resid, iocb->un.fcpi.fcpi_parm, cmnd->cmnd[0], cmnd->underflow);	/* end varargs */
+		}
+	} else {
+		datadir = elx_cmd->OS_io_info.datadir;
+
+		if ((datadir == SCSI_DATA_READ) && iocb->un.fcpi.fcpi_parm) {
+			/* 
+			 * This is ALWAYS a readcheck error!! 
+			 * Give Check Condition priority over Read Check 
+			 */
+
+			if (fcprsp->rspStatus3 != SCSI_STAT_CHECK_COND) {
+				/* FCP Read Check Error */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0734,	/* ptr to msg structure */
+					       elx_mes0734,	/* ptr to msg */
+					       elx_msgBlk0734.msgPreambleStr,	/* begin varargs */
+					       SWAP_DATA(fcpcmd->fcpDl), SWAP_DATA(fcprsp->rspResId), iocb->un.fcpi.fcpi_parm, cmnd->cmnd[0]);	/* end varargs */
+
+				presult->host_status = DID_ERROR;
+				cmnd->resid = cmnd->request_bufflen;
+				scsi_status = (uint32_t) (fcprsp->rspStatus3);
+				fcprsp->rspSnsLen = 0;
+				return (scsi_status);
+			}
+
+			/* FCP Read Check Error with Check Condition */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0735,	/* ptr to msg structure */
+				       elx_mes0735,	/* ptr to msg */
+				       elx_msgBlk0735.msgPreambleStr,	/* begin varargs */
+				       SWAP_DATA(fcpcmd->fcpDl), SWAP_DATA(fcprsp->rspResId), iocb->un.fcpi.fcpi_parm, cmnd->cmnd[0]);	/* end varargs */
+		}
+	}
+
+	if (fcprsp->rspStatus2 & RESID_UNDER) {
+		uint32_t len, resid;
+
+		switch (cmnd->cmnd[0]) {
+		case TEST_UNIT_READY:
+		case REQUEST_SENSE:
+		case INQUIRY:
+		case RECEIVE_DIAGNOSTIC:
+		case READ_CAPACITY:
+		case FCP_SCSI_READ_DEFECT_LIST:
+		case MDACIOCTL_DIRECT_CMD:
+			/* No error */
+			fcprsp->rspSnsLen = 0;
+			return (scsi_status);
+		default:
+			len = cmnd->request_bufflen;
+			resid = SWAP_DATA(fcprsp->rspResId);
+			if (!(fcprsp->rspStatus2 & SNS_LEN_VALID) &&
+			    (len - resid < cmnd->underflow)) {
+
+				/* FCP command <cmd> residual underrun converted to error */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0717,	/* ptr to msg structure */
+					       elx_mes0717,	/* ptr to msg */
+					       elx_msgBlk0717.msgPreambleStr,	/* begin varargs */
+					       cmnd->cmnd[0], len, resid, cmnd->underflow);	/* end varargs */
+
+				presult->host_status = DID_ERROR;
+				scsi_status = (uint32_t) (fcprsp->rspStatus3);
+				fcprsp->rspSnsLen = 0;
+				return (scsi_status);
+			}
+		}
+	}
+
+	if ((fcprsp->rspStatus2 & SNS_LEN_VALID) && (fcprsp->rspSnsLen != 0)) {
+		uint32_t snsLen, rspLen;
+
+		rspLen = SWAP_DATA(fcprsp->rspRspLen);
+		snsLen = SWAP_DATA(fcprsp->rspSnsLen);
+		if (snsLen > MAX_ELX_SNS) {
+			snsLen = MAX_ELX_SNS;
+		}
+		memcpy(plun->sense, ((uint8_t *) & fcprsp->rspInfo0) + rspLen,
+		       snsLen);
+		plun->sense_length = snsLen;
+
+		/* then we return this sense info in the sense buffer for this cmd */
+		if (snsLen > SCSI_SENSE_BUFFERSIZE) {
+			snsLen = SCSI_SENSE_BUFFERSIZE;
+		}
+		memcpy(cmnd->sense_buffer, plun->sense, snsLen);
+		plun->sense_valid = 0;
+	} else {
+		fcprsp->rspSnsLen = 0;
+	}
+
+	scsi_status = (uint32_t) (fcprsp->rspStatus3);
+
+	switch (scsi_status) {
+	case SCSI_STAT_QUE_FULL:
+		if (clp[ELX_CFG_DQFULL_THROTTLE_UP_TIME].a_current) {
+			elx_scsi_lower_lun_qthrottle(phba, elx_cmd);
+		}
+		break;
+
+	case SCSI_STAT_CHECK_COND:
+		{
+			uint32_t i;
+			uint32_t cc;
+			uint32_t *lp;
+
+			i = SWAP_DATA(fcprsp->rspRspLen);
+			lp = (uint32_t *) (((uint8_t *) & fcprsp->rspInfo0) +
+					   i);
+			cc = (SWAP_DATA((lp[3]) & SWAP_DATA(0xFF000000)));
+
+			/* <ASC ASCQ> Check condition received */
+			elx_printf_log(phba->brd_no, &elx_msgBlk0737,	/* ptr to msg structure */
+				       elx_mes0737,	/* ptr to msg */
+				       elx_msgBlk0737.msgPreambleStr,	/* begin varargs */
+				       cc, clp[ELX_CFG_CHK_COND_ERR].a_current, clp[ELX_CFG_DELAY_RSP_ERR].a_current, *lp);	/* end varargs */
+
+			switch (cc) {
+			case 0x29000000:
+				/* Retry FCP command due to 29,00 check condition */
+				elx_printf_log(phba->brd_no, &elx_msgBlk0732,	/* ptr to msg structure */
+					       elx_mes0732,	/* ptr to msg */
+					       elx_msgBlk0732.msgPreambleStr,	/* begin varargs */
+					       *lp, *(lp + 1), *(lp + 2), *(lp + 3));	/* end varargs */
+
+				elx_sched_queue_command(phba, elx_cmd);
+				scsi_status = ELX_CMD_BEING_RETRIED;
+				break;
+			case 0x0:	/* ASC and ASCQ = 0 */
+				break;
+			case 0x44000000:	/* Internal Target Failure */
+			case 0x25000000:	/* Login Unit not supported */
+			case 0x20000000:	/* Invalid cmd operation code */
+				/* These will be considered an error if the command is not a TUR
+				 * and CHK_COND_ERR is not set */
+				if ((fcpcmd->fcpCdb[0] !=
+				     FCP_SCSI_TEST_UNIT_READY)
+				    && (clp[ELX_CFG_CHK_COND_ERR].a_current)) {
+					presult->host_status = DID_ERROR;
+					scsi_status = 0;
+				}
+			}
+		}
+		break;
+
+	default:
+		break;
+	}
+	return (scsi_status);
+}
+
+void
+elx_iodone(elxHBA_t * phba, ELX_SCSI_BUF_t * elx_cmd)
+{
+	Scsi_Cmnd *lnx_cmnd = (Scsi_Cmnd *) elx_cmd->pOSCmd;
+	LINUX_HBA_t *plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	uint32_t *lp;
+	int datadir;
+
+	if ((lnx_cmnd->result) || (elx_cmd->fcp_rsp->rspSnsLen)) {
+		lp = (uint32_t *) lnx_cmnd->sense_buffer;
+		/* Iodone <target>/<lun> error <result> SNS <lp> <lp3> */
+		elx_printf_log(phba->brd_no, &elx_msgBlk0710,	/* ptr to msg structure */
+			       elx_mes0710,	/* ptr to msg */
+			       elx_msgBlk0710.msgPreambleStr,	/* begin varargs */
+			       elx_cmd->scsi_target, (uint32_t) elx_cmd->scsi_lun, lnx_cmnd->result, *lp, *(lp + 3), lnx_cmnd->retries, lnx_cmnd->resid);	/* end varargs */
+	}
+
+	datadir = elx_cmd->OS_io_info.datadir;
+	if (lnx_cmnd->use_sg) {
+		pci_unmap_sg(plxhba->pcidev, lnx_cmnd->request_buffer,
+			     lnx_cmnd->use_sg, scsi_to_pci_dma_dir(datadir));
+	} else if ((lnx_cmnd->request_bufflen)
+		   && (elx_cmd->OS_io_info.nonsg_phys)) {
+#if LINUX_VERSION_CODE <= KERNEL_VERSION(2,4,12)
+		pci_unmap_single(plxhba->pcidev,
+				 (uint64_t) ((unsigned long)(elx_cmd->
+							     OS_io_info.
+							     nonsg_phys)),
+				 lnx_cmnd->request_bufflen,
+				 scsi_to_pci_dma_dir(datadir));
+#else
+		pci_unmap_page(plxhba->pcidev,
+			       (uint64_t) ((unsigned long)(elx_cmd->OS_io_info.
+							   nonsg_phys)),
+			       lnx_cmnd->request_bufflen,
+			       scsi_to_pci_dma_dir(datadir));
+#endif
+	}
+
+	elx_free_scsi_buf(elx_cmd);
+
+	plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	/* Queue iodone to be called at end of ISR */
+	if (plxhba->iodone.q_first) {
+		((Scsi_Cmnd *) (plxhba->iodone.q_last))->host_scribble =
+		    (void *)lnx_cmnd;
+	} else {
+		plxhba->iodone.q_first = (ELX_SLINK_t *) lnx_cmnd;
+	}
+	plxhba->iodone.q_last = (ELX_SLINK_t *) lnx_cmnd;
+	plxhba->iodone.q_cnt++;
+	lnx_cmnd->host_scribble = 0;
+
+	return;
+}
+
+int
+elx_scsi_delay_iodone(elxHBA_t * phba, ELX_SCSI_BUF_t * elx_cmd)
+{
+	elxCfgParam_t *clp;
+	uint32_t tmout;
+
+	clp = &phba->config[0];
+
+	if (clp[ELX_CFG_NO_DEVICE_DELAY].a_current) {
+		/* Set a timer so iodone can be called
+		 * for buffer upon expiration.
+		 */
+		tmout = clp[ELX_CFG_NO_DEVICE_DELAY].a_current;
+
+		/* If able to clock set this request, then just return here */
+		if (elx_clk_set
+		    (phba, tmout,
+		     (void (*)(elxHBA_t *, void *, void *))elx_iodone,
+		     (void *)elx_cmd, 0) != 0) {
+			return (1);
+		}
+	}
+	elx_iodone(phba, elx_cmd);
+	return (0);
+}
+
+void
+elx_block_requests(elxHBA_t * phba)
+{
+	LINUX_HBA_t *plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+	plxhba->in_retry = 1;
+	scsi_block_requests(plxhba->host);
+
+}
+
+void
+elx_unblock_requests(elxHBA_t * phba)
+{
+	LINUX_HBA_t *plxhba = (LINUX_HBA_t *) phba->pHbaOSEnv;
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	Scsi_Cmnd *cmnd, *next_cmnd;
+#endif
+	unsigned long iflag;
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+	cmnd = plxhba->cmnd_retry_list;
+	plxhba->in_retry = 0;
+	while (cmnd) {
+		next_cmnd = cmnd->reset_chain;
+		cmnd->reset_chain = 0;
+		cmnd->result = ScsiResult(DID_RESET, 0);
+
+		ELX_DRVR_UNLOCK(phba, iflag);
+		cmnd->scsi_done(cmnd);
+		ELX_DRVR_LOCK(phba, iflag);
+
+		cmnd = next_cmnd;
+	}
+	plxhba->cmnd_retry_list = 0;
+#endif
+	iflag = phba->iflag;
+
+	ELX_DRVR_UNLOCK(phba, iflag);
+	scsi_unblock_requests(plxhba->host);
+	ELX_DRVR_LOCK(phba, iflag);
+	phba->iflag = iflag;
+}
+
+#include <linux/wait.h>
+
+void
+elx_sli_wake_iocb_wait(elxHBA_t * phba,
+		       ELX_IOCBQ_t * queue1, ELX_IOCBQ_t * queue2)
+{
+	wait_queue_head_t *pdone_q;
+
+	queue1->iocb_flag |= ELX_IO_WAIT;
+	if (queue1->context2 && queue2)
+		memcpy(queue1->context2, queue2, sizeof (ELX_IOCBQ_t));
+	pdone_q = (wait_queue_head_t *) queue1->context1;
+	if (pdone_q) {
+		wake_up_interruptible(pdone_q);
+	}
+	/* if pdone_q/context3 was NULL, it means the waiter already gave
+	   up and returned, so we don't have to do anything */
+
+	return;
+}
+
+int
+elx_sli_issue_iocb_wait(elxHBA_t * phba,
+			ELX_SLI_RING_t * pring,
+			ELX_IOCBQ_t * piocb,
+			uint32_t flag,
+			ELX_IOCBQ_t * prspiocbq, uint32_t timeout)
+{
+	DECLARE_WAIT_QUEUE_HEAD(done_q);
+	DECLARE_WAITQUEUE(wq_entry, current);
+	uint32_t timeleft = 0;
+	int retval;
+	unsigned long iflag = phba->iflag;
+
+	/* The caller must leave context1 empty for the driver. */
+	if (piocb->context1 != 0) {
+		return (IOCB_ERROR);
+	}
+	/* If the caller has provided a response iocbq buffer, then context2 
+	 * is NULL or its an error.
+	 */
+	if (prspiocbq) {
+		if (piocb->context2) {
+			return (IOCB_ERROR);
+		}
+		piocb->context2 = prspiocbq;
+	}
+
+	/* setup wake call as IOCB callback */
+	piocb->iocb_cmpl = elx_sli_wake_iocb_wait;
+	/* setup context field to pass wait_queue pointer to wake function  */
+	piocb->context1 = &done_q;
+
+	/* start to sleep before we wait, to avoid races */
+	set_current_state(TASK_INTERRUPTIBLE);
+	add_wait_queue(&done_q, &wq_entry);
+
+	/* now issue the command */
+	retval = elx_sli_issue_iocb(phba, pring, piocb, flag);
+	if ((retval == IOCB_SUCCESS) ||
+	    ((!(flag & SLI_IOCB_RET_IOCB)) && retval == IOCB_BUSY)) {
+		ELX_DRVR_UNLOCK(phba, iflag);
+		timeleft = schedule_timeout(timeout * HZ);
+		ELX_DRVR_LOCK(phba, iflag);
+		piocb->context1 = 0;	/* prevents completion fcn from signalling */
+		piocb->iocb_cmpl = 0;
+		if (piocb->context2 == prspiocbq)
+			piocb->context2 = 0;
+
+		/* if schedule_timeout returns 0, we timed out and were not woken up 
+		 * if ELX_IO_WAIT is not set, we go woken up by a signal.
+		 */
+		if ((timeleft == 0) || !(piocb->iocb_flag & ELX_IO_WAIT)) {
+			if (timeleft == 0)
+				retval = IOCB_TIMEDOUT;
+
+			if (piocb->q_f && piocb->q_b)
+				elx_deque(piocb);
+		}
+	}
+	remove_wait_queue(&done_q, &wq_entry);
+	set_current_state(TASK_RUNNING);
+	return retval;
+}
+
+void
+elx_sli_wake_iocb_high_priority(elxHBA_t * phba,
+				ELX_IOCBQ_t * queue1, ELX_IOCBQ_t * queue2)
+{
+	if (queue1->context2 && queue2)
+		memcpy(queue1->context2, queue2, sizeof (ELX_IOCBQ_t));
+
+	/* The waiter is looking for a non-zero context3 value 
+	   as a signal to wake up */
+	queue1->context3 = (void *)1;
+
+	return;
+}
+
+int
+elx_sli_issue_iocb_wait_high_priority(elxHBA_t * phba,
+				      ELX_SLI_RING_t * pring,
+				      ELX_IOCBQ_t * piocb,
+				      uint32_t flag,
+				      ELX_IOCBQ_t * prspiocbq, uint32_t timeout)
+{
+	int retval, j;
+	unsigned long drvr_flag = phba->iflag;
+	unsigned long iflag;
+
+	/* The caller must left context1 empty.  */
+	if (piocb->context1 != 0) {
+		return (IOCB_ERROR);
+	}
+	/* If the caller has provided a response iocbq buffer, context2 is NULL
+	 * or its an error.
+	 */
+	if (prspiocbq) {
+		if (piocb->context2) {
+			return (IOCB_ERROR);
+		}
+		piocb->context2 = prspiocbq;
+	}
+
+	/* setup wake call as IOCB callback */
+	piocb->iocb_cmpl = elx_sli_wake_iocb_high_priority;
+
+	/* now issue the command */
+	retval =
+	    elx_sli_issue_iocb(phba, pring, piocb,
+			       flag | SLI_IOCB_HIGH_PRIORITY);
+
+	/* 20 * 50ms is 1sec */
+	for (j = 0; j < 20; j++) {
+		ELX_DRVR_UNLOCK(phba, drvr_flag);
+		mdelay(100);
+		ELX_DRVR_LOCK(phba, drvr_flag);
+
+		elx_hipri_lock(phba, &iflag);
+		if (piocb->context3) {
+			elx_hipri_unlock(phba, &iflag);
+			break;
+		}
+		elx_hipri_unlock(phba, &iflag);
+	}
+
+	retval = IOCB_SUCCESS;
+
+	return retval;
+}
+
+void
+elx_sli_wake_mbox_wait(elxHBA_t * phba, ELX_MBOXQ_t * pmboxq)
+{
+	wait_queue_head_t *pdone_q;
+
+	pdone_q = (wait_queue_head_t *) pmboxq->context1;
+	if (pdone_q)
+		wake_up_interruptible(pdone_q);
+	/* if pdone_q/context3 was NULL, it means the waiter already gave
+	   up and returned, so we don't have to do anything */
+
+	return;
+}
+
+int
+elx_sli_issue_mbox_wait(elxHBA_t * phba, ELX_MBOXQ_t * pmboxq, uint32_t timeout)
+{
+	DECLARE_WAIT_QUEUE_HEAD(done_q);
+	DECLARE_WAITQUEUE(wq_entry, current);
+	uint32_t timeleft = 0;
+	int retval;
+	unsigned long iflag = phba->iflag;
+
+	/* The caller must leave context1 empty. */
+	if (pmboxq->context1 != 0) {
+		return (MBX_NOT_FINISHED);
+	}
+
+	/* setup wake call as IOCB callback */
+	pmboxq->mbox_cmpl = elx_sli_wake_mbox_wait;
+	/* setup context field to pass wait_queue pointer to wake function  */
+	pmboxq->context1 = &done_q;
+
+	/* start to sleep before we wait, to avoid races */
+	set_current_state(TASK_INTERRUPTIBLE);
+	add_wait_queue(&done_q, &wq_entry);
+
+	/* now issue the command */
+	retval = elx_sli_issue_mbox(phba, pmboxq, MBX_NOWAIT);
+	if (retval == MBX_BUSY || retval == MBX_SUCCESS) {
+		ELX_DRVR_UNLOCK(phba, iflag);
+		timeleft = schedule_timeout(timeout * HZ);
+		ELX_DRVR_LOCK(phba, iflag);
+		pmboxq->context1 = 0;
+	}
+
+	/* if schedule_timeout returns 0, we timed out and were not woken up */
+
+	else if (timeleft == 0) {
+		retval = MBX_TIMEOUT;
+	}
+	set_current_state(TASK_RUNNING);
+	remove_wait_queue(&done_q, &wq_entry);
+	return retval;
+}
diff -p -purNX /suse/olh/kernel/kernel_exclude.txt linux-2.6.3.emulex/drivers/scsi/lpfc/prod_os.h linux-2.6.3/drivers/scsi/lpfc/prod_os.h
--- linux-2.6.3.emulex/drivers/scsi/lpfc/prod_os.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.3/drivers/scsi/lpfc/prod_os.h	2004-03-01 14:55:45.000000000 +0100
@@ -0,0 +1,152 @@
+/*******************************************************************
+ * This file is part of the Emulex Linux Device Driver for         *
+ * Enterprise Fibre Channel Host Bus Adapters.                     *
+ * Refer to the README file included with this package for         *
+ * driver version and adapter support.                             *
+ * Copyright (C) 2004 Emulex Corporation.                          *
+ * www.emulex.com                                                  *
+ *                                                                 *
+ * This program is free software; you can redistribute it and/or   *
+ * modify it under the terms of the GNU General Public License     *
+ * as published by the Free Software Foundation; either version 2  *
+ * of the License, or (at your option) any later version.          *
+ *                                                                 *
+ * This program is distributed in the hope that it will be useful, *
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of  *
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the   *
+ * GNU General Public License for more details, a copy of which    *
+ * can be found in the file COPYING included with this package.    *
+ *******************************************************************/
+
+#include "elx_util.h"
+
+#if defined(RED_HAT_LINUX_KERNEL) && (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,9))
+#define KERNEL_HAS_PCI_MAP_PAGE
+#endif
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(2,4,12))
+#define KERNEL_HAS_PCI_MAP_PAGE
+#endif
+
+#ifdef powerpc
+#include <asm/pci_dma.h>
+/* On powerpc, 0 is a valid physical address */
+#ifdef NO_TCE
+#define INVALID_PHYS       NO_TCE
+#else
+#define INVALID_PHYS       0
+#endif
+
+#else
+#define INVALID_PHYS       0
+#endif				/* powerpc */
+
+#define is_invalid_phys(addr) ((addr) == (void *)((unsigned long)INVALID_PHYS))
+
+typedef struct elx_lck {
+	spinlock_t elx_lock;
+} elx_lck_t;
+
+/* Per Driver info */
+typedef struct elxLinuxDriver {
+	elx_lck_t clklock;
+} LINUX_DRVR_t;
+
+/* Per HBA info */
+typedef struct elxLinuxHba {
+	struct Scsi_Host *host;
+	struct pci_dev *pcidev;
+	elx_lck_t drvrlock;
+	elx_lck_t slilock;
+	elx_lck_t memlock;
+	elx_lck_t schlock;
+	elx_lck_t disclock;
+	elx_lck_t ioclock;
+	ELX_SLINK_t iodone;
+	elx_lck_t hiprilock;
+	atomic_t cmnds_in_flight;
+	struct net_device_stats ndstats;
+
+	void *pci_bar0_map;	/* mapped address for PCI BAR0 */
+	void *pci_bar1_map;	/* mapped address for PCI BAR1 */
+
+	void *MBslimaddr;	/* virtual address for mbox cmds */
+	void *HAregaddr;	/* virtual address for host attn reg */
+	void *CAregaddr;	/* virtual address for chip attn reg */
+	void *HSregaddr;	/* virtual address for host status reg */
+	void *HCregaddr;	/* virtual address for host ctl reg */
+	wait_queue_head_t linkevtwq;
+	wait_queue_head_t rscnevtwq;
+	wait_queue_head_t ctevtwq;
+
+	struct scsi_cmnd *cmnd_retry_list;
+	int in_retry;
+
+} LINUX_HBA_t;
+
+/* Per Target info */
+typedef struct elxLinuxTgt {
+} LINUX_TGT_t;
+
+/* Per LUN info */
+typedef struct elxLinuxLun {
+	void *scsi_dev;
+	uint32_t scpcnt;
+} LINUX_LUN_t;
+
+/* Per SCSI cmd info */
+typedef struct elxLinuxBuf {
+	uint32_t timeout;	/* Fill in how OS represents a time stamp */
+	uint32_t offset;
+	uint32_t *fc_cmd_dma_handle;
+} LINUX_BUF_t;
+
+typedef uint32_t elx_lun_t;
+
+typedef struct sc_buf T_SCSIBUF;
+#define SET_ADAPTER_STATUS(bp, val) bp->general_card_status = val;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,3,17)
+#define  NETDEVICE struct net_device
+#else
+#define  NETDEVICE struct device
+#endif
+
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,3,43)
+#define netif_start_queue(dev)  clear_bit(0, (void*)&dev->tbusy)
+#define netif_stop_queue(dev)   set_bit(0, (void*)&dev->tbusy)
+#define netdevice_start(dev)    dev->start = 1
+#define netdevice_stop(dev)     dev->start = 0
+#define dev_kfree_skb_irq(a)    dev_kfree_skb(a)
+#else
+#define netdevice_start(dev)
+#define netdevice_stop(dev)
+#endif
+
+/* forward declaration for compiler */
+struct elxHBA;
+
+struct lpfn_probe {
+	int (*open) (NETDEVICE *);
+	int (*stop) (NETDEVICE *);
+	int (*hard_start_xmit) (struct sk_buff *, NETDEVICE *);
+	int (*hard_header) (struct sk_buff *, NETDEVICE *,
+			    unsigned short, void *, void *, unsigned);
+	int (*rebuild_header) (struct sk_buff *);
+	void (*receive) (struct elxHBA *, void *, uint32_t);
+	struct net_device_stats *(*get_stats) (NETDEVICE *);
+	int (*change_mtu) (NETDEVICE *, int);
+	int (*probe) (void);
+};
+#define LPFN_PROBE  1
+#define LPFN_DETACH 2
+#define LPFN_DFC    3
+
+/* SCSI Layer io_request locking macros */
+#if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,0)
+ /* io_request_lock is not present in 2.6.0 */
+#define LPFC_LOCK_SCSI_DONE    spin_lock_irqsave(&io_request_lock, sflag)
+#define LPFC_UNLOCK_SCSI_DONE  spin_unlock_irqrestore(&io_request_lock, sflag)
+#else
+#define LPFC_LOCK_SCSI_DONE    spin_lock_irqsave(host->host_lock, sflag)
+#define LPFC_UNLOCK_SCSI_DONE  spin_unlock_irqrestore(host->host_lock, sflag)
+#endif
