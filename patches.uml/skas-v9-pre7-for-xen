Subject: skas3 bits for xen.
From: kraxel@suse.de

Index: linux-2.6.14/arch/i386/xen/kernel/ldt.c
===================================================================
--- linux-2.6.14.orig/arch/i386/xen/kernel/ldt.c	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/arch/i386/xen/kernel/ldt.c	2005-12-02 17:33:32.000000000 +0100
@@ -28,11 +28,12 @@ static void flush_ldt(void *null)
 }
 #endif
 
-static int alloc_ldt(mm_context_t *pc, int mincount, int reload)
+static int alloc_ldt(struct mm_struct *mm, int mincount, int reload)
 {
 	void *oldldt;
 	void *newldt;
 	int oldsize;
+	mm_context_t * pc = &mm->context;
 
 	if (mincount <= pc->size)
 		return 0;
@@ -62,7 +63,8 @@ static int alloc_ldt(mm_context_t *pc, i
 #endif
 		make_pages_readonly(pc->ldt, (pc->size * LDT_ENTRY_SIZE) /
 				    PAGE_SIZE);
-		load_LDT(pc);
+		if (&current->active_mm->context == pc)
+			load_LDT(pc);
 #ifdef CONFIG_SMP
 		mask = cpumask_of_cpu(smp_processor_id());
 		if (!cpus_equal(current->mm->cpu_vm_mask, mask))
@@ -81,13 +83,13 @@ static int alloc_ldt(mm_context_t *pc, i
 	return 0;
 }
 
-static inline int copy_ldt(mm_context_t *new, mm_context_t *old)
+static inline int copy_ldt(struct mm_struct *new, struct mm_struct *old)
 {
-	int err = alloc_ldt(new, old->size, 0);
+	int err = alloc_ldt(new, old->context.size, 0);
 	if (err < 0)
 		return err;
-	memcpy(new->ldt, old->ldt, old->size*LDT_ENTRY_SIZE);
-	make_pages_readonly(new->ldt, (new->size * LDT_ENTRY_SIZE) /
+	memcpy(new->context.ldt, old->context.ldt, old->context.size*LDT_ENTRY_SIZE);
+	make_pages_readonly(new->context.ldt, (new->context.size * LDT_ENTRY_SIZE) /
 			    PAGE_SIZE);
 	return 0;
 }
@@ -96,22 +98,24 @@ static inline int copy_ldt(mm_context_t 
  * we do not have to muck with descriptors here, that is
  * done in switch_mm() as needed.
  */
-int init_new_context(struct task_struct *tsk, struct mm_struct *mm)
+int copy_context(struct mm_struct *mm, struct mm_struct *old_mm)
 {
-	struct mm_struct * old_mm;
 	int retval = 0;
 
-	init_MUTEX(&mm->context.sem);
-	mm->context.size = 0;
-	old_mm = current->mm;
 	if (old_mm && old_mm->context.size > 0) {
 		down(&old_mm->context.sem);
-		retval = copy_ldt(&mm->context, &old_mm->context);
+		retval = copy_ldt(mm, old_mm);
 		up(&old_mm->context.sem);
 	}
 	return retval;
 }
 
+int init_new_context(struct task_struct *tsk, struct mm_struct *mm)
+{
+	init_new_empty_context(mm);
+	return copy_context(mm, current->mm);
+}
+
 /*
  * No need to lock the MM as we are the last user
  */
@@ -131,11 +135,11 @@ void destroy_context(struct mm_struct *m
 	}
 }
 
-static int read_ldt(void __user * ptr, unsigned long bytecount)
+static int read_ldt(struct mm_struct * mm, void __user * ptr,
+		    unsigned long bytecount)
 {
 	int err;
 	unsigned long size;
-	struct mm_struct * mm = current->mm;
 
 	if (!mm->context.size)
 		return 0;
@@ -184,9 +188,8 @@ static int read_default_ldt(void __user 
 	return err;
 }
 
-static int write_ldt(void __user * ptr, unsigned long bytecount, int oldmode)
+static int write_ldt(struct mm_struct * mm, void __user * ptr, unsigned long bytecount, int oldmode)
 {
-	struct mm_struct * mm = current->mm;
 	__u32 entry_1, entry_2;
 	int error;
 	struct user_desc ldt_info;
@@ -210,7 +213,7 @@ static int write_ldt(void __user * ptr, 
 
 	down(&mm->context.sem);
 	if (ldt_info.entry_number >= mm->context.size) {
-		error = alloc_ldt(&current->mm->context, ldt_info.entry_number+1, 1);
+		error = alloc_ldt(mm, ldt_info.entry_number+1, 1);
 		if (error < 0)
 			goto out_unlock;
 	}
@@ -240,23 +243,33 @@ out:
 	return error;
 }
 
-asmlinkage int sys_modify_ldt(int func, void __user *ptr, unsigned long bytecount)
+int __modify_ldt(struct mm_struct * mm, int func, void __user *ptr,
+	       unsigned long bytecount)
 {
 	int ret = -ENOSYS;
 
 	switch (func) {
 	case 0:
-		ret = read_ldt(ptr, bytecount);
+		ret = read_ldt(mm, ptr, bytecount);
 		break;
 	case 1:
-		ret = write_ldt(ptr, bytecount, 1);
+		ret = write_ldt(mm, ptr, bytecount, 1);
 		break;
 	case 2:
 		ret = read_default_ldt(ptr, bytecount);
 		break;
 	case 0x11:
-		ret = write_ldt(ptr, bytecount, 0);
+		ret = write_ldt(mm, ptr, bytecount, 0);
 		break;
 	}
 	return ret;
 }
+
+asmlinkage int sys_modify_ldt(int func, void __user *ptr, unsigned long bytecount)
+{
+	int ret = __modify_ldt(current->mm, func, ptr, bytecount);
+	/* A tail call would reorder parameters on the stack and they would then
+	 * be restored at the wrong places. */
+	prevent_tail_call(ret);
+	return ret;
+}
Index: linux-2.6.14/arch/x86_64/xen/kernel/ldt.c
===================================================================
--- linux-2.6.14.orig/arch/x86_64/xen/kernel/ldt.c	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/arch/x86_64/xen/kernel/ldt.c	2005-12-02 17:33:14.000000000 +0100
@@ -23,6 +23,7 @@
 #include <asm/desc.h>
 #include <asm/proto.h>
 #include <asm/pgalloc.h>
+#include <asm/mmu_context.h>
 
 #ifdef CONFIG_SMP /* avoids "defined but not used" warnig */
 static void flush_ldt(void *null)
@@ -32,11 +33,12 @@ static void flush_ldt(void *null)
 }
 #endif
 
-static int alloc_ldt(mm_context_t *pc, unsigned mincount, int reload)
+static int alloc_ldt(struct mm_struct *mm, unsigned mincount, int reload)
 {
 	void *oldldt;
 	void *newldt;
 	unsigned oldsize;
+	mm_context_t * pc = &mm->context;
 
 	if (mincount <= (unsigned)pc->size)
 		return 0;
@@ -66,10 +68,11 @@ static int alloc_ldt(mm_context_t *pc, u
 #endif
 		make_pages_readonly(pc->ldt, (pc->size * LDT_ENTRY_SIZE) /
 				    PAGE_SIZE);
-		load_LDT(pc);
+		if (&current->active_mm->context == pc)
+			load_LDT(pc);
 #ifdef CONFIG_SMP
 		mask = cpumask_of_cpu(smp_processor_id());
-		if (!cpus_equal(current->mm->cpu_vm_mask, mask))
+		if (!cpus_equal(mm->cpu_vm_mask, mask))
 			smp_call_function(flush_ldt, NULL, 1, 1);
 		preempt_enable();
 #endif
@@ -85,13 +88,13 @@ static int alloc_ldt(mm_context_t *pc, u
 	return 0;
 }
 
-static inline int copy_ldt(mm_context_t *new, mm_context_t *old)
+static inline int copy_ldt(struct mm_struct *new, struct mm_struct *old)
 {
-	int err = alloc_ldt(new, old->size, 0);
+	int err = alloc_ldt(new, old->context.size, 0);
 	if (err < 0)
 		return err;
-	memcpy(new->ldt, old->ldt, old->size*LDT_ENTRY_SIZE);
-	make_pages_readonly(new->ldt, (new->size * LDT_ENTRY_SIZE) /
+	memcpy(new->context.ldt, old->context.ldt, old->context.size*LDT_ENTRY_SIZE);
+	make_pages_readonly(new->context.ldt, (new->context.size * LDT_ENTRY_SIZE) /
 			    PAGE_SIZE);
 	return 0;
 }
@@ -100,17 +103,14 @@ static inline int copy_ldt(mm_context_t 
  * we do not have to muck with descriptors here, that is
  * done in switch_mm() as needed.
  */
-int init_new_context(struct task_struct *tsk, struct mm_struct *mm)
+int copy_context(struct mm_struct *mm, struct mm_struct *old_mm)
 {
-	struct mm_struct * old_mm;
 	int retval = 0;
 
 	memset(&mm->context, 0, sizeof(mm->context));
-	init_MUTEX(&mm->context.sem);
-	old_mm = current->mm;
 	if (old_mm && old_mm->context.size > 0) {
 		down(&old_mm->context.sem);
-		retval = copy_ldt(&mm->context, &old_mm->context);
+		retval = copy_ldt(mm, old_mm);
 		up(&old_mm->context.sem);
 	}
 	if (retval == 0) {
@@ -121,6 +121,12 @@ int init_new_context(struct task_struct 
 	return retval;
 }
 
+int init_new_context(struct task_struct *tsk, struct mm_struct *mm)
+{
+	init_new_empty_context(mm);
+	return copy_context(mm, current->mm);
+}
+
 /*
  * 
  * Don't touch the LDT register - we're already in the next thread.
@@ -146,11 +152,10 @@ void destroy_context(struct mm_struct *m
 	}
 }
 
-static int read_ldt(void __user * ptr, unsigned long bytecount)
+static int read_ldt(struct mm_struct * mm, void __user * ptr, unsigned long bytecount)
 {
 	int err;
 	unsigned long size;
-	struct mm_struct * mm = current->mm;
 
 	if (!mm->context.size)
 		return 0;
@@ -191,10 +196,8 @@ static int read_default_ldt(void __user 
 	return bytecount; 
 }
 
-static int write_ldt(void __user * ptr, unsigned long bytecount, int oldmode)
+static int write_ldt(struct mm_struct * mm, void __user * ptr, unsigned long bytecount, int oldmode)
 {
-	struct task_struct *me = current;
-	struct mm_struct * mm = me->mm;
 	__u32 entry_1, entry_2, *lp;
 	unsigned long mach_lp;
 	int error;
@@ -219,7 +222,7 @@ static int write_ldt(void __user * ptr, 
 
 	down(&mm->context.sem);
 	if (ldt_info.entry_number >= (unsigned)mm->context.size) {
-		error = alloc_ldt(&current->mm->context, ldt_info.entry_number+1, 1);
+		error = alloc_ldt(mm, ldt_info.entry_number+1, 1);
 		if (error < 0)
 			goto out_unlock;
 	}
@@ -251,23 +254,29 @@ out:
 	return error;
 }
 
-asmlinkage int sys_modify_ldt(int func, void __user *ptr, unsigned long bytecount)
+int __modify_ldt(struct mm_struct * mm, int func, void __user *ptr,
+		unsigned long bytecount)
 {
 	int ret = -ENOSYS;
 
 	switch (func) {
 	case 0:
-		ret = read_ldt(ptr, bytecount);
+		ret = read_ldt(mm, ptr, bytecount);
 		break;
 	case 1:
-		ret = write_ldt(ptr, bytecount, 1);
+		ret = write_ldt(mm, ptr, bytecount, 1);
 		break;
 	case 2:
 		ret = read_default_ldt(ptr, bytecount);
 		break;
 	case 0x11:
-		ret = write_ldt(ptr, bytecount, 0);
+		ret = write_ldt(mm, ptr, bytecount, 0);
 		break;
 	}
 	return ret;
 }
+
+asmlinkage int sys_modify_ldt(int func, void __user *ptr, unsigned long bytecount)
+{
+	return __modify_ldt(current->mm, func, ptr, bytecount);
+}
Index: linux-2.6.14/arch/x86_64/xen/mm/Makefile
===================================================================
--- linux-2.6.14.orig/arch/x86_64/xen/mm/Makefile	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/arch/x86_64/xen/mm/Makefile	2005-12-02 17:00:49.000000000 +0100
@@ -13,6 +13,7 @@ i386-obj-y := hypervisor.o ioremap.o
 #c-obj-$(CONFIG_HUGETLB_PAGE) += hugetlbpage.o
 c-obj-$(CONFIG_NUMA) += numa.o
 c-obj-$(CONFIG_K8_NUMA) += k8topology.o
+c-obj-$(CONFIG_PROC_MM) += proc_mm.o
 
 hugetlbpage-y = ../../../i386/mm/hugetlbpage.o
 
Index: linux-2.6.14/include/asm-i386/mach-xen/asm/desc.h
===================================================================
--- linux-2.6.14.orig/include/asm-i386/mach-xen/asm/desc.h	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/include/asm-i386/mach-xen/asm/desc.h	2005-12-02 16:41:58.000000000 +0100
@@ -159,6 +159,9 @@ static inline unsigned long get_desc_bas
 	return base;
 }
 
+extern int __modify_ldt(struct mm_struct * mm, int func, void __user *ptr,
+		      unsigned long bytecount);
+
 #endif /* !__ASSEMBLY__ */
 
 #endif
Index: linux-2.6.14/include/asm-i386/mach-xen/asm/mmu_context.h
===================================================================
--- linux-2.6.14.orig/include/asm-i386/mach-xen/asm/mmu_context.h	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/include/asm-i386/mach-xen/asm/mmu_context.h	2005-12-02 16:41:58.000000000 +0100
@@ -6,13 +6,25 @@
 #include <asm/atomic.h>
 #include <asm/pgalloc.h>
 #include <asm/tlbflush.h>
+#include <asm/semaphore.h>
 
 /*
- * Used for LDT copy/destruction.
+ * Used for LDT initialization/destruction. You cannot copy an LDT with
+ * init_new_context, since it thinks you are passing it a new LDT and won't
+ * deallocate its old content.
  */
 int init_new_context(struct task_struct *tsk, struct mm_struct *mm);
 void destroy_context(struct mm_struct *mm);
 
+/* LDT initialization for a clean environment - needed for SKAS.*/
+static inline void init_new_empty_context(struct mm_struct *mm)
+{
+	init_MUTEX(&mm->context.sem);
+	mm->context.size = 0;
+}
+
+/* LDT copy for SKAS - for the above problem.*/
+int copy_context(struct mm_struct *mm, struct mm_struct *old_mm);
 
 static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
 {
@@ -50,6 +62,10 @@ static inline void switch_mm(struct mm_s
 	int cpu = smp_processor_id();
 	struct mmuext_op _op[2], *op = _op;
 
+#ifdef CONFIG_SMP
+	prev = per_cpu(cpu_tlbstate, cpu).active_mm;
+#endif
+
 	if (likely(prev != next)) {
 		if (!test_bit(PG_pinned, &virt_to_page(next->pgd)->flags))
 			mm_pin(next);
@@ -84,7 +100,6 @@ static inline void switch_mm(struct mm_s
 #if 0 /* XEN: no lazy tlb */
 	else {
 		per_cpu(cpu_tlbstate, cpu).state = TLBSTATE_OK;
-		BUG_ON(per_cpu(cpu_tlbstate, cpu).active_mm != next);
 
 		if (!cpu_test_and_set(cpu, next->cpu_vm_mask)) {
 			/* We were in lazy tlb mode and leave_mm disabled 
Index: linux-2.6.14/include/asm-i386/mach-xen/asm/ptrace.h
===================================================================
--- linux-2.6.14.orig/include/asm-i386/mach-xen/asm/ptrace.h	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/include/asm-i386/mach-xen/asm/ptrace.h	2005-12-02 16:41:58.000000000 +0100
@@ -84,4 +84,33 @@ extern unsigned long profile_pc(struct p
 #endif
 #endif /* __KERNEL__ */
 
+/*For SKAS3 support.*/
+#ifndef _LINUX_PTRACE_STRUCT_DEF
+#define _LINUX_PTRACE_STRUCT_DEF
+
+#define PTRACE_FAULTINFO	  52
+/* 53 was used for PTRACE_SIGPENDING, don't reuse it. */
+#define PTRACE_LDT		  54
+#define PTRACE_SWITCH_MM 	  55
+#define PTRACE_EX_FAULTINFO	  56
+
+struct ptrace_faultinfo {
+	int is_write;
+	unsigned long addr;
+};
+
+struct ptrace_ex_faultinfo {
+	int is_write;
+	unsigned long addr;
+	int trap_no;
+};
+
+struct ptrace_ldt {
+	int func;
+  	void *ptr;
+	unsigned long bytecount;
+};
+
+#endif /*ifndef _LINUX_PTRACE_STRUCT_DEF*/
+
 #endif
Index: linux-2.6.14/include/asm-x86_64/mach-xen/asm/desc.h
===================================================================
--- linux-2.6.14.orig/include/asm-x86_64/mach-xen/asm/desc.h	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/include/asm-x86_64/mach-xen/asm/desc.h	2005-12-02 16:41:58.000000000 +0100
@@ -247,6 +247,9 @@ static inline void load_LDT(mm_context_t
 
 extern struct desc_ptr idt_descr;
 
+extern int __modify_ldt(struct mm_struct * mm, int func, void __user *ptr,
+		unsigned long bytecount);
+
 #endif /* !__ASSEMBLY__ */
 
 #endif
Index: linux-2.6.14/include/asm-x86_64/mach-xen/asm/mmu_context.h
===================================================================
--- linux-2.6.14.orig/include/asm-x86_64/mach-xen/asm/mmu_context.h	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/include/asm-x86_64/mach-xen/asm/mmu_context.h	2005-12-02 16:59:18.000000000 +0100
@@ -9,13 +9,27 @@
 #include <asm/pda.h>
 #include <asm/pgtable.h>
 #include <asm/tlbflush.h>
+#include <asm/semaphore.h>
 
 /*
  * possibly do the LDT unload here?
+ * Used for LDT initialization/destruction. You cannot copy an LDT with
+ * init_new_context, since it thinks you are passing it a new LDT and won't
+ * deallocate its old content.
  */
 int init_new_context(struct task_struct *tsk, struct mm_struct *mm);
 void destroy_context(struct mm_struct *mm);
 
+/* LDT initialization for a clean environment - needed for SKAS.*/
+static inline void init_new_empty_context(struct mm_struct *mm)
+{
+	init_MUTEX(&mm->context.sem);
+	mm->context.size = 0;
+}
+
+/* LDT copy for SKAS - for the above problem.*/
+int copy_context(struct mm_struct *mm, struct mm_struct *old_mm);
+
 static inline void enter_lazy_tlb(struct mm_struct *mm, struct task_struct *tsk)
 {
 #if 0 /*  XEN: no lazy tlb */
@@ -66,6 +80,9 @@ static inline void switch_mm(struct mm_s
 	unsigned cpu = smp_processor_id();
 	struct mmuext_op _op[3], *op = _op;
 
+#ifdef CONFIG_SMP
+	prev = read_pda(active_mm);
+#endif
 	if (likely(prev != next)) {
 		if (!next->context.pinned)
 			mm_pin(next);
@@ -103,8 +120,6 @@ static inline void switch_mm(struct mm_s
 #if 0 /* XEN: no lazy tlb */
 	else {
 		write_pda(mmu_state, TLBSTATE_OK);
-		if (read_pda(active_mm) != next)
-			out_of_line_bug();
 		if(!test_and_set_bit(cpu, &next->cpu_vm_mask)) {
 			/* We were in lazy tlb mode and leave_mm disabled 
 			 * tlb flush IPI delivery. We must reload CR3
Index: linux-2.6.14/include/asm-x86_64/mach-xen/asm/ptrace.h
===================================================================
--- linux-2.6.14.orig/include/asm-x86_64/mach-xen/asm/ptrace.h	2005-12-02 16:41:37.000000000 +0100
+++ linux-2.6.14/include/asm-x86_64/mach-xen/asm/ptrace.h	2005-12-02 16:41:58.000000000 +0100
@@ -64,6 +64,59 @@ struct pt_regs {
 /* top of stack page */ 
 };
 
+/* Stolen from
+#include <linux/compat.h>; we can't include it because
+there is a nasty ciclic include chain.
+*/
+
+#include <asm/types.h>
+
+#define		compat_int_t	s32
+#define		compat_long_t	s32
+#define		compat_uint_t	u32
+#define		compat_ulong_t	u32
+#define		compat_uptr_t	u32
+
+struct ptrace_faultinfo32 {
+	compat_int_t is_write;
+	compat_ulong_t addr;
+};
+
+struct ptrace_ex_faultinfo32 {
+	compat_int_t is_write;
+	compat_ulong_t addr;
+	compat_int_t trap_no;
+};
+
+struct ptrace_ldt32 {
+	compat_int_t func;
+	compat_uptr_t ptr; /*Actually a void pointer on i386, but must be converted.*/
+	compat_ulong_t bytecount;
+};
+
+struct ptrace_faultinfo {
+	int is_write;
+	unsigned long addr;
+};
+
+struct ptrace_ex_faultinfo {
+	int is_write;
+	unsigned long addr;
+	int trap_no;
+};
+
+struct ptrace_ldt {
+	int func;
+  	void *ptr;
+	unsigned long bytecount;
+};
+
+#undef	compat_int_t
+#undef	compat_long_t
+#undef	compat_uint_t
+#undef	compat_ulong_t
+#undef	compat_uptr_t
+
 #endif
 
 /* Arbitrarily choose the same ptrace numbers as used by the Sparc code. */
@@ -74,6 +127,12 @@ struct pt_regs {
 #define PTRACE_GETFPXREGS         18
 #define PTRACE_SETFPXREGS         19
 
+#define PTRACE_FAULTINFO 52
+/* 53 was used for PTRACE_SIGPENDING, don't reuse it. */
+#define PTRACE_LDT 54
+#define PTRACE_SWITCH_MM 55
+#define PTRACE_EX_FAULTINFO	  56
+
 /* only useful for access 32bit programs */
 #define PTRACE_GET_THREAD_AREA    25
 #define PTRACE_SET_THREAD_AREA    26
