diff -purN linux-2.6.5/arch/ppc64/Kconfig linux-2.6.5.ppc64_linus/arch/ppc64/Kconfig
--- linux-2.6.5/arch/ppc64/Kconfig	2004-04-04 03:37:23.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/Kconfig	2004-04-29 11:17:16.000000000 +0000
@@ -248,6 +248,14 @@ source "fs/Kconfig.binfmt"
 
 source "drivers/pci/Kconfig"
 
+config HOTPLUG_CPU
+	bool "Support for hot-pluggable CPUs"
+	depends on SMP && HOTPLUG && EXPERIMENTAL
+	---help---
+	  Say Y here to be able to turn CPUs off and on.
+
+	  Say N if you are unsure.
+
 source "drivers/pcmcia/Kconfig"
 
 source "drivers/pci/hotplug/Kconfig"
diff -purN linux-2.6.5/arch/ppc64/kernel/Makefile linux-2.6.5.ppc64_linus/arch/ppc64/kernel/Makefile
--- linux-2.6.5/arch/ppc64/kernel/Makefile	2004-04-04 03:38:21.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/Makefile	2004-04-29 11:17:16.000000000 +0000
@@ -11,7 +11,7 @@ obj-y               :=	setup.o entry.o t
 			udbg.o binfmt_elf32.o sys_ppc32.o ioctl32.o \
 			ptrace32.o signal32.o rtc.o init_task.o \
 			lmb.o cputable.o cpu_setup_power4.o idle_power4.o \
-			iommu.o
+			iommu.o sysfs.o vio.o
 
 obj-$(CONFIG_PPC_OF) +=	of_device.o
 
@@ -34,7 +34,7 @@ obj-$(CONFIG_PPC_ISERIES) += iSeries_irq
 obj-$(CONFIG_PPC_PSERIES) += pSeries_pci.o pSeries_lpar.o pSeries_hvCall.o \
 			     eeh.o nvram.o pSeries_nvram.o rtasd.o ras.o \
 			     open_pic.o xics.o pSeries_htab.o rtas.o \
-			     chrp_setup.o i8259.o prom.o vio.o pSeries_iommu.o
+			     chrp_setup.o i8259.o prom.o pSeries_iommu.o
 
 obj-$(CONFIG_PROC_FS)		+= proc_ppc64.o
 obj-$(CONFIG_RTAS_FLASH)	+= rtas_flash.o
diff -purN linux-2.6.5/arch/ppc64/kernel/chrp_setup.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/chrp_setup.c
--- linux-2.6.5/arch/ppc64/kernel/chrp_setup.c	2004-04-04 03:36:19.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/chrp_setup.c	2004-04-29 11:17:16.000000000 +0000
@@ -252,7 +252,7 @@ chrp_init(unsigned long r3, unsigned lon
 
 	ppc_md.setup_arch     = chrp_setup_arch;
 	ppc_md.get_cpuinfo    = chrp_get_cpuinfo;
-	if(naca->interrupt_controller == IC_OPEN_PIC) {
+	if (naca->interrupt_controller == IC_OPEN_PIC) {
 		ppc_md.init_IRQ       = pSeries_init_openpic; 
 		ppc_md.get_irq        = openpic_get_irq;
 	} else {
@@ -267,6 +267,7 @@ chrp_init(unsigned long r3, unsigned lon
 	ppc_md.restart        = rtas_restart;
 	ppc_md.power_off      = rtas_power_off;
 	ppc_md.halt           = rtas_halt;
+	ppc_md.panic          = rtas_os_term;
 
 	ppc_md.get_boot_time  = pSeries_get_boot_time;
 	ppc_md.get_rtc_time   = pSeries_get_rtc_time;
diff -purN linux-2.6.5/arch/ppc64/kernel/cputable.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/cputable.c
--- linux-2.6.5/arch/ppc64/kernel/cputable.c	2004-04-04 03:36:14.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/cputable.c	2004-04-29 11:17:16.000000000 +0000
@@ -48,7 +48,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* Power3 */
 	    0xffff0000, 0x00400000, "POWER3 (630)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-		    CPU_FTR_DABR | CPU_FTR_IABR,
+		    CPU_FTR_IABR | CPU_FTR_PMC8,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power3,
@@ -57,7 +57,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* Power3+ */
 	    0xffff0000, 0x00410000, "POWER3 (630+)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-		    CPU_FTR_DABR | CPU_FTR_IABR,
+		    CPU_FTR_IABR | CPU_FTR_PMC8,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power3,
@@ -66,7 +66,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* Northstar */
 	    0xffff0000, 0x00330000, "RS64-II (northstar)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-		    CPU_FTR_DABR | CPU_FTR_IABR,
+		    CPU_FTR_IABR | CPU_FTR_PMC8 | CPU_FTR_MMCRA,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power3,
@@ -75,7 +75,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* Pulsar */
 	    0xffff0000, 0x00340000, "RS64-III (pulsar)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-		    CPU_FTR_DABR | CPU_FTR_IABR,
+		    CPU_FTR_IABR | CPU_FTR_PMC8 | CPU_FTR_MMCRA,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power3,
@@ -84,7 +84,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* I-star */
 	    0xffff0000, 0x00360000, "RS64-III (icestar)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-		    CPU_FTR_DABR | CPU_FTR_IABR,
+		    CPU_FTR_IABR | CPU_FTR_PMC8 | CPU_FTR_MMCRA,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power3,
@@ -93,7 +93,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* S-star */
 	    0xffff0000, 0x00370000, "RS64-IV (sstar)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-		    CPU_FTR_DABR | CPU_FTR_IABR,
+		    CPU_FTR_IABR | CPU_FTR_PMC8 | CPU_FTR_MMCRA,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power3,
@@ -102,7 +102,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* Power4 */
 	    0xffff0000, 0x00350000, "POWER4 (gp)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-	    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_DABR,
+		    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_PMC8 | CPU_FTR_MMCRA,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power4,
@@ -111,7 +111,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* Power4+ */
 	    0xffff0000, 0x00380000, "POWER4+ (gq)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-	    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_DABR,
+		    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_PMC8 | CPU_FTR_MMCRA,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power4,
@@ -120,7 +120,8 @@ struct cpu_spec	cpu_specs[] = {
     {	/* PPC970 */
 	    0xffff0000, 0x00390000, "PPC970",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-	    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_ALTIVEC_COMP | CPU_FTR_CAN_NAP,
+		    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_ALTIVEC_COMP |
+		    CPU_FTR_CAN_NAP | CPU_FTR_PMC8 | CPU_FTR_MMCRA,
 	    COMMON_USER_PPC64 | PPC_FEATURE_HAS_ALTIVEC_COMP,
 	    128, 128,
 	    __setup_cpu_ppc970,
@@ -129,7 +130,8 @@ struct cpu_spec	cpu_specs[] = {
     {	/* PPC970FX */
 	    0xffff0000, 0x003c0000, "PPC970FX",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-	    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_ALTIVEC_COMP | CPU_FTR_CAN_NAP,
+		    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_ALTIVEC_COMP |
+		    CPU_FTR_CAN_NAP | CPU_FTR_PMC8 | CPU_FTR_MMCRA,
 	    COMMON_USER_PPC64 | PPC_FEATURE_HAS_ALTIVEC_COMP,
 	    128, 128,
 	    __setup_cpu_ppc970,
@@ -138,7 +140,18 @@ struct cpu_spec	cpu_specs[] = {
     {	/* Power5 */
 	    0xffff0000, 0x003a0000, "POWER5 (gr)",
 	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-	    CPU_FTR_PPCAS_ARCH_V2,
+		    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_MMCRA | CPU_FTR_SMT |
+		    CPU_FTR_COHERENT_ICACHE | CPU_FTR_LOCKLESS_TLBIE,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power4,
+	    COMMON_PPC64_FW
+    },
+    {	/* Power5 */
+	    0xffff0000, 0x003b0000, "POWER5 (gs)",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
+		    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_MMCRA | CPU_FTR_SMT |
+		    CPU_FTR_COHERENT_ICACHE | CPU_FTR_LOCKLESS_TLBIE,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power4,
@@ -147,7 +160,7 @@ struct cpu_spec	cpu_specs[] = {
     {	/* default match */
 	    0x00000000, 0x00000000, "POWER4 (compatible)",
   	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
-	    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_DABR,
+		    CPU_FTR_PPCAS_ARCH_V2,
 	    COMMON_USER_PPC64,
 	    128, 128,
 	    __setup_cpu_power4,
diff -purN linux-2.6.5/arch/ppc64/kernel/dma.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/dma.c
--- linux-2.6.5/arch/ppc64/kernel/dma.c	2004-04-04 03:36:16.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/dma.c	2004-04-29 11:17:16.000000000 +0000
@@ -5,14 +5,11 @@
  * the pci and vio busses
  */
 
-#include <linux/config.h>
 #include <linux/device.h>
 #include <linux/dma-mapping.h>
 /* Include the busses we support */
 #include <linux/pci.h>
-#ifdef CONFIG_PPC_PSERIES
 #include <asm/vio.h>
-#endif
 #include <asm/scatterlist.h>
 #include <asm/bug.h>
 
@@ -20,10 +17,8 @@ int dma_supported(struct device *dev, u6
 {
 	if (dev->bus == &pci_bus_type)
 		return pci_dma_supported(to_pci_dev(dev), mask);
-#ifdef CONFIG_PPC_PSERIES
 	if (dev->bus == &vio_bus_type)
 		return vio_dma_supported(to_vio_dev(dev), mask);
-#endif
 	BUG();
 	return 0;
 }
@@ -33,10 +28,8 @@ int dma_set_mask(struct device *dev, u64
 {
 	if (dev->bus == &pci_bus_type)
 		return pci_set_dma_mask(to_pci_dev(dev), dma_mask);
-#ifdef CONFIG_PPC_PSERIES
 	if (dev->bus == &vio_bus_type)
 		return vio_set_dma_mask(to_vio_dev(dev), dma_mask);
-#endif
 	BUG();
 	return 0;
 }
@@ -47,10 +40,8 @@ void *dma_alloc_coherent(struct device *
 {
 	if (dev->bus == &pci_bus_type)
 		return pci_alloc_consistent(to_pci_dev(dev), size, dma_handle);
-#ifdef CONFIG_PPC_PSERIES
 	if (dev->bus == &vio_bus_type)
 		return vio_alloc_consistent(to_vio_dev(dev), size, dma_handle);
-#endif
 	BUG();
 	return 0;
 }
@@ -61,10 +52,8 @@ void dma_free_coherent(struct device *de
 {
 	if (dev->bus == &pci_bus_type)
 		pci_free_consistent(to_pci_dev(dev), size, cpu_addr, dma_handle);
-#ifdef CONFIG_PPC_PSERIES
 	else if (dev->bus == &vio_bus_type)
 		vio_free_consistent(to_vio_dev(dev), size, cpu_addr, dma_handle);
-#endif
 	else
 		BUG();
 }
@@ -75,10 +64,8 @@ dma_addr_t dma_map_single(struct device 
 {
 	if (dev->bus == &pci_bus_type)
 		return pci_map_single(to_pci_dev(dev), cpu_addr, size, (int)direction);
-#ifdef CONFIG_PPC_PSERIES
 	if (dev->bus == &vio_bus_type)
-		return vio_map_single(to_vio_dev(dev), cpu_addr, size, (int)direction);
-#endif
+		return vio_map_single(to_vio_dev(dev), cpu_addr, size, direction);
 	BUG();
 	return (dma_addr_t)0;
 }
@@ -89,10 +76,8 @@ void dma_unmap_single(struct device *dev
 {
 	if (dev->bus == &pci_bus_type)
 		pci_unmap_single(to_pci_dev(dev), dma_addr, size, (int)direction);
-#ifdef CONFIG_PPC_PSERIES
 	else if (dev->bus == &vio_bus_type)
-		vio_unmap_single(to_vio_dev(dev), dma_addr, size, (int)direction);
-#endif
+		vio_unmap_single(to_vio_dev(dev), dma_addr, size, direction);
 	else
 		BUG();
 }
@@ -104,10 +89,8 @@ dma_addr_t dma_map_page(struct device *d
 {
 	if (dev->bus == &pci_bus_type)
 		return pci_map_page(to_pci_dev(dev), page, offset, size, (int)direction);
-#ifdef CONFIG_PPC_PSERIES
 	if (dev->bus == &vio_bus_type)
-		return vio_map_page(to_vio_dev(dev), page, offset, size, (int)direction);
-#endif
+		return vio_map_page(to_vio_dev(dev), page, offset, size, direction);
 	BUG();
 	return (dma_addr_t)0;
 }
@@ -118,10 +101,8 @@ void dma_unmap_page(struct device *dev, 
 {
 	if (dev->bus == &pci_bus_type)
 		pci_unmap_page(to_pci_dev(dev), dma_address, size, (int)direction);
-#ifdef CONFIG_PPC_PSERIES
 	else if (dev->bus == &vio_bus_type)
-		vio_unmap_page(to_vio_dev(dev), dma_address, size, (int)direction);
-#endif
+		vio_unmap_page(to_vio_dev(dev), dma_address, size, direction);
 	else
 		BUG();
 }
@@ -132,10 +113,8 @@ int dma_map_sg(struct device *dev, struc
 {
 	if (dev->bus == &pci_bus_type)
 		return pci_map_sg(to_pci_dev(dev), sg, nents, (int)direction);
-#ifdef CONFIG_PPC_PSERIES
 	if (dev->bus == &vio_bus_type)
-		return vio_map_sg(to_vio_dev(dev), sg, nents, (int)direction);
-#endif
+		return vio_map_sg(to_vio_dev(dev), sg, nents, direction);
 	BUG();
 	return 0;
 }
@@ -146,39 +125,9 @@ void dma_unmap_sg(struct device *dev, st
 {
 	if (dev->bus == &pci_bus_type)
 		pci_unmap_sg(to_pci_dev(dev), sg, nhwentries, (int)direction);
-#ifdef CONFIG_PPC_PSERIES
 	else if (dev->bus == &vio_bus_type)
-		vio_unmap_sg(to_vio_dev(dev), sg, nhwentries, (int)direction);
-#endif
+		vio_unmap_sg(to_vio_dev(dev), sg, nhwentries, direction);
 	else
 		BUG();
 }
 EXPORT_SYMBOL(dma_unmap_sg);
-
-void dma_sync_single(struct device *dev, dma_addr_t dma_handle, size_t size,
-		enum dma_data_direction direction)
-{
-	if (dev->bus == &pci_bus_type)
-		pci_dma_sync_single(to_pci_dev(dev), dma_handle, size, (int)direction);
-#ifdef CONFIG_PPC_PSERIES
-	else if (dev->bus == &vio_bus_type)
-		vio_dma_sync_single(to_vio_dev(dev), dma_handle, size, (int)direction);
-#endif
-	else
-		BUG();
-}
-EXPORT_SYMBOL(dma_sync_single);
-
-void dma_sync_sg(struct device *dev, struct scatterlist *sg, int nelems,
-		enum dma_data_direction direction)
-{
-	if (dev->bus == &pci_bus_type)
-		pci_dma_sync_sg(to_pci_dev(dev), sg, nelems, (int)direction);
-#ifdef CONFIG_PPC_PSERIES
-	else if (dev->bus == &vio_bus_type)
-		vio_dma_sync_sg(to_vio_dev(dev), sg, nelems, (int)direction);
-#endif
-	else
-		BUG();
-}
-EXPORT_SYMBOL(dma_sync_sg);
diff -purN linux-2.6.5/arch/ppc64/kernel/eeh.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/eeh.c
--- linux-2.6.5/arch/ppc64/kernel/eeh.c	2004-04-04 03:37:36.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/eeh.c	2004-04-29 11:17:16.000000000 +0000
@@ -395,6 +395,12 @@ unsigned long eeh_check_failure(void *to
 		return val;
 	}
 
+        /* Make sure we aren't ISA */
+        if (!strcmp(dn->type, "isa")) {
+                pci_dev_put(dev);
+                return val;
+        }
+
 	if (!dn->eeh_config_addr) {
 		pci_dev_put(dev);
 		return val;
diff -purN linux-2.6.5/arch/ppc64/kernel/entry.S linux-2.6.5.ppc64_linus/arch/ppc64/kernel/entry.S
--- linux-2.6.5/arch/ppc64/kernel/entry.S	2004-04-04 03:36:14.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/entry.S	2004-04-29 11:17:16.000000000 +0000
@@ -468,6 +468,7 @@ do_work:
 	b	.ret_from_except
 
 unrecov_restore:
+	mfspr   r13,SPRG3
 	addi	r3,r1,STACK_FRAME_OVERHEAD
 	bl	.unrecoverable_exception
 	b	unrecov_restore
@@ -510,12 +511,25 @@ _GLOBAL(enter_rtas)
 	mfsrr1	r10
 	std	r10,_SRR1(r1)
 
+	/* There is no way it is acceptable to get here with interrupts enabled,
+	 * check it with the asm equivalent of WARN_ON
+	 */
+	mfmsr	r6
+	andi.	r0,r6,MSR_EE
+1:	tdnei	r0,0
+.section __bug_table,"a"
+	.llong	1b,__LINE__ + 0x1000000, 1f, 2f
+.previous
+.section .rodata,"a"
+1:	.asciz	__FILE__
+2:	.asciz "enter_rtas"
+.previous
+	
 	/* Unfortunately, the stack pointer and the MSR are also clobbered,
 	 * so they are saved in the PACA which allows us to restore
 	 * our original state after RTAS returns.
          */
 	std	r1,PACAR1(r13)
-	mfmsr	r6
         std	r6,PACASAVEDMSR(r13)
 
 	/* Setup our real return addr */	
diff -purN linux-2.6.5/arch/ppc64/kernel/head.S linux-2.6.5.ppc64_linus/arch/ppc64/kernel/head.S
--- linux-2.6.5/arch/ppc64/kernel/head.S	2004-04-04 03:37:07.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/head.S	2004-04-29 11:17:16.000000000 +0000
@@ -93,8 +93,13 @@
 _stext:
 #ifdef CONFIG_PPC_PSERIES
 _STATIC(__start)
+	/* NOP this out unconditionally */
+BEGIN_FTR_SECTION
 	b .__start_initialization_pSeries
+END_FTR_SECTION(0, 1)
 #endif
+	/* Catch branch to 0 in real mode */
+	trap
 #ifdef CONFIG_PPC_ISERIES
 	/*
 	 * At offset 0x20, there is a pointer to iSeries LPAR data.
@@ -767,6 +772,7 @@ DataAccessSLB_common:
 	beq     fast_exception_return   /* Return if we succeeded */
 	addi	r3,r1,STACK_FRAME_OVERHEAD
 	DO_COPY_EE()
+	ld      r4,_DAR(r1)
 	li	r6,0x380
 	li	r5,0
 	bl      .save_remaining_regs
@@ -810,6 +816,7 @@ InstructionAccessSLB_common:
 
 	addi	r3,r1,STACK_FRAME_OVERHEAD
 	DO_COPY_EE()
+	mr      r4,r22                  /* SRR0 = NIA        */
 	li	r6,0x480
 	li	r5,0
 	bl      .save_remaining_regs
diff -purN linux-2.6.5/arch/ppc64/kernel/i8259.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/i8259.c
--- linux-2.6.5/arch/ppc64/kernel/i8259.c	2004-04-04 03:38:23.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/i8259.c	2004-04-29 11:17:16.000000000 +0000
@@ -124,8 +124,8 @@ static void i8259_unmask_irq(unsigned in
 
 static void i8259_end_irq(unsigned int irq)
 {
-	if (!(irq_desc[irq].status & (IRQ_DISABLED|IRQ_INPROGRESS)) &&
-	    irq_desc[irq].action)
+	if (!(get_irq_desc(irq)->status & (IRQ_DISABLED|IRQ_INPROGRESS)) &&
+	    get_irq_desc(irq)->action)
 		i8259_unmask_irq(irq);
 }
 
diff -purN linux-2.6.5/arch/ppc64/kernel/iSeries_iommu.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/iSeries_iommu.c
--- linux-2.6.5/arch/ppc64/kernel/iSeries_iommu.c	2004-04-04 03:36:15.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/iSeries_iommu.c	2004-04-29 11:17:16.000000000 +0000
@@ -2,24 +2,24 @@
  * arch/ppc64/kernel/iSeries_iommu.c
  *
  * Copyright (C) 2001 Mike Corrigan & Dave Engebretsen, IBM Corporation
- * 
- * Rewrite, cleanup: 
+ *
+ * Rewrite, cleanup:
  *
  * Copyright (C) 2004 Olof Johansson <olof@austin.ibm.com>, IBM Corporation
  *
  * Dynamic DMA mapping support, iSeries-specific parts.
  *
- * 
+ *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License as published by
  * the Free Software Foundation; either version 2 of the License, or
  * (at your option) any later version.
- * 
+ *
  * This program is distributed in the hope that it will be useful,
  * but WITHOUT ANY WARRANTY; without even the implied warranty of
  * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  * GNU General Public License for more details.
- * 
+ *
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
@@ -33,6 +33,7 @@
 #include <linux/spinlock.h>
 #include <linux/string.h>
 #include <linux/pci.h>
+#include <linux/dma-mapping.h>
 #include <asm/io.h>
 #include <asm/prom.h>
 #include <asm/rtas.h>
@@ -43,37 +44,21 @@
 #include <asm/iommu.h>
 #include <asm/pci-bridge.h>
 #include <asm/iSeries/iSeries_pci.h>
-#include <asm/iSeries/vio.h>
 
 #include <asm/machdep.h>
 
 #include "pci.h"
 
 
-static struct iommu_table veth_iommu_table;	/* Tce table for virtual ethernet */
-static struct iommu_table vio_iommu_table;	/* Tce table for virtual I/O */
-
-static struct iSeries_Device_Node veth_dev_node = { .LogicalSlot = 0xFF, .iommu_table = &veth_iommu_table };
-static struct iSeries_Device_Node vio_dev_node  = { .LogicalSlot = 0xFF, .iommu_table = &vio_iommu_table };
-
-static struct pci_dev _veth_dev = { .sysdata = &veth_dev_node };
-static struct pci_dev _vio_dev  = { .sysdata = &vio_dev_node, .dev.bus = &pci_bus_type  };
-
-struct pci_dev *iSeries_veth_dev = &_veth_dev;
-struct device *iSeries_vio_dev = &_vio_dev.dev;
-
-EXPORT_SYMBOL(iSeries_veth_dev);
-EXPORT_SYMBOL(iSeries_vio_dev);
-
 extern struct list_head iSeries_Global_Device_List;
 
 
 static void tce_build_iSeries(struct iommu_table *tbl, long index, long npages,
-			      unsigned long uaddr, int direction)
+		unsigned long uaddr, enum dma_data_direction direction)
 {
 	u64 rc;
 	union tce_entry tce;
-	
+
 	while (npages--) {
 		tce.te_word = 0;
 		tce.te_bits.tb_rpn = virt_to_abs(uaddr) >> PAGE_SHIFT;
@@ -82,17 +67,17 @@ static void tce_build_iSeries(struct iom
 			/* Virtual Bus */
 			tce.te_bits.tb_valid = 1;
 			tce.te_bits.tb_allio = 1;
-			if (direction != PCI_DMA_TODEVICE)
+			if (direction != DMA_TO_DEVICE)
 				tce.te_bits.tb_rdwr = 1;
 		} else {
 			/* PCI Bus */
 			tce.te_bits.tb_rdwr = 1; /* Read allowed */
-			if (direction != PCI_DMA_TODEVICE)
+			if (direction != DMA_TO_DEVICE)
 				tce.te_bits.tb_pciwr = 1;
 		}
-		
-		rc = HvCallXm_setTce((u64)tbl->it_index, 
-				     (u64)index, 
+
+		rc = HvCallXm_setTce((u64)tbl->it_index,
+				     (u64)index,
 				     tce.te_word);
 		if (rc)
 			panic("PCI_DMA: HvCallXm_setTce failed, Rc: 0x%lx\n", rc);
@@ -113,7 +98,7 @@ static void tce_free_iSeries(struct iomm
 				     (u64)index,
 				     tce.te_word);
 
-		if (rc) 
+		if (rc)
 			panic("PCI_DMA: HvCallXm_setTce failed, Rc: 0x%lx\n", rc);
 
 		index++;
@@ -121,50 +106,10 @@ static void tce_free_iSeries(struct iomm
 
 }
 
-void __init iommu_vio_init(void)
-{
-	struct iommu_table *t;
-	struct iommu_table_cb cb;
-	unsigned long cbp;
-
-	cb.itc_busno = 255;    /* Bus 255 is the virtual bus */
-	cb.itc_virtbus = 0xff; /* Ask for virtual bus */
-	
-	cbp = virt_to_abs(&cb);
-	HvCallXm_getTceTableParms(cbp);
-	
-	veth_iommu_table.it_size        = cb.itc_size / 2;
-	veth_iommu_table.it_busno       = cb.itc_busno;
-	veth_iommu_table.it_offset      = cb.itc_offset;
-	veth_iommu_table.it_index       = cb.itc_index;
-	veth_iommu_table.it_type        = TCE_VB;
-	veth_iommu_table.it_entrysize	= sizeof(union tce_entry);
-	veth_iommu_table.it_blocksize	= 1;
-
-	t = iommu_init_table(&veth_iommu_table);
-
-	if (!t)
-		printk("Virtual Bus VETH TCE table failed.\n");
-
-	vio_iommu_table.it_size         = cb.itc_size - veth_iommu_table.it_size;
-	vio_iommu_table.it_busno        = cb.itc_busno;
-	vio_iommu_table.it_offset       = cb.itc_offset +
-		veth_iommu_table.it_size * (PAGE_SIZE/sizeof(union tce_entry));
-	vio_iommu_table.it_index        = cb.itc_index;
-	vio_iommu_table.it_type         = TCE_VB; 
-	vio_iommu_table.it_entrysize	= sizeof(union tce_entry);
-	vio_iommu_table.it_blocksize	= 1;
-
-	t = iommu_init_table(&vio_iommu_table);
-
-	if (!t) 
-		printk("Virtual Bus VIO TCE table failed.\n");
-}
-
 
 /*
  * This function compares the known tables to find an iommu_table
- * that has already been built for hardware TCEs.                          
+ * that has already been built for hardware TCEs.
  */
 static struct iommu_table *iommu_table_find(struct iommu_table * tbl)
 {
@@ -172,26 +117,26 @@ static struct iommu_table *iommu_table_f
 
 	for (dp =  (struct iSeries_Device_Node *)iSeries_Global_Device_List.next;
 	     dp != (struct iSeries_Device_Node *)&iSeries_Global_Device_List;
-	     dp =  (struct iSeries_Device_Node *)dp->Device_List.next) 
+	     dp =  (struct iSeries_Device_Node *)dp->Device_List.next)
 		if (dp->iommu_table                 != NULL &&
 		    dp->iommu_table->it_type        == TCE_PCI &&
 		    dp->iommu_table->it_offset      == tbl->it_offset &&
 		    dp->iommu_table->it_index       == tbl->it_index &&
-		    dp->iommu_table->it_size        == tbl->it_size) 
+		    dp->iommu_table->it_size        == tbl->it_size)
 			return dp->iommu_table;
-			
+
 
 	return NULL;
 }
 
 /*
  * Call Hv with the architected data structure to get TCE table info.
- * info. Put the returned data into the Linux representation of the   
- * TCE table data.                                                     
- * The Hardware Tce table comes in three flavors.                     
- * 1. TCE table shared between Buses.                                  
- * 2. TCE table per Bus.                                               
- * 3. TCE Table per IOA.                                               
+ * info. Put the returned data into the Linux representation of the
+ * TCE table data.
+ * The Hardware Tce table comes in three flavors.
+ * 1. TCE table shared between Buses.
+ * 2. TCE table per Bus.
+ * 3. TCE Table per IOA.
  */
 static void iommu_table_getparms(struct iSeries_Device_Node* dn,
 				 struct iommu_table* tbl)
@@ -200,7 +145,7 @@ static void iommu_table_getparms(struct 
 
 	parms = (struct iommu_table_cb*)kmalloc(sizeof(*parms), GFP_KERNEL);
 
-	if (parms == NULL) 
+	if (parms == NULL)
 		panic("PCI_DMA: TCE Table Allocation failed.");
 
 	memset(parms, 0, sizeof(*parms));
diff -purN linux-2.6.5/arch/ppc64/kernel/iSeries_irq.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/iSeries_irq.c
--- linux-2.6.5/arch/ppc64/kernel/iSeries_irq.c	2004-04-04 03:37:38.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/iSeries_irq.c	2004-04-29 11:17:16.000000000 +0000
@@ -122,8 +122,8 @@ void __init iSeries_activate_IRQs()
 	int irq;
 	unsigned long flags;
 
-	for (irq = 0; irq < NR_IRQS; irq++) {
-		irq_desc_t *desc = &irq_desc[irq];
+	for_each_irq (irq) {
+		irq_desc_t *desc = get_irq_desc(irq);
 
 		if (desc && desc->handler && desc->handler->startup) {
 			spin_lock_irqsave(&desc->lock, flags);
diff -purN linux-2.6.5/arch/ppc64/kernel/iSeries_setup.h linux-2.6.5.ppc64_linus/arch/ppc64/kernel/iSeries_setup.h
--- linux-2.6.5/arch/ppc64/kernel/iSeries_setup.h	2004-04-04 03:37:37.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/iSeries_setup.h	2004-04-29 11:17:16.000000000 +0000
@@ -19,8 +19,6 @@
 #ifndef	__ISERIES_SETUP_H__
 #define	__ISERIES_SETUP_H__
 
-#include <linux/irq.h>		/* for irq_desc_t */
-
 extern void iSeries_init_early(void);
 extern void iSeries_init(unsigned long r3, unsigned long ird_start,
 		unsigned long ird_end, unsigned long cline_start,
@@ -29,7 +27,6 @@ extern void iSeries_setup_arch(void);
 extern void iSeries_setup_residual(struct seq_file *m, int cpu_id);
 extern void iSeries_get_cpuinfo(struct seq_file *m);
 extern void iSeries_init_IRQ(void);
-extern void iSeries_init_irq_desc(irq_desc_t *);
 extern int iSeries_get_irq(struct pt_regs *regs);
 extern void iSeries_restart(char *cmd);
 extern void iSeries_power_off(void);
diff -purN linux-2.6.5/arch/ppc64/kernel/idle.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/idle.c
--- linux-2.6.5/arch/ppc64/kernel/idle.c	2004-04-04 03:37:41.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/idle.c	2004-04-29 11:17:16.000000000 +0000
@@ -26,6 +26,7 @@
 #include <linux/unistd.h>
 #include <linux/slab.h>
 #include <linux/interrupt.h>
+#include <linux/cpu.h>
 
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
@@ -150,17 +151,24 @@ int default_idle(void)
 		}
 
 		schedule();
+		if (cpu_is_offline(smp_processor_id()) &&
+				system_state == SYSTEM_RUNNING)
+			cpu_die();
 	}
 
 	return 0;
 }
 
 #ifdef CONFIG_PPC_PSERIES
+
+DECLARE_PER_CPU(unsigned long, smt_snooze_delay);
+
 int dedicated_idle(void)
 {
 	long oldval;
 	struct paca_struct *lpaca = get_paca(), *ppaca;
 	unsigned long start_snooze;
+	unsigned long *smt_snooze_delay = &__get_cpu_var(smt_snooze_delay);
 
 	ppaca = &paca[smp_processor_id() ^ 1];
 
@@ -173,14 +181,14 @@ int dedicated_idle(void)
 		if (!oldval) {
 			set_thread_flag(TIF_POLLING_NRFLAG);
 			start_snooze = __get_tb() +
-				naca->smt_snooze_delay*tb_ticks_per_usec;
+				*smt_snooze_delay * tb_ticks_per_usec;
 			while (!need_resched()) {
 				/* need_resched could be 1 or 0 at this 
 				 * point.  If it is 0, set it to 0, so
 				 * an IPI/Prod is sent.  If it is 1, keep
 				 * it that way & schedule work.
 				 */
-				if (naca->smt_snooze_delay == 0 ||
+				if (*smt_snooze_delay == 0 ||
 				    __get_tb() < start_snooze) {
 					HMT_low(); /* Low thread priority */
 					continue;
@@ -236,6 +244,9 @@ int dedicated_idle(void)
 		HMT_medium();
 		lpaca->xLpPaca.xIdle = 0;
 		schedule();
+		if (cpu_is_offline(smp_processor_id()) &&
+				system_state == SYSTEM_RUNNING)
+			cpu_die();
 	}
 	return 0;
 }
@@ -245,6 +256,10 @@ int shared_idle(void)
 	struct paca_struct *lpaca = get_paca();
 
 	while (1) {
+		if (cpu_is_offline(smp_processor_id()) &&
+				system_state == SYSTEM_RUNNING)
+			cpu_die();
+
 		/* Indicate to the HV that we are idle.  Now would be
 		 * a good time to find other work to dispatch. */
 		lpaca->xLpPaca.xIdle = 1;
diff -purN linux-2.6.5/arch/ppc64/kernel/iommu.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/iommu.c
--- linux-2.6.5/arch/ppc64/kernel/iommu.c	2004-04-04 03:36:12.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/iommu.c	2004-04-29 11:17:16.000000000 +0000
@@ -31,7 +31,6 @@
 #include <linux/mm.h>
 #include <linux/spinlock.h>
 #include <linux/string.h>
-#include <linux/pci.h>
 #include <linux/dma-mapping.h>
 #include <linux/init.h>
 #include <asm/io.h>
@@ -141,8 +140,8 @@ static unsigned long iommu_range_alloc(s
 	return n;
 }
 
-dma_addr_t iommu_alloc(struct iommu_table *tbl, void *page,
-		       unsigned int npages, int direction)
+static dma_addr_t iommu_alloc(struct iommu_table *tbl, void *page,
+		       unsigned int npages, enum dma_data_direction direction)
 {
 	unsigned long entry, flags;
 	dma_addr_t ret = DMA_ERROR_CODE;
@@ -207,7 +206,7 @@ static void __iommu_free(struct iommu_ta
 		__clear_bit(free_entry+i, tbl->it_map);
 }
 
-void iommu_free(struct iommu_table *tbl, dma_addr_t dma_addr, 
+static void iommu_free(struct iommu_table *tbl, dma_addr_t dma_addr,
 		unsigned int npages)
 {
 	unsigned long flags;
@@ -226,8 +225,9 @@ void iommu_free(struct iommu_table *tbl,
 	spin_unlock_irqrestore(&(tbl->it_lock), flags);
 }
 
-int iommu_alloc_sg(struct iommu_table *tbl, struct device *dev,
-		   struct scatterlist *sglist, int nelems, int direction)
+int iommu_map_sg(struct device *dev, struct iommu_table *tbl,
+		struct scatterlist *sglist, int nelems,
+		enum dma_data_direction direction)
 {
 	dma_addr_t dma_next, dma_addr;
 	unsigned long flags;
@@ -235,6 +235,11 @@ int iommu_alloc_sg(struct iommu_table *t
 	int outcount;
 	unsigned long handle;
 
+	BUG_ON(direction == DMA_NONE);
+
+	if ((nelems == 0) || !tbl)
+		return 0;
+
 	outs = s = segstart = &sglist[0];
 	outcount = 1;
 	handle = 0;
@@ -349,11 +354,16 @@ int iommu_alloc_sg(struct iommu_table *t
 }
 
 
-void iommu_free_sg(struct iommu_table *tbl, struct scatterlist *sglist,
-		   int nelems)
+void iommu_unmap_sg(struct iommu_table *tbl, struct scatterlist *sglist,
+		int nelems, enum dma_data_direction direction)
 {
 	unsigned long flags;
 
+	BUG_ON(direction == DMA_NONE);
+
+	if (!tbl)
+		return;
+
 	spin_lock_irqsave(&(tbl->it_lock), flags);
 
 	while (nelems--) {
@@ -414,3 +424,104 @@ struct iommu_table *iommu_init_table(str
 
 	return tbl;
 }
+
+/* Creates TCEs for a user provided buffer.  The user buffer must be
+ * contiguous real kernel storage (not vmalloc).  The address of the buffer
+ * passed here is the kernel (virtual) address of the buffer.  The buffer
+ * need not be page aligned, the dma_addr_t returned will point to the same
+ * byte within the page as vaddr.
+ */
+dma_addr_t iommu_map_single(struct iommu_table *tbl, void *vaddr,
+		size_t size, enum dma_data_direction direction)
+{
+	dma_addr_t dma_handle = DMA_ERROR_CODE;
+	unsigned long uaddr;
+	unsigned int npages;
+
+	BUG_ON(direction == DMA_NONE);
+
+	uaddr = (unsigned long)vaddr;
+	npages = PAGE_ALIGN(uaddr + size) - (uaddr & PAGE_MASK);
+	npages >>= PAGE_SHIFT;
+
+	if (tbl) {
+		dma_handle = iommu_alloc(tbl, vaddr, npages, direction);
+		if (dma_handle == DMA_ERROR_CODE) {
+			if (printk_ratelimit())  {
+				printk(KERN_INFO "iommu_alloc failed, "
+						"tbl %p vaddr %p npages %d\n",
+						tbl, vaddr, npages);
+			}
+		} else
+			dma_handle |= (uaddr & ~PAGE_MASK);
+	}
+
+	return dma_handle;
+}
+
+void iommu_unmap_single(struct iommu_table *tbl, dma_addr_t dma_handle,
+		size_t size, enum dma_data_direction direction)
+{
+	BUG_ON(direction == DMA_NONE);
+
+	if (tbl)
+		iommu_free(tbl, dma_handle, (PAGE_ALIGN(dma_handle + size) -
+					(dma_handle & PAGE_MASK)) >> PAGE_SHIFT);
+}
+
+/* Allocates a contiguous real buffer and creates mappings over it.
+ * Returns the virtual address of the buffer and sets dma_handle
+ * to the dma address (mapping) of the first page.
+ */
+void *iommu_alloc_consistent(struct iommu_table *tbl, size_t size,
+		dma_addr_t *dma_handle)
+{
+	void *ret = NULL;
+	dma_addr_t mapping;
+	unsigned int npages, order;
+
+	size = PAGE_ALIGN(size);
+	npages = size >> PAGE_SHIFT;
+	order = get_order(size);
+
+ 	/*
+	 * Client asked for way too much space.  This is checked later
+	 * anyway.  It is easier to debug here for the drivers than in
+	 * the tce tables.
+	 */
+	if (order >= IOMAP_MAX_ORDER) {
+		printk("iommu_alloc_consistent size too large: 0x%lx\n", size);
+		return (void *)DMA_ERROR_CODE;
+	}
+
+	if (!tbl)
+		return NULL;
+
+	/* Alloc enough pages (and possibly more) */
+	ret = (void *)__get_free_pages(GFP_ATOMIC, order);
+	if (!ret)
+		return NULL;
+	memset(ret, 0, size);
+
+	/* Set up tces to cover the allocated range */
+	mapping = iommu_alloc(tbl, ret, npages, DMA_BIDIRECTIONAL);
+	if (mapping == DMA_ERROR_CODE) {
+		free_pages((unsigned long)ret, order);
+		ret = NULL;
+	} else
+		*dma_handle = mapping;
+	return ret;
+}
+
+void iommu_free_consistent(struct iommu_table *tbl, size_t size,
+			 void *vaddr, dma_addr_t dma_handle)
+{
+	unsigned int npages;
+
+	if (tbl) {
+		size = PAGE_ALIGN(size);
+		npages = size >> PAGE_SHIFT;
+		iommu_free(tbl, dma_handle, npages);
+		free_pages((unsigned long)vaddr, get_order(size));
+	}
+}
diff -purN linux-2.6.5/arch/ppc64/kernel/irq.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/irq.c
--- linux-2.6.5/arch/ppc64/kernel/irq.c	2004-04-04 03:36:57.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/irq.c	2004-04-29 11:17:16.000000000 +0000
@@ -67,6 +67,7 @@ irq_desc_t irq_desc[NR_IRQS] __cacheline
 	}
 };
 
+int __irq_offset_value;
 int ppc_spurious_interrupts = 0;
 unsigned long lpEvent_count = 0;
 
@@ -76,7 +77,7 @@ setup_irq(unsigned int irq, struct irqac
 	int shared = 0;
 	unsigned long flags;
 	struct irqaction *old, **p;
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 
 	/*
 	 * Some drivers like serial.c use request_irq() heavily,
@@ -134,7 +135,7 @@ setup_irq(unsigned int irq, struct irqac
 
 inline void synchronize_irq(unsigned int irq)
 {
-	while (irq_desc[irq].status & IRQ_INPROGRESS)
+	while (get_irq_desc(irq)->status & IRQ_INPROGRESS)
 		cpu_relax();
 }
 
@@ -148,11 +149,10 @@ EXPORT_SYMBOL(synchronize_irq);
 static int
 do_free_irq(int irq, void* dev_id)
 {
-	irq_desc_t *desc;
+	irq_desc_t *desc = get_irq_desc(irq);
 	struct irqaction **p;
 	unsigned long flags;
 
-	desc = irq_desc + irq;
 	spin_lock_irqsave(&desc->lock,flags);
 	p = &desc->action;
 	for (;;) {
@@ -247,7 +247,7 @@ EXPORT_SYMBOL(free_irq);
  
 inline void disable_irq_nosync(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -276,7 +276,7 @@ EXPORT_SYMBOL(disable_irq_nosync);
  
 void disable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	disable_irq_nosync(irq);
 	if (desc->action)
 		synchronize_irq(irq);
@@ -296,7 +296,7 @@ EXPORT_SYMBOL(disable_irq);
  
 void enable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -327,6 +327,7 @@ int show_interrupts(struct seq_file *p, 
 {
 	int i = *(loff_t *) v, j;
 	struct irqaction * action;
+	irq_desc_t *desc;
 	unsigned long flags;
 
 	if (i == 0) {
@@ -339,8 +340,9 @@ int show_interrupts(struct seq_file *p, 
 	}
 
 	if (i < NR_IRQS) {
-		spin_lock_irqsave(&irq_desc[i].lock, flags);
-		action = irq_desc[i].action;
+		desc = get_irq_desc(i);
+		spin_lock_irqsave(&desc->lock, flags);
+		action = desc->action;
 		if (!action || !action->handler)
 			goto skip;
 		seq_printf(p, "%3d: ", i);
@@ -352,17 +354,17 @@ int show_interrupts(struct seq_file *p, 
 #else
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif /* CONFIG_SMP */
-		if (irq_desc[i].handler)		
-			seq_printf(p, " %s ", irq_desc[i].handler->typename );
+		if (desc->handler)
+			seq_printf(p, " %s ", desc->handler->typename );
 		else
 			seq_printf(p, "  None      ");
-		seq_printf(p, "%s", (irq_desc[i].status & IRQ_LEVEL) ? "Level " : "Edge  ");
+		seq_printf(p, "%s", (desc->status & IRQ_LEVEL) ? "Level " : "Edge  ");
 		seq_printf(p, "    %s",action->name);
 		for (action=action->next; action; action = action->next)
 			seq_printf(p, ", %s", action->name);
 		seq_putc(p, '\n');
 skip:
-		spin_unlock_irqrestore(&irq_desc[i].lock, flags);
+		spin_unlock_irqrestore(&desc->lock, flags);
 	} else if (i == NR_IRQS)
 		seq_printf(p, "BAD: %10u\n", ppc_spurious_interrupts);
 	return 0;
@@ -482,7 +484,7 @@ void ppc_irq_dispatch_handler(struct pt_
 	int status;
 	struct irqaction *action;
 	int cpu = smp_processor_id();
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	irqreturn_t action_ret;
 
 	kstat_cpu(cpu).irqs[irq]++;
@@ -564,11 +566,11 @@ out:
 	 * The ->end() handler has to deal with interrupts which got
 	 * disabled while the handler was running.
 	 */
-	if (irq_desc[irq].handler) {
-		if (irq_desc[irq].handler->end)
-			irq_desc[irq].handler->end(irq);
-		else if (irq_desc[irq].handler->enable)
-			irq_desc[irq].handler->enable(irq);
+	if (desc->handler) {
+		if (desc->handler->end)
+			desc->handler->end(irq);
+		else if (desc->handler->enable)
+			desc->handler->enable(irq);
 	}
 	spin_unlock(&desc->lock);
 }
@@ -683,6 +685,7 @@ static struct proc_dir_entry * root_irq_
 static struct proc_dir_entry * irq_dir [NR_IRQS];
 static struct proc_dir_entry * smp_affinity_entry [NR_IRQS];
 
+/* Protected by get_irq_desc(irq)->lock. */
 #ifdef CONFIG_IRQ_ALL_CPUS
 cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
 #else  /* CONFIG_IRQ_ALL_CPUS */
@@ -702,16 +705,18 @@ static int irq_affinity_read_proc (char 
 static int irq_affinity_write_proc (struct file *file, const char *buffer,
 					unsigned long count, void *data)
 {
-	int irq = (long)data, full_count = count, err;
+	unsigned int irq = (long)data;
+	irq_desc_t *desc = get_irq_desc(irq);
+	int ret;
 	cpumask_t new_value, tmp;
 	cpumask_t allcpus = CPU_MASK_ALL;
 
-	if (!irq_desc[irq].handler->set_affinity)
+	if (!desc->handler->set_affinity)
 		return -EIO;
 
-	err = cpumask_parse(buffer, count, new_value);
-	if (err)
-		return err;
+	ret = cpumask_parse(buffer, count, new_value);
+	if (ret != 0)
+		return ret;
 
 	/*
 	 * We check for CPU_MASK_ALL in xics to send irqs to all cpus.
@@ -722,18 +727,29 @@ static int irq_affinity_write_proc (stru
 	cpus_and(new_value, new_value, allcpus);
 
 	/*
+	 * Grab lock here so cpu_online_map can't change, and also
+	 * protect irq_affinity[].
+	 */
+	spin_lock(&desc->lock);
+
+	/*
 	 * Do not allow disabling IRQs completely - it's a too easy
 	 * way to make the system unusable accidentally :-) At least
 	 * one online CPU still has to be targeted.
 	 */
 	cpus_and(tmp, new_value, cpu_online_map);
-	if (cpus_empty(tmp))
-		return -EINVAL;
+	if (cpus_empty(tmp)) {
+		ret = -EINVAL;
+		goto out;
+	}
 
 	irq_affinity[irq] = new_value;
-	irq_desc[irq].handler->set_affinity(irq, new_value);
+	desc->handler->set_affinity(irq, new_value);
+	ret = count;
 
-	return full_count;
+out:
+	spin_unlock(&desc->lock);
+	return ret;
 }
 
 static int prof_cpu_mask_read_proc (char *page, char **start, off_t off,
@@ -828,8 +844,8 @@ void init_irq_proc (void)
 	/*
 	 * Create entries for all existing IRQs.
 	 */
-	for (i = 0; i < NR_IRQS; i++) {
-		if (irq_desc[i].handler == NULL)
+	for_each_irq(i) {
+		if (get_irq_desc(i)->handler == NULL)
 			continue;
 		register_irq_proc(i);
 	}
@@ -857,7 +873,7 @@ unsigned int virt_irq_to_real_map[NR_IRQ
  * we don't end up with an interrupt number >= NR_IRQS.
  */
 #define MIN_VIRT_IRQ	3
-#define MAX_VIRT_IRQ	(NR_IRQS - NUM_8259_INTERRUPTS - 1)
+#define MAX_VIRT_IRQ	(NR_IRQS - NUM_ISA_INTERRUPTS - 1)
 #define NR_VIRT_IRQS	(MAX_VIRT_IRQ - MIN_VIRT_IRQ + 1)
 
 void
@@ -946,5 +962,4 @@ unsigned int real_irq_to_virt_slowpath(u
 
 }
 
-
 #endif
diff -purN linux-2.6.5/arch/ppc64/kernel/misc.S linux-2.6.5.ppc64_linus/arch/ppc64/kernel/misc.S
--- linux-2.6.5/arch/ppc64/kernel/misc.S	2004-04-04 03:38:13.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/misc.S	2004-04-29 11:17:16.000000000 +0000
@@ -132,7 +132,7 @@ _GLOBAL(flush_instruction_cache)
  *   flush all bytes from start through stop-1 inclusive
  */
 
-_GLOBAL(flush_icache_range)
+_GLOBAL(__flush_icache_range)
 
 /*
  * Flush the data cache to memory 
@@ -828,6 +828,18 @@ _GLOBAL(sys_call_table32)
 	.llong .compat_fstatfs64
 	.llong .ppc32_fadvise64_64	/* 32bit only fadvise64_64 */
 	.llong .ppc_rtas		/* 255 */
+	.llong .sys_ni_syscall		/* 256 reserved for sys_debug_setcontext */
+	.llong .sys_ni_syscall		/* 257 reserved for vserver */
+	.llong .sys_ni_syscall		/* 258 reserved for new sys_remap_file_pages */
+	.llong .sys_ni_syscall		/* 259 reserved for new sys_mbind */
+	.llong .sys_ni_syscall		/* 260 reserved for new sys_get_mempolicy */
+	.llong .sys_ni_syscall		/* 261 reserved for new sys_set_mempolicy */
+	.llong .compat_sys_mq_open
+	.llong .sys_mq_unlink
+	.llong .compat_sys_mq_timedsend
+	.llong .compat_sys_mq_timedreceive /* 265 */
+	.llong .compat_sys_mq_notify
+	.llong .compat_sys_mq_getsetattr
 
 	.balign 8
 _GLOBAL(sys_call_table)
@@ -1087,3 +1099,15 @@ _GLOBAL(sys_call_table)
 	.llong .sys_fstatfs64
 	.llong .sys_ni_syscall		/* 32bit only fadvise64_64 */
 	.llong .ppc_rtas		/* 255 */
+	.llong .sys_ni_syscall		/* 256 reserved for sys_debug_setcontext */
+	.llong .sys_ni_syscall		/* 257 reserved for vserver */
+	.llong .sys_ni_syscall		/* 258 reserved for new sys_remap_file_pages */
+	.llong .sys_ni_syscall		/* 259 reserved for new sys_mbind */
+	.llong .sys_ni_syscall		/* 260 reserved for new sys_get_mempolicy */
+	.llong .sys_ni_syscall		/* 261 reserved for new sys_set_mempolicy */
+	.llong .sys_mq_open
+	.llong .sys_mq_unlink
+	.llong .sys_mq_timedsend
+	.llong .sys_mq_timedreceive	/* 265 */
+	.llong .sys_mq_notify
+	.llong .sys_mq_getsetattr
diff -purN linux-2.6.5/arch/ppc64/kernel/nvram.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/nvram.c
--- linux-2.6.5/arch/ppc64/kernel/nvram.c	2004-04-04 03:36:15.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/nvram.c	2004-04-29 11:17:16.000000000 +0000
@@ -32,7 +32,7 @@
 #include <asm/prom.h>
 #include <asm/machdep.h>
 
-#define DEBUG_NVRAM
+#undef DEBUG_NVRAM
 
 static int nvram_scan_partitions(void);
 static int nvram_setup_partition(void);
@@ -199,7 +199,7 @@ static struct miscdevice nvram_dev = {
 };
 
 
-
+#ifdef DEBUG_NVRAM
 static void nvram_print_partitions(char * label)
 {
 	struct list_head * p;
@@ -215,6 +215,7 @@ static void nvram_print_partitions(char 
 		       tmp_part->header.name);
 	}
 }
+#endif
 
 
 static int nvram_write_header(struct nvram_partition * part)
diff -purN linux-2.6.5/arch/ppc64/kernel/open_pic.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/open_pic.c
--- linux-2.6.5/arch/ppc64/kernel/open_pic.c	2004-04-04 03:37:23.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/open_pic.c	2004-04-29 11:17:16.000000000 +0000
@@ -67,7 +67,6 @@ static void openpic_disable_irq(u_int ir
 static void openpic_initirq(u_int irq, u_int pri, u_int vector, int polarity,
 			    int is_level);
 static void openpic_mapirq(u_int irq, u_int cpumask);
-static void openpic_set_sense(u_int irq, int sense);
 
 static void find_ISUs(void);
 
@@ -170,7 +169,7 @@ void __init pSeries_init_openpic(void)
         int i;
         unsigned int *addrp;
         unsigned char* chrp_int_ack_special = 0;
-        unsigned char init_senses[NR_IRQS - NUM_8259_INTERRUPTS];
+        unsigned char init_senses[NR_IRQS - NUM_ISA_INTERRUPTS];
         int nmi_irq = -1;
 #if defined(CONFIG_VT) && defined(CONFIG_ADB_KEYBOARD) && defined(XMON)
         struct device_node *kbd;
@@ -185,12 +184,12 @@ void __init pSeries_init_openpic(void)
 			__ioremap(addrp[prom_n_addr_cells(np)-1], 1, _PAGE_NO_CACHE);
         /* hydra still sets OpenPIC_InitSenses to a static set of values */
         if (OpenPIC_InitSenses == NULL) {
-                prom_get_irq_senses(init_senses, NUM_8259_INTERRUPTS, NR_IRQS);
+                prom_get_irq_senses(init_senses, NUM_ISA_INTERRUPTS, NR_IRQS);
                 OpenPIC_InitSenses = init_senses;
-                OpenPIC_NumInitSenses = NR_IRQS - NUM_8259_INTERRUPTS;
+                OpenPIC_NumInitSenses = NR_IRQS - NUM_ISA_INTERRUPTS;
         }
-        openpic_init(1, NUM_8259_INTERRUPTS, chrp_int_ack_special, nmi_irq);
-        for ( i = 0 ; i < NUM_8259_INTERRUPTS  ; i++ )
+        openpic_init(1, NUM_ISA_INTERRUPTS, chrp_int_ack_special, nmi_irq);
+        for (i = 0; i < NUM_ISA_INTERRUPTS; i++)
                 irq_desc[i].handler = &i8259_pic;
 	of_node_put(np);
 }
@@ -441,7 +440,7 @@ static int __init openpic_setup_i8259(vo
 
 	if (naca->interrupt_controller == IC_OPEN_PIC) {
 		/* Initialize the cascade */
-		if (request_irq(NUM_8259_INTERRUPTS, no_action, SA_INTERRUPT,
+		if (request_irq(NUM_ISA_INTERRUPTS, no_action, SA_INTERRUPT,
 				"82c59 cascade", NULL))
 			printk(KERN_ERR "Unable to get OpenPIC IRQ 0 for cascade\n");
 		i8259_init();
@@ -820,13 +819,21 @@ static void openpic_mapirq(u_int irq, u_
  *
  *  sense: 1 for level, 0 for edge
  */
-static inline void openpic_set_sense(u_int irq, int sense)
+#if 0	/* not used */
+static void openpic_set_sense(u_int irq, int sense)
 {
 	openpic_safe_writefield(&GET_ISU(irq).Vector_Priority,
 				OPENPIC_SENSE_LEVEL,
 				(sense ? OPENPIC_SENSE_LEVEL : 0));
 }
 
+static int openpic_get_sense(u_int irq)
+{
+	return openpic_readfield(&GET_ISU(irq).Vector_Priority,
+				 OPENPIC_SENSE_LEVEL) != 0;
+}
+#endif
+
 static void openpic_end_irq(unsigned int irq_nr)
 {
 	openpic_eoi();
diff -purN linux-2.6.5/arch/ppc64/kernel/open_pic.h linux-2.6.5.ppc64_linus/arch/ppc64/kernel/open_pic.h
--- linux-2.6.5/arch/ppc64/kernel/open_pic.h	2004-04-04 03:36:18.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/open_pic.h	2004-04-29 11:17:16.000000000 +0000
@@ -14,6 +14,7 @@
 
 #include <linux/config.h>
 #include <linux/cpumask.h>
+#include <linux/irq.h>
 
 #define OPENPIC_SIZE	0x40000
 
@@ -38,11 +39,4 @@ extern void openpic_init_processor(u_int
 extern void openpic_setup_ISU(int isu_num, unsigned long addr);
 extern void openpic_cause_IPI(u_int ipi, u_int cpumask);
 
-extern inline int openpic_to_irq(int irq)
-{
-	if (systemcfg->platform == PLATFORM_POWERMAC)
-		return irq;
-	return irq += NUM_8259_INTERRUPTS;
-}
-/*extern int open_pic_irq_offset;*/
 #endif /* _PPC64_KERNEL_OPEN_PIC_H */
diff -purN linux-2.6.5/arch/ppc64/kernel/pSeries_htab.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pSeries_htab.c
--- linux-2.6.5/arch/ppc64/kernel/pSeries_htab.c	2004-04-04 03:36:55.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pSeries_htab.c	2004-04-29 11:17:16.000000000 +0000
@@ -221,9 +221,11 @@ static long pSeries_hpte_updatepp(unsign
 	if ((cur_cpu_spec->cpu_features & CPU_FTR_TLBIEL) && !large && local) {
 		tlbiel(va);
 	} else {
-		spin_lock_irqsave(&pSeries_tlbie_lock, flags);
+		if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+			spin_lock_irqsave(&pSeries_tlbie_lock, flags);
 		tlbie(va, large);
-		spin_unlock_irqrestore(&pSeries_tlbie_lock, flags);
+		if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+			spin_unlock_irqrestore(&pSeries_tlbie_lock, flags);
 	}
 
 	return ret;
@@ -255,9 +257,11 @@ static void pSeries_hpte_updateboltedpp(
 	set_pp_bit(newpp, hptep);
 
 	/* Ensure it is out of the tlb too */
-	spin_lock_irqsave(&pSeries_tlbie_lock, flags);
+	if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+		spin_lock_irqsave(&pSeries_tlbie_lock, flags);
 	tlbie(va, 0);
-	spin_unlock_irqrestore(&pSeries_tlbie_lock, flags);
+	if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+		spin_unlock_irqrestore(&pSeries_tlbie_lock, flags);
 }
 
 static void pSeries_hpte_invalidate(unsigned long slot, unsigned long va,
@@ -287,9 +291,11 @@ static void pSeries_hpte_invalidate(unsi
 	if ((cur_cpu_spec->cpu_features & CPU_FTR_TLBIEL) && !large && local) {
 		tlbiel(va);
 	} else {
-		spin_lock_irqsave(&pSeries_tlbie_lock, flags);
+		if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+			spin_lock_irqsave(&pSeries_tlbie_lock, flags);
 		tlbie(va, large);
-		spin_unlock_irqrestore(&pSeries_tlbie_lock, flags);
+		if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+			spin_unlock_irqrestore(&pSeries_tlbie_lock, flags);
 	}
 }
 
@@ -356,7 +362,8 @@ static void pSeries_flush_hash_range(uns
 		asm volatile("ptesync":::"memory");
 	} else {
 		/* XXX double check that it is safe to take this late */
-		spin_lock_irqsave(&pSeries_tlbie_lock, flags);
+		if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+			spin_lock_irqsave(&pSeries_tlbie_lock, flags);
 
 		asm volatile("ptesync":::"memory");
 
@@ -365,7 +372,8 @@ static void pSeries_flush_hash_range(uns
 
 		asm volatile("eieio; tlbsync; ptesync":::"memory");
 
-		spin_unlock_irqrestore(&pSeries_tlbie_lock, flags);
+		if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+			spin_unlock_irqrestore(&pSeries_tlbie_lock, flags);
 	}
 }
 
@@ -384,8 +392,12 @@ void hpte_init_pSeries(void)
 	root = of_find_node_by_path("/");
 	if (root) {
 		model = get_property(root, "model", NULL);
-		if (strcmp(model, "CHRP IBM,9076-N81"))
-			ppc_md.flush_hash_range = pSeries_flush_hash_range;
+		if (!strcmp(model, "CHRP IBM,9076-N81")) {
+			of_node_put(root);
+			return;
+		}
 		of_node_put(root);
 	}
+
+	ppc_md.flush_hash_range = pSeries_flush_hash_range;
 }
diff -purN linux-2.6.5/arch/ppc64/kernel/pSeries_iommu.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pSeries_iommu.c
--- linux-2.6.5/arch/ppc64/kernel/pSeries_iommu.c	2004-04-04 03:36:26.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pSeries_iommu.c	2004-04-29 11:17:16.000000000 +0000
@@ -33,6 +33,7 @@
 #include <linux/spinlock.h>
 #include <linux/string.h>
 #include <linux/pci.h>
+#include <linux/dma-mapping.h>
 #include <asm/io.h>
 #include <asm/prom.h>
 #include <asm/rtas.h>
@@ -46,7 +47,7 @@
 
 static void tce_build_pSeries(struct iommu_table *tbl, long index, 
 			      long npages, unsigned long uaddr, 
-			      int direction)
+			      enum dma_data_direction direction)
 {
 	union tce_entry t;
 	union tce_entry *tp;
@@ -54,7 +55,7 @@ static void tce_build_pSeries(struct iom
 	t.te_word = 0;
 	t.te_rdwr = 1; // Read allowed 
 
-	if (direction != PCI_DMA_TODEVICE)
+	if (direction != DMA_TO_DEVICE)
 		t.te_pciwr = 1;
 
 	tp = ((union tce_entry *)tbl->it_base) + index;
diff -purN linux-2.6.5/arch/ppc64/kernel/pSeries_lpar.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pSeries_lpar.c
--- linux-2.6.5/arch/ppc64/kernel/pSeries_lpar.c	2004-04-04 03:38:25.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pSeries_lpar.c	2004-04-29 11:17:16.000000000 +0000
@@ -21,6 +21,7 @@
 
 #include <linux/config.h>
 #include <linux/kernel.h>
+#include <linux/dma-mapping.h>
 #include <asm/processor.h>
 #include <asm/mmu.h>
 #include <asm/page.h>
@@ -30,13 +31,13 @@
 #include <asm/mmu_context.h>
 #include <asm/ppcdebug.h>
 #include <asm/iommu.h>
-#include <linux/pci.h>
 #include <asm/naca.h>
 #include <asm/tlbflush.h>
 #include <asm/tlb.h>
 #include <asm/hvcall.h>
 #include <asm/prom.h>
 #include <asm/abs_addr.h>
+#include <asm/cputable.h>
 
 /* in pSeries_hvCall.S */
 EXPORT_SYMBOL(plpar_hcall);
@@ -129,8 +130,9 @@ long plpar_put_term_char(unsigned long t
 				  lbuf[1]);
 }
 
-static void tce_build_pSeriesLP(struct iommu_table *tbl, long tcenum, long npages,
-				unsigned long uaddr, int direction )
+static void tce_build_pSeriesLP(struct iommu_table *tbl, long tcenum,
+		long npages, unsigned long uaddr,
+		enum dma_data_direction direction)
 {
 	u64 rc;
 	union tce_entry tce;
@@ -138,7 +140,7 @@ static void tce_build_pSeriesLP(struct i
 	tce.te_word = 0;
 	tce.te_rpn = (virt_to_abs(uaddr)) >> PAGE_SHIFT;
 	tce.te_rdwr = 1;
-	if (direction != PCI_DMA_TODEVICE)
+	if (direction != DMA_TO_DEVICE)
 		tce.te_pciwr = 1;
 
 	while (npages--) {
@@ -146,7 +148,7 @@ static void tce_build_pSeriesLP(struct i
 				   (u64)tcenum << 12, 
 				   tce.te_word );
 		
-		if(rc && printk_ratelimit()) {
+		if (rc && printk_ratelimit()) {
 			printk("tce_build_pSeriesLP: plpar_tce_put failed. rc=%ld\n", rc);
 			printk("\tindex   = 0x%lx\n", (u64)tbl->it_index);
 			printk("\ttcenum  = 0x%lx\n", (u64)tcenum);
@@ -559,12 +561,14 @@ void pSeries_lpar_flush_hash_range(unsig
 	unsigned long flags;
 	struct ppc64_tlb_batch *batch = &__get_cpu_var(ppc64_tlb_batch);
 
-	spin_lock_irqsave(&pSeries_lpar_tlbie_lock, flags);
+	if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+		spin_lock_irqsave(&pSeries_lpar_tlbie_lock, flags);
 
 	for (i = 0; i < number; i++)
 		flush_hash_page(context, batch->addr[i], batch->pte[i], local);
 
-	spin_unlock_irqrestore(&pSeries_lpar_tlbie_lock, flags);
+	if (!(cur_cpu_spec->cpu_features & CPU_FTR_LOCKLESS_TLBIE))
+		spin_unlock_irqrestore(&pSeries_lpar_tlbie_lock, flags);
 }
 
 void pSeries_lpar_mm_init(void)
diff -purN linux-2.6.5/arch/ppc64/kernel/pSeries_pci.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pSeries_pci.c
--- linux-2.6.5/arch/ppc64/kernel/pSeries_pci.c	2004-04-04 03:38:27.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pSeries_pci.c	2004-04-29 11:17:16.000000000 +0000
@@ -44,6 +44,12 @@
 #include "open_pic.h"
 #include "pci.h"
 
+/* legal IO pages under MAX_ISA_PORT.  This is to ensure we don't touch
+   devices we don't have access to. */
+unsigned long io_page_mask;
+
+EXPORT_SYMBOL(io_page_mask);
+
 /* RTAS tokens */
 static int read_pci_config;
 static int write_pci_config;
@@ -280,6 +286,8 @@ static void __init pci_process_bridge_OF
 					pci_process_ISA_OF_ranges(isa_dn,
 						hose->io_base_phys,
 						hose->io_base_virt);
+                                        /* Allow all IO */
+                                        io_page_mask = -1;
 				}
 			}
 
@@ -523,8 +531,24 @@ void __devinit pcibios_fixup_device_reso
 	for (i = 0; i < PCI_NUM_RESOURCES; i++) {
 		if (dev->resource[i].flags & IORESOURCE_IO) {
 			unsigned long offset = (unsigned long)hose->io_base_virt - pci_io_base;
-			dev->resource[i].start += offset;
-			dev->resource[i].end += offset;
+                        unsigned long start, end, mask;
+
+                        start = dev->resource[i].start += offset;
+                        end = dev->resource[i].end += offset;
+
+                        /* Need to allow IO access to pages that are in the
+                           ISA range */
+                        if (start < MAX_ISA_PORT) {
+                                if (end > MAX_ISA_PORT)
+                                        end = MAX_ISA_PORT;
+
+                                start >>= PAGE_SHIFT;
+                                end >>= PAGE_SHIFT;
+
+                                /* get the range of pages for the map */
+                                mask = ((1 << (end+1))-1) ^ ((1 << start)-1);
+                                io_page_mask |= mask;
+                        }
 		}
                 else if (dev->resource[i].flags & IORESOURCE_MEM) {
 			dev->resource[i].start += hose->pci_mem_offset;
diff -purN linux-2.6.5/arch/ppc64/kernel/pci_dma_direct.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pci_dma_direct.c
--- linux-2.6.5/arch/ppc64/kernel/pci_dma_direct.c	2004-04-04 03:36:13.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pci_dma_direct.c	2004-04-29 11:17:16.000000000 +0000
@@ -18,6 +18,7 @@
 #include <linux/init.h>
 #include <linux/bootmem.h>
 #include <linux/mm.h>
+#include <linux/dma-mapping.h>
 
 #include <asm/sections.h>
 #include <asm/io.h>
@@ -49,18 +50,18 @@ static void pci_direct_free_consistent(s
 }
 
 static dma_addr_t pci_direct_map_single(struct pci_dev *hwdev, void *ptr,
-				  size_t size, int direction)
+		size_t size, enum dma_data_direction direction)
 {
 	return virt_to_abs(ptr);
 }
 
 static void pci_direct_unmap_single(struct pci_dev *hwdev, dma_addr_t dma_addr,
-			      size_t size, int direction)
+		size_t size, enum dma_data_direction direction)
 {
 }
 
 static int pci_direct_map_sg(struct pci_dev *hwdev, struct scatterlist *sg,
-		       int nents, int direction)
+		int nents, enum dma_data_direction direction)
 {
 	int i;
 
@@ -73,7 +74,7 @@ static int pci_direct_map_sg(struct pci_
 }
 
 static void pci_direct_unmap_sg(struct pci_dev *hwdev, struct scatterlist *sg,
-			  int nents, int direction)
+		int nents, enum dma_data_direction direction)
 {
 }
 
diff -purN linux-2.6.5/arch/ppc64/kernel/pci_dn.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pci_dn.c
--- linux-2.6.5/arch/ppc64/kernel/pci_dn.c	2004-04-04 03:38:24.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pci_dn.c	2004-04-29 11:17:16.000000000 +0000
@@ -50,13 +50,20 @@ update_dn_pci_info(struct device_node *d
 	struct pci_controller *phb = (struct pci_controller *)data;
 	u32 *regs;
 	char *device_type = get_property(dn, "device_type", 0);
+	char *model;
 
 	dn->phb = phb;
 	if (device_type && strcmp(device_type, "pci") == 0 && get_property(dn, "class-code", 0) == 0) {
 		/* special case for PHB's.  Sigh. */
 		regs = (u32 *)get_property(dn, "bus-range", 0);
 		dn->busno = regs[0];
-		dn->devfn = 0;	/* assumption */
+
+		model = (char *)get_property(dn, "model", NULL);
+
+		if (strstr(model, "U3"))
+			dn->devfn = -1;
+		else
+			dn->devfn = 0;	/* assumption */
 	} else {
 		regs = (u32 *)get_property(dn, "reg", 0);
 		if (regs) {
diff -purN linux-2.6.5/arch/ppc64/kernel/pci_iommu.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pci_iommu.c
--- linux-2.6.5/arch/ppc64/kernel/pci_iommu.c	2004-04-04 03:37:36.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pci_iommu.c	2004-04-29 11:17:16.000000000 +0000
@@ -43,8 +43,6 @@
 #include <asm/iSeries/iSeries_pci.h>
 #endif /* CONFIG_PPC_ISERIES */
 
-#define DBG(...)
-
 static inline struct iommu_table *devnode_table(struct pci_dev *dev)
 {
 	if (!dev)
@@ -66,154 +64,49 @@ static inline struct iommu_table *devnod
  * Returns the virtual address of the buffer and sets dma_handle
  * to the dma address (mapping) of the first page.
  */
-void *pci_iommu_alloc_consistent(struct pci_dev *hwdev, size_t size,
+static void *pci_iommu_alloc_consistent(struct pci_dev *hwdev, size_t size,
 			   dma_addr_t *dma_handle)
 {
-	struct iommu_table *tbl;
-	void *ret = NULL;
-	dma_addr_t mapping;
-	unsigned int npages, order;
-
-	size = PAGE_ALIGN(size);
-	npages = size >> PAGE_SHIFT;
-	order = get_order(size);
-
- 	/* Client asked for way too much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
-	if (order >= IOMAP_MAX_ORDER) {
-		printk("PCI_DMA: pci_alloc_consistent size too large: 0x%lx\n",
-			size);
-		return (void *)DMA_ERROR_CODE;
-	}
-
-	tbl = devnode_table(hwdev); 
-
-	if (!tbl)
-		return NULL;
-
-	/* Alloc enough pages (and possibly more) */
-	ret = (void *)__get_free_pages(GFP_ATOMIC, order);
-
-	if (!ret)
-		return NULL;
-
-	memset(ret, 0, size);
-
-	/* Set up tces to cover the allocated range */
-	mapping = iommu_alloc(tbl, ret, npages, PCI_DMA_BIDIRECTIONAL);
-
-	if (mapping == DMA_ERROR_CODE) {
-		free_pages((unsigned long)ret, order);
-		ret = NULL;
-	} else
-		*dma_handle = mapping;
-
-	return ret;
+	return iommu_alloc_consistent(devnode_table(hwdev), size, dma_handle);
 }
 
-
-void pci_iommu_free_consistent(struct pci_dev *hwdev, size_t size,
+static void pci_iommu_free_consistent(struct pci_dev *hwdev, size_t size,
 			 void *vaddr, dma_addr_t dma_handle)
 {
-	struct iommu_table *tbl;
-	unsigned int npages;
-	
-	size = PAGE_ALIGN(size);
-	npages = size >> PAGE_SHIFT;
-
-	tbl = devnode_table(hwdev); 
-
-	if (tbl) {
-		iommu_free(tbl, dma_handle, npages);
-		free_pages((unsigned long)vaddr, get_order(size));
-	}
+	iommu_free_consistent(devnode_table(hwdev), size, vaddr, dma_handle);
 }
 
-
 /* Creates TCEs for a user provided buffer.  The user buffer must be 
  * contiguous real kernel storage (not vmalloc).  The address of the buffer
  * passed here is the kernel (virtual) address of the buffer.  The buffer
  * need not be page aligned, the dma_addr_t returned will point to the same
  * byte within the page as vaddr.
  */
-dma_addr_t pci_iommu_map_single(struct pci_dev *hwdev, void *vaddr,
-				size_t size, int direction)
+static dma_addr_t pci_iommu_map_single(struct pci_dev *hwdev, void *vaddr,
+		size_t size, enum dma_data_direction direction)
 {
-	struct iommu_table * tbl;
-	dma_addr_t dma_handle = DMA_ERROR_CODE;
-	unsigned long uaddr;
-	unsigned int npages;
-
-	BUG_ON(direction == PCI_DMA_NONE);
-
-	uaddr = (unsigned long)vaddr;
-	npages = PAGE_ALIGN(uaddr + size) - (uaddr & PAGE_MASK);
-	npages >>= PAGE_SHIFT;
-
-	tbl = devnode_table(hwdev); 
-
-	if (tbl) {
-		dma_handle = iommu_alloc(tbl, vaddr, npages, direction);
-		if (dma_handle == DMA_ERROR_CODE) {
-			if (printk_ratelimit())  {
-				printk(KERN_INFO "iommu_alloc failed, tbl %p vaddr %p npages %d\n",
-				       tbl, vaddr, npages);
-			}
-		} else 
-			dma_handle |= (uaddr & ~PAGE_MASK);
-	}
-
-	return dma_handle;
+	return iommu_map_single(devnode_table(hwdev), vaddr, size, direction);
 }
 
 
-void pci_iommu_unmap_single(struct pci_dev *hwdev, dma_addr_t dma_handle,
-		      size_t size, int direction)
+static void pci_iommu_unmap_single(struct pci_dev *hwdev, dma_addr_t dma_handle,
+		size_t size, enum dma_data_direction direction)
 {
-	struct iommu_table *tbl;
-	unsigned int npages;
-	
-	BUG_ON(direction == PCI_DMA_NONE);
-
-	npages = (PAGE_ALIGN(dma_handle + size) - (dma_handle & PAGE_MASK))
-		>> PAGE_SHIFT;
-
-	tbl = devnode_table(hwdev); 
-
-	if (tbl) 
-		iommu_free(tbl, dma_handle, npages);
+	iommu_unmap_single(devnode_table(hwdev), dma_handle, size, direction);
 }
 
 
-int pci_iommu_map_sg(struct pci_dev *pdev, struct scatterlist *sglist, int nelems,
-	       int direction)
+static int pci_iommu_map_sg(struct pci_dev *pdev, struct scatterlist *sglist,
+		int nelems, enum dma_data_direction direction)
 {
-	struct iommu_table * tbl;
-
-	BUG_ON(direction == PCI_DMA_NONE);
-
-	if (nelems == 0)
-		return 0;
-
-	tbl = devnode_table(pdev); 
-	if (!tbl)
-		return 0;
-
-	return iommu_alloc_sg(tbl, &pdev->dev, sglist, nelems, direction);
+	return iommu_map_sg(&pdev->dev, devnode_table(pdev), sglist,
+			nelems, direction);
 }
 
-void pci_iommu_unmap_sg(struct pci_dev *pdev, struct scatterlist *sglist, int nelems,
-		  int direction)
+static void pci_iommu_unmap_sg(struct pci_dev *pdev, struct scatterlist *sglist,
+		int nelems, enum dma_data_direction direction)
 {
-	struct iommu_table *tbl;
-
-	BUG_ON(direction == PCI_DMA_NONE);
-
-	tbl = devnode_table(pdev); 
-	if (!tbl)
-		return;
-
-	iommu_free_sg(tbl, sglist, nelems);
+	iommu_unmap_sg(devnode_table(pdev), sglist, nelems, direction);
 }
 
 /* We support DMA to/from any memory page via the iommu */
diff -purN linux-2.6.5/arch/ppc64/kernel/pmac_iommu.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pmac_iommu.c
--- linux-2.6.5/arch/ppc64/kernel/pmac_iommu.c	2004-04-04 03:38:21.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/pmac_iommu.c	2004-04-29 11:17:16.000000000 +0000
@@ -33,6 +33,7 @@
 #include <linux/spinlock.h>
 #include <linux/string.h>
 #include <linux/pci.h>
+#include <linux/dma-mapping.h>
 #include <linux/vmalloc.h>
 #include <asm/io.h>
 #include <asm/prom.h>
@@ -141,7 +142,7 @@ static void dart_flush(struct iommu_tabl
 
 static void dart_build_pmac(struct iommu_table *tbl, long index, 
 			    long npages, unsigned long uaddr,
-			    int direction)
+			    enum dma_data_direction direction)
 {
 	unsigned int *dp;
 	unsigned int rpn;
diff -purN linux-2.6.5/arch/ppc64/kernel/ppc_ksyms.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/ppc_ksyms.c
--- linux-2.6.5/arch/ppc64/kernel/ppc_ksyms.c	2004-04-04 03:36:26.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/ppc_ksyms.c	2004-04-29 11:17:16.000000000 +0000
@@ -42,6 +42,7 @@
 #include <asm/cacheflush.h>
 #ifdef CONFIG_PPC_ISERIES
 #include <asm/iSeries/HvCallSc.h>
+#include <asm/iSeries/LparData.h>
 #endif
 
 extern int do_signal(sigset_t *, struct pt_regs *);
@@ -71,6 +72,9 @@ EXPORT_SYMBOL(__down_interruptible);
 EXPORT_SYMBOL(__up);
 EXPORT_SYMBOL(naca);
 EXPORT_SYMBOL(__down);
+#ifdef CONFIG_PPC_ISERIES
+EXPORT_SYMBOL(itLpNaca);
+#endif
 
 EXPORT_SYMBOL(csum_partial);
 EXPORT_SYMBOL(csum_partial_copy_generic);
diff -purN linux-2.6.5/arch/ppc64/kernel/prom.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/prom.c
--- linux-2.6.5/arch/ppc64/kernel/prom.c	2004-04-04 03:37:37.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/prom.c	2004-04-29 11:12:49.000000000 +0000
@@ -32,6 +32,7 @@
 #include <linux/proc_fs.h>
 #include <linux/stringify.h>
 #include <linux/delay.h>
+#include <linux/initrd.h>
 #include <asm/prom.h>
 #include <asm/rtas.h>
 #include <asm/lmb.h>
@@ -123,12 +124,7 @@ struct pci_intr_map {
 
 
 typedef unsigned long interpret_func(struct device_node *, unsigned long,
-				     int, int);
-static interpret_func interpret_pci_props;
-static interpret_func interpret_isa_props;
-static interpret_func interpret_root_props;
-static interpret_func interpret_dbdma_props;
-static interpret_func interpret_macio_props;
+				     int, int, int);
 
 #ifndef FB_MAX			/* avoid pulling in all of the fb stuff */
 #define FB_MAX	8
@@ -142,6 +138,9 @@ phandle prom_display_nodes[FB_MAX] __ini
 unsigned int prom_num_displays = 0;
 char *of_stdout_device = 0;
 
+static int iommu_force_on;
+int ppc64_iommu_off;
+
 extern struct rtas_t rtas;
 extern unsigned long klimit;
 extern struct lmb lmb;
@@ -161,29 +160,6 @@ struct device_node *allnodes = 0;
  */
 static rwlock_t devtree_lock = RW_LOCK_UNLOCKED;
 
-static unsigned long call_prom(const char *service, int nargs, int nret, ...);
-static void prom_panic(const char *reason);
-static unsigned long copy_device_tree(unsigned long);
-static unsigned long inspect_node(phandle, struct device_node *, unsigned long,
-				  unsigned long, struct device_node ***);
-static unsigned long finish_node(struct device_node *, unsigned long,
-				 interpret_func *, int, int);
-static unsigned long finish_node_interrupts(struct device_node *, unsigned long);
-static unsigned long check_display(unsigned long);
-static int prom_next_node(phandle *);
-static struct bi_record * prom_bi_rec_verify(struct bi_record *);
-static unsigned long prom_bi_rec_reserve(unsigned long);
-static struct device_node *find_phandle(phandle);
-static void of_node_cleanup(struct device_node *);
-static struct device_node *derive_parent(const char *);
-static void add_node_proc_entries(struct device_node *);
-static void remove_node_proc_entries(struct device_node *);
-static int of_finish_dynamic_node(struct device_node *);
-
-#ifdef DEBUG_PROM
-void prom_dump_lmb(void);
-#endif
-
 extern unsigned long reloc_offset(void);
 
 extern void enter_prom(struct prom_args *args);
@@ -208,8 +184,9 @@ char testString[] = "LINUX\n"; 
  * mode when we do.  We switch back to 64b mode upon return.
  */
 
-static unsigned long __init
-call_prom(const char *service, int nargs, int nret, ...)
+#define PROM_ERROR	(0x00000000fffffffful)
+
+static unsigned long __init call_prom(const char *service, int nargs, int nret, ...)
 {
 	int i;
 	unsigned long offset = reloc_offset();
@@ -235,30 +212,7 @@ call_prom(const char *service, int nargs
 }
 
 
-static void __init
-prom_panic(const char *reason)
-{
-	unsigned long offset = reloc_offset();
-
-	prom_print(reason);
-	/* ToDo: should put up an SRC here */
-	call_prom(RELOC("exit"), 0, 0);
-
-	for (;;)			/* should never get here */
-		;
-}
-
-void __init
-prom_enter(void)
-{
-	unsigned long offset = reloc_offset();
-
-	call_prom(RELOC("enter"), 0, 0);
-}
-
-
-void __init
-prom_print(const char *msg)
+static void __init prom_print(const char *msg)
 {
 	const char *p, *q;
 	unsigned long offset = reloc_offset();
@@ -281,8 +235,8 @@ prom_print(const char *msg)
 	}
 }
 
-void
-prom_print_hex(unsigned long val)
+
+static void __init prom_print_hex(unsigned long val)
 {
         int i, nibbles = sizeof(val)*2;
         char buf[sizeof(val)*2+1];
@@ -297,16 +251,47 @@ prom_print_hex(unsigned long val)
 	prom_print(buf);
 }
 
-void
-prom_print_nl(void)
+
+static void __init prom_print_nl(void)
 {
 	unsigned long offset = reloc_offset();
 	prom_print(RELOC("\n"));
 }
 
 
-static unsigned long
-prom_initialize_naca(unsigned long mem)
+static void __init prom_panic(const char *reason)
+{
+	unsigned long offset = reloc_offset();
+
+	prom_print(reason);
+	/* ToDo: should put up an SRC here */
+	call_prom(RELOC("exit"), 0, 0);
+
+	for (;;)			/* should never get here */
+		;
+}
+
+
+static int __init prom_next_node(phandle *nodep)
+{
+	phandle node;
+	unsigned long offset = reloc_offset();
+
+	if ((node = *nodep) != 0
+	    && (*nodep = call_prom(RELOC("child"), 1, 1, node)) != 0)
+		return 1;
+	if ((*nodep = call_prom(RELOC("peer"), 1, 1, node)) != 0)
+		return 1;
+	for (;;) {
+		if ((node = call_prom(RELOC("parent"), 1, 1, node)) == 0)
+			return 0;
+		if ((*nodep = call_prom(RELOC("peer"), 1, 1, node)) != 0)
+			return 1;
+	}
+}
+
+
+static void __init prom_initialize_naca(void)
 {
 	phandle node;
 	char type[64];
@@ -521,14 +506,10 @@ prom_initialize_naca(unsigned long mem)
 
 	prom_print(RELOC("prom_initialize_naca: end...\n"));
 #endif
-
-	return mem;
 }
 
-static int iommu_force_on;
-int ppc64_iommu_off;
 
-static void early_cmdline_parse(void)
+static void __init early_cmdline_parse(void)
 {
 	unsigned long offset = reloc_offset();
 	char *opt;
@@ -558,8 +539,58 @@ static void early_cmdline_parse(void)
 #endif
 }
 
-static unsigned long __init
-prom_initialize_lmb(unsigned long mem)
+#ifdef DEBUG_PROM
+void prom_dump_lmb(void)
+{
+        unsigned long i;
+        unsigned long offset = reloc_offset();
+	struct lmb *_lmb  = PTRRELOC(&lmb);
+
+        prom_print(RELOC("\nprom_dump_lmb:\n"));
+        prom_print(RELOC("    memory.cnt                  = 0x"));
+        prom_print_hex(_lmb->memory.cnt);
+	prom_print_nl();
+        prom_print(RELOC("    memory.size                 = 0x"));
+        prom_print_hex(_lmb->memory.size);
+	prom_print_nl();
+        for (i=0; i < _lmb->memory.cnt ;i++) {
+                prom_print(RELOC("    memory.region[0x"));
+		prom_print_hex(i);
+		prom_print(RELOC("].base       = 0x"));
+                prom_print_hex(_lmb->memory.region[i].base);
+		prom_print_nl();
+                prom_print(RELOC("                      .physbase = 0x"));
+                prom_print_hex(_lmb->memory.region[i].physbase);
+		prom_print_nl();
+                prom_print(RELOC("                      .size     = 0x"));
+                prom_print_hex(_lmb->memory.region[i].size);
+		prom_print_nl();
+        }
+
+	prom_print_nl();
+        prom_print(RELOC("    reserved.cnt                  = 0x"));
+        prom_print_hex(_lmb->reserved.cnt);
+	prom_print_nl();
+        prom_print(RELOC("    reserved.size                 = 0x"));
+        prom_print_hex(_lmb->reserved.size);
+	prom_print_nl();
+        for (i=0; i < _lmb->reserved.cnt ;i++) {
+                prom_print(RELOC("    reserved.region[0x"));
+		prom_print_hex(i);
+		prom_print(RELOC("].base       = 0x"));
+                prom_print_hex(_lmb->reserved.region[i].base);
+		prom_print_nl();
+                prom_print(RELOC("                      .physbase = 0x"));
+                prom_print_hex(_lmb->reserved.region[i].physbase);
+		prom_print_nl();
+                prom_print(RELOC("                      .size     = 0x"));
+                prom_print_hex(_lmb->reserved.region[i].size);
+		prom_print_nl();
+        }
+}
+#endif /* DEBUG_PROM */
+
+static void __init prom_initialize_lmb(void)
 {
 	phandle node;
 	char type[64];
@@ -621,8 +652,6 @@ prom_initialize_lmb(unsigned long mem)
 #ifdef DEBUG_PROM
 	prom_dump_lmb();
 #endif /* DEBUG_PROM */
-
-	return mem;
 }
 
 static char hypertas_funcs[1024];
@@ -642,13 +671,15 @@ prom_instantiate_rtas(void)
 #endif
 	prom_rtas = (ihandle)call_prom(RELOC("finddevice"), 1, 1, RELOC("/rtas"));
 	if (prom_rtas != (ihandle) -1) {
-		int  rc; 
-		
-		if ((rc = call_prom(RELOC("getprop"), 
+		unsigned long x;
+		x = call_prom(RELOC("getprop"),
 				  4, 1, prom_rtas,
 				  RELOC("ibm,hypertas-functions"), 
 				  hypertas_funcs, 
-				  sizeof(hypertas_funcs))) > 0) {
+			      sizeof(hypertas_funcs));
+
+		if (x != PROM_ERROR) {
+			prom_print(RELOC("Hypertas detected, assuming LPAR !\n"));
 			_systemcfg->platform = PLATFORM_PSERIES_LPAR;
 		}
 
@@ -670,6 +701,7 @@ prom_instantiate_rtas(void)
 				struct lmb *_lmb  = PTRRELOC(&lmb);
 				rtas_region = min(_lmb->rmo_size, RTAS_INSTANTIATE_MAX);
 			}
+
 			_rtas->base = lmb_alloc_base(_rtas->size, PAGE_SIZE, rtas_region);
 
 			prom_print(RELOC(" at 0x"));
@@ -679,10 +711,10 @@ prom_instantiate_rtas(void)
 					      	1, 1, RELOC("/rtas"));
 			prom_print(RELOC("..."));
 
-			if ((long)call_prom(RELOC("call-method"), 3, 2,
+			if (call_prom(RELOC("call-method"), 3, 2,
 						      RELOC("instantiate-rtas"),
 						      prom_rtas,
-						      _rtas->base) >= 0) {
+						      _rtas->base) != PROM_ERROR) {
 				_rtas->entry = (long)_prom->args.rets[1];
 			}
 			RELOC(rtas_rmo_buf)
@@ -713,74 +745,9 @@ prom_instantiate_rtas(void)
 #endif
 }
 
-unsigned long prom_strtoul(const char *cp)
-{
-	unsigned long result = 0,value;
-
-	while (*cp) {
-		value = *cp-'0';
-		result = result*10 + value;
-		cp++;
-	} 
-
-	return result;
-}
-
-#ifdef DEBUG_PROM
-void
-prom_dump_lmb(void)
-{
-        unsigned long i;
-        unsigned long offset = reloc_offset();
-	struct lmb *_lmb  = PTRRELOC(&lmb);
-
-        prom_print(RELOC("\nprom_dump_lmb:\n"));
-        prom_print(RELOC("    memory.cnt                  = 0x"));
-        prom_print_hex(_lmb->memory.cnt);
-	prom_print_nl();
-        prom_print(RELOC("    memory.size                 = 0x"));
-        prom_print_hex(_lmb->memory.size);
-	prom_print_nl();
-        for (i=0; i < _lmb->memory.cnt ;i++) {
-                prom_print(RELOC("    memory.region[0x"));
-		prom_print_hex(i);
-		prom_print(RELOC("].base       = 0x"));
-                prom_print_hex(_lmb->memory.region[i].base);
-		prom_print_nl();
-                prom_print(RELOC("                      .physbase = 0x"));
-                prom_print_hex(_lmb->memory.region[i].physbase);
-		prom_print_nl();
-                prom_print(RELOC("                      .size     = 0x"));
-                prom_print_hex(_lmb->memory.region[i].size);
-		prom_print_nl();
-        }
-
-	prom_print_nl();
-        prom_print(RELOC("    reserved.cnt                  = 0x"));
-        prom_print_hex(_lmb->reserved.cnt);
-	prom_print_nl();
-        prom_print(RELOC("    reserved.size                 = 0x"));
-        prom_print_hex(_lmb->reserved.size);
-	prom_print_nl();
-        for (i=0; i < _lmb->reserved.cnt ;i++) {
-                prom_print(RELOC("    reserved.region[0x"));
-		prom_print_hex(i);
-		prom_print(RELOC("].base       = 0x"));
-                prom_print_hex(_lmb->reserved.region[i].base);
-		prom_print_nl();
-                prom_print(RELOC("                      .physbase = 0x"));
-                prom_print_hex(_lmb->reserved.region[i].physbase);
-		prom_print_nl();
-                prom_print(RELOC("                      .size     = 0x"));
-                prom_print_hex(_lmb->reserved.region[i].size);
-		prom_print_nl();
-        }
-}
-#endif /* DEBUG_PROM */
-
 
 #ifdef CONFIG_PMAC_DART
-void prom_initialize_dart_table(void)
+static void __init prom_initialize_dart_table(void)
 {
 	unsigned long offset = reloc_offset();
 	extern unsigned long dart_tablebase;
@@ -797,8 +764,8 @@ void prom_initialize_dart_table(void)
 	/* 16MB (1 << 24) alignment. We allocate a full 16Mb chuck since we
 	 * will blow up an entire large page anyway in the kernel mapping
 	 */
-	RELOC(dart_tablebase) =
-		absolute_to_virt(lmb_alloc_base(1UL<<24, 1UL<<24, 0x80000000L));
+	RELOC(dart_tablebase) = (unsigned long)
+		abs_to_virt(lmb_alloc_base(1UL<<24, 1UL<<24, 0x80000000L));
 
 	prom_print(RELOC("Dart at: "));
 	prom_print_hex(RELOC(dart_tablebase));
@@ -806,9 +773,7 @@ void prom_initialize_dart_table(void)
 }
 #endif /* CONFIG_PMAC_DART */
 
-
-void
-prom_initialize_tce_table(void)
+static void __init prom_initialize_tce_table(void)
 {
 	phandle node;
 	ihandle phb_node;
@@ -864,13 +829,13 @@ prom_initialize_tce_table(void)
 
 		if (call_prom(RELOC("getprop"), 4, 1, node, 
 			     RELOC("tce-table-minalign"), &minalign, 
-			     sizeof(minalign)) < 0) {
+			     sizeof(minalign)) == PROM_ERROR) {
 			minalign = 0;
 		}
 
 		if (call_prom(RELOC("getprop"), 4, 1, node, 
 			     RELOC("tce-table-minsize"), &minsize, 
-			     sizeof(minsize)) < 0) {
+			     sizeof(minsize)) == PROM_ERROR) {
 			minsize = 4UL << 20;
 		}
 
@@ -939,7 +904,7 @@ prom_initialize_tce_table(void)
 		memset(path, 0, sizeof(path));
 		/* Call OF to setup the TCE hardware */
 		if (call_prom(RELOC("package-to-path"), 3, 1, node,
-                             path, sizeof(path)-1) <= 0) {
+                             path, sizeof(path)-1) == PROM_ERROR) {
                         prom_print(RELOC("package-to-path failed\n"));
                 } else {
                         prom_print(RELOC("opening PHB "));
@@ -992,8 +957,7 @@ prom_initialize_tce_table(void)
  *
  * -- Cort
  */
-static void
-prom_hold_cpus(unsigned long mem)
+static void __init prom_hold_cpus(unsigned long mem)
 {
 	unsigned long i;
 	unsigned int reg;
@@ -1103,7 +1067,7 @@ prom_hold_cpus(unsigned long mem)
 		path = (char *) mem;
 		memset(path, 0, 256);
 		if ((long) call_prom(RELOC("package-to-path"), 3, 1,
-				     node, path, 255) < 0)
+				     node, path, 255) == PROM_ERROR)
 			continue;
 
 #ifdef DEBUG_PROM
@@ -1249,12 +1213,10 @@ next:
 #endif
 }
 
-static void
-smt_setup(void)
+static void __init smt_setup(void)
 {
 	char *p, *q;
 	char my_smt_enabled = SMT_DYNAMIC;
-	unsigned long my_smt_snooze_delay; 
 	ihandle prom_options = NULL;
 	char option[9];
 	unsigned long offset = reloc_offset();
@@ -1301,51 +1263,6 @@ smt_setup(void)
 	if (!found )
 		my_smt_enabled = SMT_DYNAMIC; /* default to on */
 
-	found = 0;
-	if (my_smt_enabled) {
-		if (strstr(RELOC(cmd_line), RELOC("smt-snooze-delay="))) {
-			for (q = RELOC(cmd_line); (p = strstr(q, RELOC("smt-snooze-delay="))) != 0; ) {
-				q = p + 17;
-				if (p > RELOC(cmd_line) && p[-1] != ' ')
-					continue;
-				found = 1;
-				/* Don't use simple_strtoul() because _ctype & others aren't RELOC'd */
-				my_smt_snooze_delay = 0;
-				while (*q >= '0' && *q <= '9') {
-					my_smt_snooze_delay = my_smt_snooze_delay * 10 + *q - '0';
-					q++;
-				}
-			}
-		}
-
-		if (!found) {
-			prom_options = (ihandle)call_prom(RELOC("finddevice"), 1, 1, RELOC("/options"));
-			if (prom_options != (ihandle) -1) {
-				call_prom(RELOC("getprop"), 
-					4, 1, prom_options,
-					RELOC("ibm,smt-snooze-delay"), 
-					option, 
-					sizeof(option));
-				if (option[0] != 0) {
-					found = 1;
-					/* Don't use simple_strtoul() because _ctype & others aren't RELOC'd */
-					my_smt_snooze_delay = 0;
-					q = option;
-					while (*q >= '0' && *q <= '9') {
-						my_smt_snooze_delay = my_smt_snooze_delay * 10 + *q - '0';
-						q++;
-					}
-				}
-			}
-		}
-
-		if (!found) {
-			my_smt_snooze_delay = 30000; /* default value */
-		}
-	} else {
-		my_smt_snooze_delay = 0; /* default value */
-	}
-	_naca->smt_snooze_delay = my_smt_snooze_delay;
 	_naca->smt_state = my_smt_enabled;
 }
 
@@ -1487,222 +1404,56 @@ static int __init prom_find_machine_type
 	return PLATFORM_PSERIES;
 }
 
+static int __init prom_set_color(ihandle ih, int i, int r, int g, int b)
+{
+	unsigned long offset = reloc_offset();
+
+	return (int)(long)call_prom(RELOC("call-method"), 6, 1,
+		                    RELOC("color!"),
+                                    ih,
+                                    (void *)(long) i,
+                                    (void *)(long) b,
+                                    (void *)(long) g,
+                                    (void *)(long) r );
+}
+
 /*
- * We enter here early on, when the Open Firmware prom is still
- * handling exceptions and the MMU hash table for us.
+ * If we have a display that we don't know how to drive,
+ * we will want to try to execute OF's open method for it
+ * later.  However, OF will probably fall over if we do that
+ * we've taken over the MMU.
+ * So we check whether we will need to open the display,
+ * and if so, open it now.
  */
-
-unsigned long __init
-prom_init(unsigned long r3, unsigned long r4, unsigned long pp,
-	  unsigned long r6, unsigned long r7)
+static unsigned long __init check_display(unsigned long mem)
 {
-	unsigned long mem;
-	ihandle prom_cpu;
-	phandle cpu_pkg;
+	phandle node;
+	ihandle ih;
+	int i, j;
 	unsigned long offset = reloc_offset();
-	long l;
-	char *p, *d;
-	unsigned long phys;
-	u32 getprop_rval;
-	struct systemcfg *_systemcfg;
-	struct paca_struct *_xPaca = PTRRELOC(&paca[0]);
-	struct prom_t *_prom = PTRRELOC(&prom);
+        struct prom_t *_prom = PTRRELOC(&prom);
+	char type[16], *path;
+	static unsigned char default_colors[] = {
+		0x00, 0x00, 0x00,
+		0x00, 0x00, 0xaa,
+		0x00, 0xaa, 0x00,
+		0x00, 0xaa, 0xaa,
+		0xaa, 0x00, 0x00,
+		0xaa, 0x00, 0xaa,
+		0xaa, 0xaa, 0x00,
+		0xaa, 0xaa, 0xaa,
+		0x55, 0x55, 0x55,
+		0x55, 0x55, 0xff,
+		0x55, 0xff, 0x55,
+		0x55, 0xff, 0xff,
+		0xff, 0x55, 0x55,
+		0xff, 0x55, 0xff,
+		0xff, 0xff, 0x55,
+		0xff, 0xff, 0xff
+	};
+	const unsigned char *clut;
 
-	/* First zero the BSS -- use memset, some arches don't have
-	 * caches on yet */
-	memset(PTRRELOC(&__bss_start), 0, __bss_stop - __bss_start);
-
-	/* Setup systemcfg and NACA pointers now */
-	RELOC(systemcfg) = _systemcfg = (struct systemcfg *)(SYSTEMCFG_VIRT_ADDR - offset);
-	RELOC(naca) = (struct naca_struct *)(NACA_VIRT_ADDR - offset);
-
-	/* Init interface to Open Firmware and pickup bi-recs */
-	prom_init_client_services(pp);
-
-	/* Init prom stdout device */
-	prom_init_stdout();
-
-	/* check out if we have bi_recs */
-	_prom->bi_recs = prom_bi_rec_verify((struct bi_record *)r6);
-	if ( _prom->bi_recs != NULL )
-		RELOC(klimit) = PTRUNRELOC((unsigned long)_prom->bi_recs +
-					   _prom->bi_recs->data[1]);
-
-	/* Default machine type. */
-	_systemcfg->platform = prom_find_machine_type();
-
-	/* On pSeries, copy the CPU hold code */
-	if (_systemcfg->platform == PLATFORM_PSERIES)
-		copy_and_flush(0, KERNELBASE - offset, 0x100, 0);
-
-	/* Start storing things at klimit */
-      	mem = RELOC(klimit) - offset; 
-
-	/* Get the full OF pathname of the stdout device */
-	p = (char *) mem;
-	memset(p, 0, 256);
-	call_prom(RELOC("instance-to-path"), 3, 1, _prom->stdout, p, 255);
-	RELOC(of_stdout_device) = PTRUNRELOC(p);
-	mem += strlen(p) + 1;
-
-	getprop_rval = 1;
-	call_prom(RELOC("getprop"), 4, 1,
-		  _prom->root, RELOC("#size-cells"),
-		  &getprop_rval, sizeof(getprop_rval));
-	_prom->encode_phys_size = (getprop_rval == 1) ? 32 : 64;
-
-	/* Determine which cpu is actually running right _now_ */
-        if ((long)call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
-			    RELOC("cpu"), &getprop_rval,
-			    sizeof(getprop_rval)) <= 0)
-                prom_panic(RELOC("cannot find boot cpu"));
-
-	prom_cpu = (ihandle)(unsigned long)getprop_rval;
-	cpu_pkg = call_prom(RELOC("instance-to-package"), 1, 1, prom_cpu);
-	call_prom(RELOC("getprop"), 4, 1,
-		cpu_pkg, RELOC("reg"),
-		&getprop_rval, sizeof(getprop_rval));
-	_prom->cpu = (int)(unsigned long)getprop_rval;
-	_xPaca[0].xHwProcNum = _prom->cpu;
-
-	RELOC(boot_cpuid) = 0;
-
-#ifdef DEBUG_PROM
-  	prom_print(RELOC("Booting CPU hw index = 0x"));
-  	prom_print_hex(_prom->cpu);
-  	prom_print_nl();
-#endif
-
-	/* Get the boot device and translate it to a full OF pathname. */
-	p = (char *) mem;
-	l = (long) call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
-			    RELOC("bootpath"), p, 1<<20);
-	if (l > 0) {
-		p[l] = 0;	/* should already be null-terminated */
-		RELOC(bootpath) = PTRUNRELOC(p);
-		mem += l + 1;
-		d = (char *) mem;
-		*d = 0;
-		call_prom(RELOC("canon"), 3, 1, p, d, 1<<20);
-		RELOC(bootdevice) = PTRUNRELOC(d);
-		mem = DOUBLEWORD_ALIGN(mem + strlen(d) + 1);
-	}
-
-	RELOC(cmd_line[0]) = 0;
-	if ((long)_prom->chosen > 0) {
-		call_prom(RELOC("getprop"), 4, 1, _prom->chosen, 
-			  RELOC("bootargs"), p, sizeof(cmd_line));
-		if (p != NULL && p[0] != 0)
-			strlcpy(RELOC(cmd_line), p, sizeof(cmd_line));
-	}
-
-	early_cmdline_parse();
-
-	mem = prom_initialize_lmb(mem);
-
-	mem = prom_bi_rec_reserve(mem);
-
-	mem = check_display(mem);
-
-	if (_systemcfg->platform != PLATFORM_POWERMAC)
-		prom_instantiate_rtas();
-        
-        /* Initialize some system info into the Naca early... */
-        mem = prom_initialize_naca(mem);
-
-	smt_setup();
-	
-        /* If we are on an SMP machine, then we *MUST* do the
-         * following, regardless of whether we have an SMP
-         * kernel or not.
-         */
-	prom_hold_cpus(mem);
-
-#ifdef DEBUG_PROM
-	prom_print(RELOC("copying OF device tree...\n"));
-#endif
-	mem = copy_device_tree(mem);
-
-	RELOC(klimit) = mem + offset;
-
-	lmb_reserve(0, __pa(RELOC(klimit)));
-
-	if (_systemcfg->platform == PLATFORM_PSERIES)
-		prom_initialize_tce_table();
-
-#ifdef CONFIG_PMAC_DART
-	if (_systemcfg->platform == PLATFORM_POWERMAC)
-		prom_initialize_dart_table();
-#endif
-
-#ifdef CONFIG_BOOTX_TEXT
-	if(_prom->disp_node) {
-		prom_print(RELOC("Setting up bi display...\n"));
-		setup_disp_fake_bi(_prom->disp_node);
-	}
-#endif /* CONFIG_BOOTX_TEXT */
-
-	prom_print(RELOC("Calling quiesce ...\n"));
-	call_prom(RELOC("quiesce"), 0, 0);
-	phys = KERNELBASE - offset;
-
-	prom_print(RELOC("returning from prom_init\n"));
-	return phys;
-}
-
-
-static int
-prom_set_color(ihandle ih, int i, int r, int g, int b)
-{
-	unsigned long offset = reloc_offset();
-
-	return (int)(long)call_prom(RELOC("call-method"), 6, 1,
-		                    RELOC("color!"),
-                                    ih,
-                                    (void *)(long) i,
-                                    (void *)(long) b,
-                                    (void *)(long) g,
-                                    (void *)(long) r );
-}
-
-/*
- * If we have a display that we don't know how to drive,
- * we will want to try to execute OF's open method for it
- * later.  However, OF will probably fall over if we do that
- * we've taken over the MMU.
- * So we check whether we will need to open the display,
- * and if so, open it now.
- */
-static unsigned long __init
-check_display(unsigned long mem)
-{
-	phandle node;
-	ihandle ih;
-	int i, j;
-	unsigned long offset = reloc_offset();
-        struct prom_t *_prom = PTRRELOC(&prom);
-	char type[16], *path;
-	static unsigned char default_colors[] = {
-		0x00, 0x00, 0x00,
-		0x00, 0x00, 0xaa,
-		0x00, 0xaa, 0x00,
-		0x00, 0xaa, 0xaa,
-		0xaa, 0x00, 0x00,
-		0xaa, 0x00, 0xaa,
-		0xaa, 0xaa, 0x00,
-		0xaa, 0xaa, 0xaa,
-		0x55, 0x55, 0x55,
-		0x55, 0x55, 0xff,
-		0x55, 0xff, 0x55,
-		0x55, 0xff, 0xff,
-		0xff, 0x55, 0x55,
-		0xff, 0x55, 0xff,
-		0xff, 0xff, 0x55,
-		0xff, 0xff, 0xff
-	};
-	const unsigned char *clut;
-
-	_prom->disp_node = 0;
+	_prom->disp_node = 0;
 
 	prom_print(RELOC("Looking for displays\n"));
 	if (RELOC(of_stdout_device) != 0) {
@@ -1788,52 +1539,48 @@ check_display(unsigned long mem)
 	return DOUBLEWORD_ALIGN(mem);
 }
 
-
-static int __init
-prom_next_node(phandle *nodep)
+/* Return (relocated) pointer to this much memory: moves initrd if reqd. */
+static void __init *__make_room(unsigned long *mem_start, unsigned long *mem_end,
+				unsigned long needed, unsigned long align)
 {
-	phandle node;
+	void *ret;
 	unsigned long offset = reloc_offset();
 
-	if ((node = *nodep) != 0
-	    && (*nodep = call_prom(RELOC("child"), 1, 1, node)) != 0)
-		return 1;
-	if ((*nodep = call_prom(RELOC("peer"), 1, 1, node)) != 0)
-		return 1;
-	for (;;) {
-		if ((node = call_prom(RELOC("parent"), 1, 1, node)) == 0)
-			return 0;
-		if ((*nodep = call_prom(RELOC("peer"), 1, 1, node)) != 0)
-			return 1;
-	}
-}
+	*mem_start = ALIGN(*mem_start, align);
+	if (*mem_start + needed > *mem_end) {
+#ifdef CONFIG_BLK_DEV_INITRD
+		/* FIXME: Apple OF doesn't map unclaimed mem.  If this
+		 * ever happened on G5, we'd need to fix. */
+		unsigned long initrd_len;
 
-/*
- * Make a copy of the device tree from the PROM.
- */
-static unsigned long __init
-copy_device_tree(unsigned long mem_start)
-{
-	phandle root;
-	unsigned long new_start;
-	struct device_node **allnextp;
-	unsigned long offset = reloc_offset();
-	unsigned long mem_end = mem_start + (8<<20);
+		if (*mem_end != RELOC(initrd_start))
+			prom_panic(RELOC("No memory for copy_device_tree"));
 
-	root = call_prom(RELOC("peer"), 1, 1, (phandle)0);
-	if (root == (phandle)0) {
-		prom_panic(RELOC("couldn't get device tree root\n"));
+		prom_print("Huge device_tree: moving initrd\n");
+		/* Move by 4M. */
+		initrd_len = RELOC(initrd_end) - RELOC(initrd_start);
+		*mem_end = RELOC(initrd_start) + 4 * 1024 * 1024;
+		memmove((void *)*mem_end, (void *)RELOC(initrd_start),
+			initrd_len);
+		RELOC(initrd_start) = *mem_end;
+		RELOC(initrd_end) = RELOC(initrd_start) + initrd_len;
+#else
+		prom_panic(RELOC("No memory for copy_device_tree"));
+#endif
 	}
-	allnextp = &RELOC(allnodes);
-	mem_start = DOUBLEWORD_ALIGN(mem_start);
-	new_start = inspect_node(root, 0, mem_start, mem_end, &allnextp);
-	*allnextp = 0;
-	return new_start;
+
+	ret = (void *)*mem_start;
+	*mem_start += needed;
+
+	return ret;
 }
 
-static unsigned long __init
+#define make_room(startp, endp, type) \
+	__make_room(startp, endp, sizeof(type), __alignof__(type))
+
+static void __init
 inspect_node(phandle node, struct device_node *dad,
-	     unsigned long mem_start, unsigned long mem_end,
+	     unsigned long *mem_start, unsigned long *mem_end,
 	     struct device_node ***allnextpp)
 {
 	int l;
@@ -1844,9 +1591,9 @@ inspect_node(phandle node, struct device
 	unsigned char *valp;
 	unsigned long offset = reloc_offset();
 
-	np = (struct device_node *) mem_start;
-	mem_start += sizeof(struct device_node);
+	np = make_room(mem_start, mem_end, struct device_node);
 	memset(np, 0, sizeof(*np));
+
 	np->node = node;
 	**allnextpp = PTRUNRELOC(np);
 	*allnextpp = &np->allnext;
@@ -1864,19 +1611,22 @@ inspect_node(phandle node, struct device
 	prev_propp = &np->properties;
 	prev_name = RELOC("");
 	for (;;) {
-		pp = (struct property *) mem_start;
-		namep = (char *) (pp + 1);
-		pp->name = PTRUNRELOC(namep);
+		/* 32 is max len of name including nul. */
+		namep = make_room(mem_start, mem_end, char[32]);
 		if ((long) call_prom(RELOC("nextprop"), 3, 1, node, prev_name,
-				    namep) <= 0)
+				     namep) <= 0) {
+			/* No more nodes: unwind alloc */
+			*mem_start = (unsigned long)namep;
 			break;
-		mem_start = DOUBLEWORD_ALIGN((unsigned long)namep + strlen(namep) + 1);
+		}
+		/* Trim off some if we can */
+		*mem_start = DOUBLEWORD_ALIGN((unsigned long)namep
+					     + strlen(namep) + 1);
+		pp = make_room(mem_start, mem_end, struct property);
+		pp->name = PTRUNRELOC(namep);
 		prev_name = namep;
-		valp = (unsigned char *) mem_start;
-		pp->value = PTRUNRELOC(valp);
-		pp->length = (int)(long)
-			call_prom(RELOC("getprop"), 4, 1, node, namep,
-				  valp, mem_end - mem_start);
+
+		pp->length = call_prom(RELOC("getproplen"), 2, 1, node, namep);
 		if (pp->length < 0)
 			continue;
 		if (pp->length > MAX_PROPERTY_LENGTH) {
@@ -1895,7 +1645,9 @@ inspect_node(phandle node, struct device
 
 			continue;
 		}
-		mem_start = DOUBLEWORD_ALIGN(mem_start + pp->length);
+		valp = __make_room(mem_start, mem_end, pp->length, 1);
+		pp->value = PTRUNRELOC(valp);
+		call_prom(RELOC("getprop"), 4, 1, node, namep,valp,pp->length);
 		*prev_propp = PTRUNRELOC(pp);
 		prev_propp = &pp->next;
 	}
@@ -1919,104 +1671,392 @@ inspect_node(phandle node, struct device
 	*prev_propp = 0;
 
 	/* get the node's full name */
+	namep = (char *)*mem_start;
 	l = (long) call_prom(RELOC("package-to-path"), 3, 1, node,
-			    (char *) mem_start, mem_end - mem_start);
+			     namep, *mem_end - *mem_start);
 	if (l >= 0) {
-		np->full_name = PTRUNRELOC((char *) mem_start);
-		*(char *)(mem_start + l) = 0;
-		mem_start = DOUBLEWORD_ALIGN(mem_start + l + 1);
+		/* Didn't fit?  Get more room. */
+		if (l+1 > *mem_end - *mem_start) {
+			namep = __make_room(mem_start, mem_end, l+1, 1);
+			call_prom(RELOC("package-to-path"),3,1,node,namep,l);
+		}
+		np->full_name = PTRUNRELOC(namep);
+		namep[l] = '\0';
+		*mem_start = DOUBLEWORD_ALIGN(*mem_start + l + 1);
 	}
 
 	/* do all our children */
 	child = call_prom(RELOC("child"), 1, 1, node);
 	while (child != (phandle)0) {
-		mem_start = inspect_node(child, np, mem_start, mem_end,
+		inspect_node(child, np, mem_start, mem_end,
 					 allnextpp);
 		child = call_prom(RELOC("peer"), 1, 1, child);
 	}
-
-	return mem_start;
 }
 
 /*
- * finish_device_tree is called once things are running normally
- * (i.e. with text and data mapped to the address they were linked at).
- * It traverses the device tree and fills in the name, type,
- * {n_}addrs and {n_}intrs fields of each node.
+ * Make a copy of the device tree from the PROM.
  */
-void __init
-finish_device_tree(void)
+static unsigned long __init
+copy_device_tree(unsigned long mem_start)
 {
-	unsigned long mem = klimit;
+	phandle root;
+	struct device_node **allnextp;
+	unsigned long offset = reloc_offset();
+	unsigned long mem_end;
 
-	virt_irq_init();
+	/* We pass mem_end-mem_start to OF: keep it well under 32-bit */
+	mem_end = mem_start + 1024*1024*1024;
+#ifdef CONFIG_BLK_DEV_INITRD
+	if (RELOC(initrd_start) && RELOC(initrd_start) > mem_start)
+		mem_end = RELOC(initrd_start);
+#endif /* CONFIG_BLK_DEV_INITRD */
+
+	root = call_prom(RELOC("peer"), 1, 1, (phandle)0);
+	if (root == (phandle)0) {
+		prom_panic(RELOC("couldn't get device tree root\n"));
+	}
+	allnextp = &RELOC(allnodes);
+	inspect_node(root, 0, &mem_start, &mem_end, &allnextp);
+	*allnextp = 0;
+	return mem_start;
+}
+
+/* Verify bi_recs are good */
+static struct bi_record * __init prom_bi_rec_verify(struct bi_record *bi_recs)
+{
+	struct bi_record *first, *last;
+#ifdef DEBUG_PROM
+	unsigned long offset = reloc_offset();
 
-	mem = finish_node(allnodes, mem, NULL, 0, 0);
-	dev_tree_size = mem - (unsigned long) allnodes;
+  	prom_print(RELOC("birec_verify: r6=0x"));
+  	prom_print_hex((unsigned long)bi_recs);
+  	prom_print_nl();
+	if (bi_recs != NULL) {
+		prom_print(RELOC("  tag=0x"));
+		prom_print_hex(bi_recs->tag);
+		prom_print_nl();
+	}
+#endif /* DEBUG_PROM */
 
-	mem = _ALIGN(mem, PAGE_SIZE);
-	lmb_reserve(__pa(klimit), mem-klimit);
+	if ( bi_recs == NULL || bi_recs->tag != BI_FIRST )
+		return NULL;
 
-	klimit = mem;
+	last = (struct bi_record *)(long)bi_recs->data[0];
 
-	rtas.dev = of_find_node_by_name(NULL, "rtas");
+#ifdef DEBUG_PROM
+  	prom_print(RELOC("  last=0x"));
+  	prom_print_hex((unsigned long)last);
+  	prom_print_nl();
+	if (last != NULL) {
+		prom_print(RELOC("  last_tag=0x"));
+		prom_print_hex(last->tag);
+		prom_print_nl();
+	}
+#endif /* DEBUG_PROM */
+
+	if ( last == NULL || last->tag != BI_LAST )
+		return NULL;
+
+	first = (struct bi_record *)(long)last->data[0];
+#ifdef DEBUG_PROM
+  	prom_print(RELOC("  first=0x"));
+  	prom_print_hex((unsigned long)first);
+  	prom_print_nl();
+#endif /* DEBUG_PROM */
+
+	if ( first == NULL || first != bi_recs )
+		return NULL;
+
+	return bi_recs;
 }
 
-static unsigned long __init
-finish_node(struct device_node *np, unsigned long mem_start,
-	    interpret_func *ifunc, int naddrc, int nsizec)
+static void __init prom_bi_rec_reserve(void)
 {
-	struct device_node *child;
-	int *ip;
+	unsigned long offset = reloc_offset();
+	struct prom_t *_prom = PTRRELOC(&prom);
+	struct bi_record *rec;
 
-	np->name = get_property(np, "name", 0);
-	np->type = get_property(np, "device_type", 0);
+	if ( _prom->bi_recs != NULL) {
+
+		for ( rec=_prom->bi_recs;
+		      rec->tag != BI_LAST;
+		      rec=bi_rec_next(rec) ) {
+#ifdef DEBUG_PROM
+			prom_print(RELOC("bi: 0x"));
+			prom_print_hex(rec->tag);
+			prom_print_nl();
+#endif /* DEBUG_PROM */
+			switch (rec->tag) {
+#ifdef CONFIG_BLK_DEV_INITRD
+			case BI_INITRD:
+				RELOC(initrd_start) = (unsigned long)(rec->data[0]);
+				RELOC(initrd_end) = RELOC(initrd_start) + rec->data[1];
+				break;
+#endif /* CONFIG_BLK_DEV_INITRD */
+			}
+		}
+		/* The next use of this field will be after relocation
+	 	 * is enabled, so convert this physical address into a
+	 	 * virtual address.
+	 	 */
+		_prom->bi_recs = PTRUNRELOC(_prom->bi_recs);
+	}
+}
+
+/*
+ * We enter here early on, when the Open Firmware prom is still
+ * handling exceptions and the MMU hash table for us.
+ */
+
+unsigned long __init
+prom_init(unsigned long r3, unsigned long r4, unsigned long pp,
+	  unsigned long r6, unsigned long r7)
+{
+	unsigned long mem;
+	ihandle prom_cpu;
+	phandle cpu_pkg;
+	unsigned long offset = reloc_offset();
+	long l;
+	char *p, *d;
+	unsigned long phys;
+	u32 getprop_rval;
+	struct systemcfg *_systemcfg;
+	struct paca_struct *_xPaca = PTRRELOC(&paca[0]);
+	struct prom_t *_prom = PTRRELOC(&prom);
+
+	/* First zero the BSS -- use memset, some arches don't have
+	 * caches on yet */
+	memset(PTRRELOC(&__bss_start), 0, __bss_stop - __bss_start);
+
+	/* Setup systemcfg and NACA pointers now */
+	RELOC(systemcfg) = _systemcfg = (struct systemcfg *)(SYSTEMCFG_VIRT_ADDR - offset);
+	RELOC(naca) = (struct naca_struct *)(NACA_VIRT_ADDR - offset);
+
+	/* Init interface to Open Firmware and pickup bi-recs */
+	prom_init_client_services(pp);
+
+	/* Init prom stdout device */
+	prom_init_stdout();
+
+#ifdef DEBUG_PROM
+  	prom_print(RELOC("klimit=0x"));
+  	prom_print_hex(RELOC(klimit));
+  	prom_print_nl();
+  	prom_print(RELOC("offset=0x"));
+  	prom_print_hex(offset);
+  	prom_print_nl();
+  	prom_print(RELOC("->mem=0x"));
+  	prom_print_hex(RELOC(klimit) - offset);
+  	prom_print_nl();
+#endif /* DEBUG_PROM */
+
+	/* check out if we have bi_recs */
+	_prom->bi_recs = prom_bi_rec_verify((struct bi_record *)r6);
+	if ( _prom->bi_recs != NULL ) {
+		RELOC(klimit) = PTRUNRELOC((unsigned long)_prom->bi_recs +
+					   _prom->bi_recs->data[1]);
+#ifdef DEBUG_PROM
+		prom_print(RELOC("bi_recs=0x"));
+		prom_print_hex((unsigned long)_prom->bi_recs);
+		prom_print_nl();
+		prom_print(RELOC("new mem=0x"));
+		prom_print_hex(RELOC(klimit) - offset);
+		prom_print_nl();
+#endif /* DEBUG_PROM */
+	}
+
+	/* If we don't have birec's or didn't find them, check for an initrd
+	 * using the "yaboot" way
+	 */
+#ifdef CONFIG_BLK_DEV_INITRD
+	if ( _prom->bi_recs == NULL && r3 && r4 && r4 != 0xdeadbeef) {
+		RELOC(initrd_start) = (r3 >= KERNELBASE) ? __pa(r3) : r3;
+		RELOC(initrd_end) = RELOC(initrd_start) + r4;
+		RELOC(initrd_below_start_ok) = 1;
+	}
+#endif /* CONFIG_BLK_DEV_INITRD */
+
+	/* Default machine type. */
+	_systemcfg->platform = prom_find_machine_type();
+
+	/* On pSeries, copy the CPU hold code */
+	if (_systemcfg->platform == PLATFORM_PSERIES)
+		copy_and_flush(0, KERNELBASE - offset, 0x100, 0);
+
+	/* Start storing things at klimit */
+      	mem = RELOC(klimit) - offset;
+
+	/* Get the full OF pathname of the stdout device */
+	p = (char *) mem;
+	memset(p, 0, 256);
+	call_prom(RELOC("instance-to-path"), 3, 1, _prom->stdout, p, 255);
+	RELOC(of_stdout_device) = PTRUNRELOC(p);
+	mem += strlen(p) + 1;
+
+	getprop_rval = 1;
+	call_prom(RELOC("getprop"), 4, 1,
+		  _prom->root, RELOC("#size-cells"),
+		  &getprop_rval, sizeof(getprop_rval));
+	_prom->encode_phys_size = (getprop_rval == 1) ? 32 : 64;
+
+	/* Determine which cpu is actually running right _now_ */
+        if ((long)call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
+			    RELOC("cpu"), &getprop_rval,
+			    sizeof(getprop_rval)) <= 0)
+                prom_panic(RELOC("cannot find boot cpu"));
+
+	prom_cpu = (ihandle)(unsigned long)getprop_rval;
+	cpu_pkg = call_prom(RELOC("instance-to-package"), 1, 1, prom_cpu);
+	call_prom(RELOC("getprop"), 4, 1,
+		cpu_pkg, RELOC("reg"),
+		&getprop_rval, sizeof(getprop_rval));
+	_prom->cpu = (int)(unsigned long)getprop_rval;
+	_xPaca[0].xHwProcNum = _prom->cpu;
+
+	RELOC(boot_cpuid) = 0;
+
+#ifdef DEBUG_PROM
+  	prom_print(RELOC("Booting CPU hw index = 0x"));
+  	prom_print_hex(_prom->cpu);
+  	prom_print_nl();
+#endif
+
+	/* Get the boot device and translate it to a full OF pathname. */
+	p = (char *) mem;
+	l = (long) call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
+			    RELOC("bootpath"), p, 1<<20);
+	if (l > 0) {
+		p[l] = 0;	/* should already be null-terminated */
+		RELOC(bootpath) = PTRUNRELOC(p);
+		mem += l + 1;
+		d = (char *) mem;
+		*d = 0;
+		call_prom(RELOC("canon"), 3, 1, p, d, 1<<20);
+		RELOC(bootdevice) = PTRUNRELOC(d);
+		mem = DOUBLEWORD_ALIGN(mem + strlen(d) + 1);
+	}
+
+	RELOC(cmd_line[0]) = 0;
+	if ((long)_prom->chosen > 0) {
+		call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
+			  RELOC("bootargs"), p, sizeof(cmd_line));
+		if (p != NULL && p[0] != 0)
+			strlcpy(RELOC(cmd_line), p, sizeof(cmd_line));
+	}
+
+	early_cmdline_parse();
+
+	prom_initialize_lmb();
+
+	prom_bi_rec_reserve();
+
+	mem = check_display(mem);
+
+	if (_systemcfg->platform != PLATFORM_POWERMAC)
+		prom_instantiate_rtas();
+
+        /* Initialize some system info into the Naca early... */
+        prom_initialize_naca();
+
+	smt_setup();
+
+        /* If we are on an SMP machine, then we *MUST* do the
+         * following, regardless of whether we have an SMP
+         * kernel or not.
+         */
+	prom_hold_cpus(mem);
+
+#ifdef DEBUG_PROM
+  	prom_print(RELOC("after basic inits, mem=0x"));
+  	prom_print_hex(mem);
+  	prom_print_nl();
+#ifdef CONFIG_BLK_DEV_INITRD
+	prom_print(RELOC("initrd_start=0x"));
+	prom_print_hex(RELOC(initrd_start));
+	prom_print_nl();
+	prom_print(RELOC("initrd_end=0x"));
+	prom_print_hex(RELOC(initrd_end));
+	prom_print_nl();
+#endif /* CONFIG_BLK_DEV_INITRD */
+	prom_print(RELOC("copying OF device tree...\n"));
+#endif /* DEBUG_PROM */
+	mem = copy_device_tree(mem);
+
+	RELOC(klimit) = mem + offset;
+
+#ifdef DEBUG_PROM
+	prom_print(RELOC("new klimit is\n"));
+  	prom_print(RELOC("klimit=0x"));
+  	prom_print_hex(RELOC(klimit));
+	prom_print(RELOC(" ->mem=0x\n"));
+  	prom_print(RELOC("klimit=0x"));
+  	prom_print_hex(mem);
+  	prom_print_nl();
+#endif /* DEBUG_PROM */
+
+	lmb_reserve(0, __pa(RELOC(klimit)));
+
+#ifdef CONFIG_BLK_DEV_INITRD
+	if (RELOC(initrd_start)) {
+		unsigned long initrd_len;
+		initrd_len = RELOC(initrd_end) - RELOC(initrd_start);
+
+		/* Move initrd if it's where we're going to copy kernel. */
+		if (RELOC(initrd_start) < __pa(RELOC(klimit))) {
+			memmove((void *)mem, (void *)RELOC(initrd_start),
+				initrd_len);
+			RELOC(initrd_start) = mem;
+			RELOC(initrd_end) = mem + initrd_len;
+		}
+
+		lmb_reserve(RELOC(initrd_start), initrd_len);
+	}
+#endif /* CONFIG_BLK_DEV_INITRD */
+
+	if (_systemcfg->platform == PLATFORM_PSERIES)
+		prom_initialize_tce_table();
 
-	/* get the device addresses and interrupts */
-	if (ifunc != NULL)
-		mem_start = ifunc(np, mem_start, naddrc, nsizec);
+#ifdef CONFIG_PMAC_DART
+	if (_systemcfg->platform == PLATFORM_POWERMAC)
+		prom_initialize_dart_table();
+#endif
 
-	mem_start = finish_node_interrupts(np, mem_start);
+#ifdef CONFIG_BOOTX_TEXT
+	if(_prom->disp_node) {
+		prom_print(RELOC("Setting up bi display...\n"));
+		setup_disp_fake_bi(_prom->disp_node);
+	}
+#endif /* CONFIG_BOOTX_TEXT */
 
-	/* Look for #address-cells and #size-cells properties. */
-	ip = (int *) get_property(np, "#address-cells", 0);
-	if (ip != NULL)
-		naddrc = *ip;
-	ip = (int *) get_property(np, "#size-cells", 0);
-	if (ip != NULL)
-		nsizec = *ip;
+	prom_print(RELOC("Calling quiesce ...\n"));
+	call_prom(RELOC("quiesce"), 0, 0);
+	phys = KERNELBASE - offset;
 
-	/* the f50 sets the name to 'display' and 'compatible' to what we
-	 * expect for the name -- Cort
-	 */
-	if (!strcmp(np->name, "display"))
-		np->name = get_property(np, "compatible", 0);
+#ifdef CONFIG_BLK_DEV_INITRD
+	/* If we had an initrd, we convert its address to virtual */
+	if (RELOC(initrd_start)) {
+		RELOC(initrd_start) = (unsigned long)__va(RELOC(initrd_start));
+		RELOC(initrd_end) = (unsigned long)__va(RELOC(initrd_end));
+	}
+#endif /* CONFIG_BLK_DEV_INITRD */
 
-	if (!strcmp(np->name, "device-tree") || np->parent == NULL)
-		ifunc = interpret_root_props;
-	else if (np->type == 0)
-		ifunc = NULL;
-	else if (!strcmp(np->type, "pci") || !strcmp(np->type, "vci"))
-		ifunc = interpret_pci_props;
-	else if (!strcmp(np->type, "dbdma"))
-		ifunc = interpret_dbdma_props;
-	else if (!strcmp(np->type, "mac-io") || ifunc == interpret_macio_props)
-		ifunc = interpret_macio_props;
-	else if (!strcmp(np->type, "isa"))
-		ifunc = interpret_isa_props;
-	else if (!strcmp(np->name, "uni-n") || !strcmp(np->name, "u3"))
-		ifunc = interpret_root_props;
-	else if (!((ifunc == interpret_dbdma_props
-		    || ifunc == interpret_macio_props)
-		   && (!strcmp(np->type, "escc")
-		       || !strcmp(np->type, "media-bay"))))
-		ifunc = NULL;
+	prom_print(RELOC("returning from prom_init\n"));
+	return phys;
+}
 
-	for (child = np->child; child != NULL; child = child->sibling)
-		mem_start = finish_node(child, mem_start, ifunc,
-					naddrc, nsizec);
+/*
+ * Find the device_node with a given phandle.
+ */
+static struct device_node * __devinit
+find_phandle(phandle ph)
+{
+	struct device_node *np;
 
-	return mem_start;
+	for (np = allnodes; np != 0; np = np->allnext)
+		if (np->linux_phandle == ph)
+			return np;
+	return NULL;
 }
 
 /*
@@ -2159,11 +2199,9 @@ map_interrupt(unsigned int **irq, struct
 	return nintrc;
 }
 
-/*
- * New version of finish_node_interrupts.
- */
 static unsigned long __init
-finish_node_interrupts(struct device_node *np, unsigned long mem_start)
+finish_node_interrupts(struct device_node *np, unsigned long mem_start,
+		       int measure_only)
 {
 	unsigned int *ints;
 	int intlen, intrcells;
@@ -2180,6 +2218,9 @@ finish_node_interrupts(struct device_nod
 	np->intrs = (struct interrupt_info *) mem_start;
 	mem_start += intlen * sizeof(struct interrupt_info);
 
+	if (measure_only)
+		return mem_start;
+
 	for (i = 0; i < intlen; ++i) {
 		np->intrs[i].line = 0;
 		np->intrs[i].sense = 1;
@@ -2191,7 +2232,7 @@ finish_node_interrupts(struct device_nod
 			printk(KERN_CRIT "Could not allocate interrupt "
 			       "number for %s\n", np->full_name);
 		} else
-			np->intrs[i].line = openpic_to_irq(virq);
+			np->intrs[i].line = irq_offset_up(virq);
 
 		/* We offset irq numbers for the u3 MPIC by 128 in PowerMac */
 		if (systemcfg->platform == PLATFORM_POWERMAC && ic && ic->parent) {
@@ -2214,39 +2255,9 @@ finish_node_interrupts(struct device_nod
 	return mem_start;
 }
 
-int
-prom_n_addr_cells(struct device_node* np)
-{
-	int* ip;
-	do {
-		if (np->parent)
-			np = np->parent;
-		ip = (int *) get_property(np, "#address-cells", 0);
-		if (ip != NULL)
-			return *ip;
-	} while (np->parent);
-	/* No #address-cells property for the root node, default to 1 */
-	return 1;
-}
-
-int
-prom_n_size_cells(struct device_node* np)
-{
-	int* ip;
-	do {
-		if (np->parent)
-			np = np->parent;
-		ip = (int *) get_property(np, "#size-cells", 0);
-		if (ip != NULL)
-			return *ip;
-	} while (np->parent);
-	/* No #size-cells property for the root node, default to 1 */
-	return 1;
-}
-
 static unsigned long __init
 interpret_pci_props(struct device_node *np, unsigned long mem_start,
-		    int naddrc, int nsizec)
+		    int naddrc, int nsizec, int measure_only)
 {
 	struct address_range *adr;
 	struct pci_reg_property *pci_addrs;
@@ -2258,9 +2269,11 @@ interpret_pci_props(struct device_node *
 		i = 0;
 		adr = (struct address_range *) mem_start;
 		while ((l -= sizeof(struct pci_reg_property)) >= 0) {
-			adr[i].space = pci_addrs[i].addr.a_hi;
-			adr[i].address = pci_addrs[i].addr.a_lo;
-			adr[i].size = pci_addrs[i].size_lo;
+ 			if (!measure_only) {
+				adr[i].space = pci_addrs[i].addr.a_hi;
+				adr[i].address = pci_addrs[i].addr.a_lo;
+				adr[i].size = pci_addrs[i].size_lo;
+			}
 			++i;
 		}
 		np->addrs = adr;
@@ -2272,7 +2285,7 @@ interpret_pci_props(struct device_node *
 
 static unsigned long __init
 interpret_dbdma_props(struct device_node *np, unsigned long mem_start,
-		      int naddrc, int nsizec)
+		      int naddrc, int nsizec, int measure_only)
 {
 	struct reg_property32 *rp;
 	struct address_range *adr;
@@ -2281,10 +2294,12 @@ interpret_dbdma_props(struct device_node
 	struct device_node *db;
 
 	base_address = 0;
-	for (db = np->parent; db != NULL; db = db->parent) {
-		if (!strcmp(db->type, "dbdma") && db->n_addrs != 0) {
-			base_address = db->addrs[0].address;
-			break;
+	if (!measure_only) {
+		for (db = np->parent; db != NULL; db = db->parent) {
+			if (!strcmp(db->type, "dbdma") && db->n_addrs != 0) {
+				base_address = db->addrs[0].address;
+				break;
+			}
 		}
 	}
 
@@ -2293,9 +2308,11 @@ interpret_dbdma_props(struct device_node
 		i = 0;
 		adr = (struct address_range *) mem_start;
 		while ((l -= sizeof(struct reg_property32)) >= 0) {
-			adr[i].space = 2;
-			adr[i].address = rp[i].address + base_address;
-			adr[i].size = rp[i].size;
+ 			if (!measure_only) {
+				adr[i].space = 2;
+				adr[i].address = rp[i].address + base_address;
+				adr[i].size = rp[i].size;
+			}
 			++i;
 		}
 		np->addrs = adr;
@@ -2308,7 +2325,7 @@ interpret_dbdma_props(struct device_node
 
 static unsigned long __init
 interpret_macio_props(struct device_node *np, unsigned long mem_start,
-		      int naddrc, int nsizec)
+		      int naddrc, int nsizec, int measure_only)
 {
 	struct reg_property32 *rp;
 	struct address_range *adr;
@@ -2317,10 +2334,12 @@ interpret_macio_props(struct device_node
 	struct device_node *db;
 
 	base_address = 0;
-	for (db = np->parent; db != NULL; db = db->parent) {
-		if (!strcmp(db->type, "mac-io") && db->n_addrs != 0) {
-			base_address = db->addrs[0].address;
-			break;
+	if (!measure_only) {
+		for (db = np->parent; db != NULL; db = db->parent) {
+			if (!strcmp(db->type, "mac-io") && db->n_addrs != 0) {
+				base_address = db->addrs[0].address;
+				break;
+			}
 		}
 	}
 
@@ -2329,9 +2348,11 @@ interpret_macio_props(struct device_node
 		i = 0;
 		adr = (struct address_range *) mem_start;
 		while ((l -= sizeof(struct reg_property32)) >= 0) {
-			adr[i].space = 2;
-			adr[i].address = rp[i].address + base_address;
-			adr[i].size = rp[i].size;
+ 			if (!measure_only) {
+				adr[i].space = 2;
+				adr[i].address = rp[i].address + base_address;
+				adr[i].size = rp[i].size;
+			}
 			++i;
 		}
 		np->addrs = adr;
@@ -2344,7 +2365,7 @@ interpret_macio_props(struct device_node
 
 static unsigned long __init
 interpret_isa_props(struct device_node *np, unsigned long mem_start,
-		    int naddrc, int nsizec)
+		    int naddrc, int nsizec, int measure_only)
 {
 	struct isa_reg_property *rp;
 	struct address_range *adr;
@@ -2355,9 +2376,11 @@ interpret_isa_props(struct device_node *
 		i = 0;
 		adr = (struct address_range *) mem_start;
 		while ((l -= sizeof(struct reg_property)) >= 0) {
-			adr[i].space = rp[i].space;
-			adr[i].address = rp[i].address;
-			adr[i].size = rp[i].size;
+ 			if (!measure_only) {
+				adr[i].space = rp[i].space;
+				adr[i].address = rp[i].address;
+				adr[i].size = rp[i].size;
+			}
 			++i;
 		}
 		np->addrs = adr;
@@ -2370,7 +2393,7 @@ interpret_isa_props(struct device_node *
 
 static unsigned long __init
 interpret_root_props(struct device_node *np, unsigned long mem_start,
-		     int naddrc, int nsizec)
+		     int naddrc, int nsizec, int measure_only)
 {
 	struct address_range *adr;
 	int i, l;
@@ -2382,9 +2405,11 @@ interpret_root_props(struct device_node 
 		i = 0;
 		adr = (struct address_range *) mem_start;
 		while ((l -= rpsize) >= 0) {
-			adr[i].space = 0;
-			adr[i].address = rp[naddrc - 1];
-			adr[i].size = rp[naddrc + nsizec - 1];
+ 			if (!measure_only) {
+				adr[i].space = 0;
+				adr[i].address = rp[naddrc - 1];
+				adr[i].size = rp[naddrc + nsizec - 1];
+			}
 			++i;
 			rp += naddrc + nsizec;
 		}
@@ -2396,6 +2421,119 @@ interpret_root_props(struct device_node 
 	return mem_start;
 }
 
+static unsigned long __init
+finish_node(struct device_node *np, unsigned long mem_start,
+	    interpret_func *ifunc, int naddrc, int nsizec, int measure_only)
+{
+	struct device_node *child;
+	int *ip;
+
+	np->name = get_property(np, "name", 0);
+	np->type = get_property(np, "device_type", 0);
+
+	if (!np->name)
+		np->name = "<NULL>";
+	if (!np->type)
+		np->type = "<NULL>";
+
+	/* get the device addresses and interrupts */
+	if (ifunc != NULL)
+		mem_start = ifunc(np, mem_start, naddrc, nsizec, measure_only);
+
+	mem_start = finish_node_interrupts(np, mem_start, measure_only);
+
+	/* Look for #address-cells and #size-cells properties. */
+	ip = (int *) get_property(np, "#address-cells", 0);
+	if (ip != NULL)
+		naddrc = *ip;
+	ip = (int *) get_property(np, "#size-cells", 0);
+	if (ip != NULL)
+		nsizec = *ip;
+
+	/* the f50 sets the name to 'display' and 'compatible' to what we
+	 * expect for the name -- Cort
+	 */
+	if (!strcmp(np->name, "display"))
+		np->name = get_property(np, "compatible", 0);
+
+	if (!strcmp(np->name, "device-tree") || np->parent == NULL)
+		ifunc = interpret_root_props;
+	else if (np->type == 0)
+		ifunc = NULL;
+	else if (!strcmp(np->type, "pci") || !strcmp(np->type, "vci"))
+		ifunc = interpret_pci_props;
+	else if (!strcmp(np->type, "dbdma"))
+		ifunc = interpret_dbdma_props;
+	else if (!strcmp(np->type, "mac-io") || ifunc == interpret_macio_props)
+		ifunc = interpret_macio_props;
+	else if (!strcmp(np->type, "isa"))
+		ifunc = interpret_isa_props;
+	else if (!strcmp(np->name, "uni-n") || !strcmp(np->name, "u3"))
+		ifunc = interpret_root_props;
+	else if (!((ifunc == interpret_dbdma_props
+		    || ifunc == interpret_macio_props)
+		   && (!strcmp(np->type, "escc")
+		       || !strcmp(np->type, "media-bay"))))
+		ifunc = NULL;
+
+	for (child = np->child; child != NULL; child = child->sibling)
+		mem_start = finish_node(child, mem_start, ifunc,
+					naddrc, nsizec, measure_only);
+
+	return mem_start;
+}
+
+/*
+ * finish_device_tree is called once things are running normally
+ * (i.e. with text and data mapped to the address they were linked at).
+ * It traverses the device tree and fills in the name, type,
+ * {n_}addrs and {n_}intrs fields of each node.
+ */
+void __init
+finish_device_tree(void)
+{
+	unsigned long mem = klimit;
+
+	virt_irq_init();
+
+	dev_tree_size = finish_node(allnodes, 0, NULL, 0, 0, 1);
+	mem = (long)abs_to_virt(lmb_alloc(dev_tree_size,
+					  __alignof__(struct device_node)));
+	if (finish_node(allnodes, mem, NULL, 0, 0, 0) != mem + dev_tree_size)
+		BUG();
+	rtas.dev = of_find_node_by_name(NULL, "rtas");
+}
+
+int
+prom_n_addr_cells(struct device_node* np)
+{
+	int* ip;
+	do {
+		if (np->parent)
+			np = np->parent;
+		ip = (int *) get_property(np, "#address-cells", 0);
+		if (ip != NULL)
+			return *ip;
+	} while (np->parent);
+	/* No #address-cells property for the root node, default to 1 */
+	return 1;
+}
+
+int
+prom_n_size_cells(struct device_node* np)
+{
+	int* ip;
+	do {
+		if (np->parent)
+			np = np->parent;
+		ip = (int *) get_property(np, "#size-cells", 0);
+		if (ip != NULL)
+			return *ip;
+	} while (np->parent);
+	/* No #size-cells property for the root node, default to 1 */
+	return 1;
+}
+
 /*
  * Work out the sense (active-low level / active-high edge)
  * of each interrupt from the device tree.
@@ -2765,30 +2903,6 @@ struct device_node *of_node_get(struct d
 EXPORT_SYMBOL(of_node_get);
 
 /**
- *	of_node_put - Decrement refcount of a node
- *	@node:	Node to dec refcount, NULL is supported to
- *		simplify writing of callers
- *
- */
-void of_node_put(struct device_node *node)
-{
-	if (!node)
-		return;
-
-	WARN_ON(0 == atomic_read(&node->_users));
-
-	if (OF_IS_STALE(node)) {
-		if (atomic_dec_and_test(&node->_users)) {
-			of_node_cleanup(node);
-			return;
-		}
-	}
-	else
-		atomic_dec(&node->_users);
-}
-EXPORT_SYMBOL(of_node_put);
-
-/**
  *	of_node_cleanup - release a dynamically allocated node
  *	@arg:  Node to be released
  */
@@ -2805,11 +2919,35 @@ static void of_node_cleanup(struct devic
 		kfree(prop);
 		prop = next;
 	}
-	kfree(node->intrs);
-	kfree(node->addrs);
-	kfree(node->full_name);
-	kfree(node);
+	kfree(node->intrs);
+	kfree(node->addrs);
+	kfree(node->full_name);
+	kfree(node);
+}
+
+/**
+ *	of_node_put - Decrement refcount of a node
+ *	@node:	Node to dec refcount, NULL is supported to
+ *		simplify writing of callers
+ *
+ */
+void of_node_put(struct device_node *node)
+{
+	if (!node)
+		return;
+
+	WARN_ON(0 == atomic_read(&node->_users));
+
+	if (OF_IS_STALE(node)) {
+		if (atomic_dec_and_test(&node->_users)) {
+			of_node_cleanup(node);
+			return;
+		}
+	}
+	else
+		atomic_dec(&node->_users);
 }
+EXPORT_SYMBOL(of_node_put);
 
 /**
  *	derive_parent - basically like dirname(1)
@@ -2844,104 +2982,6 @@ static struct device_node *derive_parent
 /*
  * Routines for "runtime" addition and removal of device tree nodes.
  */
-
-/*
- * Given a path and a property list, construct an OF device node, add
- * it to the device tree and global list, and place it in
- * /proc/device-tree.  This function may sleep.
- */
-int of_add_node(const char *path, struct property *proplist)
-{
-	struct device_node *np;
-	int err = 0;
-
-	np = kmalloc(sizeof(struct device_node), GFP_KERNEL);
-	if (!np)
-		return -ENOMEM;
-
-	memset(np, 0, sizeof(*np));
-
-	np->full_name = kmalloc(strlen(path) + 1, GFP_KERNEL);
-	if (!np->full_name) {
-		kfree(np);
-		return -ENOMEM;
-	}
-	strcpy(np->full_name, path);
-
-	np->properties = proplist;
-	OF_MARK_DYNAMIC(np);
-	of_node_get(np);
-	np->parent = derive_parent(path);
-	if (!np->parent) {
-		kfree(np);
-		return -EINVAL; /* could also be ENOMEM, though */
-	}
-
-	if (0 != (err = of_finish_dynamic_node(np))) {
-		kfree(np);
-		return err;
-	}
-
-	write_lock(&devtree_lock);
-	np->sibling = np->parent->child;
-	np->allnext = allnodes;
-	np->parent->child = np;
-	allnodes = np;
-	write_unlock(&devtree_lock);
-
-	add_node_proc_entries(np);
-
-	of_node_put(np->parent);
-	of_node_put(np);
-	return 0;
-}
-
-/*
- * Remove an OF device node from the system.
- * Caller should have already "gotten" np.
- */
-int of_remove_node(struct device_node *np)
-{
-	struct device_node *parent, *child;
-
-	parent = of_get_parent(np);
-	if (!parent)
-		return -EINVAL;
-
-	if ((child = of_get_next_child(np, NULL))) {
-		of_node_put(child);
-		return -EBUSY;
-	}
-
-	write_lock(&devtree_lock);
-	OF_MARK_STALE(np);
-	remove_node_proc_entries(np);
-	if (allnodes == np)
-		allnodes = np->allnext;
-	else {
-		struct device_node *prev;
-		for (prev = allnodes;
-		     prev->allnext != np;
-		     prev = prev->allnext)
-			;
-		prev->allnext = np->allnext;
-	}
-
-	if (parent->child == np)
-		parent->child = np->sibling;
-	else {
-		struct device_node *prevsib;
-		for (prevsib = np->parent->child;
-		     prevsib->sibling != np;
-		     prevsib = prevsib->sibling)
-			;
-		prevsib->sibling = np->sibling;
-	}
-	write_unlock(&devtree_lock);
-	of_node_put(parent);
-	return 0;
-}
-
 #ifdef CONFIG_PROC_DEVICETREE
 /*
  * Add a node to /proc/device-tree.
@@ -3019,7 +3059,7 @@ static int of_finish_dynamic_node_interr
 			       "number for %s\n", node->full_name);
 			return -ENOMEM;
 		}
-		node->intrs[i].line = openpic_to_irq(virq);
+		node->intrs[i].line = irq_offset_up(virq);
 		if (n > 1)
 			node->intrs[i].sense = irq[1];
 		if (n > 2) {
@@ -3133,17 +3173,100 @@ out:
 }
 
 /*
- * Find the device_node with a given phandle.
+ * Given a path and a property list, construct an OF device node, add
+ * it to the device tree and global list, and place it in
+ * /proc/device-tree.  This function may sleep.
  */
-static struct device_node * __devinit
-find_phandle(phandle ph)
+int of_add_node(const char *path, struct property *proplist)
 {
 	struct device_node *np;
+	int err = 0;
 
-	for (np = allnodes; np != 0; np = np->allnext)
-		if (np->linux_phandle == ph)
-			return np;
-	return NULL;
+	np = kmalloc(sizeof(struct device_node), GFP_KERNEL);
+	if (!np)
+		return -ENOMEM;
+
+	memset(np, 0, sizeof(*np));
+
+	np->full_name = kmalloc(strlen(path) + 1, GFP_KERNEL);
+	if (!np->full_name) {
+		kfree(np);
+		return -ENOMEM;
+	}
+	strcpy(np->full_name, path);
+
+	np->properties = proplist;
+	OF_MARK_DYNAMIC(np);
+	of_node_get(np);
+	np->parent = derive_parent(path);
+	if (!np->parent) {
+		kfree(np);
+		return -EINVAL; /* could also be ENOMEM, though */
+	}
+
+	if (0 != (err = of_finish_dynamic_node(np))) {
+		kfree(np);
+		return err;
+	}
+
+	write_lock(&devtree_lock);
+	np->sibling = np->parent->child;
+	np->allnext = allnodes;
+	np->parent->child = np;
+	allnodes = np;
+	write_unlock(&devtree_lock);
+
+	add_node_proc_entries(np);
+
+	of_node_put(np->parent);
+	of_node_put(np);
+	return 0;
+}
+
+/*
+ * Remove an OF device node from the system.
+ * Caller should have already "gotten" np.
+ */
+int of_remove_node(struct device_node *np)
+{
+	struct device_node *parent, *child;
+
+	parent = of_get_parent(np);
+	if (!parent)
+		return -EINVAL;
+
+	if ((child = of_get_next_child(np, NULL))) {
+		of_node_put(child);
+		return -EBUSY;
+	}
+
+	write_lock(&devtree_lock);
+	OF_MARK_STALE(np);
+	remove_node_proc_entries(np);
+	if (allnodes == np)
+		allnodes = np->allnext;
+	else {
+		struct device_node *prev;
+		for (prev = allnodes;
+		     prev->allnext != np;
+		     prev = prev->allnext)
+			;
+		prev->allnext = np->allnext;
+	}
+
+	if (parent->child == np)
+		parent->child = np->sibling;
+	else {
+		struct device_node *prevsib;
+		for (prevsib = np->parent->child;
+		     prevsib->sibling != np;
+		     prevsib = prevsib->sibling)
+			;
+		prevsib->sibling = np->sibling;
+	}
+	write_unlock(&devtree_lock);
+	of_node_put(parent);
+	return 0;
 }
 
 /*
@@ -3229,55 +3352,3 @@ print_properties(struct device_node *np)
 	}
 }
 #endif
-
-
-/* Verify bi_recs are good */
-static struct bi_record *
-prom_bi_rec_verify(struct bi_record *bi_recs)
-{
-	struct bi_record *first, *last;
-
-	if ( bi_recs == NULL || bi_recs->tag != BI_FIRST )
-		return NULL;
-
-	last = (struct bi_record *)(long)bi_recs->data[0];
-	if ( last == NULL || last->tag != BI_LAST )
-		return NULL;
-
-	first = (struct bi_record *)(long)last->data[0];
-	if ( first == NULL || first != bi_recs )
-		return NULL;
-
-	return bi_recs;
-}
-
-static unsigned long
-prom_bi_rec_reserve(unsigned long mem)
-{
-	unsigned long offset = reloc_offset();
-	struct prom_t *_prom = PTRRELOC(&prom);
-	struct bi_record *rec;
-
-	if ( _prom->bi_recs != NULL) {
-
-		for ( rec=_prom->bi_recs;
-		      rec->tag != BI_LAST;
-		      rec=bi_rec_next(rec) ) {
-			switch (rec->tag) {
-#ifdef CONFIG_BLK_DEV_INITRD
-			case BI_INITRD:
-				lmb_reserve(rec->data[0], rec->data[1]);
-				break;
-#endif /* CONFIG_BLK_DEV_INITRD */
-			}
-		}
-		/* The next use of this field will be after relocation
-	 	 * is enabled, so convert this physical address into a
-	 	 * virtual address.
-	 	 */
-		_prom->bi_recs = PTRUNRELOC(_prom->bi_recs);
-	}
-
-	return mem;
-}
-
diff -purN linux-2.6.5/arch/ppc64/kernel/ras.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/ras.c
--- linux-2.6.5/arch/ppc64/kernel/ras.c	2004-04-04 03:36:54.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/ras.c	2004-04-29 11:17:16.000000000 +0000
@@ -1,4 +1,3 @@
-
 /*
  * ras.c
  * Copyright (C) 2001 Dave Engebretsen IBM Corporation
@@ -80,7 +79,7 @@ static int __init init_ras_IRQ(void)
 				       "number for %s\n", np->full_name);
 				break;
 			}
-			request_irq(virq + NUM_8259_INTERRUPTS, 
+			request_irq(irq_offset_up(virq),
 				    ras_error_interrupt, 0, 
 				    "RAS_ERROR", NULL);
 			ireg++;
@@ -98,7 +97,7 @@ static int __init init_ras_IRQ(void)
 				       " number for %s\n", np->full_name);
 				break;
 			}
-			request_irq(virq + NUM_8259_INTERRUPTS, 
+			request_irq(irq_offset_up(virq),
 				    ras_epow_interrupt, 0, 
 				    "RAS_EPOW", NULL);
 			ireg++;
@@ -110,6 +109,9 @@ static int __init init_ras_IRQ(void)
 }
 __initcall(init_ras_IRQ);
 
+static struct rtas_error_log log_buf;
+static spinlock_t log_lock = SPIN_LOCK_UNLOCKED;
+
 /*
  * Handle power subsystem events (EPOW).
  *
@@ -124,11 +126,17 @@ ras_epow_interrupt(int irq, void *dev_id
 	unsigned int size = sizeof(log_entry);
 	long status = 0xdeadbeef;
 
+	spin_lock(&log_lock);
+
 	status = rtas_call(rtas_token("check-exception"), 6, 1, NULL, 
 			   0x500, irq, 
 			   RTAS_EPOW_WARNING | RTAS_POWERMGM_EVENTS, 
 			   1,  /* Time Critical */
-			   __pa(&log_entry), size);
+			   __pa(&log_buf), size);
+
+	log_entry = log_buf;
+
+	spin_unlock(&log_lock);
 
 	udbg_printf("EPOW <0x%lx 0x%lx>\n", 
 		    *((unsigned long *)&log_entry), status); 
@@ -157,11 +165,17 @@ ras_error_interrupt(int irq, void *dev_i
 	long status = 0xdeadbeef;
 	int fatal;
 
+	spin_lock(&log_lock);
+
 	status = rtas_call(rtas_token("check-exception"), 6, 1, NULL, 
 			   0x500, irq, 
 			   RTAS_INTERNAL_ERROR, 
 			   1, /* Time Critical */
-			   __pa(&log_entry), size);
+			   __pa(&log_buf), size);
+
+	log_entry = log_buf;
+
+	spin_unlock(&log_lock);
 
 	if ((status == 0) && (log_entry.severity >= SEVERITY_ERROR_SYNC)) 
 		fatal = 1;
diff -purN linux-2.6.5/arch/ppc64/kernel/rtas.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/rtas.c
--- linux-2.6.5/arch/ppc64/kernel/rtas.c	2004-04-04 03:36:25.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/rtas.c	2004-04-29 11:17:16.000000000 +0000
@@ -66,53 +66,22 @@ spinlock_t rtas_data_buf_lock = SPIN_LOC
 char rtas_data_buf[RTAS_DATA_BUF_SIZE]__page_aligned;
 
 void
-phys_call_rtas(int token, int nargs, int nret, ...)
-{
-	va_list list;
-	unsigned long offset = reloc_offset();
-	struct rtas_args *rtas = PTRRELOC(&(get_paca()->xRtas));
-	int i;
-
-	rtas->token = token;
-	rtas->nargs = nargs;
-	rtas->nret  = nret;
-	rtas->rets  = (rtas_arg_t *)PTRRELOC(&(rtas->args[nargs]));
-
-	va_start(list, nret);
-	for (i = 0; i < nargs; i++)
-	  rtas->args[i] = (rtas_arg_t)LONG_LSW(va_arg(list, ulong));
-	va_end(list);
-
-        enter_rtas(rtas);	
-}
-
-void
-phys_call_rtas_display_status(char c)
+call_rtas_display_status(char c)
 {
-	unsigned long offset = reloc_offset();
-	struct rtas_args *rtas = PTRRELOC(&(get_paca()->xRtas));
-
-	rtas->token = 10;
-	rtas->nargs = 1;
-	rtas->nret  = 1;
-	rtas->rets  = (rtas_arg_t *)PTRRELOC(&(rtas->args[1]));
-	rtas->args[0] = (int)c;
+	struct rtas_args *args = &(get_paca()->xRtas);
+	unsigned long s;
 
-	enter_rtas(rtas);	
-}
+	spin_lock_irqsave(&rtas.lock, s);
 
-void
-call_rtas_display_status(char c)
-{
-	struct rtas_args *rtas = &(get_paca()->xRtas);
+	args->token = 10;
+	args->nargs = 1;
+	args->nret  = 1;
+	args->rets  = (rtas_arg_t *)&(args->args[1]);
+	args->args[0] = (int)c;
 
-	rtas->token = 10;
-	rtas->nargs = 1;
-	rtas->nret  = 1;
-	rtas->rets  = (rtas_arg_t *)&(rtas->args[1]);
-	rtas->args[0] = (int)c;
+	enter_rtas((void *)__pa((unsigned long)args));	
 
-	enter_rtas((void *)__pa((unsigned long)rtas));	
+	spin_unlock_irqrestore(&rtas.lock, s);
 }
 
 int
@@ -127,8 +96,9 @@ rtas_token(const char *service)
 	return tokp ? *tokp : RTAS_UNKNOWN_SERVICE;
 }
 
-void
-log_rtas_error(struct rtas_args	*rtas_args)
+
+static int
+__log_rtas_error(struct rtas_args *rtas_args)
 {
 	struct rtas_args err_args, temp_args;
 
@@ -147,13 +117,24 @@ log_rtas_error(struct rtas_args	*rtas_ar
 	PPCDBG(PPCDBG_RTAS, "\tentering rtas with 0x%lx\n",
 	       (void *)__pa((unsigned long)&err_args));
 	enter_rtas((void *)__pa((unsigned long)&get_paca()->xRtas));
-	PPCDBG(PPCDBG_RTAS, "\treturned from rtas ...\n");
-
+	PPCDBG(PPCDBG_RTAS, "\treturned from rtas ...\n");	
 
 	err_args = get_paca()->xRtas;
 	get_paca()->xRtas = temp_args;
 
-	if (err_args.rets[0] == 0)
+	return err_args.rets[0];
+}
+
+void
+log_rtas_error(struct rtas_args	*rtas_args)
+{
+	unsigned long s;
+	int rc;
+
+	spin_lock_irqsave(&rtas.lock, s);
+	rc = __log_rtas_error(rtas_args);
+	spin_unlock_irqrestore(&rtas.lock, s);
+	if (rc == 0)
 		log_error(rtas_err_buf, ERR_TYPE_RTAS_LOG, 0);
 }
 
@@ -162,9 +143,10 @@ rtas_call(int token, int nargs, int nret
 	  unsigned long *outputs, ...)
 {
 	va_list list;
-	int i;
+	int i, logit = 0;
 	unsigned long s;
 	struct rtas_args *rtas_args = &(get_paca()->xRtas);
+	long ret;
 
 	PPCDBG(PPCDBG_RTAS, "Entering rtas_call\n");
 	PPCDBG(PPCDBG_RTAS, "\ttoken    = 0x%x\n", token);
@@ -174,6 +156,9 @@ rtas_call(int token, int nargs, int nret
 	if (token == RTAS_UNKNOWN_SERVICE)
 		return -1;
 
+	/* Gotta do something different here, use global lock for now... */
+	spin_lock_irqsave(&rtas.lock, s);
+
 	rtas_args->token = token;
 	rtas_args->nargs = nargs;
 	rtas_args->nret  = nret;
@@ -186,26 +171,16 @@ rtas_call(int token, int nargs, int nret
 	va_end(list);
 
 	for (i = 0; i < nret; ++i)
-	  rtas_args->rets[i] = 0;
+		rtas_args->rets[i] = 0;
 
-#if 0   /* Gotta do something different here, use global lock for now... */
-	spin_lock_irqsave(&rtas_args->lock, s);
-#else
-	spin_lock_irqsave(&rtas.lock, s);
-#endif
 	PPCDBG(PPCDBG_RTAS, "\tentering rtas with 0x%lx\n",
 		(void *)__pa((unsigned long)rtas_args));
 	enter_rtas((void *)__pa((unsigned long)rtas_args));
 	PPCDBG(PPCDBG_RTAS, "\treturned from rtas ...\n");
 
 	if (rtas_args->rets[0] == -1)
-		log_rtas_error(rtas_args);
+		logit = (__log_rtas_error(rtas_args) == 0);
 
-#if 0   /* Gotta do something different here, use global lock for now... */
-	spin_unlock_irqrestore(&rtas_args->lock, s);
-#else
-	spin_unlock_irqrestore(&rtas.lock, s);
-#endif
 	ifppcdebug(PPCDBG_RTAS) {
 		for(i=0; i < nret ;i++)
 			udbg_printf("\tnret[%d] = 0x%lx\n", i, (ulong)rtas_args->rets[i]);
@@ -214,7 +189,15 @@ rtas_call(int token, int nargs, int nret
 	if (nret > 1 && outputs != NULL)
 		for (i = 0; i < nret-1; ++i)
 			outputs[i] = rtas_args->rets[i+1];
-	return (ulong)((nret > 0) ? rtas_args->rets[0] : 0);
+	ret = (ulong)((nret > 0) ? rtas_args->rets[0] : 0);
+
+	/* Gotta do something different here, use global lock for now... */
+	spin_unlock_irqrestore(&rtas.lock, s);
+
+	if (logit)
+		log_error(rtas_err_buf, ERR_TYPE_RTAS_LOG, 0);
+
+	return ret;
 }
 
 /* Given an RTAS status code of 990n compute the hinted delay of 10^n
@@ -448,6 +431,27 @@ rtas_halt(void)
         rtas_power_off();
 }
 
+/* Must be in the RMO region, so we place it here */
+static char rtas_os_term_buf[2048];
+
+void rtas_os_term(char *str)
+{
+	long status;
+
+	snprintf(rtas_os_term_buf, 2048, "OS panic: %s", str);
+
+	do {
+		status = rtas_call(rtas_token("ibm,os-term"), 1, 1, NULL,
+				   __pa(rtas_os_term_buf));
+
+		if (status == RTAS_BUSY)
+			udelay(1);
+		else if (status != 0)
+			printk(KERN_EMERG "ibm,os-term call failed %ld\n",
+			       status);
+	} while (status == RTAS_BUSY);
+}
+
 unsigned long rtas_rmo_buf = 0;
 
 asmlinkage int ppc_rtas(struct rtas_args __user *uargs)
@@ -479,12 +483,12 @@ asmlinkage int ppc_rtas(struct rtas_args
 	enter_rtas((void *)__pa((unsigned long)&get_paca()->xRtas));
 	args = get_paca()->xRtas;
 
+	spin_unlock_irqrestore(&rtas.lock, flags);
+
 	args.rets  = (rtas_arg_t *)&(args.args[nargs]);
 	if (args.rets[0] == -1)
 		log_rtas_error(&args);
 
-	spin_unlock_irqrestore(&rtas.lock, flags);
-
 	/* Copy out args. */
 	if (copy_to_user(uargs->args + nargs,
 			 args.args + nargs,
@@ -494,6 +498,28 @@ asmlinkage int ppc_rtas(struct rtas_args
 	return 0;
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+/* This version can't take the spinlock. */
+
+void rtas_stop_self(void)
+{
+	struct rtas_args *rtas_args = &(get_paca()->xRtas);
+
+	local_irq_disable();
+
+	rtas_args->token = rtas_token("stop-self");
+	BUG_ON(rtas_args->token == RTAS_UNKNOWN_SERVICE);
+	rtas_args->nargs = 0;
+	rtas_args->nret  = 1;
+	rtas_args->rets  = &(rtas_args->args[0]);
+
+	printk("%u %u Ready to die...\n",
+	       smp_processor_id(), hard_smp_processor_id());
+	enter_rtas((void *)__pa(rtas_args));
+
+	panic("Alas, I survived.\n");
+}
+#endif /* CONFIG_HOTPLUG_CPU */
 
 EXPORT_SYMBOL(rtas_firmware_flash_list);
 EXPORT_SYMBOL(rtas_token);
diff -purN linux-2.6.5/arch/ppc64/kernel/rtasd.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/rtasd.c
--- linux-2.6.5/arch/ppc64/kernel/rtasd.c	2004-04-04 03:36:54.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/rtasd.c	2004-04-29 11:17:16.000000000 +0000
@@ -78,7 +78,7 @@ static void printk_log_rtas(char *buf, i
 	char buffer[64];
 	char * str = "RTAS event";
 
-	printk(RTAS_ERR "%d -------- %s begin --------\n", error_log_cnt, str);
+	printk(RTAS_DEBUG "%d -------- %s begin --------\n", error_log_cnt, str);
 
 	/*
 	 * Print perline bytes on each line, each line will start
@@ -99,12 +99,12 @@ static void printk_log_rtas(char *buf, i
 		n += sprintf(buffer+n, "%02x", (unsigned char)buf[i]);
 
 		if (j == (perline-1))
-			printk(KERN_ERR "%s\n", buffer);
+			printk(KERN_DEBUG "%s\n", buffer);
 	}
 	if ((i % perline) != 0)
-		printk(KERN_ERR "%s\n", buffer);
+		printk(KERN_DEBUG "%s\n", buffer);
 
-	printk(RTAS_ERR "%d -------- %s end ----------\n", error_log_cnt, str);
+	printk(RTAS_DEBUG "%d -------- %s end ----------\n", error_log_cnt, str);
 }
 
 static int log_rtas_len(char * buf)
@@ -119,10 +119,11 @@ static int log_rtas_len(char * buf)
 
 		/* extended header */
 		len += err->extended_log_length;
-
-		if (len > RTAS_ERROR_LOG_MAX)
-			len = RTAS_ERROR_LOG_MAX;
 	}
+
+	if (len > rtas_error_log_max)
+		len = rtas_error_log_max;
+
 	return len;
 }
 
@@ -330,6 +331,10 @@ static int get_eventscan_parms(void)
 		printk(KERN_ERR "rtasd: truncated error log from %d to %d bytes\n", rtas_error_log_max, RTAS_ERROR_LOG_MAX);
 		rtas_error_log_max = RTAS_ERROR_LOG_MAX;
 	}
+
+	/* Make room for the sequence number */
+	rtas_error_log_buffer_max = rtas_error_log_max + sizeof(int);
+
 	of_node_put(node);
 
 	return 0;
@@ -405,8 +410,7 @@ static int rtasd(void *unused)
 
 	if (surveillance_timeout != -1) {
 		DEBUG("enabling surveillance\n");
-		if (enable_surveillance(surveillance_timeout))
-			goto error_vfree;
+		enable_surveillance(surveillance_timeout);
 		DEBUG("surveillance enabled\n");
 	}
 
@@ -430,10 +434,6 @@ static int rtasd(void *unused)
 			cpu = first_cpu_const(mk_cpumask_const(cpu_online_map));
 	}
 
-error_vfree:
-	if (rtas_log_buf)
-		vfree(rtas_log_buf);
-	rtas_log_buf = NULL;
 error:
 	/* Should delete proc entries */
 	return -EINVAL;
@@ -459,9 +459,6 @@ static int __init rtas_init(void)
 	if (kernel_thread(rtasd, 0, CLONE_FS) < 0)
 		printk(KERN_ERR "Failed to start RTAS daemon\n");
 
-	/* Make room for the sequence number */
-	rtas_error_log_buffer_max = rtas_error_log_max + sizeof(int);
-
 	return 0;
 }
 
diff -purN linux-2.6.5/arch/ppc64/kernel/setup.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/setup.c
--- linux-2.6.5/arch/ppc64/kernel/setup.c	2004-04-04 03:37:06.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/setup.c	2004-04-29 11:17:16.000000000 +0000
@@ -25,6 +25,8 @@
 #include <linux/version.h>
 #include <linux/tty.h>
 #include <linux/root_dev.h>
+#include <linux/notifier.h>
+#include <linux/cpu.h>
 #include <asm/io.h>
 #include <asm/prom.h>
 #include <asm/processor.h>
@@ -93,6 +95,13 @@ unsigned long SYSRQ_KEY;
 
 struct machdep_calls ppc_md;
 
+static int ppc64_panic_event(struct notifier_block *, unsigned long, void *);
+
+static struct notifier_block ppc64_panic_block = {
+	notifier_call: ppc64_panic_event,
+	priority: INT_MIN /* may not return; must be done last */
+};
+
 /*
  * Perhaps we can put the pmac screen_info[] here
  * on pmac as well so we don't need the ifdef's.
@@ -215,6 +224,7 @@ void setup_system(unsigned long r3, unsi
 	if (systemcfg->platform & PLATFORM_PSERIES) {
 		early_console_initialized = 1;
 		register_console(&udbg_console);
+		__irq_offset_value = NUM_ISA_INTERRUPTS;
 		finish_device_tree();
 		chrp_init(r3, r4, r5, r6, r7);
 
@@ -318,6 +328,14 @@ EXPORT_SYMBOL(machine_halt);
 unsigned long ppc_proc_freq;
 unsigned long ppc_tb_freq;
 
+static int ppc64_panic_event(struct notifier_block *this,
+                             unsigned long event, void *ptr)
+{
+	ppc_md.panic((char *)ptr);  /* May not return */
+	return NOTIFY_DONE;
+}
+
+
 #ifdef CONFIG_SMP
 DEFINE_PER_CPU(unsigned int, pvr);
 #endif
@@ -338,8 +356,13 @@ static int show_cpuinfo(struct seq_file 
 		return 0;
 	}
 
-	if (!cpu_online(cpu_id))
+	/* We only show online cpus: disable preempt (overzealous, I
+	 * knew) to prevent cpu going down. */
+	preempt_disable();
+	if (!cpu_online(cpu_id)) {
+		preempt_enable();
 		return 0;
+	}
 
 #ifdef CONFIG_SMP
 	pvr = per_cpu(pvr, cpu_id);
@@ -372,7 +395,8 @@ static int show_cpuinfo(struct seq_file 
 		   ppc_proc_freq % 1000000);
 
 	seq_printf(m, "revision\t: %hd.%hd\n\n", maj, min);
-	
+
+	preempt_enable();
 	return 0;
 }
 
@@ -598,6 +622,9 @@ void __init setup_arch(char **cmdline_p)
 	/* reboot on panic */
 	panic_timeout = 180;
 
+	if (ppc_md.panic)
+		notifier_chain_register(&panic_notifier_list, &ppc64_panic_block);
+
 	init_mm.start_code = PAGE_OFFSET;
 	init_mm.end_code = (unsigned long) _etext;
 	init_mm.end_data = (unsigned long) _edata;
diff -purN linux-2.6.5/arch/ppc64/kernel/signal.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/signal.c
--- linux-2.6.5/arch/ppc64/kernel/signal.c	2004-04-04 03:36:12.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/signal.c	2004-04-29 11:17:16.000000000 +0000
@@ -115,7 +115,7 @@ long sys_sigaltstack(const stack_t *uss,
  * Set up the sigcontext for the signal frame.
  */
 
-static int setup_sigcontext(struct sigcontext *sc, struct pt_regs *regs,
+static long setup_sigcontext(struct sigcontext *sc, struct pt_regs *regs,
 		 int signr, sigset_t *set, unsigned long handler)
 {
 	/* When CONFIG_ALTIVEC is set, we _always_ setup v_regs even if the
@@ -129,7 +129,7 @@ static int setup_sigcontext(struct sigco
 #ifdef CONFIG_ALTIVEC
 	elf_vrreg_t *v_regs = (elf_vrreg_t *)(((unsigned long)sc->vmx_reserve) & ~0xful);
 #endif
-	int err = 0;
+	long err = 0;
 
 	if (regs->msr & MSR_FP)
 		giveup_fpu(current);
@@ -173,18 +173,32 @@ static int setup_sigcontext(struct sigco
  * Restore the sigcontext from the signal frame.
  */
 
-static int restore_sigcontext(struct pt_regs *regs, sigset_t *set, int sig, struct sigcontext *sc)
+static long restore_sigcontext(struct pt_regs *regs, sigset_t *set, int sig,
+			      struct sigcontext *sc)
 {
 #ifdef CONFIG_ALTIVEC
 	elf_vrreg_t *v_regs;
 #endif
-	unsigned int err = 0;
+	unsigned long err = 0;
 	unsigned long save_r13;
+	elf_greg_t *gregs = (elf_greg_t *)regs;
+	int i;
 
 	/* If this is not a signal return, we preserve the TLS in r13 */
 	if (!sig)
 		save_r13 = regs->gpr[13];
-	err |= __copy_from_user(regs, &sc->gp_regs, GP_REGS_SIZE);
+
+	/* copy everything before MSR */
+	err |= __copy_from_user(regs, &sc->gp_regs,
+				PT_MSR*sizeof(unsigned long));
+
+	/* skip MSR and SOFTE */
+	for (i = PT_MSR+1; i <= PT_RESULT; i++) {
+		if (i == PT_SOFTE)
+			continue;
+		err |= __get_user(gregs[i], &sc->gp_regs[i]);
+	}
+
 	if (!sig)
 		regs->gpr[13] = save_r13;
 	err |= __copy_from_user(&current->thread.fpr, &sc->fp_regs, FP_REGS_SIZE);
@@ -235,9 +249,10 @@ static inline void * get_sigframe(struct
 /*
  * Setup the trampoline code on the stack
  */
-static int setup_trampoline(unsigned int syscall, unsigned int *tramp)
+static long setup_trampoline(unsigned int syscall, unsigned int *tramp)
 {
-	int i, err = 0;
+	int i;
+	long err = 0;
 
 	/* addi r1, r1, __SIGNAL_FRAMESIZE  # Pop the dummy stackframe */
 	err |= __put_user(0x38210000UL | (__SIGNAL_FRAMESIZE & 0xffff), &tramp[0]);
@@ -372,7 +387,7 @@ static void setup_rt_frame(int signr, st
 	func_descr_t *funct_desc_ptr;
 	struct rt_sigframe *frame;
 	unsigned long newsp = 0;
-	int err = 0;
+	long err = 0;
 
 	frame = get_sigframe(ka, regs, sizeof(*frame));
 
diff -purN linux-2.6.5/arch/ppc64/kernel/signal32.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/signal32.c
--- linux-2.6.5/arch/ppc64/kernel/signal32.c	2004-04-04 03:38:14.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/signal32.c	2004-04-29 11:17:16.000000000 +0000
@@ -185,25 +185,28 @@ static int save_user_regs(struct pt_regs
  * Restore the current user register values from the user stack,
  * (except for MSR).
  */
-static int restore_user_regs(struct pt_regs *regs, struct mcontext32 __user *sr, int sig)
+static long restore_user_regs(struct pt_regs *regs,
+			      struct mcontext32 __user *sr, int sig)
 {
 	elf_greg_t64 *gregs = (elf_greg_t64 *)regs;
-	int i, err = 0;
+	int i;
+	long err = 0;
 	unsigned int save_r2;
 #ifdef CONFIG_ALTIVEC
 	unsigned long msr;
 #endif
 
 	/*
-	 * restore general registers but not including MSR. Also take
-	 * care of keeping r2 (TLS) intact if not a signal
+	 * restore general registers but not including MSR or SOFTE. Also
+	 * take care of keeping r2 (TLS) intact if not a signal
 	 */
 	if (!sig)
 		save_r2 = (unsigned int)regs->gpr[2];
-	for (i = 0; i < PT_MSR; i ++)
-		err |= __get_user(gregs[i], &sr->mc_gregs[i]);
-	for (i ++; i <= PT_RESULT; i ++)
+	for (i = 0; i <= PT_RESULT; i++) {
+		if ((i == PT_MSR) || (i == PT_SOFTE))
+			continue;
 		err |= __get_user(gregs[i], &sr->mc_gregs[i]);
+	}
 	if (!sig)
 		regs->gpr[2] = (unsigned long) save_r2;
 	if (err)
@@ -427,9 +430,9 @@ long sys32_rt_sigpending(compat_sigset_t
 }
 
 
-static int copy_siginfo_to_user32(compat_siginfo_t *d, siginfo_t *s)
+static long copy_siginfo_to_user32(compat_siginfo_t *d, siginfo_t *s)
 {
-	int err;
+	long err;
 
 	if (!access_ok (VERIFY_WRITE, d, sizeof(*d)))
 		return -EFAULT;
@@ -495,45 +498,6 @@ long sys32_rt_sigtimedwait(compat_sigset
 	return ret;
 }
 
-
-
-static siginfo_t * siginfo32to64(siginfo_t *d, compat_siginfo_t *s)
-{
-	d->si_signo = s->si_signo;
-	d->si_errno = s->si_errno;
-	d->si_code = s->si_code;
-	if (s->si_signo >= SIGRTMIN) {
-		d->si_pid = s->si_pid;
-		d->si_uid = s->si_uid;
-		d->si_int = s->si_int;
-	} else {
-		switch (s->si_signo) {
-		/* XXX: What about POSIX1.b timers */
-		case SIGCHLD:
-			d->si_pid = s->si_pid;
-			d->si_status = s->si_status;
-			d->si_utime = s->si_utime;
-			d->si_stime = s->si_stime;
-			break;
-		case SIGSEGV:
-		case SIGBUS:
-		case SIGFPE:
-		case SIGILL:
-			d->si_addr = (void *)A(s->si_addr);
-	  		break;
-		case SIGPOLL:
-			d->si_band = s->si_band;
-			d->si_fd = s->si_fd;
-			break;
-		default:
-			d->si_pid = s->si_pid;
-			d->si_uid = s->si_uid;
-			break;
-		}
-	}
-	return d;
-}
-
 /*
  * Note: it is necessary to treat pid and sig as unsigned ints, with the
  * corresponding cast to a signed int to insure that the proper conversion
@@ -544,15 +508,12 @@ static siginfo_t * siginfo32to64(siginfo
 long sys32_rt_sigqueueinfo(u32 pid, u32 sig, compat_siginfo_t *uinfo)
 {
 	siginfo_t info;
-	compat_siginfo_t info32;
 	int ret;
 	mm_segment_t old_fs = get_fs();
 	
-	if (copy_from_user (&info32, uinfo, sizeof(compat_siginfo_t)))
+	if (copy_from_user (&info, uinfo, 3*sizeof(int)) ||
+	    copy_from_user (info._sifields._pad, uinfo->_sifields._pad, SI_PAD_SIZE32))
 		return -EFAULT;
-    	/* XXX: Is this correct? */
-	siginfo32to64(&info, &info32);
-
 	set_fs (KERNEL_DS);
 	ret = sys_rt_sigqueueinfo((int)pid, (int)sig, &info);
 	set_fs (old_fs);
diff -purN linux-2.6.5/arch/ppc64/kernel/smp.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/smp.c
--- linux-2.6.5/arch/ppc64/kernel/smp.c	2004-04-04 03:37:37.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/smp.c	2004-04-29 11:17:16.000000000 +0000
@@ -230,10 +230,237 @@ static void __devinit smp_openpic_setup_
 	do_openpic_setup_cpu();
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+/* Get state of physical CPU.
+ * Return codes:
+ *	0	- The processor is in the RTAS stopped state
+ *	1	- stop-self is in progress
+ *	2	- The processor is not in the RTAS stopped state
+ *	-1	- Hardware Error
+ *	-2	- Hardware Busy, Try again later.
+ */
+static int query_cpu_stopped(unsigned int pcpu)
+{
+	long cpu_status;
+	int status, qcss_tok;
+
+	qcss_tok = rtas_token("query-cpu-stopped-state");
+	BUG_ON(qcss_tok == RTAS_UNKNOWN_SERVICE);
+	status = rtas_call(qcss_tok, 1, 2, &cpu_status, pcpu);
+	if (status != 0) {
+		printk(KERN_ERR
+		       "RTAS query-cpu-stopped-state failed: %i\n", status);
+		return status;
+	}
+
+	return cpu_status;
+}
+
+int __cpu_disable(void)
+{
+	/* FIXME: go put this in a header somewhere */
+	extern void xics_migrate_irqs_away(void);
+
+	systemcfg->processorCount--;
+
+	/*fix boot_cpuid here*/
+	if (smp_processor_id() == boot_cpuid)
+		boot_cpuid = any_online_cpu(cpu_online_map);
+
+	/* FIXME: abstract this to not be platform specific later on */
+	xics_migrate_irqs_away();
+	return 0;
+}
+
+void __cpu_die(unsigned int cpu)
+{
+	int tries;
+	int cpu_status;
+	unsigned int pcpu = get_hard_smp_processor_id(cpu);
+
+	for (tries = 0; tries < 5; tries++) {
+		cpu_status = query_cpu_stopped(pcpu);
+
+		if (cpu_status == 0)
+			break;
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(HZ);
+	}
+	if (cpu_status != 0) {
+		printk("Querying DEAD? cpu %i (%i) shows %i\n",
+		       cpu, pcpu, cpu_status);
+	}
+
+	/* Isolation and deallocation are definatly done by
+	 * drslot_chrp_cpu.  If they were not they would be
+	 * done here.  Change isolate state to Isolate and
+	 * change allocation-state to Unusable.
+	 */
+	paca[cpu].xProcStart = 0;
+
+	/* So we can recognize if it fails to come up next time. */
+	cpu_callin_map[cpu] = 0;
+}
+
+/* Kill this cpu */
+void cpu_die(void)
+{
+	local_irq_disable();
+	rtas_stop_self();
+	/* Should never get here... */
+	BUG();
+	for(;;);
+}
+
+/* Search all cpu device nodes for an offline logical cpu.  If a
+ * device node has a "ibm,my-drc-index" property (meaning this is an
+ * LPAR), paranoid-check whether we own the cpu.  For each "thread"
+ * of a cpu, if it is offline and has the same hw index as before,
+ * grab that in preference.
+ */
+static unsigned int find_physical_cpu_to_start(unsigned int old_hwindex)
+{
+	struct device_node *np = NULL;
+	unsigned int best = -1U;
+
+	while ((np = of_find_node_by_type(np, "cpu"))) {
+		int nr_threads, len;
+		u32 *index = (u32 *)get_property(np, "ibm,my-drc-index", NULL);
+		u32 *tid = (u32 *)
+			get_property(np, "ibm,ppc-interrupt-server#s", &len);
+
+		if (!tid)
+			tid = (u32 *)get_property(np, "reg", &len);
+
+		if (!tid)
+			continue;
+
+		/* If there is a drc-index, make sure that we own
+		 * the cpu.
+		 */
+		if (index) {
+			int state;
+			int rc = rtas_get_sensor(9003, *index, &state);
+			if (rc != 0 || state != 1)
+				continue;
+		}
+
+		nr_threads = len / sizeof(u32);
+
+		while (nr_threads--) {
+			if (0 == query_cpu_stopped(tid[nr_threads])) {
+				best = tid[nr_threads];
+				if (best == old_hwindex)
+					goto out;
+			}
+		}
+	}
+out:
+	of_node_put(np);
+	return best;
+}
+
+/**
+ * smp_startup_cpu() - start the given cpu
+ *
+ * At boot time, there is nothing to do.  At run-time, call RTAS with
+ * the appropriate start location, if the cpu is in the RTAS stopped
+ * state.
+ *
+ * Returns:
+ *	0	- failure
+ *	1	- success
+ */
+static inline int __devinit smp_startup_cpu(unsigned int lcpu)
+{
+	int status;
+	extern void (*pseries_secondary_smp_init)(unsigned int cpu);
+	unsigned long start_here = __pa(pseries_secondary_smp_init);
+	unsigned int pcpu;
+
+	/* At boot time the cpus are already spinning in hold
+	 * loops, so nothing to do. */
+ 	if (system_state == SYSTEM_BOOTING)
+		return 1;
+
+	pcpu = find_physical_cpu_to_start(get_hard_smp_processor_id(lcpu));
+	if (pcpu == -1U) {
+		printk(KERN_INFO "No more cpus available, failing\n");
+		return 0;
+	}
+
+	/* Fixup atomic count: it exited inside IRQ handler. */
+	((struct task_struct *)paca[lcpu].xCurrent)->thread_info->preempt_count
+		= 0;
+	/* Fixup SLB round-robin so next segment (kernel) goes in segment 0 */
+	paca[lcpu].xStab_data.next_round_robin = 0;
+
+	/* At boot this is done in prom.c. */
+	paca[lcpu].xHwProcNum = pcpu;
+
+	status = rtas_call(rtas_token("start-cpu"), 3, 1, NULL,
+			   pcpu, start_here, lcpu);
+	if (status != 0) {
+		printk(KERN_ERR "start-cpu failed: %i\n", status);
+		return 0;
+	}
+	return 1;
+}
+
+static inline void look_for_more_cpus(void)
+{
+	int num_addr_cell, num_size_cell, len, i, maxcpus;
+	struct device_node *np;
+	unsigned int *ireg;
+
+	/* Find the property which will tell us about how many CPUs
+	 * we're allowed to have. */
+	if ((np = find_path_device("/rtas")) == NULL) {
+		printk(KERN_ERR "Could not find /rtas in device tree!");
+		return;
+	}
+	num_addr_cell = prom_n_addr_cells(np);
+	num_size_cell = prom_n_size_cells(np);
+
+	ireg = (unsigned int *)get_property(np, "ibm,lrdr-capacity", &len);
+	if (ireg == NULL) {
+		/* FIXME: make sure not marked as lrdr_capable() */
+		return;
+	}
+
+	maxcpus = ireg[num_addr_cell + num_size_cell];
+	/* DRENG need to account for threads here too */
+
+	if (maxcpus > NR_CPUS) {
+		printk(KERN_WARNING
+		       "Partition configured for %d cpus, "
+		       "operating system maximum is %d.\n", maxcpus, NR_CPUS);
+		maxcpus = NR_CPUS;
+	} else
+		printk(KERN_INFO "Partition configured for %d cpus.\n",
+		       maxcpus);
+
+	/* Make those cpus (which might appear later) possible too. */
+	for (i = 0; i < maxcpus; i++)
+		cpu_set(i, cpu_possible_map);
+}
+#else /* ... CONFIG_HOTPLUG_CPU */
+static inline int __devinit smp_startup_cpu(unsigned int lcpu)
+{
+	return 1;
+}
+static inline void look_for_more_cpus(void)
+{
+}
+#endif /* CONFIG_HOTPLUG_CPU */
+
 static void smp_pSeries_kick_cpu(int nr)
 {
 	BUG_ON(nr < 0 || nr >= NR_CPUS);
 
+	if (!smp_startup_cpu(nr))
+		return;
+
 	/* The processor is currently spinning, waiting
 	 * for the xProcStart field to become non-zero
 	 * After we set xProcStart, the processor will
@@ -241,7 +468,7 @@ static void smp_pSeries_kick_cpu(int nr)
 	 */
 	paca[nr].xProcStart = 1;
 }
-#endif
+#endif /* CONFIG_PPC_PSERIES */
 
 static void __init smp_space_timers(unsigned int max_cpus)
 {
@@ -462,12 +689,9 @@ int smp_call_function (void (*func) (voi
 		       int wait)
 { 
 	struct call_data_struct data;
-	int ret = -1, cpus = num_online_cpus()-1;
+	int ret = -1, cpus;
 	unsigned long timeout;
 
-	if (!cpus)
-		return 0;
-
 	data.func = func;
 	data.info = info;
 	atomic_set(&data.started, 0);
@@ -476,6 +700,14 @@ int smp_call_function (void (*func) (voi
 		atomic_set(&data.finished, 0);
 
 	spin_lock(&call_lock);
+	/* Must grab online cpu count with preempt disabled, otherwise
+	 * it can change. */
+	cpus = num_online_cpus() - 1;
+	if (!cpus) {
+		ret = 0;
+		goto out;
+	}
+
 	call_data = &data;
 	wmb();
 	/* Send a message to all other CPUs and wait for them to respond */
@@ -565,8 +797,31 @@ static void __devinit smp_store_cpu_info
 	per_cpu(pvr, id) = _get_PVR();
 }
 
+static void __init smp_create_idle(unsigned int cpu)
+{
+	struct pt_regs regs;
+	struct task_struct *p;
+
+	/* create a process for the processor */
+	/* only regs.msr is actually used, and 0 is OK for it */
+	memset(&regs, 0, sizeof(struct pt_regs));
+	p = copy_process(CLONE_VM | CLONE_IDLETASK,
+			 0, &regs, 0, NULL, NULL);
+	if (IS_ERR(p))
+		panic("failed fork for CPU %u: %li", cpu, PTR_ERR(p));
+
+	wake_up_forked_process(p);
+	init_idle(p, cpu);
+	unhash_process(p);
+
+	paca[cpu].xCurrent = (u64)p;
+	current_set[cpu] = p->thread_info;
+}
+
 void __init smp_prepare_cpus(unsigned int max_cpus)
 {
+	unsigned int cpu;
+
 	/* 
 	 * setup_cpu may need to be called on the boot cpu. We havent
 	 * spun any cpus up but lets be paranoid.
@@ -593,6 +848,8 @@ void __init smp_prepare_cpus(unsigned in
 	 * number of msecs off until someone does a settimeofday()
 	 */
 	do_gtod.tb_orig_stamp = tb_last_stamp;
+
+	look_for_more_cpus();
 #endif
 
 	max_cpus = smp_ops->probe();
@@ -601,20 +858,31 @@ void __init smp_prepare_cpus(unsigned in
 	__save_cpu_setup();
 
 	smp_space_timers(max_cpus);
+
+	for_each_cpu(cpu)
+		if (cpu != boot_cpuid)
+			smp_create_idle(cpu);
 }
 
 void __devinit smp_prepare_boot_cpu(void)
 {
-	cpu_set(smp_processor_id(), cpu_online_map);
-	/* FIXME: what about cpu_possible()? */
+	BUG_ON(smp_processor_id() != boot_cpuid);
+
+	/* cpu_possible is set up in prom.c */
+	cpu_set(boot_cpuid, cpu_online_map);
+
+	paca[boot_cpuid].xCurrent = (u64)current;
+	current_set[boot_cpuid] = current->thread_info;
 }
 
 int __devinit __cpu_up(unsigned int cpu)
 {
-	struct pt_regs regs;
-	struct task_struct *p;
 	int c;
 
+	/* At boot, don't bother with non-present cpus -JSCHOPP */
+	if (system_state == SYSTEM_BOOTING && !cpu_present_at_boot(cpu))
+		return -ENOENT;
+
 	paca[cpu].prof_counter = 1;
 	paca[cpu].prof_multiplier = 1;
 	paca[cpu].default_decr = tb_ticks_per_jiffy / decr_overclock;
@@ -632,19 +900,9 @@ int __devinit __cpu_up(unsigned int cpu)
 		paca[cpu].xStab_data.real = virt_to_abs(tmp);
 	}
 
-	/* create a process for the processor */
-	/* only regs.msr is actually used, and 0 is OK for it */
-	memset(&regs, 0, sizeof(struct pt_regs));
-	p = copy_process(CLONE_VM|CLONE_IDLETASK, 0, &regs, 0, NULL, NULL);
-	if (IS_ERR(p))
-		panic("failed fork for CPU %u: %li", cpu, PTR_ERR(p));
-
-	wake_up_forked_process(p);
-	init_idle(p, cpu);
-	unhash_process(p);
-
-	paca[cpu].xCurrent = (u64)p;
-	current_set[cpu] = p->thread_info;
+	/* The information for processor bringup must be written out
+	 * to main store before we release the processor. */
+	mb();
 
 	/* The information for processor bringup must
 	 * be written out to main store before we release
@@ -676,6 +934,7 @@ int __devinit __cpu_up(unsigned int cpu)
 	return 0;
 }
 
+extern unsigned int default_distrib_server;
 /* Activate a secondary processor. */
 int __devinit start_secondary(void *unused)
 {
@@ -698,6 +957,15 @@ int __devinit start_secondary(void *unus
 	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
 		vpa_init(cpu); 
 	}
+
+#ifdef CONFIG_IRQ_ALL_CPUS
+	/* Put the calling processor into the GIQ.  This is really only
+	 * necessary from a secondary thread as the OF start-cpu interface
+	 * performs this function for us on primary threads.
+	 */
+	/* TODO: 9005 is #defined in rtas-proc.c -- move to a header */
+	rtas_set_indicator(9005, default_distrib_server, 1);
+#endif
 #endif
 
 	local_irq_enable();
@@ -728,71 +996,3 @@ void __init smp_cpus_done(unsigned int m
 
 	set_cpus_allowed(current, old_mask);
 }
-
-#ifdef CONFIG_NUMA
-static struct node node_devices[MAX_NUMNODES];
-
-static void register_nodes(void)
-{
-	int i;
-	int ret;
-
-	for (i = 0; i < MAX_NUMNODES; i++) {
-		if (node_online(i)) {
-			int p_node = parent_node(i);
-			struct node *parent = NULL;
-
-			if (p_node != i)
-				parent = &node_devices[p_node];
-
-			ret = register_node(&node_devices[i], i, parent);
-			if (ret)
-				printk(KERN_WARNING "register_nodes: "
-				       "register_node %d failed (%d)", i, ret);
-		}
-	}
-}
-#else
-static void register_nodes(void)
-{
-	return;
-}
-#endif
-
-/* Only valid if CPU is online. */
-static ssize_t show_physical_id(struct sys_device *dev, char *buf)
-{
-	struct cpu *cpu = container_of(dev, struct cpu, sysdev);
-
-	return sprintf(buf, "%u\n", get_hard_smp_processor_id(cpu->sysdev.id));
-}
-static SYSDEV_ATTR(physical_id, 0444, show_physical_id, NULL);
-
-static DEFINE_PER_CPU(struct cpu, cpu_devices);
-
-static int __init topology_init(void)
-{
-	int cpu;
-	struct node *parent = NULL;
-	int ret;
-
-	register_nodes();
-
-	for_each_cpu(cpu) {
-#ifdef CONFIG_NUMA
-		parent = &node_devices[cpu_to_node(cpu)];
-#endif
-		ret = register_cpu(&per_cpu(cpu_devices, cpu), cpu, parent);
-		if (ret)
-			printk(KERN_WARNING "topology_init: register_cpu %d "
-			       "failed (%d)\n", cpu, ret);
-
-		ret = sysdev_create_file(&per_cpu(cpu_devices, cpu).sysdev,
-					 &attr_physical_id);
-		if (ret)
-			printk(KERN_WARNING "toplogy_init: sysdev_create_file "
-			       "%d failed (%d)\n", cpu, ret);
-	}
-	return 0;
-}
-__initcall(topology_init);
diff -purN linux-2.6.5/arch/ppc64/kernel/sysfs.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/sysfs.c
--- linux-2.6.5/arch/ppc64/kernel/sysfs.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/sysfs.c	2004-04-29 11:17:16.000000000 +0000
@@ -0,0 +1,331 @@
+#include <linux/config.h>
+#include <linux/sysdev.h>
+#include <linux/cpu.h>
+#include <linux/smp.h>
+#include <linux/percpu.h>
+#include <linux/init.h>
+#include <linux/sched.h>
+#include <asm/current.h>
+#include <asm/processor.h>
+#include <asm/cputable.h>
+#include <asm/hvcall.h>
+#include <asm/prom.h>
+
+
+/* SMT stuff */
+
+#ifndef CONFIG_PPC_ISERIES
+
+/* default to snooze disabled */
+DEFINE_PER_CPU(unsigned long, smt_snooze_delay);
+
+static ssize_t store_smt_snooze_delay(struct sys_device *dev, const char *buf,
+				      size_t count)
+{
+	struct cpu *cpu = container_of(dev, struct cpu, sysdev);
+	ssize_t ret;
+	unsigned long snooze;
+
+	ret = sscanf(buf, "%lu", &snooze);
+	if (ret != 1)
+		return -EINVAL;
+
+	per_cpu(smt_snooze_delay, cpu->sysdev.id) = snooze;
+
+	return count;
+}
+
+static ssize_t show_smt_snooze_delay(struct sys_device *dev, char *buf)
+{
+	struct cpu *cpu = container_of(dev, struct cpu, sysdev);
+
+	return sprintf(buf, "%lu\n", per_cpu(smt_snooze_delay, cpu->sysdev.id));
+}
+
+static SYSDEV_ATTR(smt_snooze_delay, 0644, show_smt_snooze_delay,
+		   store_smt_snooze_delay);
+
+/* Only parse OF options if the matching cmdline option was not specified */
+static int smt_snooze_cmdline;
+
+static int __init smt_setup(void)
+{
+	struct device_node *options;
+	unsigned int *val;
+	unsigned int cpu;
+
+	if (!cur_cpu_spec->cpu_features & CPU_FTR_SMT)
+		return 1;
+
+	options = find_path_device("/options");
+	if (!options)
+		return 1;
+
+	val = (unsigned int *)get_property(options, "ibm,smt-snooze-delay",
+					   NULL);
+	if (!smt_snooze_cmdline && val) {
+		for_each_cpu(cpu)
+			per_cpu(smt_snooze_delay, cpu) = *val;
+	}
+
+	return 1;
+}
+__initcall(smt_setup);
+
+static int __init setup_smt_snooze_delay(char *str)
+{
+	unsigned int cpu;
+	int snooze;
+
+	if (!cur_cpu_spec->cpu_features & CPU_FTR_SMT)
+		return 1;
+
+	smt_snooze_cmdline = 1;
+
+	if (get_option(&str, &snooze)) {
+		for_each_cpu(cpu)
+			per_cpu(smt_snooze_delay, cpu) = snooze;
+	}
+
+	return 1;
+}
+__setup("smt-snooze-delay=", setup_smt_snooze_delay);
+
+#endif
+
+
+/* PMC stuff */
+
+/*
+ * Enabling PMCs will slow partition context switch times so we only do
+ * it the first time we write to the PMCs.
+ */
+
+static DEFINE_PER_CPU(char, pmcs_enabled);
+
+#ifdef CONFIG_PPC_ISERIES
+void ppc64_enable_pmcs(void)
+{
+	/* XXX Implement for iseries */
+}
+#else
+void ppc64_enable_pmcs(void)
+{
+	unsigned long hid0;
+	unsigned long set, reset;
+	int ret;
+
+	/* Only need to enable them once */
+	if (__get_cpu_var(pmcs_enabled))
+		return;
+
+	__get_cpu_var(pmcs_enabled) = 1;
+
+	switch (systemcfg->platform) {
+		case PLATFORM_PSERIES:
+			hid0 = mfspr(HID0);
+			hid0 |= 1UL << (63 - 20);
+
+			/* POWER4 requires the following sequence */
+			asm volatile(
+				"sync\n"
+				"mtspr	%1, %0\n"
+				"mfspr	%0, %1\n"
+				"mfspr	%0, %1\n"
+				"mfspr	%0, %1\n"
+				"mfspr	%0, %1\n"
+				"mfspr	%0, %1\n"
+				"mfspr	%0, %1\n"
+				"isync" : "=&r" (hid0) : "i" (HID0), "0" (hid0):
+				"memory");
+			break;
+
+		case PLATFORM_PSERIES_LPAR:
+			set = 1UL << 63;
+			reset = 0;
+			ret = plpar_hcall_norets(H_PERFMON, set, reset);
+			if (ret)
+				printk(KERN_ERR "H_PERFMON call returned %d",
+				       ret);
+			break;
+
+		default:
+			break;
+	}
+
+	/* instruct hypervisor to maintain PMCs */
+	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
+		char *ptr = (char *)&paca[smp_processor_id()].xLpPaca;
+		ptr[0xBB] = 1;
+	}
+}
+#endif
+
+/* XXX convert to rusty's on_one_cpu */
+static unsigned long run_on_cpu(unsigned long cpu,
+			        unsigned long (*func)(unsigned long),
+				unsigned long arg)
+{
+	cpumask_t old_affinity = current->cpus_allowed;
+	unsigned long ret;
+
+	/* should return -EINVAL to userspace */
+	if (set_cpus_allowed(current, cpumask_of_cpu(cpu)))
+		return 0;
+
+	ret = func(arg);
+
+	set_cpus_allowed(current, old_affinity);
+
+	return ret;
+}
+
+#define SYSFS_PMCSETUP(NAME, ADDRESS) \
+static unsigned long read_##NAME(unsigned long junk) \
+{ \
+	return mfspr(ADDRESS); \
+} \
+static unsigned long write_##NAME(unsigned long val) \
+{ \
+	ppc64_enable_pmcs(); \
+	mtspr(ADDRESS, val); \
+	return 0; \
+} \
+static ssize_t show_##NAME(struct sys_device *dev, char *buf) \
+{ \
+	struct cpu *cpu = container_of(dev, struct cpu, sysdev); \
+	unsigned long val = run_on_cpu(cpu->sysdev.id, read_##NAME, 0); \
+	return sprintf(buf, "%lx\n", val); \
+} \
+static ssize_t store_##NAME(struct sys_device *dev, const char *buf, \
+			    size_t count) \
+{ \
+	struct cpu *cpu = container_of(dev, struct cpu, sysdev); \
+	unsigned long val; \
+	int ret = sscanf(buf, "%lx", &val); \
+	if (ret != 1) \
+		return -EINVAL; \
+	run_on_cpu(cpu->sysdev.id, write_##NAME, val); \
+	return count; \
+}
+
+SYSFS_PMCSETUP(mmcr0, SPRN_MMCR0);
+SYSFS_PMCSETUP(mmcr1, SPRN_MMCR1);
+SYSFS_PMCSETUP(mmcra, SPRN_MMCRA);
+SYSFS_PMCSETUP(pmc1, SPRN_PMC1);
+SYSFS_PMCSETUP(pmc2, SPRN_PMC2);
+SYSFS_PMCSETUP(pmc3, SPRN_PMC3);
+SYSFS_PMCSETUP(pmc4, SPRN_PMC4);
+SYSFS_PMCSETUP(pmc5, SPRN_PMC5);
+SYSFS_PMCSETUP(pmc6, SPRN_PMC6);
+SYSFS_PMCSETUP(pmc7, SPRN_PMC7);
+SYSFS_PMCSETUP(pmc8, SPRN_PMC8);
+SYSFS_PMCSETUP(purr, SPRN_PURR);
+
+static SYSDEV_ATTR(mmcr0, 0600, show_mmcr0, store_mmcr0);
+static SYSDEV_ATTR(mmcr1, 0600, show_mmcr1, store_mmcr1);
+static SYSDEV_ATTR(mmcra, 0600, show_mmcra, store_mmcra);
+static SYSDEV_ATTR(pmc1, 0600, show_pmc1, store_pmc1);
+static SYSDEV_ATTR(pmc2, 0600, show_pmc2, store_pmc2);
+static SYSDEV_ATTR(pmc3, 0600, show_pmc3, store_pmc3);
+static SYSDEV_ATTR(pmc4, 0600, show_pmc4, store_pmc4);
+static SYSDEV_ATTR(pmc5, 0600, show_pmc5, store_pmc5);
+static SYSDEV_ATTR(pmc6, 0600, show_pmc6, store_pmc6);
+static SYSDEV_ATTR(pmc7, 0600, show_pmc7, store_pmc7);
+static SYSDEV_ATTR(pmc8, 0600, show_pmc8, store_pmc8);
+static SYSDEV_ATTR(purr, 0600, show_purr, NULL);
+
+static void __init register_cpu_pmc(struct sys_device *s)
+{
+	sysdev_create_file(s, &attr_mmcr0);
+	sysdev_create_file(s, &attr_mmcr1);
+
+	if (cur_cpu_spec->cpu_features & CPU_FTR_MMCRA)
+		sysdev_create_file(s, &attr_mmcra);
+
+	sysdev_create_file(s, &attr_pmc1);
+	sysdev_create_file(s, &attr_pmc2);
+	sysdev_create_file(s, &attr_pmc3);
+	sysdev_create_file(s, &attr_pmc4);
+	sysdev_create_file(s, &attr_pmc5);
+	sysdev_create_file(s, &attr_pmc6);
+
+	if (cur_cpu_spec->cpu_features & CPU_FTR_PMC8) {
+		sysdev_create_file(s, &attr_pmc7);
+		sysdev_create_file(s, &attr_pmc8);
+	}
+
+	if (cur_cpu_spec->cpu_features & CPU_FTR_SMT)
+		sysdev_create_file(s, &attr_purr);
+}
+
+
+/* NUMA stuff */
+
+#ifdef CONFIG_NUMA
+static struct node node_devices[MAX_NUMNODES];
+
+static void register_nodes(void)
+{
+	int i;
+
+	for (i = 0; i < MAX_NUMNODES; i++) {
+		if (node_online(i)) {
+			int p_node = parent_node(i);
+			struct node *parent = NULL;
+
+			if (p_node != i)
+				parent = &node_devices[p_node];
+
+			register_node(&node_devices[i], i, parent);
+		}
+	}
+}
+#else
+static void register_nodes(void)
+{
+	return;
+}
+#endif
+
+
+/* Only valid if CPU is online. */
+static ssize_t show_physical_id(struct sys_device *dev, char *buf)
+{
+	struct cpu *cpu = container_of(dev, struct cpu, sysdev);
+
+	return sprintf(buf, "%u\n", get_hard_smp_processor_id(cpu->sysdev.id));
+}
+static SYSDEV_ATTR(physical_id, 0444, show_physical_id, NULL);
+
+
+static DEFINE_PER_CPU(struct cpu, cpu_devices);
+
+static int __init topology_init(void)
+{
+	int cpu;
+	struct node *parent = NULL;
+
+	register_nodes();
+
+	for_each_cpu(cpu) {
+		struct cpu *c = &per_cpu(cpu_devices, cpu);
+
+#ifdef CONFIG_NUMA
+		parent = &node_devices[cpu_to_node(cpu)];
+#endif
+		register_cpu(c, cpu, parent);
+
+		register_cpu_pmc(&c->sysdev);
+
+		sysdev_create_file(&c->sysdev, &attr_physical_id);
+
+#ifndef CONFIG_PPC_ISERIES
+		if (cur_cpu_spec->cpu_features & CPU_FTR_SMT)
+			sysdev_create_file(&c->sysdev, &attr_smt_snooze_delay);
+#endif
+	}
+
+	return 0;
+}
+__initcall(topology_init);
diff -purN linux-2.6.5/arch/ppc64/kernel/traps.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/traps.c
--- linux-2.6.5/arch/ppc64/kernel/traps.c	2004-04-04 03:37:07.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/traps.c	2004-04-29 11:17:16.000000000 +0000
@@ -37,9 +37,6 @@
 #include <asm/processor.h>
 #include <asm/ppcdebug.h>
 
-extern int fix_alignment(struct pt_regs *);
-extern void bad_page_fault(struct pt_regs *, unsigned long, int);
-
 #ifdef CONFIG_PPC_PSERIES
 /* This is true if we are using the firmware NMI handler (typically LPAR) */
 extern int fwnmi_active;
@@ -67,11 +64,17 @@ EXPORT_SYMBOL(__debugger_fault_handler);
 
 static spinlock_t die_lock = SPIN_LOCK_UNLOCKED;
 
-void die(const char *str, struct pt_regs *regs, long err)
+int die(const char *str, struct pt_regs *regs, long err)
 {
 	static int die_counter;
 	int nl = 0;
 
+	if (debugger_fault_handler(regs))
+		return 1;
+
+	if (debugger(regs))
+		return 1;
+
 	console_verbose();
 	spin_lock_irq(&die_lock);
 	bust_spinlocks(1);
@@ -92,6 +95,24 @@ void die(const char *str, struct pt_regs
 	printk("NUMA ");
 	nl = 1;
 #endif
+	switch(systemcfg->platform) {
+		case PLATFORM_PSERIES:
+			printk("PSERIES ");
+			nl = 1;
+			break;
+		case PLATFORM_PSERIES_LPAR:
+			printk("PSERIES LPAR ");
+			nl = 1;
+			break;
+		case PLATFORM_ISERIES_LPAR:
+			printk("ISERIES LPAR ");
+			nl = 1;
+			break;
+		case PLATFORM_POWERMAC:
+			printk("POWERMAC ");
+			nl = 1;
+			break;
+	}
 	if (nl)
 		printk("\n");
 	show_regs(regs);
@@ -108,15 +129,16 @@ void die(const char *str, struct pt_regs
 		panic("Fatal exception");
 	}
 	do_exit(SIGSEGV);
+
+	return 0;
 }
 
 static void
 _exception(int signr, siginfo_t *info, struct pt_regs *regs)
 {
 	if (!user_mode(regs)) {
-		if (debugger(regs))
+		if (die("Exception in kernel mode", regs, signr))
 			return;
-		die("Exception in kernel mode", regs, signr);
 	}
 
 	force_sig_info(signr, info, current);
@@ -170,8 +192,7 @@ SystemResetException(struct pt_regs *reg
 	}
 #endif
 
-	if (!debugger(regs))
-		die("System Reset", regs, 0);
+	die("System Reset", regs, 0);
 
 	/* Must die if the interrupt is not recoverable */
 	if (!(regs->msr & MSR_RI))
@@ -228,9 +249,6 @@ static int recover_mce(struct pt_regs *r
  *
  * On hardware prior to Power 4 these exceptions were asynchronous which
  * means we can't tell exactly where it occurred and so we can't recover.
- *
- * Note that the debugger should test RI=0 and warn the user that system
- * state has been corrupted.
  */
 void
 MachineCheckException(struct pt_regs *regs)
@@ -248,12 +266,11 @@ MachineCheckException(struct pt_regs *re
 	}
 #endif
 
-	if (debugger_fault_handler(regs))
-		return;
-	if (debugger(regs))
-		return;
+	die("Machine check", regs, 0);
 
-	die("Machine check in kernel mode", regs, 0);
+	/* Must die if the interrupt is not recoverable */
+	if (!(regs->msr & MSR_RI))
+		panic("Unrecoverable Machine check");
 }
 
 void
@@ -379,9 +396,6 @@ ProgramCheckException(struct pt_regs *re
 {
 	siginfo_t info;
 
-	if (debugger_fault_handler(regs))
-		return;
-
 	if (regs->msr & 0x100000) {
 		/* IEEE FP exception */
 
@@ -420,16 +434,18 @@ ProgramCheckException(struct pt_regs *re
 	}
 }
 
-void
-KernelFPUnavailableException(struct pt_regs *regs)
+void KernelFPUnavailableException(struct pt_regs *regs)
 {
-	die("Unrecoverable FP Unavailable Exception in Kernel", regs, 0);
+	printk(KERN_EMERG "Unrecoverable FP Unavailable Exception "
+			  "%lx at %lx\n", regs->trap, regs->nip);
+	die("Unrecoverable FP Unavailable Exception", regs, SIGABRT);
 }
 
-void
-KernelAltivecUnavailableException(struct pt_regs *regs)
+void KernelAltivecUnavailableException(struct pt_regs *regs)
 {
-	die("Unrecoverable VMX/Altivec Unavailable Exception in Kernel", regs, 0);
+	printk(KERN_EMERG "Unrecoverable VMX/Altivec Unavailable Exception "
+			  "%lx at %lx\n", regs->trap, regs->nip);
+	die("Unrecoverable VMX/Altivec Unavailable Exception", regs, SIGABRT);
 }
 
 void
@@ -449,16 +465,16 @@ SingleStepException(struct pt_regs *regs
 	_exception(SIGTRAP, &info, regs);	
 }
 
+static void dummy_perf(struct pt_regs *regs)
+{
+}
+
+void (*perf_irq)(struct pt_regs *) = dummy_perf;
+
 void
 PerformanceMonitorException(struct pt_regs *regs)
 {
-	siginfo_t info;
-
-	info.si_signo = SIGTRAP;
-	info.si_errno = 0;
-	info.si_code = TRAP_BRKPT;
-	info.si_addr = 0;
-	_exception(SIGTRAP, &info, regs);
+	perf_irq(regs);
 }
 
 void
@@ -521,7 +537,6 @@ void unrecoverable_exception(struct pt_r
 {
 	printk(KERN_EMERG "Unrecoverable exception %lx at %lx\n",
 	       regs->trap, regs->nip);
-	debugger(regs);
 	die("Unrecoverable exception", regs, SIGABRT);
 }
 
@@ -533,7 +548,6 @@ void kernel_bad_stack(struct pt_regs *re
 {
 	printk(KERN_EMERG "Bad kernel stack pointer %lx at %lx\n",
 	       regs->gpr[1], regs->nip);
-	debugger(regs);
 	die("Bad kernel stack pointer", regs, SIGABRT);
 }
 
diff -purN linux-2.6.5/arch/ppc64/kernel/vio.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/vio.c
--- linux-2.6.5/arch/ppc64/kernel/vio.c	2004-04-04 03:36:52.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/vio.c	2004-04-29 11:17:16.000000000 +0000
@@ -14,7 +14,6 @@
 
 #include <linux/init.h>
 #include <linux/console.h>
-#include <linux/pci.h>
 #include <linux/version.h>
 #include <linux/module.h>
 #include <linux/kobject.h>
@@ -26,7 +25,8 @@
 #include <asm/ppcdebug.h>
 #include <asm/vio.h>
 #include <asm/hvcall.h>
-#include "open_pic.h"
+#include <asm/iSeries/vio.h>
+#include <asm/iSeries/HvCallXm.h>
 
 #define DBGENTER() pr_debug("%s entered\n", __FUNCTION__)
 
@@ -34,9 +34,31 @@ extern struct subsystem devices_subsys; 
 
 struct iommu_table *vio_build_iommu_table(struct vio_dev *dev);
 
+#ifdef CONFIG_PPC_PSERIES
 static int vio_num_address_cells;
+#endif
 static struct vio_dev *vio_bus_device; /* fake "parent" device */
 
+#ifdef CONFIG_PPC_ISERIES
+static struct iommu_table veth_iommu_table;
+static struct iommu_table vio_iommu_table;
+
+static struct vio_dev _veth_dev = {
+	.iommu_table = &veth_iommu_table,
+	.dev.bus = &vio_bus_type
+};
+static struct vio_dev _vio_dev  = {
+	.iommu_table = &vio_iommu_table,
+	.dev.bus = &vio_bus_type
+};
+
+struct vio_dev *iSeries_veth_dev = &_veth_dev;
+struct device *iSeries_vio_dev = &_vio_dev.dev;
+
+EXPORT_SYMBOL(iSeries_veth_dev);
+EXPORT_SYMBOL(iSeries_vio_dev);
+#endif
+
 /* convert from struct device to struct vio_dev and pass to driver.
  * dev->driver has already been set by generic code because vio_bus_match
  * succeeded. */
@@ -119,21 +141,67 @@ const struct vio_device_id * vio_match_d
 {
 	DBGENTER();
 
+#ifdef CONFIG_PPC_PSERIES
 	while (ids->type) {
 		if ((strncmp(dev->archdata->type, ids->type, strlen(ids->type)) == 0) &&
 			device_is_compatible((struct device_node*)dev->archdata, ids->compat))
 			return ids;
 		ids++;
 	}
+#endif
 	return NULL;
 }
 
+#ifdef CONFIG_PPC_ISERIES
+void __init iommu_vio_init(void)
+{
+	struct iommu_table *t;
+	struct iommu_table_cb cb;
+	unsigned long cbp;
+
+	cb.itc_busno = 255;    /* Bus 255 is the virtual bus */
+	cb.itc_virtbus = 0xff; /* Ask for virtual bus */
+
+	cbp = virt_to_abs(&cb);
+	HvCallXm_getTceTableParms(cbp);
+
+	veth_iommu_table.it_size        = cb.itc_size / 2;
+	veth_iommu_table.it_busno       = cb.itc_busno;
+	veth_iommu_table.it_offset      = cb.itc_offset;
+	veth_iommu_table.it_index       = cb.itc_index;
+	veth_iommu_table.it_type        = TCE_VB;
+	veth_iommu_table.it_entrysize	= sizeof(union tce_entry);
+	veth_iommu_table.it_blocksize	= 1;
+
+	t = iommu_init_table(&veth_iommu_table);
+
+	if (!t)
+		printk("Virtual Bus VETH TCE table failed.\n");
+
+	vio_iommu_table.it_size         = cb.itc_size - veth_iommu_table.it_size;
+	vio_iommu_table.it_busno        = cb.itc_busno;
+	vio_iommu_table.it_offset       = cb.itc_offset +
+		veth_iommu_table.it_size * (PAGE_SIZE/sizeof(union tce_entry));
+	vio_iommu_table.it_index        = cb.itc_index;
+	vio_iommu_table.it_type         = TCE_VB;
+	vio_iommu_table.it_entrysize	= sizeof(union tce_entry);
+	vio_iommu_table.it_blocksize	= 1;
+
+	t = iommu_init_table(&vio_iommu_table);
+
+	if (!t)
+		printk("Virtual Bus VIO TCE table failed.\n");
+}
+#endif
+
 /**
  * vio_bus_init: - Initialize the virtual IO bus
  */
 static int __init vio_bus_init(void)
 {
+#ifdef CONFIG_PPC_PSERIES
 	struct device_node *node_vroot, *of_node;
+#endif
 	int err;
 
 	err = bus_register(&vio_bus_type);
@@ -158,6 +226,7 @@ static int __init vio_bus_init(void)
 		return err;
 	}
 
+#ifdef CONFIG_PPC_PSERIES
 	node_vroot = find_devices("vdevice");
 	if ((node_vroot == NULL) || (node_vroot->child == NULL)) {
 		/* this machine doesn't do virtual IO, and that's ok */
@@ -177,6 +246,7 @@ static int __init vio_bus_init(void)
 
 		vio_register_device(of_node);
 	}
+#endif
 
 	return 0;
 }
@@ -184,6 +254,7 @@ static int __init vio_bus_init(void)
 __initcall(vio_bus_init);
 
 
+#ifdef CONFIG_PPC_PSERIES
 /* vio_dev refcount hit 0 */
 static void __devinit vio_dev_release(struct device *dev)
 {
@@ -256,7 +327,7 @@ struct vio_dev * __devinit vio_register_
 			printk(KERN_ERR "Unable to allocate interrupt "
 			       "number for %s\n", of_node->full_name);
 		} else
-			viodev->irq = openpic_to_irq(virq);
+			viodev->irq = irq_offset_up(virq);
 	}
 
 	/* init generic 'struct device' fields: */
@@ -414,146 +485,48 @@ int vio_disable_interrupts(struct vio_de
 	return rc;
 }
 EXPORT_SYMBOL(vio_disable_interrupts);
-
+#endif
 
 dma_addr_t vio_map_single(struct vio_dev *dev, void *vaddr,
-			  size_t size, int direction )
+			  size_t size, enum dma_data_direction direction)
 {
-	struct iommu_table *tbl;
-	dma_addr_t dma_handle = DMA_ERROR_CODE;
-	unsigned long uaddr;
-	unsigned int npages;
-
-	BUG_ON(direction == PCI_DMA_NONE);
-
-	uaddr = (unsigned long)vaddr;
-	npages = PAGE_ALIGN( uaddr + size ) - ( uaddr & PAGE_MASK );
-	npages >>= PAGE_SHIFT;
-
-	tbl = dev->iommu_table;
-
-	if (tbl) {
-		dma_handle = iommu_alloc(tbl, vaddr, npages, direction);
-		dma_handle |= (uaddr & ~PAGE_MASK);
-	}
-
-	return dma_handle;
+	return iommu_map_single(dev->iommu_table, vaddr, size, direction);
 }
 EXPORT_SYMBOL(vio_map_single);
 
 void vio_unmap_single(struct vio_dev *dev, dma_addr_t dma_handle,
-		      size_t size, int direction)
+		      size_t size, enum dma_data_direction direction)
 {
-	struct iommu_table * tbl;
-	unsigned int npages;
-
-	BUG_ON(direction == PCI_DMA_NONE);
-
-	npages = PAGE_ALIGN( dma_handle + size ) - ( dma_handle & PAGE_MASK );
-	npages >>= PAGE_SHIFT;
-
-	tbl = dev->iommu_table;
-	if(tbl)
-		iommu_free(tbl, dma_handle, npages);
+	iommu_unmap_single(dev->iommu_table, dma_handle, size, direction);
 }
 EXPORT_SYMBOL(vio_unmap_single);
 
 int vio_map_sg(struct vio_dev *vdev, struct scatterlist *sglist, int nelems,
-	       int direction)
+	       enum dma_data_direction direction)
 {
-	struct iommu_table *tbl;
-
-	BUG_ON(direction == PCI_DMA_NONE);
-
-	if (nelems == 0)
-		return 0;
-
-	tbl = vdev->iommu_table;
-	if (!tbl)
-		return 0;
-
-	return iommu_alloc_sg(tbl, &vdev->dev, sglist, nelems, direction);
+	return iommu_map_sg(&vdev->dev, vdev->iommu_table, sglist,
+			nelems, direction);
 }
 EXPORT_SYMBOL(vio_map_sg);
 
 void vio_unmap_sg(struct vio_dev *vdev, struct scatterlist *sglist, int nelems,
-		  int direction)
+		  enum dma_data_direction direction)
 {
-	struct iommu_table *tbl;
-
-	BUG_ON(direction == PCI_DMA_NONE);
-
-	tbl = vdev->iommu_table;
-	if (tbl)
-		iommu_free_sg(tbl, sglist, nelems);
+	iommu_unmap_sg(vdev->iommu_table, sglist, nelems, direction);
 }
 EXPORT_SYMBOL(vio_unmap_sg);
 
 void *vio_alloc_consistent(struct vio_dev *dev, size_t size,
 			   dma_addr_t *dma_handle)
 {
-	struct iommu_table * tbl;
-	void *ret = NULL;
-	unsigned int npages, order;
-	dma_addr_t tce;
-
-	size = PAGE_ALIGN(size);
-	npages = size >> PAGE_SHIFT;
-	order = get_order(size);
-
- 	/* Client asked for way to much space.  This is checked later anyway */
-	/* It is easier to debug here for the drivers than in the tce tables.*/
- 	if(order >= IOMAP_MAX_ORDER) {
- 		printk("VIO_DMA: vio_alloc_consistent size to large: 0x%lx \n", size);
- 		return (void *)DMA_ERROR_CODE;
- 	}
-
-	tbl = dev->iommu_table;
-
-	if (tbl) {
-		/* Alloc enough pages (and possibly more) */
-		ret = (void *)__get_free_pages(GFP_ATOMIC, order);
-		if (ret) {
-			/* Page allocation succeeded */
-			memset(ret, 0, npages << PAGE_SHIFT);
-			/* Set up tces to cover the allocated range */
-			tce = iommu_alloc(tbl, ret, npages, PCI_DMA_BIDIRECTIONAL);
-			if (tce == DMA_ERROR_CODE) {
-				PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: iommu_alloc failed\n" );
-				free_pages((unsigned long)ret, order);
-				ret = NULL;
-			} else {
-				*dma_handle = tce;
-			}
-		}
-		else PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: __get_free_pages failed for size = %d\n", size);
-	}
-	else PPCDBG(PPCDBG_TCE, "vio_alloc_consistent: get_iommu_table failed for 0x%016lx\n", dev);
-
-	PPCDBG(PPCDBG_TCE, "\tvio_alloc_consistent: dma_handle = 0x%16.16lx\n", *dma_handle);
-	PPCDBG(PPCDBG_TCE, "\tvio_alloc_consistent: return     = 0x%16.16lx\n", ret);
-	return ret;
+	return iommu_alloc_consistent(dev->iommu_table, size, dma_handle);
 }
 EXPORT_SYMBOL(vio_alloc_consistent);
 
 void vio_free_consistent(struct vio_dev *dev, size_t size,
 			 void *vaddr, dma_addr_t dma_handle)
 {
-	struct iommu_table *tbl;
-	unsigned int npages;
-
-	PPCDBG(PPCDBG_TCE, "vio_free_consistent:\n");
-	PPCDBG(PPCDBG_TCE, "\tdev = 0x%16.16lx, size = 0x%16.16lx, dma_handle = 0x%16.16lx, vaddr = 0x%16.16lx\n", dev, size, dma_handle, vaddr);
-
-	size = PAGE_ALIGN(size);
-	npages = size >> PAGE_SHIFT;
-
-	tbl = dev->iommu_table;
-
-	if ( tbl ) {
-		iommu_free(tbl, dma_handle, npages);
-		free_pages((unsigned long)vaddr, get_order(size));
-	}
+	iommu_free_consistent(dev->iommu_table, size, vaddr, dma_handle);
 }
 EXPORT_SYMBOL(vio_free_consistent);
 
diff -purN linux-2.6.5/arch/ppc64/kernel/xics.c linux-2.6.5.ppc64_linus/arch/ppc64/kernel/xics.c
--- linux-2.6.5/arch/ppc64/kernel/xics.c	2004-04-04 03:37:23.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/kernel/xics.c	2004-04-29 11:17:16.000000000 +0000
@@ -19,6 +19,7 @@
 #include <linux/init.h>
 #include <linux/gfp.h>
 #include <linux/radix-tree.h>
+#include <linux/cpu.h>
 #include <asm/prom.h>
 #include <asm/io.h>
 #include <asm/pgtable.h>
@@ -58,7 +59,6 @@ struct hw_interrupt_type xics_8259_pic =
 static struct radix_tree_root irq_map = RADIX_TREE_INIT(GFP_KERNEL);
 
 #define XICS_IPI		2
-#define XICS_IRQ_OFFSET		0x10
 #define XICS_IRQ_SPURIOUS	0
 
 /* Want a priority other than 0.  Various HW issues require this. */
@@ -91,7 +91,8 @@ static struct xics_ipl *xics_per_cpu[NR_
 static int xics_irq_8259_cascade = 0;
 static int xics_irq_8259_cascade_real = 0;
 static unsigned int default_server = 0xFF;
-static unsigned int default_distrib_server = 0;
+/* also referenced in smp.c... */
+unsigned int default_distrib_server = 0;
 
 /*
  * XICS only has a single IPI, so encode the messages per CPU
@@ -216,7 +217,7 @@ xics_ops pSeriesLP_ops = {
 
 static unsigned int xics_startup(unsigned int virq)
 {
-	virq -= XICS_IRQ_OFFSET;
+	virq = irq_offset_down(virq);
 	if (radix_tree_insert(&irq_map, virt_irq_to_real(virq),
 			      &virt_irq_to_real_map[virq]) == -ENOMEM)
 		printk(KERN_CRIT "Out of memory creating real -> virtual"
@@ -235,26 +236,54 @@ static unsigned int real_irq_to_virt(uns
 	return ptr - virt_irq_to_real_map;
 }
 
-static void xics_enable_irq(unsigned int virq)
+#ifdef CONFIG_SMP
+static int get_irq_server(unsigned int irq)
 {
-	unsigned int irq;
-	long call_status;
+	cpumask_t cpumask = irq_affinity[irq];
+	cpumask_t allcpus = CPU_MASK_ALL;
+	cpumask_t tmp = CPU_MASK_NONE;
 	unsigned int server;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
-	if (irq == XICS_IPI)
-		return;
-
 #ifdef CONFIG_IRQ_ALL_CPUS
-	if (smp_threads_ready)
-		server = default_distrib_server;
-	else
+	/* For the moment only implement delivery to all cpus or one cpu */
+	if (smp_threads_ready) {
+		if (cpus_equal(cpumask, allcpus)) {
+			server = default_distrib_server;
+		} else {
+			cpus_and(tmp, cpu_online_map, cpumask);
+
+			if (cpus_empty(tmp))
+				server = default_distrib_server;
+			else
+				server = get_hard_smp_processor_id(first_cpu(tmp));
+		}
+	} else {
 		server = default_server;
+	}
 #else
 	server = default_server;
 #endif
+	return server;
+
+}
+#else
+static int get_irq_server(unsigned int irq)
+{
+	return default_server;
+}
+#endif
 
+static void xics_enable_irq(unsigned int virq)
+{
+	unsigned int irq;
+	long call_status;
+	unsigned int server;
+
+	irq = virt_irq_to_real(irq_offset_down(virq));
+	if (irq == XICS_IPI)
+		return;
+
+	server = get_irq_server(virq);
 	call_status = rtas_call(ibm_set_xive, 3, 1, NULL, irq, server,
 				DEFAULT_PRIORITY);
 	if (call_status != 0) {
@@ -275,6 +304,7 @@ static void xics_enable_irq(unsigned int
 static void xics_disable_real_irq(unsigned int irq)
 {
 	long call_status;
+	unsigned int server;
 
 	if (irq == XICS_IPI)
 		return;
@@ -286,9 +316,9 @@ static void xics_disable_real_irq(unsign
 		return;
 	}
 
+	server = get_irq_server(irq);
 	/* Have to set XIVE to 0xff to be able to remove a slot */
-	call_status = rtas_call(ibm_set_xive, 3, 1, NULL, irq, default_server,
-				0xff);
+	call_status = rtas_call(ibm_set_xive, 3, 1, NULL, irq, server, 0xff);
 	if (call_status != 0) {
 		printk(KERN_ERR "xics_disable_irq: irq=%x: ibm_set_xive(0xff)"
 		       " returned %lx\n", irq, call_status);
@@ -300,25 +330,25 @@ static void xics_disable_irq(unsigned in
 {
 	unsigned int irq;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = virt_irq_to_real(irq_offset_down(virq));
 	xics_disable_real_irq(irq);
 }
 
-static void xics_end_irq(unsigned int	irq)
+static void xics_end_irq(unsigned int irq)
 {
 	int cpu = smp_processor_id();
 
 	iosync();
-	ops->xirr_info_set(cpu, ((0xff<<24) |
-				 (virt_irq_to_real(irq-XICS_IRQ_OFFSET))));
+	ops->xirr_info_set(cpu, ((0xff << 24) |
+				 (virt_irq_to_real(irq_offset_down(irq)))));
+
 }
 
 static void xics_mask_and_ack_irq(unsigned int irq)
 {
 	int cpu = smp_processor_id();
 
-	if (irq < XICS_IRQ_OFFSET) {
+	if (irq < irq_offset_value()) {
 		i8259_pic.ack(irq);
 		iosync();
 		ops->xirr_info_set(cpu, ((0xff<<24) |
@@ -344,7 +374,8 @@ int xics_get_irq(struct pt_regs *regs)
 		irq = i8259_irq(cpu);
 		if (irq == -1) {
 			/* Spurious cascaded interrupt.  Still must ack xics */
-                        xics_end_irq(XICS_IRQ_OFFSET + xics_irq_8259_cascade);
+			xics_end_irq(irq_offset_up(xics_irq_8259_cascade));
+
 			irq = -1;
 		}
 	} else if (vec == XICS_IRQ_SPURIOUS) {
@@ -358,7 +389,7 @@ int xics_get_irq(struct pt_regs *regs)
 			       " disabling it.\n", vec);
 			xics_disable_real_irq(vec);
 		} else
-			irq += XICS_IRQ_OFFSET;
+			irq = irq_offset_up(irq);
 	}
 	return irq;
 }
@@ -372,6 +403,9 @@ irqreturn_t xics_ipi_action(int irq, voi
 	int cpu = smp_processor_id();
 
 	ops->qirr_info(cpu, 0xff);
+
+	WARN_ON(cpu_is_offline(cpu));
+
 	while (xics_ipi_message[cpu].value) {
 		if (test_and_clear_bit(PPC_MSG_CALL_FUNCTION,
 				       &xics_ipi_message[cpu].value)) {
@@ -514,6 +548,9 @@ nextnode:
 	if (systemcfg->platform == PLATFORM_PSERIES) {
 #ifdef CONFIG_SMP
 		for_each_cpu(i) {
+			/* FIXME: Do this dynamically! --RR */
+			if (!cpu_present_at_boot(i))
+				continue;
 			xics_per_cpu[i] = __ioremap((ulong)inodes[get_hard_smp_processor_id(i)].addr, 
 						    (ulong)inodes[get_hard_smp_processor_id(i)].size,
 						    _PAGE_NO_CACHE);
@@ -534,9 +571,9 @@ nextnode:
 	xics_8259_pic.enable = i8259_pic.enable;
 	xics_8259_pic.disable = i8259_pic.disable;
 	for (i = 0; i < 16; ++i)
-		irq_desc[i].handler = &xics_8259_pic;
+		get_irq_desc(i)->handler = &xics_8259_pic;
 	for (; i < NR_IRQS; ++i)
-		irq_desc[i].handler = &xics_pic;
+		get_irq_desc(i)->handler = &xics_pic;
 
 	ops->cppr_info(boot_cpuid, 0xff);
 	iosync();
@@ -552,7 +589,7 @@ static int __init xics_setup_i8259(void)
 {
 	if (naca->interrupt_controller == IC_PPC_XIC &&
 	    xics_irq_8259_cascade != -1) {
-		if (request_irq(xics_irq_8259_cascade + XICS_IRQ_OFFSET,
+		if (request_irq(irq_offset_up(xics_irq_8259_cascade),
 				no_action, 0, "8259 cascade", 0))
 			printk(KERN_ERR "xics_init_IRQ: couldn't get 8259 cascade\n");
 		i8259_init();
@@ -567,36 +604,31 @@ void xics_request_IPIs(void)
 	virt_irq_to_real_map[XICS_IPI] = XICS_IPI;
 
 	/* IPIs are marked SA_INTERRUPT as they must run with irqs disabled */
-	request_irq(XICS_IPI + XICS_IRQ_OFFSET, xics_ipi_action, SA_INTERRUPT,
+	request_irq(irq_offset_up(XICS_IPI), xics_ipi_action, SA_INTERRUPT,
 		    "IPI", 0);
-	irq_desc[XICS_IPI+XICS_IRQ_OFFSET].status |= IRQ_PER_CPU;
+	get_irq_desc(irq_offset_up(XICS_IPI))->status |= IRQ_PER_CPU;
 }
 #endif
 
 static void xics_set_affinity(unsigned int virq, cpumask_t cpumask)
 {
-        irq_desc_t *desc = irq_desc + virq;
 	unsigned int irq;
-	unsigned long flags;
 	long status;
 	unsigned long xics_status[2];
 	unsigned long newmask;
 	cpumask_t allcpus = CPU_MASK_ALL;
 	cpumask_t tmp = CPU_MASK_NONE;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = virt_irq_to_real(irq_offset_down(virq));
 	if (irq == XICS_IPI)
 		return;
 
-        spin_lock_irqsave(&desc->lock, flags);
-
 	status = rtas_call(ibm_get_xive, 1, 3, (void *)&xics_status, irq);
 
 	if (status) {
 		printk(KERN_ERR "xics_set_affinity: irq=%d ibm,get-xive "
 		       "returns %ld\n", irq, status);
-		goto out;
+		return;
 	}
 
 	/* For the moment only implement delivery to all cpus or one cpu */
@@ -605,8 +637,8 @@ static void xics_set_affinity(unsigned i
 	} else {
 		cpus_and(tmp, cpu_online_map, cpumask);
 		if (cpus_empty(tmp))
-			goto out;
-		newmask = get_hard_smp_processor_id(first_cpu(cpumask));
+			return;
+		newmask = get_hard_smp_processor_id(first_cpu(tmp));
 	}
 
 	status = rtas_call(ibm_set_xive, 3, 1, NULL,
@@ -615,9 +647,86 @@ static void xics_set_affinity(unsigned i
 	if (status) {
 		printk(KERN_ERR "xics_set_affinity irq=%d ibm,set-xive "
 		       "returns %ld\n", irq, status);
-		goto out;
+		return;
+	}
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+
+/* Interrupts are disabled. */
+void xics_migrate_irqs_away(void)
+{
+	int set_indicator = rtas_token("set-indicator");
+	const unsigned long giqs = 9005UL; /* Global Interrupt Queue Server */
+	unsigned long status = 0;
+	unsigned int irq, cpu = smp_processor_id();
+	unsigned long xics_status[2];
+	unsigned long flags;
+
+	BUG_ON(set_indicator == RTAS_UNKNOWN_SERVICE);
+
+	/* Reject any interrupt that was queued to us... */
+	ops->cppr_info(cpu, 0);
+	iosync();
+
+	/* Refuse any new interrupts... */
+	rtas_call(set_indicator, 3, 1, &status, giqs,
+		  hard_smp_processor_id(), 0UL);
+	WARN_ON(status != 0);
+
+	/* Allow IPIs again... */
+	ops->cppr_info(cpu, DEFAULT_PRIORITY);
+	iosync();
+
+	printk(KERN_WARNING "HOTPLUG: Migrating IRQs away\n");
+	for_each_irq(irq) {
+		irq_desc_t *desc = get_irq_desc(irq);
+
+		/* We need to get IPIs still. */
+		if (irq_offset_down(irq) == XICS_IPI)
+			continue;
+
+		/* We only need to migrate enabled IRQS */
+		if (desc == NULL || desc->handler == NULL
+		    || desc->action == NULL
+		    || desc->handler->set_affinity == NULL)
+			continue;
+
+		spin_lock_irqsave(&desc->lock, flags);
+
+		status = rtas_call(ibm_get_xive, 1, 3, (void *)&xics_status,
+				   irq);
+		if (status) {
+			printk(KERN_ERR "migrate_irqs_away: irq=%d "
+					"ibm,get-xive returns %ld\n",
+					irq, status);
+			goto unlock;
+		}
+
+		/*
+		 * We only support delivery to all cpus or to one cpu.
+		 * The irq has to be migrated only in the single cpu
+		 * case.
+		 */
+		if (xics_status[0] != get_hard_smp_processor_id(cpu))
+			goto unlock;
+
+		printk(KERN_WARNING "IRQ %d affinity broken off cpu %u\n",
+		       irq, cpu);
+
+		/* Reset affinity to all cpus */
+		xics_status[0] = default_distrib_server;
+
+		status = rtas_call(ibm_set_xive, 3, 1, NULL,
+				irq, xics_status[0], xics_status[1]);
+		if (status)
+			printk(KERN_ERR "migrate_irqs_away irq=%d "
+					"ibm,set-xive returns %ld\n",
+					irq, status);
+
+unlock:
+		spin_unlock_irqrestore(&desc->lock, flags);
 	}
 
-out:
-        spin_unlock_irqrestore(&desc->lock, flags);
 }
+#endif
diff -purN linux-2.6.5/arch/ppc64/mm/fault.c linux-2.6.5.ppc64_linus/arch/ppc64/mm/fault.c
--- linux-2.6.5/arch/ppc64/mm/fault.c	2004-04-04 03:37:39.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/mm/fault.c	2004-04-29 11:17:16.000000000 +0000
@@ -37,8 +37,6 @@
 #include <asm/system.h>
 #include <asm/uaccess.h>
 
-void bad_page_fault(struct pt_regs *, unsigned long, int);
-
 /*
  * The error_code parameter is
  *  - DSISR for a non-SLB data access fault,
@@ -177,10 +175,8 @@ do_sigbus:
  * It is called from do_page_fault above and from some of the procedures
  * in traps.c.
  */
-void
-bad_page_fault(struct pt_regs *regs, unsigned long address, int sig)
+void bad_page_fault(struct pt_regs *regs, unsigned long address, int sig)
 {
-	extern void die(const char *, struct pt_regs *, long);
 	const struct exception_table_entry *entry;
 
 	/* Are we prepared to handle this fault?  */
@@ -190,7 +186,5 @@ bad_page_fault(struct pt_regs *regs, uns
 	}
 
 	/* kernel has accessed a bad area */
-	if (debugger(regs))
-		return;
 	die("Kernel access of bad area", regs, sig);
 }
diff -purN linux-2.6.5/arch/ppc64/mm/hash_low.S linux-2.6.5.ppc64_linus/arch/ppc64/mm/hash_low.S
--- linux-2.6.5/arch/ppc64/mm/hash_low.S	2004-04-04 03:38:00.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/mm/hash_low.S	2004-04-29 11:17:16.000000000 +0000
@@ -126,10 +126,12 @@ _GLOBAL(__hash_page)
 	 * code rather than call a C function...) 
 	 */
 BEGIN_FTR_SECTION
+BEGIN_FTR_SECTION
 	mr	r4,r30
 	mr	r5,r7
 	bl	.hash_page_do_lazy_icache
 END_FTR_SECTION_IFSET(CPU_FTR_NOEXECUTE)
+END_FTR_SECTION_IFCLR(CPU_FTR_COHERENT_ICACHE)
 
 	/* At this point, r3 contains new PP bits, save them in
 	 * place of "access" in the param area (sic)
diff -purN linux-2.6.5/arch/ppc64/mm/init.c linux-2.6.5.ppc64_linus/arch/ppc64/mm/init.c
--- linux-2.6.5/arch/ppc64/mm/init.c	2004-04-04 03:37:23.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/mm/init.c	2004-04-29 11:17:16.000000000 +0000
@@ -696,6 +696,8 @@ void __init mem_init(void)
  */
 void flush_dcache_page(struct page *page)
 {
+	if (cur_cpu_spec->cpu_features & CPU_FTR_COHERENT_ICACHE)
+		return;
 	/* avoid an atomic op if possible */
 	if (test_bit(PG_arch_1, &page->flags))
 		clear_bit(PG_arch_1, &page->flags);
@@ -705,6 +707,8 @@ void clear_user_page(void *page, unsigne
 {
 	clear_page(page);
 
+	if (cur_cpu_spec->cpu_features & CPU_FTR_COHERENT_ICACHE)
+		return;
 	/*
 	 * We shouldnt have to do this, but some versions of glibc
 	 * require it (ld.so assumes zero filled pages are icache clean)
@@ -736,6 +740,9 @@ void copy_user_page(void *vto, void *vfr
 		return;
 #endif
 
+	if (cur_cpu_spec->cpu_features & CPU_FTR_COHERENT_ICACHE)
+		return;
+
 	/* avoid an atomic op if possible */
 	if (test_bit(PG_arch_1, &pg->flags))
 		clear_bit(PG_arch_1, &pg->flags);
@@ -768,7 +775,8 @@ void update_mmu_cache(struct vm_area_str
 	cpumask_t tmp;
 
 	/* handle i-cache coherency */
-	if (!(cur_cpu_spec->cpu_features & CPU_FTR_NOEXECUTE)) {
+	if (!(cur_cpu_spec->cpu_features & CPU_FTR_COHERENT_ICACHE) &&
+	    !(cur_cpu_spec->cpu_features & CPU_FTR_NOEXECUTE)) {
 		unsigned long pfn = pte_pfn(pte);
 		if (pfn_valid(pfn)) {
 			struct page *page = pfn_to_page(pfn);
diff -purN linux-2.6.5/arch/ppc64/mm/numa.c linux-2.6.5.ppc64_linus/arch/ppc64/mm/numa.c
--- linux-2.6.5/arch/ppc64/mm/numa.c	2004-04-04 03:37:36.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/mm/numa.c	2004-04-29 11:17:16.000000000 +0000
@@ -16,6 +16,7 @@
 #include <linux/module.h>
 #include <asm/lmb.h>
 #include <asm/machdep.h>
+#include <asm/abs_addr.h>
 
 #if 1
 #define dbg(args...) udbg_printf(args)
@@ -31,9 +32,7 @@
 
 int numa_cpu_lookup_table[NR_CPUS] = { [ 0 ... (NR_CPUS - 1)] =
 	ARRAY_INITIALISER};
-int numa_memory_lookup_table[MAX_MEMORY >> MEMORY_INCREMENT_SHIFT] =
-	{ [ 0 ... ((MAX_MEMORY >> MEMORY_INCREMENT_SHIFT) - 1)] =
-	ARRAY_INITIALISER};
+char *numa_memory_lookup_table;
 cpumask_t numa_cpumask_lookup_table[MAX_NUMNODES];
 int nr_cpus_in_node[MAX_NUMNODES] = { [0 ... (MAX_NUMNODES -1)] = 0};
 
@@ -65,12 +64,20 @@ static int __init parse_numa_properties(
 	int *memory_associativity;
 	int depth;
 	int max_domain = 0;
+	long entries = lmb_end_of_DRAM() >> MEMORY_INCREMENT_SHIFT;
+	long i;
 
 	if (strstr(saved_command_line, "numa=off")) {
 		printk(KERN_WARNING "NUMA disabled by user\n");
 		return -1;
 	}
 
+	numa_memory_lookup_table =
+		(char *)abs_to_virt(lmb_alloc(entries * sizeof(char), 1));
+
+	for (i = 0; i < entries ; i++)
+		numa_memory_lookup_table[i] = ARRAY_INITIALISER;
+
 	cpu = of_find_node_by_type(NULL, "cpu");
 	if (!cpu)
 		goto err;
@@ -124,6 +131,9 @@ static int __init parse_numa_properties(
 			max_domain = numa_domain;
 
 		map_cpu_to_node(cpu_nr, numa_domain);
+		/* register the second thread on an SMT machine */
+		if (cur_cpu_spec->cpu_features & CPU_FTR_SMT)
+			map_cpu_to_node(cpu_nr ^ 0x1, numa_domain);
 	}
 
 	for (; memory; memory = of_find_node_by_type(memory, "memory")) {
@@ -232,6 +242,14 @@ static void __init setup_nonnuma(void)
 	printk(KERN_INFO "Memory hole size: %ldMB\n",
 	       (top_of_ram - total_ram) >> 20);
 
+	if (!numa_memory_lookup_table) {
+		long entries = top_of_ram >> MEMORY_INCREMENT_SHIFT;
+		numa_memory_lookup_table =
+			(char *)abs_to_virt(lmb_alloc(entries * sizeof(char), 1));
+		for (i = 0; i < entries ; i++)
+			numa_memory_lookup_table[i] = ARRAY_INITIALISER;
+	}
+
 	for (i = 0; i < NR_CPUS; i++)
 		map_cpu_to_node(i, 0);
 
diff -purN linux-2.6.5/arch/ppc64/oprofile/Makefile linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/Makefile
--- linux-2.6.5/arch/ppc64/oprofile/Makefile	2004-04-04 03:36:16.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/Makefile	2004-04-29 11:17:16.000000000 +0000
@@ -6,4 +6,4 @@ DRIVER_OBJS := $(addprefix ../../../driv
 		oprofilefs.o oprofile_stats.o \
 		timer_int.o )
 
-oprofile-y := $(DRIVER_OBJS) init.o
+oprofile-y := $(DRIVER_OBJS) common.o op_model_rs64.o op_model_power4.o
diff -purN linux-2.6.5/arch/ppc64/oprofile/common.c linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/common.c
--- linux-2.6.5/arch/ppc64/oprofile/common.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/common.c	2004-04-29 11:17:16.000000000 +0000
@@ -0,0 +1,183 @@
+/*
+ * Copyright (C) 2004 Anton Blanchard <anton@au.ibm.com>, IBM
+ *
+ * Based on alpha version.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/oprofile.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <linux/errno.h>
+#include <asm/ptrace.h>
+#include <asm/system.h>
+
+#include "op_impl.h"
+
+extern struct op_ppc64_model op_model_rs64;
+extern struct op_ppc64_model op_model_power4;
+static struct op_ppc64_model *model;
+
+extern void (*perf_irq)(struct pt_regs *);
+static void (*save_perf_irq)(struct pt_regs *);
+
+static struct op_counter_config ctr[OP_MAX_COUNTER];
+static struct op_system_config sys;
+
+static void op_handle_interrupt(struct pt_regs *regs)
+{
+	model->handle_interrupt(regs, ctr);
+}
+
+static int op_ppc64_setup(void)
+{
+	/* Install our interrupt handler into the existing hook.  */
+	save_perf_irq = perf_irq;
+	perf_irq = op_handle_interrupt;
+
+	mb();
+
+	/* Pre-compute the values to stuff in the hardware registers.  */
+	model->reg_setup(ctr, &sys, model->num_counters);
+
+	/* Configure the registers on all cpus.  */
+	on_each_cpu(model->cpu_setup, NULL, 0, 1);
+
+	return 0;
+}
+
+static void op_ppc64_shutdown(void)
+{
+	/*
+	 * We need to be sure we have cleared all pending exceptions before
+	 * removing the interrupt handler. For the moment we play it safe and
+	 * leave it in
+	 */
+#if 0
+	mb();
+
+	/* Remove our interrupt handler. We may be removing this module. */
+	perf_irq = save_perf_irq;
+#endif
+}
+
+static void op_ppc64_cpu_start(void *dummy)
+{
+	model->start(ctr);
+}
+
+static int op_ppc64_start(void)
+{
+	on_each_cpu(op_ppc64_cpu_start, NULL, 0, 1);
+	return 0;
+}
+
+static inline void op_ppc64_cpu_stop(void *dummy)
+{
+	model->stop();
+}
+
+static void op_ppc64_stop(void)
+{
+	on_each_cpu(op_ppc64_cpu_stop, NULL, 0, 1);
+}
+
+static int op_ppc64_create_files(struct super_block *sb, struct dentry *root)
+{
+	int i;
+
+	for (i = 0; i < model->num_counters; ++i) {
+		struct dentry *dir;
+		char buf[3];
+
+		snprintf(buf, sizeof buf, "%d", i);
+		dir = oprofilefs_mkdir(sb, root, buf);
+
+		oprofilefs_create_ulong(sb, dir, "enabled", &ctr[i].enabled);
+		oprofilefs_create_ulong(sb, dir, "event", &ctr[i].event);
+		oprofilefs_create_ulong(sb, dir, "count", &ctr[i].count);
+		/*
+		 * We dont support per counter user/kernel selection, but
+		 * we leave the entries because userspace expects them
+		 */
+		oprofilefs_create_ulong(sb, dir, "kernel", &ctr[i].kernel);
+		oprofilefs_create_ulong(sb, dir, "user", &ctr[i].user);
+		oprofilefs_create_ulong(sb, dir, "unit_mask", &ctr[i].unit_mask);
+	}
+
+	oprofilefs_create_ulong(sb, root, "enable_kernel", &sys.enable_kernel);
+	oprofilefs_create_ulong(sb, root, "enable_user", &sys.enable_user);
+
+	return 0;
+}
+
+static struct oprofile_operations oprof_ppc64_ops = {
+	.create_files	= op_ppc64_create_files,
+	.setup		= op_ppc64_setup,
+	.shutdown	= op_ppc64_shutdown,
+	.start		= op_ppc64_start,
+	.stop		= op_ppc64_stop,
+	.cpu_type	= NULL		/* To be filled in below. */
+};
+
+int __init oprofile_arch_init(struct oprofile_operations **ops)
+{
+	unsigned int pvr;
+
+	pvr = _get_PVR();
+
+	switch (PVR_VER(pvr)) {
+		case PV_630:
+		case PV_630p:
+			model = &op_model_rs64;
+			model->num_counters = 8;
+			oprof_ppc64_ops.cpu_type = "ppc64/power3";
+			break;
+
+		case PV_NORTHSTAR:
+		case PV_PULSAR:
+		case PV_ICESTAR:
+		case PV_SSTAR:
+			model = &op_model_rs64;
+			model->num_counters = 8;
+			oprof_ppc64_ops.cpu_type = "ppc64/rs64";
+			break;
+
+		case PV_POWER4:
+		case PV_POWER4p:
+			model = &op_model_power4;
+			model->num_counters = 8;
+			oprof_ppc64_ops.cpu_type = "ppc64/power4";
+			break;
+
+		case PV_GPUL:
+			model = &op_model_power4;
+			model->num_counters = 8;
+			oprof_ppc64_ops.cpu_type = "ppc64/970";
+			break;
+
+		case PV_POWER5:
+			model = &op_model_power4;
+			model->num_counters = 6;
+			oprof_ppc64_ops.cpu_type = "ppc64/power5";
+			break;
+
+		default:
+			return -ENODEV;
+	}
+
+	*ops = &oprof_ppc64_ops;
+
+	printk(KERN_INFO "oprofile: using %s performance monitoring.\n",
+	       oprof_ppc64_ops.cpu_type);
+
+	return 0;
+}
+
+void oprofile_arch_exit(void)
+{
+}
diff -purN linux-2.6.5/arch/ppc64/oprofile/init.c linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/init.c
--- linux-2.6.5/arch/ppc64/oprofile/init.c	2004-04-04 03:37:23.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/init.c	1970-01-01 00:00:00.000000000 +0000
@@ -1,24 +0,0 @@
-/**
- * @file init.c
- *
- * @remark Copyright 2002 OProfile authors
- * @remark Read the file COPYING
- *
- * @author John Levon <levon@movementarian.org>
- */
-
-#include <linux/kernel.h>
-#include <linux/oprofile.h>
-#include <linux/init.h>
- 
-extern void timer_init(struct oprofile_operations ** ops);
-
-int __init oprofile_arch_init(struct oprofile_operations ** ops)
-{
-	return -ENODEV;
-}
-
-
-void oprofile_arch_exit(void)
-{
-}
diff -purN linux-2.6.5/arch/ppc64/oprofile/op_impl.h linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/op_impl.h
--- linux-2.6.5/arch/ppc64/oprofile/op_impl.h	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/op_impl.h	2004-04-29 11:17:16.000000000 +0000
@@ -0,0 +1,136 @@
+/*
+ * Copyright (C) 2004 Anton Blanchard <anton@au.ibm.com>, IBM
+ *
+ * Based on alpha version.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#ifndef OP_IMPL_H
+#define OP_IMPL_H 1
+
+#define OP_MAX_COUNTER 8
+
+#define MSR_PMM		(1UL << (63 - 61))
+
+/* freeze counters. set to 1 on a perfmon exception */
+#define MMCR0_FC	(1UL << (31 - 0))
+
+/* freeze counters while MSR mark = 1 */
+#define MMCR0_FCM1	(1UL << (31 - 3))
+
+/* performance monitor exception enable */
+#define MMCR0_PMXE	(1UL << (31 - 5))
+
+/* freeze counters on enabled condition or event */
+#define MMCR0_FCECE	(1UL << (31 - 6))
+
+/* performance monitor alert has occurred, set to 0 after handling exception */
+#define MMCR0_PMAO	(1UL << (31 - 24))
+
+/* PMC1 count enable*/
+#define MMCR0_PMC1INTCONTROL	(1UL << (31 - 16))
+
+/* PMCn count enable*/
+#define MMCR0_PMCNINTCONTROL	(1UL << (31 - 17))
+
+/* state of MSR HV when SIAR set */
+#define MMCRA_SIHV	(1UL << (63 - 35))
+
+/* state of MSR PR when SIAR set */
+#define MMCRA_SIPR	(1UL << (63 - 36))
+
+/* enable sampling */
+#define MMCRA_SAMPLE_ENABLE	(1UL << (63 - 63))
+
+/* Per-counter configuration as set via oprofilefs.  */
+struct op_counter_config {
+	unsigned long valid;
+	unsigned long enabled;
+	unsigned long event;
+	unsigned long count;
+	unsigned long kernel;
+	/* We dont support per counter user/kernel selection */
+	unsigned long user;
+	unsigned long unit_mask;
+};
+
+/* System-wide configuration as set via oprofilefs.  */
+struct op_system_config {
+	unsigned long enable_kernel;
+	unsigned long enable_user;
+};
+
+/* Per-arch configuration */
+struct op_ppc64_model {
+	void (*reg_setup) (struct op_counter_config *,
+			   struct op_system_config *,
+			   int num_counters);
+	void (*cpu_setup) (void *);
+	void (*start) (struct op_counter_config *);
+	void (*stop) (void);
+	void (*handle_interrupt) (struct pt_regs *,
+				  struct op_counter_config *);
+	int num_counters;
+};
+
+static inline unsigned int ctr_read(unsigned int i)
+{
+	switch(i) {
+	case 0:
+		return mfspr(SPRN_PMC1);
+	case 1:
+		return mfspr(SPRN_PMC2);
+	case 2:
+		return mfspr(SPRN_PMC3);
+	case 3:
+		return mfspr(SPRN_PMC4);
+	case 4:
+		return mfspr(SPRN_PMC5);
+	case 5:
+		return mfspr(SPRN_PMC6);
+	case 6:
+		return mfspr(SPRN_PMC7);
+	case 7:
+		return mfspr(SPRN_PMC8);
+	default:
+		return 0;
+	}
+}
+
+static inline void ctr_write(unsigned int i, unsigned int val)
+{
+	switch(i) {
+	case 0:
+		mtspr(SPRN_PMC1, val);
+		break;
+	case 1:
+		mtspr(SPRN_PMC2, val);
+		break;
+	case 2:
+		mtspr(SPRN_PMC3, val);
+		break;
+	case 3:
+		mtspr(SPRN_PMC4, val);
+		break;
+	case 4:
+		mtspr(SPRN_PMC5, val);
+		break;
+	case 5:
+		mtspr(SPRN_PMC6, val);
+		break;
+	case 6:
+		mtspr(SPRN_PMC7, val);
+		break;
+	case 7:
+		mtspr(SPRN_PMC8, val);
+		break;
+	default:
+		break;
+	}
+}
+
+#endif
diff -purN linux-2.6.5/arch/ppc64/oprofile/op_model_power4.c linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/op_model_power4.c
--- linux-2.6.5/arch/ppc64/oprofile/op_model_power4.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/op_model_power4.c	2004-04-29 11:17:16.000000000 +0000
@@ -0,0 +1,248 @@
+/*
+ * Copyright (C) 2004 Anton Blanchard <anton@au.ibm.com>, IBM
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/oprofile.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <asm/ptrace.h>
+#include <asm/system.h>
+#include <asm/processor.h>
+#include <asm/cputable.h>
+#include <asm/systemcfg.h>
+#include <asm/rtas.h>
+
+#define dbg(args...) printk(args)
+
+#include "op_impl.h"
+
+static unsigned long reset_value[OP_MAX_COUNTER];
+
+static int num_counters;
+
+static void power4_reg_setup(struct op_counter_config *ctr,
+			     struct op_system_config *sys,
+			     int num_ctrs)
+{
+	int i;
+
+	num_counters = num_ctrs;
+
+	for (i = 0; i < num_counters; ++i)
+		reset_value[i] = 0x80000000UL - ctr[i].count;
+
+	/* XXX setup user and kernel profiling */
+}
+
+extern void ppc64_enable_pmcs(void);
+
+static void power4_cpu_setup(void *unused)
+{
+	unsigned int mmcr0 = mfspr(SPRN_MMCR0);
+	unsigned long mmcra = mfspr(SPRN_MMCRA);
+
+	ppc64_enable_pmcs();
+
+	/* set the freeze bit */
+	mmcr0 |= MMCR0_FC;
+	mtspr(SPRN_MMCR0, mmcr0);
+
+	mmcr0 |= MMCR0_FCM1|MMCR0_PMXE|MMCR0_FCECE;
+	mmcr0 |= MMCR0_PMC1INTCONTROL|MMCR0_PMCNINTCONTROL;
+	mtspr(SPRN_MMCR0, mmcr0);
+
+	mmcra |= MMCRA_SAMPLE_ENABLE;
+	mtspr(SPRN_MMCRA, mmcra);
+
+	dbg("setup on cpu %d, mmcr0 %lx\n", smp_processor_id(),
+	    mfspr(SPRN_MMCR0));
+	dbg("setup on cpu %d, mmcr1 %lx\n", smp_processor_id(),
+	    mfspr(SPRN_MMCR1));
+	dbg("setup on cpu %d, mmcra %lx\n", smp_processor_id(),
+	    mfspr(SPRN_MMCRA));
+}
+
+static void power4_start(struct op_counter_config *ctr)
+{
+	int i;
+	unsigned int mmcr0;
+
+	/* set the PMM bit (see comment below) */
+	mtmsrd(mfmsr() | MSR_PMM);
+
+	for (i = 0; i < num_counters; ++i) {
+		if (ctr[i].enabled) {
+			ctr_write(i, reset_value[i]);
+		} else {
+			ctr_write(i, 0);
+		}
+	}
+
+	mmcr0 = mfspr(SPRN_MMCR0);
+
+	/*
+	 * We must clear the PMAO bit on some (GQ) chips. Just do it
+	 * all the time
+	 */
+	mmcr0 &= ~MMCR0_PMAO;
+
+	/*
+	 * now clear the freeze bit, counting will not start until we
+	 * rfid from this excetion, because only at that point will
+	 * the PMM bit be cleared
+	 */
+	mmcr0 &= ~MMCR0_FC;
+	mtspr(SPRN_MMCR0, mmcr0);
+
+	dbg("start on cpu %d, mmcr0 %x\n", smp_processor_id(), mmcr0);
+}
+
+static void power4_stop(void)
+{
+	unsigned int mmcr0;
+
+	/* freeze counters */
+	mmcr0 = mfspr(SPRN_MMCR0);
+	mmcr0 |= MMCR0_FC;
+	mtspr(SPRN_MMCR0, mmcr0);
+
+	dbg("stop on cpu %d, mmcr0 %x\n", smp_processor_id(), mmcr0);
+
+	mb();
+}
+
+/* Fake functions used by canonicalize_pc */
+static void __attribute_used__ hypervisor_bucket(void)
+{
+}
+
+static void __attribute_used__ rtas_bucket(void)
+{
+}
+
+static void __attribute_used__ kernel_unknown_bucket(void)
+{
+}
+
+/* XXX Not currently working */
+static int mmcra_has_sihv = 0;
+
+/*
+ * On GQ and newer the MMCRA stores the HV and PR bits at the time
+ * the SIAR was sampled. We use that to work out if the SIAR was sampled in
+ * the hypervisor, our exception vectors or RTAS.
+ */
+static unsigned long get_pc(void)
+{
+	unsigned long pc = mfspr(SPRN_SIAR);
+	unsigned long mmcra;
+
+	/* Cant do much about it */
+	if (!mmcra_has_sihv)
+		return pc;
+
+	mmcra = mfspr(SPRN_MMCRA);
+
+	/* Were we in the hypervisor? */
+	if ((systemcfg->platform == PLATFORM_PSERIES_LPAR) &&
+	    (mmcra & MMCRA_SIHV))
+		/* function descriptor madness */
+		return *((unsigned long *)hypervisor_bucket);
+
+	/* We were in userspace, nothing to do */
+	if (mmcra & MMCRA_SIPR)
+		return pc;
+
+	/* Were we in our exception vectors? */
+	if (pc < 0x4000UL)
+		return (unsigned long)__va(pc);
+
+#ifdef CONFIG_PPC_PSERIES
+	/* Were we in RTAS? */
+	if (pc >= rtas.base && pc < (rtas.base + rtas.size))
+		/* function descriptor madness */
+		return *((unsigned long *)rtas_bucket);
+#endif
+
+	/* Not sure where we were */
+	if (pc < KERNELBASE)
+		/* function descriptor madness */
+		return *((unsigned long *)kernel_unknown_bucket);
+
+	return pc;
+}
+
+static int get_kernel(unsigned long pc)
+{
+	int is_kernel;
+
+	if (!mmcra_has_sihv) {
+		is_kernel = (pc >= KERNELBASE);
+	} else {
+		unsigned long mmcra = mfspr(SPRN_MMCRA);
+		is_kernel = ((mmcra & MMCRA_SIPR) == 0);
+	}
+
+	return is_kernel;
+}
+
+static void power4_handle_interrupt(struct pt_regs *regs,
+				    struct op_counter_config *ctr)
+{
+	unsigned long pc;
+	int is_kernel;
+	int val;
+	int i;
+	unsigned int cpu = smp_processor_id();
+	unsigned int mmcr0;
+
+	pc = get_pc();
+	is_kernel = get_kernel(pc);
+
+	/* set the PMM bit (see comment below) */
+	mtmsrd(mfmsr() | MSR_PMM);
+
+	for (i = 0; i < num_counters; ++i) {
+		val = ctr_read(i);
+		if (val < 0) {
+			if (ctr[i].enabled) {
+				oprofile_add_sample(pc, is_kernel, i, cpu);
+				ctr_write(i, reset_value[i]);
+			} else {
+				ctr_write(i, 0);
+			}
+		}
+	}
+
+	mmcr0 = mfspr(SPRN_MMCR0);
+
+	/* reset the perfmon trigger */
+	mmcr0 |= MMCR0_PMXE;
+
+	/*
+	 * We must clear the PMAO bit on some (GQ) chips. Just do it
+	 * all the time
+	 */
+	mmcr0 &= ~MMCR0_PMAO;
+
+	/*
+	 * now clear the freeze bit, counting will not start until we
+	 * rfid from this exception, because only at that point will
+	 * the PMM bit be cleared
+	 */
+	mmcr0 &= ~MMCR0_FC;
+	mtspr(SPRN_MMCR0, mmcr0);
+}
+
+struct op_ppc64_model op_model_power4 = {
+	.reg_setup		= power4_reg_setup,
+	.cpu_setup		= power4_cpu_setup,
+	.start			= power4_start,
+	.stop			= power4_stop,
+	.handle_interrupt	= power4_handle_interrupt,
+};
diff -purN linux-2.6.5/arch/ppc64/oprofile/op_model_rs64.c linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/op_model_rs64.c
--- linux-2.6.5/arch/ppc64/oprofile/op_model_rs64.c	1970-01-01 00:00:00.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/oprofile/op_model_rs64.c	2004-04-29 11:17:16.000000000 +0000
@@ -0,0 +1,220 @@
+/*
+ * Copyright (C) 2004 Anton Blanchard <anton@au.ibm.com>, IBM
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/oprofile.h>
+#include <linux/init.h>
+#include <linux/smp.h>
+#include <asm/ptrace.h>
+#include <asm/system.h>
+#include <asm/processor.h>
+#include <asm/cputable.h>
+
+#define dbg(args...) printk(args)
+
+#include "op_impl.h"
+
+static void ctrl_write(unsigned int i, unsigned int val)
+{
+	unsigned int tmp;
+	unsigned long shift, mask;
+
+	dbg("ctrl_write %d %x\n", i, val);
+
+	switch(i) {
+	case 0:
+		tmp = mfspr(SPRN_MMCR0);
+		shift = 6;
+		mask = 0x7F;
+		break;
+	case 1:
+		tmp = mfspr(SPRN_MMCR0);
+		shift = 0;
+		mask = 0x3F;
+		break;
+	case 2:
+		tmp = mfspr(SPRN_MMCR1);
+		shift = 31 - 4;
+		mask = 0x1F;
+		break;
+	case 3:
+		tmp = mfspr(SPRN_MMCR1);
+		shift = 31 - 9;
+		mask = 0x1F;
+		break;
+	case 4:
+		tmp = mfspr(SPRN_MMCR1);
+		shift = 31 - 14;
+		mask = 0x1F;
+		break;
+	case 5:
+		tmp = mfspr(SPRN_MMCR1);
+		shift = 31 - 19;
+		mask = 0x1F;
+		break;
+	case 6:
+		tmp = mfspr(SPRN_MMCR1);
+		shift = 31 - 24;
+		mask = 0x1F;
+		break;
+	case 7:
+		tmp = mfspr(SPRN_MMCR1);
+		shift = 31 - 28;
+		mask = 0xF;
+		break;
+	}
+
+	tmp = tmp & ~(mask << shift);
+	tmp |= val << shift;
+
+	switch(i) {
+		case 0:
+		case 1:
+			mtspr(SPRN_MMCR0, tmp);
+			break;
+		default:
+			mtspr(SPRN_MMCR1, tmp);
+	}
+
+	dbg("ctrl_write mmcr0 %lx mmcr1 %lx\n", mfspr(SPRN_MMCR0),
+	       mfspr(SPRN_MMCR1));
+}
+
+static unsigned long reset_value[OP_MAX_COUNTER];
+
+static int num_counters;
+
+static void rs64_reg_setup(struct op_counter_config *ctr,
+			   struct op_system_config *sys,
+			   int num_ctrs)
+{
+	int i;
+
+	num_counters = num_ctrs;
+
+	for (i = 0; i < num_counters; ++i)
+		reset_value[i] = 0x80000000UL - ctr[i].count;
+
+	/* XXX setup user and kernel profiling */
+}
+
+static void rs64_cpu_setup(void *unused)
+{
+	unsigned int mmcr0;
+
+	/* reset MMCR0 and set the freeze bit */
+	mmcr0 = MMCR0_FC;
+	mtspr(SPRN_MMCR0, mmcr0);
+
+	/* reset MMCR1, MMCRA */
+	mtspr(SPRN_MMCR1, 0);
+
+	if (cur_cpu_spec->cpu_features & CPU_FTR_MMCRA)
+		mtspr(SPRN_MMCRA, 0);
+
+	mmcr0 |= MMCR0_FCM1|MMCR0_PMXE|MMCR0_FCECE;
+	/* Only applies to POWER3, but should be safe on RS64 */
+	mmcr0 |= MMCR0_PMC1INTCONTROL|MMCR0_PMCNINTCONTROL;
+	mtspr(SPRN_MMCR0, mmcr0);
+
+	dbg("setup on cpu %d, mmcr0 %lx\n", smp_processor_id(),
+	    mfspr(SPRN_MMCR0));
+	dbg("setup on cpu %d, mmcr1 %lx\n", smp_processor_id(),
+	    mfspr(SPRN_MMCR1));
+}
+
+static void rs64_start(struct op_counter_config *ctr)
+{
+	int i;
+	unsigned int mmcr0;
+
+	/* set the PMM bit (see comment below) */
+	mtmsrd(mfmsr() | MSR_PMM);
+
+	for (i = 0; i < num_counters; ++i) {
+		if (ctr[i].enabled) {
+			ctr_write(i, reset_value[i]);
+			ctrl_write(i, ctr[i].event);
+		} else {
+			ctr_write(i, 0);
+		}
+	}
+
+	mmcr0 = mfspr(SPRN_MMCR0);
+
+	/*
+	 * now clear the freeze bit, counting will not start until we
+	 * rfid from this excetion, because only at that point will
+	 * the PMM bit be cleared
+	 */
+	mmcr0 &= ~MMCR0_FC;
+	mtspr(SPRN_MMCR0, mmcr0);
+
+	dbg("start on cpu %d, mmcr0 %x\n", smp_processor_id(), mmcr0);
+}
+
+static void rs64_stop(void)
+{
+	unsigned int mmcr0;
+
+	/* freeze counters */
+	mmcr0 = mfspr(SPRN_MMCR0);
+	mmcr0 |= MMCR0_FC;
+	mtspr(SPRN_MMCR0, mmcr0);
+
+	dbg("stop on cpu %d, mmcr0 %x\n", smp_processor_id(), mmcr0);
+
+	mb();
+}
+
+static void rs64_handle_interrupt(struct pt_regs *regs,
+				  struct op_counter_config *ctr)
+{
+	unsigned int mmcr0;
+	int val;
+	int i;
+	unsigned long pc = mfspr(SPRN_SIAR);
+	int is_kernel = (pc >= KERNELBASE);
+	unsigned int cpu = smp_processor_id();
+
+	/* set the PMM bit (see comment below) */
+	mtmsrd(mfmsr() | MSR_PMM);
+
+	for (i = 0; i < num_counters; ++i) {
+		val = ctr_read(i);
+		if (val < 0) {
+			if (ctr[i].enabled) {
+				oprofile_add_sample(pc, is_kernel, i, cpu);
+				ctr_write(i, reset_value[i]);
+			} else {
+				ctr_write(i, 0);
+			}
+		}
+	}
+
+	mmcr0 = mfspr(SPRN_MMCR0);
+
+	/* reset the perfmon trigger */
+	mmcr0 |= MMCR0_PMXE;
+
+	/*
+	 * now clear the freeze bit, counting will not start until we
+	 * rfid from this exception, because only at that point will
+	 * the PMM bit be cleared
+	 */
+	mmcr0 &= ~MMCR0_FC;
+	mtspr(SPRN_MMCR0, mmcr0);
+}
+
+struct op_ppc64_model op_model_rs64 = {
+	.reg_setup		= rs64_reg_setup,
+	.cpu_setup		= rs64_cpu_setup,
+	.start			= rs64_start,
+	.stop			= rs64_stop,
+	.handle_interrupt	= rs64_handle_interrupt,
+};
diff -purN linux-2.6.5/arch/ppc64/xmon/start.c linux-2.6.5.ppc64_linus/arch/ppc64/xmon/start.c
--- linux-2.6.5/arch/ppc64/xmon/start.c	2004-04-04 03:38:26.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/xmon/start.c	2004-04-29 11:17:16.000000000 +0000
@@ -19,6 +19,7 @@
 #include <asm/processor.h>
 #include <asm/udbg.h>
 #include <asm/system.h>
+#include "nonstdio.h"
 
 #ifdef CONFIG_MAGIC_SYSRQ
 
@@ -63,9 +64,8 @@ xmon_read_poll(void)
 	return udbg_getc_poll();
 }
  
-void *xmon_stdin;
-void *xmon_stdout;
-void *xmon_stderr;
+FILE *xmon_stdin;
+FILE *xmon_stdout;
 
 int
 xmon_putc(int c, void *f)
diff -purN linux-2.6.5/arch/ppc64/xmon/xmon.c linux-2.6.5.ppc64_linus/arch/ppc64/xmon/xmon.c
--- linux-2.6.5/arch/ppc64/xmon/xmon.c	2004-04-04 03:38:10.000000000 +0000
+++ linux-2.6.5.ppc64_linus/arch/ppc64/xmon/xmon.c	2004-04-29 11:17:16.000000000 +0000
@@ -452,7 +452,7 @@ insert_bpts()
 		}
 	}
 
-	if ((cur_cpu_spec->cpu_features & CPU_FTR_DABR) && dabr.enabled)
+	if (dabr.enabled)
 		set_dabr(dabr.address);
 	if ((cur_cpu_spec->cpu_features & CPU_FTR_IABR) && iabr.enabled)
 		set_iabr(iabr.address);
@@ -465,8 +465,7 @@ remove_bpts()
 	struct bpt *bp;
 	unsigned instr;
 
-	if ((cur_cpu_spec->cpu_features & CPU_FTR_DABR))
-		set_dabr(0);
+	set_dabr(0);
 	if ((cur_cpu_spec->cpu_features & CPU_FTR_IABR))
 		set_iabr(0);
 
@@ -543,8 +542,7 @@ cmds(struct pt_regs *excp)
 			symbol_lookup();
 			break;
 		case 'r':
-			if (excp != NULL)
-				prregs(excp);	/* print regs */
+			prregs(excp);	/* print regs */
 			break;
 		case 'e':
 			if (excp == NULL)
@@ -751,10 +749,6 @@ bpt_cmds(void)
 	cmd = inchar();
 	switch (cmd) {
 	case 'd':	/* bd - hardware data breakpoint */
-		if (!(cur_cpu_spec->cpu_features & CPU_FTR_DABR)) {
-			printf("Not implemented on this cpu\n");
-			break;
-		}
 		mode = 7;
 		cmd = inchar();
 		if (cmd == 'r')
@@ -971,8 +965,7 @@ static void backtrace(struct pt_regs *ex
 
 spinlock_t exception_print_lock = SPIN_LOCK_UNLOCKED;
 
-void
-excprint(struct pt_regs *fp)
+void excprint(struct pt_regs *fp)
 {
 	unsigned long flags;
 
@@ -1007,21 +1000,31 @@ excprint(struct pt_regs *fp)
 	spin_unlock_irqrestore(&exception_print_lock, flags);
 }
 
-void
-prregs(struct pt_regs *fp)
+void prregs(struct pt_regs *fp)
 {
 	int n;
 	unsigned long base;
 
 	if (scanhex((void *)&base))
 		fp = (struct pt_regs *) base;
-	for (n = 0; n < 16; ++n)
-		printf("R%.2ld = %.16lx   R%.2ld = %.16lx\n", n, fp->gpr[n],
-		       n+16, fp->gpr[n+16]);
-	printf("pc  = %.16lx   msr = %.16lx\nlr  = %.16lx   cr  = %.16lx\n",
-	       fp->nip, fp->msr, fp->link, fp->ccr);
-	printf("ctr = %.16lx   xer = %.16lx   trap = %8lx\n",
-	       fp->ctr, fp->xer, fp->trap);
+
+	if (setjmp(bus_error_jmp) == 0) {
+		__debugger_fault_handler = handle_fault;
+		sync();
+		for (n = 0; n < 16; ++n)
+			printf("R%.2ld = %.16lx   R%.2ld = %.16lx\n", n,
+			       fp->gpr[n], n+16, fp->gpr[n+16]);
+		printf("pc  = %.16lx   msr = %.16lx\nlr  = %.16lx   "
+		       "cr  = %.16lx\n", fp->nip, fp->msr, fp->link, fp->ccr);
+		printf("ctr = %.16lx   xer = %.16lx   trap = %8lx\n",
+		       fp->ctr, fp->xer, fp->trap);
+
+		sync();
+		/* wait a little while to see if we get a machine check */
+		__delay(200);
+	} else {
+		printf("*** Error reading regs\n");
+	}
 }
 
 void
diff -purN linux-2.6.5/include/asm-ppc64/cacheflush.h linux-2.6.5.ppc64_linus/include/asm-ppc64/cacheflush.h
--- linux-2.6.5/include/asm-ppc64/cacheflush.h	2004-04-04 03:36:16.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/cacheflush.h	2004-04-29 11:17:16.000000000 +0000
@@ -1,8 +1,8 @@
 #ifndef _PPC64_CACHEFLUSH_H
 #define _PPC64_CACHEFLUSH_H
 
-/* Keep includes the same across arches.  */
 #include <linux/mm.h>
+#include <asm/cputable.h>
 
 /*
  * No cache flushing is required when address mappings are
@@ -18,7 +18,7 @@
 #define flush_cache_vunmap(start, end)		do { } while (0)
 
 extern void flush_dcache_page(struct page *page);
-extern void flush_icache_range(unsigned long, unsigned long);
+extern void __flush_icache_range(unsigned long, unsigned long);
 extern void flush_icache_user_range(struct vm_area_struct *vma,
 				    struct page *page, unsigned long addr,
 				    int len);
@@ -35,4 +35,10 @@ do { memcpy(dst, src, len); \
 
 extern void __flush_dcache_icache(void *page_va);
 
+static inline void flush_icache_range(unsigned long start, unsigned long stop)
+{
+	if (!(cur_cpu_spec->cpu_features & CPU_FTR_COHERENT_ICACHE))
+		__flush_icache_range(start, stop);
+}
+
 #endif /* _PPC64_CACHEFLUSH_H */
diff -purN linux-2.6.5/include/asm-ppc64/cputable.h linux-2.6.5.ppc64_linus/include/asm-ppc64/cputable.h
--- linux-2.6.5/include/asm-ppc64/cputable.h	2004-04-04 03:37:37.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/cputable.h	2004-04-29 11:17:16.000000000 +0000
@@ -125,8 +125,12 @@ extern firmware_feature_t firmware_featu
 #define CPU_FTR_TLBIEL         		0x0000000400000000
 #define CPU_FTR_NOEXECUTE     		0x0000000800000000
 #define CPU_FTR_NODSISRALIGN  		0x0000001000000000
-#define CPU_FTR_DABR  			0x0000002000000000
-#define CPU_FTR_IABR  			0x0000004000000000
+#define CPU_FTR_IABR  			0x0000002000000000
+#define CPU_FTR_MMCRA  			0x0000004000000000
+#define CPU_FTR_PMC8  			0x0000008000000000
+#define CPU_FTR_SMT  			0x0000010000000000
+#define CPU_FTR_COHERENT_ICACHE  	0x0000020000000000
+#define CPU_FTR_LOCKLESS_TLBIE		0x0000040000000000
 
 /* Platform firmware features */
 #define FW_FTR_                         0x0000000000000001
diff -purN linux-2.6.5/include/asm-ppc64/dma-mapping.h linux-2.6.5.ppc64_linus/include/asm-ppc64/dma-mapping.h
--- linux-2.6.5/include/asm-ppc64/dma-mapping.h	2004-04-04 03:38:20.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/dma-mapping.h	2004-04-29 11:17:16.000000000 +0000
@@ -36,10 +36,43 @@ extern int dma_map_sg(struct device *dev
 		enum dma_data_direction direction);
 extern void dma_unmap_sg(struct device *dev, struct scatterlist *sg,
 		int nhwentries, enum dma_data_direction direction);
-extern void dma_sync_single(struct device *dev, dma_addr_t dma_handle,
-		size_t size, enum dma_data_direction direction);
-extern void dma_sync_sg(struct device *dev, struct scatterlist *sg, int nelems,
-		enum dma_data_direction direction);
+
+static inline void
+dma_sync_single_for_cpu(struct device *dev, dma_addr_t dma_handle, size_t size,
+			enum dma_data_direction direction)
+{
+	BUG_ON(direction == DMA_NONE);
+	/* nothing to do */
+}
+
+static inline void
+dma_sync_single_for_device(struct device *dev, dma_addr_t dma_handle, size_t size,
+			   enum dma_data_direction direction)
+{
+	BUG_ON(direction == DMA_NONE);
+	/* nothing to do */
+}
+
+static inline void
+dma_sync_sg_for_cpu(struct device *dev, struct scatterlist *sg, int nelems,
+		    enum dma_data_direction direction)
+{
+	BUG_ON(direction == DMA_NONE);
+	/* nothing to do */
+}
+
+static inline void
+dma_sync_sg_for_device(struct device *dev, struct scatterlist *sg, int nelems,
+		       enum dma_data_direction direction)
+{
+	BUG_ON(direction == DMA_NONE);
+	/* nothing to do */
+}
+
+static inline int dma_mapping_error(dma_addr_t dma_addr)
+{
+	return (dma_addr == DMA_ERROR_CODE);
+}
 
 /* Now for the API extensions over the pci_ one */
 
@@ -56,27 +89,29 @@ dma_get_cache_alignment(void)
 }
 
 static inline void
-dma_sync_single_range(struct device *dev, dma_addr_t dma_handle,
-		      unsigned long offset, size_t size,
-		      enum dma_data_direction direction)
+dma_sync_single_range_for_cpu(struct device *dev, dma_addr_t dma_handle,
+			      unsigned long offset, size_t size,
+			      enum dma_data_direction direction)
 {
-	/* just sync everything, that's all the pci API can do */
-	dma_sync_single(dev, dma_handle, offset+size, direction);
+	BUG_ON(direction == DMA_NONE);
+	/* nothing to do */
 }
 
 static inline void
-dma_cache_sync(void *vaddr, size_t size,
-	       enum dma_data_direction direction)
+dma_sync_single_range_for_device(struct device *dev, dma_addr_t dma_handle,
+				 unsigned long offset, size_t size,
+				 enum dma_data_direction direction)
 {
-	/* could define this in terms of the dma_cache ... operations,
-	 * but if you get this on a platform, you should convert the platform
-	 * to using the generic device DMA API */
-	BUG();
+	BUG_ON(direction == DMA_NONE);
+	/* nothing to do */
 }
 
-static inline int dma_mapping_error(dma_addr_t dma_addr)
+static inline void
+dma_cache_sync(void *vaddr, size_t size,
+	       enum dma_data_direction direction)
 {
-	return (dma_addr == DMA_ERROR_CODE);
+	BUG_ON(direction == DMA_NONE);
+	/* nothing to do */
 }
 
 #endif	/* _ASM_DMA_MAPPING_H */
diff -purN linux-2.6.5/include/asm-ppc64/eeh.h linux-2.6.5.ppc64_linus/include/asm-ppc64/eeh.h
--- linux-2.6.5/include/asm-ppc64/eeh.h	2004-04-04 03:38:14.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/eeh.h	2004-04-29 11:17:16.000000000 +0000
@@ -199,74 +199,71 @@ static inline void eeh_memcpy_toio(void 
 	memcpy(vdest, src, n);
 }
 
-/* The I/O macros must handle ISA ports as well as PCI I/O bars.
- * ISA does not implement EEH and ISA may not exist in the system.
- * For PCI we check for EEH failures.
- */
-#define _IO_IS_ISA(port) ((port) < 0x10000)
-#define _IO_HAS_ISA_BUS	(isa_io_base != 0)
+#define MAX_ISA_PORT 0x10000
+extern unsigned long io_page_mask;
+#define _IO_IS_VALID(port) ((port) >= MAX_ISA_PORT || (1 << (port>>PAGE_SHIFT)) & io_page_mask)
 
 static inline u8 eeh_inb(unsigned long port) {
 	u8 val;
-	if (_IO_IS_ISA(port) && !_IO_HAS_ISA_BUS)
+	if (!_IO_IS_VALID(port))
 		return ~0;
 	val = in_8((u8 *)(port+pci_io_base));
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR(val, u8))
+	if (EEH_POSSIBLE_IO_ERROR(val, u8))
 		return eeh_check_failure((void*)(port), val);
 	return val;
 }
 
 static inline void eeh_outb(u8 val, unsigned long port) {
-	if (!_IO_IS_ISA(port) || _IO_HAS_ISA_BUS)
+	if (_IO_IS_VALID(port))
 		return out_8((u8 *)(port+pci_io_base), val);
 }
 
 static inline u16 eeh_inw(unsigned long port) {
 	u16 val;
-	if (_IO_IS_ISA(port) && !_IO_HAS_ISA_BUS)
+	if (!_IO_IS_VALID(port))
 		return ~0;
 	val = in_le16((u16 *)(port+pci_io_base));
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR(val, u16))
+	if (EEH_POSSIBLE_IO_ERROR(val, u16))
 		return eeh_check_failure((void*)(port), val);
 	return val;
 }
 
 static inline void eeh_outw(u16 val, unsigned long port) {
-	if (!_IO_IS_ISA(port) || _IO_HAS_ISA_BUS)
+	if (_IO_IS_VALID(port))
 		return out_le16((u16 *)(port+pci_io_base), val);
 }
 
 static inline u32 eeh_inl(unsigned long port) {
 	u32 val;
-	if (_IO_IS_ISA(port) && !_IO_HAS_ISA_BUS)
+	if (!_IO_IS_VALID(port))
 		return ~0;
 	val = in_le32((u32 *)(port+pci_io_base));
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR(val, u32))
+	if (EEH_POSSIBLE_IO_ERROR(val, u32))
 		return eeh_check_failure((void*)(port), val);
 	return val;
 }
 
 static inline void eeh_outl(u32 val, unsigned long port) {
-	if (!_IO_IS_ISA(port) || _IO_HAS_ISA_BUS)
+	if (_IO_IS_VALID(port))
 		return out_le32((u32 *)(port+pci_io_base), val);
 }
 
 /* in-string eeh macros */
 static inline void eeh_insb(unsigned long port, void * buf, int ns) {
 	_insb((u8 *)(port+pci_io_base), buf, ns);
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR((*(((u8*)buf)+ns-1)), u8))
+	if (EEH_POSSIBLE_IO_ERROR((*(((u8*)buf)+ns-1)), u8))
 		eeh_check_failure((void*)(port), *(u8*)buf);
 }
 
 static inline void eeh_insw_ns(unsigned long port, void * buf, int ns) {
 	_insw_ns((u16 *)(port+pci_io_base), buf, ns);
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR((*(((u16*)buf)+ns-1)), u16))
+	if (EEH_POSSIBLE_IO_ERROR((*(((u16*)buf)+ns-1)), u16))
 		eeh_check_failure((void*)(port), *(u16*)buf);
 }
 
 static inline void eeh_insl_ns(unsigned long port, void * buf, int nl) {
 	_insl_ns((u32 *)(port+pci_io_base), buf, nl);
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR((*(((u32*)buf)+nl-1)), u32))
+	if (EEH_POSSIBLE_IO_ERROR((*(((u32*)buf)+nl-1)), u32))
 		eeh_check_failure((void*)(port), *(u32*)buf);
 }
 
diff -purN linux-2.6.5/include/asm-ppc64/hw_irq.h linux-2.6.5.ppc64_linus/include/asm-ppc64/hw_irq.h
--- linux-2.6.5/include/asm-ppc64/hw_irq.h	2004-04-04 03:38:22.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/hw_irq.h	2004-04-29 11:17:16.000000000 +0000
@@ -75,9 +75,24 @@ static inline void __do_save_and_cli(uns
 
 #endif /* CONFIG_PPC_ISERIES */
 
-#define mask_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->disable) irq_desc[irq].handler->disable(irq);})
-#define unmask_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->enable) irq_desc[irq].handler->enable(irq);})
-#define ack_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->ack) irq_desc[irq].handler->ack(irq);})
+#define mask_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->disable)	\
+			desc->handler->disable(irq);		\
+	})
+#define unmask_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->enable)	\
+			desc->handler->enable(irq);		\
+	})
+#define ack_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->ack)	\
+			desc->handler->ack(irq);		\
+	})
 
 /* Should we handle this via lost interrupts and IPIs or should we don't care like
  * we do now ? --BenH.
diff -purN linux-2.6.5/include/asm-ppc64/iommu.h linux-2.6.5.ppc64_linus/include/asm-ppc64/iommu.h
--- linux-2.6.5/include/asm-ppc64/iommu.h	2004-04-04 03:37:37.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/iommu.h	2004-04-29 11:17:16.000000000 +0000
@@ -19,12 +19,13 @@
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
 
-#ifndef _PCI_DMA_H
-#define _PCI_DMA_H
+#ifndef _ASM_IOMMU_H
+#define _ASM_IOMMU_H
 
 #include <asm/types.h>
 #include <linux/spinlock.h>
 #include <linux/device.h>
+#include <linux/dma-mapping.h>
 
 /*
  * IOMAP_MAX_ORDER defines the largest contiguous block
@@ -130,19 +131,20 @@ extern void iommu_devnode_init(struct iS
  */
 extern struct iommu_table *iommu_init_table(struct iommu_table * tbl);
 
-/* allocates a range of tces and sets them to the pages  */
-extern dma_addr_t iommu_alloc(struct iommu_table *, void *page, 
-			      unsigned int numPages, int direction);
-extern void iommu_free(struct iommu_table *tbl, dma_addr_t dma_addr, 
-		       unsigned int npages);
-
-/* same with sg lists */
-extern int iommu_alloc_sg(struct iommu_table *table, struct device *dev,
-			  struct scatterlist *sglist, int nelems,
-			  int direction);
-extern void iommu_free_sg(struct iommu_table *tbl, struct scatterlist *sglist,
-			  int nelems);
-
+extern int iommu_map_sg(struct device *dev, struct iommu_table *tbl,
+		struct scatterlist *sglist, int nelems,
+		enum dma_data_direction direction);
+extern void iommu_unmap_sg(struct iommu_table *tbl, struct scatterlist *sglist,
+		int nelems, enum dma_data_direction direction);
+
+extern void *iommu_alloc_consistent(struct iommu_table *tbl, size_t size,
+		dma_addr_t *dma_handle);
+extern void iommu_free_consistent(struct iommu_table *tbl, size_t size,
+		void *vaddr, dma_addr_t dma_handle);
+extern dma_addr_t iommu_map_single(struct iommu_table *tbl, void *vaddr,
+		size_t size, enum dma_data_direction direction);
+extern void iommu_unmap_single(struct iommu_table *tbl, dma_addr_t dma_handle,
+		size_t size, enum dma_data_direction direction);
 
 extern void tce_init_pSeries(void);
 extern void tce_init_iSeries(void);
@@ -152,4 +154,4 @@ extern void pci_dma_init_direct(void);
 
 extern int ppc64_iommu_off;
 
-#endif
+#endif /* _ASM_IOMMU_H */
diff -purN linux-2.6.5/include/asm-ppc64/irq.h linux-2.6.5.ppc64_linus/include/asm-ppc64/irq.h
--- linux-2.6.5/include/asm-ppc64/irq.h	2004-04-04 03:38:24.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/irq.h	2004-04-29 11:17:16.000000000 +0000
@@ -11,6 +11,11 @@
 
 #include <asm/atomic.h>
 
+/*
+ * Maximum number of interrupt sources that we can handle.
+ */
+#define NR_IRQS		512
+
 extern void disable_irq(unsigned int);
 extern void disable_irq_nosync(unsigned int);
 extern void enable_irq(unsigned int);
@@ -18,12 +23,11 @@ extern void enable_irq(unsigned int);
 /* this number is used when no interrupt has been assigned */
 #define NO_IRQ			(-1)
 
-/*
- * this is the maximum number of virtual irqs we will use.
- */
-#define NR_IRQS			512
+#define get_irq_desc(irq) (&irq_desc[(irq)])
 
-#define NUM_8259_INTERRUPTS	16
+/* Define a way to iterate across irqs. */
+#define for_each_irq(i) \
+	for ((i) = 0; (i) < NR_IRQS; ++(i))
 
 /* Interrupt numbers are virtual in case they are sparsely
  * distributed by the hardware.
@@ -41,12 +45,39 @@ static inline unsigned int virt_irq_to_r
 	return virt_irq_to_real_map[virt_irq];
 }
 
+/*
+ * Because many systems have two overlapping names spaces for
+ * interrupts (ISA and XICS for example), and the ISA interrupts
+ * have historically not been easy to renumber, we allow ISA
+ * interrupts to take values 0 - 15, and shift up the remaining
+ * interrupts by 0x10.
+ */
+#define NUM_ISA_INTERRUPTS	0x10
+extern int __irq_offset_value;
+
+static inline int irq_offset_up(int irq)
+{
+	return(irq + __irq_offset_value);
+}
+
+static inline int irq_offset_down(int irq)
+{
+	return(irq - __irq_offset_value);
+}
+
+static inline int irq_offset_value(void)
+{
+	return __irq_offset_value;
+}
+
 static __inline__ int irq_canonicalize(int irq)
 {
 	return irq;
 }
 
-#define NR_MASK_WORDS	((NR_IRQS + 63) / 64)
+/* struct irqaction;
+struct pt_regs;
+int handle_IRQ_event(unsigned int, struct pt_regs *, struct irqaction *); */
 
 #endif /* _ASM_IRQ_H */
 #endif /* __KERNEL__ */
diff -purN linux-2.6.5/include/asm-ppc64/machdep.h linux-2.6.5.ppc64_linus/include/asm-ppc64/machdep.h
--- linux-2.6.5/include/asm-ppc64/machdep.h	2004-04-04 03:36:55.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/machdep.h	2004-04-29 11:17:16.000000000 +0000
@@ -11,6 +11,7 @@
 
 #include <linux/config.h>
 #include <linux/seq_file.h>
+#include <linux/dma-mapping.h>
 
 struct pt_regs;
 struct pci_bus;	
@@ -57,7 +58,7 @@ struct machdep_calls {
 				     long index,
 				     long npages,
 				     unsigned long uaddr,
-				     int direction);
+				     enum dma_data_direction direction);
 	void		(*tce_free)(struct iommu_table *tbl,
 				    long index,
 				    long npages);
@@ -79,6 +80,7 @@ struct machdep_calls {
 	void		(*restart)(char *cmd);
 	void		(*power_off)(void);
 	void		(*halt)(void);
+	void		(*panic)(char *str);
 
 	int		(*set_rtc_time)(struct rtc_time *);
 	void		(*get_rtc_time)(struct rtc_time *);
diff -purN linux-2.6.5/include/asm-ppc64/mmzone.h linux-2.6.5.ppc64_linus/include/asm-ppc64/mmzone.h
--- linux-2.6.5/include/asm-ppc64/mmzone.h	2004-04-04 03:38:18.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/mmzone.h	2004-04-29 11:17:16.000000000 +0000
@@ -19,13 +19,13 @@ extern struct pglist_data node_data[];
  */
 
 extern int numa_cpu_lookup_table[];
-extern int numa_memory_lookup_table[];
+extern char *numa_memory_lookup_table;
 extern cpumask_t numa_cpumask_lookup_table[];
 extern int nr_cpus_in_node[];
 
 #define MAX_MEMORY (1UL << 41)
-/* 256MB regions */
-#define MEMORY_INCREMENT_SHIFT 28
+/* 16MB regions */
+#define MEMORY_INCREMENT_SHIFT 24
 #define MEMORY_INCREMENT (1UL << MEMORY_INCREMENT_SHIFT)
 
 /* NUMA debugging, will not work on a DLPAR machine */
diff -purN linux-2.6.5/include/asm-ppc64/naca.h linux-2.6.5.ppc64_linus/include/asm-ppc64/naca.h
--- linux-2.6.5/include/asm-ppc64/naca.h	2004-04-04 03:37:06.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/naca.h	2004-04-29 11:17:16.000000000 +0000
@@ -37,12 +37,10 @@ struct naca_struct {
 	u32 dCacheL1LinesPerPage;	/* L1 d-cache lines / page   0x64 */
 	u32 iCacheL1LogLineSize;	/* L1 i-cache line size Log2 0x68 */
 	u32 iCacheL1LinesPerPage;	/* L1 i-cache lines / page   0x6c */
-	u64 smt_snooze_delay;           /* Delay (in usec) before    0x70 */
-                                        /* entering ST mode               */
-	u8  smt_state;                  /* 0 = SMT off               0x78 */
+	u8  smt_state;                  /* 0 = SMT off               0x70 */
 	                                /* 1 = SMT on                     */
 	                                /* 2 = SMT dynamic                */
-	u8  resv0[7];                   /* Reserved           0x70 - 0x7F */
+	u8  resv0[15];                  /* Reserved           0x71 - 0x7F */
 };
 
 extern struct naca_struct *naca;
diff -purN linux-2.6.5/include/asm-ppc64/paca.h linux-2.6.5.ppc64_linus/include/asm-ppc64/paca.h
--- linux-2.6.5/include/asm-ppc64/paca.h	2004-04-04 03:36:57.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/paca.h	2004-04-29 11:17:16.000000000 +0000
@@ -64,13 +64,13 @@ struct paca_struct {
         u16 xHwProcNum;                 /* Physical processor number            0x1A */
 	u32 default_decr;		/* Default decrementer value		0x1c */	
 	u64 xKsave;			/* Saved Kernel stack addr or zero	0x20 */
-	struct ItLpQueue *lpQueuePtr;	/* LpQueue handled by this processor    0x30 */
-	u64  xTOC;			/* Kernel TOC address			0x38 */
-	STAB xStab_data;		/* Segment table information		0x40,0x48,0x50 */
-	u8 *exception_sp;		/*                                      0x58 */
-	u8 xProcEnabled;		/*                                      0x59 */
-	u8 prof_enabled;		/* 1=iSeries profiling enabled          0x60 */
-	u8 resv1[38];			/*					0x61-0x7F */
+	struct ItLpQueue *lpQueuePtr;	/* LpQueue handled by this processor    0x28 */
+	u64  xTOC;			/* Kernel TOC address			0x30 */
+	STAB xStab_data;		/* Segment table information		0x38,0x40,0x48 */
+	u8 *exception_sp;		/*                                      0x50 */
+	u8 xProcEnabled;		/*                                      0x58 */
+	u8 prof_enabled;		/* 1=iSeries profiling enabled          0x59 */
+	u8 resv1[38];			/*					0x5a-0x7f*/
 
 /*=====================================================================================
  * CACHE_LINE_2 0x0080 - 0x00FF
diff -purN linux-2.6.5/include/asm-ppc64/page.h linux-2.6.5.ppc64_linus/include/asm-ppc64/page.h
--- linux-2.6.5/include/asm-ppc64/page.h	2004-04-04 03:36:14.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/page.h	2004-04-29 11:17:16.000000000 +0000
@@ -22,6 +22,10 @@
 #define PAGE_MASK	(~(PAGE_SIZE-1))
 #define PAGE_OFFSET_MASK (PAGE_SIZE-1)
 
+#define SID_SHIFT       28
+#define SID_MASK        0xfffffffff
+#define GET_ESID(x)     (((x) >> SID_SHIFT) & SID_MASK)
+
 #ifdef CONFIG_HUGETLB_PAGE
 
 #define HPAGE_SHIFT	24
@@ -33,30 +37,36 @@
 #define TASK_HPAGE_BASE 	(0x0000010000000000UL)
 #define TASK_HPAGE_END 	(0x0000018000000000UL)
 
-/* For 32-bit processes the hugepage range is 2-3G */
-#define TASK_HPAGE_BASE_32	(0x80000000UL)
-#define TASK_HPAGE_END_32	(0xc0000000UL)
+#define LOW_ESID_MASK(addr, len)	(((1U << (GET_ESID(addr+len-1)+1)) \
+	   	                	- (1U << GET_ESID(addr))) & 0xffff)
 
 #define ARCH_HAS_HUGEPAGE_ONLY_RANGE
 #define ARCH_HAS_PREPARE_HUGEPAGE_RANGE
 
-#define is_hugepage_low_range(addr, len) \
-	(((addr) > (TASK_HPAGE_BASE_32-(len))) && ((addr) < TASK_HPAGE_END_32))
-#define is_hugepage_high_range(addr, len) \
+#define touches_hugepage_low_range(addr, len) \
+	(LOW_ESID_MASK((addr), (len)) & current->mm->context.htlb_segs)
+#define touches_hugepage_high_range(addr, len) \
 	(((addr) > (TASK_HPAGE_BASE-(len))) && ((addr) < TASK_HPAGE_END))
 
+#define __within_hugepage_low_range(addr, len, segmask) \
+	((LOW_ESID_MASK((addr), (len)) | (segmask)) == (segmask))
+#define within_hugepage_low_range(addr, len) \
+	__within_hugepage_low_range((addr), (len), \
+				    current->mm->context.htlb_segs)
+#define within_hugepage_high_range(addr, len) (((addr) >= TASK_HPAGE_BASE) \
+	  && ((addr)+(len) <= TASK_HPAGE_END) && ((addr)+(len) >= (addr)))
+
 #define is_hugepage_only_range(addr, len) \
-	(is_hugepage_high_range((addr), (len)) || \
-	 (current->mm->context.low_hpages \
-	  && is_hugepage_low_range((addr), (len))))
+	(touches_hugepage_high_range((addr), (len)) || \
+	  touches_hugepage_low_range((addr), (len)))
 #define hugetlb_free_pgtables free_pgtables
 #define HAVE_ARCH_HUGETLB_UNMAPPED_AREA
 
 #define in_hugepage_area(context, addr) \
 	((cur_cpu_spec->cpu_features & CPU_FTR_16M_PAGE) && \
-	 ((((addr) >= TASK_HPAGE_BASE) && ((addr) < TASK_HPAGE_END)) || \
-	  ((context).low_hpages && \
-	   (((addr) >= TASK_HPAGE_BASE_32) && ((addr) < TASK_HPAGE_END_32)))))
+	 ( (((addr) >= TASK_HPAGE_BASE) && ((addr) < TASK_HPAGE_END)) || \
+	   ( ((addr) < 0x100000000L) && \
+	     ((1 << GET_ESID(addr)) & (context).htlb_segs) ) ) )
 
 #else /* !CONFIG_HUGETLB_PAGE */
 
@@ -64,10 +74,6 @@
 
 #endif /* !CONFIG_HUGETLB_PAGE */
 
-#define SID_SHIFT       28
-#define SID_MASK        0xfffffffff
-#define GET_ESID(x)     (((x) >> SID_SHIFT) & SID_MASK)
-
 /* align addr on a size boundary - adjust address up/down if needed */
 #define _ALIGN_UP(addr,size)	(((addr)+((size)-1))&(~((size)-1)))
 #define _ALIGN_DOWN(addr,size)	((addr)&(~((size)-1)))
diff -purN linux-2.6.5/include/asm-ppc64/pci-bridge.h linux-2.6.5.ppc64_linus/include/asm-ppc64/pci-bridge.h
--- linux-2.6.5/include/asm-ppc64/pci-bridge.h	2004-04-04 03:36:17.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/pci-bridge.h	2004-04-29 11:17:16.000000000 +0000
@@ -2,6 +2,8 @@
 #ifndef _ASM_PCI_BRIDGE_H
 #define _ASM_PCI_BRIDGE_H
 
+#include <linux/pci.h>
+
 /*
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
diff -purN linux-2.6.5/include/asm-ppc64/pci.h linux-2.6.5.ppc64_linus/include/asm-ppc64/pci.h
--- linux-2.6.5/include/asm-ppc64/pci.h	2004-04-04 03:36:56.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/pci.h	2004-04-29 11:17:16.000000000 +0000
@@ -64,13 +64,13 @@ struct pci_dma_ops {
 				       void *vaddr, dma_addr_t dma_handle);
 
 	dma_addr_t	(*pci_map_single)(struct pci_dev *hwdev, void *ptr,
-					  size_t size, int direction);
+					  size_t size, enum dma_data_direction direction);
 	void		(*pci_unmap_single)(struct pci_dev *hwdev, dma_addr_t dma_addr,
-					    size_t size, int direction);
+					    size_t size, enum dma_data_direction direction);
 	int		(*pci_map_sg)(struct pci_dev *hwdev, struct scatterlist *sg,
-				      int nents, int direction);
+				      int nents, enum dma_data_direction direction);
 	void		(*pci_unmap_sg)(struct pci_dev *hwdev, struct scatterlist *sg,
-					int nents, int direction);
+					int nents, enum dma_data_direction direction);
 	int		(*pci_dma_supported)(struct pci_dev *hwdev, u64 mask);
 	int		(*pci_dac_dma_supported)(struct pci_dev *hwdev, u64 mask);
 };
@@ -92,25 +92,29 @@ static inline void pci_free_consistent(s
 static inline dma_addr_t pci_map_single(struct pci_dev *hwdev, void *ptr,
 					size_t size, int direction)
 {
-	return pci_dma_ops.pci_map_single(hwdev, ptr, size, direction); 
+	return pci_dma_ops.pci_map_single(hwdev, ptr, size,
+			(enum dma_data_direction)direction);
 }
 
 static inline void pci_unmap_single(struct pci_dev *hwdev, dma_addr_t dma_addr,
 				    size_t size, int direction)
 {
-	pci_dma_ops.pci_unmap_single(hwdev, dma_addr, size, direction);
+	pci_dma_ops.pci_unmap_single(hwdev, dma_addr, size,
+			(enum dma_data_direction)direction);
 }
 
 static inline int pci_map_sg(struct pci_dev *hwdev, struct scatterlist *sg,
 			     int nents, int direction)
 {
-	return pci_dma_ops.pci_map_sg(hwdev, sg, nents, direction);
+	return pci_dma_ops.pci_map_sg(hwdev, sg, nents,
+			(enum dma_data_direction)direction);
 }
 
 static inline void pci_unmap_sg(struct pci_dev *hwdev, struct scatterlist *sg,
 				int nents, int direction)
 {
-	pci_dma_ops.pci_unmap_sg(hwdev, sg, nents, direction);
+	pci_dma_ops.pci_unmap_sg(hwdev, sg, nents,
+			(enum dma_data_direction)direction);
 }
 
 static inline void pci_dma_sync_single_for_cpu(struct pci_dev *hwdev,
diff -purN linux-2.6.5/include/asm-ppc64/pgtable.h linux-2.6.5.ppc64_linus/include/asm-ppc64/pgtable.h
--- linux-2.6.5/include/asm-ppc64/pgtable.h	2004-04-04 03:38:18.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/pgtable.h	2004-04-29 11:17:16.000000000 +0000
@@ -313,7 +313,9 @@ static inline int ptep_test_and_clear_yo
 {
 	unsigned long old;
 
-	old = pte_update(ptep, _PAGE_ACCESSED | _PAGE_HPTEFLAGS);
+       	if ((pte_val(*ptep) & (_PAGE_ACCESSED | _PAGE_HASHPTE)) == 0)
+		return 0;
+	old = pte_update(ptep, _PAGE_ACCESSED);
 	if (old & _PAGE_HASHPTE) {
 		hpte_update(ptep, old, 0);
 		flush_tlb_pending();	/* XXX generic code doesn't flush */
@@ -326,12 +328,13 @@ static inline int ptep_test_and_clear_yo
  * moment we always flush but we need to fix hpte_update and test if the
  * optimisation is worth it.
  */
-#if 1
 static inline int ptep_test_and_clear_dirty(pte_t *ptep)
 {
 	unsigned long old;
 
-	old = pte_update(ptep, _PAGE_DIRTY | _PAGE_HPTEFLAGS);
+       	if ((pte_val(*ptep) & _PAGE_DIRTY) == 0)
+		return 0;
+	old = pte_update(ptep, _PAGE_DIRTY);
 	if (old & _PAGE_HASHPTE)
 		hpte_update(ptep, old, 0);
 	return (old & _PAGE_DIRTY) != 0;
@@ -341,7 +344,9 @@ static inline void ptep_set_wrprotect(pt
 {
 	unsigned long old;
 
-	old = pte_update(ptep, _PAGE_RW | _PAGE_HPTEFLAGS);
+       	if ((pte_val(*ptep) & _PAGE_RW) == 0)
+       		return;
+	old = pte_update(ptep, _PAGE_RW);
 	if (old & _PAGE_HASHPTE)
 		hpte_update(ptep, old, 0);
 }
@@ -358,7 +363,6 @@ static inline void ptep_set_wrprotect(pt
 #define ptep_clear_flush_young(__vma, __address, __ptep)		\
 ({									\
 	int __young = ptep_test_and_clear_young(__ptep);		\
-	flush_tlb_page(__vma, __address);				\
 	__young;							\
 })
 
@@ -370,27 +374,6 @@ static inline void ptep_set_wrprotect(pt
 	__dirty;							\
 })
 
-#else
-static inline int ptep_test_and_clear_dirty(pte_t *ptep)
-{
-	unsigned long old;
-
-	old = pte_update(ptep, _PAGE_DIRTY);
-	if ((~old & (_PAGE_HASHPTE | _PAGE_RW | _PAGE_DIRTY)) == 0)
-		hpte_update(ptep, old, 1);
-	return (old & _PAGE_DIRTY) != 0;
-}
-
-static inline void ptep_set_wrprotect(pte_t *ptep)
-{
-	unsigned long old;
-
-	old = pte_update(ptep, _PAGE_RW);
-	if ((~old & (_PAGE_HASHPTE | _PAGE_RW | _PAGE_DIRTY)) == 0)
-		hpte_update(ptep, old, 1);
-}
-#endif
-
 static inline pte_t ptep_get_and_clear(pte_t *ptep)
 {
 	unsigned long old = pte_update(ptep, ~0UL);
diff -purN linux-2.6.5/include/asm-ppc64/processor.h linux-2.6.5.ppc64_linus/include/asm-ppc64/processor.h
--- linux-2.6.5/include/asm-ppc64/processor.h	2004-04-04 03:36:17.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/processor.h	2004-04-29 11:17:16.000000000 +0000
@@ -235,8 +235,6 @@
 #define	SPRN_IMMR	0x27E  	/* Internal Memory Map Register */
 #define	SPRN_L2CR	0x3F9	/* Level 2 Cache Control Regsiter */
 #define	SPRN_LR		0x008	/* Link Register */
-#define	SPRN_MMCR0	0x3B8	/* Monitor Mode Control Register 0 */
-#define	SPRN_MMCR1	0x3BC	/* Monitor Mode Control Register 1 */
 #define	SPRN_PBL1	0x3FC	/* Protection Bound Lower 1 */
 #define	SPRN_PBL2	0x3FE	/* Protection Bound Lower 2 */
 #define	SPRN_PBU1	0x3FD	/* Protection Bound Upper 1 */
@@ -244,10 +242,7 @@
 #define	SPRN_PID	0x3B1	/* Process ID */
 #define	SPRN_PIR	0x3FF	/* Processor Identification Register */
 #define	SPRN_PIT	0x3DB	/* Programmable Interval Timer */
-#define	SPRN_PMC1	0x3B9	/* Performance Counter Register 1 */
-#define	SPRN_PMC2	0x3BA	/* Performance Counter Register 2 */
-#define	SPRN_PMC3	0x3BD	/* Performance Counter Register 3 */
-#define	SPRN_PMC4	0x3BE	/* Performance Counter Register 4 */
+#define	SPRN_PURR	0x135	/* Processor Utilization of Resources Register */
 #define	SPRN_PVR	0x11F	/* Processor Version Register */
 #define	SPRN_RPA	0x3D6	/* Required Physical Address Register */
 #define	SPRN_SDA	0x3BF	/* Sampled Data Address Register */
@@ -307,17 +302,26 @@
 #define	    WRS_SYSTEM		3		/* WDT forced system reset */
 #define	  TSR_PIS		0x08000000	/* PIT Interrupt Status */
 #define	  TSR_FIS		0x04000000	/* FIT Interrupt Status */
-#define	SPRN_UMMCR0	0x3A8	/* User Monitor Mode Control Register 0 */
-#define	SPRN_UMMCR1	0x3AC	/* User Monitor Mode Control Register 0 */
-#define	SPRN_UPMC1	0x3A9	/* User Performance Counter Register 1 */
-#define	SPRN_UPMC2	0x3AA	/* User Performance Counter Register 2 */
-#define	SPRN_UPMC3	0x3AD	/* User Performance Counter Register 3 */
-#define	SPRN_UPMC4	0x3AE	/* User Performance Counter Register 4 */
 #define	SPRN_USIA	0x3AB	/* User Sampled Instruction Address Register */
 #define	SPRN_XER	0x001	/* Fixed Point Exception Register */
 #define	SPRN_ZPR	0x3B0	/* Zone Protection Register */
 #define SPRN_VRSAVE     0x100   /* Vector save */
 
+/* Performance monitor SPRs */
+#define SPRN_SIAR	780
+#define SPRN_SDAR	781
+#define SPRN_MMCRA	786
+#define SPRN_PMC1	787
+#define SPRN_PMC2	788
+#define SPRN_PMC3	789
+#define SPRN_PMC4	790
+#define SPRN_PMC5	791
+#define SPRN_PMC6	792
+#define SPRN_PMC7	793
+#define SPRN_PMC8	794
+#define SPRN_MMCR0	795
+#define SPRN_MMCR1	798
+
 /* Short-hand versions for a number of the above SPRNs */
 
 #define	CTR	SPRN_CTR	/* Counter Register */
@@ -343,6 +347,7 @@
 #define	__LR	SPRN_LR
 #define	PVR	SPRN_PVR	/* Processor Version */
 #define	PIR	SPRN_PIR	/* Processor ID */
+#define	PURR	SPRN_PURR	/* Processor Utilization of Resource Register */
 #define	RPA	SPRN_RPA	/* Required Physical Address Register */
 #define	SDR1	SPRN_SDR1      	/* MMU hash base register */
 #define	SPR0	SPRN_SPRG0	/* Supervisor Private Registers */
@@ -548,6 +553,8 @@ struct thread_struct {
 #endif /* CONFIG_ALTIVEC */
 };
 
+#define ARCH_MIN_TASKALIGN 16
+
 #define INIT_SP		(sizeof(init_stack) + (unsigned long) &init_stack)
 
 #define INIT_THREAD  { \
diff -purN linux-2.6.5/include/asm-ppc64/rtas.h linux-2.6.5.ppc64_linus/include/asm-ppc64/rtas.h
--- linux-2.6.5/include/asm-ppc64/rtas.h	2004-04-04 03:38:22.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/rtas.h	2004-04-29 11:17:16.000000000 +0000
@@ -169,12 +169,11 @@ extern struct rtas_t rtas;
 extern void enter_rtas(struct rtas_args *);
 extern int rtas_token(const char *service);
 extern long rtas_call(int token, int, int, unsigned long *, ...);
-extern void phys_call_rtas(int, int, int, ...);
-extern void phys_call_rtas_display_status(char);
 extern void call_rtas_display_status(char);
 extern void rtas_restart(char *cmd);
 extern void rtas_power_off(void);
 extern void rtas_halt(void);
+extern void rtas_os_term(char *str);
 extern int rtas_get_sensor(int sensor, int index, int *state);
 extern int rtas_get_power_level(int powerdomain, int *level);
 extern int rtas_set_power_level(int powerdomain, int level, int *setlevel);
@@ -198,7 +197,7 @@ extern void pSeries_log_error(char *buf,
 /* All the types and not flags */
 #define ERR_TYPE_MASK	(ERR_TYPE_RTAS_LOG | ERR_TYPE_KERNEL_PANIC)
 
-#define RTAS_ERR KERN_ERR "RTAS: "
+#define RTAS_DEBUG KERN_DEBUG "RTAS: "
  
 #define RTAS_ERROR_LOG_MAX 2048
  
@@ -219,6 +218,8 @@ extern void pSeries_log_error(char *buf,
 extern spinlock_t rtas_data_buf_lock;
 extern char rtas_data_buf[RTAS_DATA_BUF_SIZE];
 
+extern void rtas_stop_self(void);
+
 /* RMO buffer reserved for user-space RTAS use */
 extern unsigned long rtas_rmo_buf;
 
diff -purN linux-2.6.5/include/asm-ppc64/smp.h linux-2.6.5.ppc64_linus/include/asm-ppc64/smp.h
--- linux-2.6.5/include/asm-ppc64/smp.h	2004-04-04 03:36:11.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/smp.h	2004-04-29 11:17:16.000000000 +0000
@@ -67,9 +67,14 @@ extern cpumask_t cpu_available_map;
 #endif
 #define PPC_MSG_DEBUGGER_BREAK  3
 
+extern cpumask_t irq_affinity[];
+
 void smp_init_iSeries(void);
 void smp_init_pSeries(void);
 
+extern int __cpu_disable(void);
+extern void __cpu_die(unsigned int cpu);
+extern void cpu_die(void) __attribute__((noreturn));
 #endif /* !(CONFIG_SMP) */
 
 #define get_hard_smp_processor_id(CPU) (paca[(CPU)].xHwProcNum)
diff -purN linux-2.6.5/include/asm-ppc64/system.h linux-2.6.5.ppc64_linus/include/asm-ppc64/system.h
--- linux-2.6.5/include/asm-ppc64/system.h	2004-04-04 03:38:24.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/system.h	2004-04-29 11:17:16.000000000 +0000
@@ -94,7 +94,12 @@ static inline int debugger_dabr_match(st
 static inline int debugger_fault_handler(struct pt_regs *regs) { return 0; }
 #endif
 
+extern int fix_alignment(struct pt_regs *regs);
+extern void bad_page_fault(struct pt_regs *regs, unsigned long address,
+			   int sig);
 extern void show_regs(struct pt_regs * regs);
+extern int die(const char *str, struct pt_regs *regs, long err);
+
 extern void flush_instruction_cache(void);
 extern int _get_PVR(void);
 extern void giveup_fpu(struct task_struct *);
diff -purN linux-2.6.5/include/asm-ppc64/unistd.h linux-2.6.5.ppc64_linus/include/asm-ppc64/unistd.h
--- linux-2.6.5/include/asm-ppc64/unistd.h	2004-04-04 03:36:14.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/unistd.h	2004-04-29 11:17:16.000000000 +0000
@@ -266,8 +266,20 @@
 #define __NR_fstatfs64		253
 #define __NR_fadvise64_64	254
 #define __NR_rtas		255
+/* Number 256 is reserved for sys_debug_setcontext */
+/* Number 257 is reserved for vserver */
+/* Number 258 is reserved for new sys_remap_file_pages */
+/* Number 259 is reserved for new sys_mbind */
+/* Number 260 is reserved for new sys_get_mempolicy */
+/* Number 261 is reserved for new sys_set_mempolicy */
+#define __NR_mq_open		262
+#define __NR_mq_unlink		263
+#define __NR_mq_timedsend	264
+#define __NR_mq_timedreceive	265
+#define __NR_mq_notify		266
+#define __NR_mq_getsetattr	267
 
-#define __NR_syscalls		256
+#define __NR_syscalls		268
 #ifdef __KERNEL__
 #define NR_syscalls	__NR_syscalls
 #endif
diff -purN linux-2.6.5/include/asm-ppc64/vio.h linux-2.6.5.ppc64_linus/include/asm-ppc64/vio.h
--- linux-2.6.5/include/asm-ppc64/vio.h	2004-04-04 03:37:36.000000000 +0000
+++ linux-2.6.5.ppc64_linus/include/asm-ppc64/vio.h	2004-04-29 11:17:16.000000000 +0000
@@ -17,7 +17,6 @@
 #include <linux/init.h>
 #include <linux/errno.h>
 #include <linux/device.h>
-#include <linux/pci.h>
 #include <linux/dma-mapping.h>
 #include <asm/hvcall.h>
 #include <asm/prom.h>
@@ -58,13 +57,13 @@ int vio_enable_interrupts(struct vio_dev
 int vio_disable_interrupts(struct vio_dev *dev);
 
 dma_addr_t vio_map_single(struct vio_dev *dev, void *vaddr, 
-			  size_t size, int direction);
+			  size_t size, enum dma_data_direction direction);
 void vio_unmap_single(struct vio_dev *dev, dma_addr_t dma_handle, 
-		      size_t size, int direction);
+		      size_t size, enum dma_data_direction direction);
 int vio_map_sg(struct vio_dev *vdev, struct scatterlist *sglist, 
-	       int nelems, int direction);
+	       int nelems, enum dma_data_direction direction);
 void vio_unmap_sg(struct vio_dev *vdev, struct scatterlist *sglist, 
-		  int nelems, int direction);
+		  int nelems, enum dma_data_direction direction);
 void *vio_alloc_consistent(struct vio_dev *dev, size_t size, 
 			   dma_addr_t *dma_handle);
 void vio_free_consistent(struct vio_dev *dev, size_t size, void *vaddr, 
@@ -79,23 +78,10 @@ static inline int vio_dma_supported(stru
 		vio_map_single(dev, (page_address(page) + (off)), size, dir)
 #define vio_unmap_page(dev,addr,sz,dir) vio_unmap_single(dev,addr,sz,dir)
 
-
-static inline void vio_dma_sync_single(struct vio_dev *hwdev,
-				       dma_addr_t dma_handle,
-				       size_t size, int direction)
-{
-	BUG_ON(direction == PCI_DMA_NONE);
-	/* nothing to do */
-}
-
-static inline void vio_dma_sync_sg(struct vio_dev *hwdev,
-				   struct scatterlist *sg,
-				   int nelems, int direction)
+static inline int vio_set_dma_mask(struct vio_dev *dev, u64 mask)
 {
-	BUG_ON(direction == PCI_DMA_NONE);
-	/* nothing to do */
+	return -EIO;
 }
-static inline int vio_set_dma_mask(struct vio_dev *dev, u64 mask) { return -EIO; }
 
 extern struct bus_type vio_bus_type;
 
@@ -138,9 +124,4 @@ static inline struct vio_dev *to_vio_dev
 	return container_of(dev, struct vio_dev, dev);
 }
 
-static inline int vio_dma_mapping_error(dma_addr_t dma_addr)
-{
-	return dma_mapping_error(dma_addr);
-}
-
 #endif /* _ASM_VIO_H */
