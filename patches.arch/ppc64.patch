diff -purN linux-2.5/arch/ppc64/Kconfig linuxppc64-2.5/arch/ppc64/Kconfig
--- linux-2.5/arch/ppc64/Kconfig	2004-03-18 02:43:04.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/Kconfig	2004-03-20 10:56:41.000000000 +0000
@@ -89,6 +89,16 @@ config PPC_PMAC
 	bool "Apple PowerMac G5 support"
 	select ADB_PMU
 
+config PPC_SPLPAR
+	depends on PPC_PSERIES
+	bool "Support for shared-processor logical partitions"
+	default n
+	help
+	  Enabling this option will make the kernel run more efficiently
+	  on logically-partitioned pSeries systems which use shared
+	  processors, that is, which share physical processors between
+	  two or more partitions.
+
 config PMAC_DART
 	bool "Enable DART/IOMMU on PowerMac (allow >2G of RAM)"
 	depends on PPC_PMAC
@@ -203,11 +213,27 @@ config SCANLOG
 	depends on PPC_RTAS
 
 config LPARCFG
-	bool "LPAR Configuration Data"
+	tristate "LPAR Configuration Data"
 	help
 	Provide system capacity information via human readable 
 	<key word>=<value> pairs through a /proc/ppc64/lparcfg interface.
 
+config VIOCFG
+	tristate "Virtual I/O Configuration Data"
+	depends on PPC_PSERIES && SCSI_IBMVSCSI
+	help
+	Provide configuration information from a virtual I/O host.
+	Data is in the form
+	<key word>=<value> pairs in /proc/vioconfig.
+
+config PPC_VPURR
+	bool "Virtual Processor Utilization Values"
+	default n
+	depends on PPC_PSERIES
+	help
+	Provide framework to collect virtual processor utilization
+	periodically. If unsure say NO.
+
 endmenu
 
 
@@ -248,6 +274,14 @@ source "fs/Kconfig.binfmt"
 
 source "drivers/pci/Kconfig"
 
+config HOTPLUG_CPU
+	bool "Support for hot-pluggable CPUs (EXPERIMENTAL)"
+	depends on SMP && HOTPLUG && EXPERIMENTAL
+	---help---
+	  Say Y here to experiment with turning CPUs off and on.
+
+	  Say N if you are unsure.
+
 source "drivers/pcmcia/Kconfig"
 
 source "drivers/pci/hotplug/Kconfig"
@@ -363,17 +397,46 @@ config DEBUGGER
 	  Include in-kernel hooks for kernel debuggers. Unless you are
 	  intending to debug the kernel, say N here.
 
-config XMON
-	bool "Include xmon kernel debugger"
+choice
+	optional
 	depends on DEBUGGER
+	prompt "Kernel Debugger"
+
+config XMON
+	bool "XMON"
 	help
 	  Include in-kernel hooks for the xmon kernel monitor/debugger.
 	  Unless you are intending to debug the kernel, say N here.
 
+config KDB
+	bool "KDB"
+	help
+	  Include in-kernel hooks for the kdb kernel monitor/debugger.
+	  Unless you are intending to debug the kernel, say N here.
+
+config KDB_MODULES
+	bool "Enable additional KDB modules"
+	depends on KDB
+	help
+	  Include additional KDB support for viewing buffer heads,
+	  pages, inodes, dentrys, vm areas and scsi devices and
+	  scsi commands.
+
+endchoice
+
+
 config XMON_DEFAULT
 	bool "Enable xmon by default"
 	depends on XMON
 
+config KDB_OFF
+	bool "Turn KDB off as default."
+	depends on KDB
+
+	help
+ 	   KDB will remain built into the kernel, but will be turned off. 
+	   "cat 1 > /proc/sys/kernel/kdb" to turn it on. 
+
 config PPCDBG
 	bool "Include PPCDBG realtime debugging"
 	depends on DEBUG_KERNEL
@@ -386,6 +449,13 @@ config DEBUG_INFO
 	  debugging info resulting in a larger kernel image.
 	  Say Y here only if you plan to use gdb to debug the kernel.
 	  If you don't debug the kernel, you can say N.
+
+config DEBUG_SPINLOCK_SLEEP
+	bool "Sleep-inside-spinlock checking"
+	depends on DEBUG_KERNEL
+	help
+	  If you say Y here, various routines which may sleep will become very
+	  noisy if they are called with a spinlock held.
 	  
 endmenu
 
diff -purN linux-2.5/arch/ppc64/Makefile linuxppc64-2.5/arch/ppc64/Makefile
--- linux-2.5/arch/ppc64/Makefile	2004-03-16 11:30:37.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/Makefile	2004-03-17 00:46:40.000000000 +0000
@@ -43,6 +43,11 @@ libs-y				+= arch/ppc64/lib/
 core-y				+= arch/ppc64/kernel/
 core-y				+= arch/ppc64/mm/
 core-$(CONFIG_XMON)		+= arch/ppc64/xmon/
+ifeq ($(CONFIG_KDB),y)
+  # Use ifeq for now because kdb subdirs are not in bk yet
+  # Otherwise make mrproper will die because it also cleans core-n
+  core-y			+= arch/ppc64/kdb/
+endif
 drivers-$(CONFIG_OPROFILE)	+= arch/ppc64/oprofile/
 
 boot := arch/ppc64/boot
diff -purN linux-2.5/arch/ppc64/configs/iSeries_defconfig linuxppc64-2.5/arch/ppc64/configs/iSeries_defconfig
--- linux-2.5/arch/ppc64/configs/iSeries_defconfig	2004-03-16 11:30:38.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/configs/iSeries_defconfig	2004-03-18 23:01:08.000000000 +0000
@@ -90,7 +90,7 @@ CONFIG_PCI_NAMES=y
 #
 # Generic Driver Options
 #
-CONFIG_FW_LOADER=m
+CONFIG_FW_LOADER=y
 # CONFIG_DEBUG_DRIVER is not set
 
 #
@@ -178,8 +178,12 @@ CONFIG_SCSI_FC_ATTRS=y
 # CONFIG_SCSI_FUTURE_DOMAIN is not set
 # CONFIG_SCSI_GDTH is not set
 # CONFIG_SCSI_IPS is not set
+# CONFIG_SCSI_IBMVSCSI is not set
 # CONFIG_SCSI_INIA100 is not set
 # CONFIG_SCSI_SYM53C8XX_2 is not set
+CONFIG_SCSI_IPR=y
+# CONFIG_SCSI_IPR_TRACE is not set
+# CONFIG_SCSI_IPR_DUMP is not set
 # CONFIG_SCSI_QLOGIC_ISP is not set
 # CONFIG_SCSI_QLOGIC_FC is not set
 # CONFIG_SCSI_QLOGIC_1280 is not set
@@ -417,7 +421,7 @@ CONFIG_E1000=y
 #
 CONFIG_IXGB=m
 # CONFIG_IXGB_NAPI is not set
-# CONFIG_VETH is not set
+# CONFIG_ISERIES_VETH is not set
 # CONFIG_FDDI is not set
 # CONFIG_HIPPI is not set
 CONFIG_PPP=m
@@ -758,7 +762,7 @@ CONFIG_NLS_DEFAULT="iso8859-1"
 CONFIG_VIOCONS=y
 CONFIG_VIODASD=y
 CONFIG_VIOCD=y
-# CONFIG_VIOTAPE is not set
+CONFIG_VIOTAPE=y
 CONFIG_VIOPATH=y
 
 #
@@ -778,6 +782,7 @@ CONFIG_MAGIC_SYSRQ=y
 # CONFIG_DEBUGGER is not set
 # CONFIG_PPCDBG is not set
 # CONFIG_DEBUG_INFO is not set
+CONFIG_DEBUG_SPINLOCK_SLEEP=y
 
 #
 # Security options
diff -purN linux-2.5/arch/ppc64/configs/pSeries_defconfig linuxppc64-2.5/arch/ppc64/configs/pSeries_defconfig
--- linux-2.5/arch/ppc64/configs/pSeries_defconfig	2004-03-17 12:02:30.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/configs/pSeries_defconfig	2004-03-18 08:10:24.000000000 +0000
@@ -107,7 +107,7 @@ CONFIG_PROC_DEVICETREE=y
 #
 # Generic Driver Options
 #
-CONFIG_FW_LOADER=m
+CONFIG_FW_LOADER=y
 # CONFIG_DEBUG_DRIVER is not set
 
 #
@@ -250,12 +250,17 @@ CONFIG_SCSI_FC_ATTRS=y
 # CONFIG_SCSI_FUTURE_DOMAIN is not set
 # CONFIG_SCSI_GDTH is not set
 # CONFIG_SCSI_IPS is not set
+CONFIG_SCSI_IBMVSCSI=m
+CONFIG_SCSI_IBMVSCSIS=m
 # CONFIG_SCSI_INIA100 is not set
 CONFIG_SCSI_SYM53C8XX_2=y
 CONFIG_SCSI_SYM53C8XX_DMA_ADDRESSING_MODE=0
 CONFIG_SCSI_SYM53C8XX_DEFAULT_TAGS=16
 CONFIG_SCSI_SYM53C8XX_MAX_TAGS=64
 # CONFIG_SCSI_SYM53C8XX_IOMAPPED is not set
+CONFIG_SCSI_IPR=y
+# CONFIG_SCSI_IPR_TRACE is not set
+# CONFIG_SCSI_IPR_DUMP is not set
 # CONFIG_SCSI_QLOGIC_ISP is not set
 # CONFIG_SCSI_QLOGIC_FC is not set
 # CONFIG_SCSI_QLOGIC_1280 is not set
@@ -495,9 +500,9 @@ CONFIG_TIGON3=y
 #
 CONFIG_IXGB=m
 # CONFIG_IXGB_NAPI is not set
+CONFIG_IBMVETH=m
 # CONFIG_FDDI is not set
 # CONFIG_HIPPI is not set
-CONFIG_IBMVETH=m
 CONFIG_PPP=m
 # CONFIG_PPP_MULTILINK is not set
 # CONFIG_PPP_FILTER is not set
@@ -630,6 +635,7 @@ CONFIG_UNIX98_PTYS=y
 CONFIG_LEGACY_PTYS=y
 CONFIG_LEGACY_PTY_COUNT=256
 CONFIG_HVC_CONSOLE=y
+CONFIG_HVCS=m
 
 #
 # Mice
@@ -658,7 +664,7 @@ CONFIG_HVC_CONSOLE=y
 # CONFIG_AGP is not set
 # CONFIG_DRM is not set
 CONFIG_RAW_DRIVER=y
-CONFIG_MAX_RAW_DEVS=256
+CONFIG_MAX_RAW_DEVS=2048
 
 #
 # I2C support
@@ -1058,9 +1064,11 @@ CONFIG_DEBUG_STACK_USAGE=y
 CONFIG_MAGIC_SYSRQ=y
 CONFIG_DEBUGGER=y
 CONFIG_XMON=y
+# CONFIG_KDB is not set
 CONFIG_XMON_DEFAULT=y
 # CONFIG_PPCDBG is not set
 # CONFIG_DEBUG_INFO is not set
+CONFIG_DEBUG_SPINLOCK_SLEEP=y
 
 #
 # Security options
diff -purN linux-2.5/arch/ppc64/defconfig linuxppc64-2.5/arch/ppc64/defconfig
--- linux-2.5/arch/ppc64/defconfig	2004-03-17 12:02:30.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/defconfig	2004-03-18 08:10:24.000000000 +0000
@@ -107,7 +107,7 @@ CONFIG_PROC_DEVICETREE=y
 #
 # Generic Driver Options
 #
-CONFIG_FW_LOADER=m
+CONFIG_FW_LOADER=y
 # CONFIG_DEBUG_DRIVER is not set
 
 #
@@ -250,12 +250,17 @@ CONFIG_SCSI_FC_ATTRS=y
 # CONFIG_SCSI_FUTURE_DOMAIN is not set
 # CONFIG_SCSI_GDTH is not set
 # CONFIG_SCSI_IPS is not set
+CONFIG_SCSI_IBMVSCSI=m
+CONFIG_SCSI_IBMVSCSIS=m
 # CONFIG_SCSI_INIA100 is not set
 CONFIG_SCSI_SYM53C8XX_2=y
 CONFIG_SCSI_SYM53C8XX_DMA_ADDRESSING_MODE=0
 CONFIG_SCSI_SYM53C8XX_DEFAULT_TAGS=16
 CONFIG_SCSI_SYM53C8XX_MAX_TAGS=64
 # CONFIG_SCSI_SYM53C8XX_IOMAPPED is not set
+CONFIG_SCSI_IPR=y
+# CONFIG_SCSI_IPR_TRACE is not set
+# CONFIG_SCSI_IPR_DUMP is not set
 # CONFIG_SCSI_QLOGIC_ISP is not set
 # CONFIG_SCSI_QLOGIC_FC is not set
 # CONFIG_SCSI_QLOGIC_1280 is not set
@@ -495,9 +500,9 @@ CONFIG_TIGON3=y
 #
 CONFIG_IXGB=m
 # CONFIG_IXGB_NAPI is not set
+CONFIG_IBMVETH=m
 # CONFIG_FDDI is not set
 # CONFIG_HIPPI is not set
-CONFIG_IBMVETH=m
 CONFIG_PPP=m
 # CONFIG_PPP_MULTILINK is not set
 # CONFIG_PPP_FILTER is not set
@@ -630,6 +635,7 @@ CONFIG_UNIX98_PTYS=y
 CONFIG_LEGACY_PTYS=y
 CONFIG_LEGACY_PTY_COUNT=256
 CONFIG_HVC_CONSOLE=y
+CONFIG_HVCS=m
 
 #
 # Mice
@@ -658,7 +664,7 @@ CONFIG_HVC_CONSOLE=y
 # CONFIG_AGP is not set
 # CONFIG_DRM is not set
 CONFIG_RAW_DRIVER=y
-CONFIG_MAX_RAW_DEVS=256
+CONFIG_MAX_RAW_DEVS=2048
 
 #
 # I2C support
@@ -1058,9 +1064,11 @@ CONFIG_DEBUG_STACK_USAGE=y
 CONFIG_MAGIC_SYSRQ=y
 CONFIG_DEBUGGER=y
 CONFIG_XMON=y
+# CONFIG_KDB is not set
 CONFIG_XMON_DEFAULT=y
 # CONFIG_PPCDBG is not set
 # CONFIG_DEBUG_INFO is not set
+CONFIG_DEBUG_SPINLOCK_SLEEP=y
 
 #
 # Security options
diff -purN linux-2.5/arch/ppc64/kernel/Makefile linuxppc64-2.5/arch/ppc64/kernel/Makefile
--- linux-2.5/arch/ppc64/kernel/Makefile	2004-03-16 11:30:38.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/Makefile	2004-03-20 10:56:41.000000000 +0000
@@ -44,6 +44,8 @@ obj-$(CONFIG_PPC_RTAS)		+= rtas-proc.o
 obj-$(CONFIG_SCANLOG)		+= scanlog.o
 obj-$(CONFIG_VIOPATH)		+= viopath.o
 obj-$(CONFIG_LPARCFG)		+= lparcfg.o
+obj-$(CONFIG_PPC_VPURR)		+= vpurr.o
+obj-$(CONFIG_VIOCFG)		+= vioconfig.o
 obj-$(CONFIG_HVC_CONSOLE)	+= hvconsole.o
 obj-$(CONFIG_BOOTX_TEXT)	+= btext.o
 
diff -purN linux-2.5/arch/ppc64/kernel/chrp_setup.c linuxppc64-2.5/arch/ppc64/kernel/chrp_setup.c
--- linux-2.5/arch/ppc64/kernel/chrp_setup.c	2004-03-22 05:48:50.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/chrp_setup.c	2004-03-23 04:57:13.000000000 +0000
@@ -139,10 +139,6 @@ chrp_setup_arch(void)
 #ifdef CONFIG_BLK_DEV_INITRD
 	/* this is fine for chrp */
 	initrd_below_start_ok = 1;
-	
-	if (initrd_start)
-		ROOT_DEV = Root_RAM0;
-	else
 #endif
 	ROOT_DEV = Root_SDA2;
 
@@ -252,7 +248,7 @@ chrp_init(unsigned long r3, unsigned lon
 
 	ppc_md.setup_arch     = chrp_setup_arch;
 	ppc_md.get_cpuinfo    = chrp_get_cpuinfo;
-	if(naca->interrupt_controller == IC_OPEN_PIC) {
+	if (naca->interrupt_controller == IC_OPEN_PIC) {
 		ppc_md.init_IRQ       = pSeries_init_openpic; 
 		ppc_md.get_irq        = openpic_get_irq;
 	} else {
diff -purN linux-2.5/arch/ppc64/kernel/eeh.c linuxppc64-2.5/arch/ppc64/kernel/eeh.c
--- linux-2.5/arch/ppc64/kernel/eeh.c	2004-03-16 11:30:36.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/eeh.c	2004-03-23 18:52:35.000000000 +0000
@@ -395,6 +395,12 @@ unsigned long eeh_check_failure(void *to
 		return val;
 	}
 
+        /* Make sure we aren't ISA */
+        if (!strcmp(dn->type, "isa")) {
+                pci_dev_put(dev);
+                return val;
+        }
+
 	if (!dn->eeh_config_addr) {
 		pci_dev_put(dev);
 		return val;
diff -purN linux-2.5/arch/ppc64/kernel/i8259.c linuxppc64-2.5/arch/ppc64/kernel/i8259.c
--- linux-2.5/arch/ppc64/kernel/i8259.c	2003-02-11 11:51:44.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/i8259.c	2003-09-12 19:50:39.000000000 +0000
@@ -124,8 +124,8 @@ static void i8259_unmask_irq(unsigned in
 
 static void i8259_end_irq(unsigned int irq)
 {
-	if (!(irq_desc[irq].status & (IRQ_DISABLED|IRQ_INPROGRESS)) &&
-	    irq_desc[irq].action)
+	if (!(get_irq_desc(irq)->status & (IRQ_DISABLED|IRQ_INPROGRESS)) &&
+	    get_irq_desc(irq)->action)
 		i8259_unmask_irq(irq);
 }
 
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_irq.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_irq.c
--- linux-2.5/arch/ppc64/kernel/iSeries_irq.c	2004-02-25 02:54:12.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_irq.c	2004-02-26 06:29:56.000000000 +0000
@@ -122,8 +122,8 @@ void __init iSeries_activate_IRQs()
 	int irq;
 	unsigned long flags;
 
-	for (irq = 0; irq < NR_IRQS; irq++) {
-		irq_desc_t *desc = &irq_desc[irq];
+	for_each_irq (irq) {
+		irq_desc_t *desc = get_irq_desc(irq);
 
 		if (desc && desc->handler && desc->handler->startup) {
 			spin_lock_irqsave(&desc->lock, flags);
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_pci.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_pci.c
--- linux-2.5/arch/ppc64/kernel/iSeries_pci.c	2004-03-21 10:27:39.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_pci.c	2004-03-23 04:57:14.000000000 +0000
@@ -46,6 +46,7 @@
 #include <asm/iSeries/iSeries_irq.h>
 #include <asm/iSeries/iSeries_pci.h>
 #include <asm/iSeries/mf.h>
+#include <asm/iSeries/vio.h>
 
 #include "iSeries_IoMmTable.h"
 #include "pci.h"
@@ -242,6 +243,11 @@ void __init iSeries_pci_final_fixup(void
 	iSeries_IoMmTable_Status();
 	iSeries_activate_IRQs();
 	mf_displaySrc(0xC9000200);
+
+	/* Now set up virtual bus device information */
+	if (device_register(iSeries_vio_dev)) {
+	    printk("pcibios error registering iSeries_vio_dev\n");
+	}
 }
 
 void pcibios_fixup_bus(struct pci_bus *PciBus)
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_setup.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_setup.c
--- linux-2.5/arch/ppc64/kernel/iSeries_setup.c	2004-03-21 10:27:41.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_setup.c	2004-03-23 04:57:14.000000000 +0000
@@ -298,7 +298,6 @@ void __init iSeries_init_early(void)
 		initrd_start = (unsigned long)__va(naca->xRamDisk);
 		initrd_end = initrd_start + naca->xRamDiskSize * PAGE_SIZE;
 		initrd_below_start_ok = 1;	// ramdisk in kernel space
-		ROOT_DEV = Root_RAM0;
 		if (((rd_size * 1024) / PAGE_SIZE) < naca->xRamDiskSize)
 			rd_size = (naca->xRamDiskSize * PAGE_SIZE) / 1024;
 	} else
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_setup.h linuxppc64-2.5/arch/ppc64/kernel/iSeries_setup.h
--- linux-2.5/arch/ppc64/kernel/iSeries_setup.h	2004-01-21 01:50:56.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_setup.h	2004-02-26 10:56:03.000000000 +0000
@@ -29,7 +29,6 @@ extern void iSeries_setup_arch(void);
 extern void iSeries_setup_residual(struct seq_file *m, int cpu_id);
 extern void iSeries_get_cpuinfo(struct seq_file *m);
 extern void iSeries_init_IRQ(void);
-extern void iSeries_init_irq_desc(irq_desc_t *);
 extern int iSeries_get_irq(struct pt_regs *regs);
 extern void iSeries_restart(char *cmd);
 extern void iSeries_power_off(void);
diff -purN linux-2.5/arch/ppc64/kernel/idle.c linuxppc64-2.5/arch/ppc64/kernel/idle.c
--- linux-2.5/arch/ppc64/kernel/idle.c	2004-03-25 08:39:55.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/idle.c	2004-03-26 13:16:48.000000000 +0000
@@ -26,6 +26,7 @@
 #include <linux/unistd.h>
 #include <linux/slab.h>
 #include <linux/interrupt.h>
+#include <linux/cpu.h>
 
 #include <asm/pgtable.h>
 #include <asm/uaccess.h>
@@ -150,6 +151,8 @@ int default_idle(void)
 		}
 
 		schedule();
+		if (cpu_is_offline(smp_processor_id()) && system_state == SYSTEM_RUNNING)
+			cpu_die();
 	}
 
 	return 0;
@@ -236,6 +239,8 @@ int dedicated_idle(void)
 		HMT_medium();
 		lpaca->xLpPaca.xIdle = 0;
 		schedule();
+		if (cpu_is_offline(smp_processor_id()) && system_state == SYSTEM_RUNNING)
+			cpu_die();
 	}
 	return 0;
 }
@@ -245,6 +250,9 @@ int shared_idle(void)
 	struct paca_struct *lpaca = get_paca();
 
 	while (1) {
+		if (cpu_is_offline(smp_processor_id()) && system_state == SYSTEM_RUNNING)
+			cpu_die();
+
 		/* Indicate to the HV that we are idle.  Now would be
 		 * a good time to find other work to dispatch. */
 		lpaca->xLpPaca.xIdle = 1;
diff -purN linux-2.5/arch/ppc64/kernel/irq.c linuxppc64-2.5/arch/ppc64/kernel/irq.c
--- linux-2.5/arch/ppc64/kernel/irq.c	2004-03-16 11:30:37.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/irq.c	2004-03-17 01:47:27.000000000 +0000
@@ -67,6 +67,7 @@ irq_desc_t irq_desc[NR_IRQS] __cacheline
 	}
 };
 
+int __irq_offset_value;
 int ppc_spurious_interrupts = 0;
 unsigned long lpEvent_count = 0;
 
@@ -76,7 +77,7 @@ setup_irq(unsigned int irq, struct irqac
 	int shared = 0;
 	unsigned long flags;
 	struct irqaction *old, **p;
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 
 	/*
 	 * Some drivers like serial.c use request_irq() heavily,
@@ -134,7 +135,7 @@ setup_irq(unsigned int irq, struct irqac
 
 inline void synchronize_irq(unsigned int irq)
 {
-	while (irq_desc[irq].status & IRQ_INPROGRESS)
+	while (get_irq_desc(irq)->status & IRQ_INPROGRESS)
 		cpu_relax();
 }
 
@@ -148,11 +149,10 @@ EXPORT_SYMBOL(synchronize_irq);
 static int
 do_free_irq(int irq, void* dev_id)
 {
-	irq_desc_t *desc;
+	irq_desc_t *desc = get_irq_desc(irq);
 	struct irqaction **p;
 	unsigned long flags;
 
-	desc = irq_desc + irq;
 	spin_lock_irqsave(&desc->lock,flags);
 	p = &desc->action;
 	for (;;) {
@@ -247,7 +247,7 @@ EXPORT_SYMBOL(free_irq);
  
 inline void disable_irq_nosync(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -276,7 +276,7 @@ EXPORT_SYMBOL(disable_irq_nosync);
  
 void disable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	disable_irq_nosync(irq);
 	if (desc->action)
 		synchronize_irq(irq);
@@ -296,7 +296,7 @@ EXPORT_SYMBOL(disable_irq);
  
 void enable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -327,6 +327,7 @@ int show_interrupts(struct seq_file *p, 
 {
 	int i = *(loff_t *) v, j;
 	struct irqaction * action;
+	irq_desc_t *desc;
 	unsigned long flags;
 
 	if (i == 0) {
@@ -339,8 +340,9 @@ int show_interrupts(struct seq_file *p, 
 	}
 
 	if (i < NR_IRQS) {
-		spin_lock_irqsave(&irq_desc[i].lock, flags);
-		action = irq_desc[i].action;
+		desc = get_irq_desc(i);
+		spin_lock_irqsave(&desc->lock, flags);
+		action = desc->action;
 		if (!action || !action->handler)
 			goto skip;
 		seq_printf(p, "%3d: ", i);
@@ -352,17 +354,17 @@ int show_interrupts(struct seq_file *p, 
 #else
 		seq_printf(p, "%10u ", kstat_irqs(i));
 #endif /* CONFIG_SMP */
-		if (irq_desc[i].handler)		
-			seq_printf(p, " %s ", irq_desc[i].handler->typename );
+		if (desc->handler)
+			seq_printf(p, " %s ", desc->handler->typename );
 		else
 			seq_printf(p, "  None      ");
-		seq_printf(p, "%s", (irq_desc[i].status & IRQ_LEVEL) ? "Level " : "Edge  ");
+		seq_printf(p, "%s", (desc->status & IRQ_LEVEL) ? "Level " : "Edge  ");
 		seq_printf(p, "    %s",action->name);
 		for (action=action->next; action; action = action->next)
 			seq_printf(p, ", %s", action->name);
 		seq_putc(p, '\n');
 skip:
-		spin_unlock_irqrestore(&irq_desc[i].lock, flags);
+		spin_unlock_irqrestore(&desc->lock, flags);
 	} else if (i == NR_IRQS)
 		seq_printf(p, "BAD: %10u\n", ppc_spurious_interrupts);
 	return 0;
@@ -482,7 +484,7 @@ void ppc_irq_dispatch_handler(struct pt_
 	int status;
 	struct irqaction *action;
 	int cpu = smp_processor_id();
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	irqreturn_t action_ret;
 
 	kstat_cpu(cpu).irqs[irq]++;
@@ -564,11 +566,11 @@ out:
 	 * The ->end() handler has to deal with interrupts which got
 	 * disabled while the handler was running.
 	 */
-	if (irq_desc[irq].handler) {
-		if (irq_desc[irq].handler->end)
-			irq_desc[irq].handler->end(irq);
-		else if (irq_desc[irq].handler->enable)
-			irq_desc[irq].handler->enable(irq);
+	if (desc->handler) {
+		if (desc->handler->end)
+			desc->handler->end(irq);
+		else if (desc->handler->enable)
+			desc->handler->enable(irq);
 	}
 	spin_unlock(&desc->lock);
 }
@@ -683,6 +685,7 @@ static struct proc_dir_entry * root_irq_
 static struct proc_dir_entry * irq_dir [NR_IRQS];
 static struct proc_dir_entry * smp_affinity_entry [NR_IRQS];
 
+/* Protected by get_irq_desc(irq)->lock. */
 #ifdef CONFIG_IRQ_ALL_CPUS
 cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
 #else  /* CONFIG_IRQ_ALL_CPUS */
@@ -702,16 +705,18 @@ static int irq_affinity_read_proc (char 
 static int irq_affinity_write_proc (struct file *file, const char *buffer,
 					unsigned long count, void *data)
 {
-	int irq = (long)data, full_count = count, err;
+	unsigned int irq = (long)data;
+	irq_desc_t *desc = get_irq_desc(irq);
+	int ret;
 	cpumask_t new_value, tmp;
 	cpumask_t allcpus = CPU_MASK_ALL;
 
-	if (!irq_desc[irq].handler->set_affinity)
+	if (!desc->handler->set_affinity)
 		return -EIO;
 
-	err = cpumask_parse(buffer, count, new_value);
-	if (err)
-		return err;
+	ret = cpumask_parse(buffer, count, new_value);
+	if (ret != 0)
+		return ret;
 
 	/*
 	 * We check for CPU_MASK_ALL in xics to send irqs to all cpus.
@@ -721,19 +726,28 @@ static int irq_affinity_write_proc (stru
 	 */
 	cpus_and(new_value, new_value, allcpus);
 
+	/* Grab lock here so cpu_online_map can't change, and also
+	 * protect irq_affinity[]. */
+        spin_lock(&desc->lock);
+
 	/*
 	 * Do not allow disabling IRQs completely - it's a too easy
 	 * way to make the system unusable accidentally :-) At least
 	 * one online CPU still has to be targeted.
 	 */
 	cpus_and(tmp, new_value, cpu_online_map);
-	if (cpus_empty(tmp))
-		return -EINVAL;
+	if (cpus_empty(tmp)) {
+		ret = -EINVAL;
+		goto out;
+	}
 
 	irq_affinity[irq] = new_value;
-	irq_desc[irq].handler->set_affinity(irq, new_value);
+	desc->handler->set_affinity(irq, new_value);
+	ret = count;
 
-	return full_count;
+out:
+	spin_unlock(&desc->lock);
+	return ret;
 }
 
 static int prof_cpu_mask_read_proc (char *page, char **start, off_t off,
@@ -828,8 +842,8 @@ void init_irq_proc (void)
 	/*
 	 * Create entries for all existing IRQs.
 	 */
-	for (i = 0; i < NR_IRQS; i++) {
-		if (irq_desc[i].handler == NULL)
+	for_each_irq(i) {
+		if (get_irq_desc(i)->handler == NULL)
 			continue;
 		register_irq_proc(i);
 	}
@@ -857,7 +871,7 @@ unsigned int virt_irq_to_real_map[NR_IRQ
  * we don't end up with an interrupt number >= NR_IRQS.
  */
 #define MIN_VIRT_IRQ	3
-#define MAX_VIRT_IRQ	(NR_IRQS - NUM_8259_INTERRUPTS - 1)
+#define MAX_VIRT_IRQ	(NR_IRQS - NUM_ISA_INTERRUPTS - 1)
 #define NR_VIRT_IRQS	(MAX_VIRT_IRQ - MIN_VIRT_IRQ + 1)
 
 void
@@ -946,5 +960,4 @@ unsigned int real_irq_to_virt_slowpath(u
 
 }
 
-
 #endif
diff -purN linux-2.5/arch/ppc64/kernel/lparcfg.c linuxppc64-2.5/arch/ppc64/kernel/lparcfg.c
--- linux-2.5/arch/ppc64/kernel/lparcfg.c	2004-02-27 05:33:08.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/lparcfg.c	2004-03-02 22:14:49.000000000 +0000
@@ -29,9 +29,31 @@
 #include <asm/hvcall.h>
 #include <asm/cputable.h>
 
-#define MODULE_VERS "1.0"
+#define MODULE_VERS "1.1"
 #define MODULE_NAME "lparcfg"
 
+/* #define LPARCFG_DEBUG */
+
+/* find a better place for this function... */
+void log_plpar_hcall_return(unsigned long rc,char * tag)
+{
+	if (rc==0) /* success, return */
+		return;
+/* check for null tag ? */
+	if (rc == H_Hardware)
+		printk("plpar-hcall (%s) failed with hardware fault\n",tag);
+	else if (rc == H_Function)
+		printk("plpar-hcall (%s) failed; function not allowed\n",tag);
+	else if (rc == H_Authority)
+		printk("plpar-hcall (%s) failed; not authorized to this function\n",tag);
+	else if (rc == H_Parameter)
+		printk("plpar-hcall (%s) failed; Bad parameter(s)\n",tag);
+	else
+		printk("plpar-hcall (%s) failed with unexpected rc(0x%lx)\n",tag,rc);
+
+}
+
+
 static struct proc_dir_entry *proc_ppc64_lparcfg;
 #define LPARCFG_BUFF_SIZE 4096
 
@@ -217,7 +239,7 @@ static int lparcfg_data(unsigned char *b
  *          XXXX - reserved (0)
  *              XXXX - Group Number
  *                  XXXX - Pool Number.
- *  R7 (PPOONNMMLLKKJJII)
+ *  R7 (IIJJKKLLMMNNOOPP).
  *      XX - reserved. (0)
  *        XX - bit 0-6 reserved (0).   bit 7 is Capped indicator.
  *          XX - variable processor Capacity Weight
@@ -225,76 +247,140 @@ static int lparcfg_data(unsigned char *b
  *              XXXX - Active processors in Physical Processor Pool.
  *                  XXXX  - Processors active on platform. 
  */
-unsigned int h_get_ppp(unsigned long *entitled,unsigned long  *unallocated,unsigned long *aggregation,unsigned long *resource)
+static unsigned int h_get_ppp(unsigned long *entitled,unsigned long  *unallocated,unsigned long *aggregation,unsigned long *resource)
 {
 	unsigned long rc;
 	rc = plpar_hcall_4out(H_GET_PPP,0,0,0,0,entitled,unallocated,aggregation,resource);
-	return 0;
+
+	log_plpar_hcall_return(rc,"H_GET_PPP");
+
+	return rc;
+}
+
+static void h_pic(unsigned long *pool_idle_time,unsigned long *num_procs)
+{
+	unsigned long rc;
+	unsigned long dummy;
+	rc = plpar_hcall(H_PIC,0,0,0,0,pool_idle_time,num_procs,&dummy);
+
+	log_plpar_hcall_return(rc,"H_PIC");
+}
+
+/* prototyping h_purr functionality.  this may need to be moved into decrementer code. */
+static void h_purr(unsigned long *purr)
+{
+	unsigned long rc;
+
+	unsigned long dummy;
+	rc = plpar_hcall(H_PURR, 0, 0, 0, 0,purr, &dummy, &dummy);
+
+	log_plpar_hcall_return(rc,"H_PURR");
 }
 
-/*
- * get_splpar_potential_characteristics().
- * Retrieve the potential_processors and max_entitled_capacity values
- * through the get-system-parameter rtas call.
- */
 #define SPLPAR_CHARACTERISTICS_TOKEN 20
 #define SPLPAR_MAXLENGTH 1026*(sizeof(char))
-unsigned int get_splpar_potential_characteristics(void)
+
+/*
+ * parse_system_parameter_string()
+ * Retrieve the potential_processors, max_entitled_capacity and friends 
+ * through the get-system-parameter rtas call.  Replace keyword strings as
+ * necessary, and add the contents to 'buf'.
+ */
+unsigned long parse_system_parameter_string(unsigned long n, char * buf)
 {
-	/* return 0 for now.  Underlying rtas functionality is not yet complete. 12/01/2003*/
-	return 0; 
-#if 0 
 	long call_status;
 	unsigned long ret[2];
 
-	char * buffer = kmalloc(SPLPAR_MAXLENGTH, GFP_KERNEL);
-
-	printk("token for ibm,get-system-parameter (0x%x)\n",rtas_token("ibm,get-system-parameter"));
+	char * local_buffer = kmalloc(SPLPAR_MAXLENGTH, GFP_KERNEL);
+	if (!local_buffer) {
+		printk("%s %s kmalloc failure at line %d \n",__FILE__,__FUNCTION__,__LINE__);
+		return n;
+	}
 
+	spin_lock(&rtas_data_buf_lock);
+	memset(rtas_data_buf, 0, SPLPAR_MAXLENGTH); 
 	call_status = rtas_call(rtas_token("ibm,get-system-parameter"), 3, 1,
 				NULL,
 				SPLPAR_CHARACTERISTICS_TOKEN,
-				&buffer,
+				__pa(rtas_data_buf),
 				SPLPAR_MAXLENGTH,
 				(void *)&ret);
+	memcpy(local_buffer,rtas_data_buf, SPLPAR_MAXLENGTH);
+	spin_unlock(&rtas_data_buf_lock);
 
 	if (call_status!=0) {
-		printk("Error calling get-system-parameter (0x%lx)\n",call_status);
-		kfree(buffer);
-		return -1;
+		printk("%s %s Error calling get-system-parameter (0x%lx)\n",__FILE__,__FUNCTION__,call_status);
 	} else {
-		printk("get-system-parameter (%s)\n",buffer);
-		kfree(buffer);
-		/* TODO: Add code here to parse out value for system_potential_processors and partition_max_entitled_capacity */
-		return 1;
-	}
+		int splpar_strlen;
+		int idx,w_idx;
+		char * workbuffer = kmalloc(SPLPAR_MAXLENGTH, GFP_KERNEL);
+		if (!workbuffer) {
+			printk("%s %s kmalloc failure at line %d \n",__FILE__,__FUNCTION__,__LINE__);
+			return n;
+		}
+
+#ifdef LPARCFG_DEBUG
+		printk("success calling get-system-parameter \n");
 #endif
+		splpar_strlen=local_buffer[0]*16+local_buffer[1];
+		local_buffer+=2; /* step over strlen value */
+
+		memset(workbuffer, 0, SPLPAR_MAXLENGTH);
+		w_idx=0; idx=0;
+		while ((*local_buffer) && (idx<splpar_strlen)) {
+			workbuffer[w_idx++]=local_buffer[idx++];
+			if ((local_buffer[idx]==',')||(local_buffer[idx]=='\0')) {
+				workbuffer[w_idx]='\0';
+				if (w_idx) /* avoid the empty string */
+				{
+					n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n, 
+						      "%s\n",workbuffer);
+				}
+				memset(workbuffer, 0, SPLPAR_MAXLENGTH);
+				idx++; /* skip the comma */
+				w_idx=0;
+			} else if (local_buffer[idx]=='=') {
+				/* code here to replace workbuffer contents
+				 with different keyword strings */
+				if (0==strcmp(workbuffer,"MaxEntCap")) {
+					strcpy(workbuffer,"partition_max_entitled_capacity\0");
+					w_idx=strlen(workbuffer);
+				}
+				if (0==strcmp(workbuffer,"MaxPlatProcs")) {
+					strcpy(workbuffer,"system_potential_processors\0");
+					w_idx=strlen(workbuffer);
+				}
+			}
+		}
+		kfree(workbuffer);
+		local_buffer-=2; /* back up over strlen value */
+	}
+	kfree(local_buffer);
+	return n;
 }
 
 static int lparcfg_data(unsigned char *buf, unsigned long size)
 {
-	unsigned long n = 0;
-	int shared, max_entitled_capacity;
-	int processors, system_active_processors, system_potential_processors;
-	struct device_node *root;
+	unsigned long n = 0;		/* scnprintf index */
+	int system_active_processors;
+	struct device_node *rootdn;
 	const char *model = "";
 	const char *system_id = "";
 	unsigned int *lp_index_ptr, lp_index = 0;
 	struct device_node *rtas_node;
-	int *ip;
-	unsigned long h_entitled,h_unallocated,h_aggregation,h_resource;
+	int *lrdrp;
 
 	if((buf == NULL) || (size > LPARCFG_BUFF_SIZE)) {
 		return -EFAULT;
 	}
 	memset(buf, 0, size); 
 
-	root = find_path_device("/");
-	if (root) {
-		model = get_property(root, "model", NULL);
-		system_id = get_property(root, "system-id", NULL);
-		lp_index_ptr = (unsigned int *)get_property(root, "ibm,partition-no", NULL);
-		if(lp_index_ptr) lp_index = *lp_index_ptr;
+	rootdn = find_path_device("/");
+	if (rootdn) {
+		model = get_property(rootdn, "model", NULL);
+		system_id = get_property(rootdn, "system-id", NULL);
+		lp_index_ptr = (unsigned int *)get_property(rootdn, "ibm,partition-no", NULL);
+		if (lp_index_ptr) lp_index = *lp_index_ptr;
 	}
 
 	n  = scnprintf(buf, LPARCFG_BUFF_SIZE - n,
@@ -307,16 +393,22 @@ static int lparcfg_data(unsigned char *b
 		      "partition_id=%d\n", (int)lp_index); 
 
 	rtas_node = find_path_device("/rtas");
-	ip = (int *)get_property(rtas_node, "ibm,lrdr-capacity", NULL);
-	if (ip == NULL) {
+	lrdrp = (int *)get_property(rtas_node, "ibm,lrdr-capacity", NULL);
+
+	if (lrdrp == NULL) {
 		system_active_processors = systemcfg->processorCount; 
 	} else {
-		system_active_processors = *(ip + 4);
-	}
+		system_active_processors = *(lrdrp + 4);
+	} 
 
 	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
+		unsigned long h_entitled,h_unallocated,h_aggregation,h_resource;
+		unsigned long pool_idle_time,pool_procs;
+		unsigned long purr;
+
 		h_get_ppp(&h_entitled,&h_unallocated,&h_aggregation,&h_resource);
-#ifdef DEBUG
+
+#ifdef LPARCFG_DEBUG
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
 			      "R4=0x%lx\n", h_entitled);
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
@@ -325,68 +417,93 @@ static int lparcfg_data(unsigned char *b
 			      "R6=0x%lx\n", h_aggregation);
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
 			      "R7=0x%lx\n", h_resource);
-#endif /* DEBUG */
-	}
+#endif /* LPARCFG_DEBUG */
+
+		h_pic(&pool_idle_time,&pool_procs);
+
+		h_purr(&purr);
+
+		/* this call handles the ibm,get-system-parameter contents */
+		n = parse_system_parameter_string(n,buf);
+
+		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
+			      "partition_entitled_capacity=%ld\n",
+			      h_entitled);
+
+		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
+			      "pool=%ld\n",
+			      (h_aggregation >> 0*8) & 0xffff);
+
+		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
+			      "group=%ld\n",
+			      (h_aggregation >> 2*8) & 0xffff);
 
-	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
-		system_potential_processors =  get_splpar_potential_characteristics();
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
 			      "system_active_processors=%ld\n", 
 			      (h_resource >> 2*8) & 0xffff);
+
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "system_potential_processors=%d\n", 
-			      system_potential_processors);
-	} else {
-		system_potential_processors = system_active_processors;
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "system_active_processors=%d\n", 
-			      system_active_processors);
+			      "pool_capacity=%ld\n",
+			      (h_resource >> 3*8) & 0xffff);
+
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "system_potential_processors=%d\n", 
-			      system_potential_processors);
-	}
+			      "capacity_weight=%ld\n",
+			      (h_resource>>5*8) & 0xFF);
 
-	processors = systemcfg->processorCount;
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_active_processors=%d\n", processors);  
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_potential_processors=%d\n",
-		      system_active_processors);
+		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
+			      "capped=%ld\n",
+			      (h_resource >> 6*8) & 0x40);
 
-	/* max_entitled_capacity will come out of get_splpar_potential_characteristics() when that function is complete */
-	max_entitled_capacity = system_active_processors * 100; 
-	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "partition_entitled_capacity=%ld\n", h_entitled);
-	} else {
+			      "unallocated_variable_weight=%ld\n",
+			      (h_resource>>7*8) & 0xFF);
+
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "partition_entitled_capacity=%d\n", system_active_processors*100);
-	}
+			      "unallocated_capacity=%ld\n",
+			      h_unallocated);
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_max_entitled_capacity=%d\n", 
-		      max_entitled_capacity);
+		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n, 
+			      "pool_idle_time=%ld\n",
+			      pool_idle_time);
 
-	shared = 0;
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "shared_processor_mode=%d\n", shared);
+		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n, 
+			      "pool_num_procs=%ld\n",
+			      pool_procs);
 
-	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "pool=%ld\n", (h_aggregation >> 0*8)&0xffff);
+		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n, 
+			      "purr=%ld\n",
+			      purr);
 
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "pool_capacity=%ld\n", (h_resource >> 3*8) &0xffff);
+	} else /* non SPLPAR case */ {
+		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n, 
+			      "system_active_processors=%d\n",
+			      system_active_processors);
 
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "group=%ld\n", (h_aggregation >> 2*8)&0xffff);
+			      "system_potential_processors=%d\n",
+			      system_active_processors);
 
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "capped=%ld\n", (h_resource >> 6*8)&0x40);
+			      "partition_max_entitled_capacity=%d\n",
+			      100*system_active_processors);
 
 		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "capacity_weight=%d\n", (int)(h_resource>>5*8)&0xFF);
+			      "partition_entitled_capacity=%d\n",
+			      system_active_processors*100);
 	}
+
+	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
+		      "partition_active_processors=%d\n",
+		      (int) systemcfg->processorCount);
+
+	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
+		      "partition_potential_processors=%d\n",
+		      system_active_processors);
+
+	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
+		      "shared_processor_mode=%d\n",
+		      paca[0].xLpPaca.xSharedProc);
+
 	return 0;
 }
 
diff -purN linux-2.5/arch/ppc64/kernel/open_pic.c linuxppc64-2.5/arch/ppc64/kernel/open_pic.c
--- linux-2.5/arch/ppc64/kernel/open_pic.c	2004-02-23 16:39:14.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/open_pic.c	2004-02-26 10:56:03.000000000 +0000
@@ -67,7 +67,6 @@ static void openpic_disable_irq(u_int ir
 static void openpic_initirq(u_int irq, u_int pri, u_int vector, int polarity,
 			    int is_level);
 static void openpic_mapirq(u_int irq, u_int cpumask);
-static void openpic_set_sense(u_int irq, int sense);
 
 static void find_ISUs(void);
 
@@ -170,7 +169,7 @@ void __init pSeries_init_openpic(void)
         int i;
         unsigned int *addrp;
         unsigned char* chrp_int_ack_special = 0;
-        unsigned char init_senses[NR_IRQS - NUM_8259_INTERRUPTS];
+        unsigned char init_senses[NR_IRQS - NUM_ISA_INTERRUPTS];
         int nmi_irq = -1;
 #if defined(CONFIG_VT) && defined(CONFIG_ADB_KEYBOARD) && defined(XMON)
         struct device_node *kbd;
@@ -185,12 +184,12 @@ void __init pSeries_init_openpic(void)
 			__ioremap(addrp[prom_n_addr_cells(np)-1], 1, _PAGE_NO_CACHE);
         /* hydra still sets OpenPIC_InitSenses to a static set of values */
         if (OpenPIC_InitSenses == NULL) {
-                prom_get_irq_senses(init_senses, NUM_8259_INTERRUPTS, NR_IRQS);
+                prom_get_irq_senses(init_senses, NUM_ISA_INTERRUPTS, NR_IRQS);
                 OpenPIC_InitSenses = init_senses;
-                OpenPIC_NumInitSenses = NR_IRQS - NUM_8259_INTERRUPTS;
+                OpenPIC_NumInitSenses = NR_IRQS - NUM_ISA_INTERRUPTS;
         }
-        openpic_init(1, NUM_8259_INTERRUPTS, chrp_int_ack_special, nmi_irq);
-        for ( i = 0 ; i < NUM_8259_INTERRUPTS  ; i++ )
+        openpic_init(1, NUM_ISA_INTERRUPTS, chrp_int_ack_special, nmi_irq);
+        for (i = 0; i < NUM_ISA_INTERRUPTS; i++)
                 irq_desc[i].handler = &i8259_pic;
 	of_node_put(np);
 }
@@ -441,7 +440,7 @@ static int __init openpic_setup_i8259(vo
 
 	if (naca->interrupt_controller == IC_OPEN_PIC) {
 		/* Initialize the cascade */
-		if (request_irq(NUM_8259_INTERRUPTS, no_action, SA_INTERRUPT,
+		if (request_irq(NUM_ISA_INTERRUPTS, no_action, SA_INTERRUPT,
 				"82c59 cascade", NULL))
 			printk(KERN_ERR "Unable to get OpenPIC IRQ 0 for cascade\n");
 		i8259_init();
@@ -820,13 +819,21 @@ static void openpic_mapirq(u_int irq, u_
  *
  *  sense: 1 for level, 0 for edge
  */
-static inline void openpic_set_sense(u_int irq, int sense)
+#if 0	/* not used */
+static void openpic_set_sense(u_int irq, int sense)
 {
 	openpic_safe_writefield(&GET_ISU(irq).Vector_Priority,
 				OPENPIC_SENSE_LEVEL,
 				(sense ? OPENPIC_SENSE_LEVEL : 0));
 }
 
+static int openpic_get_sense(u_int irq)
+{
+	return openpic_readfield(&GET_ISU(irq).Vector_Priority,
+				 OPENPIC_SENSE_LEVEL) != 0;
+}
+#endif
+
 static void openpic_end_irq(unsigned int irq_nr)
 {
 	openpic_eoi();
diff -purN linux-2.5/arch/ppc64/kernel/open_pic.h linuxppc64-2.5/arch/ppc64/kernel/open_pic.h
--- linux-2.5/arch/ppc64/kernel/open_pic.h	2004-02-12 04:30:16.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/open_pic.h	2004-02-26 10:56:03.000000000 +0000
@@ -14,6 +14,7 @@
 
 #include <linux/config.h>
 #include <linux/cpumask.h>
+#include <linux/irq.h>
 
 #define OPENPIC_SIZE	0x40000
 
@@ -38,11 +39,4 @@ extern void openpic_init_processor(u_int
 extern void openpic_setup_ISU(int isu_num, unsigned long addr);
 extern void openpic_cause_IPI(u_int ipi, u_int cpumask);
 
-extern inline int openpic_to_irq(int irq)
-{
-	if (systemcfg->platform == PLATFORM_POWERMAC)
-		return irq;
-	return irq += NUM_8259_INTERRUPTS;
-}
-/*extern int open_pic_irq_offset;*/
 #endif /* _PPC64_KERNEL_OPEN_PIC_H */
diff -purN linux-2.5/arch/ppc64/kernel/open_pic_u3.c linuxppc64-2.5/arch/ppc64/kernel/open_pic_u3.c
--- linux-2.5/arch/ppc64/kernel/open_pic_u3.c	2004-02-12 03:47:52.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/open_pic_u3.c	2004-02-26 10:56:03.000000000 +0000
@@ -251,6 +251,14 @@ static inline void openpic2_set_sense(u_
 				 (sense ? OPENPIC_SENSE_LEVEL : 0));
 }
 
+#if 0	/* not used */
+static int openpic2_get_sense(u_int irq)
+{
+	return openpic2_readfield(&GET_ISU(irq).Vector_Priority,
+				  OPENPIC_SENSE_LEVEL) != 0;
+}
+#endif
+
 static void openpic2_end_irq(unsigned int irq_nr)
 {
 	openpic2_eoi();
diff -purN linux-2.5/arch/ppc64/kernel/pSeries_pci.c linuxppc64-2.5/arch/ppc64/kernel/pSeries_pci.c
--- linux-2.5/arch/ppc64/kernel/pSeries_pci.c	2004-03-22 05:48:50.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pSeries_pci.c	2004-03-23 18:52:35.000000000 +0000
@@ -44,6 +44,12 @@
 #include "open_pic.h"
 #include "pci.h"
 
+/* legal IO pages under MAX_ISA_PORT.  This is to ensure we don't touch
+   devices we don't have access to. */
+unsigned long io_page_mask; 
+
+EXPORT_SYMBOL(io_page_mask);
+
 /* RTAS tokens */
 static int read_pci_config;
 static int write_pci_config;
@@ -280,6 +286,8 @@ static void __init pci_process_bridge_OF
 					pci_process_ISA_OF_ranges(isa_dn,
 						hose->io_base_phys,
 						hose->io_base_virt);
+                                        /* Allow all IO */
+                                        io_page_mask = -1;
 				}
 			}
 
@@ -523,8 +531,24 @@ void __devinit pcibios_fixup_device_reso
 	for (i = 0; i < PCI_NUM_RESOURCES; i++) {
 		if (dev->resource[i].flags & IORESOURCE_IO) {
 			unsigned long offset = (unsigned long)hose->io_base_virt - pci_io_base;
-			dev->resource[i].start += offset;
-			dev->resource[i].end += offset;
+                        unsigned long start, end, mask;
+ 
+                        start = dev->resource[i].start += offset;
+                        end = dev->resource[i].end += offset;
+ 
+                        /* Need to allow IO access to pages that are in the
+                           ISA range */
+                        if (start < MAX_ISA_PORT) {
+                                if (end > MAX_ISA_PORT)
+                                        end = MAX_ISA_PORT;
+				
+                                start >>= PAGE_SHIFT;
+                                end >>= PAGE_SHIFT;
+ 
+                                /* get the range of pages for the map */
+                                mask = ((1 << (end+1))-1) ^ ((1 << start)-1);
+                                io_page_mask |= mask;
+                        }
 		}
                 else if (dev->resource[i].flags & IORESOURCE_MEM) {
 			dev->resource[i].start += hose->pci_mem_offset;
diff -purN linux-2.5/arch/ppc64/kernel/pci_dn.c linuxppc64-2.5/arch/ppc64/kernel/pci_dn.c
--- linux-2.5/arch/ppc64/kernel/pci_dn.c	2004-02-27 23:02:35.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pci_dn.c	2004-03-25 20:19:40.000000000 +0000
@@ -50,13 +50,20 @@ update_dn_pci_info(struct device_node *d
 	struct pci_controller *phb = (struct pci_controller *)data;
 	u32 *regs;
 	char *device_type = get_property(dn, "device_type", 0);
+	char *model;
 
 	dn->phb = phb;
 	if (device_type && strcmp(device_type, "pci") == 0 && get_property(dn, "class-code", 0) == 0) {
 		/* special case for PHB's.  Sigh. */
 		regs = (u32 *)get_property(dn, "bus-range", 0);
 		dn->busno = regs[0];
-		dn->devfn = 0;	/* assumption */
+		
+		model = (char *)get_property(dn, "model", NULL);
+
+		if (strstr(model, "U3")) 
+			dn->devfn = -1;
+		else
+			dn->devfn = 0;	/* assumption */
 	} else {
 		regs = (u32 *)get_property(dn, "reg", 0);
 		if (regs) {
diff -purN linux-2.5/arch/ppc64/kernel/proc_ppc64.c linuxppc64-2.5/arch/ppc64/kernel/proc_ppc64.c
--- linux-2.5/arch/ppc64/kernel/proc_ppc64.c	2004-03-16 11:30:38.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/proc_ppc64.c	2004-03-17 04:34:55.000000000 +0000
@@ -32,6 +32,8 @@
 #include <asm/uaccess.h>
 #include <asm/prom.h>
 
+void proc_ppc64_create_smt(void);
+
 static loff_t  page_map_seek( struct file *file, loff_t off, int whence);
 static ssize_t page_map_read( struct file *file, char *buf, size_t nbytes, loff_t *ppos);
 static int     page_map_mmap( struct file *file, struct vm_area_struct *vma );
@@ -130,6 +132,8 @@ static int __init proc_ppc64_init(void)
 		proc_create_paca(pde, i);
 
 #ifdef CONFIG_PPC_PSERIES
+	proc_ppc64_create_smt();
+
 	if ((systemcfg->platform & PLATFORM_PSERIES))
 		proc_ppc64_create_ofdt();
 #endif
@@ -412,3 +416,84 @@ static void release_prop_list(const stru
 
 }
 #endif	/* defined(CONFIG_PPC_PSERIES) */
+
+static int proc_ppc64_smt_snooze_read(char *page, char **start, off_t off,
+				      int count, int *eof, void *data)
+{
+	if (naca->smt_snooze_delay)
+		return sprintf(page, "%lu\n", naca->smt_snooze_delay);
+	else 
+		return sprintf(page, "disabled\n");
+}
+ 
+static int proc_ppc64_smt_snooze_write(struct file* file, const char *buffer,
+				       unsigned long count, void *data)
+{
+	unsigned long val;
+	char val_string[22];
+
+	if (!capable(CAP_SYS_ADMIN))
+		return -EACCES;
+
+	if (count > sizeof(val_string) - 1)
+		return -EINVAL;
+
+	if (copy_from_user(val_string, buffer, count))
+		return -EFAULT;
+
+	val_string[count] = '\0';
+
+	if (val_string[0] == '0' && (val_string[1] == '\n' || val_string[1] == '\0')) {
+		naca->smt_snooze_delay = 0;
+		return count;
+	}
+ 
+	val = simple_strtoul(val_string, NULL, 10);
+	if (val != 0) 
+		naca->smt_snooze_delay = val;
+	else
+		return -EINVAL;
+
+	return count;
+}
+ 
+static int proc_ppc64_smt_state_read(char *page, char **start, off_t off,
+				      int count, int *eof, void *data)
+{
+	switch(naca->smt_state) {
+	case SMT_OFF:
+		return sprintf(page, "off\n");
+		break;
+	case SMT_ON:
+		return sprintf(page, "on\n");
+		break;
+	case SMT_DYNAMIC:
+		return sprintf(page, "dynamic\n");
+		break;
+	default:
+		return sprintf(page, "unknown\n");
+		break;
+	}
+}
+ 
+void proc_ppc64_create_smt(void)
+{
+	struct proc_dir_entry *ent_snooze = 
+		create_proc_entry("ppc64/smt-snooze-delay", S_IRUGO | S_IWUSR,
+				  NULL);
+	struct proc_dir_entry *ent_enabled = 
+		create_proc_entry("ppc64/smt-enabled", S_IRUGO | S_IWUSR, NULL);
+	if (ent_snooze) {
+		ent_snooze->nlink = 1;
+		ent_snooze->data = NULL;
+		ent_snooze->read_proc = (void *)proc_ppc64_smt_snooze_read;
+		ent_snooze->write_proc = (void *)proc_ppc64_smt_snooze_write;
+	}
+
+	if (ent_enabled) {
+		ent_enabled->nlink = 1;
+		ent_enabled->data = NULL;
+		ent_enabled->read_proc = (void *)proc_ppc64_smt_state_read;
+		ent_enabled->write_proc = NULL;
+	}
+}
diff -purN linux-2.5/arch/ppc64/kernel/prom.c linuxppc64-2.5/arch/ppc64/kernel/prom.c
--- linux-2.5/arch/ppc64/kernel/prom.c	2004-03-22 10:17:13.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/prom.c	2004-03-23 04:57:15.000000000 +0000
@@ -1337,7 +1337,7 @@ smt_setup(void)
 		}
 
 		if (!found) {
-			my_smt_snooze_delay = 30000; /* default value */
+			my_smt_snooze_delay = 0; /* default value */
 		}
 	} else {
 		my_smt_snooze_delay = 0; /* default value */
@@ -2188,7 +2188,7 @@ finish_node_interrupts(struct device_nod
 			printk(KERN_CRIT "Could not allocate interrupt "
 			       "number for %s\n", np->full_name);
 		} else
-			np->intrs[i].line = openpic_to_irq(virq);
+			np->intrs[i].line = irq_offset_up(virq);
 
 		/* We offset irq numbers for the u3 MPIC by 128 in PowerMac */
 		if (systemcfg->platform == PLATFORM_POWERMAC && ic && ic->parent) {
@@ -2984,7 +2984,7 @@ static void remove_node_proc_entries(str
 }
 #endif /* CONFIG_PROC_DEVICETREE */
 
-/*
+/* 
  * Fix up n_intrs and intrs fields in a new device node
  *
  */
@@ -3000,7 +3000,7 @@ static int of_finish_dynamic_node_interr
 	node->n_intrs = intlen;
 	node->intrs = kmalloc(sizeof(struct interrupt_info) * intlen,
 			      GFP_KERNEL);
-	if (!node->intrs)
+	if (!node->intrs) 
 		return -ENOMEM;
 
 	for (i = 0; i < intlen; ++i) {
@@ -3016,7 +3016,7 @@ static int of_finish_dynamic_node_interr
 			       "number for %s\n", node->full_name);
 			return -ENOMEM;
 		}
-		node->intrs[i].line = openpic_to_irq(virq);
+		node->intrs[i].line = irq_offset_up(virq);
 		if (n > 1)
 			node->intrs[i].sense = irq[1];
 		if (n > 2) {
diff -purN linux-2.5/arch/ppc64/kernel/ras.c linuxppc64-2.5/arch/ppc64/kernel/ras.c
--- linux-2.5/arch/ppc64/kernel/ras.c	2004-03-16 11:30:38.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/ras.c	2004-03-17 00:46:45.000000000 +0000
@@ -1,4 +1,3 @@
-
 /*
  * ras.c
  * Copyright (C) 2001 Dave Engebretsen IBM Corporation
@@ -80,7 +79,7 @@ static int __init init_ras_IRQ(void)
 				       "number for %s\n", np->full_name);
 				break;
 			}
-			request_irq(virq + NUM_8259_INTERRUPTS, 
+			request_irq(irq_offset_up(virq),
 				    ras_error_interrupt, 0, 
 				    "RAS_ERROR", NULL);
 			ireg++;
@@ -98,7 +97,7 @@ static int __init init_ras_IRQ(void)
 				       " number for %s\n", np->full_name);
 				break;
 			}
-			request_irq(virq + NUM_8259_INTERRUPTS, 
+			request_irq(irq_offset_up(virq), 
 				    ras_epow_interrupt, 0, 
 				    "RAS_EPOW", NULL);
 			ireg++;
diff -purN linux-2.5/arch/ppc64/kernel/rtas.c linuxppc64-2.5/arch/ppc64/kernel/rtas.c
--- linux-2.5/arch/ppc64/kernel/rtas.c	2004-03-21 10:27:37.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/rtas.c	2004-03-23 04:57:15.000000000 +0000
@@ -494,6 +498,28 @@ asmlinkage int ppc_rtas(struct rtas_args
 	return 0;
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+/* This version can't take the spinlock. */
+
+void rtas_stop_self(void)
+{
+	struct rtas_args *rtas_args = &(get_paca()->xRtas);
+
+	local_irq_disable();
+
+	rtas_args->token = rtas_token("stop-self");
+	BUG_ON(rtas_args->token == RTAS_UNKNOWN_SERVICE);
+	rtas_args->nargs = 0;
+	rtas_args->nret  = 1;
+	rtas_args->rets  = &(rtas_args->args[0]);
+
+	printk("%u %u Ready to die...\n",
+	       smp_processor_id(), hard_smp_processor_id());
+	enter_rtas((void *)__pa(rtas_args));
+
+	panic("Alas, I survived.\n");
+}
+#endif /* CONFIG_HOTPLUG_CPU */
 
 EXPORT_SYMBOL(rtas_firmware_flash_list);
 EXPORT_SYMBOL(rtas_token);
diff -purN linux-2.5/arch/ppc64/kernel/setup.c linuxppc64-2.5/arch/ppc64/kernel/setup.c
--- linux-2.5/arch/ppc64/kernel/setup.c	2004-03-21 10:27:41.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/setup.c	2004-03-23 05:14:51.000000000 +0000
@@ -25,6 +25,7 @@
 #include <linux/tty.h>
 #include <linux/root_dev.h>
 #include <linux/notifier.h>
+#include <linux/cpu.h>
 #include <asm/io.h>
 #include <asm/prom.h>
 #include <asm/processor.h>
@@ -215,6 +224,7 @@ void setup_system(unsigned long r3, unsi
 	if (systemcfg->platform & PLATFORM_PSERIES) {
 		early_console_initialized = 1;
 		register_console(&udbg_console);
+		__irq_offset_value = NUM_ISA_INTERRUPTS;
 		finish_device_tree();
 		chrp_init(r3, r4, r5, r6, r7);
 
@@ -338,8 +356,13 @@ static int show_cpuinfo(struct seq_file 
 		return 0;
 	}
 
-	if (!cpu_online(cpu_id))
+	/* We only show online cpus: disable preempt (overzealous, I
+	 * knew) to prevent cpu going down. */
+	preempt_disable();
+	if (!cpu_online(cpu_id)) {
+		preempt_enable();
 		return 0;
+	}
 
 #ifdef CONFIG_SMP
 	pvr = per_cpu(pvr, cpu_id);
@@ -372,7 +395,8 @@ static int show_cpuinfo(struct seq_file 
 		   ppc_proc_freq % 1000000);
 
 	seq_printf(m, "revision\t: %hd.%hd\n\n", maj, min);
-	
+
+	preempt_enable();
 	return 0;
 }
 
@@ -405,7 +429,6 @@ void parse_cmd_line(unsigned long r3, un
 	if ((initrd_start == 0) && r3 && r4 && r4 != 0xdeadbeef) {
 		initrd_start = (r3 >= KERNELBASE) ? r3 : (unsigned long)__va(r3);
 		initrd_end = initrd_start + r4;
-		ROOT_DEV = Root_RAM0;
 		initrd_below_start_ok = 1;
 	}
 #endif
@@ -530,7 +553,6 @@ int parse_bootinfo(void)
 		case BI_INITRD:
 			initrd_start = (unsigned long)__va(rec->data[0]);
 			initrd_end = initrd_start + rec->data[1];
-			ROOT_DEV = Root_RAM0;
 			initrd_below_start_ok = 1;
 			break;
 #endif /* CONFIG_BLK_DEV_INITRD */
diff -purN linux-2.5/arch/ppc64/kernel/signal.c linuxppc64-2.5/arch/ppc64/kernel/signal.c
--- linux-2.5/arch/ppc64/kernel/signal.c	2004-01-31 08:15:29.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/signal.c	2004-02-01 02:40:22.000000000 +0000
@@ -96,7 +96,7 @@ long sys_rt_sigsuspend(sigset_t *unewset
 	regs->gpr[3] = EINTR;
 	regs->ccr |= 0x10000000;
 	while (1) {
-		current->state = TASK_INTERRUPTIBLE;
+		set_current_state(TASK_INTERRUPTIBLE);
 		schedule();
 		if (do_signal(&saveset, regs))
 			return regs->gpr[3];
diff -purN linux-2.5/arch/ppc64/kernel/signal32.c linuxppc64-2.5/arch/ppc64/kernel/signal32.c
--- linux-2.5/arch/ppc64/kernel/signal32.c	2004-02-25 10:31:13.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/signal32.c	2004-02-26 05:41:43.000000000 +0000
@@ -271,7 +271,7 @@ long sys32_sigsuspend(old_sigset_t mask,
 	regs->gpr[3] = EINTR;
 	regs->ccr |= 0x10000000;
 	while (1) {
-		current->state = TASK_INTERRUPTIBLE;
+		set_current_state(TASK_INTERRUPTIBLE);
 		schedule();
 		if (do_signal32(&saveset, regs))
 			/*
@@ -589,7 +589,7 @@ int sys32_rt_sigsuspend(compat_sigset_t*
 	regs->gpr[3] = EINTR;
 	regs->ccr |= 0x10000000;
 	while (1) {
-		current->state = TASK_INTERRUPTIBLE;
+		set_current_state(TASK_INTERRUPTIBLE);
 		schedule();
 		if (do_signal32(&saveset, regs))
 			/*
diff -purN linux-2.5/arch/ppc64/kernel/smp.c linuxppc64-2.5/arch/ppc64/kernel/smp.c
--- linux-2.5/arch/ppc64/kernel/smp.c	2004-02-23 16:39:11.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/smp.c	2004-03-10 07:17:39.000000000 +0000
@@ -53,6 +53,10 @@
 #include <asm/cputable.h>
 #include <asm/system.h>
 
+#ifdef CONFIG_KDB
+#include <linux/kdb.h>
+#endif
+
 int smp_threads_ready;
 unsigned long cache_decay_ticks;
 
@@ -75,6 +79,23 @@ void smp_call_function_interrupt(void);
 extern long register_vpa(unsigned long flags, unsigned long proc,
 			 unsigned long vpa);
 
+#ifdef CONFIG_KDB
+	/* save regs here before calling kdb_ipi */
+struct pt_regs *kdb_smp_regs[NR_CPUS];
+	
+/* called for each processor.. drop each into kdb. */
+static void smp_kdb_stop_proc(void *dummy)
+{
+    kdb_ipi(kdb_smp_regs[smp_processor_id()], NULL);
+}
+	
+void smp_kdb_stop(void)
+{
+    int ret=0;
+    ret = smp_call_function(smp_kdb_stop_proc, NULL, 1, 0);
+}
+#endif
+
 /* Low level assembly function used to backup CPU 0 state */
 extern void __save_cpu_setup(void);
 
@@ -230,10 +251,302 @@ static void __devinit smp_openpic_setup_
 	do_openpic_setup_cpu();
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+/* Get state of physical CPU.
+ * Return codes:
+ *	0	- The processor is in the RTAS stopped state
+ *	1	- stop-self is in progress
+ *	2	- The processor is not in the RTAS stopped state
+ *	-1	- Hardware Error
+ *	-2	- Hardware Busy, Try again later.
+ */
+static int query_cpu_stopped(unsigned int pcpu)
+{
+	long cpu_status;
+	int status, qcss_tok;
+
+	qcss_tok = rtas_token("query-cpu-stopped-state");
+	BUG_ON(qcss_tok == RTAS_UNKNOWN_SERVICE);
+	status = rtas_call(qcss_tok, 1, 2, &cpu_status, pcpu);
+	if (status != 0) {
+		printk(KERN_ERR
+		       "RTAS query-cpu-stopped-state failed: %i\n", status);
+		return status;
+	}
+
+	return cpu_status;
+}
+
+int __cpu_disable(void)
+{
+	/* FIXME: go put this in a header somewhere */
+	extern void xics_migrate_irqs_away(void);
+
+	systemcfg->processorCount--;
+
+	/*fix boot_cpuid here*/
+	if (smp_processor_id() == boot_cpuid)
+		boot_cpuid = any_online_cpu(cpu_online_map);
+
+	/* FIXME: abstract this to not be platform specific later on */
+	xics_migrate_irqs_away();
+	return 0; 
+}
+
+void __cpu_die(unsigned int cpu)
+{
+	int tries;
+	int cpu_status;
+	unsigned int pcpu = get_hard_smp_processor_id(cpu);
+
+	for (tries = 0; tries < 5; tries++) {
+		cpu_status = query_cpu_stopped(pcpu);
+
+		if (cpu_status == 0)
+			break;
+		set_current_state(TASK_UNINTERRUPTIBLE);
+		schedule_timeout(HZ);
+	}
+	if (cpu_status != 0) {
+		printk("Querying DEAD? cpu %i (%i) shows %i\n",
+		       cpu, pcpu, cpu_status);
+	}
+
+	/* Isolation and deallocation are definatly done by
+	 * drslot_chrp_cpu.  If they were not they would be
+	 * done here.  Change isolate state to Isolate and
+	 * change allocation-state to Unusable.
+	 */
+	paca[cpu].xProcStart = 0;
+
+	/* So we can recognize if it fails to come up next time. */
+	cpu_callin_map[cpu] = 0;
+}
+
+/* Kill this cpu */
+void cpu_die(void)
+{
+	local_irq_disable();
+	rtas_stop_self();
+	/* Should never get here... */
+	BUG();
+	for(;;);
+}
+
+/* RPA 7.3.7.5 defines the state return values.
+ * 7.3.7.5 and 17.4.3.3 define the status return values. */
+static int check_dr_state(int drc_index)
+{
+	const int sensor = 9003;	/* DR-entity-sense */
+	/* Don't spend forever waiting for RTAS to give us an answer. */
+	unsigned long max_wait_tb = __get_tb() + 5 * tb_ticks_per_sec;
+
+	do {
+		unsigned long state;
+		int status = rtas_call(rtas_token("get-sensor-state"),
+				       2, 2, &state, sensor, drc_index);
+
+		switch (status) {
+		    case -1:	/* Hardware error */
+		    case -3:	/* No such sensor implemented */
+			return -ENOSYS;
+		    case -9000:	/* Need DR entity to be powered & unisolated */
+		    case -9001:	/* Need DR entity to be powered up */
+		    case -9002:	/* Legacy.  Treat as state == 2 (unusable) */
+			return -EBADSLT;
+		    case 0:
+			switch (state) {
+			    case 1:	/* DR entity present */
+				return 0;
+			    case 0:	/* DR connector empty */
+			    case 2:	/* DR entity unusable */
+			    case 3:	/* DR entity available for exchange */
+				return -EBADSLT;
+			    default:	/* shouldn't happen */
+				return -ENOMSG;
+			}
+		    case 9000 ... 9005: {
+			unsigned int wait_time;
+
+			wait_time = rtas_extended_busy_delay_time(status);
+			set_current_state(TASK_UNINTERRUPTIBLE);
+			schedule_timeout(wait_time);
+		    }
+		    default:	/* shouldn't happen */
+			return -ENOMSG;
+		}
+	} while (__get_tb() < max_wait_tb);
+
+	return -ETIMEDOUT;
+}
+
+/* Search all cpu DR entities, looking for one which is present.  If
+ * the same hw index as before is available, grab that in preference.a
+ * Match the dr-index to a cpu node in the device tree.  Use the reg
+ * (hw index) from the node to query rtas if the cpu is in a stopped
+ * state.
+ */
+static unsigned int find_physical_cpu_to_start(unsigned int old_hwindex)
+{
+	int i, idx;
+	int count = 0;
+	int num_addr_cell, num_size_cell, len;
+	struct device_node *np;
+	unsigned int *ireg, *indexes;
+	int status;
+	int dr_state ;
+	unsigned int best = -1U;
+
+	if ((np = find_path_device("/cpus")) == NULL) {
+		printk(KERN_ERR "Could not find /cpus in device tree!");
+		goto out;
+	}
+	num_addr_cell = prom_n_addr_cells(np); 
+	num_size_cell = prom_n_size_cells(np); 
+
+	indexes = (unsigned int *)get_property(np, "ibm,drc-indexes", &len);
+	if (indexes == NULL) {
+		printk(KERN_INFO "Couldn't find ibm,drc-indexes in /cpus\n");
+		goto out;
+	}
+
+	count = indexes[0];
+	for (i = 0; i < count; i++) {
+		idx = indexes[i+1];
+
+		/* Returns 0 for candidate processor slots */
+		dr_state = check_dr_state(idx); 
+		if (dr_state)
+			continue;
+
+		for (np = of_find_node_by_type(NULL, "cpu");
+		     np; np = of_find_node_by_type(np, "cpu")) {
+			ireg = (unsigned int *)
+				get_property(np, "ibm,my-drc-index", &len);
+
+			if (!ireg || ireg[0] != idx)
+				continue;
+			ireg = (unsigned int *)get_property(np, "reg", &len);
+
+			if (!ireg)
+				continue;
+
+			status = query_cpu_stopped(*ireg);
+			if (status == 0) {
+				best = *ireg;
+				if (best == old_hwindex) {
+					of_node_put(np);
+					goto out;
+				}
+			}
+		}
+	}
+ out:
+	return best;
+}
+
+/**
+ * smp_startup_cpu() - start the given cpu
+ *
+ * At boot time, there is nothing to do.  At run-time, call RTAS with
+ * the appropriate start location, if the cpu is in the RTAS stopped
+ * state.
+ *
+ * Returns:
+ *	0	- failure
+ *	1	- success
+ */
+static inline int __devinit smp_startup_cpu(unsigned int lcpu)
+{
+	int status;
+	extern void (*pseries_secondary_smp_init)(unsigned int cpu);
+	unsigned long start_here = __pa(pseries_secondary_smp_init);
+	unsigned int pcpu;
+
+	/* At boot time the cpus are already spinning in hold
+	 * loops, so nothing to do. */
+ 	if (system_state == SYSTEM_BOOTING)
+		return 1;
+
+	pcpu = find_physical_cpu_to_start(get_hard_smp_processor_id(lcpu));
+	if (pcpu == -1U) {
+		printk(KERN_INFO "No more cpus available, failing\n");
+		return 0;
+	}
+
+	/* Fixup atomic count: it exited inside IRQ handler. */
+	((struct task_struct *)paca[lcpu].xCurrent)->thread_info->preempt_count
+		= 0;
+	/* Fixup SLB round-robin so next segment (kernel) goes in segment 0 */
+	paca[lcpu].xStab_data.next_round_robin = 0;
+
+	/* At boot this is done in prom.c. */
+	paca[lcpu].xHwProcNum = pcpu;
+
+	status = rtas_call(rtas_token("start-cpu"), 3, 1, NULL,
+			   pcpu, start_here, lcpu);
+	if (status != 0) {
+		printk(KERN_ERR "start-cpu failed: %i\n", status);
+		return 0;
+	}
+	return 1;
+}
+
+static inline void look_for_more_cpus(void)
+{
+	int num_addr_cell, num_size_cell, len, i, maxcpus;
+	struct device_node *np;
+	unsigned int *ireg;
+
+	/* Find the property which will tell us about how many CPUs
+	 * we're allowed to have. */
+	if ((np = find_path_device("/rtas")) == NULL) {
+		printk(KERN_ERR "Could not find /rtas in device tree!");
+		return;
+	}
+	num_addr_cell = prom_n_addr_cells(np); 
+	num_size_cell = prom_n_size_cells(np); 
+
+	ireg = (unsigned int *)get_property(np, "ibm,lrdr-capacity", &len);
+	if (ireg == NULL) {
+		printk(KERN_INFO "Couldn't find ibm,lrdr-capacity in /rtas\n");
+		/* FIXME: make sure not marked as lrdr_capable() */
+		return;
+	}
+
+	maxcpus = ireg[num_addr_cell + num_size_cell];
+	/* DRENG need to account for threads here too */
+
+	if (maxcpus > NR_CPUS) {
+		printk(KERN_WARNING
+		       "Partition configured for %d cpus, "
+		       "operating system maximum is %d.\n", maxcpus, NR_CPUS);
+		maxcpus = NR_CPUS;
+	} else
+		printk(KERN_INFO "Partition configured for %d cpus.\n",
+		       maxcpus);
+
+	/* Make those cpus (which might appear later) possible too. */
+	for (i = 0; i < maxcpus; i++)
+		cpu_set(i, cpu_possible_map);
+}
+#else /* ... CONFIG_HOTPLUG_CPU */
+static inline int __devinit smp_startup_cpu(unsigned int lcpu)
+{
+	return 1;
+}
+static inline void look_for_more_cpus(void)
+{
+}
+#endif /* CONFIG_HOTPLUG_CPU */
+
 static void smp_pSeries_kick_cpu(int nr)
 {
 	BUG_ON(nr < 0 || nr >= NR_CPUS);
 
+	if (!smp_startup_cpu(nr))
+		return;
+
 	/* The processor is currently spinning, waiting
 	 * for the xProcStart field to become non-zero
 	 * After we set xProcStart, the processor will
@@ -241,7 +554,7 @@ static void smp_pSeries_kick_cpu(int nr)
 	 */
 	paca[nr].xProcStart = 1;
 }
-#endif
+#endif /* CONFIG_PPC_PSERIES */
 
 static void __init smp_space_timers(unsigned int max_cpus)
 {
@@ -378,6 +691,9 @@ void smp_message_recv(int msg, struct pt
 {
 	switch(msg) {
 	case PPC_MSG_CALL_FUNCTION:
+#ifdef CONFIG_KDB
+	        kdb_smp_regs[smp_processor_id()]=regs;
+#endif
 		smp_call_function_interrupt();
 		break;
 	case PPC_MSG_RESCHEDULE: 
@@ -462,12 +778,9 @@ int smp_call_function (void (*func) (voi
 		       int wait)
 { 
 	struct call_data_struct data;
-	int ret = -1, cpus = num_online_cpus()-1;
+	int ret = -1, cpus;
 	unsigned long timeout;
 
-	if (!cpus)
-		return 0;
-
 	data.func = func;
 	data.info = info;
 	atomic_set(&data.started, 0);
@@ -476,6 +789,14 @@ int smp_call_function (void (*func) (voi
 		atomic_set(&data.finished, 0);
 
 	spin_lock(&call_lock);
+	/* Must grab online cpu count with preempt disabled, otherwise
+	 * it can change. */
+	cpus = num_online_cpus() - 1;
+	if (!cpus) {
+		ret = 0;
+		goto out;
+	}
+
 	call_data = &data;
 	wmb();
 	/* Send a message to all other CPUs and wait for them to respond */
@@ -565,8 +886,31 @@ static void __devinit smp_store_cpu_info
 	per_cpu(pvr, id) = _get_PVR();
 }
 
+static void __init smp_create_idle(unsigned int cpu)
+{
+	struct pt_regs regs;
+	struct task_struct *p;
+
+	/* create a process for the processor */
+	/* only regs.msr is actually used, and 0 is OK for it */
+	memset(&regs, 0, sizeof(struct pt_regs));
+	p = copy_process(CLONE_VM | CLONE_IDLETASK,
+			 0, &regs, 0, NULL, NULL);
+	if (IS_ERR(p))
+		panic("failed fork for CPU %u: %li", cpu, PTR_ERR(p));
+
+	wake_up_forked_process(p);
+	init_idle(p, cpu);
+	unhash_process(p);
+
+	paca[cpu].xCurrent = (u64)p;
+	current_set[cpu] = p->thread_info;
+}
+
 void __init smp_prepare_cpus(unsigned int max_cpus)
 {
+	unsigned int cpu;
+
 	/* 
 	 * setup_cpu may need to be called on the boot cpu. We havent
 	 * spun any cpus up but lets be paranoid.
@@ -593,6 +937,8 @@ void __init smp_prepare_cpus(unsigned in
 	 * number of msecs off until someone does a settimeofday()
 	 */
 	do_gtod.tb_orig_stamp = tb_last_stamp;
+
+	look_for_more_cpus();
 #endif
 
 	max_cpus = smp_ops->probe();
@@ -601,20 +947,31 @@ void __init smp_prepare_cpus(unsigned in
 	__save_cpu_setup();
 
 	smp_space_timers(max_cpus);
+
+	for_each_cpu(cpu)
+		if (cpu != boot_cpuid)
+			smp_create_idle(cpu);
 }
 
 void __devinit smp_prepare_boot_cpu(void)
 {
-	cpu_set(smp_processor_id(), cpu_online_map);
-	/* FIXME: what about cpu_possible()? */
+	BUG_ON(smp_processor_id() != boot_cpuid);
+
+	/* cpu_possible is set up in prom.c */
+	cpu_set(boot_cpuid, cpu_online_map);
+
+	paca[boot_cpuid].xCurrent = (u64)current;
+	current_set[boot_cpuid] = current->thread_info;
 }
 
 int __devinit __cpu_up(unsigned int cpu)
 {
-	struct pt_regs regs;
-	struct task_struct *p;
 	int c;
 
+	/* At boot, don't bother with non-present cpus -JSCHOPP */
+	if (system_state == SYSTEM_BOOTING && !cpu_present_at_boot(cpu))
+		return -ENOENT;
+
 	paca[cpu].prof_counter = 1;
 	paca[cpu].prof_multiplier = 1;
 	paca[cpu].default_decr = tb_ticks_per_jiffy / decr_overclock;
@@ -632,19 +989,9 @@ int __devinit __cpu_up(unsigned int cpu)
 		paca[cpu].xStab_data.real = (unsigned long)__v2a(tmp);
 	}
 
-	/* create a process for the processor */
-	/* only regs.msr is actually used, and 0 is OK for it */
-	memset(&regs, 0, sizeof(struct pt_regs));
-	p = copy_process(CLONE_VM|CLONE_IDLETASK, 0, &regs, 0, NULL, NULL);
-	if (IS_ERR(p))
-		panic("failed fork for CPU %u: %li", cpu, PTR_ERR(p));
-
-	wake_up_forked_process(p);
-	init_idle(p, cpu);
-	unhash_process(p);
-
-	paca[cpu].xCurrent = (u64)p;
-	current_set[cpu] = p->thread_info;
+	/* The information for processor bringup must be written out
+	 * to main store before we release the processor. */
+	mb();
 
 	/* The information for processor bringup must
 	 * be written out to main store before we release
@@ -676,6 +1023,7 @@ int __devinit __cpu_up(unsigned int cpu)
 	return 0;
 }
 
+extern unsigned int default_distrib_server;
 /* Activate a secondary processor. */
 int __devinit start_secondary(void *unused)
 {
@@ -698,6 +1046,15 @@ int __devinit start_secondary(void *unus
 	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
 		vpa_init(cpu); 
 	}
+
+#ifdef CONFIG_IRQ_ALL_CPUS
+	/* Put the calling processor into the GIQ.  This is really only 
+	 * necessary from a secondary thread as the OF start-cpu interface
+	 * performs this function for us on primary threads.
+	 */
+	/* TODO: 9005 is #defined in rtas-proc.c -- move to a header */
+	rtas_set_indicator(9005, default_distrib_server, 1);
+#endif
 #endif
 
 	local_irq_enable();
diff -purN linux-2.5/arch/ppc64/kernel/vio.c linuxppc64-2.5/arch/ppc64/kernel/vio.c
--- linux-2.5/arch/ppc64/kernel/vio.c	2004-03-22 10:44:59.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/vio.c	2004-03-23 04:57:16.000000000 +0000
@@ -25,7 +25,6 @@
 #include <asm/ppcdebug.h>
 #include <asm/vio.h>
 #include <asm/hvcall.h>
-#include "open_pic.h"
 
 #define DBGENTER() pr_debug("%s entered\n", __FUNCTION__)
 
@@ -255,7 +254,7 @@ struct vio_dev * __devinit vio_register_
 			printk(KERN_ERR "Unable to allocate interrupt "
 			       "number for %s\n", of_node->full_name);
 		} else
-			viodev->irq = openpic_to_irq(virq);
+			viodev->irq = irq_offset_up(virq);
 	}
 
 	/* init generic 'struct device' fields: */
diff -purN linux-2.5/arch/ppc64/kernel/vioconfig.c linuxppc64-2.5/arch/ppc64/kernel/vioconfig.c
--- linux-2.5/arch/ppc64/kernel/vioconfig.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/vioconfig.c	2004-03-16 20:52:15.000000000 +0000
@@ -0,0 +1,89 @@
+/* ------------------------------------------------------------
+ * vioconfig.c
+ * (C) Copyright IBM Corporation 1994, 2004
+ * Author: Dave Boutcher (sleddog@us.ibm.com)
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or
+ * (at your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307
+ * USA
+ *
+ * ------------------------------------------------------------
+ * proc file to display configuration information retrieved froma vio
+ * host
+ */
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/proc_fs.h>
+#include <asm/vio.h>
+
+static struct proc_dir_entry *vio_config;
+
+extern int ibmvscsi_get_host_config(struct vio_dev *vdev,
+				    unsigned char *buffer, 
+				    int length);
+
+static int proc_read(char *buf, char **start, off_t offset,
+		     int blen, int *eof, void *data)
+{
+	struct device_node *node_vroot, *of_node;
+	struct vio_dev * vdev;
+	
+	node_vroot = find_devices("vdevice");
+	if ((node_vroot == NULL) || (node_vroot->child == NULL)) {
+		/* this machine doesn't do virtual IO, and that's ok */
+		return 0;
+	}
+
+	/*
+	 * loop through all vdevices
+	 */
+	for (of_node = node_vroot->child;
+			of_node != NULL;
+			of_node = of_node->sibling) {
+		/* see if this is a vscsi device */
+		if ((of_node->type != NULL) &&
+		    (strncmp(of_node->type, "vscsi", 5) == 0)) {
+			/* see if we get a vdevice for that */
+			vdev = vio_find_node(of_node);
+			
+			/* Finally see if we get host config data */
+			if (ibmvscsi_get_host_config(vdev, buf, blen) == 0) {
+				break;
+			}
+		}
+	}
+
+	*eof = 1;
+	return strlen(buf);
+}
+
+int __init vioconfig_module_init(void)
+{
+	vio_config = create_proc_read_entry("vioconfig",
+					    S_IFREG | S_IRUSR,
+					    NULL,
+					    proc_read,
+					    NULL);
+	if (!vio_config)
+		return -1;
+	return 0;
+}
+
+void __exit vioconfig_module_exit(void)
+{
+	remove_proc_entry("vioconfig", vio_config->parent);
+}	
+
+module_init(vioconfig_module_init);
+module_exit(vioconfig_module_exit);
diff -purN linux-2.5/arch/ppc64/kernel/vmlinux.lds.S linuxppc64-2.5/arch/ppc64/kernel/vmlinux.lds.S
--- linux-2.5/arch/ppc64/kernel/vmlinux.lds.S	2004-01-19 06:28:28.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/vmlinux.lds.S	2004-03-05 13:02:02.000000000 +0000
@@ -84,6 +84,10 @@ SECTIONS
 	__con_initcall_end = .;
 	}
 
+  __kdb_initcall_start = .;
+  .kdb_initcall.init : { *(.kdb_initcall.init) }
+  __kdb_initcall_end = .;
+
   SECURITY_INIT
 
   . = ALIGN(4096);
diff -purN linux-2.5/arch/ppc64/kernel/vpurr.c linuxppc64-2.5/arch/ppc64/kernel/vpurr.c
--- linux-2.5/arch/ppc64/kernel/vpurr.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/vpurr.c	2004-03-20 10:56:41.000000000 +0000
@@ -0,0 +1,101 @@
+/*
+ * PPC64 Cpu util performace monitoring.
+ *
+ * Manish Ahuja mahuja@us.ibm.com
+ *    Copyright (c) 2004 Manish Ahuja IBM CORP.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ *
+ *	This file will also report many of the perf values for 2.6 
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/proc_fs.h>
+#include <linux/init.h>
+#include <asm/uaccess.h>
+#include <asm/hvcall.h>
+#include <asm/cputable.h>
+#include "vpurr.h"
+
+#define SAMPLE_TICK HZ
+
+DEFINE_PER_CPU(struct cpu_util_store, cpu_util_sampler);
+
+static void collect_startpurr(int cpu);
+
+/*
+ * This is a timer handler.  There is on per CPU. It gets scheduled
+ * every SAMPLE_TICK ticks.
+ */
+
+static void util_timer_func(unsigned long data)
+{
+	struct cpu_util_store * cus = &__get_cpu_var(cpu_util_sampler);
+	struct timer_list *tl = &cus->cpu_util_timer;
+
+	cus->current_purr = mfspr(PURR);
+	cus->tb = mftb();
+
+	/*printk(KERN_INFO "PURR VAL %ld %lld %lld\n", data, cus->current_purr, cus->tb);*/
+
+	mod_timer(tl, jiffies + SAMPLE_TICK);
+}
+
+/*
+ * One time function that gets called when all the cpu's are online 
+ * to start collection. It adds the timer to each cpu on the system.
+ * start_purr is collected during smp_init time in __cpu_up code
+ */
+
+static void start_util_timer(int cpu)
+{
+	struct cpu_util_store * cus = &per_cpu(cpu_util_sampler, cpu);
+	struct timer_list *tl = &cus->cpu_util_timer;
+
+	if (tl->function != NULL)
+		return;
+
+	init_timer(tl);
+	tl->expires = jiffies + SAMPLE_TICK;
+	tl->data = cpu;
+	tl->function = util_timer_func;
+	add_timer_on(tl, cpu);
+}
+
+static int __init cpu_util_init(void)
+{
+	int cpu;
+
+	if (PVR_VER(systemcfg->processor) == PV_POWER5) {
+		for_each_online_cpu(cpu){
+			collect_startpurr(cpu);
+			start_util_timer(cpu);
+		}
+	}
+
+	return 0;
+}
+
+__initcall(cpu_util_init);
+
+/* Collect starting purr, to collect starting purr from the
+ * cpu in question, we make a call to get that cpu and then run
+ */
+
+static void collect_startpurr(int cpu)
+{
+	struct cpu_util_store * cus = &per_cpu(cpu_util_sampler, cpu);	
+
+	set_cpus_allowed(current, cpumask_of_cpu(cpu));
+	BUG_ON(smp_processor_id() != cpu);
+
+	cus->start_purr = mfspr(PURR);
+	cus->tb = mftb();
+}
+
diff -purN linux-2.5/arch/ppc64/kernel/vpurr.h linuxppc64-2.5/arch/ppc64/kernel/vpurr.h
--- linux-2.5/arch/ppc64/kernel/vpurr.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/vpurr.h	2004-03-20 10:56:41.000000000 +0000
@@ -0,0 +1,26 @@
+/*
+ *    Copyright (c) 2004 Manish Ahuja <mahuja@us.ibm.com> IBM CORP.
+ *
+ *    Module name: vpurr.h
+ *
+ *    Description:
+ *      Architecture- / platform-specific boot-time initialization code for
+ *      tracking purr utilization and other performace features in coming 
+ * 	releases for splpar/smt machines.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+#define PURR 309
+
+DECLARE_PER_CPU(struct cpu_util_store, cpu_util_sampler);
+
+struct cpu_util_store {
+        struct timer_list cpu_util_timer;
+        u64 start_purr;
+        u64 current_purr;
+        u64 tb;
+};
diff -purN linux-2.5/arch/ppc64/kernel/xics.c linuxppc64-2.5/arch/ppc64/kernel/xics.c
--- linux-2.5/arch/ppc64/kernel/xics.c	2004-03-16 11:30:37.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/xics.c	2004-03-22 01:51:17.000000000 +0000
@@ -19,6 +19,7 @@
 #include <linux/init.h>
 #include <linux/gfp.h>
 #include <linux/radix-tree.h>
+#include <linux/cpu.h>
 #include <asm/prom.h>
 #include <asm/io.h>
 #include <asm/pgtable.h>
@@ -58,7 +59,6 @@ struct hw_interrupt_type xics_8259_pic =
 static struct radix_tree_root irq_map = RADIX_TREE_INIT(GFP_KERNEL);
 
 #define XICS_IPI		2
-#define XICS_IRQ_OFFSET		0x10
 #define XICS_IRQ_SPURIOUS	0
 
 /* Want a priority other than 0.  Various HW issues require this. */
@@ -91,7 +91,8 @@ static struct xics_ipl *xics_per_cpu[NR_
 static int xics_irq_8259_cascade = 0;
 static int xics_irq_8259_cascade_real = 0;
 static unsigned int default_server = 0xFF;
-static unsigned int default_distrib_server = 0;
+/* also referenced in smp.c... */
+unsigned int default_distrib_server = 0;
 
 /*
  * XICS only has a single IPI, so encode the messages per CPU
@@ -216,7 +217,7 @@ xics_ops pSeriesLP_ops = {
 
 static unsigned int xics_startup(unsigned int virq)
 {
-	virq -= XICS_IRQ_OFFSET;
+	virq = irq_offset_down(virq);
 	if (radix_tree_insert(&irq_map, virt_irq_to_real(virq),
 			      &virt_irq_to_real_map[virq]) == -ENOMEM)
 		printk(KERN_CRIT "Out of memory creating real -> virtual"
@@ -235,26 +236,47 @@ static unsigned int real_irq_to_virt(uns
 	return ptr - virt_irq_to_real_map;
 }
 
+static int get_irq_server(unsigned int irq)
+{
+	cpumask_t cpumask = irq_affinity[irq];
+	cpumask_t allcpus = CPU_MASK_ALL;
+	cpumask_t tmp = CPU_MASK_NONE;
+	unsigned int server;
+	
+#ifdef CONFIG_IRQ_ALL_CPUS
+	/* For the moment only implement delivery to all cpus or one cpu */
+	if (smp_threads_ready) {
+		if (cpus_equal(cpumask, allcpus)) {
+			server = default_distrib_server;
+		} else {
+			cpus_and(tmp, cpu_online_map, cpumask);
+
+			if (cpus_empty(tmp))
+				server = default_distrib_server;
+			else
+				server = get_hard_smp_processor_id(first_cpu(tmp));
+		}
+	} else {
+		server = default_server;
+	}
+#else
+	server = default_server;
+#endif
+	return server;
+
+}
+
 static void xics_enable_irq(unsigned int virq)
 {
 	unsigned int irq;
 	long call_status;
 	unsigned int server;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = virt_irq_to_real(irq_offset_down(virq));
 	if (irq == XICS_IPI)
 		return;
 
-#ifdef CONFIG_IRQ_ALL_CPUS
-	if (smp_threads_ready)
-		server = default_distrib_server;
-	else
-		server = default_server;
-#else
-	server = default_server;
-#endif
-
+	server = get_irq_server(virq);
 	call_status = rtas_call(ibm_set_xive, 3, 1, NULL, irq, server,
 				DEFAULT_PRIORITY);
 	if (call_status != 0) {
@@ -275,6 +297,7 @@ static void xics_enable_irq(unsigned int
 static void xics_disable_real_irq(unsigned int irq)
 {
 	long call_status;
+	unsigned int server;
 
 	if (irq == XICS_IPI)
 		return;
@@ -286,9 +309,9 @@ static void xics_disable_real_irq(unsign
 		return;
 	}
 
+	server = get_irq_server(irq);
 	/* Have to set XIVE to 0xff to be able to remove a slot */
-	call_status = rtas_call(ibm_set_xive, 3, 1, NULL, irq, default_server,
-				0xff);
+	call_status = rtas_call(ibm_set_xive, 3, 1, NULL, irq, server, 0xff);
 	if (call_status != 0) {
 		printk(KERN_ERR "xics_disable_irq: irq=%x: ibm_set_xive(0xff)"
 		       " returned %lx\n", irq, call_status);
@@ -300,25 +323,25 @@ static void xics_disable_irq(unsigned in
 {
 	unsigned int irq;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = virt_irq_to_real(irq_offset_down(virq));
 	xics_disable_real_irq(irq);
 }
 
-static void xics_end_irq(unsigned int	irq)
+static void xics_end_irq(unsigned int irq)
 {
 	int cpu = smp_processor_id();
 
 	iosync();
-	ops->xirr_info_set(cpu, ((0xff<<24) |
-				 (virt_irq_to_real(irq-XICS_IRQ_OFFSET))));
+	ops->xirr_info_set(cpu, ((0xff << 24) |
+				 (virt_irq_to_real(irq_offset_down(irq)))));
+
 }
 
 static void xics_mask_and_ack_irq(unsigned int irq)
 {
 	int cpu = smp_processor_id();
 
-	if (irq < XICS_IRQ_OFFSET) {
+	if (irq < irq_offset_value()) {
 		i8259_pic.ack(irq);
 		iosync();
 		ops->xirr_info_set(cpu, ((0xff<<24) |
@@ -344,7 +367,8 @@ int xics_get_irq(struct pt_regs *regs)
 		irq = i8259_irq(cpu);
 		if (irq == -1) {
 			/* Spurious cascaded interrupt.  Still must ack xics */
-                        xics_end_irq(XICS_IRQ_OFFSET + xics_irq_8259_cascade);
+			xics_end_irq(irq_offset_up(xics_irq_8259_cascade));
+
 			irq = -1;
 		}
 	} else if (vec == XICS_IRQ_SPURIOUS) {
@@ -358,7 +382,7 @@ int xics_get_irq(struct pt_regs *regs)
 			       " disabling it.\n", vec);
 			xics_disable_real_irq(vec);
 		} else
-			irq += XICS_IRQ_OFFSET;
+			irq = irq_offset_up(irq);
 	}
 	return irq;
 }
@@ -372,6 +396,11 @@ irqreturn_t xics_ipi_action(int irq, voi
 	int cpu = smp_processor_id();
 
 	ops->qirr_info(cpu, 0xff);
+	if (cpu_is_offline(cpu))
+		printk("xics_ipi_action %08lx on %i\n",
+		       xics_ipi_message[cpu].value,
+		       cpu);
+
 	while (xics_ipi_message[cpu].value) {
 		if (test_and_clear_bit(PPC_MSG_CALL_FUNCTION,
 				       &xics_ipi_message[cpu].value)) {
@@ -514,6 +543,9 @@ nextnode:
 	if (systemcfg->platform == PLATFORM_PSERIES) {
 #ifdef CONFIG_SMP
 		for_each_cpu(i) {
+			/* FIXME: Do this dynamically! --RR */
+			if (!cpu_present_at_boot(i))
+				continue;
 			xics_per_cpu[i] = __ioremap((ulong)inodes[get_hard_smp_processor_id(i)].addr, 
 						    (ulong)inodes[get_hard_smp_processor_id(i)].size,
 						    _PAGE_NO_CACHE);
@@ -534,9 +566,9 @@ nextnode:
 	xics_8259_pic.enable = i8259_pic.enable;
 	xics_8259_pic.disable = i8259_pic.disable;
 	for (i = 0; i < 16; ++i)
-		irq_desc[i].handler = &xics_8259_pic;
+		get_irq_desc(i)->handler = &xics_8259_pic;
 	for (; i < NR_IRQS; ++i)
-		irq_desc[i].handler = &xics_pic;
+		get_irq_desc(i)->handler = &xics_pic;
 
 	ops->cppr_info(boot_cpuid, 0xff);
 	iosync();
@@ -552,7 +584,7 @@ static int __init xics_setup_i8259(void)
 {
 	if (naca->interrupt_controller == IC_PPC_XIC &&
 	    xics_irq_8259_cascade != -1) {
-		if (request_irq(xics_irq_8259_cascade + XICS_IRQ_OFFSET,
+		if (request_irq(irq_offset_up(xics_irq_8259_cascade),
 				no_action, 0, "8259 cascade", 0))
 			printk(KERN_ERR "xics_init_IRQ: couldn't get 8259 cascade\n");
 		i8259_init();
@@ -567,36 +599,31 @@ void xics_request_IPIs(void)
 	virt_irq_to_real_map[XICS_IPI] = XICS_IPI;
 
 	/* IPIs are marked SA_INTERRUPT as they must run with irqs disabled */
-	request_irq(XICS_IPI + XICS_IRQ_OFFSET, xics_ipi_action, SA_INTERRUPT,
+	request_irq(irq_offset_up(XICS_IPI), xics_ipi_action, SA_INTERRUPT,
 		    "IPI", 0);
-	irq_desc[XICS_IPI+XICS_IRQ_OFFSET].status |= IRQ_PER_CPU;
+	get_irq_desc(irq_offset_up(XICS_IPI))->status |= IRQ_PER_CPU;
 }
 #endif
 
 static void xics_set_affinity(unsigned int virq, cpumask_t cpumask)
 {
-        irq_desc_t *desc = irq_desc + virq;
 	unsigned int irq;
-	unsigned long flags;
 	long status;
 	unsigned long xics_status[2];
 	unsigned long newmask;
 	cpumask_t allcpus = CPU_MASK_ALL;
 	cpumask_t tmp = CPU_MASK_NONE;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = virt_irq_to_real(irq_offset_down(virq));
 	if (irq == XICS_IPI)
 		return;
 
-        spin_lock_irqsave(&desc->lock, flags);
-
 	status = rtas_call(ibm_get_xive, 1, 3, (void *)&xics_status, irq);
 
 	if (status) {
 		printk(KERN_ERR "xics_set_affinity: irq=%d ibm,get-xive "
 		       "returns %ld\n", irq, status);
-		goto out;
+		return;
 	}
 
 	/* For the moment only implement delivery to all cpus or one cpu */
@@ -605,8 +632,8 @@ static void xics_set_affinity(unsigned i
 	} else {
 		cpus_and(tmp, cpu_online_map, cpumask);
 		if (cpus_empty(tmp))
-			goto out;
-		newmask = get_hard_smp_processor_id(first_cpu(cpumask));
+			return;
+		newmask = get_hard_smp_processor_id(first_cpu(tmp));
 	}
 
 	status = rtas_call(ibm_set_xive, 3, 1, NULL,
@@ -615,9 +642,86 @@ static void xics_set_affinity(unsigned i
 	if (status) {
 		printk(KERN_ERR "xics_set_affinity irq=%d ibm,set-xive "
 		       "returns %ld\n", irq, status);
-		goto out;
+		return;
+	}
+}
+
+#ifdef CONFIG_HOTPLUG_CPU
+
+/* Interrupts are disabled. */
+void xics_migrate_irqs_away(void)
+{
+	int set_indicator = rtas_token("set-indicator");
+	const unsigned long giqs = 9005UL; /* Global Interrupt Queue Server */
+	unsigned long status = 0;
+	unsigned int irq, cpu = smp_processor_id();
+	unsigned long xics_status[2];
+	unsigned long flags;
+
+	BUG_ON(set_indicator == RTAS_UNKNOWN_SERVICE);
+
+	/* Reject any interrupt that was queued to us... */
+	ops->cppr_info(cpu, 0);
+	iosync();
+
+	/* Refuse any new interrupts... */
+	rtas_call(set_indicator, 3, 1, &status, giqs,
+		  hard_smp_processor_id(), 0UL);
+	WARN_ON(status != 0);
+
+	/* Allow IPIs again... */
+	ops->cppr_info(cpu, DEFAULT_PRIORITY);
+	iosync();
+
+	printk(KERN_WARNING "HOTPLUG: Migrating IRQs away\n");
+	for_each_irq(irq) {
+		irq_desc_t *desc = get_irq_desc(irq);
+
+		/* We need to get IPIs still. */
+		if (irq_offset_down(irq) == XICS_IPI)
+			continue;
+
+		/* We only need to migrate enabled IRQS */
+		if (desc == NULL || desc->handler == NULL
+		    || desc->action == NULL
+		    || desc->handler->set_affinity == NULL)
+			continue;
+
+		spin_lock_irqsave(&desc->lock, flags);
+
+		status = rtas_call(ibm_get_xive, 1, 3, (void *)&xics_status,
+				   irq);
+		if (status) {
+			printk(KERN_ERR "migrate_irqs_away: irq=%d "
+					"ibm,get-xive returns %ld\n",
+					irq, status);
+			goto unlock;
+		}
+
+		/* 
+		 * We only support delivery to all cpus or to one cpu.
+		 * The irq has to be migrated only in the single cpu
+		 * case.
+		 */
+		if (xics_status[0] != get_hard_smp_processor_id(cpu))
+			goto unlock;
+
+		printk(KERN_WARNING "IRQ %d affinity broken off cpu %u\n",
+		       irq, cpu);
+
+		/* Reset affinity to all cpus */
+		xics_status[0] = default_distrib_server;
+
+		status = rtas_call(ibm_set_xive, 3, 1, NULL,
+				irq, xics_status[0], xics_status[1]);
+		if (status)
+			printk(KERN_ERR "migrate_irqs_away irq=%d "
+					"ibm,set-xive returns %ld\n",
+					irq, status);
+
+unlock:
+		spin_unlock_irqrestore(&desc->lock, flags);
 	}
 
-out:
-        spin_unlock_irqrestore(&desc->lock, flags);
 }
+#endif
diff -purN linux-2.5/arch/ppc64/lib/Makefile linuxppc64-2.5/arch/ppc64/lib/Makefile
--- linux-2.5/arch/ppc64/lib/Makefile	2003-06-10 13:09:57.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/lib/Makefile	2004-03-19 03:01:36.000000000 +0000
@@ -4,3 +4,6 @@
 
 lib-y := checksum.o dec_and_lock.o string.o strcase.o
 lib-y += copypage.o memcpy.o copyuser.o
+
+lib-$(CONFIG_PPC_ISERIES) += locks.o
+lib-$(CONFIG_PPC_SPLPAR)  += locks.o
diff -purN linux-2.5/arch/ppc64/lib/locks.c linuxppc64-2.5/arch/ppc64/lib/locks.c
--- linux-2.5/arch/ppc64/lib/locks.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/lib/locks.c	2004-03-19 02:52:48.000000000 +0000
@@ -0,0 +1,90 @@
+/*
+ * Slow paths for spin and read/write lock operations.
+ *
+ * Copyright (C) 2001 Paul Mackerras <paulus@au.ibm.com>, IBM
+ * Copyright (C) 2001 Anton Blanchard <anton@au.ibm.com>, IBM
+ * Copyright (C) 2002 Dave Engebretsen <engebret@us.ibm.com>, IBM
+ *   Rework to support virtual processors
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <asm/hvcall.h>
+#include <asm/iSeries/HvCall.h>
+
+/*
+ * On a system with shared processors (that is, where a physical
+ * processor is multiplexed between several virtual processors),
+ * there is no point spinning on a lock if the holder of the lock
+ * isn't currently scheduled on a physical processor.  Instead
+ * we detect this situation and ask the hypervisor to give the
+ * rest of our timeslice to the lock holder.
+ */
+
+/* waiting for a spinlock... */
+void __spin_yield(spinlock_t *lock)
+{
+	unsigned int lock_value, holder_cpu, yield_count;
+	struct paca_struct *holder_paca;
+
+	lock_value = lock->lock;
+	if (lock_value == 0)
+		return;
+	holder_cpu = lock_value & 0xffff;
+	BUG_ON(holder_cpu >= NR_CPUS);
+	holder_paca = &paca[holder_cpu];
+	yield_count = holder_paca->xLpPaca.xYieldCount;
+	if ((yield_count & 1) == 0)
+		return;		/* virtual cpu is currently running */
+	rmb();
+	if (lock->lock != lock_value)
+		return;		/* something has changed */
+#ifdef CONFIG_PPC_ISERIES
+	HvCall2(HvCallBaseYieldProcessor, HvCall_YieldToProc,
+		((u64)holder_cpu << 32) | yield_count);
+#else
+	plpar_hcall_norets(H_CONFER, holder_cpu, yield_count);
+#endif
+}
+
+EXPORT_SYMBOL(__spin_yield);
+
+/*
+ * Waiting for a read lock or a write lock on a rwlock...
+ * This turns out to be the same for read and write locks, since
+ * we only know the holder if it is write-locked.
+ */
+void __rw_yield(rwlock_t *rw)
+{
+	int lock_value;
+	unsigned int holder_cpu, yield_count;
+	struct paca_struct *holder_paca;
+
+	lock_value = rw->lock;
+	if (lock_value >= 0)
+		return;		/* no write lock at present */
+	holder_cpu = lock_value & 0xffff;
+	BUG_ON(holder_cpu >= NR_CPUS);
+	holder_paca = &paca[holder_cpu];
+	yield_count = holder_paca->xLpPaca.xYieldCount;
+	if ((yield_count & 1) == 0)
+		return;		/* virtual cpu is currently running */
+	rmb();
+	if (rw->lock != lock_value)
+		return;		/* something has changed */
+#ifdef CONFIG_PPC_ISERIES
+	HvCall2(HvCallBaseYieldProcessor, HvCall_YieldToProc,
+		((u64)holder_cpu << 32) | yield_count);
+#else
+	plpar_hcall_norets(H_CONFER, holder_cpu, yield_count);
+#endif
+}
+
+EXPORT_SYMBOL(__rw_yield);
diff -purN linux-2.5/arch/ppc64/mm/numa.c linuxppc64-2.5/arch/ppc64/mm/numa.c
--- linux-2.5/arch/ppc64/mm/numa.c	2004-03-19 05:59:29.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/mm/numa.c	2004-03-21 00:59:12.000000000 +0000
@@ -133,6 +133,7 @@ static int __init parse_numa_properties(
 		unsigned long size = 0;
 		int numa_domain;
 		int ranges;
+		int propsize;
 
 		tmp1 = (int *)get_property(memory, "reg", NULL);
 		if (!tmp1)
@@ -159,10 +160,21 @@ new_range:
 		if ((start + size) > MAX_MEMORY)
 			BUG();
 
+		/* Some versions of OF sometimes have an empty property for
+		 * associativity, so we need to get the size too.
+		 */
 		tmp2 = (int *)get_property(memory, "ibm,associativity",
-					   NULL);
+					   &propsize);
 		if (!tmp2)
 			continue;
+
+		if (!propsize) {
+			printk(KERN_INFO "Buggy OF? Empty ibm,associativity "
+			       "property for %s. Disabling NUMA.\n",
+			       memory->full_name);
+			goto err;
+		}
+
 		numa_domain = tmp2[depth];
 
 		/* FIXME */
diff -purN linux-2.5/arch/ppc64/xmon/start.c linuxppc64-2.5/arch/ppc64/xmon/start.c
--- linux-2.5/arch/ppc64/xmon/start.c	2004-02-14 11:48:01.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/xmon/start.c	2004-03-19 21:49:51.000000000 +0000
@@ -19,6 +19,7 @@
 #include <asm/processor.h>
 #include <asm/udbg.h>
 #include <asm/system.h>
+#include "nonstdio.h"
 
 #ifdef CONFIG_MAGIC_SYSRQ
 
@@ -63,9 +64,8 @@ xmon_read_poll(void)
 	return udbg_getc_poll();
 }
  
-void *xmon_stdin;
-void *xmon_stdout;
-void *xmon_stderr;
+FILE *xmon_stdin;
+FILE *xmon_stdout;
 
 int
 xmon_putc(int c, void *f)
diff -purN linux-2.5/include/asm-ppc/unistd.h linuxppc64-2.5/include/asm-ppc/unistd.h
--- linux-2.5/include/asm-ppc/unistd.h	2004-03-16 10:29:21.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc/unistd.h	2004-03-17 00:47:00.000000000 +0000
@@ -280,6 +280,7 @@
 		register unsigned long __sc_5  __asm__ ("r5");		\
 		register unsigned long __sc_6  __asm__ ("r6");		\
 		register unsigned long __sc_7  __asm__ ("r7");		\
+		register unsigned long __sc_8  __asm__ ("r8");		\
 									\
 		__sc_loadargs_##nr(name, args);				\
 		__asm__ __volatile__					\
@@ -288,10 +289,10 @@
 			: "=&r" (__sc_0),				\
 			  "=&r" (__sc_3),  "=&r" (__sc_4),		\
 			  "=&r" (__sc_5),  "=&r" (__sc_6),		\
-			  "=&r" (__sc_7)				\
+			  "=&r" (__sc_7),  "=&r" (__sc_8)		\
 			: __sc_asm_input_##nr				\
 			: "cr0", "ctr", "memory",			\
-			  "r8", "r9", "r10","r11", "r12");		\
+			  "r9", "r10","r11", "r12");			\
 		__sc_ret = __sc_3;					\
 		__sc_err = __sc_0;					\
 	}								\
@@ -319,6 +320,9 @@
 #define __sc_loadargs_5(name, arg1, arg2, arg3, arg4, arg5)		\
 	__sc_loadargs_4(name, arg1, arg2, arg3, arg4);			\
 	__sc_7 = (unsigned long) (arg5)
+#define __sc_loadargs_6(name, arg1, arg2, arg3, arg4, arg5, arg6)	\
+	__sc_loadargs_5(name, arg1, arg2, arg3, arg4, arg5);		\
+	__sc_8 = (unsigned long) (arg6)
 
 #define __sc_asm_input_0 "0" (__sc_0)
 #define __sc_asm_input_1 __sc_asm_input_0, "1" (__sc_3)
@@ -326,6 +330,7 @@
 #define __sc_asm_input_3 __sc_asm_input_2, "3" (__sc_5)
 #define __sc_asm_input_4 __sc_asm_input_3, "4" (__sc_6)
 #define __sc_asm_input_5 __sc_asm_input_4, "5" (__sc_7)
+#define __sc_asm_input_6 __sc_asm_input_5, "6" (__sc_8)
 
 #define _syscall0(type,name)						\
 type name(void)								\
@@ -363,6 +368,12 @@ type name(type1 arg1, type2 arg2, type3 
 	__syscall_nr(5, type, name, arg1, arg2, arg3, arg4, arg5);	\
 }
 
+#define _syscall6(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,type5,arg5,type6,arg6) \
+type name(type1 arg1, type2 arg2, type3 arg3, type4 arg4, type5 arg5, type6 arg6) \
+{									\
+	__syscall_nr(6, type, name, arg1, arg2, arg3, arg4, arg5, arg6); \
+}
+
 #ifdef __KERNEL__
 
 #define __NR__exit __NR_exit
diff -purN linux-2.5/include/asm-ppc64/eeh.h linuxppc64-2.5/include/asm-ppc64/eeh.h
--- linux-2.5/include/asm-ppc64/eeh.h	2004-03-16 11:30:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/eeh.h	2004-03-23 18:52:35.000000000 +0000
@@ -199,74 +199,71 @@ static inline void eeh_memcpy_toio(void 
 	memcpy(vdest, src, n);
 }
 
-/* The I/O macros must handle ISA ports as well as PCI I/O bars.
- * ISA does not implement EEH and ISA may not exist in the system.
- * For PCI we check for EEH failures.
- */
-#define _IO_IS_ISA(port) ((port) < 0x10000)
-#define _IO_HAS_ISA_BUS	(isa_io_base != 0)
+#define MAX_ISA_PORT 0x10000
+extern unsigned long io_page_mask;
+#define _IO_IS_VALID(port) ((port) >= MAX_ISA_PORT || (1 << (port>>PAGE_SHIFT)) & io_page_mask)
 
 static inline u8 eeh_inb(unsigned long port) {
 	u8 val;
-	if (_IO_IS_ISA(port) && !_IO_HAS_ISA_BUS)
+	if (!_IO_IS_VALID(port))
 		return ~0;
 	val = in_8((u8 *)(port+pci_io_base));
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR(val, u8))
+	if (EEH_POSSIBLE_IO_ERROR(val, u8))
 		return eeh_check_failure((void*)(port), val);
 	return val;
 }
 
 static inline void eeh_outb(u8 val, unsigned long port) {
-	if (!_IO_IS_ISA(port) || _IO_HAS_ISA_BUS)
+	if (_IO_IS_VALID(port))
 		return out_8((u8 *)(port+pci_io_base), val);
 }
 
 static inline u16 eeh_inw(unsigned long port) {
 	u16 val;
-	if (_IO_IS_ISA(port) && !_IO_HAS_ISA_BUS)
+	if (!_IO_IS_VALID(port))
 		return ~0;
 	val = in_le16((u16 *)(port+pci_io_base));
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR(val, u16))
+	if (EEH_POSSIBLE_IO_ERROR(val, u16))
 		return eeh_check_failure((void*)(port), val);
 	return val;
 }
 
 static inline void eeh_outw(u16 val, unsigned long port) {
-	if (!_IO_IS_ISA(port) || _IO_HAS_ISA_BUS)
+	if (_IO_IS_VALID(port))
 		return out_le16((u16 *)(port+pci_io_base), val);
 }
 
 static inline u32 eeh_inl(unsigned long port) {
 	u32 val;
-	if (_IO_IS_ISA(port) && !_IO_HAS_ISA_BUS)
+	if (!_IO_IS_VALID(port))
 		return ~0;
 	val = in_le32((u32 *)(port+pci_io_base));
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR(val, u32))
+	if (EEH_POSSIBLE_IO_ERROR(val, u32))
 		return eeh_check_failure((void*)(port), val);
 	return val;
 }
 
 static inline void eeh_outl(u32 val, unsigned long port) {
-	if (!_IO_IS_ISA(port) || _IO_HAS_ISA_BUS)
+	if (_IO_IS_VALID(port))
 		return out_le32((u32 *)(port+pci_io_base), val);
 }
 
 /* in-string eeh macros */
 static inline void eeh_insb(unsigned long port, void * buf, int ns) {
 	_insb((u8 *)(port+pci_io_base), buf, ns);
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR((*(((u8*)buf)+ns-1)), u8))
+	if (EEH_POSSIBLE_IO_ERROR((*(((u8*)buf)+ns-1)), u8))
 		eeh_check_failure((void*)(port), *(u8*)buf);
 }
 
 static inline void eeh_insw_ns(unsigned long port, void * buf, int ns) {
 	_insw_ns((u16 *)(port+pci_io_base), buf, ns);
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR((*(((u16*)buf)+ns-1)), u16))
+	if (EEH_POSSIBLE_IO_ERROR((*(((u16*)buf)+ns-1)), u16))
 		eeh_check_failure((void*)(port), *(u16*)buf);
 }
 
 static inline void eeh_insl_ns(unsigned long port, void * buf, int nl) {
 	_insl_ns((u32 *)(port+pci_io_base), buf, nl);
-	if (!_IO_IS_ISA(port) && EEH_POSSIBLE_IO_ERROR((*(((u32*)buf)+nl-1)), u32))
+	if (EEH_POSSIBLE_IO_ERROR((*(((u32*)buf)+nl-1)), u32))
 		eeh_check_failure((void*)(port), *(u32*)buf);
 }
 
diff -purN linux-2.5/include/asm-ppc64/hardirq.h linuxppc64-2.5/include/asm-ppc64/hardirq.h
--- linux-2.5/include/asm-ppc64/hardirq.h	2003-09-11 04:07:58.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/hardirq.h	2004-02-18 06:28:00.000000000 +0000
@@ -80,7 +80,8 @@ typedef struct {
 
 #define irq_enter()		(preempt_count() += HARDIRQ_OFFSET)
 
-#ifdef CONFIG_PREEMPT
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_DEBUG_SPINLOCK_SLEEP)
+#include <linux/smp_lock.h>
 # define in_atomic()	((preempt_count() & ~PREEMPT_ACTIVE) != kernel_locked())
 # define IRQ_EXIT_OFFSET (HARDIRQ_OFFSET-1)
 #else
diff -purN linux-2.5/include/asm-ppc64/hw_irq.h linuxppc64-2.5/include/asm-ppc64/hw_irq.h
--- linux-2.5/include/asm-ppc64/hw_irq.h	2004-01-21 01:50:56.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/hw_irq.h	2004-01-24 06:44:51.000000000 +0000
@@ -75,9 +75,24 @@ static inline void __do_save_and_cli(uns
 
 #endif /* CONFIG_PPC_ISERIES */
 
-#define mask_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->disable) irq_desc[irq].handler->disable(irq);})
-#define unmask_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->enable) irq_desc[irq].handler->enable(irq);})
-#define ack_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->ack) irq_desc[irq].handler->ack(irq);})
+#define mask_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->disable)	\
+			desc->handler->disable(irq);		\
+	})
+#define unmask_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->enable)	\
+			desc->handler->enable(irq);		\
+	})
+#define ack_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->ack)	\
+			desc->handler->ack(irq);		\
+	})
 
 /* Should we handle this via lost interrupts and IPIs or should we don't care like
  * we do now ? --BenH.
diff -purN linux-2.5/include/asm-ppc64/irq.h linuxppc64-2.5/include/asm-ppc64/irq.h
--- linux-2.5/include/asm-ppc64/irq.h	2004-02-25 02:54:12.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/irq.h	2004-02-26 10:56:03.000000000 +0000
@@ -11,6 +11,11 @@
 
 #include <asm/atomic.h>
 
+/*
+ * Maximum number of interrupt sources that we can handle.
+ */
+#define NR_IRQS		512
+
 extern void disable_irq(unsigned int);
 extern void disable_irq_nosync(unsigned int);
 extern void enable_irq(unsigned int);
@@ -18,12 +23,11 @@ extern void enable_irq(unsigned int);
 /* this number is used when no interrupt has been assigned */
 #define NO_IRQ			(-1)
 
-/*
- * this is the maximum number of virtual irqs we will use.
- */
-#define NR_IRQS			512
+#define get_irq_desc(irq) (&irq_desc[(irq)])
 
-#define NUM_8259_INTERRUPTS	16
+/* Define a way to iterate across irqs. */
+#define for_each_irq(i) \
+	for ((i) = 0; (i) < NR_IRQS; ++(i))
 
 /* Interrupt numbers are virtual in case they are sparsely
  * distributed by the hardware.
@@ -41,12 +45,35 @@ static inline unsigned int virt_irq_to_r
 	return virt_irq_to_real_map[virt_irq];
 }
 
+/*
+ * Because many systems have two overlapping names spaces for
+ * interrupts (ISA and XICS for example), and the ISA interrupts
+ * have historically not been easy to renumber, we allow ISA
+ * interrupts to take values 0 - 15, and shift up the remaining
+ * interrupts by 0x10.
+ */
+#define NUM_ISA_INTERRUPTS	0x10
+extern int __irq_offset_value;
+
+static inline int irq_offset_up(int irq)
+{
+	return(irq + __irq_offset_value);
+}
+
+static inline int irq_offset_down(int irq)
+{
+	return(irq - __irq_offset_value);
+}
+
+static inline int irq_offset_value(void)
+{
+	return __irq_offset_value;
+}
+
 static __inline__ int irq_canonicalize(int irq)
 {
 	return irq;
 }
 
-#define NR_MASK_WORDS	((NR_IRQS + 63) / 64)
-
 #endif /* _ASM_IRQ_H */
 #endif /* __KERNEL__ */
diff -purN linux-2.5/include/asm-ppc64/machdep.h linuxppc64-2.5/include/asm-ppc64/machdep.h
--- linux-2.5/include/asm-ppc64/machdep.h	2004-03-21 10:27:41.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/machdep.h	2004-03-23 04:57:22.000000000 +0000
@@ -11,6 +11,7 @@
 
 #include <linux/config.h>
 #include <linux/seq_file.h>
+#include <linux/irq.h>
 
 struct pt_regs;
 struct pci_bus;	
diff -purN linux-2.5/include/asm-ppc64/rtas.h linuxppc64-2.5/include/asm-ppc64/rtas.h
--- linux-2.5/include/asm-ppc64/rtas.h	2004-03-16 11:30:38.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/rtas.h	2004-03-17 16:17:20.000000000 +0000
@@ -219,6 +220,8 @@ extern void pSeries_log_error(char *buf,
 extern spinlock_t rtas_data_buf_lock;
 extern char rtas_data_buf[RTAS_DATA_BUF_SIZE];
 
+extern void rtas_stop_self(void);
+
 /* RMO buffer reserved for user-space RTAS use */
 extern unsigned long rtas_rmo_buf;
 
diff -purN linux-2.5/include/asm-ppc64/siginfo.h linuxppc64-2.5/include/asm-ppc64/siginfo.h
--- linux-2.5/include/asm-ppc64/siginfo.h	2003-09-11 04:03:18.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/siginfo.h	2004-03-19 18:33:59.000000000 +0000
@@ -10,6 +10,7 @@
 
 #define __ARCH_SI_PREAMBLE_SIZE	(4 * sizeof(int))
 #define SI_PAD_SIZE32		((SI_MAX_SIZE/sizeof(int)) - 3)
+#define __ARCH_SI_BAND_T 	long
 
 #include <asm-generic/siginfo.h>
 
diff -purN linux-2.5/include/asm-ppc64/smp.h linuxppc64-2.5/include/asm-ppc64/smp.h
--- linux-2.5/include/asm-ppc64/smp.h	2004-02-23 16:39:10.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/smp.h	2004-03-09 23:39:56.000000000 +0000
@@ -67,9 +67,14 @@ extern cpumask_t cpu_available_map;
 #endif
 #define PPC_MSG_DEBUGGER_BREAK  3
 
+extern cpumask_t irq_affinity[];
+
 void smp_init_iSeries(void);
 void smp_init_pSeries(void);
 
+extern int __cpu_disable(void);
+extern void __cpu_die(unsigned int cpu);
+extern void cpu_die(void) __attribute__((noreturn));
 #endif /* !(CONFIG_SMP) */
 
 #define get_hard_smp_processor_id(CPU) (paca[(CPU)].xHwProcNum)
diff -purN linux-2.5/include/asm-ppc64/spinlock.h linuxppc64-2.5/include/asm-ppc64/spinlock.h
--- linux-2.5/include/asm-ppc64/spinlock.h	2002-09-10 09:50:15.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/spinlock.h	2004-03-19 03:01:36.000000000 +0000
@@ -4,7 +4,7 @@
 /*
  * Simple spin lock operations.  
  *
- * Copyright (C) 2001 Paul Mackerras <paulus@au.ibm.com>, IBM
+ * Copyright (C) 2001-2004 Paul Mackerras <paulus@au.ibm.com>, IBM
  * Copyright (C) 2001 Anton Blanchard <anton@au.ibm.com>, IBM
  *
  * Type of int is used as a full 64b word is not necessary.
@@ -14,56 +14,72 @@
  * as published by the Free Software Foundation; either version
  * 2 of the License, or (at your option) any later version.
  */
+#include <linux/config.h>
+#include <linux/compiler.h>
+#include <linux/threads.h>
+#include <asm/memory.h>
+
 typedef struct {
 	volatile unsigned int lock;
 } spinlock_t;
 
+/*
+ * When we have shared processors, we need to be able to tell
+ * which virtual processor holds the lock, so we can tell the
+ * hypervisor to give our timeslice to them if they are not
+ * currently scheduled on a real processor.  To do this,
+ * we put paca->xPacaIndex + 0x10000 in the lock when it is
+ * held.
+ */
+
 #ifdef __KERNEL__
 #define SPIN_LOCK_UNLOCKED	(spinlock_t) { 0 }
 
 #define spin_is_locked(x)	((x)->lock != 0)
 
-static __inline__ int _raw_spin_trylock(spinlock_t *lock)
+/*
+ * This returns the old value in the lock, so we succeeded
+ * in getting the lock if the return value is 0.
+ */
+static __inline__ int __spin_trylock(spinlock_t *lock)
 {
-	unsigned int tmp;
+	unsigned int tmp, tmp2;
 
 	__asm__ __volatile__(
-"1:	lwarx		%0,0,%1		# spin_trylock\n\
+"1:	lwarx		%0,0,%2		# __spin_trylock\n\
 	cmpwi		0,%0,0\n\
-	li		%0,0\n\
 	bne-		2f\n\
-	li		%0,1\n\
-	stwcx.		%0,0,%1\n\
+	lhz		%1,24(13)\n\
+	oris		%1,%1,1\n\
+	stwcx.		%1,0,%2\n\
 	bne-		1b\n\
 	isync\n\
-2:"	: "=&r"(tmp)
-	: "r"(&lock->lock)
+2:"	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&lock->lock)
 	: "cr0", "memory");
 
 	return tmp;
 }
 
-static __inline__ void _raw_spin_lock(spinlock_t *lock)
+static __inline__ int _raw_spin_trylock(spinlock_t *lock)
 {
-	unsigned int tmp;
+	return __spin_trylock(lock) == 0;
+}
 
-	__asm__ __volatile__(
-	"b		2f		# spin_lock\n\
-1:"
-	HMT_LOW
-"	lwzx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne+		1b\n"
-	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne-		1b\n\
-	stwcx.		%2,0,%1\n\
-	bne-		2b\n\
-	isync"
-	: "=&r"(tmp)
-	: "r"(&lock->lock), "r"(1)
-	: "cr0", "memory");
+extern void __spin_yield(spinlock_t *);
+#if !defined(CONFIG_PPC_ISERIES) && !defined(CONFIG_PPC_SPLPAR)
+#define __spin_yield(x)		do { } while (0)
+#endif
+
+static __inline__ void _raw_spin_lock(spinlock_t *lock)
+{
+	while (unlikely(__spin_trylock(lock) != 0)) {
+		do {
+			HMT_low();
+			__spin_yield(lock);
+		} while (likely(lock->lock != 0));
+		HMT_medium();
+	}
 }
 
 static __inline__ void _raw_spin_unlock(spinlock_t *lock)
@@ -81,6 +97,10 @@ static __inline__ void _raw_spin_unlock(
  * can "mix" irq-safe locks - any writer needs to get a
  * irq-safe write-lock, but readers can get non-irqsafe
  * read-locks.
+ *
+ * For a write lock, we store 0x80000000 | paca->xPacaIndex,
+ * so that we can tell who holds the lock, which we need
+ * to know if we are running on shared processors.
  */
 typedef struct {
 	volatile signed int lock;
@@ -88,50 +108,48 @@ typedef struct {
 
 #define RW_LOCK_UNLOCKED (rwlock_t) { 0 }
 
-static __inline__ int _raw_read_trylock(rwlock_t *rw)
+/*
+ * This returns the old value in the lock + 1,
+ * so we got a read lock if the return value is > 0.
+ */
+static __inline__ int __read_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
-	unsigned int ret;
+	int tmp;
 
 	__asm__ __volatile__(
-"1:	lwarx		%0,0,%2		# read_trylock\n\
-	li		%1,0\n\
+"1:	lwarx		%0,0,%1		# read_trylock\n\
 	extsw		%0,%0\n\
 	addic.		%0,%0,1\n\
 	ble-		2f\n\
-	stwcx.		%0,0,%2\n\
+	stwcx.		%0,0,%1\n\
 	bne-		1b\n\
-	li		%1,1\n\
 	isync\n\
-2:"	: "=&r"(tmp), "=&r"(ret)
-	: "r"(&rw->lock)
-	: "cr0", "memory");
+2:"	: "=&r" (tmp)
+	: "r" (&rw->lock)
+	: "cr0", "xer", "memory");
 
-	return ret;
+	return tmp;
 }
 
-static __inline__ void _raw_read_lock(rwlock_t *rw)
+static __inline__ int _raw_read_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
+	return __read_trylock(rw) > 0;
+}
 
-	__asm__ __volatile__(
-	"b		2f		# read_lock\n\
-1:"
-	HMT_LOW
-"	lwax		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	blt+		1b\n"
-	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	extsw		%0,%0\n\
-	addic.		%0,%0,1\n\
-	ble-		1b\n\
-	stwcx.		%0,0,%1\n\
-	bne-		2b\n\
-	isync"
-	: "=&r"(tmp)
-	: "r"(&rw->lock)
-	: "cr0", "memory");
+extern void __rw_yield(rwlock_t *);
+#if !defined(CONFIG_PPC_ISERIES) && !defined(CONFIG_PPC_SPLPAR)
+#define __rw_yield(x)		do { } while (0)
+#endif
+
+static __inline__ void _raw_read_lock(rwlock_t *rw)
+{
+	while (unlikely(__read_trylock(rw) <= 0)) {
+		do {
+			HMT_low();
+			__rw_yield(rw);
+		} while (likely(rw->lock < 0));
+		HMT_medium();
+	}
 }
 
 static __inline__ void _raw_read_unlock(rwlock_t *rw)
@@ -149,48 +167,44 @@ static __inline__ void _raw_read_unlock(
 	: "cr0", "memory");
 }
 
-static __inline__ int _raw_write_trylock(rwlock_t *rw)
+/*
+ * This returns the old value in the lock,
+ * so we got the write lock if the return value is 0.
+ */
+static __inline__ int __write_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
-	unsigned int ret;
+	int tmp, tmp2;
 
 	__asm__ __volatile__(
 "1:	lwarx		%0,0,%2		# write_trylock\n\
 	cmpwi		0,%0,0\n\
-	li		%1,0\n\
 	bne-		2f\n\
-	stwcx.		%3,0,%2\n\
+	lhz		%1,24(13)\n\
+	oris		%1,%1,0x8000\n\
+	stwcx.		%1,0,%2\n\
 	bne-		1b\n\
-	li		%1,1\n\
 	isync\n\
-2:"	: "=&r"(tmp), "=&r"(ret)
-	: "r"(&rw->lock), "r"(-1)
+2:"	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&rw->lock)
 	: "cr0", "memory");
 
-	return ret;
+	return tmp;
 }
 
-static __inline__ void _raw_write_lock(rwlock_t *rw)
+static __inline__ int _raw_write_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
+	return __write_trylock(rw) == 0;
+}
 
-	__asm__ __volatile__(
-	"b		2f		# write_lock\n\
-1:"
-	HMT_LOW
-	"lwax		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne+		1b\n"
-	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne-		1b\n\
-	stwcx.		%2,0,%1\n\
-	bne-		2b\n\
-	isync"
-	: "=&r"(tmp)
-	: "r"(&rw->lock), "r"(-1)
-	: "cr0", "memory");
+static __inline__ void _raw_write_lock(rwlock_t *rw)
+{
+	while (unlikely(__write_trylock(rw) != 0)) {
+		do {
+			HMT_low();
+			__rw_yield(rw);
+		} while (likely(rw->lock != 0));
+		HMT_medium();
+	}
 }
 
 static __inline__ void _raw_write_unlock(rwlock_t *rw)
diff -purN linux-2.5/include/linux/preempt.h linuxppc64-2.5/include/linux/preempt.h
--- linux-2.5/include/linux/preempt.h	2004-02-25 10:42:02.000000000 +0000
+++ linuxppc64-2.5/include/linux/preempt.h	2004-02-26 05:42:10.000000000 +0000
@@ -25,6 +25,17 @@ do { \
 
 asmlinkage void preempt_schedule(void);
 
+#define preempt_check_resched() \
+do { \
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED))) \
+		preempt_schedule(); \
+} while (0)
+#else
+#define preempt_check_resched()		do { } while (0)
+#endif
+
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_DEBUG_SPINLOCK_SLEEP)
+
 #define preempt_disable() \
 do { \
 	inc_preempt_count(); \
@@ -37,12 +48,6 @@ do { \
 	dec_preempt_count(); \
 } while (0)
 
-#define preempt_check_resched() \
-do { \
-	if (unlikely(test_thread_flag(TIF_NEED_RESCHED))) \
-		preempt_schedule(); \
-} while (0)
-
 #define preempt_enable() \
 do { \
 	preempt_enable_no_resched(); \
diff -purN linux-2.5/kernel/sched.c linuxppc64-2.5/kernel/sched.c
--- linux-2.5/kernel/sched.c	2004-03-19 04:54:57.000000000 +0000
+++ linuxppc64-2.5/kernel/sched.c	2004-03-22 01:51:17.000000000 +0000
@@ -724,7 +724,7 @@ void fastcall sched_fork(task_t *p)
 	INIT_LIST_HEAD(&p->run_list);
 	p->array = NULL;
 	spin_lock_init(&p->switch_lock);
-#ifdef CONFIG_PREEMPT
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_DEBUG_SPINLOCK_SLEEP)
 	/*
 	 * During context-switch we hold precisely one spinlock, which
 	 * schedule_tail drops. (in the common case it's this_rq()->lock,
@@ -2676,7 +2676,7 @@ void __init init_idle(task_t *idle, int 
 	local_irq_restore(flags);
 
 	/* Set the preempt count _outside_ the spinlocks! */
-#ifdef CONFIG_PREEMPT
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_DEBUG_SPINLOCK_SLEEP)
 	idle->thread_info->preempt_count = (idle->lock_depth >= 0);
 #else
 	idle->thread_info->preempt_count = 0;
