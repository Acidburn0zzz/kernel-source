diff -purN linux-2.5-latest/arch/ppc64/kernel/HvCall.c linuxppc64-2.5-latest/arch/ppc64/kernel/HvCall.c
--- linux-2.5-latest/arch/ppc64/kernel/HvCall.c	2003-10-10 11:39:44.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/HvCall.c	2003-10-10 11:34:59.000000000 +0200
@@ -90,11 +90,11 @@ void HvCall_writeLogBuffer(const void *b
 	struct HvLpBufferList bufList;
 	u64 bytesLeft = bufLen;
 	u64 leftThisPage;
-	u64 curPtr = virt_to_absolute( (unsigned long) buffer );
+	u64 curPtr = virt_to_absolute((unsigned long) buffer);
 
 	while (bytesLeft) {
 		bufList.addr = curPtr;
-      
+
 		leftThisPage = ((curPtr & PAGE_MASK) + PAGE_SIZE) - curPtr;
 
 		if (leftThisPage > bytesLeft) {
@@ -105,11 +105,11 @@ void HvCall_writeLogBuffer(const void *b
 			bytesLeft -= leftThisPage;
 		}
 
-		curPtr = (curPtr & PAGE_MASK) + PAGE_SIZE;
-	}
-
 
-	HvCall2(HvCallBaseWriteLogBuffer,
-		virt_to_absolute((unsigned long)&bufList), bufLen);
+		HvCall2(HvCallBaseWriteLogBuffer,
+			virt_to_absolute((unsigned long) &bufList),
+			bufList.len);
 
+		curPtr = (curPtr & PAGE_MASK) + PAGE_SIZE;
+	}
 }
diff -purN linux-2.5-latest/arch/ppc64/kernel/asm-offsets.c linuxppc64-2.5-latest/arch/ppc64/kernel/asm-offsets.c
--- linux-2.5-latest/arch/ppc64/kernel/asm-offsets.c	2003-10-10 11:39:19.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/asm-offsets.c	2003-10-10 11:34:39.000000000 +0200
@@ -85,7 +85,7 @@ int main(void)
 	DEFINE(PACAEXCSP, offsetof(struct paca_struct, exception_sp));
 	DEFINE(PACAPROCENABLED, offsetof(struct paca_struct, xProcEnabled));
 	DEFINE(PACADEFAULTDECR, offsetof(struct paca_struct, default_decr));
-	DEFINE(PACAPROFENABLED, offsetof(struct paca_struct, prof_enabled));
+/*	DEFINE(PACAPROFENABLED, offsetof(struct paca_struct, prof_enabled)); */
 	DEFINE(PACAPROFLEN, offsetof(struct paca_struct, prof_len));
 	DEFINE(PACAPROFSHIFT, offsetof(struct paca_struct, prof_shift));
 	DEFINE(PACAPROFBUFFER, offsetof(struct paca_struct, prof_buffer));
diff -purN linux-2.5-latest/arch/ppc64/kernel/chrp_setup.c linuxppc64-2.5-latest/arch/ppc64/kernel/chrp_setup.c
--- linux-2.5-latest/arch/ppc64/kernel/chrp_setup.c	2003-10-10 11:38:19.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/chrp_setup.c	2003-10-10 11:33:30.000000000 +0200
@@ -69,6 +69,7 @@ extern volatile unsigned char *chrp_int_
 void chrp_progress(char *, unsigned short);
 
 extern void openpic_init_IRQ(void);
+extern void openpic_init_irq_desc(irq_desc_t *);
 
 extern void find_and_init_phbs(void);
 
@@ -96,16 +97,19 @@ chrp_get_cpuinfo(struct seq_file *m)
 
 	seq_printf(m, "timebase\t: %lu\n", ppc_tb_freq);
 
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	if (root)
 		model = get_property(root, "model", NULL);
 	seq_printf(m, "machine\t\t: CHRP %s\n", model);
+	of_node_put(root);
 }
 
 #define I8042_DATA_REG 0x60
 
-void __init chrp_request_regions(void) 
+void __init chrp_request_regions(void)
 {
+	struct device_node *i8042;
+
 	request_region(0x20,0x20,"pic1");
 	request_region(0xa0,0x20,"pic2");
 	request_region(0x00,0x20,"dma1");
@@ -118,8 +122,9 @@ void __init chrp_request_regions(void) 
 	 * tree and reserve the region if it does not appear. Later on
 	 * the i8042 code will try and reserve this region and fail.
 	 */
-	if (!find_type_devices("8042"))
+	if (!(i8042 = of_find_node_by_type(NULL, "8042")))
 		request_region(I8042_DATA_REG, 16, "reserved (no i8042)");
+	of_node_put(i8042);
 }
 
 void __init
@@ -158,7 +163,7 @@ chrp_setup_arch(void)
 #endif
 
 	/* Find the Open PIC if present */
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	opprop = (unsigned int *) get_property(root,
 				"platform-open-pic", NULL);
 	if (opprop != 0) {
@@ -170,6 +175,7 @@ chrp_setup_arch(void)
 		printk(KERN_DEBUG "OpenPIC addr: %lx\n", openpic);
 		OpenPIC_Addr = __ioremap(openpic, 0x40000, _PAGE_NO_CACHE);
 	}
+	of_node_put(root);
 
 #ifdef CONFIG_DUMMY_CONSOLE
 	conswitchp = &dummy_con;
@@ -244,10 +250,12 @@ chrp_init(unsigned long r3, unsigned lon
 	ppc_md.setup_residual = NULL;
 	ppc_md.get_cpuinfo    = chrp_get_cpuinfo;
 	if(naca->interrupt_controller == IC_OPEN_PIC) {
-		ppc_md.init_IRQ       = openpic_init_IRQ; 
+		ppc_md.init_IRQ       = openpic_init_IRQ;
+		ppc_md.init_irq_desc  = openpic_init_irq_desc;
 		ppc_md.get_irq        = openpic_get_irq;
 	} else {
 		ppc_md.init_IRQ       = xics_init_IRQ;
+		ppc_md.init_irq_desc  = xics_init_irq_desc;
 		ppc_md.get_irq        = xics_get_irq;
 	}
 
@@ -271,7 +279,7 @@ chrp_init(unsigned long r3, unsigned lon
 	struct device_node * dn;
 	char * hypertas;
 	unsigned int len;
-	dn = find_path_device("/rtas");
+	dn = of_find_node_by_path("/rtas");
 	cur_cpu_spec->firmware_features = 0;
 	hypertas = get_property(dn, "ibm,hypertas-functions", &len);
 	if (hypertas) {
@@ -290,6 +298,7 @@ chrp_init(unsigned long r3, unsigned lon
 		hypertas+= hypertas_len +1;
 	    }
 	}
+	of_node_put(dn);
 	udbg_printf("firmware_features bitmask: 0x%x \n",
 		    cur_cpu_spec->firmware_features);
 }
@@ -319,6 +328,13 @@ chrp_progress(char *s, unsigned short he
 		display_character = rtas_token("display-character");
 		set_indicator = rtas_token("set-indicator");
 	}
+	if (display_character == RTAS_UNKNOWN_SERVICE) {
+		/* use hex display */
+		if (set_indicator == RTAS_UNKNOWN_SERVICE)
+			return;
+		rtas_call(set_indicator, 3, 1, NULL, 6, 0, hex);
+		return;
+	}
 
 	if(display_character == RTAS_UNKNOWN_SERVICE) {
 		/* use hex display if available */
@@ -405,11 +421,11 @@ void __init pSeries_calibrate_decr(void)
 
 	/*
 	 * The cpu node should have a timebase-frequency property
-	 * to tell us the rate at which the decrementer counts. 
+	 * to tell us the rate at which the decrementer counts.
 	 */
 	freq = 16666000;        /* hardcoded default */
-	cpu = find_type_devices("cpu");
-	if (cpu != 0) { 
+	cpu = of_find_node_by_type(NULL, "cpu");
+	if (cpu != 0) {
 		fp = (int *) get_property(cpu, "timebase-frequency", NULL);
 		if (fp != 0)
 			freq = *fp;
@@ -422,11 +438,12 @@ void __init pSeries_calibrate_decr(void)
 			processor_freq = *fp;
 	}
 	ppc_proc_freq = processor_freq;
-	
-        printk("time_init: decrementer frequency = %lu.%.6lu MHz\n", 
-	       freq/1000000, freq%1000000 );
+	of_node_put(cpu);
+
+	printk("time_init: decrementer frequency = %lu.%.6lu MHz\n",
+	       freq/1000000, freq%1000000);
 	printk("time_init: processor frequency   = %lu.%.6lu MHz\n",
-		processor_freq/1000000, processor_freq%1000000 );
+	       processor_freq/1000000, processor_freq%1000000);
 
 	tb_ticks_per_jiffy = freq / HZ;
 	tb_ticks_per_sec = tb_ticks_per_jiffy * HZ;
diff -purN linux-2.5-latest/arch/ppc64/kernel/eeh.c linuxppc64-2.5-latest/arch/ppc64/kernel/eeh.c
--- linux-2.5-latest/arch/ppc64/kernel/eeh.c	2003-10-10 11:39:19.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/eeh.c	2003-10-10 11:34:38.000000000 +0200
@@ -257,7 +257,7 @@ void eeh_init(void)
 
 	/* Enable EEH for all adapters.  Note that eeh requires buid's */
 	info.adapters_enabled = 0;
-	for (phb = find_devices("pci"); phb; phb = phb->next) {
+	for (phb = of_find_node_by_name(NULL, "pci"); phb; phb = of_find_node_by_name(phb, "pci")) {
 		int len;
 		int *buid_vals = (int *) get_property(phb, "ibm,fw-phb-id", &len);
 		if (!buid_vals)
diff -purN linux-2.5-latest/arch/ppc64/kernel/head.S linuxppc64-2.5-latest/arch/ppc64/kernel/head.S
--- linux-2.5-latest/arch/ppc64/kernel/head.S	2003-10-10 11:39:00.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/head.S	2003-10-10 11:34:20.000000000 +0200
@@ -708,6 +708,21 @@ HardwareInterrupt_entry:
 	bl      .do_IRQ
 	b       .ret_from_except
 
+3:
+	/* error - counts out of sync                                      */
+#ifdef CONFIG_XMON
+	bl	.xmon
+#endif
+#ifdef CONFIG_KDB
+        /*          kdb(KDB_REASON_FAULT,regs->trap,regs); */
+	li      r3,1
+	li 	r4,0x200
+	li      r5,0
+	bl	.kdb
+#endif
+4:	b	4b
+
+
 	.globl Alignment_common
 Alignment_common:
 	EXCEPTION_PROLOG_COMMON
diff -purN linux-2.5-latest/arch/ppc64/kernel/i8259.c linuxppc64-2.5-latest/arch/ppc64/kernel/i8259.c
--- linux-2.5-latest/arch/ppc64/kernel/i8259.c	2003-10-10 11:40:13.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/i8259.c	2003-10-10 11:35:17.000000000 +0200
@@ -124,8 +124,8 @@ static void i8259_unmask_irq(unsigned in
 
 static void i8259_end_irq(unsigned int irq)
 {
-	if (!(irq_desc[irq].status & (IRQ_DISABLED|IRQ_INPROGRESS)) &&
-	    irq_desc[irq].action)
+	if (!(get_irq_desc(irq)->status & (IRQ_DISABLED|IRQ_INPROGRESS)) &&
+	    get_irq_desc(irq)->action)
 		i8259_unmask_irq(irq);
 }
 
diff -purN linux-2.5-latest/arch/ppc64/kernel/idle.c linuxppc64-2.5-latest/arch/ppc64/kernel/idle.c
--- linux-2.5-latest/arch/ppc64/kernel/idle.c	2003-10-10 11:39:39.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/idle.c	2003-10-10 11:34:54.000000000 +0200
@@ -84,8 +84,6 @@ int cpu_idle(void)
 	lpaca = get_paca();
 
 	while (1) {
-		irq_stat[smp_processor_id()].idle_timestamp = jiffies;
-
 		if (lpaca->xLpPaca.xSharedProc) {
 			if (ItLpQueue_isLpIntPending(lpaca->lpQueuePtr))
 				process_iSeries_events();
@@ -125,7 +123,6 @@ int cpu_idle(void)
 	long oldval;
 
 	while (1) {
-		irq_stat[smp_processor_id()].idle_timestamp = jiffies;
 		oldval = test_and_clear_thread_flag(TIF_NEED_RESCHED);
 
 		if (!oldval) {
diff -purN linux-2.5-latest/arch/ppc64/kernel/irq.c linuxppc64-2.5-latest/arch/ppc64/kernel/irq.c
--- linux-2.5-latest/arch/ppc64/kernel/irq.c	2003-10-10 11:38:50.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/irq.c	2003-10-10 11:34:09.000000000 +0200
@@ -40,6 +40,7 @@
 #include <linux/irq.h>
 #include <linux/proc_fs.h>
 #include <linux/random.h>
+#include <linux/bootmem.h>
 #include <linux/kallsyms.h>
 
 #include <asm/uaccess.h>
@@ -55,6 +56,77 @@
 #include <asm/machdep.h>
 #include <asm/paca.h>
 
+/*
+ * Because the name space for interrupts is so large on ppc64 systems we
+ * avoid declaring a single array of "NR_IRQ" interrupts and instead build
+ * a three level tree leading to the irq_desc_t (similar to page tables).
+ *
+ * Currently we cover 24-bit irq values:
+ *    10-bits:  the "base" dir (2-pages)
+ *     9-bits:  the "middle" dir (1-page)
+ *     5-bits:  the "bottom" page (1-page) holding 128byte irq_desc's.
+ *
+ * We pack a hw_irq_stat struct directly after the irq_desc in the otherwise
+ * wasted space of the cacheline.
+ *
+ * MAX_IRQS is the max this implementation will support.
+ * It is much larger than NR_IRQS which is bogus on this arch and often used
+ * to declare arrays.
+ *
+ * Note that all "undefined" mid table and bottom table pointers will point
+ * to dummy tables.  Therefore, we don't need to check for NULL on spurious
+ * interrupts.
+ */
+
+#define MAX_IRQS (1<<24)
+#define IRQ_BASE_INDEX_SIZE  10
+#define IRQ_MID_INDEX_SIZE  9
+#define IRQ_BOT_DESC_SIZE 5
+
+#define IRQ_BASE_PTRS	(1 << IRQ_BASE_INDEX_SIZE)
+#define IRQ_MID_PTRS	(1 << IRQ_MID_INDEX_SIZE)
+#define IRQ_BOT_DESCS (1 << IRQ_BOT_DESC_SIZE)
+
+#define IRQ_BASE_IDX_SHIFT (IRQ_MID_INDEX_SIZE + IRQ_BOT_DESC_SIZE)
+#define IRQ_MID_IDX_SHIFT (IRQ_BOT_DESC_SIZE)
+
+#define IRQ_MID_IDX_MASK  ((1 << IRQ_MID_INDEX_SIZE) - 1)
+#define IRQ_BOT_IDX_MASK  ((1 << IRQ_BOT_DESC_SIZE) - 1)
+
+
+/* Define a way to iterate across irqs fairly efficiently. */
+#define for_each_irq(i) \
+	for ((i) = 0; (i) < MAX_IRQS; (i) = _next_irq(i))
+unsigned int _next_irq(unsigned int irq);
+
+/* The hw_irq_stat struct is stored directly after the irq_desc_t
+ * in the same cacheline.  We need to use care to make sure we don't
+ * overrun the size of the cacheline.
+ *
+ * Currently sizeof(irq_desc_t) is 32 bytes or less and this hw_irq_stat
+ * fills the rest of the cache line.
+ *
+ * The irqs_per_cpu field is an optimization for systems with 4 cpus or less
+ * to avoid allocating space for irq-per-cpu statistics (and hitting another
+ * cacheline to do the counting).  This field could be discarded.
+ */
+struct hw_irq_stat {
+	unsigned long irqs;		/* statistic per irq */
+	unsigned long *per_cpu_stats;
+	struct proc_dir_entry *irq_dir, *smp_affinity;
+	unsigned long irq_affinity;	/* ToDo: cpu bitmask */
+	unsigned long irqs_per_cpu[4];
+};
+static inline struct hw_irq_stat *get_irq_stat(irq_desc_t *desc)
+{
+	/* WARNING: this assume lock is the last field! */
+	return (struct hw_irq_stat *)(&desc->lock+1);
+}
+static inline unsigned long *get_irq_per_cpu(struct hw_irq_stat *hw)
+{
+	return hw->per_cpu_stats;
+}
+
 void enable_irq(unsigned int irq_nr);
 void disable_irq(unsigned int irq_nr);
 
@@ -64,24 +136,229 @@ extern void iSeries_smp_message_recv( st
 
 volatile unsigned char *chrp_int_ack_special;
 static void register_irq_proc (unsigned int irq);
-
-irq_desc_t irq_desc[NR_IRQS] __cacheline_aligned = {
-	[0 ... NR_IRQS-1] = {
-		.lock = SPIN_LOCK_UNLOCKED
-	}
-};
+static irq_desc_t *add_irq_desc(unsigned int irq);
 	
 int ppc_spurious_interrupts = 0;
 unsigned long lpEvent_count = 0;
 
+extern struct hw_interrupt_type xics_pic;
+extern struct hw_interrupt_type xics_8259_pic;
+extern int mem_init_done;
+
+irq_desc_t **irq_desc_base_dir[IRQ_BASE_PTRS] __page_aligned = {0};
+irq_desc_t **irq_desc_mid_null;
+irq_desc_t *irq_desc_bot_null;
+
+static inline irq_desc_t **get_irq_mid_table(unsigned int irq)
+{
+	/* Assume irq < MAX_IRQS so we won't index off the end. */
+	return irq_desc_base_dir[irq >> IRQ_BASE_IDX_SHIFT];
+}
+
+static inline irq_desc_t *get_irq_bot_table(unsigned int irq,
+					    irq_desc_t **mid_ptr)
+{
+	return mid_ptr[(irq >> IRQ_MID_IDX_SHIFT) & IRQ_MID_IDX_MASK];
+}
+
+
+/* This should be inline. */
+void *_get_irq_desc(unsigned int irq)
+{
+	irq_desc_t **mid_table, *bot_table, *desc;
+
+	mid_table = get_irq_mid_table(irq);
+	bot_table = get_irq_bot_table(irq, mid_table);
+
+	desc = bot_table + (irq & IRQ_BOT_IDX_MASK);
+	return desc;
+}
+
+/* This is used by the for_each_irq(i) macro to iterate quickly over
+ * all interrupt.  It optimizes by skipping over ptrs to the null tables
+ * when possible, but it may produce false positives.
+ */
+unsigned int _next_irq(unsigned int irq)
+{
+	irq_desc_t **mid_table, *bot_table;
+
+	irq++;
+	/* Easy case first...staying on the current bot_table. */
+	if (irq & IRQ_BOT_IDX_MASK)
+		return irq;
+
+	/* Now skip empty mid tables */
+	while (irq < MAX_IRQS &&
+	       (mid_table = get_irq_mid_table(irq)) == irq_desc_mid_null) {
+		/* index to the next base index (i.e. the next mid table) */
+		irq = (irq & ~(IRQ_BASE_IDX_SHIFT-1)) + IRQ_BASE_IDX_SHIFT;
+	}
+	/* And skip empty bot tables */
+	while (irq < MAX_IRQS &&
+	       (bot_table = get_irq_bot_table(irq, mid_table)) == irq_desc_bot_null) {
+		/* index to the next mid index (i.e. the next bot table) */
+		irq = (irq & ~(IRQ_MID_IDX_SHIFT-1)) + IRQ_MID_IDX_SHIFT;
+	}
+	return irq;
+}
+
+
+/* Same as get_irq_desc(irq) except it will "fault in" a real desc as needed
+ * rather than return the null entry.
+ * This is used by code that is actually defining the irq.
+ *
+ * NULL may be returned on memory allocation failure.  In general, init code
+ * doesn't look for this, but setup_irq does.  In this failure case the desc
+ * is left pointing at the null pages so callers of get_irq_desc() should
+ * always return something.
+ */
+void *_get_real_irq_desc(unsigned int irq)
+{
+	irq_desc_t *desc = get_irq_desc(irq);
+	if (((unsigned long)desc & PAGE_MASK) ==
+	    (unsigned long)irq_desc_bot_null) {
+		desc = add_irq_desc(irq);
+	}
+	return desc;
+}
+
+/* Allocate an irq middle page and init entries to null page. */
+static irq_desc_t **alloc_irq_mid_page(void)
+{
+	irq_desc_t **m, **ent;
+
+	if (mem_init_done)
+		m = (irq_desc_t **)__get_free_page(GFP_KERNEL);
+	else
+		m = (irq_desc_t **)alloc_bootmem_pages(PAGE_SIZE);
+	if (m) {
+		for (ent = m; ent < m + IRQ_MID_PTRS; ent++) {
+			*ent = irq_desc_bot_null;
+		}
+	}
+	return m;
+}
+
+/* Allocate an irq bottom page and init the entries. */
+static irq_desc_t *alloc_irq_bot_page(void)
+{
+	irq_desc_t *b, *ent;
+	if (mem_init_done)
+		b = (irq_desc_t *)get_zeroed_page(GFP_KERNEL);
+	else
+		b = (irq_desc_t *)alloc_bootmem_pages(PAGE_SIZE);
+	if (b) {
+		for (ent = b; ent < b + IRQ_BOT_DESCS; ent++) {
+			ent->lock = SPIN_LOCK_UNLOCKED;
+		}
+	}
+	return b;
+}
+
+/*
+ * The universe of interrupt numbers ranges from 0 to 2^24.
+ * Use a sparsely populated tree to map from the irq to the handler.
+ * Top level is 2 contiguous pages, covering the 10 most significant 
+ * bits.  Mid level is 1 page, covering 9 bits.  Last page covering
+ * 5 bits is the irq_desc, each of which is 128B.
+ */
+static void irq_desc_init(void) {
+	irq_desc_t ***entry_p;
+
+	/* 
+	 * Now initialize the tables to point though the NULL tables for
+	 * the default case of no interrupt handler (spurious).
+	 */
+	irq_desc_bot_null = alloc_irq_bot_page();
+	irq_desc_mid_null = alloc_irq_mid_page();
+	if (!irq_desc_bot_null || !irq_desc_mid_null)
+		panic("irq_desc_init: could not allocate pages\n");
+	for(entry_p = irq_desc_base_dir;
+	    entry_p < irq_desc_base_dir + IRQ_BASE_PTRS;
+	    entry_p++) {
+		*entry_p = irq_desc_mid_null;
+	}
+}
+
+/*
+ * Add a new irq desc for the given irq if needed.
+ * This breaks any ptr to the "null" middle or "bottom" irq desc page.
+ * Note that we don't ever coalesce pages as the interrupts are released.
+ * This isn't worth the effort.  We add the cpu stats info when the
+ * interrupt is actually requested.
+ *
+ * May return NULL if memory could not be allocated.
+ */
+static irq_desc_t *add_irq_desc(unsigned int irq)
+{
+	irq_desc_t **mid_table_p, *bot_table_p;
+
+	mid_table_p = get_irq_mid_table(irq); 
+	if(mid_table_p == irq_desc_mid_null) {
+		/* No mid table for this IRQ - create it */
+		mid_table_p = alloc_irq_mid_page();
+		if (!mid_table_p) return NULL;
+		irq_desc_base_dir[irq >> IRQ_BASE_IDX_SHIFT] = mid_table_p;
+	}
+
+	bot_table_p = (irq_desc_t *)(*(mid_table_p + ((irq >> 5) & 0x1ff)));
+
+	if(bot_table_p == irq_desc_bot_null) {
+		/* No bot table for this IRQ - create it */
+		bot_table_p = alloc_irq_bot_page();
+		if (!bot_table_p) return NULL;
+		mid_table_p[(irq >> IRQ_MID_IDX_SHIFT) & IRQ_MID_IDX_MASK] = bot_table_p;
+	}
+
+	return bot_table_p + (irq & IRQ_BOT_IDX_MASK);
+}
+
+void allocate_per_cpu_stats(struct hw_irq_stat *hwstat)
+{
+	unsigned long *p;
+
+	if (naca->interrupt_controller == IC_OPEN_PIC) {
+		/* Cheap optimization -- assume max cpus on open pic is 4
+		 * and so they will fit in cacheline after desc.
+		 * ToDo: verify max cpus.  Assume no hot plug?
+		 */
+		hwstat->per_cpu_stats = hwstat->irqs_per_cpu;
+		return;
+	}
+	if (mem_init_done) {
+		p = (unsigned long *)kmalloc(sizeof(long)*NR_CPUS, GFP_KERNEL);
+		if (p) memset(p, 0, sizeof(long)*NR_CPUS);
+	} else
+		p = (unsigned long *)alloc_bootmem(sizeof(long)*NR_CPUS);
+	hwstat->per_cpu_stats = p;
+}
+
 int
 setup_irq(unsigned int irq, struct irqaction * new)
 {
 	int shared = 0;
 	unsigned long flags;
 	struct irqaction *old, **p;
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_real_irq_desc(irq);
+	struct hw_irq_stat *hwstat;
+
+	if (!desc)
+		return -ENOMEM;
+
+	ppc_md.init_irq_desc(desc);
+
+	hwstat = get_irq_stat(desc);
 
+#ifdef CONFIG_IRQ_ALL_CPUS
+	hwstat->irq_affinity = ~0;
+#else
+	hwstat->irq_affinity = 0;
+#endif
+
+	/* Now is the time to add per-cpu kstat data to the desc
+	 * since it appears we are actually going to use the irq.
+	 */
+	allocate_per_cpu_stats(hwstat);
 	/*
 	 * Some drivers like serial.c use request_irq() heavily,
 	 * so we have to be careful not to interfere with a
@@ -136,7 +413,7 @@ setup_irq(unsigned int irq, struct irqac
 
 inline void synchronize_irq(unsigned int irq)
 {
-	while (irq_desc[irq].status & IRQ_INPROGRESS)
+	while (get_irq_desc(irq)->status & IRQ_INPROGRESS)
 		cpu_relax();
 }
 
@@ -148,11 +425,10 @@ inline void synchronize_irq(unsigned int
 static int
 do_free_irq(int irq, void* dev_id)
 {
-	irq_desc_t *desc;
+	irq_desc_t *desc = get_irq_desc(irq);
 	struct irqaction **p;
 	unsigned long flags;
 
-	desc = irq_desc + irq;
 	spin_lock_irqsave(&desc->lock,flags);
 	p = &desc->action;
 	for (;;) {
@@ -183,41 +459,6 @@ do_free_irq(int irq, void* dev_id)
 	return -ENOENT;
 }
 
-int request_irq(unsigned int irq,
-	irqreturn_t (*handler)(int, void *, struct pt_regs *),
-	unsigned long irqflags, const char * devname, void *dev_id)
-{
-	struct irqaction *action;
-	int retval;
-
-	if (irq >= NR_IRQS)
-		return -EINVAL;
-	if (!handler)
-		/* We could implement really free_irq() instead of that... */
-		return do_free_irq(irq, dev_id);
-	
-	action = (struct irqaction *)
-		kmalloc(sizeof(struct irqaction), GFP_KERNEL);
-	if (!action) {
-		printk(KERN_ERR "kmalloc() failed for irq %d !\n", irq);
-		return -ENOMEM;
-	}
-	
-	action->handler = handler;
-	action->flags = irqflags;					
-	action->mask = 0;
-	action->name = devname;
-	action->dev_id = dev_id;
-	action->next = NULL;
-	
-	retval = setup_irq(irq, action);
-	if (retval)
-		kfree(action);
-		
-	return 0;
-}
-
-EXPORT_SYMBOL(request_irq);
 
 void free_irq(unsigned int irq, void *dev_id)
 {
@@ -246,7 +487,7 @@ EXPORT_SYMBOL(free_irq);
  
  void disable_irq_nosync(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -289,7 +530,7 @@ void disable_irq(unsigned int irq)
  
 void enable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -313,10 +554,49 @@ void enable_irq(unsigned int irq)
 	spin_unlock_irqrestore(&desc->lock, flags);
 }
 
+int request_irq(unsigned int irq,
+	irqreturn_t (*handler)(int, void *, struct pt_regs *),
+	unsigned long irqflags, const char * devname, void *dev_id)
+{
+	struct irqaction *action;
+	int retval;
+
+	if (irq >= MAX_IRQS)
+		return -EINVAL;
+	if (!handler)
+		/* We could implement really free_irq() instead of that... */
+		return do_free_irq(irq, dev_id);
+	
+	action = (struct irqaction *)
+		kmalloc(sizeof(struct irqaction), GFP_KERNEL);
+	if (!action) {
+		printk(KERN_ERR "kmalloc() failed for irq %d !\n", irq);
+		return -ENOMEM;
+	}
+	
+	action->handler = handler;
+	action->flags = irqflags;					
+	action->mask = 0;
+	action->name = devname;
+	action->dev_id = dev_id;
+	action->next = NULL;
+	
+	retval = setup_irq(irq, action);
+	if (retval)
+		kfree(action);
+		
+	return 0;
+}
+
+EXPORT_SYMBOL(request_irq);
+
 int show_interrupts(struct seq_file *p, void *v)
 {
 	int i, j;
 	struct irqaction * action;
+	irq_desc_t *desc;
+	struct hw_irq_stat *hwstat;
+	unsigned long *per_cpus;
 	unsigned long flags;
 
 	seq_printf(p, "           ");
@@ -326,31 +606,35 @@ int show_interrupts(struct seq_file *p, 
 	}
 	seq_putc(p, '\n');
 
-	for (i = 0 ; i < NR_IRQS ; i++) {
-		spin_lock_irqsave(&irq_desc[i].lock, flags);
-		action = irq_desc[i].action;
+	for_each_irq(i) {
+		desc = get_irq_desc(i);
+		spin_lock_irqsave(&desc->lock, flags);
+		action = desc->action;
+
 		if (!action || !action->handler)
 			goto skip;
-		seq_printf(p, "%3d: ", i);		
-#ifdef CONFIG_SMP
-		for (j = 0; j < NR_CPUS; j++) {
-			if (cpu_online(j))
-				seq_printf(p, "%10u ", kstat_cpu(j).irqs[i]);
+		seq_printf(p, "%3d: ", i);
+		hwstat = get_irq_stat(desc);
+		per_cpus = get_irq_per_cpu(hwstat);
+		if (per_cpus) {
+			for (j = 0; j < NR_CPUS; j++) {
+				if (cpu_online(j))
+					seq_printf(p, "%10lu ", per_cpus[j]);
+			}
+		} else {
+			seq_printf(p, "%10lu ", hwstat->irqs);
 		}
-#else		
-		seq_printf(p, "%10u ", kstat_irqs(i));
-#endif /* CONFIG_SMP */
-		if (irq_desc[i].handler)		
-			seq_printf(p, " %s ", irq_desc[i].handler->typename );
+		if (get_irq_desc(i)->handler)		
+			seq_printf(p, " %s ", get_irq_desc(i)->handler->typename );
 		else
 			seq_printf(p, "  None      ");
-		seq_printf(p, "%s", (irq_desc[i].status & IRQ_LEVEL) ? "Level " : "Edge  ");
+		seq_printf(p, "%s", (get_irq_desc(i)->status & IRQ_LEVEL) ? "Level " : "Edge  ");
 		seq_printf(p, "    %s",action->name);
 		for (action=action->next; action; action = action->next)
 			seq_printf(p, ", %s", action->name);
 		seq_putc(p, '\n');
 skip:
-		spin_unlock_irqrestore(&irq_desc[i].lock, flags);
+		spin_unlock_irqrestore(&desc->lock, flags);
 	}
 	seq_printf(p, "BAD: %10u\n", ppc_spurious_interrupts);
 	return 0;
@@ -466,9 +750,17 @@ void ppc_irq_dispatch_handler(struct pt_
 	int status;
 	struct irqaction *action;
 	int cpu = smp_processor_id();
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
+	struct hw_irq_stat *hwstat;
+	unsigned long *per_cpus;
+
+	/* Statistics. */
+	hwstat = get_irq_stat(desc);	/* same cache line as desc */
+	hwstat->irqs++;
+	per_cpus = get_irq_per_cpu(hwstat); /* same cache line for < 8 cpus */
+	if (per_cpus)
+		per_cpus[cpu]++;
 
-	kstat_cpu(cpu).irqs[irq]++;
 	spin_lock(&desc->lock);
 	ack_irq(irq);	
 	/*
@@ -542,11 +834,11 @@ out:
 	 * The ->end() handler has to deal with interrupts which got
 	 * disabled while the handler was running.
 	 */
-	if (irq_desc[irq].handler) {
-		if (irq_desc[irq].handler->end)
-			irq_desc[irq].handler->end(irq);
-		else if (irq_desc[irq].handler->enable)
-			irq_desc[irq].handler->enable(irq);
+	if (desc->handler) {
+		if (desc->handler->end)
+			desc->handler->end(irq);
+		else if (desc->handler->enable)
+			desc->handler->enable(irq);
 	}
 	spin_unlock(&desc->lock);
 }
@@ -630,43 +922,44 @@ void __init init_IRQ(void)
 		return;
 	else
 		once++;
-	
+
+	/* Initialize the irq tree */
+	irq_desc_init();
+
 	ppc_md.init_IRQ();
 }
 
 static struct proc_dir_entry * root_irq_dir;
-static struct proc_dir_entry * irq_dir [NR_IRQS];
-static struct proc_dir_entry * smp_affinity_entry [NR_IRQS];
 
 #ifdef CONFIG_IRQ_ALL_CPUS
-cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
+  cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
 #else  /* CONFIG_IRQ_ALL_CPUS */
-cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_NONE };
+  cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_NONE };
 #endif /* CONFIG_IRQ_ALL_CPUS */
-
+  
 #define HEX_DIGITS (2*sizeof(cpumask_t))
 
 static int irq_affinity_read_proc (char *page, char **start, off_t off,
 			int count, int *eof, void *data)
 {
-	int k, len;
-	cpumask_t tmp = irq_affinity[(long)data];
+ 	int k, len;
+ 	cpumask_t tmp = irq_affinity[(long)data];
 
 	if (count < HEX_DIGITS+1)
 		return -EINVAL;
 
-	for (k = 0; k < sizeof(cpumask_t) / sizeof(u16); ++k) {
-		int j = sprintf(page, "%04hx", (u16)cpus_coerce(tmp));
-		len += j;
-		page += j;
-		cpus_shift_right(tmp, tmp, 16);
-	}
-	len += sprintf(page, "\n");
-	return len;
+ 	for (k = 0; k < sizeof(cpumask_t) / sizeof(u16); ++k) {
+ 		int j = sprintf(page, "%04hx", (u16)cpus_coerce(tmp));
+ 		len += j;
+ 		page += j;
+ 		cpus_shift_right(tmp, tmp, 16);
+ 	}
+ 	len += sprintf(page, "\n");
+ 	return len;
 }
 
 static unsigned int parse_hex_value (const char *buffer,
-		unsigned long count, cpumask_t *ret)
+		unsigned long count, long *ret)
 {
 	unsigned char hexnum [HEX_DIGITS];
 	cpumask_t value = CPU_MASK_NONE;
@@ -709,10 +1002,13 @@ out:
 static int irq_affinity_write_proc (struct file *file, const char *buffer,
 					unsigned long count, void *data)
 {
-	int irq = (long)data, full_count = count, err;
+	unsigned int irq = (long)data;
+	irq_desc_t *desc = get_irq_desc(irq);
+	struct hw_irq_stat *hwstat = get_irq_stat(desc);
+	int full_count = count, err;
 	cpumask_t new_value, tmp;
 
-	if (!irq_desc[irq].handler->set_affinity)
+	if (!desc->handler->set_affinity)
 		return -EIO;
 
 	err = parse_hex_value(buffer, count, &new_value);
@@ -726,9 +1022,8 @@ static int irq_affinity_write_proc (stru
 	if (cpus_empty(tmp))
 		return -EINVAL;
 
-	irq_affinity[irq] = new_value;
-	irq_desc[irq].handler->set_affinity(irq, new_value);
-
+	hwstat->irq_affinity = new_value;
+	desc->handler->set_affinity(irq, new_value);
 	return full_count;
 }
 
@@ -776,25 +1071,30 @@ static void register_irq_proc (unsigned 
 {
 	struct proc_dir_entry *entry;
 	char name [MAX_NAMELEN];
+	irq_desc_t *desc;
+	struct hw_irq_stat *hwstat;
 
-	if (!root_irq_dir || (irq_desc[irq].handler == NULL) || irq_dir[irq])
+	desc = get_real_irq_desc(irq);
+	if (!root_irq_dir || !desc || !desc->handler)
+		return;
+	hwstat = get_irq_stat(desc);
+	if (hwstat->irq_dir)
 		return;
 
 	memset(name, 0, MAX_NAMELEN);
 	sprintf(name, "%d", irq);
 
 	/* create /proc/irq/1234 */
-	irq_dir[irq] = proc_mkdir(name, root_irq_dir);
+	hwstat->irq_dir = proc_mkdir(name, root_irq_dir);	
 
 	/* create /proc/irq/1234/smp_affinity */
-	entry = create_proc_entry("smp_affinity", 0600, irq_dir[irq]);
+	entry = create_proc_entry("smp_affinity", 0600, hwstat->irq_dir);
 
 	entry->nlink = 1;
 	entry->data = (void *)(long)irq;
 	entry->read_proc = irq_affinity_read_proc;
 	entry->write_proc = irq_affinity_write_proc;
-
-	smp_affinity_entry[irq] = entry;
+	hwstat->smp_affinity = entry;
 }
 
 unsigned long prof_cpu_mask = -1;
@@ -818,8 +1118,8 @@ void init_irq_proc (void)
 	/*
 	 * Create entries for all existing IRQs.
 	 */
-	for (i = 0; i < NR_IRQS; i++) {
-		if (irq_desc[i].handler == NULL)
+	for_each_irq(i) {
+		if (get_irq_desc(i)->handler == NULL)
 			continue;
 		register_irq_proc(i);
 	}
diff -purN linux-2.5-latest/arch/ppc64/kernel/nvram.c linuxppc64-2.5-latest/arch/ppc64/kernel/nvram.c
--- linux-2.5-latest/arch/ppc64/kernel/nvram.c	2003-10-10 11:38:10.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/nvram.c	2003-10-10 11:33:19.000000000 +0200
@@ -116,7 +116,7 @@ int __init nvram_init(void)
 {
 	struct device_node *nvram;
 	unsigned int *nbytes_p, proplen;
-	if ((nvram = find_type_devices("nvram")) != NULL) {
+	if ((nvram = of_find_node_by_type(NULL, "nvram")) != NULL) {
 		nbytes_p = (unsigned int *)get_property(nvram, "#bytes", &proplen);
 		if (nbytes_p && proplen == sizeof(unsigned int)) {
 			rtas_nvram_size = *nbytes_p;
@@ -125,6 +125,7 @@ int __init nvram_init(void)
 	nvram_fetch = rtas_token("nvram-fetch");
 	nvram_store = rtas_token("nvram-store");
 	printk(KERN_INFO "PPC64 nvram contains %d bytes\n", rtas_nvram_size);
+	of_node_put(nvram);
 
 	return misc_register(&nvram_dev);
 }
diff -purN linux-2.5-latest/arch/ppc64/kernel/open_pic.c linuxppc64-2.5-latest/arch/ppc64/kernel/open_pic.c
--- linux-2.5-latest/arch/ppc64/kernel/open_pic.c	2003-10-10 11:39:09.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/open_pic.c	2003-10-10 11:34:29.000000000 +0200
@@ -130,19 +130,29 @@ unsigned int openpic_vec_spurious;
 
 #define GET_ISU(source)	ISU[(source) >> 4][(source) & 0xf]
 
+void
+openpic_init_irq_desc(irq_desc_t *desc)
+{
+	/* Don't mess with the handler if already set.
+	 * This leaves the setup of isa/ipi handlers undisturbed.
+	 */
+	if (!desc->handler)
+		desc->handler = &open_pic;
+}
+
 void __init openpic_init_IRQ(void)
 {
         struct device_node *np;
         int i;
         unsigned int *addrp;
         unsigned char* chrp_int_ack_special = 0;
-        unsigned char init_senses[NR_IRQS - NUM_8259_INTERRUPTS];
+        unsigned char init_senses[NR_IRQS - NUM_ISA_INTERRUPTS];
         int nmi_irq = -1;
 #if defined(CONFIG_VT) && defined(CONFIG_ADB_KEYBOARD) && defined(XMON)
         struct device_node *kbd;
 #endif
 
-        if (!(np = find_devices("pci"))
+        if (!(np = of_find_node_by_name(NULL, "pci"))
             || !(addrp = (unsigned int *)
                  get_property(np, "8259-interrupt-acknowledge", NULL)))
                 printk(KERN_ERR "Cannot find pci to get ack address\n");
@@ -151,13 +161,14 @@ void __init openpic_init_IRQ(void)
 			__ioremap(addrp[prom_n_addr_cells(np)-1], 1, _PAGE_NO_CACHE);
         /* hydra still sets OpenPIC_InitSenses to a static set of values */
         if (OpenPIC_InitSenses == NULL) {
-                prom_get_irq_senses(init_senses, NUM_8259_INTERRUPTS, NR_IRQS);
+                prom_get_irq_senses(init_senses, NUM_ISA_INTERRUPTS, NR_IRQS);
                 OpenPIC_InitSenses = init_senses;
-                OpenPIC_NumInitSenses = NR_IRQS - NUM_8259_INTERRUPTS;
+                OpenPIC_NumInitSenses = NR_IRQS - NUM_ISA_INTERRUPTS;
         }
-        openpic_init(1, NUM_8259_INTERRUPTS, chrp_int_ack_special, nmi_irq);
-        for ( i = 0 ; i < NUM_8259_INTERRUPTS  ; i++ )
-                irq_desc[i].handler = &i8259_pic;
+        openpic_init(1, NUM_ISA_INTERRUPTS, chrp_int_ack_special, nmi_irq);
+        for ( i = 0 ; i < NUM_ISA_INTERRUPTS  ; i++ )
+                get_real_irq_desc(i)->handler = &i8259_pic;
+	of_node_put(np);
 }
 
 static inline u_int openpic_read(volatile u_int *addr)
@@ -341,8 +352,8 @@ void __init openpic_init(int main_pic, i
 		/* Disabled, Priority 10..13 */
 		openpic_initipi(i, 10+i, openpic_vec_ipi+i);
 		/* IPIs are per-CPU */
-		irq_desc[openpic_vec_ipi+i].status |= IRQ_PER_CPU;
-		irq_desc[openpic_vec_ipi+i].handler = &open_pic_ipi;
+		get_real_irq_desc(openpic_vec_ipi+i)->status |= IRQ_PER_CPU;
+		get_real_irq_desc(openpic_vec_ipi+i)->handler = &open_pic_ipi;
 	}
 #endif
 
@@ -367,7 +378,7 @@ void __init openpic_init(int main_pic, i
 		pri = (i == programmer_switch_irq)? 9: 8;
 		sense = (i < OpenPIC_NumInitSenses)? OpenPIC_InitSenses[i]: 1;
 		if (sense)
-			irq_desc[i+offset].status = IRQ_LEVEL;
+			get_real_irq_desc(i+offset)->status = IRQ_LEVEL;
 
 		/* Enabled, Priority 8 or 9 */
 		openpic_initirq(i, pri, i+offset, !sense, sense);
@@ -375,10 +386,6 @@ void __init openpic_init(int main_pic, i
 		openpic_mapirq(i, 1 << boot_cpuid);
 	}
 
-	/* Init descriptors */
-	for (i = offset; i < NumSources + offset; i++)
-		irq_desc[i].handler = &open_pic;
-
 	/* Initialize the spurious interrupt */
 	ppc64_boot_msg(0x24, "OpenPic Spurious");
 	openpic_set_spurious(openpic_vec_spurious);
@@ -397,7 +404,7 @@ static int __init openpic_setup_i8259(vo
 {
 	if (naca->interrupt_controller == IC_OPEN_PIC) {
 		/* Initialize the cascade */
-		if (request_irq(NUM_8259_INTERRUPTS, no_action, SA_INTERRUPT,
+		if (request_irq(NUM_ISA_INTERRUPTS, no_action, SA_INTERRUPT,
 				"82c59 cascade", NULL))
 			printk(KERN_ERR "Unable to get OpenPIC IRQ 0 for cascade\n");
 		i8259_init();
@@ -753,7 +760,7 @@ static inline void openpic_set_sense(u_i
 
 static void openpic_end_irq(unsigned int irq_nr)
 {
-	if ((irq_desc[irq_nr].status & IRQ_LEVEL) != 0)
+	if ((get_irq_desc(irq_nr)->status & IRQ_LEVEL) != 0)
 		openpic_eoi();
 }
 
diff -purN linux-2.5-latest/arch/ppc64/kernel/open_pic.h linuxppc64-2.5-latest/arch/ppc64/kernel/open_pic.h
--- linux-2.5-latest/arch/ppc64/kernel/open_pic.h	2003-10-10 11:38:18.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/open_pic.h	2003-10-10 11:33:29.000000000 +0200
@@ -38,9 +38,4 @@ extern void openpic_init_processor(u_int
 extern void openpic_setup_ISU(int isu_num, unsigned long addr);
 extern void openpic_cause_IPI(u_int ipi, u_int cpumask);
 
-extern inline int openpic_to_irq(int irq)
-{
-	return irq += NUM_8259_INTERRUPTS;
-}
-/*extern int open_pic_irq_offset;*/
 #endif /* _PPC64_KERNEL_OPEN_PIC_H */
diff -purN linux-2.5-latest/arch/ppc64/kernel/pSeries_htab.c linuxppc64-2.5-latest/arch/ppc64/kernel/pSeries_htab.c
--- linux-2.5-latest/arch/ppc64/kernel/pSeries_htab.c	2003-10-10 11:38:42.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/pSeries_htab.c	2003-10-10 11:33:59.000000000 +0200
@@ -389,10 +389,11 @@ void hpte_init_pSeries(void)
 	ppc_md.hpte_remove     	= pSeries_hpte_remove;
 
 	/* Disable TLB batching on nighthawk */
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	if (root) {
 		model = get_property(root, "model", NULL);
 		if (strcmp(model, "CHRP IBM,9076-N81"))
 			ppc_md.flush_hash_range = pSeries_flush_hash_range;
+		of_node_put(root);
 	}
 }
diff -purN linux-2.5-latest/arch/ppc64/kernel/pSeries_hvCall.S linuxppc64-2.5-latest/arch/ppc64/kernel/pSeries_hvCall.S
--- linux-2.5-latest/arch/ppc64/kernel/pSeries_hvCall.S	2003-10-10 11:40:06.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/pSeries_hvCall.S	2003-10-10 11:35:12.000000000 +0200
@@ -67,3 +67,35 @@ _GLOBAL(plpar_hcall_norets)
 	ld	r0,-8(r1)
 	mtcrf	0xff,r0
 	blr                     /* return r3 = status */
+
+
+/* long plpar_hcall_8arg_2ret(unsigned long opcode,		 R3 
+			     unsigned long arg1,		 R4 
+		 	     unsigned long arg2,		 R5 
+			     unsigned long arg3,		 R6 
+	 		     unsigned long arg4,		 R7 
+	 		     unsigned long arg5,		 R8 
+			     unsigned long arg6,		 R9 
+	 		     unsigned long arg7,		 R10 
+	 		     unsigned long arg8,		 R11
+	 		     unsigned long *out1);		 R12	
+
+ */
+
+	.text
+_GLOBAL(plpar_hcall_8arg_2ret)
+	mfcr	r0
+	std	r0,-8(r1)
+	stdu	r1,-32(r1)
+
+        std     r12,-8(r1)      /* Save out ptr */
+	
+	HSC                     /* invoke the hypervisor */
+
+        ld      r10,-8(r1)      /* Fetch r4 ret arg */
+        std     r4,0(r10)
+
+	ld	r1,0(r1)
+	ld	r0,-8(r1)
+	mtcrf	0xff,r0
+	blr                     /* return r3 = status */
diff -purN linux-2.5-latest/arch/ppc64/kernel/pSeries_lpar.c linuxppc64-2.5-latest/arch/ppc64/kernel/pSeries_lpar.c
--- linux-2.5-latest/arch/ppc64/kernel/pSeries_lpar.c	2003-10-10 11:40:17.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/pSeries_lpar.c	2003-10-10 11:35:20.000000000 +0200
@@ -234,12 +234,14 @@ void pSeriesLP_init_early(void)
 	 * is the starting termno (the one we use) and the second is the
 	 * number of terminals.
 	 */
-	np = find_path_device("/rtas");
+	np = of_find_node_by_path("/rtas");
 	if (np) {
 		u32 *termno = (u32 *)get_property(np, "ibm,termno", 0);
 		if (termno)
 			vtermno = termno[0];
+		of_node_put(np);
 	}
+
 	ppc_md.udbg_putc = udbg_putcLP;
 	ppc_md.udbg_getc = udbg_getcLP;
 	ppc_md.udbg_getc_poll = udbg_getc_pollLP;
@@ -289,20 +291,19 @@ int hvc_count(int *start_termno)
 {
 	u32 *termno;
 	struct device_node *dn;
+	int ret = 0;
 
-	if ((dn = find_path_device("/rtas")) != NULL) {
+	if ((dn = of_find_node_by_path("/rtas")) != NULL) {
 		if ((termno = (u32 *)get_property(dn, "ibm,termno", 0)) != NULL) {
 			if (start_termno)
 				*start_termno = termno[0];
-			return termno[1];
+			ret = termno[1];
 		}
+		of_node_put(dn);
 	}
-	return 0;
+	return ret;
 }
 
-
-
-
 long pSeries_lpar_hpte_insert(unsigned long hpte_group,
 			      unsigned long va, unsigned long prpn,
 			      int secondary, unsigned long hpteflags,
diff -purN linux-2.5-latest/arch/ppc64/kernel/pSeries_pci.c linuxppc64-2.5-latest/arch/ppc64/kernel/pSeries_pci.c
--- linux-2.5-latest/arch/ppc64/kernel/pSeries_pci.c	2003-10-10 11:40:23.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/pSeries_pci.c	2003-10-10 11:35:24.000000000 +0200
@@ -188,6 +188,7 @@ static void __init pci_process_bridge_OF
 	struct resource *res;
 	int np, na = prom_n_addr_cells(dev);
 	unsigned long pci_addr, cpu_phys_addr;
+	struct device_node *isa_dn;
 
 	np = na + 5;
 
@@ -219,8 +220,11 @@ static void __init pci_process_bridge_OF
 						       size, _PAGE_NO_CACHE);
 			if (primary) {
 				pci_io_base = (unsigned long)hose->io_base_virt;
-				if (find_type_devices("isa"))
+				isa_dn = of_find_node_by_type(NULL, "isa");
+				if (isa_dn) {
 					isa_io_base = pci_io_base;
+					of_node_put(isa_dn);
+				}
 			}
 
 			res = &hose->io_resource;
@@ -386,7 +390,7 @@ unsigned long __init find_and_init_phbs(
 	unsigned int root_size_cells = 0;
 	unsigned int index;
 	unsigned int *opprop;
-	struct device_node *root = find_path_device("/");
+	struct device_node *root = of_find_node_by_path("/");
 
 	read_pci_config = rtas_token("read-pci-config");
 	write_pci_config = rtas_token("write-pci-config");
@@ -402,7 +406,9 @@ unsigned long __init find_and_init_phbs(
 
 	index = 0;
 
-	for (node = root->child; node != NULL; node = node->sibling) {
+	for (node = of_get_next_child(root, NULL);
+	     node != NULL;
+	     node = of_get_next_child(root, node)) {
 		if (node->type == NULL || strcmp(node->type, "pci") != 0)
 			continue;
 
@@ -420,6 +426,7 @@ unsigned long __init find_and_init_phbs(
 		index++;
 	}
 
+	of_node_put(root);
 	pci_devs_phb_init();
 
 	return 0;
@@ -525,11 +532,12 @@ static void check_s7a(void)
 	struct device_node *root;
 	char *model;
 
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	if (root) {
 		model = get_property(root, "model", NULL);
 		if (model && !strcmp(model, "IBM,7013-S7A"))
 			s7a_workaround = 1;
+		of_node_put(root);
 	}
 }
 
diff -purN linux-2.5-latest/arch/ppc64/kernel/pci.c linuxppc64-2.5-latest/arch/ppc64/kernel/pci.c
--- linux-2.5-latest/arch/ppc64/kernel/pci.c	2003-10-10 11:39:48.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/pci.c	2003-10-10 11:35:01.000000000 +0200
@@ -126,6 +126,7 @@ struct pci_dev *pci_find_dev_by_addr(uns
 	while ((dev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL) {
 		if ((dev->class >> 16) == PCI_BASE_CLASS_BRIDGE)
 			continue;
+		
 		for (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {
 			unsigned long start = pci_resource_start(dev,i);
 			unsigned long end = pci_resource_end(dev,i);
diff -purN linux-2.5-latest/arch/ppc64/kernel/pci_dma.c linuxppc64-2.5-latest/arch/ppc64/kernel/pci_dma.c
--- linux-2.5-latest/arch/ppc64/kernel/pci_dma.c	2003-10-10 11:39:13.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/pci_dma.c	2003-10-10 11:34:32.000000000 +0200
@@ -98,7 +98,7 @@ void free_tce_range_nolock(struct TceTab
 			   unsigned order );
 
 /* allocates a range of tces and sets them to the pages  */
-static inline dma_addr_t get_tces( struct TceTable *, 
+/*static*/ inline dma_addr_t get_tces( struct TceTable *, 
 				   unsigned order, 
 				   void *page, 
 				   unsigned numPages,
@@ -210,7 +210,7 @@ static void tce_build_pSeries(struct Tce
  * Build a TceTable structure.  This contains a multi-level bit map which
  * is used to manage allocation of the tce space.
  */
-static struct TceTable *build_tce_table( struct TceTable * tbl )
+/*static*/ struct TceTable *build_tce_table( struct TceTable * tbl )
 {
 	unsigned long bits, bytes, totalBytes;
 	unsigned long numBits[NUM_TCE_LEVELS], numBytes[NUM_TCE_LEVELS];
@@ -518,7 +518,7 @@ static long test_tce_range( struct TceTa
 	return retval;
 }
 
-static inline dma_addr_t get_tces( struct TceTable *tbl, unsigned order, void *page, unsigned numPages, int direction )
+/*static*/ inline dma_addr_t get_tces( struct TceTable *tbl, unsigned order, void *page, unsigned numPages, int direction )
 {
 	long tcenum;
 	unsigned long uaddr;
@@ -581,7 +581,7 @@ static void tce_free_one_pSeries( struct
 }
 #endif
 
-static void tce_free(struct TceTable *tbl, dma_addr_t dma_addr, 
+/*static*/ void tce_free(struct TceTable *tbl, dma_addr_t dma_addr, 
 			     unsigned order, unsigned num_pages)
 {
 	long tcenum, total_tces, free_tce;
diff -purN linux-2.5-latest/arch/ppc64/kernel/ppc_ksyms.c linuxppc64-2.5-latest/arch/ppc64/kernel/ppc_ksyms.c
--- linux-2.5-latest/arch/ppc64/kernel/ppc_ksyms.c	2003-10-10 11:38:29.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/ppc_ksyms.c	2003-10-10 11:33:41.000000000 +0200
@@ -203,7 +203,6 @@ EXPORT_SYMBOL_NOVERS(memcmp);
 EXPORT_SYMBOL(abs);
 
 EXPORT_SYMBOL(timer_interrupt);
-EXPORT_SYMBOL(irq_desc);
 EXPORT_SYMBOL(get_wchan);
 EXPORT_SYMBOL(console_drivers);
 #ifdef CONFIG_XMON
diff -purN linux-2.5-latest/arch/ppc64/kernel/prom.c linuxppc64-2.5-latest/arch/ppc64/kernel/prom.c
--- linux-2.5-latest/arch/ppc64/kernel/prom.c	2003-10-10 11:39:29.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/prom.c	2003-10-10 11:34:46.000000000 +0200
@@ -150,13 +150,8 @@ int boot_cpuid = 0;
 
 struct device_node *allnodes = 0;
 
-#define UNDEFINED_IRQ 0xffff
-unsigned short real_irq_to_virt_map[NR_HW_IRQS];
-unsigned short virt_irq_to_real_map[NR_IRQS];
-int last_virt_irq = 2;	/* index of last virt_irq.  Skip through IPI */
-
 static unsigned long call_prom(const char *service, int nargs, int nret, ...);
-static void prom_exit(void);
+static void prom_panic(const char *reason);
 static unsigned long copy_device_tree(unsigned long);
 static unsigned long inspect_node(phandle, struct device_node *, unsigned long,
 				  unsigned long, struct device_node ***);
@@ -223,10 +218,12 @@ call_prom(const char *service, int nargs
 
 
 static void __init
-prom_exit()
+prom_panic(const char *reason)
 {
 	unsigned long offset = reloc_offset();
 
+	prom_print(reason);
+	/* ToDo: should put up an SRC here */
 	call_prom(RELOC("exit"), 0, 0);
 
 	for (;;)			/* should never get here */
@@ -785,8 +782,7 @@ prom_initialize_tce_table(void)
 		base = lmb_alloc(minsize, align);
 
 		if ( !base ) {
-			prom_print(RELOC("ERROR, cannot find space for TCE table.\n"));
-			prom_exit();
+			prom_panic(RELOC("ERROR, cannot find space for TCE table.\n"));
 		}
 
 		vbase = absolute_to_virt(base);
@@ -1060,7 +1056,7 @@ prom_init(unsigned long r3, unsigned lon
 	  unsigned long r6, unsigned long r7)
 {
 	unsigned long mem;
-	ihandle prom_root, prom_cpu;
+	ihandle prom_mmu,prom_root, prom_cpu;
 	phandle cpu_pkg;
 	unsigned long offset = reloc_offset();
 	long l;
@@ -1092,12 +1088,12 @@ prom_init(unsigned long r3, unsigned lon
 				       RELOC("/chosen"));
 
 	if ((long)_prom->chosen <= 0)
-		prom_exit();
+		prom_panic(RELOC("cannot find chosen")); /* msg won't be printed :( */
 
         if ((long)call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
 			    RELOC("stdout"), &getprop_rval,
 			    sizeof(getprop_rval)) <= 0)
-                prom_exit();
+                prom_panic(RELOC("cannot find stdout"));
 
         _prom->stdout = (ihandle)(unsigned long)getprop_rval;
 
@@ -1123,7 +1119,7 @@ prom_init(unsigned long r3, unsigned lon
         if ((long)call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
 			    RELOC("cpu"), &getprop_rval,
 			    sizeof(getprop_rval)) <= 0)
-                prom_exit();
+                prom_panic(RELOC("cannot find boot cpu"));
 
 	prom_cpu = (ihandle)(unsigned long)getprop_rval;
 	cpu_pkg = call_prom(RELOC("instance-to-package"), 1, 1, prom_cpu);
@@ -1188,9 +1184,34 @@ prom_init(unsigned long r3, unsigned lon
 	if (_systemcfg->platform == PLATFORM_PSERIES)
 		prom_initialize_tce_table();
 
-	prom_print(RELOC("Calling quiesce ...\n"));
-	call_prom(RELOC("quiesce"), 0, 0);
-	phys = KERNELBASE - offset;
+ 	if ((long) call_prom(RELOC("getprop"), 4, 1,
+				_prom->chosen,
+				RELOC("mmu"),
+				&getprop_rval,
+				sizeof(getprop_rval)) <= 0) {	
+                prom_panic(RELOC(" no MMU found\n"));
+	}
+
+	/* We assume the phys. address size is 3 cells */
+	RELOC(prom_mmu) = (ihandle)(unsigned long)getprop_rval;
+
+	if ((long)call_prom(RELOC("call-method"), 4, 4,
+				RELOC("translate"),
+				prom_mmu,
+				(void *)(KERNELBASE - offset),
+				(void *)1) != 0) {
+		prom_print(RELOC(" (translate failed) "));
+	} else {
+		prom_print(RELOC(" (translate ok) "));
+		phys = (unsigned long)_prom->args.rets[3];
+	}
+
+	/* If OpenFirmware version >= 3, then use quiesce call */
+	if (_prom->version >= 3) {
+		prom_print(RELOC("Calling quiesce ...\n"));
+		call_prom(RELOC("quiesce"), 0, 0);
+		phys = KERNELBASE - offset;
+	}
 
 	prom_print(RELOC("returning from prom_init\n"));
 	return phys;
@@ -1308,46 +1329,6 @@ check_display(unsigned long mem)
 	return DOUBLEWORD_ALIGN(mem);
 }
 
-void
-virt_irq_init(void)
-{
-	int i;
-	for (i = 0; i < NR_IRQS; i++)
-		virt_irq_to_real_map[i] = UNDEFINED_IRQ;
-	for (i = 0; i < NR_HW_IRQS; i++)
-		real_irq_to_virt_map[i] = UNDEFINED_IRQ;
-}
-
-/* Create a mapping for a real_irq if it doesn't already exist.
- * Return the virtual irq as a convenience.
- */
-unsigned long
-virt_irq_create_mapping(unsigned long real_irq)
-{
-	unsigned long virq;
-	if (naca->interrupt_controller == IC_OPEN_PIC)
-		return real_irq;	/* no mapping for openpic (for now) */
-	virq = real_irq_to_virt(real_irq);
-	if (virq == UNDEFINED_IRQ) {
-		/* Assign a virtual IRQ number */
-		if (real_irq < NR_IRQS && virt_irq_to_real(real_irq) == UNDEFINED_IRQ) {
-			/* A 1-1 mapping will work. */
-			virq = real_irq;
-		} else {
-			while (last_virt_irq < NR_IRQS &&
-			       virt_irq_to_real(++last_virt_irq) != UNDEFINED_IRQ)
-				/* skip irq's in use */;
-			if (last_virt_irq >= NR_IRQS)
-				panic("Too many IRQs are required on this system.  NR_IRQS=%d\n", NR_IRQS);
-			virq = last_virt_irq;
-		}
-		virt_irq_to_real_map[virq] = real_irq;
-		real_irq_to_virt_map[real_irq] = virq;
-	}
-	return virq;
-}
-
-
 static int __init
 prom_next_node(phandle *nodep)
 {
@@ -1381,8 +1362,7 @@ copy_device_tree(unsigned long mem_start
 
 	root = call_prom(RELOC("peer"), 1, 1, (phandle)0);
 	if (root == (phandle)0) {
-		prom_print(RELOC("couldn't get device tree root\n"));
-		prom_exit();
+		prom_panic(RELOC("couldn't get device tree root\n"));
 	}
 	allnextp = &RELOC(allnodes);
 	mem_start = DOUBLEWORD_ALIGN(mem_start);
@@ -1477,8 +1457,6 @@ finish_device_tree(void)
 {
 	unsigned long mem = klimit;
 
-	virt_irq_init();
-
 	mem = finish_node(allnodes, mem, NULL, 0, 0);
 	dev_tree_size = mem - (unsigned long) allnodes;
 
@@ -1487,7 +1465,7 @@ finish_device_tree(void)
 
 	klimit = mem;
 
-	rtas.dev = find_devices("rtas");
+	rtas.dev = of_find_node_by_name(NULL, "rtas");
 }
 
 static unsigned long __init
@@ -1704,7 +1682,7 @@ finish_node_interrupts(struct device_nod
 		n = map_interrupt(&irq, &ic, np, ints, intrcells);
 		if (n <= 0)
 			continue;
-		np->intrs[i].line = openpic_to_irq(virt_irq_create_mapping(irq[0]));
+		np->intrs[i].line = irq_offset_up(irq[0]);
 		if (n > 1)
 			np->intrs[i].sense = irq[1];
 		if (n > 2) {
@@ -1939,11 +1917,14 @@ int
 machine_is_compatible(const char *compat)
 {
 	struct device_node *root;
-	
-	root = find_path_device("/");
-	if (root == 0)
-		return 0;
-	return device_is_compatible(root, compat);
+	int rc = 0;
+  
+	root = of_find_node_by_path("/");
+	if (root) {
+		rc = device_is_compatible(root, compat);
+		of_node_put(root);
+	}
+	return rc;
 }
 
 /*
@@ -1983,6 +1964,185 @@ find_path_device(const char *path)
 	return NULL;
 }
 
+/*******
+ *
+ * New implementation of the OF "find" APIs, return a refcounted
+ * object, call of_node_put() when done. Currently, still lacks
+ * locking as old implementation, this is being done for ppc64.
+ *
+ * Note that property management will need some locking as well,
+ * this isn't dealt with yet.
+ *
+ *******/
+
+/**
+ *	of_find_node_by_name - Find a node by its "name" property
+ *	@from:	The node to start searching from or NULL, the node
+ *		you pass will not be searched, only the next one
+ *		will; typically, you pass what the previous call
+ *		returned. of_node_put() will be called on it
+ *	@name:	The name string to match against
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_node_by_name(struct device_node *from,
+	const char *name)
+{
+	struct device_node *np = from ? from->allnext : allnodes;
+
+	for (; np != 0; np = np->allnext)
+		if (np->name != 0 && strcasecmp(np->name, name) == 0)
+			break;
+	if (from)
+		of_node_put(from);
+	return of_node_get(np);
+}
+
+/**
+ *	of_find_node_by_type - Find a node by its "device_type" property
+ *	@from:	The node to start searching from or NULL, the node
+ *		you pass will not be searched, only the next one
+ *		will; typically, you pass what the previous call
+ *		returned. of_node_put() will be called on it
+ *	@name:	The type string to match against
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_node_by_type(struct device_node *from,
+	const char *type)
+{
+	struct device_node *np = from ? from->allnext : allnodes;
+
+	for (; np != 0; np = np->allnext)
+		if (np->type != 0 && strcasecmp(np->type, type) == 0)
+			break;
+	if (from)
+		of_node_put(from);
+	return of_node_get(np);
+}
+
+/**
+ *	of_find_compatible_node - Find a node based on type and one of the
+ *                                tokens in its "compatible" property
+ *	@from:		The node to start searching from or NULL, the node
+ *			you pass will not be searched, only the next one
+ *			will; typically, you pass what the previous call
+ *			returned. of_node_put() will be called on it
+ *	@type:		The type string to match "device_type" or NULL to ignore
+ *	@compatible:	The string to match to one of the tokens in the device
+ *			"compatible" list.
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_compatible_node(struct device_node *from,
+	const char *type, const char *compatible)
+{
+	struct device_node *np = from ? from->allnext : allnodes;
+
+	for (; np != 0; np = np->allnext) {
+		if (type != NULL
+		    && !(np->type != 0 && strcasecmp(np->type, type) == 0))
+			continue;
+		if (device_is_compatible(np, compatible))
+			break;
+	}
+	if (from)
+		of_node_put(from);
+	return of_node_get(np);
+}
+
+/**
+ *	of_find_node_by_path - Find a node matching a full OF path
+ *	@path:	The full path to match
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_node_by_path(const char *path)
+{
+	struct device_node *np = allnodes;
+
+	for (; np != 0; np = np->allnext)
+		if (np->full_name != 0 && strcasecmp(np->full_name, path) == 0)
+			break;
+	return of_node_get(np);
+}
+
+/**
+ *	of_find_all_nodes - Get next node in global list
+ *	@prev:	Previous node or NULL to start iteration
+ *		of_node_put() will be called on it
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_all_nodes(struct device_node *prev)
+{
+	struct device_node *np = prev ? prev->allnext : allnodes;
+
+	if (prev)
+		of_node_put(prev);
+	return of_node_get(np);
+}
+
+/**
+ *	of_get_parent - Get a node's parent if any
+ *	@node:	Node to get parent
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_get_parent(const struct device_node *node)
+{
+	return node ? of_node_get(node->parent) : NULL;
+}
+
+/**
+ *	of_get_next_child - Iterate a node childs
+ *	@node:	parent node
+ *	@prev:	previous child of the parent node, or NULL to get first
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_get_next_child(const struct device_node *node,
+	struct device_node *prev)
+{
+	struct device_node *next = prev ? prev->sibling : node->child;
+
+	for (; next != 0; next = next->sibling)
+		if (of_node_get(next))
+			break;
+	if (prev)
+		of_node_put(prev);
+	return next;
+}
+
+/**
+ *	of_node_get - Increment refcount of a node
+ *	@node:	Node to inc refcount, NULL is supported to
+ *		simplify writing of callers
+ *
+ *	Returns the node itself or NULL if gone.
+ */
+struct device_node *of_node_get(struct device_node *node)
+{
+	return node;
+}
+
+/**
+ *	of_node_put - Decrement refcount of a node
+ *	@node:	Node to dec refcount, NULL is supported to
+ *		simplify writing of callers
+ *
+ */
+void of_node_put(struct device_node *node)
+{
+}
+
 /*
  * Find the device_node with a given phandle.
  */
@@ -2082,17 +2242,6 @@ print_properties(struct device_node *np)
 #endif
 
 
-void __init
-abort()
-{
-#ifdef CONFIG_XMON
-	xmon(NULL);
-#endif
-	for (;;)
-		prom_exit();
-}
-
-
 /* Verify bi_recs are good */
 static struct bi_record *
 prom_bi_rec_verify(struct bi_record *bi_recs)
diff -purN linux-2.5-latest/arch/ppc64/kernel/ras.c linuxppc64-2.5-latest/arch/ppc64/kernel/ras.c
--- linux-2.5-latest/arch/ppc64/kernel/ras.c	2003-10-10 11:38:38.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/ras.c	2003-10-10 11:33:54.000000000 +0200
@@ -1,4 +1,3 @@
-
 /*
  * ras.c
  * Copyright (C) 2001 Dave Engebretsen IBM Corporation
@@ -70,27 +69,29 @@ static int __init init_ras_IRQ(void)
 	struct device_node *np;
 	unsigned int *ireg, len, i;
 
-	if((np = find_path_device("/event-sources/internal-errors")) &&
-	   (ireg = (unsigned int *)get_property(np, "open-pic-interrupt", 
-						&len))) {
-		for(i=0; i<(len / sizeof(*ireg)); i++) {
-			request_irq(virt_irq_create_mapping(*(ireg)) + NUM_8259_INTERRUPTS, 
+	if ((np = of_find_node_by_path("/event-sources/internal-errors")) &&
+	    (ireg = (unsigned int *)get_property(np, "open-pic-interrupt",
+						 &len))) {
+		for (i=0; i<(len / sizeof(*ireg)); i++) {
+			request_irq(irq_offset_up(*(ireg)), 
 				    ras_error_interrupt, 0, 
 				    "RAS_ERROR", NULL);
 			ireg++;
 		}
 	}
+	of_node_put(np);
 
-	if((np = find_path_device("/event-sources/epow-events")) &&
-	   (ireg = (unsigned int *)get_property(np, "open-pic-interrupt", 
-						&len))) {
-		for(i=0; i<(len / sizeof(*ireg)); i++) {
-			request_irq(virt_irq_create_mapping(*(ireg)) + NUM_8259_INTERRUPTS, 
+	if ((np = of_find_node_by_path("/event-sources/epow-events")) &&
+	    (ireg = (unsigned int *)get_property(np, "open-pic-interrupt",
+						 &len))) {
+		for (i=0; i<(len / sizeof(*ireg)); i++) {
+			request_irq(irq_offset_up(*(ireg)),
 				    ras_epow_interrupt, 0, 
 				    "RAS_EPOW", NULL);
 			ireg++;
 		}
 	}
+	of_node_put(np);
 
 	return 1;
 }
diff -purN linux-2.5-latest/arch/ppc64/kernel/rtas-proc.c linuxppc64-2.5-latest/arch/ppc64/kernel/rtas-proc.c
--- linux-2.5-latest/arch/ppc64/kernel/rtas-proc.c	2003-10-10 11:38:54.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/rtas-proc.c	2003-10-10 11:34:12.000000000 +0200
@@ -200,7 +200,7 @@ void proc_rtas_init(void)
 {
 	struct proc_dir_entry *entry;
 
-	rtas_node = find_devices("rtas");
+	rtas_node = of_find_node_by_name(NULL, "rtas");
 	if ((rtas_node == NULL) || (systemcfg->platform == PLATFORM_ISERIES_LPAR)) {
 		return;
 	}
diff -purN linux-2.5-latest/arch/ppc64/kernel/rtasd.c linuxppc64-2.5-latest/arch/ppc64/kernel/rtasd.c
--- linux-2.5-latest/arch/ppc64/kernel/rtasd.c	2003-10-10 11:38:38.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/rtasd.c	2003-10-10 11:33:55.000000000 +0200
@@ -165,11 +165,12 @@ static int get_eventscan_parms(void)
 	struct device_node *node;
 	int *ip;
 
-	node = find_path_device("/rtas");
+	node = of_find_node_by_path("/rtas");
 
 	ip = (int *)get_property(node, "rtas-event-scan-rate", NULL);
 	if (ip == NULL) {
 		printk(KERN_ERR "rtasd: no rtas-event-scan-rate\n");
+		of_node_put(node);
 		return -1;
 	}
 	rtas_event_scan_rate = *ip;
@@ -178,6 +179,7 @@ static int get_eventscan_parms(void)
 	ip = (int *)get_property(node, "rtas-error-log-max", NULL);
 	if (ip == NULL) {
 		printk(KERN_ERR "rtasd: no rtas-error-log-max\n");
+		of_node_put(node);
 		return -1;
 	}
 	rtas_error_log_max = *ip;
@@ -187,6 +189,7 @@ static int get_eventscan_parms(void)
 		printk(KERN_ERR "rtasd: truncated error log from %d to %d bytes\n", rtas_error_log_max, RTAS_ERROR_LOG_MAX);
 		rtas_error_log_max = RTAS_ERROR_LOG_MAX;
 	}
+	of_node_put(node);
 
 	return 0;
 }
diff -purN linux-2.5-latest/arch/ppc64/kernel/setup.c linuxppc64-2.5-latest/arch/ppc64/kernel/setup.c
--- linux-2.5-latest/arch/ppc64/kernel/setup.c	2003-10-10 11:38:54.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/setup.c	2003-10-10 11:34:13.000000000 +0200
@@ -38,6 +38,7 @@
 #include <asm/paca.h>
 #include <asm/ppcdebug.h>
 #include <asm/time.h>
+#include <asm/cputable.h>
 #include <asm/sections.h>
 
 extern unsigned long klimit;
@@ -315,13 +316,14 @@ static int show_cpuinfo(struct seq_file 
 		struct device_node *cpu_node;
 		int *fp;
 
-		cpu_node = find_type_devices("cpu");
+		cpu_node = of_find_node_by_type(NULL, "cpu");
 		if (cpu_node) {
 			fp = (int *) get_property(cpu_node, "clock-frequency",
 						  NULL);
 			if (fp)
 				seq_printf(m, "clock\t\t: %dMHz\n",
 					   *fp / 1000000);
+			of_node_put(cpu_node);
 		}
 	}
 
@@ -375,11 +377,12 @@ void parse_cmd_line(unsigned long r3, un
 	strlcpy(cmd_line, CONFIG_CMDLINE, sizeof(cmd_line));
 #endif /* CONFIG_CMDLINE */
 
-	chosen = find_devices("chosen");
+	chosen = of_find_node_by_name(NULL, "chosen");
 	if (chosen != NULL) {
 		p = get_property(chosen, "bootargs", NULL);
 		if (p != NULL && p[0] != 0)
 			strlcpy(cmd_line, p, sizeof(cmd_line));
+		of_node_put(chosen);
 	}
 
 	/* Look for mem= option on command line */
diff -purN linux-2.5-latest/arch/ppc64/kernel/xics.c linuxppc64-2.5-latest/arch/ppc64/kernel/xics.c
--- linux-2.5-latest/arch/ppc64/kernel/xics.c	2003-10-10 11:39:04.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/kernel/xics.c	2003-10-10 11:34:25.000000000 +0200
@@ -35,6 +35,7 @@ void xics_disable_irq(u_int irq);
 void xics_mask_and_ack_irq(u_int irq);
 void xics_end_irq(u_int irq);
 void xics_set_affinity(unsigned int irq_nr, cpumask_t cpumask);
+void ppc64_boot_msg(unsigned int src, const char *msg);
 
 struct hw_interrupt_type xics_pic = {
 	" XICS     ",
@@ -58,7 +59,6 @@ struct hw_interrupt_type xics_8259_pic =
 };
 
 #define XICS_IPI		2
-#define XICS_IRQ_OFFSET		0x10
 #define XICS_IRQ_SPURIOUS	0
 
 /* Want a priority other than 0.  Various HW issues require this. */
@@ -214,14 +214,12 @@ xics_ops pSeriesLP_ops = {
 	pSeriesLP_qirr_info
 };
 
-void xics_enable_irq(u_int virq)
+void xics_enable_irq(unsigned int irq)
 {
-	u_int irq;
 	long call_status;
 	unsigned int server;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = irq_offset_down(irq);
 	if (irq == XICS_IPI)
 		return;
 
@@ -251,13 +249,11 @@ void xics_enable_irq(u_int virq)
 	}
 }
 
-void xics_disable_irq(u_int virq)
+void xics_disable_irq(unsigned int irq)
 {
-	u_int irq;
 	long call_status;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = irq_offset_down(irq);
 	if (irq == XICS_IPI)
 		return;
 
@@ -278,20 +274,20 @@ void xics_disable_irq(u_int virq)
 	}
 }
 
-void xics_end_irq(u_int	irq)
+void xics_end_irq(unsigned int irq)
 {
 	int cpu = smp_processor_id();
 
 	iosync();
-	ops->xirr_info_set(cpu, ((0xff<<24) |
-				 (virt_irq_to_real(irq-XICS_IRQ_OFFSET))));
+	ops->xirr_info_set(cpu, ((0xff<<24) | (irq_offset_down(irq))));
+
 }
 
 void xics_mask_and_ack_irq(u_int irq)
 {
 	int cpu = smp_processor_id();
 
-	if (irq < XICS_IRQ_OFFSET) {
+	if (irq < irq_offset_value()) {
 		i8259_pic.ack(irq);
 		iosync();
 		ops->xirr_info_set(cpu, ((0xff<<24) |
@@ -315,13 +311,14 @@ int xics_get_irq(struct pt_regs *regs)
 		irq = i8259_irq(cpu);
 		if (irq == -1) {
 			/* Spurious cascaded interrupt.  Still must ack xics */
-                        xics_end_irq(XICS_IRQ_OFFSET + xics_irq_8259_cascade);
+			xics_end_irq(irq_offset_up(xics_irq_8259_cascade));
+
 			irq = -1;
 		}
 	} else if (vec == XICS_IRQ_SPURIOUS) {
 		irq = -1;
 	} else {
-		irq = real_irq_to_virt(vec) + XICS_IRQ_OFFSET;
+		irq = irq_offset_up(vec);
 	}
 	return irq;
 }
@@ -379,6 +376,16 @@ void xics_setup_cpu(void)
 
 #endif /* CONFIG_SMP */
 
+void
+xics_init_irq_desc(irq_desc_t *desc)
+{
+	/* Don't mess with the handler if already set.
+	 * This leaves the setup of isa handlers undisturbed.
+	 */
+	if (!desc->handler)
+		desc->handler = &xics_pic;
+}
+
 void xics_init_IRQ(void)
 {
 	int i;
@@ -398,7 +405,7 @@ void xics_init_IRQ(void)
 	ibm_int_on  = rtas_token("ibm,int-on");
 	ibm_int_off = rtas_token("ibm,int-off");
 
-	np = find_type_devices("PowerPC-External-Interrupt-Presentation");
+	np = of_find_node_by_type(NULL, "PowerPC-External-Interrupt-Presentation");
 	if (!np) {
 		printk(KERN_WARNING "Can't find Interrupt Presentation\n");
 		udbg_printf("Can't find Interrupt Presentation\n");
@@ -433,11 +440,13 @@ nextnode:
 		if (indx >= NR_CPUS) break;
 	}
 
-	np = np->next;
+	np = of_find_node_by_type(np, "PowerPC-External-Interrupt-Presentation");
 	if ((indx < NR_CPUS) && np) goto nextnode;
 
 	/* Find the server numbers for the boot cpu. */
-	for (np = find_type_devices("cpu"); np; np = np->next) {
+	for (np = of_find_node_by_type(NULL, "cpu");
+	     np;
+	     np = of_find_node_by_type(np, "cpu")) {
 		ireg = (uint *)get_property(np, "reg", &ilen);
 		if (ireg && ireg[0] == smp_processor_id()) {
 			ireg = (uint *)get_property(np, "ibm,ppc-interrupt-gserver#s", &ilen);
@@ -449,11 +458,12 @@ nextnode:
 			break;
 		}
 	}
+	of_node_put(np);
 
 	intr_base = inodes[0].addr;
 	intr_size = (ulong)inodes[0].size;
 
-	np = find_type_devices("interrupt-controller");
+	np = of_find_node_by_type(NULL, "interrupt-controller");
 	if (!np) {
 		printk(KERN_WARNING "xics:  no ISA Interrupt Controller\n");
 		xics_irq_8259_cascade_real = -1;
@@ -466,7 +476,8 @@ nextnode:
 			while (1);
 		}
 		xics_irq_8259_cascade_real = *ireg;
-		xics_irq_8259_cascade = virt_irq_create_mapping(xics_irq_8259_cascade_real);
+		xics_irq_8259_cascade = xics_irq_8259_cascade_real;
+		of_node_put(np);
 	}
 
 	if (systemcfg->platform == PLATFORM_PSERIES) {
@@ -494,9 +505,7 @@ nextnode:
 	xics_8259_pic.enable = i8259_pic.enable;
 	xics_8259_pic.disable = i8259_pic.disable;
 	for (i = 0; i < 16; ++i)
-		irq_desc[i].handler = &xics_8259_pic;
-	for (; i < NR_IRQS; ++i)
-		irq_desc[i].handler = &xics_pic;
+		get_real_irq_desc(i)->handler = &xics_8259_pic;
 
 	ops->cppr_info(boot_cpuid, 0xff);
 	iosync();
@@ -512,7 +521,7 @@ static int __init xics_setup_i8259(void)
 {
 	if (naca->interrupt_controller == IC_PPC_XIC &&
 	    xics_irq_8259_cascade != -1) {
-		if (request_irq(xics_irq_8259_cascade + XICS_IRQ_OFFSET,
+		if (request_irq(irq_offset_up(xics_irq_8259_cascade), 
 				no_action, 0, "8259 cascade", 0))
 			printk(KERN_ERR "xics_init_IRQ: couldn't get 8259 cascade\n");
 		i8259_init();
@@ -524,19 +533,14 @@ arch_initcall(xics_setup_i8259);
 #ifdef CONFIG_SMP
 void xics_request_IPIs(void)
 {
-	real_irq_to_virt_map[XICS_IPI] = virt_irq_to_real_map[XICS_IPI] =
-		XICS_IPI;
-	/* IPIs are marked SA_INTERRUPT as they must run with irqs disabled */
-	request_irq(XICS_IPI + XICS_IRQ_OFFSET, xics_ipi_action, SA_INTERRUPT,
-		    "IPI", 0);
-	irq_desc[XICS_IPI+XICS_IRQ_OFFSET].status |= IRQ_PER_CPU;
+	request_irq(irq_offset_up(XICS_IPI), xics_ipi_action, SA_INTERRUPT, "IPI", 0);
+	get_real_irq_desc(irq_offset_up(XICS_IPI))->status |= IRQ_PER_CPU;
 }
 #endif
 
-void xics_set_affinity(unsigned int virq, cpumask_t cpumask)
+void xics_set_affinity(unsigned int irq, cpumask_t cpumask)
 {
-        irq_desc_t *desc = irq_desc + virq;
-	unsigned int irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 	long status;
 	unsigned long xics_status[2];
@@ -544,8 +548,7 @@ void xics_set_affinity(unsigned int virq
 	cpumask_t allcpus = CPU_MASK_ALL;
 	cpumask_t tmp = CPU_MASK_NONE;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = irq_offset_down(irq);
 	if (irq == XICS_IPI)
 		return;
 
diff -purN linux-2.5-latest/arch/ppc64/mm/numa.c linuxppc64-2.5-latest/arch/ppc64/mm/numa.c
--- linux-2.5-latest/arch/ppc64/mm/numa.c	2003-10-10 11:39:23.000000000 +0200
+++ linuxppc64-2.5-latest/arch/ppc64/mm/numa.c	2003-10-10 11:34:41.000000000 +0200
@@ -45,29 +45,29 @@ static inline void map_cpu_to_node(int c
 
 static int __init parse_numa_properties(void)
 {
-	struct device_node *cpu;
-	struct device_node *memory;
+	struct device_node *cpu = NULL;
+	struct device_node *memory = NULL;
 	int *cpu_associativity;
 	int *memory_associativity;
 	int depth;
 	int max_domain = 0;
 
-	cpu = find_type_devices("cpu");
+	cpu = of_find_node_by_type(NULL, "cpu");
 	if (!cpu)
-		return -1;
+		goto err;
 
-	memory = find_type_devices("memory");
+	memory = of_find_node_by_type(NULL, "memory");
 	if (!memory)
-		return -1;
+		goto err;
 
 	cpu_associativity = (int *)get_property(cpu, "ibm,associativity", NULL);
 	if (!cpu_associativity)
-		return -1;
+		goto err;
 
 	memory_associativity = (int *)get_property(memory, "ibm,associativity",
 						   NULL);
 	if (!memory_associativity)
-		return -1;
+		goto err;
 
 	/* find common depth */
 	if (cpu_associativity[0] < memory_associativity[0])
@@ -75,7 +75,7 @@ static int __init parse_numa_properties(
 	else
 		depth = memory_associativity[0];
 
-	for (cpu = find_type_devices("cpu"); cpu; cpu = cpu->next) {
+	for (; cpu; cpu = of_find_node_by_type(cpu, "cpu")) {
 		int *tmp;
 		int cpu_nr, numa_domain;
 
@@ -105,8 +105,7 @@ static int __init parse_numa_properties(
 		map_cpu_to_node(cpu_nr, numa_domain);
 	}
 
-	for (memory = find_type_devices("memory"); memory;
-	     memory = memory->next) {
+	for (; memory; memory = of_find_node_by_type(memory, "memory")) {
 		int *tmp1, *tmp2;
 		unsigned long i;
 		unsigned long start = 0;
@@ -195,6 +194,10 @@ new_range:
 	numnodes = max_domain + 1;
 
 	return 0;
+err:
+	of_node_put(cpu);
+	of_node_put(memory);
+	return -1;
 }
 
 void setup_nonnuma(void)
@@ -306,6 +309,7 @@ void __init paging_init(void)
 {
 	unsigned long zones_size[MAX_NR_ZONES];
 	int i, nid;
+	struct page *node_mem_map; 
 
 	for (i = 1; i < MAX_NR_ZONES; i++)
 		zones_size[i] = 0;
@@ -314,16 +318,24 @@ void __init paging_init(void)
 		unsigned long start_pfn;
 		unsigned long end_pfn;
 
-		if (node_data[nid].node_spanned_pages == 0)
-			continue;
-
 		start_pfn = plat_node_bdata[nid].node_boot_start >> PAGE_SHIFT;
 		end_pfn = plat_node_bdata[nid].node_low_pfn;
 
 		zones_size[ZONE_DMA] = end_pfn - start_pfn;
 		dbg("free_area_init node %d %lx %lx\n", nid,
 				zones_size[ZONE_DMA], start_pfn);
-		free_area_init_node(nid, NODE_DATA(nid), NULL, zones_size,
-				    start_pfn, NULL);
+
+		/* 
+		 * Give this empty node a dummy struct page to avoid
+		 * us from trying to allocate a node local mem_map
+		 * in free_area_init_node (which will fail).
+		 */
+		if (!node_data[nid].node_spanned_pages)
+			node_mem_map = alloc_bootmem(sizeof(struct page));
+		else
+			node_mem_map = NULL;
+
+		free_area_init_node(nid, NODE_DATA(nid), node_mem_map,
+				    zones_size, start_pfn, NULL);
 	}
 }
diff -purN linux-2.5-latest/drivers/net/e100/e100_main.c linuxppc64-2.5-latest/drivers/net/e100/e100_main.c
--- linux-2.5-latest/drivers/net/e100/e100_main.c	2003-10-10 11:38:54.000000000 +0200
+++ linuxppc64-2.5-latest/drivers/net/e100/e100_main.c	2003-10-10 11:34:14.000000000 +0200
@@ -1500,7 +1500,7 @@ e100_setup_tcb_pool(tcb_t *head, unsigne
 		pcurr_tcb->tcb_skb = NULL;
 	}
 
-	wmb();
+	mb();
 }
 
 /***************************************************************************/
@@ -1753,7 +1753,7 @@ e100_watchdog(struct net_device *dev)
 	/* Check for command completion on next watchdog timer. */
 	e100_dump_stats_cntrs(bdp);
 
-	wmb();
+	mb();
 
 	/* relaunch watchdog timer in 2 sec */
 	mod_timer(&(bdp->watchdog_timer), jiffies + (2 * HZ));
@@ -2229,7 +2229,7 @@ e100_prepare_xmit_buff(struct e100_priva
 
 	bdp->tcb_pool.tail = NEXT_TCB_TOUSE(bdp->tcb_pool.tail);
 
-	wmb();
+	mb();
 
 	e100_start_cu(bdp, tcb);
 
@@ -2516,7 +2516,7 @@ e100_clr_cntrs(struct e100_private *bdp)
 	/* clear the dump counter complete word */
 	pcmd_complete = e100_cmd_complete_location(bdp);
 	*pcmd_complete = 0;
-	wmb();
+	mb();
 
 	if (!e100_wait_exec_cmplx(bdp, bdp->stat_cnt_phys, SCB_CUC_DUMP_ADDR, 0))
 		return false;
@@ -2651,7 +2651,7 @@ e100_exec_non_cu_cmd(struct e100_private
 	ntcb_hdr->cb_status = 0;
 	ntcb_hdr->cb_lnk_ptr = 0;
 
-	wmb();
+	mb();
 	if (in_interrupt())
 		return e100_delayed_exec_non_cu_cmd(bdp, command);
 
diff -purN linux-2.5-latest/drivers/net/e100/e100_test.c linuxppc64-2.5-latest/drivers/net/e100/e100_test.c
--- linux-2.5-latest/drivers/net/e100/e100_test.c	2003-10-10 11:38:51.000000000 +0200
+++ linuxppc64-2.5-latest/drivers/net/e100/e100_test.c	2003-10-10 11:34:10.000000000 +0200
@@ -316,7 +316,7 @@ e100_diag_loopback_alloc(struct e100_pri
 	memset((void *) ((u8 *) tbd + sizeof (tbd_t)), 0xFF, 512);
 	/* The value of second 512 bytes is BA */
 	memset((void *) ((u8 *) tbd + sizeof (tbd_t) + 512), 0xBA, 512);
-	wmb();
+	mb();
 	rfd = pci_alloc_consistent(bdp->pdev, sizeof (rfd_t), &dma_handle);
 
 	if (rfd == NULL) {
@@ -335,7 +335,7 @@ e100_diag_loopback_alloc(struct e100_pri
 	bdp->loopback.dma_handle = dma_handle;
 	bdp->loopback.tcb = tcb;
 	bdp->loopback.rfd = rfd;
-	wmb();
+	mb();
 	return true;
 }
 
diff -purN linux-2.5-latest/drivers/pci/Makefile linuxppc64-2.5-latest/drivers/pci/Makefile
--- linux-2.5-latest/drivers/pci/Makefile	2003-10-10 11:39:56.000000000 +0200
+++ linuxppc64-2.5-latest/drivers/pci/Makefile	2003-10-10 11:35:06.000000000 +0200
@@ -22,6 +22,7 @@ obj-$(CONFIG_ALPHA) += setup-bus.o setup
 obj-$(CONFIG_ARM) += setup-bus.o setup-irq.o
 obj-$(CONFIG_PARISC) += setup-bus.o
 obj-$(CONFIG_SUPERH) += setup-bus.o setup-irq.o
+obj-$(CONFIG_PPC64) += setup-bus.o
 obj-$(CONFIG_PPC32) += setup-irq.o
 obj-$(CONFIG_PPC64) += setup-bus.o
 obj-$(CONFIG_SGI_IP27) += setup-irq.o
diff -purN linux-2.5-latest/drivers/pci/pci-sysfs.c linuxppc64-2.5-latest/drivers/pci/pci-sysfs.c
--- linux-2.5-latest/drivers/pci/pci-sysfs.c	2003-10-10 11:39:04.000000000 +0200
+++ linuxppc64-2.5-latest/drivers/pci/pci-sysfs.c	2003-10-10 11:34:25.000000000 +0200
@@ -15,6 +15,7 @@
 
 #include <linux/config.h>
 #include <linux/kernel.h>
+#include <linux/stat.h>
 #include <linux/pci.h>
 #include <linux/stat.h>
 
diff -purN linux-2.5-latest/drivers/pci/probe.c linuxppc64-2.5-latest/drivers/pci/probe.c
--- linux-2.5-latest/drivers/pci/probe.c	2003-10-10 11:39:27.000000000 +0200
+++ linuxppc64-2.5-latest/drivers/pci/probe.c	2003-10-10 11:34:44.000000000 +0200
@@ -176,7 +176,7 @@ void __devinit pci_read_bridge_bases(str
 		limit |= (io_limit_hi << 16);
 	}
 
-	if (base && base <= limit) {
+	if (base <= limit) {
 		res->flags = (io_base_lo & PCI_IO_RANGE_TYPE_MASK) | IORESOURCE_IO;
 		res->start = base;
 		res->end = limit + 0xfff;
@@ -572,12 +572,14 @@ int __devinit pci_scan_slot(struct pci_b
 		list_add_tail(&dev->bus_list, &bus->devices);
 		nr++;
 
+#if 0
 		/*
 		 * If this is a single function device,
 		 * don't scan past the first function.
 		 */
 		if (!dev->multifunction)
 			break;
+#endif
 	}
 	return nr;
 }
diff -purN linux-2.5-latest/drivers/scsi/sg.c linuxppc64-2.5-latest/drivers/scsi/sg.c
--- linux-2.5-latest/drivers/scsi/sg.c	2003-10-10 11:38:53.000000000 +0200
+++ linuxppc64-2.5-latest/drivers/scsi/sg.c	2003-10-10 11:34:11.000000000 +0200
@@ -1330,6 +1330,9 @@ sg_add(struct class_device *cdev)
 	unsigned long iflags;
 	int k, error;
 
+	if (scsidp->type == 255)
+		return 0;
+
 	disk = alloc_disk(1);
 	if (!disk)
 		return -ENOMEM;
diff -purN linux-2.5-latest/drivers/scsi/sym53c8xx_2/sym_glue.c linuxppc64-2.5-latest/drivers/scsi/sym53c8xx_2/sym_glue.c
--- linux-2.5-latest/drivers/scsi/sym53c8xx_2/sym_glue.c	2003-10-10 11:40:24.000000000 +0200
+++ linuxppc64-2.5-latest/drivers/scsi/sym53c8xx_2/sym_glue.c	2003-10-10 11:35:25.000000000 +0200
@@ -2159,8 +2159,7 @@ sym53c8xx_pci_init(struct pci_dev *pdev,
 
 	/* If the chip can do Memory Write Invalidate, enable it */
 	if (chip->features & FE_WRIE) {
-		if (pci_set_mwi(pdev))
-			return -1;
+			pci_set_mwi(pdev);
 	}
 
 	/*
diff -purN linux-2.5-latest/include/asm-ppc64/cputable.h linuxppc64-2.5-latest/include/asm-ppc64/cputable.h
--- linux-2.5-latest/include/asm-ppc64/cputable.h	2003-10-10 11:39:25.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/cputable.h	2003-10-10 11:34:42.000000000 +0200
@@ -30,7 +30,7 @@
 #ifndef __ASSEMBLY__
 
 /* This structure can grow, it's real size is used by head.S code
- * via the mkdefs mecanism.
+ * via the mkdefs mechanism.
  */
 struct cpu_spec;
 
diff -purN linux-2.5-latest/include/asm-ppc64/hardirq.h linuxppc64-2.5-latest/include/asm-ppc64/hardirq.h
--- linux-2.5-latest/include/asm-ppc64/hardirq.h	2003-10-10 11:38:24.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/hardirq.h	2003-10-10 11:33:37.000000000 +0200
@@ -15,9 +15,7 @@
 
 typedef struct {
 	unsigned int __softirq_pending;
-	unsigned int __syscall_count;
 	struct task_struct * __ksoftirqd_task;
-	unsigned long idle_timestamp;
 } ____cacheline_aligned irq_cpustat_t;
 
 #include <linux/irq_cpustat.h>	/* Standard mappings for irq_cpustat_t above */
diff -purN linux-2.5-latest/include/asm-ppc64/hw_irq.h linuxppc64-2.5-latest/include/asm-ppc64/hw_irq.h
--- linux-2.5-latest/include/asm-ppc64/hw_irq.h	2003-10-10 11:40:11.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/hw_irq.h	2003-10-10 11:35:16.000000000 +0200
@@ -71,9 +71,9 @@ static inline void __do_save_and_cli(uns
 
 #endif /* CONFIG_PPC_ISERIES */
 
-#define mask_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->disable) irq_desc[irq].handler->disable(irq);})
-#define unmask_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->enable) irq_desc[irq].handler->enable(irq);})
-#define ack_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->ack) irq_desc[irq].handler->ack(irq);})
+#define mask_irq(irq) ({irq_desc_t *desc = get_irq_desc(irq); if (desc->handler && desc->handler->disable) desc->handler->disable(irq);})
+#define unmask_irq(irq) ({irq_desc_t *desc = get_irq_desc(irq); if (desc->handler && desc->handler->enable) desc->handler->enable(irq);})
+#define ack_irq(irq) ({irq_desc_t *desc = get_irq_desc(irq); if (desc->handler && desc->handler->ack) desc->handler->ack(irq);})
 
 /* Should we handle this via lost interrupts and IPIs or should we don't care like
  * we do now ? --BenH.
diff -purN linux-2.5-latest/include/asm-ppc64/irq.h linuxppc64-2.5-latest/include/asm-ppc64/irq.h
--- linux-2.5-latest/include/asm-ppc64/irq.h	2003-10-10 11:40:16.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/irq.h	2003-10-10 11:35:19.000000000 +0200
@@ -11,35 +11,16 @@
 
 #include <asm/atomic.h>
 
+#define NR_IRQS			512
+
 extern void disable_irq(unsigned int);
 extern void disable_irq_nosync(unsigned int);
 extern void enable_irq(unsigned int);
 
-/*
- * this is the maximum number of virtual irqs we will use.
- */
-#define NR_IRQS			512
-
-#define NUM_8259_INTERRUPTS	16
-
-/* Interrupt numbers are virtual in case they are sparsely
- * distributed by the hardware.
- */
-#define NR_HW_IRQS		8192
-extern unsigned short real_irq_to_virt_map[NR_HW_IRQS];
-extern unsigned short virt_irq_to_real_map[NR_IRQS];
-/* Create a mapping for a real_irq if it doesn't already exist.
- * Return the virtual irq as a convenience.
- */
-unsigned long virt_irq_create_mapping(unsigned long real_irq);
-
-/* These funcs map irqs between real and virtual */
-static inline unsigned long real_irq_to_virt(unsigned long real_irq) {
-	return real_irq_to_virt_map[real_irq];
-}
-static inline unsigned long virt_irq_to_real(unsigned long virt_irq) {
-	return virt_irq_to_real_map[virt_irq];
-}
+extern void *_get_irq_desc(unsigned int irq);
+extern void *_get_real_irq_desc(unsigned int irq);
+#define get_irq_desc(irq) ((irq_desc_t *)_get_irq_desc(irq))
+#define get_real_irq_desc(irq) ((irq_desc_t *)_get_real_irq_desc(irq))
 
 /*
  * This gets called from serial.c, which is now used on
@@ -51,7 +32,34 @@ static __inline__ int irq_canonicalize(i
 	return irq;
 }
 
-#define NR_MASK_WORDS	((NR_IRQS + 63) / 64)
+/*
+ * Because many systems have two overlapping names spaces for
+ * interrupts (ISA and XICS for example), and the ISA interrupts
+ * have historically not been easy to renumber, we allow ISA
+ * interrupts to take values 0 - 15, and shift up the remaining 
+ * interrupts by 0x10.  
+ *
+ * This would be nice to remove at some point as it adds confusion
+ * and adds a nasty end case if any platform native interrupts have 
+ * values within 0x10 of the end of that namespace.
+ */
+
+#define NUM_ISA_INTERRUPTS	0x10
+
+extern inline int irq_offset_up(int irq)
+{
+	return(irq + NUM_ISA_INTERRUPTS);
+}
+
+extern inline int irq_offset_down(int irq)
+{
+	return(irq - NUM_ISA_INTERRUPTS);
+}
+
+extern inline int irq_offset_value(void)
+{
+	return NUM_ISA_INTERRUPTS;
+}
 
 #endif /* _ASM_IRQ_H */
 #endif /* __KERNEL__ */
diff -purN linux-2.5-latest/include/asm-ppc64/machdep.h linuxppc64-2.5-latest/include/asm-ppc64/machdep.h
--- linux-2.5-latest/include/asm-ppc64/machdep.h	2003-10-10 11:38:40.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/machdep.h	2003-10-10 11:33:55.000000000 +0200
@@ -11,6 +11,7 @@
 
 #include <linux/config.h>
 #include <linux/seq_file.h>
+#include <linux/irq.h>
 
 struct pt_regs;
 struct pci_bus;	
@@ -67,6 +68,7 @@ struct machdep_calls {
 	void		(*get_cpuinfo)(struct seq_file *m);
 
 	void		(*init_IRQ)(void);
+	void		(*init_irq_desc)(irq_desc_t *desc);
 	int		(*get_irq)(struct pt_regs *);
 
 	/* Optional, may be NULL. */
diff -purN linux-2.5-latest/include/asm-ppc64/memory.h linuxppc64-2.5-latest/include/asm-ppc64/memory.h
--- linux-2.5-latest/include/asm-ppc64/memory.h	2003-10-10 11:40:20.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/memory.h	2003-10-10 11:35:21.000000000 +0200
@@ -58,7 +58,7 @@ static inline void isync(void)
 
 #define HMT_LOW
 #define HMT_MEDIUM
-#define HMT_LOW
+#define HMT_HIGH
 #endif
 
 #endif
diff -purN linux-2.5-latest/include/asm-ppc64/prom.h linuxppc64-2.5-latest/include/asm-ppc64/prom.h
--- linux-2.5-latest/include/asm-ppc64/prom.h	2003-10-10 11:40:17.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/prom.h	2003-10-10 11:35:19.000000000 +0200
@@ -171,19 +171,36 @@ extern struct prom_t prom;
 
 extern int boot_cpuid;
 
-/* Prototypes */
-extern void abort(void);
-extern unsigned long prom_init(unsigned long, unsigned long, unsigned long,
-    unsigned long, unsigned long);
-extern void prom_print(const char *msg);
-extern void relocate_nodes(void);
-extern void finish_device_tree(void);
+/* OBSOLETE: Old stlye node lookup */
 extern struct device_node *find_devices(const char *name);
 extern struct device_node *find_type_devices(const char *type);
 extern struct device_node *find_path_device(const char *path);
 extern struct device_node *find_compatible_devices(const char *type,
 						   const char *compat);
 extern struct device_node *find_all_nodes(void);
+
+/* New style node lookup */
+extern struct device_node *of_find_node_by_name(struct device_node *from,
+	const char *name);
+extern struct device_node *of_find_node_by_type(struct device_node *from,
+	const char *type);
+extern struct device_node *of_find_compatible_node(struct device_node *from,
+	const char *type, const char *compat);
+extern struct device_node *of_find_node_by_path(const char *path);
+extern struct device_node *of_find_all_nodes(struct device_node *prev);
+extern struct device_node *of_get_parent(const struct device_node *node);
+extern struct device_node *of_get_next_child(const struct device_node *node,
+					     struct device_node *prev);
+extern struct device_node *of_node_get(struct device_node *node);
+extern void of_node_put(struct device_node *node);
+
+/* Other Prototypes */
+extern void abort(void);
+extern unsigned long prom_init(unsigned long, unsigned long, unsigned long,
+	unsigned long, unsigned long);
+extern void prom_print(const char *msg);
+extern void relocate_nodes(void);
+extern void finish_device_tree(void);
 extern int device_is_compatible(struct device_node *device, const char *);
 extern int machine_is_compatible(const char *compat);
 extern unsigned char *get_property(struct device_node *node, const char *name,
diff -purN linux-2.5-latest/include/asm-ppc64/ptrace.h linuxppc64-2.5-latest/include/asm-ppc64/ptrace.h
--- linux-2.5-latest/include/asm-ppc64/ptrace.h	2003-10-10 11:39:26.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/ptrace.h	2003-10-10 11:34:43.000000000 +0200
@@ -16,7 +16,7 @@
  * that the overall structure is a multiple of 16 bytes in length.
  *
  * Note that the offsets of the fields in this struct correspond with
- * the PT_* values below.  This simplifies arch/ppc/kernel/ptrace.c.
+ * the PT_* values below.  This simplifies arch/ppc64/kernel/ptrace.c.
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
@@ -120,11 +120,14 @@ struct pt_regs32 {
 #define PT_RESULT 43
 
 #define PT_FPR0	48
+
+/* Kernel and userspace will both use this PT_FPSCR value.  32-bit apps will have
+ * visibility to the asm-ppc/ptrace.h header instead of this one.
+ */
+#define PT_FPSCR (PT_FPR0 + 32 + 1)	  /* each FP reg occupies 1 slot in 64-bit space */
+
 #ifdef __KERNEL__
-#define PT_FPSCR (PT_FPR0 + 32 + 1)	  /* each FP reg occupies 1 slot in this space */
-#define PT_FPSCR32 (PT_FPR0 + 2*32 + 1)	  /* To the 32-bit user - each FP reg occupies 2 slots in this space */
-#else
-#define PT_FPSCR (PT_FPR0 + 2*32 + 1)	/* each FP reg occupies 2 slots in this space -- Fix when 64-bit apps. */
+#define PT_FPSCR32 (PT_FPR0 + 2*32 + 1)	  /* each FP reg occupies 2 32-bit userspace slots */
 #endif
 
 /* Additional PTRACE requests implemented on PowerPC. */
diff -purN linux-2.5-latest/include/asm-ppc64/siginfo.h linuxppc64-2.5-latest/include/asm-ppc64/siginfo.h
--- linux-2.5-latest/include/asm-ppc64/siginfo.h	2003-10-10 11:39:38.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/siginfo.h	2003-10-10 11:34:54.000000000 +0200
@@ -8,8 +8,8 @@
  * 2 of the License, or (at your option) any later version.
  */
 
-#define SI_PAD_SIZE    ((SI_MAX_SIZE/sizeof(int)) - 4)
-#define SI_PAD_SIZE32  ((SI_MAX_SIZE/sizeof(int)) - 3)
+#define __ARCH_SI_PREAMBLE_SIZE	(4 * sizeof(int))
+#define SI_PAD_SIZE32		((SI_MAX_SIZE/sizeof(int)) - 3)
 
 #include <asm-generic/siginfo.h>
 
diff -purN linux-2.5-latest/include/asm-ppc64/xics.h linuxppc64-2.5-latest/include/asm-ppc64/xics.h
--- linux-2.5-latest/include/asm-ppc64/xics.h	2003-10-10 11:39:01.000000000 +0200
+++ linuxppc64-2.5-latest/include/asm-ppc64/xics.h	2003-10-10 11:34:20.000000000 +0200
@@ -15,6 +15,7 @@
 #include <linux/cache.h>
 
 void xics_init_IRQ(void);
+void xics_init_irq_desc(irq_desc_t *);
 int xics_get_irq(struct pt_regs *);
 void xics_setup_cpu(void);
 void xics_cause_IPI(int cpu);
