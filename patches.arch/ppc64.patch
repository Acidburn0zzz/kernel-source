diff -purN linux-2.5/arch/ppc/kernel/misc.S linuxppc64-2.5/arch/ppc/kernel/misc.S
--- linux-2.5/arch/ppc/kernel/misc.S	2003-09-12 16:26:52.000000000 +0000
+++ linuxppc64-2.5/arch/ppc/kernel/misc.S	2003-11-17 18:51:47.000000000 +0000
@@ -1385,3 +1385,4 @@ _GLOBAL(sys_call_table)
 	.long sys_statfs64
 	.long sys_fstatfs64
 	.long ppc_fadvise64_64
+	.long sys_ni_syscall	/* 255 - rtas (used on ppc64) */
diff -purN linux-2.5/arch/ppc64/Kconfig linuxppc64-2.5/arch/ppc64/Kconfig
--- linux-2.5/arch/ppc64/Kconfig	2003-09-26 04:04:08.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/Kconfig	2003-11-21 04:51:09.000000000 +0000
@@ -72,6 +72,14 @@ config PPC64
 	bool
 	default y
 
+config POWER4_ONLY
+	bool "Optimize for POWER4"
+	default n
+	---help---
+	  Cause the compiler to optimize for POWER4 processors. The resulting
+	  binary will not work on POWER3 or RS64 processors when compiled with
+	  binutils 2.15 or later.
+
 config SMP
 	bool "Symmetric multi-processing support"
 	---help---
@@ -130,18 +138,18 @@ config MSCHUNKS
 	depends on PPC_ISERIES
 	default y
 
-config RTAS_FLASH
-	tristate "Firmware flash interface"
-	depends on !PPC_ISERIES
-
-config SCANLOG
-	tristate "Scanlog dump interface"
-	depends on !PPC_ISERIES
 
 config PPC_RTAS
 	bool "Proc interface to RTAS"
 	depends on !PPC_ISERIES
 
+config RTAS_FLASH
+	tristate "Firmware flash interface"
+	depends on PPC_RTAS
+
+config SCANLOG
+	tristate "Scanlog dump interface"
+	depends on PPC_RTAS
 endmenu
 
 
@@ -318,7 +326,7 @@ endmenu
 
 config VIOPATH
 	bool
-	depends on PPC_ISERIES
+	depends on VIOCONS || VIODASD || VIOCD || VIOTAPE || VETH
 	default y
 
 source "arch/ppc64/oprofile/Kconfig"
@@ -355,7 +363,7 @@ config MAGIC_SYSRQ
 
 config XMON
 	bool "Include xmon kernel debugger"
-	depends on DEBUG_KERNEL
+	depends on DEBUG_KERNEL && !KDB
 	help
 	  Include in-kernel hooks for the xmon kernel monitor/debugger.
 	  Unless you are intending to debug the kernel, say N here.
@@ -364,6 +372,20 @@ config XMON_DEFAULT
 	bool "Enable xmon by default"
 	depends on XMON
 
+config KDB
+	bool "Include kdb kernel debugger"
+	depends on DEBUG_KERNEL && !XMON
+	help
+	  Include in-kernel hooks for the kdb kernel monitor/debugger.
+	  Unless you are intending to debug the kernel, say N here.
+
+config KDB_OFF
+	bool "Turn KDB off as default."
+	depends on KDB
+	help
+ 	   KDB will remain built into the kernel, but will be turned off. 
+	   "cat 1 > /proc/sys/kernel/kdb" to turn it on. 
+
 config PPCDBG
 	bool "Include PPCDBG realtime debugging"
 	depends on DEBUG_KERNEL
diff -purN linux-2.5/arch/ppc64/Makefile linuxppc64-2.5/arch/ppc64/Makefile
--- linux-2.5/arch/ppc64/Makefile	2003-09-10 18:34:20.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/Makefile	2003-10-30 19:19:37.000000000 +0000
@@ -15,10 +15,26 @@
 
 KERNELLOAD	:= 0xc000000000000000
 
+ifeq ($(shell uname -m),ppc64)
+CHECKS		= checks
+endif
+
+HAS_BIARCH      := $(shell if $(CC) -m64 -S -o /dev/null -xc /dev/null > /dev/null 2>&1; then echo y; else echo n; fi;)
+ifeq ($(HAS_BIARCH),y)
+AS              := $(AS) -64
+LD              := $(LD) -m elf64ppc
+CC		:= $(CC) -m64
+endif
+
 LDFLAGS		:= -m elf64ppc
 LDFLAGS_vmlinux	:= -Bstatic -e $(KERNELLOAD) -Ttext $(KERNELLOAD)
-CFLAGS		+= -msoft-float -pipe -Wno-uninitialized -mminimal-toc \
-		-mcpu=power4
+CFLAGS		+= -msoft-float -pipe -Wno-uninitialized -mminimal-toc
+
+ifeq ($(CONFIG_POWER4_ONLY),y)
+CFLAGS		+= -mcpu=power4
+else
+CFLAGS		+= -mtune=power4 -Wa,-mpower4
+endif
 
 have_zero_bss := $(shell if $(CC) -fno-zero-initialized-in-bss -S -o /dev/null -xc /dev/null > /dev/null 2>&1; then echo y; else echo n; fi)
 
@@ -32,6 +48,11 @@ libs-y				+= arch/ppc64/lib/
 core-y				+= arch/ppc64/kernel/
 core-y				+= arch/ppc64/mm/
 core-$(CONFIG_XMON)		+= arch/ppc64/xmon/
+ifeq ($(CONFIG_KDB),y)
+  # Use ifeq for now because kdb subdirs are not in bk yet
+  # Otherwise make mrproper will die because it also cleans core-n
+  core-y			+= arch/ppc64/kdb/
+endif
 drivers-$(CONFIG_OPROFILE)	+= arch/ppc64/oprofile/
 
 boot := arch/ppc64/boot
@@ -47,6 +68,8 @@ BOOTIMAGE := $(bootimage-y)
 install: vmlinux
 	$(Q)$(MAKE) $(build)=$(boot) BOOTIMAGE=$(BOOTIMAGE) $@
 
+all: $(BOOTIMAGE)
+
 archclean:
 	$(Q)$(MAKE) $(clean)=$(boot)
 
diff -purN linux-2.5/arch/ppc64/boot/ppc32-types.h linuxppc64-2.5/arch/ppc64/boot/ppc32-types.h
--- linux-2.5/arch/ppc64/boot/ppc32-types.h	2003-02-07 21:36:11.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/boot/ppc32-types.h	2003-11-20 16:09:20.000000000 +0000
@@ -25,6 +25,10 @@ typedef unsigned int u32;
 typedef signed long long s64;
 typedef unsigned long long u64;
 
+typedef struct {
+	__u32 u[4];
+} __attribute((aligned(16))) __vector128;
+
 #define BITS_PER_LONG 32
 
 #endif /* _PPC64_TYPES_H */
diff -purN linux-2.5/arch/ppc64/defconfig linuxppc64-2.5/arch/ppc64/defconfig
--- linux-2.5/arch/ppc64/defconfig	2003-09-02 08:05:21.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/defconfig	2003-09-18 16:04:44.000000000 +0000
@@ -23,7 +23,7 @@ CONFIG_SWAP=y
 CONFIG_SYSVIPC=y
 # CONFIG_BSD_PROCESS_ACCT is not set
 CONFIG_SYSCTL=y
-CONFIG_LOG_BUF_SHIFT=16
+CONFIG_LOG_BUF_SHIFT=17
 CONFIG_IKCONFIG=y
 CONFIG_IKCONFIG_PROC=y
 # CONFIG_EMBEDDED is not set
@@ -158,6 +158,7 @@ CONFIG_SCSI_CONSTANTS=y
 # CONFIG_SCSI_INITIO is not set
 # CONFIG_SCSI_INIA100 is not set
 CONFIG_SCSI_SYM53C8XX_2=y
+# CONFIG_SCSI_IBMSIS is not set
 CONFIG_SCSI_SYM53C8XX_DMA_ADDRESSING_MODE=0
 CONFIG_SCSI_SYM53C8XX_DEFAULT_TAGS=16
 CONFIG_SCSI_SYM53C8XX_MAX_TAGS=64
@@ -227,11 +228,10 @@ CONFIG_INET_AH=m
 CONFIG_INET_ESP=m
 CONFIG_INET_IPCOMP=m
 # CONFIG_IPV6 is not set
-# CONFIG_DECNET is not set
-# CONFIG_BRIDGE is not set
-# CONFIG_NETFILTER is not set
-CONFIG_XFRM=y
-CONFIG_XFRM_USER=m
+# CONFIG_XFRM_USER is not set
+
+
+
 
 #
 # SCTP Configuration (EXPERIMENTAL)
@@ -240,7 +240,7 @@ CONFIG_IPV6_SCTP__=y
 # CONFIG_IP_SCTP is not set
 # CONFIG_ATM is not set
 # CONFIG_VLAN_8021Q is not set
-# CONFIG_LLC is not set
+CONFIG_LLC=y
 # CONFIG_X25 is not set
 # CONFIG_LAPB is not set
 # CONFIG_NET_DIVERT is not set
@@ -346,6 +346,11 @@ CONFIG_PPPOE=m
 #
 # Token Ring devices (depends on LLC=y)
 #
+CONFIG_TR=y
+CONFIG_IBMOL=y
+# CONFIG_IBMLS is not set
+# CONFIG_3C359 is not set
+# CONFIG_TMS380TR is not set
 # CONFIG_NET_FC is not set
 # CONFIG_RCPCI is not set
 # CONFIG_SHAPER is not set
@@ -726,6 +731,8 @@ CONFIG_DEBUG_KERNEL=y
 CONFIG_MAGIC_SYSRQ=y
 CONFIG_XMON=y
 CONFIG_XMON_DEFAULT=y
+# CONFIG_KDB is not set
+# CONFIG_KDB_OFF is not set
 # CONFIG_PPCDBG is not set
 # CONFIG_DEBUG_INFO is not set
 
diff -purN linux-2.5/arch/ppc64/kdb/Makefile linuxppc64-2.5/arch/ppc64/kdb/Makefile
--- linux-2.5/arch/ppc64/kdb/Makefile	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/Makefile	2003-10-13 16:16:56.000000000 +0000
@@ -0,0 +1,7 @@
+obj-y		:= kdba_bt.o kdba_bp.o kdba_id.o kdba_io.o ppc-dis.o ppc-opc.o kdbasupport.o 
+
+# Warning: running with a minimal-toc means that kdb_setjmp will break
+# due to saving the wrong r30. A solution would be to move it into setjmp.S
+EXTRA_CFLAGS = -mno-minimal-toc
+
+override CFLAGS := $(CFLAGS) -I. -Iarch/ppc64/kdb
diff -purN linux-2.5/arch/ppc64/kdb/ansidecl.h linuxppc64-2.5/arch/ppc64/kdb/ansidecl.h
--- linux-2.5/arch/ppc64/kdb/ansidecl.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/ansidecl.h	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,198 @@
+/* ANSI and traditional C compatability macros
+   Copyright 1991, 1992, 1996, 1999 Free Software Foundation, Inc.
+   This file is part of the GNU C Library.
+
+This program is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 2 of the License, or
+(at your option) any later version.
+
+This program is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; if not, write to the Free Software
+Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  */
+
+/* ANSI and traditional C compatibility macros
+
+   ANSI C is assumed if __STDC__ is #defined.
+
+   Macro	ANSI C definition	Traditional C definition
+   -----	---- - ----------	----------- - ----------
+   PTR		`void *'		`char *'
+   LONG_DOUBLE	`long double'		`double'
+   VOLATILE	`volatile'		`'
+   SIGNED	`signed'		`'
+   PTRCONST	`void *const'		`char *'
+   ANSI_PROTOTYPES  1			not defined
+
+   CONST is also defined, but is obsolete.  Just use const.
+
+   obsolete --     DEFUN (name, arglist, args)
+
+	Defines function NAME.
+
+	ARGLIST lists the arguments, separated by commas and enclosed in
+	parentheses.  ARGLIST becomes the argument list in traditional C.
+
+	ARGS list the arguments with their types.  It becomes a prototype in
+	ANSI C, and the type declarations in traditional C.  Arguments should
+	be separated with `AND'.  For functions with a variable number of
+	arguments, the last thing listed should be `DOTS'.
+
+   obsolete --     DEFUN_VOID (name)
+
+	Defines a function NAME, which takes no arguments.
+
+   obsolete --     EXFUN (name, (prototype))	-- obsolete.
+
+	Replaced by PARAMS.  Do not use; will disappear someday soon.
+	Was used in external function declarations.
+	In ANSI C it is `NAME PROTOTYPE' (so PROTOTYPE should be enclosed in
+	parentheses).  In traditional C it is `NAME()'.
+	For a function that takes no arguments, PROTOTYPE should be `(void)'.
+
+   obsolete --     PROTO (type, name, (prototype)    -- obsolete.
+
+	This one has also been replaced by PARAMS.  Do not use.
+
+   PARAMS ((args))
+
+	We could use the EXFUN macro to handle prototype declarations, but
+	the name is misleading and the result is ugly.  So we just define a
+	simple macro to handle the parameter lists, as in:
+
+	      static int foo PARAMS ((int, char));
+
+	This produces:  `static int foo();' or `static int foo (int, char);'
+
+	EXFUN would have done it like this:
+
+	      static int EXFUN (foo, (int, char));
+
+	but the function is not external...and it's hard to visually parse
+	the function name out of the mess.   EXFUN should be considered
+	obsolete; new code should be written to use PARAMS.
+
+   DOTS is also obsolete.
+
+   Examples:
+
+	extern int printf PARAMS ((const char *format, ...));
+*/
+
+#ifndef	_ANSIDECL_H
+
+#define	_ANSIDECL_H	1
+
+
+/* Every source file includes this file,
+   so they will all get the switch for lint.  */
+/* LINTLIBRARY */
+
+
+#if defined (__STDC__) || defined (_AIX) || (defined (__mips) && defined (_SYSTYPE_SVR4)) || defined(_WIN32)
+/* All known AIX compilers implement these things (but don't always
+   define __STDC__).  The RISC/OS MIPS compiler defines these things
+   in SVR4 mode, but does not define __STDC__.  */
+
+#define	PTR		void *
+#define	PTRCONST	void *CONST
+#define	LONG_DOUBLE	long double
+
+#ifndef IN_GCC
+#define	AND		,
+#define	NOARGS		void
+#define	VOLATILE	volatile
+#define	SIGNED		signed
+#endif /* ! IN_GCC */
+
+#ifndef PARAMS
+#define PARAMS(paramlist)		paramlist
+#endif
+#define ANSI_PROTOTYPES			1
+
+#define VPARAMS(ARGS)			ARGS
+#define VA_START(va_list,var)		va_start(va_list,var)
+
+/* These are obsolete.  Do not use.  */
+#ifndef IN_GCC
+#define CONST				const
+#define DOTS				, ...
+#define PROTO(type, name, arglist)	type name arglist
+#define EXFUN(name, proto)		name proto
+#define DEFUN(name, arglist, args)	name(args)
+#define DEFUN_VOID(name)		name(void)
+#endif /* ! IN_GCC */
+
+#else	/* Not ANSI C.  */
+
+#define	PTR		char *
+#define	PTRCONST	PTR
+#define	LONG_DOUBLE	double
+
+#ifndef IN_GCC
+#define	AND		;
+#define	NOARGS
+#define	VOLATILE
+#define	SIGNED
+#endif /* !IN_GCC */
+
+#ifndef const /* some systems define it in header files for non-ansi mode */
+#define	const
+#endif
+
+#define PARAMS(paramlist)		()
+
+#define VPARAMS(ARGS)			(va_alist) va_dcl
+#define VA_START(va_list,var)		va_start(va_list)
+
+/* These are obsolete.  Do not use.  */
+#ifndef IN_GCC
+#define CONST
+#define DOTS
+#define PROTO(type, name, arglist)	type name ()
+#define EXFUN(name, proto)		name()
+#define DEFUN(name, arglist, args)	name arglist args;
+#define DEFUN_VOID(name)		name()
+#endif /* ! IN_GCC */
+
+#endif	/* ANSI C.  */
+
+/* Define macros for some gcc attributes.  This permits us to use the
+   macros freely, and know that they will come into play for the
+   version of gcc in which they are supported.  */
+
+#if __GNUC__ < 2 || (__GNUC__ == 2 && __GNUC_MINOR__ < 7)
+# define __attribute__(x)
+#endif
+
+#ifndef ATTRIBUTE_UNUSED_LABEL
+# if __GNUC__ < 2 || (__GNUC__ == 2 && __GNUC_MINOR__ < 93)
+#  define ATTRIBUTE_UNUSED_LABEL
+# else
+#  define ATTRIBUTE_UNUSED_LABEL ATTRIBUTE_UNUSED
+# endif /* GNUC < 2.93 */
+#endif /* ATTRIBUTE_UNUSED_LABEL */
+
+#ifndef ATTRIBUTE_UNUSED
+#define ATTRIBUTE_UNUSED __attribute__ ((__unused__))
+#endif /* ATTRIBUTE_UNUSED */
+
+#ifndef ATTRIBUTE_NORETURN
+#define ATTRIBUTE_NORETURN __attribute__ ((__noreturn__))
+#endif /* ATTRIBUTE_NORETURN */
+
+#ifndef ATTRIBUTE_PRINTF
+#define ATTRIBUTE_PRINTF(m, n) __attribute__ ((format (__printf__, m, n)))
+#define ATTRIBUTE_PRINTF_1 ATTRIBUTE_PRINTF(1, 2)
+#define ATTRIBUTE_PRINTF_2 ATTRIBUTE_PRINTF(2, 3)
+#define ATTRIBUTE_PRINTF_3 ATTRIBUTE_PRINTF(3, 4)
+#define ATTRIBUTE_PRINTF_4 ATTRIBUTE_PRINTF(4, 5)
+#define ATTRIBUTE_PRINTF_5 ATTRIBUTE_PRINTF(5, 6)
+#endif /* ATTRIBUTE_PRINTF */
+
+#endif	/* ansidecl.h	*/
diff -purN linux-2.5/arch/ppc64/kdb/bfd.h linuxppc64-2.5/arch/ppc64/kdb/bfd.h
--- linux-2.5/arch/ppc64/kdb/bfd.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/bfd.h	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,3706 @@
+/* DO NOT EDIT!  -*- buffer-read-only: t -*-  This file is automatically 
+   generated from "bfd-in.h", "init.c", "opncls.c", "libbfd.c", 
+   "section.c", "archures.c", "reloc.c", "syms.c", "bfd.c", "archive.c", 
+   "corefile.c", "targets.c" and "format.c".
+   Run "make headers" in your build bfd/ to regenerate.  */
+
+/* Main header file for the bfd library -- portable access to object files.
+   Copyright 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
+   2000, 2001
+   Free Software Foundation, Inc.
+   Contributed by Cygnus Support.
+
+This file is part of BFD, the Binary File Descriptor library.
+
+This program is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 2 of the License, or
+(at your option) any later version.
+
+This program is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; if not, write to the Free Software
+Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  */
+
+#ifndef __BFD_H_SEEN__
+#define __BFD_H_SEEN__
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+#include "ansidecl.h"
+#include "symcat.h"
+#if defined (__STDC__) || defined (ALMOST_STDC) || defined (HAVE_STRINGIZE)
+#ifndef SABER
+/* This hack is to avoid a problem with some strict ANSI C preprocessors.
+   The problem is, "32_" is not a valid preprocessing token, and we don't
+   want extra underscores (e.g., "nlm_32_").  The XCONCAT2 macro will
+   cause the inner CONCAT2 macros to be evaluated first, producing
+   still-valid pp-tokens.  Then the final concatenation can be done.  */
+#undef CONCAT4
+#define CONCAT4(a,b,c,d) XCONCAT2(CONCAT2(a,b),CONCAT2(c,d))
+#endif
+#endif
+
+#define BFD_VERSION 211920007
+#define BFD_VERSION_DATE 20011016
+#define BFD_VERSION_STRING "2.11.92.0.7 20011016 Debian\/GNU Linux"
+
+/* The word size used by BFD on the host.  This may be 64 with a 32
+   bit target if the host is 64 bit, or if other 64 bit targets have
+   been selected with --enable-targets, or if --enable-64-bit-bfd.  */
+#define BFD_ARCH_SIZE 64
+
+/* The word size of the default bfd target.  */
+#define BFD_DEFAULT_TARGET_SIZE 32
+
+#define BFD_HOST_64BIT_LONG 1
+#define BFD_HOST_64_BIT long
+#define BFD_HOST_U_64_BIT unsigned long
+
+#if BFD_ARCH_SIZE >= 64
+#define BFD64
+#endif
+
+#ifndef INLINE
+#if __GNUC__ >= 2
+#define INLINE __inline__
+#else
+#define INLINE
+#endif
+#endif
+
+/* forward declaration */
+typedef struct _bfd bfd;
+
+/* To squelch erroneous compiler warnings ("illegal pointer
+   combination") from the SVR3 compiler, we would like to typedef
+   boolean to int (it doesn't like functions which return boolean.
+   Making sure they are never implicitly declared to return int
+   doesn't seem to help).  But this file is not configured based on
+   the host.  */
+/* General rules: functions which are boolean return true on success
+   and false on failure (unless they're a predicate).   -- bfd.doc */
+/* I'm sure this is going to break something and someone is going to
+   force me to change it.  */
+/* typedef enum boolean {false, true} boolean; */
+/* Yup, SVR4 has a "typedef enum boolean" in <sys/types.h>  -fnf */
+/* It gets worse if the host also defines a true/false enum... -sts */
+/* And even worse if your compiler has built-in boolean types... -law */
+#if defined (__GNUG__) && (__GNUC__ > 2 || (__GNUC__ == 2 && __GNUC_MINOR__ >= 6))
+#define TRUE_FALSE_ALREADY_DEFINED
+#endif
+#ifdef MPW
+/* Pre-emptive strike - get the file with the enum.  */
+#include <Types.h>
+#define TRUE_FALSE_ALREADY_DEFINED
+#endif /* MPW */
+#ifndef TRUE_FALSE_ALREADY_DEFINED
+typedef enum bfd_boolean {false, true} boolean;
+#define BFD_TRUE_FALSE
+#else
+/* Use enum names that will appear nowhere else.  */
+typedef enum bfd_boolean {bfd_fffalse, bfd_tttrue} boolean;
+#endif
+
+/* Support for different sizes of target format ints and addresses.
+   If the type `long' is at least 64 bits, BFD_HOST_64BIT_LONG will be
+   set to 1 above.  Otherwise, if gcc is being used, this code will
+   use gcc's "long long" type.  Otherwise, BFD_HOST_64_BIT must be
+   defined above.  */
+
+#ifndef BFD_HOST_64_BIT
+# if BFD_HOST_64BIT_LONG
+#  define BFD_HOST_64_BIT long
+#  define BFD_HOST_U_64_BIT unsigned long
+# else
+#  ifdef __GNUC__
+#   if __GNUC__ >= 2
+#    define BFD_HOST_64_BIT long long
+#    define BFD_HOST_U_64_BIT unsigned long long
+#   endif /* __GNUC__ >= 2 */
+#  endif /* ! defined (__GNUC__) */
+# endif /* ! BFD_HOST_64BIT_LONG */
+#endif /* ! defined (BFD_HOST_64_BIT) */
+
+#ifdef BFD64
+
+#ifndef BFD_HOST_64_BIT
+ #error No 64 bit integer type available
+#endif /* ! defined (BFD_HOST_64_BIT) */
+
+typedef BFD_HOST_U_64_BIT bfd_vma;
+typedef BFD_HOST_64_BIT bfd_signed_vma;
+typedef BFD_HOST_U_64_BIT bfd_size_type;
+typedef BFD_HOST_U_64_BIT symvalue;
+
+#ifndef fprintf_vma
+#if BFD_HOST_64BIT_LONG
+#define sprintf_vma(s,x) sprintf (s, "%016lx", x)
+#define fprintf_vma(f,x) fprintf (f, "%016lx", x)
+#else
+#define _bfd_int64_low(x) ((unsigned long) (((x) & 0xffffffff)))
+#define _bfd_int64_high(x) ((unsigned long) (((x) >> 32) & 0xffffffff))
+#define fprintf_vma(s,x) \
+  fprintf ((s), "%08lx%08lx", _bfd_int64_high (x), _bfd_int64_low (x))
+#define sprintf_vma(s,x) \
+  sprintf ((s), "%08lx%08lx", _bfd_int64_high (x), _bfd_int64_low (x))
+#endif
+#endif
+
+#else /* not BFD64  */
+
+/* Represent a target address.  Also used as a generic unsigned type
+   which is guaranteed to be big enough to hold any arithmetic types
+   we need to deal with.  */
+typedef unsigned long bfd_vma;
+
+/* A generic signed type which is guaranteed to be big enough to hold any
+   arithmetic types we need to deal with.  Can be assumed to be compatible
+   with bfd_vma in the same way that signed and unsigned ints are compatible
+   (as parameters, in assignment, etc).  */
+typedef long bfd_signed_vma;
+
+typedef unsigned long symvalue;
+typedef unsigned long bfd_size_type;
+
+/* Print a bfd_vma x on stream s.  */
+#define fprintf_vma(s,x) fprintf (s, "%08lx", x)
+#define sprintf_vma(s,x) sprintf (s, "%08lx", x)
+
+#endif /* not BFD64  */
+
+/* A pointer to a position in a file.  */
+/* FIXME:  This should be using off_t from <sys/types.h>.
+   For now, try to avoid breaking stuff by not including <sys/types.h> here.
+   This will break on systems with 64-bit file offsets (e.g. 4.4BSD).
+   Probably the best long-term answer is to avoid using file_ptr AND off_t
+   in this header file, and to handle this in the BFD implementation
+   rather than in its interface.  */
+/* typedef off_t	file_ptr; */
+typedef bfd_signed_vma file_ptr;
+typedef bfd_vma ufile_ptr;
+
+extern void bfd_sprintf_vma PARAMS ((bfd *, char *, bfd_vma));
+extern void bfd_fprintf_vma PARAMS ((bfd *, PTR, bfd_vma));
+
+#define printf_vma(x) fprintf_vma(stdout,x)
+#define bfd_printf_vma(abfd,x) bfd_fprintf_vma (abfd,stdout,x)
+
+typedef unsigned int flagword;	/* 32 bits of flags */
+typedef unsigned char bfd_byte;
+
+/** File formats */
+
+typedef enum bfd_format {
+	      bfd_unknown = 0,	/* file format is unknown */
+	      bfd_object,	/* linker/assember/compiler output */
+	      bfd_archive,	/* object archive file */
+	      bfd_core,		/* core dump */
+	      bfd_type_end}	/* marks the end; don't use it! */
+         bfd_format;
+
+/* Values that may appear in the flags field of a BFD.  These also
+   appear in the object_flags field of the bfd_target structure, where
+   they indicate the set of flags used by that backend (not all flags
+   are meaningful for all object file formats) (FIXME: at the moment,
+   the object_flags values have mostly just been copied from backend
+   to another, and are not necessarily correct).  */
+
+/* No flags.  */
+#define BFD_NO_FLAGS   	0x00
+
+/* BFD contains relocation entries.  */
+#define HAS_RELOC   	0x01
+
+/* BFD is directly executable.  */
+#define EXEC_P      	0x02
+
+/* BFD has line number information (basically used for F_LNNO in a
+   COFF header).  */
+#define HAS_LINENO  	0x04
+
+/* BFD has debugging information.  */
+#define HAS_DEBUG   	0x08
+
+/* BFD has symbols.  */
+#define HAS_SYMS    	0x10
+
+/* BFD has local symbols (basically used for F_LSYMS in a COFF
+   header).  */
+#define HAS_LOCALS  	0x20
+
+/* BFD is a dynamic object.  */
+#define DYNAMIC     	0x40
+
+/* Text section is write protected (if D_PAGED is not set, this is
+   like an a.out NMAGIC file) (the linker sets this by default, but
+   clears it for -r or -N).  */
+#define WP_TEXT     	0x80
+
+/* BFD is dynamically paged (this is like an a.out ZMAGIC file) (the
+   linker sets this by default, but clears it for -r or -n or -N).  */
+#define D_PAGED     	0x100
+
+/* BFD is relaxable (this means that bfd_relax_section may be able to
+   do something) (sometimes bfd_relax_section can do something even if
+   this is not set).  */
+#define BFD_IS_RELAXABLE 0x200
+
+/* This may be set before writing out a BFD to request using a
+   traditional format.  For example, this is used to request that when
+   writing out an a.out object the symbols not be hashed to eliminate
+   duplicates.  */
+#define BFD_TRADITIONAL_FORMAT 0x400
+
+/* This flag indicates that the BFD contents are actually cached in
+   memory.  If this is set, iostream points to a bfd_in_memory struct.  */
+#define BFD_IN_MEMORY 0x800
+
+/* symbols and relocation */
+
+/* A count of carsyms (canonical archive symbols).  */
+typedef unsigned long symindex;
+
+/* How to perform a relocation.  */
+typedef const struct reloc_howto_struct reloc_howto_type;
+
+#define BFD_NO_MORE_SYMBOLS ((symindex) ~0)
+
+/* General purpose part of a symbol X;
+   target specific parts are in libcoff.h, libaout.h, etc.  */
+
+#define bfd_get_section(x) ((x)->section)
+#define bfd_get_output_section(x) ((x)->section->output_section)
+#define bfd_set_section(x,y) ((x)->section) = (y)
+#define bfd_asymbol_base(x) ((x)->section->vma)
+#define bfd_asymbol_value(x) (bfd_asymbol_base(x) + (x)->value)
+#define bfd_asymbol_name(x) ((x)->name)
+/*Perhaps future: #define bfd_asymbol_bfd(x) ((x)->section->owner)*/
+#define bfd_asymbol_bfd(x) ((x)->the_bfd)
+#define bfd_asymbol_flavour(x) (bfd_asymbol_bfd(x)->xvec->flavour)
+
+/* A canonical archive symbol.  */
+/* This is a type pun with struct ranlib on purpose! */
+typedef struct carsym {
+  char *name;
+  file_ptr file_offset;		/* look here to find the file */
+} carsym;			/* to make these you call a carsymogen */
+
+/* Used in generating armaps (archive tables of contents).
+   Perhaps just a forward definition would do? */
+struct orl {			/* output ranlib */
+  char **name;			/* symbol name */
+  union {
+    file_ptr pos;
+    bfd *abfd;
+  } u;				/* bfd* or file position */
+  int namidx;			/* index into string table */
+};
+
+/* Linenumber stuff */
+typedef struct lineno_cache_entry {
+  unsigned int line_number;	/* Linenumber from start of function*/
+  union {
+    struct symbol_cache_entry *sym; /* Function name */
+    bfd_vma offset;	    /* Offset into section */
+  } u;
+} alent;
+
+/* object and core file sections */
+
+#define	align_power(addr, align)	\
+	( ((addr) + ((1<<(align))-1)) & (-1 << (align)))
+
+typedef struct sec *sec_ptr;
+
+#define bfd_get_section_name(bfd, ptr) ((ptr)->name + 0)
+#define bfd_get_section_vma(bfd, ptr) ((ptr)->vma + 0)
+#define bfd_get_section_alignment(bfd, ptr) ((ptr)->alignment_power + 0)
+#define bfd_section_name(bfd, ptr) ((ptr)->name)
+#define bfd_section_size(bfd, ptr) (bfd_get_section_size_before_reloc(ptr))
+#define bfd_section_vma(bfd, ptr) ((ptr)->vma)
+#define bfd_section_lma(bfd, ptr) ((ptr)->lma)
+#define bfd_section_alignment(bfd, ptr) ((ptr)->alignment_power)
+#define bfd_get_section_flags(bfd, ptr) ((ptr)->flags + 0)
+#define bfd_get_section_userdata(bfd, ptr) ((ptr)->userdata)
+
+#define bfd_is_com_section(ptr) (((ptr)->flags & SEC_IS_COMMON) != 0)
+
+#define bfd_set_section_vma(bfd, ptr, val) (((ptr)->vma = (ptr)->lma= (val)), ((ptr)->user_set_vma = (boolean)true), true)
+#define bfd_set_section_alignment(bfd, ptr, val) (((ptr)->alignment_power = (val)),true)
+#define bfd_set_section_userdata(bfd, ptr, val) (((ptr)->userdata = (val)),true)
+
+typedef struct stat stat_type;
+
+typedef enum bfd_print_symbol
+{
+  bfd_print_symbol_name,
+  bfd_print_symbol_more,
+  bfd_print_symbol_all
+} bfd_print_symbol_type;
+
+/* Information about a symbol that nm needs.  */
+
+typedef struct _symbol_info
+{
+  symvalue value;
+  char type;
+  const char *name;            /* Symbol name.  */
+  unsigned char stab_type;     /* Stab type.  */
+  char stab_other;             /* Stab other.  */
+  short stab_desc;             /* Stab desc.  */
+  const char *stab_name;       /* String for stab type.  */
+} symbol_info;
+
+/* Get the name of a stabs type code.  */
+
+extern const char *bfd_get_stab_name PARAMS ((int));
+
+/* Hash table routines.  There is no way to free up a hash table.  */
+
+/* An element in the hash table.  Most uses will actually use a larger
+   structure, and an instance of this will be the first field.  */
+
+struct bfd_hash_entry
+{
+  /* Next entry for this hash code.  */
+  struct bfd_hash_entry *next;
+  /* String being hashed.  */
+  const char *string;
+  /* Hash code.  This is the full hash code, not the index into the
+     table.  */
+  unsigned long hash;
+};
+
+/* A hash table.  */
+
+struct bfd_hash_table
+{
+  /* The hash array.  */
+  struct bfd_hash_entry **table;
+  /* The number of slots in the hash table.  */
+  unsigned int size;
+  /* A function used to create new elements in the hash table.  The
+     first entry is itself a pointer to an element.  When this
+     function is first invoked, this pointer will be NULL.  However,
+     having the pointer permits a hierarchy of method functions to be
+     built each of which calls the function in the superclass.  Thus
+     each function should be written to allocate a new block of memory
+     only if the argument is NULL.  */
+  struct bfd_hash_entry *(*newfunc) PARAMS ((struct bfd_hash_entry *,
+					     struct bfd_hash_table *,
+					     const char *));
+   /* An objalloc for this hash table.  This is a struct objalloc *,
+     but we use PTR to avoid requiring the inclusion of objalloc.h.  */
+  PTR memory;
+};
+
+/* Initialize a hash table.  */
+extern boolean bfd_hash_table_init
+  PARAMS ((struct bfd_hash_table *,
+	   struct bfd_hash_entry *(*) (struct bfd_hash_entry *,
+				       struct bfd_hash_table *,
+				       const char *)));
+
+/* Initialize a hash table specifying a size.  */
+extern boolean bfd_hash_table_init_n
+  PARAMS ((struct bfd_hash_table *,
+	   struct bfd_hash_entry *(*) (struct bfd_hash_entry *,
+				       struct bfd_hash_table *,
+				       const char *),
+	   unsigned int size));
+
+/* Free up a hash table.  */
+extern void bfd_hash_table_free PARAMS ((struct bfd_hash_table *));
+
+/* Look up a string in a hash table.  If CREATE is true, a new entry
+   will be created for this string if one does not already exist.  The
+   COPY argument must be true if this routine should copy the string
+   into newly allocated memory when adding an entry.  */
+extern struct bfd_hash_entry *bfd_hash_lookup
+  PARAMS ((struct bfd_hash_table *, const char *, boolean create,
+	   boolean copy));
+
+/* Replace an entry in a hash table.  */
+extern void bfd_hash_replace
+  PARAMS ((struct bfd_hash_table *, struct bfd_hash_entry *old,
+	   struct bfd_hash_entry *nw));
+
+/* Base method for creating a hash table entry.  */
+extern struct bfd_hash_entry *bfd_hash_newfunc
+  PARAMS ((struct bfd_hash_entry *, struct bfd_hash_table *,
+	   const char *));
+
+/* Grab some space for a hash table entry.  */
+extern PTR bfd_hash_allocate PARAMS ((struct bfd_hash_table *,
+				      unsigned int));
+
+/* Traverse a hash table in a random order, calling a function on each
+   element.  If the function returns false, the traversal stops.  The
+   INFO argument is passed to the function.  */
+extern void bfd_hash_traverse PARAMS ((struct bfd_hash_table *,
+				       boolean (*) (struct bfd_hash_entry *,
+						    PTR),
+				       PTR info));
+
+#define COFF_SWAP_TABLE (PTR) &bfd_coff_std_swap_table
+
+/* User program access to BFD facilities */
+
+/* Direct I/O routines, for programs which know more about the object
+   file than BFD does.  Use higher level routines if possible.  */
+
+extern bfd_size_type bfd_bread PARAMS ((PTR, bfd_size_type, bfd *));
+extern bfd_size_type bfd_bwrite PARAMS ((const PTR, bfd_size_type, bfd *));
+extern int bfd_seek PARAMS ((bfd *, file_ptr, int));
+extern ufile_ptr bfd_tell PARAMS ((bfd *));
+extern int bfd_flush PARAMS ((bfd *));
+extern int bfd_stat PARAMS ((bfd *, struct stat *));
+
+/* Deprecated old routines.  */
+#if __GNUC__
+#define bfd_read(BUF, ELTSIZE, NITEMS, ABFD)				\
+  (warn_deprecated ("bfd_read", __FILE__, __LINE__, __FUNCTION__),	\
+   bfd_bread ((BUF), (ELTSIZE) * (NITEMS), (ABFD)))
+#define bfd_write(BUF, ELTSIZE, NITEMS, ABFD)				\
+  (warn_deprecated ("bfd_write", __FILE__, __LINE__, __FUNCTION__),	\
+   bfd_bwrite ((BUF), (ELTSIZE) * (NITEMS), (ABFD)))
+#else
+#define bfd_read(BUF, ELTSIZE, NITEMS, ABFD)				\
+  (warn_deprecated ("bfd_read", (const char *) 0, 0, (const char *) 0), \
+   bfd_bread ((BUF), (ELTSIZE) * (NITEMS), (ABFD)))
+#define bfd_write(BUF, ELTSIZE, NITEMS, ABFD)				\
+  (warn_deprecated ("bfd_write", (const char *) 0, 0, (const char *) 0),\
+   bfd_bwrite ((BUF), (ELTSIZE) * (NITEMS), (ABFD)))
+#endif
+extern void warn_deprecated
+  PARAMS ((const char *, const char *, int, const char *));
+
+/* Cast from const char * to char * so that caller can assign to
+   a char * without a warning.  */
+#define bfd_get_filename(abfd) ((char *) (abfd)->filename)
+#define bfd_get_cacheable(abfd) ((abfd)->cacheable)
+#define bfd_get_format(abfd) ((abfd)->format)
+#define bfd_get_target(abfd) ((abfd)->xvec->name)
+#define bfd_get_flavour(abfd) ((abfd)->xvec->flavour)
+#define bfd_family_coff(abfd) \
+  (bfd_get_flavour (abfd) == bfd_target_coff_flavour || \
+   bfd_get_flavour (abfd) == bfd_target_xcoff_flavour)
+#define bfd_big_endian(abfd) ((abfd)->xvec->byteorder == BFD_ENDIAN_BIG)
+#define bfd_little_endian(abfd) ((abfd)->xvec->byteorder == BFD_ENDIAN_LITTLE)
+#define bfd_header_big_endian(abfd) \
+  ((abfd)->xvec->header_byteorder == BFD_ENDIAN_BIG)
+#define bfd_header_little_endian(abfd) \
+  ((abfd)->xvec->header_byteorder == BFD_ENDIAN_LITTLE)
+#define bfd_get_file_flags(abfd) ((abfd)->flags)
+#define bfd_applicable_file_flags(abfd) ((abfd)->xvec->object_flags)
+#define bfd_applicable_section_flags(abfd) ((abfd)->xvec->section_flags)
+#define bfd_my_archive(abfd) ((abfd)->my_archive)
+#define bfd_has_map(abfd) ((abfd)->has_armap)
+
+#define bfd_valid_reloc_types(abfd) ((abfd)->xvec->valid_reloc_types)
+#define bfd_usrdata(abfd) ((abfd)->usrdata)
+
+#define bfd_get_start_address(abfd) ((abfd)->start_address)
+#define bfd_get_symcount(abfd) ((abfd)->symcount)
+#define bfd_get_outsymbols(abfd) ((abfd)->outsymbols)
+#define bfd_count_sections(abfd) ((abfd)->section_count)
+
+#define bfd_get_symbol_leading_char(abfd) ((abfd)->xvec->symbol_leading_char)
+
+#define bfd_set_cacheable(abfd,bool) (((abfd)->cacheable = (boolean) (bool)), true)
+
+extern boolean bfd_cache_close PARAMS ((bfd *abfd));
+/* NB: This declaration should match the autogenerated one in libbfd.h.  */
+
+extern boolean bfd_record_phdr
+  PARAMS ((bfd *, unsigned long, boolean, flagword, boolean, bfd_vma,
+	   boolean, boolean, unsigned int, struct sec **));
+
+/* Byte swapping routines.  */
+
+bfd_vma		bfd_getb64	   PARAMS ((const unsigned char *));
+bfd_vma 	bfd_getl64	   PARAMS ((const unsigned char *));
+bfd_signed_vma	bfd_getb_signed_64 PARAMS ((const unsigned char *));
+bfd_signed_vma	bfd_getl_signed_64 PARAMS ((const unsigned char *));
+bfd_vma		bfd_getb32	   PARAMS ((const unsigned char *));
+bfd_vma		bfd_getl32	   PARAMS ((const unsigned char *));
+bfd_signed_vma	bfd_getb_signed_32 PARAMS ((const unsigned char *));
+bfd_signed_vma	bfd_getl_signed_32 PARAMS ((const unsigned char *));
+bfd_vma		bfd_getb16	   PARAMS ((const unsigned char *));
+bfd_vma		bfd_getl16	   PARAMS ((const unsigned char *));
+bfd_signed_vma	bfd_getb_signed_16 PARAMS ((const unsigned char *));
+bfd_signed_vma	bfd_getl_signed_16 PARAMS ((const unsigned char *));
+void		bfd_putb64	   PARAMS ((bfd_vma, unsigned char *));
+void		bfd_putl64	   PARAMS ((bfd_vma, unsigned char *));
+void		bfd_putb32	   PARAMS ((bfd_vma, unsigned char *));
+void		bfd_putl32	   PARAMS ((bfd_vma, unsigned char *));
+void		bfd_putb16	   PARAMS ((bfd_vma, unsigned char *));
+void		bfd_putl16	   PARAMS ((bfd_vma, unsigned char *));
+
+/* Byte swapping routines which take size and endiannes as arguments.  */
+
+bfd_vma         bfd_get_bits       PARAMS ((bfd_byte *, int, boolean));
+void            bfd_put_bits       PARAMS ((bfd_vma, bfd_byte *, int, boolean));
+
+/* Externally visible ECOFF routines.  */
+
+#if defined(__STDC__) || defined(ALMOST_STDC)
+struct ecoff_debug_info;
+struct ecoff_debug_swap;
+struct ecoff_extr;
+struct symbol_cache_entry;
+struct bfd_link_info;
+struct bfd_link_hash_entry;
+struct bfd_elf_version_tree;
+#endif
+extern bfd_vma bfd_ecoff_get_gp_value PARAMS ((bfd * abfd));
+extern boolean bfd_ecoff_set_gp_value PARAMS ((bfd *abfd, bfd_vma gp_value));
+extern boolean bfd_ecoff_set_regmasks
+  PARAMS ((bfd *abfd, unsigned long gprmask, unsigned long fprmask,
+	   unsigned long *cprmask));
+extern PTR bfd_ecoff_debug_init
+  PARAMS ((bfd *output_bfd, struct ecoff_debug_info *output_debug,
+	   const struct ecoff_debug_swap *output_swap,
+	   struct bfd_link_info *));
+extern void bfd_ecoff_debug_free
+  PARAMS ((PTR handle, bfd *output_bfd, struct ecoff_debug_info *output_debug,
+	   const struct ecoff_debug_swap *output_swap,
+	   struct bfd_link_info *));
+extern boolean bfd_ecoff_debug_accumulate
+  PARAMS ((PTR handle, bfd *output_bfd, struct ecoff_debug_info *output_debug,
+	   const struct ecoff_debug_swap *output_swap,
+	   bfd *input_bfd, struct ecoff_debug_info *input_debug,
+	   const struct ecoff_debug_swap *input_swap,
+	   struct bfd_link_info *));
+extern boolean bfd_ecoff_debug_accumulate_other
+  PARAMS ((PTR handle, bfd *output_bfd, struct ecoff_debug_info *output_debug,
+	   const struct ecoff_debug_swap *output_swap, bfd *input_bfd,
+	   struct bfd_link_info *));
+extern boolean bfd_ecoff_debug_externals
+  PARAMS ((bfd *abfd, struct ecoff_debug_info *debug,
+	   const struct ecoff_debug_swap *swap,
+	   boolean relocateable,
+	   boolean (*get_extr) (struct symbol_cache_entry *,
+				struct ecoff_extr *),
+	   void (*set_index) (struct symbol_cache_entry *,
+			      bfd_size_type)));
+extern boolean bfd_ecoff_debug_one_external
+  PARAMS ((bfd *abfd, struct ecoff_debug_info *debug,
+	   const struct ecoff_debug_swap *swap,
+	   const char *name, struct ecoff_extr *esym));
+extern bfd_size_type bfd_ecoff_debug_size
+  PARAMS ((bfd *abfd, struct ecoff_debug_info *debug,
+	   const struct ecoff_debug_swap *swap));
+extern boolean bfd_ecoff_write_debug
+  PARAMS ((bfd *abfd, struct ecoff_debug_info *debug,
+	   const struct ecoff_debug_swap *swap, file_ptr where));
+extern boolean bfd_ecoff_write_accumulated_debug
+  PARAMS ((PTR handle, bfd *abfd, struct ecoff_debug_info *debug,
+	   const struct ecoff_debug_swap *swap,
+	   struct bfd_link_info *info, file_ptr where));
+extern boolean bfd_mips_ecoff_create_embedded_relocs
+  PARAMS ((bfd *, struct bfd_link_info *, struct sec *, struct sec *,
+	   char **));
+
+/* Externally visible ELF routines.  */
+
+struct bfd_link_needed_list
+{
+  struct bfd_link_needed_list *next;
+  bfd *by;
+  const char *name;
+};
+
+extern boolean bfd_elf32_record_link_assignment
+  PARAMS ((bfd *, struct bfd_link_info *, const char *, boolean));
+extern boolean bfd_elf64_record_link_assignment
+  PARAMS ((bfd *, struct bfd_link_info *, const char *, boolean));
+extern struct bfd_link_needed_list *bfd_elf_get_needed_list
+  PARAMS ((bfd *, struct bfd_link_info *));
+extern boolean bfd_elf_get_bfd_needed_list
+  PARAMS ((bfd *, struct bfd_link_needed_list **));
+extern boolean bfd_elf32_size_dynamic_sections
+  PARAMS ((bfd *, const char *, const char *, const char *,
+	   const char * const *, struct bfd_link_info *, struct sec **,
+	   struct bfd_elf_version_tree *));
+extern boolean bfd_elf64_size_dynamic_sections
+  PARAMS ((bfd *, const char *, const char *, const char *,
+	   const char * const *, struct bfd_link_info *, struct sec **,
+	   struct bfd_elf_version_tree *));
+extern void bfd_elf_set_dt_needed_name PARAMS ((bfd *, const char *));
+extern void bfd_elf_set_dt_needed_soname PARAMS ((bfd *, const char *));
+extern const char *bfd_elf_get_dt_soname PARAMS ((bfd *));
+extern struct bfd_link_needed_list *bfd_elf_get_runpath_list
+  PARAMS ((bfd *, struct bfd_link_info *));
+
+/* Return an upper bound on the number of bytes required to store a
+   copy of ABFD's program header table entries.  Return -1 if an error
+   occurs; bfd_get_error will return an appropriate code.  */
+extern long bfd_get_elf_phdr_upper_bound PARAMS ((bfd *abfd));
+
+/* Copy ABFD's program header table entries to *PHDRS.  The entries
+   will be stored as an array of Elf_Internal_Phdr structures, as
+   defined in include/elf/internal.h.  To find out how large the
+   buffer needs to be, call bfd_get_elf_phdr_upper_bound.
+
+   Return the number of program header table entries read, or -1 if an
+   error occurs; bfd_get_error will return an appropriate code.  */
+extern int bfd_get_elf_phdrs PARAMS ((bfd *abfd, void *phdrs));
+
+/* Return the arch_size field of an elf bfd, or -1 if not elf.  */
+extern int bfd_get_arch_size PARAMS ((bfd *));
+
+/* Return true if address "naturally" sign extends, or -1 if not elf.  */
+extern int bfd_get_sign_extend_vma PARAMS ((bfd *));
+
+extern boolean bfd_m68k_elf32_create_embedded_relocs
+  PARAMS ((bfd *, struct bfd_link_info *, struct sec *, struct sec *,
+	   char **));
+
+/* SunOS shared library support routines for the linker.  */
+
+extern struct bfd_link_needed_list *bfd_sunos_get_needed_list
+  PARAMS ((bfd *, struct bfd_link_info *));
+extern boolean bfd_sunos_record_link_assignment
+  PARAMS ((bfd *, struct bfd_link_info *, const char *));
+extern boolean bfd_sunos_size_dynamic_sections
+  PARAMS ((bfd *, struct bfd_link_info *, struct sec **, struct sec **,
+	   struct sec **));
+
+/* Linux shared library support routines for the linker.  */
+
+extern boolean bfd_i386linux_size_dynamic_sections
+  PARAMS ((bfd *, struct bfd_link_info *));
+extern boolean bfd_m68klinux_size_dynamic_sections
+  PARAMS ((bfd *, struct bfd_link_info *));
+extern boolean bfd_sparclinux_size_dynamic_sections
+  PARAMS ((bfd *, struct bfd_link_info *));
+
+/* mmap hacks */
+
+struct _bfd_window_internal;
+typedef struct _bfd_window_internal bfd_window_internal;
+
+typedef struct _bfd_window {
+  /* What the user asked for.  */
+  PTR data;
+  bfd_size_type size;
+  /* The actual window used by BFD.  Small user-requested read-only
+     regions sharing a page may share a single window into the object
+     file.  Read-write versions shouldn't until I've fixed things to
+     keep track of which portions have been claimed by the
+     application; don't want to give the same region back when the
+     application wants two writable copies!  */
+  struct _bfd_window_internal *i;
+} bfd_window;
+
+extern void bfd_init_window PARAMS ((bfd_window *));
+extern void bfd_free_window PARAMS ((bfd_window *));
+extern boolean bfd_get_file_window
+  PARAMS ((bfd *, file_ptr, bfd_size_type, bfd_window *, boolean));
+
+/* XCOFF support routines for the linker.  */
+
+extern boolean bfd_xcoff_link_record_set
+  PARAMS ((bfd *, struct bfd_link_info *, struct bfd_link_hash_entry *,
+	   bfd_size_type));
+extern boolean bfd_xcoff_import_symbol
+  PARAMS ((bfd *, struct bfd_link_info *, struct bfd_link_hash_entry *,
+	   bfd_vma, const char *, const char *, const char *, unsigned int));
+extern boolean bfd_xcoff_export_symbol
+  PARAMS ((bfd *, struct bfd_link_info *, struct bfd_link_hash_entry *));
+extern boolean bfd_xcoff_link_count_reloc
+  PARAMS ((bfd *, struct bfd_link_info *, const char *));
+extern boolean bfd_xcoff_record_link_assignment
+  PARAMS ((bfd *, struct bfd_link_info *, const char *));
+extern boolean bfd_xcoff_size_dynamic_sections
+  PARAMS ((bfd *, struct bfd_link_info *, const char *, const char *,
+	   unsigned long, unsigned long, unsigned long, boolean,
+	   int, boolean, boolean, struct sec **));
+
+/* Externally visible COFF routines.  */
+
+#if defined(__STDC__) || defined(ALMOST_STDC)
+struct internal_syment;
+union internal_auxent;
+#endif
+
+extern boolean bfd_coff_get_syment
+  PARAMS ((bfd *, struct symbol_cache_entry *, struct internal_syment *));
+
+extern boolean bfd_coff_get_auxent
+  PARAMS ((bfd *, struct symbol_cache_entry *, int, union internal_auxent *));
+
+extern boolean bfd_coff_set_symbol_class
+  PARAMS ((bfd *, struct symbol_cache_entry *, unsigned int));
+
+extern boolean bfd_m68k_coff_create_embedded_relocs
+  PARAMS ((bfd *, struct bfd_link_info *, struct sec *, struct sec *,
+	   char **));
+
+/* ARM Interworking support.  Called from linker.  */
+extern boolean bfd_arm_allocate_interworking_sections
+  PARAMS ((struct bfd_link_info *));
+
+extern boolean bfd_arm_process_before_allocation
+  PARAMS ((bfd *, struct bfd_link_info *, int));
+
+extern boolean bfd_arm_get_bfd_for_interworking
+  PARAMS ((bfd *, struct bfd_link_info *));
+
+/* PE ARM Interworking support.  Called from linker.  */
+extern boolean bfd_arm_pe_allocate_interworking_sections
+  PARAMS ((struct bfd_link_info *));
+
+extern boolean bfd_arm_pe_process_before_allocation
+  PARAMS ((bfd *, struct bfd_link_info *, int));
+
+extern boolean bfd_arm_pe_get_bfd_for_interworking
+  PARAMS ((bfd *, struct bfd_link_info *));
+
+/* ELF ARM Interworking support.  Called from linker.  */
+extern boolean bfd_elf32_arm_allocate_interworking_sections
+  PARAMS ((struct bfd_link_info *));
+
+extern boolean bfd_elf32_arm_process_before_allocation
+  PARAMS ((bfd *, struct bfd_link_info *, int));
+
+extern boolean bfd_elf32_arm_get_bfd_for_interworking
+  PARAMS ((bfd *, struct bfd_link_info *));
+
+/* TI COFF load page support.  */
+extern void bfd_ticoff_set_section_load_page
+  PARAMS ((struct sec *, int));
+
+extern int bfd_ticoff_get_section_load_page
+  PARAMS ((struct sec *));
+
+/* And more from the source.  */
+void
+bfd_init PARAMS ((void));
+
+bfd *
+bfd_openr PARAMS ((const char *filename, const char *target));
+
+bfd *
+bfd_fdopenr PARAMS ((const char *filename, const char *target, int fd));
+
+bfd *
+bfd_openstreamr PARAMS ((const char *, const char *, PTR));
+
+bfd *
+bfd_openw PARAMS ((const char *filename, const char *target));
+
+boolean
+bfd_close PARAMS ((bfd *abfd));
+
+boolean
+bfd_close_all_done PARAMS ((bfd *));
+
+bfd *
+bfd_create PARAMS ((const char *filename, bfd *templ));
+
+boolean
+bfd_make_writable PARAMS ((bfd *abfd));
+
+boolean
+bfd_make_readable PARAMS ((bfd *abfd));
+
+
+/* Byte swapping macros for user section data.  */
+
+#define bfd_put_8(abfd, val, ptr) \
+                ((void) (*((unsigned char *) (ptr)) = (unsigned char) (val)))
+#define bfd_put_signed_8 \
+               bfd_put_8
+#define bfd_get_8(abfd, ptr) \
+                (*(unsigned char *) (ptr) & 0xff)
+#define bfd_get_signed_8(abfd, ptr) \
+               (((*(unsigned char *) (ptr) & 0xff) ^ 0x80) - 0x80)
+
+#define bfd_put_16(abfd, val, ptr) \
+                BFD_SEND(abfd, bfd_putx16, ((val),(ptr)))
+#define bfd_put_signed_16 \
+                bfd_put_16
+#define bfd_get_16(abfd, ptr) \
+                BFD_SEND(abfd, bfd_getx16, (ptr))
+#define bfd_get_signed_16(abfd, ptr) \
+                BFD_SEND (abfd, bfd_getx_signed_16, (ptr))
+
+#define bfd_put_32(abfd, val, ptr) \
+                BFD_SEND(abfd, bfd_putx32, ((val),(ptr)))
+#define bfd_put_signed_32 \
+                bfd_put_32
+#define bfd_get_32(abfd, ptr) \
+                BFD_SEND(abfd, bfd_getx32, (ptr))
+#define bfd_get_signed_32(abfd, ptr) \
+                BFD_SEND(abfd, bfd_getx_signed_32, (ptr))
+
+#define bfd_put_64(abfd, val, ptr) \
+                BFD_SEND(abfd, bfd_putx64, ((val), (ptr)))
+#define bfd_put_signed_64 \
+                bfd_put_64
+#define bfd_get_64(abfd, ptr) \
+                BFD_SEND(abfd, bfd_getx64, (ptr))
+#define bfd_get_signed_64(abfd, ptr) \
+                BFD_SEND(abfd, bfd_getx_signed_64, (ptr))
+
+#define bfd_get(bits, abfd, ptr)                               \
+                ( (bits) ==  8 ? (bfd_vma) bfd_get_8 (abfd, ptr)       \
+                : (bits) == 16 ? bfd_get_16 (abfd, ptr)        \
+                : (bits) == 32 ? bfd_get_32 (abfd, ptr)        \
+                : (bits) == 64 ? bfd_get_64 (abfd, ptr)        \
+                : (abort (), (bfd_vma) - 1))
+
+#define bfd_put(bits, abfd, val, ptr)                          \
+                ( (bits) ==  8 ? bfd_put_8  (abfd, val, ptr)   \
+                : (bits) == 16 ? bfd_put_16 (abfd, val, ptr)   \
+                : (bits) == 32 ? bfd_put_32 (abfd, val, ptr)   \
+                : (bits) == 64 ? bfd_put_64 (abfd, val, ptr)   \
+                : (abort (), (void) 0))
+
+
+/* Byte swapping macros for file header data.  */
+
+#define bfd_h_put_8(abfd, val, ptr) \
+  bfd_put_8 (abfd, val, ptr)
+#define bfd_h_put_signed_8(abfd, val, ptr) \
+  bfd_put_8 (abfd, val, ptr)
+#define bfd_h_get_8(abfd, ptr) \
+  bfd_get_8 (abfd, ptr)
+#define bfd_h_get_signed_8(abfd, ptr) \
+  bfd_get_signed_8 (abfd, ptr)
+
+#define bfd_h_put_16(abfd, val, ptr) \
+  BFD_SEND (abfd, bfd_h_putx16, (val, ptr))
+#define bfd_h_put_signed_16 \
+  bfd_h_put_16
+#define bfd_h_get_16(abfd, ptr) \
+  BFD_SEND (abfd, bfd_h_getx16, (ptr))
+#define bfd_h_get_signed_16(abfd, ptr) \
+  BFD_SEND (abfd, bfd_h_getx_signed_16, (ptr))
+
+#define bfd_h_put_32(abfd, val, ptr) \
+  BFD_SEND (abfd, bfd_h_putx32, (val, ptr))
+#define bfd_h_put_signed_32 \
+  bfd_h_put_32
+#define bfd_h_get_32(abfd, ptr) \
+  BFD_SEND (abfd, bfd_h_getx32, (ptr))
+#define bfd_h_get_signed_32(abfd, ptr) \
+  BFD_SEND (abfd, bfd_h_getx_signed_32, (ptr))
+
+#define bfd_h_put_64(abfd, val, ptr) \
+  BFD_SEND (abfd, bfd_h_putx64, (val, ptr))
+#define bfd_h_put_signed_64 \
+  bfd_h_put_64
+#define bfd_h_get_64(abfd, ptr) \
+  BFD_SEND (abfd, bfd_h_getx64, (ptr))
+#define bfd_h_get_signed_64(abfd, ptr) \
+  BFD_SEND (abfd, bfd_h_getx_signed_64, (ptr))
+
+/* Refinements on the above, which should eventually go away.  Save
+   cluttering the source with (bfd_vma) and (bfd_byte *) casts.  */
+
+#define H_PUT_64(abfd, val, where) \
+  bfd_h_put_64 ((abfd), (bfd_vma) (val), (bfd_byte *) (where))
+
+#define H_PUT_32(abfd, val, where) \
+  bfd_h_put_32 ((abfd), (bfd_vma) (val), (bfd_byte *) (where))
+
+#define H_PUT_16(abfd, val, where) \
+  bfd_h_put_16 ((abfd), (bfd_vma) (val), (bfd_byte *) (where))
+
+#define H_PUT_8 bfd_h_put_8
+
+#define H_PUT_S64(abfd, val, where) \
+  bfd_h_put_signed_64 ((abfd), (bfd_vma) (val), (bfd_byte *) (where))
+
+#define H_PUT_S32(abfd, val, where) \
+  bfd_h_put_signed_32 ((abfd), (bfd_vma) (val), (bfd_byte *) (where))
+
+#define H_PUT_S16(abfd, val, where) \
+  bfd_h_put_signed_16 ((abfd), (bfd_vma) (val), (bfd_byte *) (where))
+
+#define H_PUT_S8 bfd_h_put_signed_8
+
+#define H_GET_64(abfd, where) \
+  bfd_h_get_64 ((abfd), (bfd_byte *) (where))
+
+#define H_GET_32(abfd, where) \
+  bfd_h_get_32 ((abfd), (bfd_byte *) (where))
+
+#define H_GET_16(abfd, where) \
+  bfd_h_get_16 ((abfd), (bfd_byte *) (where))
+
+#define H_GET_8 bfd_h_get_8
+
+#define H_GET_S64(abfd, where) \
+  bfd_h_get_signed_64 ((abfd), (bfd_byte *) (where))
+
+#define H_GET_S32(abfd, where) \
+  bfd_h_get_signed_32 ((abfd), (bfd_byte *) (where))
+
+#define H_GET_S16(abfd, where) \
+  bfd_h_get_signed_16 ((abfd), (bfd_byte *) (where))
+
+#define H_GET_S8 bfd_h_get_signed_8
+
+
+/* This structure is used for a comdat section, as in PE.  A comdat
+   section is associated with a particular symbol.  When the linker
+   sees a comdat section, it keeps only one of the sections with a
+   given name and associated with a given symbol.  */
+
+struct bfd_comdat_info
+{
+  /* The name of the symbol associated with a comdat section.  */
+  const char *name;
+
+  /* The local symbol table index of the symbol associated with a
+     comdat section.  This is only meaningful to the object file format
+     specific code; it is not an index into the list returned by
+     bfd_canonicalize_symtab.  */
+  long symbol;
+};
+
+typedef struct sec
+{
+  /* The name of the section; the name isn't a copy, the pointer is
+     the same as that passed to bfd_make_section.  */
+
+  const char *name;
+
+  /* A unique sequence number.  */
+
+  int id;
+
+  /* Which section in the bfd; 0..n-1 as sections are created in a bfd.  */
+
+  int index;
+
+  /* The next section in the list belonging to the BFD, or NULL.  */
+
+  struct sec *next;
+
+  /* The field flags contains attributes of the section. Some
+     flags are read in from the object file, and some are
+     synthesized from other information.  */
+
+  flagword flags;
+
+#define SEC_NO_FLAGS   0x000
+
+  /* Tells the OS to allocate space for this section when loading.
+     This is clear for a section containing debug information only.  */
+#define SEC_ALLOC      0x001
+
+  /* Tells the OS to load the section from the file when loading.
+     This is clear for a .bss section.  */
+#define SEC_LOAD       0x002
+
+  /* The section contains data still to be relocated, so there is
+     some relocation information too.  */
+#define SEC_RELOC      0x004
+
+  /* ELF reserves 4 processor specific bits and 8 operating system
+     specific bits in sh_flags; at present we can get away with just
+     one in communicating between the assembler and BFD, but this
+     isn't a good long-term solution.  */
+#define SEC_ARCH_BIT_0 0x008
+
+  /* A signal to the OS that the section contains read only data.  */
+#define SEC_READONLY   0x010
+
+  /* The section contains code only.  */
+#define SEC_CODE       0x020
+
+  /* The section contains data only.  */
+#define SEC_DATA       0x040
+
+  /* The section will reside in ROM.  */
+#define SEC_ROM        0x080
+
+  /* The section contains constructor information. This section
+     type is used by the linker to create lists of constructors and
+     destructors used by <<g++>>. When a back end sees a symbol
+     which should be used in a constructor list, it creates a new
+     section for the type of name (e.g., <<__CTOR_LIST__>>), attaches
+     the symbol to it, and builds a relocation. To build the lists
+     of constructors, all the linker has to do is catenate all the
+     sections called <<__CTOR_LIST__>> and relocate the data
+     contained within - exactly the operations it would peform on
+     standard data.  */
+#define SEC_CONSTRUCTOR 0x100
+
+  /* The section is a constructor, and should be placed at the
+     end of the text, data, or bss section(?).  */
+#define SEC_CONSTRUCTOR_TEXT 0x1100
+#define SEC_CONSTRUCTOR_DATA 0x2100
+#define SEC_CONSTRUCTOR_BSS  0x3100
+
+  /* The section has contents - a data section could be
+     <<SEC_ALLOC>> | <<SEC_HAS_CONTENTS>>; a debug section could be
+     <<SEC_HAS_CONTENTS>>  */
+#define SEC_HAS_CONTENTS 0x200
+
+  /* An instruction to the linker to not output the section
+     even if it has information which would normally be written.  */
+#define SEC_NEVER_LOAD 0x400
+
+  /* The section is a COFF shared library section.  This flag is
+     only for the linker.  If this type of section appears in
+     the input file, the linker must copy it to the output file
+     without changing the vma or size.  FIXME: Although this
+     was originally intended to be general, it really is COFF
+     specific (and the flag was renamed to indicate this).  It
+     might be cleaner to have some more general mechanism to
+     allow the back end to control what the linker does with
+     sections.  */
+#define SEC_COFF_SHARED_LIBRARY 0x800
+
+  /* The section has GOT references.  This flag is only for the
+     linker, and is currently only used by the elf32-hppa back end.
+     It will be set if global offset table references were detected
+     in this section, which indicate to the linker that the section
+     contains PIC code, and must be handled specially when doing a
+     static link.  */
+#define SEC_HAS_GOT_REF 0x4000
+
+  /* The section contains common symbols (symbols may be defined
+     multiple times, the value of a symbol is the amount of
+     space it requires, and the largest symbol value is the one
+     used).  Most targets have exactly one of these (which we
+     translate to bfd_com_section_ptr), but ECOFF has two.  */
+#define SEC_IS_COMMON 0x8000
+
+  /* The section contains only debugging information.  For
+     example, this is set for ELF .debug and .stab sections.
+     strip tests this flag to see if a section can be
+     discarded.  */
+#define SEC_DEBUGGING 0x10000
+
+  /* The contents of this section are held in memory pointed to
+     by the contents field.  This is checked by bfd_get_section_contents,
+     and the data is retrieved from memory if appropriate.  */
+#define SEC_IN_MEMORY 0x20000
+
+  /* The contents of this section are to be excluded by the
+     linker for executable and shared objects unless those
+     objects are to be further relocated.  */
+#define SEC_EXCLUDE 0x40000
+
+  /* The contents of this section are to be sorted based on the sum of
+     the symbol and addend values specified by the associated relocation
+     entries.  Entries without associated relocation entries will be
+     appended to the end of the section in an unspecified order.  */
+#define SEC_SORT_ENTRIES 0x80000
+
+  /* When linking, duplicate sections of the same name should be
+     discarded, rather than being combined into a single section as
+     is usually done.  This is similar to how common symbols are
+     handled.  See SEC_LINK_DUPLICATES below.  */
+#define SEC_LINK_ONCE 0x100000
+
+  /* If SEC_LINK_ONCE is set, this bitfield describes how the linker
+     should handle duplicate sections.  */
+#define SEC_LINK_DUPLICATES 0x600000
+
+  /* This value for SEC_LINK_DUPLICATES means that duplicate
+     sections with the same name should simply be discarded.  */
+#define SEC_LINK_DUPLICATES_DISCARD 0x0
+
+  /* This value for SEC_LINK_DUPLICATES means that the linker
+     should warn if there are any duplicate sections, although
+     it should still only link one copy.  */
+#define SEC_LINK_DUPLICATES_ONE_ONLY 0x200000
+
+  /* This value for SEC_LINK_DUPLICATES means that the linker
+     should warn if any duplicate sections are a different size.  */
+#define SEC_LINK_DUPLICATES_SAME_SIZE 0x400000
+
+  /* This value for SEC_LINK_DUPLICATES means that the linker
+     should warn if any duplicate sections contain different
+     contents.  */
+#define SEC_LINK_DUPLICATES_SAME_CONTENTS 0x600000
+
+  /* This section was created by the linker as part of dynamic
+     relocation or other arcane processing.  It is skipped when
+     going through the first-pass output, trusting that someone
+     else up the line will take care of it later.  */
+#define SEC_LINKER_CREATED 0x800000
+
+  /* This section should not be subject to garbage collection.  */
+#define SEC_KEEP 0x1000000
+
+  /* This section contains "short" data, and should be placed
+     "near" the GP.  */
+#define SEC_SMALL_DATA 0x2000000
+
+  /* This section contains data which may be shared with other
+     executables or shared objects.  */
+#define SEC_SHARED 0x4000000
+
+  /* When a section with this flag is being linked, then if the size of
+     the input section is less than a page, it should not cross a page
+     boundary.  If the size of the input section is one page or more, it
+     should be aligned on a page boundary.  */
+#define SEC_BLOCK 0x8000000
+
+  /* Conditionally link this section; do not link if there are no
+     references found to any symbol in the section.  */
+#define SEC_CLINK 0x10000000
+
+  /* Attempt to merge identical entities in the section.
+     Entity size is given in the entsize field.  */
+#define SEC_MERGE 0x20000000
+
+  /* If given with SEC_MERGE, entities to merge are zero terminated
+     strings where entsize specifies character size instead of fixed
+     size entries.  */
+#define SEC_STRINGS 0x40000000
+
+  /* This section contains data about section groups.  */
+#define SEC_GROUP 0x80000000
+
+  /*  End of section flags.  */
+
+  /* Some internal packed boolean fields.  */
+
+  /* See the vma field.  */
+  unsigned int user_set_vma : 1;
+
+  /* Whether relocations have been processed.  */
+  unsigned int reloc_done : 1;
+
+  /* A mark flag used by some of the linker backends.  */
+  unsigned int linker_mark : 1;
+
+  /* Another mark flag used by some of the linker backends.  Set for
+     output sections that have an input section.  */
+  unsigned int linker_has_input : 1;
+
+  /* A mark flag used by some linker backends for garbage collection.  */
+  unsigned int gc_mark : 1;
+
+  /* Used by the ELF code to mark sections which have been allocated
+     to segments.  */
+  unsigned int segment_mark : 1;
+
+  /* End of internal packed boolean fields.  */
+
+  /*  The virtual memory address of the section - where it will be
+      at run time.  The symbols are relocated against this.  The
+      user_set_vma flag is maintained by bfd; if it's not set, the
+      backend can assign addresses (for example, in <<a.out>>, where
+      the default address for <<.data>> is dependent on the specific
+      target and various flags).  */
+
+  bfd_vma vma;
+
+  /*  The load address of the section - where it would be in a
+      rom image; really only used for writing section header
+      information. */
+
+  bfd_vma lma;
+
+  /* The size of the section in octets, as it will be output.
+     Contains a value even if the section has no contents (e.g., the
+     size of <<.bss>>).  This will be filled in after relocation.  */
+
+  bfd_size_type _cooked_size;
+
+  /* The original size on disk of the section, in octets.  Normally this
+     value is the same as the size, but if some relaxing has
+     been done, then this value will be bigger.  */
+
+  bfd_size_type _raw_size;
+
+  /* If this section is going to be output, then this value is the
+     offset in *bytes* into the output section of the first byte in the
+     input section (byte ==> smallest addressable unit on the
+     target).  In most cases, if this was going to start at the
+     100th octet (8-bit quantity) in the output section, this value
+     would be 100.  However, if the target byte size is 16 bits
+     (bfd_octets_per_byte is "2"), this value would be 50.  */
+
+  bfd_vma output_offset;
+
+  /* The output section through which to map on output.  */
+
+  struct sec *output_section;
+
+  /* The alignment requirement of the section, as an exponent of 2 -
+     e.g., 3 aligns to 2^3 (or 8).  */
+
+  unsigned int alignment_power;
+
+  /* If an input section, a pointer to a vector of relocation
+     records for the data in this section.  */
+
+  struct reloc_cache_entry *relocation;
+
+  /* If an output section, a pointer to a vector of pointers to
+     relocation records for the data in this section.  */
+
+  struct reloc_cache_entry **orelocation;
+
+  /* The number of relocation records in one of the above  */
+
+  unsigned reloc_count;
+
+  /* Information below is back end specific - and not always used
+     or updated.  */
+
+  /* File position of section data.  */
+
+  file_ptr filepos;
+
+  /* File position of relocation info.  */
+
+  file_ptr rel_filepos;
+
+  /* File position of line data.  */
+
+  file_ptr line_filepos;
+
+  /* Pointer to data for applications.  */
+
+  PTR userdata;
+
+  /* If the SEC_IN_MEMORY flag is set, this points to the actual
+     contents.  */
+  unsigned char *contents;
+
+  /* Attached line number information.  */
+
+  alent *lineno;
+
+  /* Number of line number records.  */
+
+  unsigned int lineno_count;
+
+  /* Entity size for merging purposes.  */
+
+  unsigned int entsize;
+
+  /* Optional information about a COMDAT entry; NULL if not COMDAT.  */
+
+  struct bfd_comdat_info *comdat;
+
+  /* When a section is being output, this value changes as more
+     linenumbers are written out.  */
+
+  file_ptr moving_line_filepos;
+
+  /* What the section number is in the target world.  */
+
+  int target_index;
+
+  PTR used_by_bfd;
+
+  /* If this is a constructor section then here is a list of the
+     relocations created to relocate items within it.  */
+
+  struct relent_chain *constructor_chain;
+
+  /* The BFD which owns the section.  */
+
+  bfd *owner;
+
+  /* A symbol which points at this section only */
+  struct symbol_cache_entry *symbol;
+  struct symbol_cache_entry **symbol_ptr_ptr;
+
+  struct bfd_link_order *link_order_head;
+  struct bfd_link_order *link_order_tail;
+} asection ;
+
+/* These sections are global, and are managed by BFD.  The application
+   and target back end are not permitted to change the values in
+   these sections.  New code should use the section_ptr macros rather
+   than referring directly to the const sections.  The const sections
+   may eventually vanish.  */
+#define BFD_ABS_SECTION_NAME "*ABS*"
+#define BFD_UND_SECTION_NAME "*UND*"
+#define BFD_COM_SECTION_NAME "*COM*"
+#define BFD_IND_SECTION_NAME "*IND*"
+
+/* the absolute section */
+extern const asection bfd_abs_section;
+#define bfd_abs_section_ptr ((asection *) &bfd_abs_section)
+#define bfd_is_abs_section(sec) ((sec) == bfd_abs_section_ptr)
+/* Pointer to the undefined section */
+extern const asection bfd_und_section;
+#define bfd_und_section_ptr ((asection *) &bfd_und_section)
+#define bfd_is_und_section(sec) ((sec) == bfd_und_section_ptr)
+/* Pointer to the common section */
+extern const asection bfd_com_section;
+#define bfd_com_section_ptr ((asection *) &bfd_com_section)
+/* Pointer to the indirect section */
+extern const asection bfd_ind_section;
+#define bfd_ind_section_ptr ((asection *) &bfd_ind_section)
+#define bfd_is_ind_section(sec) ((sec) == bfd_ind_section_ptr)
+
+extern const struct symbol_cache_entry * const bfd_abs_symbol;
+extern const struct symbol_cache_entry * const bfd_com_symbol;
+extern const struct symbol_cache_entry * const bfd_und_symbol;
+extern const struct symbol_cache_entry * const bfd_ind_symbol;
+#define bfd_get_section_size_before_reloc(section) \
+     ((section)->reloc_done ? (abort (), (bfd_size_type) 1) \
+                            : (section)->_raw_size)
+#define bfd_get_section_size_after_reloc(section) \
+     ((section)->reloc_done ? (section)->_cooked_size \
+                            : (abort (), (bfd_size_type) 1))
+asection *
+bfd_get_section_by_name PARAMS ((bfd *abfd, const char *name));
+
+char *
+bfd_get_unique_section_name PARAMS ((bfd *abfd,
+    const char *templat,
+    int *count));
+
+asection *
+bfd_make_section_old_way PARAMS ((bfd *abfd, const char *name));
+
+asection *
+bfd_make_section_anyway PARAMS ((bfd *abfd, const char *name));
+
+asection *
+bfd_make_section PARAMS ((bfd *, const char *name));
+
+boolean
+bfd_set_section_flags PARAMS ((bfd *abfd, asection *sec, flagword flags));
+
+void
+bfd_map_over_sections PARAMS ((bfd *abfd,
+    void (*func) (bfd *abfd,
+    asection *sect,
+    PTR obj),
+    PTR obj));
+
+boolean
+bfd_set_section_size PARAMS ((bfd *abfd, asection *sec, bfd_size_type val));
+
+boolean
+bfd_set_section_contents PARAMS ((bfd *abfd, asection *section,
+    PTR data, file_ptr offset,
+    bfd_size_type count));
+
+boolean
+bfd_get_section_contents PARAMS ((bfd *abfd, asection *section,
+    PTR location, file_ptr offset,
+    bfd_size_type count));
+
+boolean
+bfd_copy_private_section_data PARAMS ((bfd *ibfd, asection *isec,
+    bfd *obfd, asection *osec));
+
+#define bfd_copy_private_section_data(ibfd, isection, obfd, osection) \
+     BFD_SEND (obfd, _bfd_copy_private_section_data, \
+               (ibfd, isection, obfd, osection))
+void
+_bfd_strip_section_from_output PARAMS ((struct bfd_link_info *info, asection *section));
+
+enum bfd_architecture
+{
+  bfd_arch_unknown,   /* File arch not known */
+  bfd_arch_obscure,   /* Arch known, not one of these */
+  bfd_arch_m68k,      /* Motorola 68xxx */
+#define bfd_mach_m68000 1
+#define bfd_mach_m68008 2
+#define bfd_mach_m68010 3
+#define bfd_mach_m68020 4
+#define bfd_mach_m68030 5
+#define bfd_mach_m68040 6
+#define bfd_mach_m68060 7
+#define bfd_mach_cpu32  8
+#define bfd_mach_mcf5200  9
+#define bfd_mach_mcf5206e 10
+#define bfd_mach_mcf5307  11
+#define bfd_mach_mcf5407  12
+  bfd_arch_vax,       /* DEC Vax */
+  bfd_arch_i960,      /* Intel 960 */
+    /* The order of the following is important.
+       lower number indicates a machine type that
+       only accepts a subset of the instructions
+       available to machines with higher numbers.
+       The exception is the "ca", which is
+       incompatible with all other machines except
+       "core". */
+
+#define bfd_mach_i960_core      1
+#define bfd_mach_i960_ka_sa     2
+#define bfd_mach_i960_kb_sb     3
+#define bfd_mach_i960_mc        4
+#define bfd_mach_i960_xa        5
+#define bfd_mach_i960_ca        6
+#define bfd_mach_i960_jx        7
+#define bfd_mach_i960_hx        8
+
+  bfd_arch_a29k,      /* AMD 29000 */
+  bfd_arch_sparc,     /* SPARC */
+#define bfd_mach_sparc                 1
+/* The difference between v8plus and v9 is that v9 is a true 64 bit env.  */
+#define bfd_mach_sparc_sparclet        2
+#define bfd_mach_sparc_sparclite       3
+#define bfd_mach_sparc_v8plus          4
+#define bfd_mach_sparc_v8plusa         5 /* with ultrasparc add'ns */
+#define bfd_mach_sparc_sparclite_le    6
+#define bfd_mach_sparc_v9              7
+#define bfd_mach_sparc_v9a             8 /* with ultrasparc add'ns */
+#define bfd_mach_sparc_v8plusb         9 /* with cheetah add'ns */
+#define bfd_mach_sparc_v9b             10 /* with cheetah add'ns */
+/* Nonzero if MACH has the v9 instruction set.  */
+#define bfd_mach_sparc_v9_p(mach) \
+  ((mach) >= bfd_mach_sparc_v8plus && (mach) <= bfd_mach_sparc_v9b \
+   && (mach) != bfd_mach_sparc_sparclite_le)
+  bfd_arch_mips,      /* MIPS Rxxxx */
+#define bfd_mach_mips3000              3000
+#define bfd_mach_mips3900              3900
+#define bfd_mach_mips4000              4000
+#define bfd_mach_mips4010              4010
+#define bfd_mach_mips4100              4100
+#define bfd_mach_mips4111              4111
+#define bfd_mach_mips4300              4300
+#define bfd_mach_mips4400              4400
+#define bfd_mach_mips4600              4600
+#define bfd_mach_mips4650              4650
+#define bfd_mach_mips5000              5000
+#define bfd_mach_mips6000              6000
+#define bfd_mach_mips8000              8000
+#define bfd_mach_mips10000             10000
+#define bfd_mach_mips12000             12000
+#define bfd_mach_mips16                16
+#define bfd_mach_mips5                 5
+#define bfd_mach_mips_sb1              12310201 /* octal 'SB', 01 */
+#define bfd_mach_mipsisa32             32
+#define bfd_mach_mipsisa64             64
+  bfd_arch_i386,      /* Intel 386 */
+#define bfd_mach_i386_i386 0
+#define bfd_mach_i386_i8086 1
+#define bfd_mach_i386_i386_intel_syntax 2
+#define bfd_mach_x86_64 3
+#define bfd_mach_x86_64_intel_syntax 4
+  bfd_arch_we32k,     /* AT&T WE32xxx */
+  bfd_arch_tahoe,     /* CCI/Harris Tahoe */
+  bfd_arch_i860,      /* Intel 860 */
+  bfd_arch_i370,      /* IBM 360/370 Mainframes */
+  bfd_arch_romp,      /* IBM ROMP PC/RT */
+  bfd_arch_alliant,   /* Alliant */
+  bfd_arch_convex,    /* Convex */
+  bfd_arch_m88k,      /* Motorola 88xxx */
+  bfd_arch_pyramid,   /* Pyramid Technology */
+  bfd_arch_h8300,     /* Hitachi H8/300 */
+#define bfd_mach_h8300   1
+#define bfd_mach_h8300h  2
+#define bfd_mach_h8300s  3
+  bfd_arch_pdp11,     /* DEC PDP-11 */
+  bfd_arch_powerpc,   /* PowerPC */
+#define bfd_mach_ppc           0
+#define bfd_mach_ppc_403       403
+#define bfd_mach_ppc_403gc     4030
+#define bfd_mach_ppc_505       505
+#define bfd_mach_ppc_601       601
+#define bfd_mach_ppc_602       602
+#define bfd_mach_ppc_603       603
+#define bfd_mach_ppc_ec603e    6031
+#define bfd_mach_ppc_604       604
+#define bfd_mach_ppc_620       620
+#define bfd_mach_ppc_630       630
+#define bfd_mach_ppc_750       750
+#define bfd_mach_ppc_860       860
+#define bfd_mach_ppc_a35       35
+#define bfd_mach_ppc_rs64ii    642
+#define bfd_mach_ppc_rs64iii   643
+#define bfd_mach_ppc_7400      7400
+  bfd_arch_rs6000,    /* IBM RS/6000 */
+#define bfd_mach_rs6k          0
+#define bfd_mach_rs6k_rs1      6001
+#define bfd_mach_rs6k_rsc      6003
+#define bfd_mach_rs6k_rs2      6002
+  bfd_arch_hppa,      /* HP PA RISC */
+  bfd_arch_d10v,      /* Mitsubishi D10V */
+#define bfd_mach_d10v          0
+#define bfd_mach_d10v_ts2      2
+#define bfd_mach_d10v_ts3      3
+  bfd_arch_d30v,      /* Mitsubishi D30V */
+  bfd_arch_m68hc11,   /* Motorola 68HC11 */
+  bfd_arch_m68hc12,   /* Motorola 68HC12 */
+  bfd_arch_z8k,       /* Zilog Z8000 */
+#define bfd_mach_z8001         1
+#define bfd_mach_z8002         2
+  bfd_arch_h8500,     /* Hitachi H8/500 */
+  bfd_arch_sh,        /* Hitachi SH */
+#define bfd_mach_sh            0
+#define bfd_mach_sh2        0x20
+#define bfd_mach_sh_dsp     0x2d
+#define bfd_mach_sh3        0x30
+#define bfd_mach_sh3_dsp    0x3d
+#define bfd_mach_sh3e       0x3e
+#define bfd_mach_sh4        0x40
+  bfd_arch_alpha,     /* Dec Alpha */
+#define bfd_mach_alpha_ev4  0x10
+#define bfd_mach_alpha_ev5  0x20
+#define bfd_mach_alpha_ev6  0x30
+  bfd_arch_arm,       /* Advanced Risc Machines ARM */
+#define bfd_mach_arm_2         1
+#define bfd_mach_arm_2a        2
+#define bfd_mach_arm_3         3
+#define bfd_mach_arm_3M        4
+#define bfd_mach_arm_4         5
+#define bfd_mach_arm_4T        6
+#define bfd_mach_arm_5         7
+#define bfd_mach_arm_5T        8
+#define bfd_mach_arm_5TE       9
+#define bfd_mach_arm_XScale    10
+  bfd_arch_ns32k,     /* National Semiconductors ns32000 */
+  bfd_arch_w65,       /* WDC 65816 */
+  bfd_arch_tic30,     /* Texas Instruments TMS320C30 */
+  bfd_arch_tic54x,    /* Texas Instruments TMS320C54X */
+  bfd_arch_tic80,     /* TI TMS320c80 (MVP) */
+  bfd_arch_v850,      /* NEC V850 */
+#define bfd_mach_v850          0
+#define bfd_mach_v850e         'E'
+#define bfd_mach_v850ea        'A'
+  bfd_arch_arc,       /* ARC Cores */
+#define bfd_mach_arc_5         0
+#define bfd_mach_arc_6         1
+#define bfd_mach_arc_7         2
+#define bfd_mach_arc_8         3
+  bfd_arch_m32r,      /* Mitsubishi M32R/D */
+#define bfd_mach_m32r          0 /* backwards compatibility */
+#define bfd_mach_m32rx         'x'
+  bfd_arch_mn10200,   /* Matsushita MN10200 */
+  bfd_arch_mn10300,   /* Matsushita MN10300 */
+#define bfd_mach_mn10300               300
+#define bfd_mach_am33          330
+  bfd_arch_fr30,
+#define bfd_mach_fr30          0x46523330
+  bfd_arch_mcore,
+  bfd_arch_ia64,      /* HP/Intel ia64 */
+#define bfd_mach_ia64_elf64    0
+#define bfd_mach_ia64_elf32    1
+  bfd_arch_pj,
+  bfd_arch_avr,       /* Atmel AVR microcontrollers */
+#define bfd_mach_avr1          1
+#define bfd_mach_avr2          2
+#define bfd_mach_avr3          3
+#define bfd_mach_avr4          4
+#define bfd_mach_avr5          5
+  bfd_arch_cris,      /* Axis CRIS */
+  bfd_arch_s390,      /* IBM s390 */
+#define bfd_mach_s390_esa      0
+#define bfd_mach_s390_esame    1
+  bfd_arch_openrisc,  /* OpenRISC */
+  bfd_arch_last
+  };
+
+typedef struct bfd_arch_info
+{
+  int bits_per_word;
+  int bits_per_address;
+  int bits_per_byte;
+  enum bfd_architecture arch;
+  unsigned long mach;
+  const char *arch_name;
+  const char *printable_name;
+  unsigned int section_align_power;
+  /* True if this is the default machine for the architecture.  */
+  boolean the_default;
+  const struct bfd_arch_info * (*compatible)
+       PARAMS ((const struct bfd_arch_info *a,
+                const struct bfd_arch_info *b));
+
+  boolean (*scan) PARAMS ((const struct bfd_arch_info *, const char *));
+
+  const struct bfd_arch_info *next;
+} bfd_arch_info_type;
+const char *
+bfd_printable_name PARAMS ((bfd *abfd));
+
+const bfd_arch_info_type *
+bfd_scan_arch PARAMS ((const char *string));
+
+const char **
+bfd_arch_list PARAMS ((void));
+
+const bfd_arch_info_type *
+bfd_arch_get_compatible PARAMS ((
+    const bfd *abfd,
+    const bfd *bbfd));
+
+void
+bfd_set_arch_info PARAMS ((bfd *abfd, const bfd_arch_info_type *arg));
+
+enum bfd_architecture
+bfd_get_arch PARAMS ((bfd *abfd));
+
+unsigned long
+bfd_get_mach PARAMS ((bfd *abfd));
+
+unsigned int
+bfd_arch_bits_per_byte PARAMS ((bfd *abfd));
+
+unsigned int
+bfd_arch_bits_per_address PARAMS ((bfd *abfd));
+
+const bfd_arch_info_type *
+bfd_get_arch_info PARAMS ((bfd *abfd));
+
+const bfd_arch_info_type *
+bfd_lookup_arch PARAMS ((enum bfd_architecture
+    arch,
+    unsigned long machine));
+
+const char *
+bfd_printable_arch_mach PARAMS ((enum bfd_architecture arch, unsigned long machine));
+
+unsigned int
+bfd_octets_per_byte PARAMS ((bfd *abfd));
+
+unsigned int
+bfd_arch_mach_octets_per_byte PARAMS ((enum bfd_architecture arch,
+    unsigned long machine));
+
+typedef enum bfd_reloc_status
+{
+  /* No errors detected */
+  bfd_reloc_ok,
+
+  /* The relocation was performed, but there was an overflow. */
+  bfd_reloc_overflow,
+
+  /* The address to relocate was not within the section supplied. */
+  bfd_reloc_outofrange,
+
+  /* Used by special functions */
+  bfd_reloc_continue,
+
+  /* Unsupported relocation size requested. */
+  bfd_reloc_notsupported,
+
+  /* Unused */
+  bfd_reloc_other,
+
+  /* The symbol to relocate against was undefined. */
+  bfd_reloc_undefined,
+
+  /* The relocation was performed, but may not be ok - presently
+     generated only when linking i960 coff files with i960 b.out
+     symbols.  If this type is returned, the error_message argument
+     to bfd_perform_relocation will be set.  */
+  bfd_reloc_dangerous
+ }
+ bfd_reloc_status_type;
+
+
+typedef struct reloc_cache_entry
+{
+  /* A pointer into the canonical table of pointers  */
+  struct symbol_cache_entry **sym_ptr_ptr;
+
+  /* offset in section */
+  bfd_size_type address;
+
+  /* addend for relocation value */
+  bfd_vma addend;
+
+  /* Pointer to how to perform the required relocation */
+  reloc_howto_type *howto;
+
+} arelent;
+enum complain_overflow
+{
+  /* Do not complain on overflow. */
+  complain_overflow_dont,
+
+  /* Complain if the bitfield overflows, whether it is considered
+     as signed or unsigned. */
+  complain_overflow_bitfield,
+
+  /* Complain if the value overflows when considered as signed
+     number. */
+  complain_overflow_signed,
+
+  /* Complain if the value overflows when considered as an
+     unsigned number. */
+  complain_overflow_unsigned
+};
+
+struct reloc_howto_struct
+{
+  /*  The type field has mainly a documentary use - the back end can
+      do what it wants with it, though normally the back end's
+      external idea of what a reloc number is stored
+      in this field.  For example, a PC relative word relocation
+      in a coff environment has the type 023 - because that's
+      what the outside world calls a R_PCRWORD reloc.  */
+  unsigned int type;
+
+  /*  The value the final relocation is shifted right by.  This drops
+      unwanted data from the relocation.  */
+  unsigned int rightshift;
+
+  /*  The size of the item to be relocated.  This is *not* a
+      power-of-two measure.  To get the number of bytes operated
+      on by a type of relocation, use bfd_get_reloc_size.  */
+  int size;
+
+  /*  The number of bits in the item to be relocated.  This is used
+      when doing overflow checking.  */
+  unsigned int bitsize;
+
+  /*  Notes that the relocation is relative to the location in the
+      data section of the addend.  The relocation function will
+      subtract from the relocation value the address of the location
+      being relocated.  */
+  boolean pc_relative;
+
+  /*  The bit position of the reloc value in the destination.
+      The relocated value is left shifted by this amount.  */
+  unsigned int bitpos;
+
+  /* What type of overflow error should be checked for when
+     relocating.  */
+  enum complain_overflow complain_on_overflow;
+
+  /* If this field is non null, then the supplied function is
+     called rather than the normal function.  This allows really
+     strange relocation methods to be accomodated (e.g., i960 callj
+     instructions).  */
+  bfd_reloc_status_type (*special_function)
+    PARAMS ((bfd *, arelent *, struct symbol_cache_entry *, PTR, asection *,
+             bfd *, char **));
+
+  /* The textual name of the relocation type.  */
+  char *name;
+
+  /* Some formats record a relocation addend in the section contents
+     rather than with the relocation.  For ELF formats this is the
+     distinction between USE_REL and USE_RELA (though the code checks
+     for USE_REL == 1/0).  The value of this field is TRUE if the
+     addend is recorded with the section contents; when performing a
+     partial link (ld -r) the section contents (the data) will be
+     modified.  The value of this field is FALSE if addends are
+     recorded with the relocation (in arelent.addend); when performing
+     a partial link the relocation will be modified.
+     All relocations for all ELF USE_RELA targets should set this field
+     to FALSE (values of TRUE should be looked on with suspicion).
+     However, the converse is not true: not all relocations of all ELF
+     USE_REL targets set this field to TRUE.  Why this is so is peculiar
+     to each particular target.  For relocs that aren't used in partial
+     links (e.g. GOT stuff) it doesn't matter what this is set to.  */
+  boolean partial_inplace;
+
+  /* The src_mask selects which parts of the read in data
+     are to be used in the relocation sum.  E.g., if this was an 8 bit
+     byte of data which we read and relocated, this would be
+     0x000000ff.  When we have relocs which have an addend, such as
+     sun4 extended relocs, the value in the offset part of a
+     relocating field is garbage so we never use it.  In this case
+     the mask would be 0x00000000.  */
+  bfd_vma src_mask;
+
+  /* The dst_mask selects which parts of the instruction are replaced
+     into the instruction.  In most cases src_mask == dst_mask,
+     except in the above special case, where dst_mask would be
+     0x000000ff, and src_mask would be 0x00000000.  */
+  bfd_vma dst_mask;
+
+  /* When some formats create PC relative instructions, they leave
+     the value of the pc of the place being relocated in the offset
+     slot of the instruction, so that a PC relative relocation can
+     be made just by adding in an ordinary offset (e.g., sun3 a.out).
+     Some formats leave the displacement part of an instruction
+     empty (e.g., m88k bcs); this flag signals the fact.  */
+  boolean pcrel_offset;
+};
+#define HOWTO(C, R, S, B, P, BI, O, SF, NAME, INPLACE, MASKSRC, MASKDST, PC) \
+  { (unsigned) C, R, S, B, P, BI, O, SF, NAME, INPLACE, MASKSRC, MASKDST, PC }
+#define NEWHOWTO(FUNCTION, NAME, SIZE, REL, IN) \
+  HOWTO (0, 0, SIZE, 0, REL, 0, complain_overflow_dont, FUNCTION, \
+         NAME, false, 0, 0, IN)
+
+#define EMPTY_HOWTO(C) \
+  HOWTO ((C), 0, 0, 0, false, 0, complain_overflow_dont, NULL, \
+         NULL, false, 0, 0, false)
+
+#define HOWTO_PREPARE(relocation, symbol)               \
+  {                                                     \
+    if (symbol != (asymbol *) NULL)                     \
+      {                                                 \
+        if (bfd_is_com_section (symbol->section))       \
+          {                                             \
+            relocation = 0;                             \
+          }                                             \
+        else                                            \
+          {                                             \
+            relocation = symbol->value;                 \
+          }                                             \
+      }                                                 \
+  }
+unsigned int
+bfd_get_reloc_size PARAMS ((reloc_howto_type *));
+
+typedef struct relent_chain
+{
+  arelent relent;
+  struct relent_chain *next;
+} arelent_chain;
+bfd_reloc_status_type
+bfd_check_overflow PARAMS ((enum complain_overflow how,
+    unsigned int bitsize,
+    unsigned int rightshift,
+    unsigned int addrsize,
+    bfd_vma relocation));
+
+bfd_reloc_status_type
+bfd_perform_relocation PARAMS ((bfd *abfd,
+    arelent *reloc_entry,
+    PTR data,
+    asection *input_section,
+    bfd *output_bfd,
+    char **error_message));
+
+bfd_reloc_status_type
+bfd_install_relocation PARAMS ((bfd *abfd,
+    arelent *reloc_entry,
+    PTR data, bfd_vma data_start,
+    asection *input_section,
+    char **error_message));
+
+enum bfd_reloc_code_real {
+  _dummy_first_bfd_reloc_code_real,
+
+
+/* Basic absolute relocations of N bits. */
+  BFD_RELOC_64,
+  BFD_RELOC_32,
+  BFD_RELOC_26,
+  BFD_RELOC_24,
+  BFD_RELOC_16,
+  BFD_RELOC_14,
+  BFD_RELOC_8,
+
+/* PC-relative relocations.  Sometimes these are relative to the address
+of the relocation itself; sometimes they are relative to the start of
+the section containing the relocation.  It depends on the specific target.
+
+The 24-bit relocation is used in some Intel 960 configurations. */
+  BFD_RELOC_64_PCREL,
+  BFD_RELOC_32_PCREL,
+  BFD_RELOC_24_PCREL,
+  BFD_RELOC_16_PCREL,
+  BFD_RELOC_12_PCREL,
+  BFD_RELOC_8_PCREL,
+
+/* For ELF. */
+  BFD_RELOC_32_GOT_PCREL,
+  BFD_RELOC_16_GOT_PCREL,
+  BFD_RELOC_8_GOT_PCREL,
+  BFD_RELOC_32_GOTOFF,
+  BFD_RELOC_16_GOTOFF,
+  BFD_RELOC_LO16_GOTOFF,
+  BFD_RELOC_HI16_GOTOFF,
+  BFD_RELOC_HI16_S_GOTOFF,
+  BFD_RELOC_8_GOTOFF,
+  BFD_RELOC_64_PLT_PCREL,
+  BFD_RELOC_32_PLT_PCREL,
+  BFD_RELOC_24_PLT_PCREL,
+  BFD_RELOC_16_PLT_PCREL,
+  BFD_RELOC_8_PLT_PCREL,
+  BFD_RELOC_64_PLTOFF,
+  BFD_RELOC_32_PLTOFF,
+  BFD_RELOC_16_PLTOFF,
+  BFD_RELOC_LO16_PLTOFF,
+  BFD_RELOC_HI16_PLTOFF,
+  BFD_RELOC_HI16_S_PLTOFF,
+  BFD_RELOC_8_PLTOFF,
+
+/* Relocations used by 68K ELF. */
+  BFD_RELOC_68K_GLOB_DAT,
+  BFD_RELOC_68K_JMP_SLOT,
+  BFD_RELOC_68K_RELATIVE,
+
+/* Linkage-table relative. */
+  BFD_RELOC_32_BASEREL,
+  BFD_RELOC_16_BASEREL,
+  BFD_RELOC_LO16_BASEREL,
+  BFD_RELOC_HI16_BASEREL,
+  BFD_RELOC_HI16_S_BASEREL,
+  BFD_RELOC_8_BASEREL,
+  BFD_RELOC_RVA,
+
+/* Absolute 8-bit relocation, but used to form an address like 0xFFnn. */
+  BFD_RELOC_8_FFnn,
+
+/* These PC-relative relocations are stored as word displacements --
+i.e., byte displacements shifted right two bits.  The 30-bit word
+displacement (<<32_PCREL_S2>> -- 32 bits, shifted 2) is used on the
+SPARC.  (SPARC tools generally refer to this as <<WDISP30>>.)  The
+signed 16-bit displacement is used on the MIPS, and the 23-bit
+displacement is used on the Alpha. */
+  BFD_RELOC_32_PCREL_S2,
+  BFD_RELOC_16_PCREL_S2,
+  BFD_RELOC_23_PCREL_S2,
+
+/* High 22 bits and low 10 bits of 32-bit value, placed into lower bits of
+the target word.  These are used on the SPARC. */
+  BFD_RELOC_HI22,
+  BFD_RELOC_LO10,
+
+/* For systems that allocate a Global Pointer register, these are
+displacements off that register.  These relocation types are
+handled specially, because the value the register will have is
+decided relatively late. */
+  BFD_RELOC_GPREL16,
+  BFD_RELOC_GPREL32,
+
+/* Reloc types used for i960/b.out. */
+  BFD_RELOC_I960_CALLJ,
+
+/* SPARC ELF relocations.  There is probably some overlap with other
+relocation types already defined. */
+  BFD_RELOC_NONE,
+  BFD_RELOC_SPARC_WDISP22,
+  BFD_RELOC_SPARC22,
+  BFD_RELOC_SPARC13,
+  BFD_RELOC_SPARC_GOT10,
+  BFD_RELOC_SPARC_GOT13,
+  BFD_RELOC_SPARC_GOT22,
+  BFD_RELOC_SPARC_PC10,
+  BFD_RELOC_SPARC_PC22,
+  BFD_RELOC_SPARC_WPLT30,
+  BFD_RELOC_SPARC_COPY,
+  BFD_RELOC_SPARC_GLOB_DAT,
+  BFD_RELOC_SPARC_JMP_SLOT,
+  BFD_RELOC_SPARC_RELATIVE,
+  BFD_RELOC_SPARC_UA16,
+  BFD_RELOC_SPARC_UA32,
+  BFD_RELOC_SPARC_UA64,
+
+/* I think these are specific to SPARC a.out (e.g., Sun 4). */
+  BFD_RELOC_SPARC_BASE13,
+  BFD_RELOC_SPARC_BASE22,
+
+/* SPARC64 relocations */
+#define BFD_RELOC_SPARC_64 BFD_RELOC_64
+  BFD_RELOC_SPARC_10,
+  BFD_RELOC_SPARC_11,
+  BFD_RELOC_SPARC_OLO10,
+  BFD_RELOC_SPARC_HH22,
+  BFD_RELOC_SPARC_HM10,
+  BFD_RELOC_SPARC_LM22,
+  BFD_RELOC_SPARC_PC_HH22,
+  BFD_RELOC_SPARC_PC_HM10,
+  BFD_RELOC_SPARC_PC_LM22,
+  BFD_RELOC_SPARC_WDISP16,
+  BFD_RELOC_SPARC_WDISP19,
+  BFD_RELOC_SPARC_7,
+  BFD_RELOC_SPARC_6,
+  BFD_RELOC_SPARC_5,
+#define BFD_RELOC_SPARC_DISP64 BFD_RELOC_64_PCREL
+  BFD_RELOC_SPARC_PLT64,
+  BFD_RELOC_SPARC_HIX22,
+  BFD_RELOC_SPARC_LOX10,
+  BFD_RELOC_SPARC_H44,
+  BFD_RELOC_SPARC_M44,
+  BFD_RELOC_SPARC_L44,
+  BFD_RELOC_SPARC_REGISTER,
+
+/* SPARC little endian relocation */
+  BFD_RELOC_SPARC_REV32,
+
+/* Alpha ECOFF and ELF relocations.  Some of these treat the symbol or
+"addend" in some special way.
+For GPDISP_HI16 ("gpdisp") relocations, the symbol is ignored when
+writing; when reading, it will be the absolute section symbol.  The
+addend is the displacement in bytes of the "lda" instruction from
+the "ldah" instruction (which is at the address of this reloc). */
+  BFD_RELOC_ALPHA_GPDISP_HI16,
+
+/* For GPDISP_LO16 ("ignore") relocations, the symbol is handled as
+with GPDISP_HI16 relocs.  The addend is ignored when writing the
+relocations out, and is filled in with the file's GP value on
+reading, for convenience. */
+  BFD_RELOC_ALPHA_GPDISP_LO16,
+
+/* The ELF GPDISP relocation is exactly the same as the GPDISP_HI16
+relocation except that there is no accompanying GPDISP_LO16
+relocation. */
+  BFD_RELOC_ALPHA_GPDISP,
+
+/* The Alpha LITERAL/LITUSE relocs are produced by a symbol reference;
+the assembler turns it into a LDQ instruction to load the address of
+the symbol, and then fills in a register in the real instruction.
+
+The LITERAL reloc, at the LDQ instruction, refers to the .lita
+section symbol.  The addend is ignored when writing, but is filled
+in with the file's GP value on reading, for convenience, as with the
+GPDISP_LO16 reloc.
+
+The ELF_LITERAL reloc is somewhere between 16_GOTOFF and GPDISP_LO16.
+It should refer to the symbol to be referenced, as with 16_GOTOFF,
+but it generates output not based on the position within the .got
+section, but relative to the GP value chosen for the file during the
+final link stage.
+
+The LITUSE reloc, on the instruction using the loaded address, gives
+information to the linker that it might be able to use to optimize
+away some literal section references.  The symbol is ignored (read
+as the absolute section symbol), and the "addend" indicates the type
+of instruction using the register:
+1 - "memory" fmt insn
+2 - byte-manipulation (byte offset reg)
+3 - jsr (target of branch) */
+  BFD_RELOC_ALPHA_LITERAL,
+  BFD_RELOC_ALPHA_ELF_LITERAL,
+  BFD_RELOC_ALPHA_LITUSE,
+
+/* The HINT relocation indicates a value that should be filled into the
+"hint" field of a jmp/jsr/ret instruction, for possible branch-
+prediction logic which may be provided on some processors. */
+  BFD_RELOC_ALPHA_HINT,
+
+/* The LINKAGE relocation outputs a linkage pair in the object file,
+which is filled by the linker. */
+  BFD_RELOC_ALPHA_LINKAGE,
+
+/* The CODEADDR relocation outputs a STO_CA in the object file,
+which is filled by the linker. */
+  BFD_RELOC_ALPHA_CODEADDR,
+
+/* The GPREL_HI/LO relocations together form a 32-bit offset from the
+GP register. */
+  BFD_RELOC_ALPHA_GPREL_HI16,
+  BFD_RELOC_ALPHA_GPREL_LO16,
+
+/* Bits 27..2 of the relocation address shifted right 2 bits;
+simple reloc otherwise. */
+  BFD_RELOC_MIPS_JMP,
+
+/* The MIPS16 jump instruction. */
+  BFD_RELOC_MIPS16_JMP,
+
+/* MIPS16 GP relative reloc. */
+  BFD_RELOC_MIPS16_GPREL,
+
+/* High 16 bits of 32-bit value; simple reloc. */
+  BFD_RELOC_HI16,
+
+/* High 16 bits of 32-bit value but the low 16 bits will be sign
+extended and added to form the final result.  If the low 16
+bits form a negative number, we need to add one to the high value
+to compensate for the borrow when the low bits are added. */
+  BFD_RELOC_HI16_S,
+
+/* Low 16 bits. */
+  BFD_RELOC_LO16,
+
+/* Like BFD_RELOC_HI16_S, but PC relative. */
+  BFD_RELOC_PCREL_HI16_S,
+
+/* Like BFD_RELOC_LO16, but PC relative. */
+  BFD_RELOC_PCREL_LO16,
+
+/* Relocation relative to the global pointer. */
+#define BFD_RELOC_MIPS_GPREL BFD_RELOC_GPREL16
+
+/* Relocation against a MIPS literal section. */
+  BFD_RELOC_MIPS_LITERAL,
+
+/* MIPS ELF relocations. */
+  BFD_RELOC_MIPS_GOT16,
+  BFD_RELOC_MIPS_CALL16,
+#define BFD_RELOC_MIPS_GPREL32 BFD_RELOC_GPREL32
+  BFD_RELOC_MIPS_GOT_HI16,
+  BFD_RELOC_MIPS_GOT_LO16,
+  BFD_RELOC_MIPS_CALL_HI16,
+  BFD_RELOC_MIPS_CALL_LO16,
+  BFD_RELOC_MIPS_SUB,
+  BFD_RELOC_MIPS_GOT_PAGE,
+  BFD_RELOC_MIPS_GOT_OFST,
+  BFD_RELOC_MIPS_GOT_DISP,
+  BFD_RELOC_MIPS_SHIFT5,
+  BFD_RELOC_MIPS_SHIFT6,
+  BFD_RELOC_MIPS_INSERT_A,
+  BFD_RELOC_MIPS_INSERT_B,
+  BFD_RELOC_MIPS_DELETE,
+  BFD_RELOC_MIPS_HIGHEST,
+  BFD_RELOC_MIPS_HIGHER,
+  BFD_RELOC_MIPS_SCN_DISP,
+  BFD_RELOC_MIPS_REL16,
+  BFD_RELOC_MIPS_RELGOT,
+  BFD_RELOC_MIPS_JALR,
+
+
+/* i386/elf relocations */
+  BFD_RELOC_386_GOT32,
+  BFD_RELOC_386_PLT32,
+  BFD_RELOC_386_COPY,
+  BFD_RELOC_386_GLOB_DAT,
+  BFD_RELOC_386_JUMP_SLOT,
+  BFD_RELOC_386_RELATIVE,
+  BFD_RELOC_386_GOTOFF,
+  BFD_RELOC_386_GOTPC,
+
+/* x86-64/elf relocations */
+  BFD_RELOC_X86_64_GOT32,
+  BFD_RELOC_X86_64_PLT32,
+  BFD_RELOC_X86_64_COPY,
+  BFD_RELOC_X86_64_GLOB_DAT,
+  BFD_RELOC_X86_64_JUMP_SLOT,
+  BFD_RELOC_X86_64_RELATIVE,
+  BFD_RELOC_X86_64_GOTPCREL,
+  BFD_RELOC_X86_64_32S,
+
+/* ns32k relocations */
+  BFD_RELOC_NS32K_IMM_8,
+  BFD_RELOC_NS32K_IMM_16,
+  BFD_RELOC_NS32K_IMM_32,
+  BFD_RELOC_NS32K_IMM_8_PCREL,
+  BFD_RELOC_NS32K_IMM_16_PCREL,
+  BFD_RELOC_NS32K_IMM_32_PCREL,
+  BFD_RELOC_NS32K_DISP_8,
+  BFD_RELOC_NS32K_DISP_16,
+  BFD_RELOC_NS32K_DISP_32,
+  BFD_RELOC_NS32K_DISP_8_PCREL,
+  BFD_RELOC_NS32K_DISP_16_PCREL,
+  BFD_RELOC_NS32K_DISP_32_PCREL,
+
+/* PDP11 relocations */
+  BFD_RELOC_PDP11_DISP_8_PCREL,
+  BFD_RELOC_PDP11_DISP_6_PCREL,
+
+/* Picojava relocs.  Not all of these appear in object files. */
+  BFD_RELOC_PJ_CODE_HI16,
+  BFD_RELOC_PJ_CODE_LO16,
+  BFD_RELOC_PJ_CODE_DIR16,
+  BFD_RELOC_PJ_CODE_DIR32,
+  BFD_RELOC_PJ_CODE_REL16,
+  BFD_RELOC_PJ_CODE_REL32,
+
+/* Power(rs6000) and PowerPC relocations. */
+  BFD_RELOC_PPC_B26,
+  BFD_RELOC_PPC_BA26,
+  BFD_RELOC_PPC_TOC16,
+  BFD_RELOC_PPC_B16,
+  BFD_RELOC_PPC_B16_BRTAKEN,
+  BFD_RELOC_PPC_B16_BRNTAKEN,
+  BFD_RELOC_PPC_BA16,
+  BFD_RELOC_PPC_BA16_BRTAKEN,
+  BFD_RELOC_PPC_BA16_BRNTAKEN,
+  BFD_RELOC_PPC_COPY,
+  BFD_RELOC_PPC_GLOB_DAT,
+  BFD_RELOC_PPC_JMP_SLOT,
+  BFD_RELOC_PPC_RELATIVE,
+  BFD_RELOC_PPC_LOCAL24PC,
+  BFD_RELOC_PPC_EMB_NADDR32,
+  BFD_RELOC_PPC_EMB_NADDR16,
+  BFD_RELOC_PPC_EMB_NADDR16_LO,
+  BFD_RELOC_PPC_EMB_NADDR16_HI,
+  BFD_RELOC_PPC_EMB_NADDR16_HA,
+  BFD_RELOC_PPC_EMB_SDAI16,
+  BFD_RELOC_PPC_EMB_SDA2I16,
+  BFD_RELOC_PPC_EMB_SDA2REL,
+  BFD_RELOC_PPC_EMB_SDA21,
+  BFD_RELOC_PPC_EMB_MRKREF,
+  BFD_RELOC_PPC_EMB_RELSEC16,
+  BFD_RELOC_PPC_EMB_RELST_LO,
+  BFD_RELOC_PPC_EMB_RELST_HI,
+  BFD_RELOC_PPC_EMB_RELST_HA,
+  BFD_RELOC_PPC_EMB_BIT_FLD,
+  BFD_RELOC_PPC_EMB_RELSDA,
+  BFD_RELOC_PPC64_HIGHER,
+  BFD_RELOC_PPC64_HIGHER_S,
+  BFD_RELOC_PPC64_HIGHEST,
+  BFD_RELOC_PPC64_HIGHEST_S,
+  BFD_RELOC_PPC64_TOC16_LO,
+  BFD_RELOC_PPC64_TOC16_HI,
+  BFD_RELOC_PPC64_TOC16_HA,
+  BFD_RELOC_PPC64_TOC,
+  BFD_RELOC_PPC64_PLTGOT16,
+  BFD_RELOC_PPC64_PLTGOT16_LO,
+  BFD_RELOC_PPC64_PLTGOT16_HI,
+  BFD_RELOC_PPC64_PLTGOT16_HA,
+  BFD_RELOC_PPC64_ADDR16_DS,
+  BFD_RELOC_PPC64_ADDR16_LO_DS,
+  BFD_RELOC_PPC64_GOT16_DS,
+  BFD_RELOC_PPC64_GOT16_LO_DS,
+  BFD_RELOC_PPC64_PLT16_LO_DS,
+  BFD_RELOC_PPC64_SECTOFF_DS,
+  BFD_RELOC_PPC64_SECTOFF_LO_DS,
+  BFD_RELOC_PPC64_TOC16_DS,
+  BFD_RELOC_PPC64_TOC16_LO_DS,
+  BFD_RELOC_PPC64_PLTGOT16_DS,
+  BFD_RELOC_PPC64_PLTGOT16_LO_DS,
+
+/* IBM 370/390 relocations */
+  BFD_RELOC_I370_D12,
+
+/* The type of reloc used to build a contructor table - at the moment
+probably a 32 bit wide absolute relocation, but the target can choose.
+It generally does map to one of the other relocation types. */
+  BFD_RELOC_CTOR,
+
+/* ARM 26 bit pc-relative branch.  The lowest two bits must be zero and are
+not stored in the instruction. */
+  BFD_RELOC_ARM_PCREL_BRANCH,
+
+/* ARM 26 bit pc-relative branch.  The lowest bit must be zero and is
+not stored in the instruction.  The 2nd lowest bit comes from a 1 bit
+field in the instruction. */
+  BFD_RELOC_ARM_PCREL_BLX,
+
+/* Thumb 22 bit pc-relative branch.  The lowest bit must be zero and is
+not stored in the instruction.  The 2nd lowest bit comes from a 1 bit
+field in the instruction. */
+  BFD_RELOC_THUMB_PCREL_BLX,
+
+/* These relocs are only used within the ARM assembler.  They are not
+(at present) written to any object files. */
+  BFD_RELOC_ARM_IMMEDIATE,
+  BFD_RELOC_ARM_ADRL_IMMEDIATE,
+  BFD_RELOC_ARM_OFFSET_IMM,
+  BFD_RELOC_ARM_SHIFT_IMM,
+  BFD_RELOC_ARM_SWI,
+  BFD_RELOC_ARM_MULTI,
+  BFD_RELOC_ARM_CP_OFF_IMM,
+  BFD_RELOC_ARM_ADR_IMM,
+  BFD_RELOC_ARM_LDR_IMM,
+  BFD_RELOC_ARM_LITERAL,
+  BFD_RELOC_ARM_IN_POOL,
+  BFD_RELOC_ARM_OFFSET_IMM8,
+  BFD_RELOC_ARM_HWLITERAL,
+  BFD_RELOC_ARM_THUMB_ADD,
+  BFD_RELOC_ARM_THUMB_IMM,
+  BFD_RELOC_ARM_THUMB_SHIFT,
+  BFD_RELOC_ARM_THUMB_OFFSET,
+  BFD_RELOC_ARM_GOT12,
+  BFD_RELOC_ARM_GOT32,
+  BFD_RELOC_ARM_JUMP_SLOT,
+  BFD_RELOC_ARM_COPY,
+  BFD_RELOC_ARM_GLOB_DAT,
+  BFD_RELOC_ARM_PLT32,
+  BFD_RELOC_ARM_RELATIVE,
+  BFD_RELOC_ARM_GOTOFF,
+  BFD_RELOC_ARM_GOTPC,
+
+/* Hitachi SH relocs.  Not all of these appear in object files. */
+  BFD_RELOC_SH_PCDISP8BY2,
+  BFD_RELOC_SH_PCDISP12BY2,
+  BFD_RELOC_SH_IMM4,
+  BFD_RELOC_SH_IMM4BY2,
+  BFD_RELOC_SH_IMM4BY4,
+  BFD_RELOC_SH_IMM8,
+  BFD_RELOC_SH_IMM8BY2,
+  BFD_RELOC_SH_IMM8BY4,
+  BFD_RELOC_SH_PCRELIMM8BY2,
+  BFD_RELOC_SH_PCRELIMM8BY4,
+  BFD_RELOC_SH_SWITCH16,
+  BFD_RELOC_SH_SWITCH32,
+  BFD_RELOC_SH_USES,
+  BFD_RELOC_SH_COUNT,
+  BFD_RELOC_SH_ALIGN,
+  BFD_RELOC_SH_CODE,
+  BFD_RELOC_SH_DATA,
+  BFD_RELOC_SH_LABEL,
+  BFD_RELOC_SH_LOOP_START,
+  BFD_RELOC_SH_LOOP_END,
+  BFD_RELOC_SH_COPY,
+  BFD_RELOC_SH_GLOB_DAT,
+  BFD_RELOC_SH_JMP_SLOT,
+  BFD_RELOC_SH_RELATIVE,
+  BFD_RELOC_SH_GOTPC,
+
+/* Thumb 23-, 12- and 9-bit pc-relative branches.  The lowest bit must
+be zero and is not stored in the instruction. */
+  BFD_RELOC_THUMB_PCREL_BRANCH9,
+  BFD_RELOC_THUMB_PCREL_BRANCH12,
+  BFD_RELOC_THUMB_PCREL_BRANCH23,
+
+/* ARC Cores relocs.
+ARC 22 bit pc-relative branch.  The lowest two bits must be zero and are
+not stored in the instruction.  The high 20 bits are installed in bits 26
+through 7 of the instruction. */
+  BFD_RELOC_ARC_B22_PCREL,
+
+/* ARC 26 bit absolute branch.  The lowest two bits must be zero and are not
+stored in the instruction.  The high 24 bits are installed in bits 23
+through 0. */
+  BFD_RELOC_ARC_B26,
+
+/* Mitsubishi D10V relocs.
+This is a 10-bit reloc with the right 2 bits
+assumed to be 0. */
+  BFD_RELOC_D10V_10_PCREL_R,
+
+/* Mitsubishi D10V relocs.
+This is a 10-bit reloc with the right 2 bits
+assumed to be 0.  This is the same as the previous reloc
+except it is in the left container, i.e.,
+shifted left 15 bits. */
+  BFD_RELOC_D10V_10_PCREL_L,
+
+/* This is an 18-bit reloc with the right 2 bits
+assumed to be 0. */
+  BFD_RELOC_D10V_18,
+
+/* This is an 18-bit reloc with the right 2 bits
+assumed to be 0. */
+  BFD_RELOC_D10V_18_PCREL,
+
+/* Mitsubishi D30V relocs.
+This is a 6-bit absolute reloc. */
+  BFD_RELOC_D30V_6,
+
+/* This is a 6-bit pc-relative reloc with
+the right 3 bits assumed to be 0. */
+  BFD_RELOC_D30V_9_PCREL,
+
+/* This is a 6-bit pc-relative reloc with
+the right 3 bits assumed to be 0. Same
+as the previous reloc but on the right side
+of the container. */
+  BFD_RELOC_D30V_9_PCREL_R,
+
+/* This is a 12-bit absolute reloc with the
+right 3 bitsassumed to be 0. */
+  BFD_RELOC_D30V_15,
+
+/* This is a 12-bit pc-relative reloc with
+the right 3 bits assumed to be 0. */
+  BFD_RELOC_D30V_15_PCREL,
+
+/* This is a 12-bit pc-relative reloc with
+the right 3 bits assumed to be 0. Same
+as the previous reloc but on the right side
+of the container. */
+  BFD_RELOC_D30V_15_PCREL_R,
+
+/* This is an 18-bit absolute reloc with
+the right 3 bits assumed to be 0. */
+  BFD_RELOC_D30V_21,
+
+/* This is an 18-bit pc-relative reloc with
+the right 3 bits assumed to be 0. */
+  BFD_RELOC_D30V_21_PCREL,
+
+/* This is an 18-bit pc-relative reloc with
+the right 3 bits assumed to be 0. Same
+as the previous reloc but on the right side
+of the container. */
+  BFD_RELOC_D30V_21_PCREL_R,
+
+/* This is a 32-bit absolute reloc. */
+  BFD_RELOC_D30V_32,
+
+/* This is a 32-bit pc-relative reloc. */
+  BFD_RELOC_D30V_32_PCREL,
+
+/* Mitsubishi M32R relocs.
+This is a 24 bit absolute address. */
+  BFD_RELOC_M32R_24,
+
+/* This is a 10-bit pc-relative reloc with the right 2 bits assumed to be 0. */
+  BFD_RELOC_M32R_10_PCREL,
+
+/* This is an 18-bit reloc with the right 2 bits assumed to be 0. */
+  BFD_RELOC_M32R_18_PCREL,
+
+/* This is a 26-bit reloc with the right 2 bits assumed to be 0. */
+  BFD_RELOC_M32R_26_PCREL,
+
+/* This is a 16-bit reloc containing the high 16 bits of an address
+used when the lower 16 bits are treated as unsigned. */
+  BFD_RELOC_M32R_HI16_ULO,
+
+/* This is a 16-bit reloc containing the high 16 bits of an address
+used when the lower 16 bits are treated as signed. */
+  BFD_RELOC_M32R_HI16_SLO,
+
+/* This is a 16-bit reloc containing the lower 16 bits of an address. */
+  BFD_RELOC_M32R_LO16,
+
+/* This is a 16-bit reloc containing the small data area offset for use in
+add3, load, and store instructions. */
+  BFD_RELOC_M32R_SDA16,
+
+/* This is a 9-bit reloc */
+  BFD_RELOC_V850_9_PCREL,
+
+/* This is a 22-bit reloc */
+  BFD_RELOC_V850_22_PCREL,
+
+/* This is a 16 bit offset from the short data area pointer. */
+  BFD_RELOC_V850_SDA_16_16_OFFSET,
+
+/* This is a 16 bit offset (of which only 15 bits are used) from the
+short data area pointer. */
+  BFD_RELOC_V850_SDA_15_16_OFFSET,
+
+/* This is a 16 bit offset from the zero data area pointer. */
+  BFD_RELOC_V850_ZDA_16_16_OFFSET,
+
+/* This is a 16 bit offset (of which only 15 bits are used) from the
+zero data area pointer. */
+  BFD_RELOC_V850_ZDA_15_16_OFFSET,
+
+/* This is an 8 bit offset (of which only 6 bits are used) from the
+tiny data area pointer. */
+  BFD_RELOC_V850_TDA_6_8_OFFSET,
+
+/* This is an 8bit offset (of which only 7 bits are used) from the tiny
+data area pointer. */
+  BFD_RELOC_V850_TDA_7_8_OFFSET,
+
+/* This is a 7 bit offset from the tiny data area pointer. */
+  BFD_RELOC_V850_TDA_7_7_OFFSET,
+
+/* This is a 16 bit offset from the tiny data area pointer. */
+  BFD_RELOC_V850_TDA_16_16_OFFSET,
+
+/* This is a 5 bit offset (of which only 4 bits are used) from the tiny
+data area pointer. */
+  BFD_RELOC_V850_TDA_4_5_OFFSET,
+
+/* This is a 4 bit offset from the tiny data area pointer. */
+  BFD_RELOC_V850_TDA_4_4_OFFSET,
+
+/* This is a 16 bit offset from the short data area pointer, with the
+bits placed non-contigously in the instruction. */
+  BFD_RELOC_V850_SDA_16_16_SPLIT_OFFSET,
+
+/* This is a 16 bit offset from the zero data area pointer, with the
+bits placed non-contigously in the instruction. */
+  BFD_RELOC_V850_ZDA_16_16_SPLIT_OFFSET,
+
+/* This is a 6 bit offset from the call table base pointer. */
+  BFD_RELOC_V850_CALLT_6_7_OFFSET,
+
+/* This is a 16 bit offset from the call table base pointer. */
+  BFD_RELOC_V850_CALLT_16_16_OFFSET,
+
+
+/* This is a 32bit pcrel reloc for the mn10300, offset by two bytes in the
+instruction. */
+  BFD_RELOC_MN10300_32_PCREL,
+
+/* This is a 16bit pcrel reloc for the mn10300, offset by two bytes in the
+instruction. */
+  BFD_RELOC_MN10300_16_PCREL,
+
+/* This is a 8bit DP reloc for the tms320c30, where the most
+significant 8 bits of a 24 bit word are placed into the least
+significant 8 bits of the opcode. */
+  BFD_RELOC_TIC30_LDP,
+
+/* This is a 7bit reloc for the tms320c54x, where the least
+significant 7 bits of a 16 bit word are placed into the least
+significant 7 bits of the opcode. */
+  BFD_RELOC_TIC54X_PARTLS7,
+
+/* This is a 9bit DP reloc for the tms320c54x, where the most
+significant 9 bits of a 16 bit word are placed into the least
+significant 9 bits of the opcode. */
+  BFD_RELOC_TIC54X_PARTMS9,
+
+/* This is an extended address 23-bit reloc for the tms320c54x. */
+  BFD_RELOC_TIC54X_23,
+
+/* This is a 16-bit reloc for the tms320c54x, where the least
+significant 16 bits of a 23-bit extended address are placed into
+the opcode. */
+  BFD_RELOC_TIC54X_16_OF_23,
+
+/* This is a reloc for the tms320c54x, where the most
+significant 7 bits of a 23-bit extended address are placed into
+the opcode. */
+  BFD_RELOC_TIC54X_MS7_OF_23,
+
+/* This is a 48 bit reloc for the FR30 that stores 32 bits. */
+  BFD_RELOC_FR30_48,
+
+/* This is a 32 bit reloc for the FR30 that stores 20 bits split up into
+two sections. */
+  BFD_RELOC_FR30_20,
+
+/* This is a 16 bit reloc for the FR30 that stores a 6 bit word offset in
+4 bits. */
+  BFD_RELOC_FR30_6_IN_4,
+
+/* This is a 16 bit reloc for the FR30 that stores an 8 bit byte offset
+into 8 bits. */
+  BFD_RELOC_FR30_8_IN_8,
+
+/* This is a 16 bit reloc for the FR30 that stores a 9 bit short offset
+into 8 bits. */
+  BFD_RELOC_FR30_9_IN_8,
+
+/* This is a 16 bit reloc for the FR30 that stores a 10 bit word offset
+into 8 bits. */
+  BFD_RELOC_FR30_10_IN_8,
+
+/* This is a 16 bit reloc for the FR30 that stores a 9 bit pc relative
+short offset into 8 bits. */
+  BFD_RELOC_FR30_9_PCREL,
+
+/* This is a 16 bit reloc for the FR30 that stores a 12 bit pc relative
+short offset into 11 bits. */
+  BFD_RELOC_FR30_12_PCREL,
+
+/* Motorola Mcore relocations. */
+  BFD_RELOC_MCORE_PCREL_IMM8BY4,
+  BFD_RELOC_MCORE_PCREL_IMM11BY2,
+  BFD_RELOC_MCORE_PCREL_IMM4BY2,
+  BFD_RELOC_MCORE_PCREL_32,
+  BFD_RELOC_MCORE_PCREL_JSR_IMM11BY2,
+  BFD_RELOC_MCORE_RVA,
+
+/* This is a 16 bit reloc for the AVR that stores 8 bit pc relative
+short offset into 7 bits. */
+  BFD_RELOC_AVR_7_PCREL,
+
+/* This is a 16 bit reloc for the AVR that stores 13 bit pc relative
+short offset into 12 bits. */
+  BFD_RELOC_AVR_13_PCREL,
+
+/* This is a 16 bit reloc for the AVR that stores 17 bit value (usually
+program memory address) into 16 bits. */
+  BFD_RELOC_AVR_16_PM,
+
+/* This is a 16 bit reloc for the AVR that stores 8 bit value (usually
+data memory address) into 8 bit immediate value of LDI insn. */
+  BFD_RELOC_AVR_LO8_LDI,
+
+/* This is a 16 bit reloc for the AVR that stores 8 bit value (high 8 bit
+of data memory address) into 8 bit immediate value of LDI insn. */
+  BFD_RELOC_AVR_HI8_LDI,
+
+/* This is a 16 bit reloc for the AVR that stores 8 bit value (most high 8 bit
+of program memory address) into 8 bit immediate value of LDI insn. */
+  BFD_RELOC_AVR_HH8_LDI,
+
+/* This is a 16 bit reloc for the AVR that stores negated 8 bit value
+(usually data memory address) into 8 bit immediate value of SUBI insn. */
+  BFD_RELOC_AVR_LO8_LDI_NEG,
+
+/* This is a 16 bit reloc for the AVR that stores negated 8 bit value
+(high 8 bit of data memory address) into 8 bit immediate value of
+SUBI insn. */
+  BFD_RELOC_AVR_HI8_LDI_NEG,
+
+/* This is a 16 bit reloc for the AVR that stores negated 8 bit value
+(most high 8 bit of program memory address) into 8 bit immediate value
+of LDI or SUBI insn. */
+  BFD_RELOC_AVR_HH8_LDI_NEG,
+
+/* This is a 16 bit reloc for the AVR that stores 8 bit value (usually
+command address) into 8 bit immediate value of LDI insn. */
+  BFD_RELOC_AVR_LO8_LDI_PM,
+
+/* This is a 16 bit reloc for the AVR that stores 8 bit value (high 8 bit
+of command address) into 8 bit immediate value of LDI insn. */
+  BFD_RELOC_AVR_HI8_LDI_PM,
+
+/* This is a 16 bit reloc for the AVR that stores 8 bit value (most high 8 bit
+of command address) into 8 bit immediate value of LDI insn. */
+  BFD_RELOC_AVR_HH8_LDI_PM,
+
+/* This is a 16 bit reloc for the AVR that stores negated 8 bit value
+(usually command address) into 8 bit immediate value of SUBI insn. */
+  BFD_RELOC_AVR_LO8_LDI_PM_NEG,
+
+/* This is a 16 bit reloc for the AVR that stores negated 8 bit value
+(high 8 bit of 16 bit command address) into 8 bit immediate value
+of SUBI insn. */
+  BFD_RELOC_AVR_HI8_LDI_PM_NEG,
+
+/* This is a 16 bit reloc for the AVR that stores negated 8 bit value
+(high 6 bit of 22 bit command address) into 8 bit immediate
+value of SUBI insn. */
+  BFD_RELOC_AVR_HH8_LDI_PM_NEG,
+
+/* This is a 32 bit reloc for the AVR that stores 23 bit value
+into 22 bits. */
+  BFD_RELOC_AVR_CALL,
+
+/* Direct 12 bit. */
+  BFD_RELOC_390_12,
+
+/* 12 bit GOT offset. */
+  BFD_RELOC_390_GOT12,
+
+/* 32 bit PC relative PLT address. */
+  BFD_RELOC_390_PLT32,
+
+/* Copy symbol at runtime. */
+  BFD_RELOC_390_COPY,
+
+/* Create GOT entry. */
+  BFD_RELOC_390_GLOB_DAT,
+
+/* Create PLT entry. */
+  BFD_RELOC_390_JMP_SLOT,
+
+/* Adjust by program base. */
+  BFD_RELOC_390_RELATIVE,
+
+/* 32 bit PC relative offset to GOT. */
+  BFD_RELOC_390_GOTPC,
+
+/* 16 bit GOT offset. */
+  BFD_RELOC_390_GOT16,
+
+/* PC relative 16 bit shifted by 1. */
+  BFD_RELOC_390_PC16DBL,
+
+/* 16 bit PC rel. PLT shifted by 1. */
+  BFD_RELOC_390_PLT16DBL,
+
+/* PC relative 32 bit shifted by 1. */
+  BFD_RELOC_390_PC32DBL,
+
+/* 32 bit PC rel. PLT shifted by 1. */
+  BFD_RELOC_390_PLT32DBL,
+
+/* 32 bit PC rel. GOT shifted by 1. */
+  BFD_RELOC_390_GOTPCDBL,
+
+/* 64 bit GOT offset. */
+  BFD_RELOC_390_GOT64,
+
+/* 64 bit PC relative PLT address. */
+  BFD_RELOC_390_PLT64,
+
+/* 32 bit rel. offset to GOT entry. */
+  BFD_RELOC_390_GOTENT,
+
+/* These two relocations are used by the linker to determine which of
+the entries in a C++ virtual function table are actually used.  When
+the --gc-sections option is given, the linker will zero out the entries
+that are not used, so that the code for those functions need not be
+included in the output.
+
+VTABLE_INHERIT is a zero-space relocation used to describe to the
+linker the inheritence tree of a C++ virtual function table.  The
+relocation's symbol should be the parent class' vtable, and the
+relocation should be located at the child vtable.
+
+VTABLE_ENTRY is a zero-space relocation that describes the use of a
+virtual function table entry.  The reloc's symbol should refer to the
+table of the class mentioned in the code.  Off of that base, an offset
+describes the entry that is being used.  For Rela hosts, this offset
+is stored in the reloc's addend.  For Rel hosts, we are forced to put
+this offset in the reloc's section offset. */
+  BFD_RELOC_VTABLE_INHERIT,
+  BFD_RELOC_VTABLE_ENTRY,
+
+/* Intel IA64 Relocations. */
+  BFD_RELOC_IA64_IMM14,
+  BFD_RELOC_IA64_IMM22,
+  BFD_RELOC_IA64_IMM64,
+  BFD_RELOC_IA64_DIR32MSB,
+  BFD_RELOC_IA64_DIR32LSB,
+  BFD_RELOC_IA64_DIR64MSB,
+  BFD_RELOC_IA64_DIR64LSB,
+  BFD_RELOC_IA64_GPREL22,
+  BFD_RELOC_IA64_GPREL64I,
+  BFD_RELOC_IA64_GPREL32MSB,
+  BFD_RELOC_IA64_GPREL32LSB,
+  BFD_RELOC_IA64_GPREL64MSB,
+  BFD_RELOC_IA64_GPREL64LSB,
+  BFD_RELOC_IA64_LTOFF22,
+  BFD_RELOC_IA64_LTOFF64I,
+  BFD_RELOC_IA64_PLTOFF22,
+  BFD_RELOC_IA64_PLTOFF64I,
+  BFD_RELOC_IA64_PLTOFF64MSB,
+  BFD_RELOC_IA64_PLTOFF64LSB,
+  BFD_RELOC_IA64_FPTR64I,
+  BFD_RELOC_IA64_FPTR32MSB,
+  BFD_RELOC_IA64_FPTR32LSB,
+  BFD_RELOC_IA64_FPTR64MSB,
+  BFD_RELOC_IA64_FPTR64LSB,
+  BFD_RELOC_IA64_PCREL21B,
+  BFD_RELOC_IA64_PCREL21BI,
+  BFD_RELOC_IA64_PCREL21M,
+  BFD_RELOC_IA64_PCREL21F,
+  BFD_RELOC_IA64_PCREL22,
+  BFD_RELOC_IA64_PCREL60B,
+  BFD_RELOC_IA64_PCREL64I,
+  BFD_RELOC_IA64_PCREL32MSB,
+  BFD_RELOC_IA64_PCREL32LSB,
+  BFD_RELOC_IA64_PCREL64MSB,
+  BFD_RELOC_IA64_PCREL64LSB,
+  BFD_RELOC_IA64_LTOFF_FPTR22,
+  BFD_RELOC_IA64_LTOFF_FPTR64I,
+  BFD_RELOC_IA64_LTOFF_FPTR32MSB,
+  BFD_RELOC_IA64_LTOFF_FPTR32LSB,
+  BFD_RELOC_IA64_LTOFF_FPTR64MSB,
+  BFD_RELOC_IA64_LTOFF_FPTR64LSB,
+  BFD_RELOC_IA64_SEGREL32MSB,
+  BFD_RELOC_IA64_SEGREL32LSB,
+  BFD_RELOC_IA64_SEGREL64MSB,
+  BFD_RELOC_IA64_SEGREL64LSB,
+  BFD_RELOC_IA64_SECREL32MSB,
+  BFD_RELOC_IA64_SECREL32LSB,
+  BFD_RELOC_IA64_SECREL64MSB,
+  BFD_RELOC_IA64_SECREL64LSB,
+  BFD_RELOC_IA64_REL32MSB,
+  BFD_RELOC_IA64_REL32LSB,
+  BFD_RELOC_IA64_REL64MSB,
+  BFD_RELOC_IA64_REL64LSB,
+  BFD_RELOC_IA64_LTV32MSB,
+  BFD_RELOC_IA64_LTV32LSB,
+  BFD_RELOC_IA64_LTV64MSB,
+  BFD_RELOC_IA64_LTV64LSB,
+  BFD_RELOC_IA64_IPLTMSB,
+  BFD_RELOC_IA64_IPLTLSB,
+  BFD_RELOC_IA64_COPY,
+  BFD_RELOC_IA64_TPREL22,
+  BFD_RELOC_IA64_TPREL64MSB,
+  BFD_RELOC_IA64_TPREL64LSB,
+  BFD_RELOC_IA64_LTOFF_TP22,
+  BFD_RELOC_IA64_LTOFF22X,
+  BFD_RELOC_IA64_LDXMOV,
+
+/* Motorola 68HC11 reloc.
+This is the 8 bits high part of an absolute address. */
+  BFD_RELOC_M68HC11_HI8,
+
+/* Motorola 68HC11 reloc.
+This is the 8 bits low part of an absolute address. */
+  BFD_RELOC_M68HC11_LO8,
+
+/* Motorola 68HC11 reloc.
+This is the 3 bits of a value. */
+  BFD_RELOC_M68HC11_3B,
+
+/* These relocs are only used within the CRIS assembler.  They are not
+(at present) written to any object files. */
+  BFD_RELOC_CRIS_BDISP8,
+  BFD_RELOC_CRIS_UNSIGNED_5,
+  BFD_RELOC_CRIS_SIGNED_6,
+  BFD_RELOC_CRIS_UNSIGNED_6,
+  BFD_RELOC_CRIS_UNSIGNED_4,
+
+/* Relocs used in ELF shared libraries for CRIS. */
+  BFD_RELOC_CRIS_COPY,
+  BFD_RELOC_CRIS_GLOB_DAT,
+  BFD_RELOC_CRIS_JUMP_SLOT,
+  BFD_RELOC_CRIS_RELATIVE,
+
+/* 32-bit offset to symbol-entry within GOT. */
+  BFD_RELOC_CRIS_32_GOT,
+
+/* 16-bit offset to symbol-entry within GOT. */
+  BFD_RELOC_CRIS_16_GOT,
+
+/* 32-bit offset to symbol-entry within GOT, with PLT handling. */
+  BFD_RELOC_CRIS_32_GOTPLT,
+
+/* 16-bit offset to symbol-entry within GOT, with PLT handling. */
+  BFD_RELOC_CRIS_16_GOTPLT,
+
+/* 32-bit offset to symbol, relative to GOT. */
+  BFD_RELOC_CRIS_32_GOTREL,
+
+/* 32-bit offset to symbol with PLT entry, relative to GOT. */
+  BFD_RELOC_CRIS_32_PLT_GOTREL,
+
+/* 32-bit offset to symbol with PLT entry, relative to this relocation. */
+  BFD_RELOC_CRIS_32_PLT_PCREL,
+
+/* Intel i860 Relocations. */
+  BFD_RELOC_860_COPY,
+  BFD_RELOC_860_GLOB_DAT,
+  BFD_RELOC_860_JUMP_SLOT,
+  BFD_RELOC_860_RELATIVE,
+  BFD_RELOC_860_PC26,
+  BFD_RELOC_860_PLT26,
+  BFD_RELOC_860_PC16,
+  BFD_RELOC_860_LOW0,
+  BFD_RELOC_860_SPLIT0,
+  BFD_RELOC_860_LOW1,
+  BFD_RELOC_860_SPLIT1,
+  BFD_RELOC_860_LOW2,
+  BFD_RELOC_860_SPLIT2,
+  BFD_RELOC_860_LOW3,
+  BFD_RELOC_860_LOGOT0,
+  BFD_RELOC_860_SPGOT0,
+  BFD_RELOC_860_LOGOT1,
+  BFD_RELOC_860_SPGOT1,
+  BFD_RELOC_860_LOGOTOFF0,
+  BFD_RELOC_860_SPGOTOFF0,
+  BFD_RELOC_860_LOGOTOFF1,
+  BFD_RELOC_860_SPGOTOFF1,
+  BFD_RELOC_860_LOGOTOFF2,
+  BFD_RELOC_860_LOGOTOFF3,
+  BFD_RELOC_860_LOPC,
+  BFD_RELOC_860_HIGHADJ,
+  BFD_RELOC_860_HAGOT,
+  BFD_RELOC_860_HAGOTOFF,
+  BFD_RELOC_860_HAPC,
+  BFD_RELOC_860_HIGH,
+  BFD_RELOC_860_HIGOT,
+  BFD_RELOC_860_HIGOTOFF,
+
+/* OpenRISC Relocations. */
+  BFD_RELOC_OPENRISC_ABS_26,
+  BFD_RELOC_OPENRISC_REL_26,
+
+/* H8 elf Relocations. */
+  BFD_RELOC_H8_DIR16A8,
+  BFD_RELOC_H8_DIR16R8,
+  BFD_RELOC_H8_DIR24A8,
+  BFD_RELOC_H8_DIR24R8,
+  BFD_RELOC_H8_DIR32A16,
+  BFD_RELOC_UNUSED };
+typedef enum bfd_reloc_code_real bfd_reloc_code_real_type;
+reloc_howto_type *
+bfd_reloc_type_lookup PARAMS ((bfd *abfd, bfd_reloc_code_real_type code));
+
+const char *
+bfd_get_reloc_code_name PARAMS ((bfd_reloc_code_real_type code));
+
+
+typedef struct symbol_cache_entry
+{
+       /* A pointer to the BFD which owns the symbol. This information
+          is necessary so that a back end can work out what additional
+          information (invisible to the application writer) is carried
+          with the symbol.
+
+          This field is *almost* redundant, since you can use section->owner
+          instead, except that some symbols point to the global sections
+          bfd_{abs,com,und}_section.  This could be fixed by making
+          these globals be per-bfd (or per-target-flavor).  FIXME. */
+
+  struct _bfd *the_bfd; /* Use bfd_asymbol_bfd(sym) to access this field. */
+
+       /* The text of the symbol. The name is left alone, and not copied; the
+          application may not alter it. */
+  const char *name;
+
+       /* The value of the symbol.  This really should be a union of a
+          numeric value with a pointer, since some flags indicate that
+          a pointer to another symbol is stored here.  */
+  symvalue value;
+
+       /* Attributes of a symbol: */
+
+#define BSF_NO_FLAGS    0x00
+
+       /* The symbol has local scope; <<static>> in <<C>>. The value
+          is the offset into the section of the data. */
+#define BSF_LOCAL      0x01
+
+       /* The symbol has global scope; initialized data in <<C>>. The
+          value is the offset into the section of the data. */
+#define BSF_GLOBAL     0x02
+
+       /* The symbol has global scope and is exported. The value is
+          the offset into the section of the data. */
+#define BSF_EXPORT     BSF_GLOBAL /* no real difference */
+
+       /* A normal C symbol would be one of:
+          <<BSF_LOCAL>>, <<BSF_FORT_COMM>>,  <<BSF_UNDEFINED>> or
+          <<BSF_GLOBAL>> */
+
+       /* The symbol is a debugging record. The value has an arbitary
+          meaning, unless BSF_DEBUGGING_RELOC is also set.  */
+#define BSF_DEBUGGING  0x08
+
+       /* The symbol denotes a function entry point.  Used in ELF,
+          perhaps others someday.  */
+#define BSF_FUNCTION    0x10
+
+       /* Used by the linker. */
+#define BSF_KEEP        0x20
+#define BSF_KEEP_G      0x40
+
+       /* A weak global symbol, overridable without warnings by
+          a regular global symbol of the same name.  */
+#define BSF_WEAK        0x80
+
+       /* This symbol was created to point to a section, e.g. ELF's
+          STT_SECTION symbols.  */
+#define BSF_SECTION_SYM 0x100
+
+       /* The symbol used to be a common symbol, but now it is
+          allocated. */
+#define BSF_OLD_COMMON  0x200
+
+       /* The default value for common data. */
+#define BFD_FORT_COMM_DEFAULT_VALUE 0
+
+       /* In some files the type of a symbol sometimes alters its
+          location in an output file - ie in coff a <<ISFCN>> symbol
+          which is also <<C_EXT>> symbol appears where it was
+          declared and not at the end of a section.  This bit is set
+          by the target BFD part to convey this information. */
+
+#define BSF_NOT_AT_END    0x400
+
+       /* Signal that the symbol is the label of constructor section. */
+#define BSF_CONSTRUCTOR   0x800
+
+       /* Signal that the symbol is a warning symbol.  The name is a
+          warning.  The name of the next symbol is the one to warn about;
+          if a reference is made to a symbol with the same name as the next
+          symbol, a warning is issued by the linker. */
+#define BSF_WARNING       0x1000
+
+       /* Signal that the symbol is indirect.  This symbol is an indirect
+          pointer to the symbol with the same name as the next symbol. */
+#define BSF_INDIRECT      0x2000
+
+       /* BSF_FILE marks symbols that contain a file name.  This is used
+          for ELF STT_FILE symbols.  */
+#define BSF_FILE          0x4000
+
+       /* Symbol is from dynamic linking information.  */
+#define BSF_DYNAMIC       0x8000
+
+       /* The symbol denotes a data object.  Used in ELF, and perhaps
+          others someday.  */
+#define BSF_OBJECT        0x10000
+
+       /* This symbol is a debugging symbol.  The value is the offset
+          into the section of the data.  BSF_DEBUGGING should be set
+          as well.  */
+#define BSF_DEBUGGING_RELOC 0x20000
+
+  flagword flags;
+
+       /* A pointer to the section to which this symbol is
+          relative.  This will always be non NULL, there are special
+          sections for undefined and absolute symbols.  */
+  struct sec *section;
+
+       /* Back end special data.  */
+  union
+    {
+      PTR p;
+      bfd_vma i;
+    } udata;
+
+} asymbol;
+#define bfd_get_symtab_upper_bound(abfd) \
+     BFD_SEND (abfd, _bfd_get_symtab_upper_bound, (abfd))
+boolean
+bfd_is_local_label PARAMS ((bfd *abfd, asymbol *sym));
+
+boolean
+bfd_is_local_label_name PARAMS ((bfd *abfd, const char *name));
+
+#define bfd_is_local_label_name(abfd, name) \
+     BFD_SEND (abfd, _bfd_is_local_label_name, (abfd, name))
+#define bfd_canonicalize_symtab(abfd, location) \
+     BFD_SEND (abfd, _bfd_canonicalize_symtab,\
+                  (abfd, location))
+boolean
+bfd_set_symtab PARAMS ((bfd *abfd, asymbol **location, unsigned int count));
+
+void
+bfd_print_symbol_vandf PARAMS ((bfd *abfd, PTR file, asymbol *symbol));
+
+#define bfd_make_empty_symbol(abfd) \
+     BFD_SEND (abfd, _bfd_make_empty_symbol, (abfd))
+#define bfd_make_debug_symbol(abfd,ptr,size) \
+        BFD_SEND (abfd, _bfd_make_debug_symbol, (abfd, ptr, size))
+int
+bfd_decode_symclass PARAMS ((asymbol *symbol));
+
+boolean
+bfd_is_undefined_symclass PARAMS ((int symclass));
+
+void
+bfd_symbol_info PARAMS ((asymbol *symbol, symbol_info *ret));
+
+boolean
+bfd_copy_private_symbol_data PARAMS ((bfd *ibfd, asymbol *isym, bfd *obfd, asymbol *osym));
+
+#define bfd_copy_private_symbol_data(ibfd, isymbol, obfd, osymbol) \
+     BFD_SEND (obfd, _bfd_copy_private_symbol_data, \
+               (ibfd, isymbol, obfd, osymbol))
+struct _bfd
+{
+    /* The filename the application opened the BFD with.  */
+    const char *filename;
+
+    /* A pointer to the target jump table.             */
+    const struct bfd_target *xvec;
+
+    /* To avoid dragging too many header files into every file that
+       includes `<<bfd.h>>', IOSTREAM has been declared as a "char
+       *", and MTIME as a "long".  Their correct types, to which they
+       are cast when used, are "FILE *" and "time_t".    The iostream
+       is the result of an fopen on the filename.  However, if the
+       BFD_IN_MEMORY flag is set, then iostream is actually a pointer
+       to a bfd_in_memory struct.  */
+    PTR iostream;
+
+    /* Is the file descriptor being cached?  That is, can it be closed as
+       needed, and re-opened when accessed later?  */
+
+    boolean cacheable;
+
+    /* Marks whether there was a default target specified when the
+       BFD was opened. This is used to select which matching algorithm
+       to use to choose the back end. */
+
+    boolean target_defaulted;
+
+    /* The caching routines use these to maintain a
+       least-recently-used list of BFDs */
+
+    struct _bfd *lru_prev, *lru_next;
+
+    /* When a file is closed by the caching routines, BFD retains
+       state information on the file here: */
+
+    ufile_ptr where;
+
+    /* and here: (``once'' means at least once) */
+
+    boolean opened_once;
+
+    /* Set if we have a locally maintained mtime value, rather than
+       getting it from the file each time: */
+
+    boolean mtime_set;
+
+    /* File modified time, if mtime_set is true: */
+
+    long mtime;
+
+    /* Reserved for an unimplemented file locking extension.*/
+
+    int ifd;
+
+    /* The format which belongs to the BFD. (object, core, etc.) */
+
+    bfd_format format;
+
+    /* The direction the BFD was opened with*/
+
+    enum bfd_direction {no_direction = 0,
+                        read_direction = 1,
+                        write_direction = 2,
+                        both_direction = 3} direction;
+
+    /* Format_specific flags*/
+
+    flagword flags;
+
+    /* Currently my_archive is tested before adding origin to
+       anything. I believe that this can become always an add of
+       origin, with origin set to 0 for non archive files.   */
+
+    ufile_ptr origin;
+
+    /* Remember when output has begun, to stop strange things
+       from happening. */
+    boolean output_has_begun;
+
+    /* Pointer to linked list of sections*/
+    struct sec  *sections;
+
+    /* The number of sections */
+    unsigned int section_count;
+
+    /* Stuff only useful for object files:
+       The start address. */
+    bfd_vma start_address;
+
+    /* Used for input and output*/
+    unsigned int symcount;
+
+    /* Symbol table for output BFD (with symcount entries) */
+    struct symbol_cache_entry  **outsymbols;
+
+    /* Pointer to structure which contains architecture information*/
+    const struct bfd_arch_info *arch_info;
+
+    /* Stuff only useful for archives:*/
+    PTR arelt_data;
+    struct _bfd *my_archive;     /* The containing archive BFD.  */
+    struct _bfd *next;           /* The next BFD in the archive.  */
+    struct _bfd *archive_head;   /* The first BFD in the archive.  */
+    boolean has_armap;
+
+    /* A chain of BFD structures involved in a link.  */
+    struct _bfd *link_next;
+
+    /* A field used by _bfd_generic_link_add_archive_symbols.  This will
+       be used only for archive elements.  */
+    int archive_pass;
+
+    /* Used by the back end to hold private data. */
+
+    union
+      {
+      struct aout_data_struct *aout_data;
+      struct artdata *aout_ar_data;
+      struct _oasys_data *oasys_obj_data;
+      struct _oasys_ar_data *oasys_ar_data;
+      struct coff_tdata *coff_obj_data;
+      struct pe_tdata *pe_obj_data;
+      struct xcoff_tdata *xcoff_obj_data;
+      struct ecoff_tdata *ecoff_obj_data;
+      struct ieee_data_struct *ieee_data;
+      struct ieee_ar_data_struct *ieee_ar_data;
+      struct srec_data_struct *srec_data;
+      struct ihex_data_struct *ihex_data;
+      struct tekhex_data_struct *tekhex_data;
+      struct elf_obj_tdata *elf_obj_data;
+      struct nlm_obj_tdata *nlm_obj_data;
+      struct bout_data_struct *bout_data;
+      struct sun_core_struct *sun_core_data;
+      struct sco5_core_struct *sco5_core_data;
+      struct trad_core_struct *trad_core_data;
+      struct som_data_struct *som_data;
+      struct hpux_core_struct *hpux_core_data;
+      struct hppabsd_core_struct *hppabsd_core_data;
+      struct sgi_core_struct *sgi_core_data;
+      struct lynx_core_struct *lynx_core_data;
+      struct osf_core_struct *osf_core_data;
+      struct cisco_core_struct *cisco_core_data;
+      struct versados_data_struct *versados_data;
+      struct netbsd_core_struct *netbsd_core_data;
+      PTR any;
+      } tdata;
+
+    /* Used by the application to hold private data*/
+    PTR usrdata;
+
+  /* Where all the allocated stuff under this BFD goes.  This is a
+     struct objalloc *, but we use PTR to avoid requiring the inclusion of
+     objalloc.h.  */
+    PTR memory;
+};
+
+typedef enum bfd_error
+{
+  bfd_error_no_error = 0,
+  bfd_error_system_call,
+  bfd_error_invalid_target,
+  bfd_error_wrong_format,
+  bfd_error_wrong_object_format,
+  bfd_error_invalid_operation,
+  bfd_error_no_memory,
+  bfd_error_no_symbols,
+  bfd_error_no_armap,
+  bfd_error_no_more_archived_files,
+  bfd_error_malformed_archive,
+  bfd_error_file_not_recognized,
+  bfd_error_file_ambiguously_recognized,
+  bfd_error_no_contents,
+  bfd_error_nonrepresentable_section,
+  bfd_error_no_debug_section,
+  bfd_error_bad_value,
+  bfd_error_file_truncated,
+  bfd_error_file_too_big,
+  bfd_error_invalid_error_code
+} bfd_error_type;
+
+bfd_error_type
+bfd_get_error PARAMS ((void));
+
+void
+bfd_set_error PARAMS ((bfd_error_type error_tag));
+
+const char *
+bfd_errmsg PARAMS ((bfd_error_type error_tag));
+
+void
+bfd_perror PARAMS ((const char *message));
+
+typedef void (*bfd_error_handler_type) PARAMS ((const char *, ...));
+
+bfd_error_handler_type
+bfd_set_error_handler PARAMS ((bfd_error_handler_type));
+
+void
+bfd_set_error_program_name PARAMS ((const char *));
+
+bfd_error_handler_type
+bfd_get_error_handler PARAMS ((void));
+
+const char *
+bfd_archive_filename PARAMS ((bfd *));
+
+long
+bfd_get_reloc_upper_bound PARAMS ((bfd *abfd, asection *sect));
+
+long
+bfd_canonicalize_reloc PARAMS ((bfd *abfd,
+    asection *sec,
+    arelent **loc,
+    asymbol **syms));
+
+void
+bfd_set_reloc PARAMS ((bfd *abfd, asection *sec, arelent **rel, unsigned int count)
+    
+    );
+
+boolean
+bfd_set_file_flags PARAMS ((bfd *abfd, flagword flags));
+
+int
+bfd_get_arch_size PARAMS ((bfd *abfd));
+
+int
+bfd_get_sign_extend_vma PARAMS ((bfd *abfd));
+
+boolean
+bfd_set_start_address PARAMS ((bfd *abfd, bfd_vma vma));
+
+long
+bfd_get_mtime PARAMS ((bfd *abfd));
+
+long
+bfd_get_size PARAMS ((bfd *abfd));
+
+unsigned int
+bfd_get_gp_size PARAMS ((bfd *abfd));
+
+void
+bfd_set_gp_size PARAMS ((bfd *abfd, unsigned int i));
+
+bfd_vma
+bfd_scan_vma PARAMS ((const char *string, const char **end, int base));
+
+boolean
+bfd_copy_private_bfd_data PARAMS ((bfd *ibfd, bfd *obfd));
+
+#define bfd_copy_private_bfd_data(ibfd, obfd) \
+     BFD_SEND (obfd, _bfd_copy_private_bfd_data, \
+               (ibfd, obfd))
+boolean
+bfd_merge_private_bfd_data PARAMS ((bfd *ibfd, bfd *obfd));
+
+#define bfd_merge_private_bfd_data(ibfd, obfd) \
+     BFD_SEND (obfd, _bfd_merge_private_bfd_data, \
+               (ibfd, obfd))
+boolean
+bfd_set_private_flags PARAMS ((bfd *abfd, flagword flags));
+
+#define bfd_set_private_flags(abfd, flags) \
+     BFD_SEND (abfd, _bfd_set_private_flags, \
+               (abfd, flags))
+#define bfd_sizeof_headers(abfd, reloc) \
+     BFD_SEND (abfd, _bfd_sizeof_headers, (abfd, reloc))
+
+#define bfd_find_nearest_line(abfd, sec, syms, off, file, func, line) \
+     BFD_SEND (abfd, _bfd_find_nearest_line,  (abfd, sec, syms, off, file, func, line))
+
+       /* Do these three do anything useful at all, for any back end?  */
+#define bfd_debug_info_start(abfd) \
+        BFD_SEND (abfd, _bfd_debug_info_start, (abfd))
+
+#define bfd_debug_info_end(abfd) \
+        BFD_SEND (abfd, _bfd_debug_info_end, (abfd))
+
+#define bfd_debug_info_accumulate(abfd, section) \
+        BFD_SEND (abfd, _bfd_debug_info_accumulate, (abfd, section))
+
+
+#define bfd_stat_arch_elt(abfd, stat) \
+        BFD_SEND (abfd, _bfd_stat_arch_elt,(abfd, stat))
+
+#define bfd_update_armap_timestamp(abfd) \
+        BFD_SEND (abfd, _bfd_update_armap_timestamp, (abfd))
+
+#define bfd_set_arch_mach(abfd, arch, mach)\
+        BFD_SEND ( abfd, _bfd_set_arch_mach, (abfd, arch, mach))
+
+#define bfd_relax_section(abfd, section, link_info, again) \
+       BFD_SEND (abfd, _bfd_relax_section, (abfd, section, link_info, again))
+
+#define bfd_gc_sections(abfd, link_info) \
+       BFD_SEND (abfd, _bfd_gc_sections, (abfd, link_info))
+
+#define bfd_merge_sections(abfd, link_info) \
+       BFD_SEND (abfd, _bfd_merge_sections, (abfd, link_info))
+
+#define bfd_link_hash_table_create(abfd) \
+       BFD_SEND (abfd, _bfd_link_hash_table_create, (abfd))
+
+#define bfd_link_add_symbols(abfd, info) \
+       BFD_SEND (abfd, _bfd_link_add_symbols, (abfd, info))
+
+#define bfd_final_link(abfd, info) \
+       BFD_SEND (abfd, _bfd_final_link, (abfd, info))
+
+#define bfd_free_cached_info(abfd) \
+       BFD_SEND (abfd, _bfd_free_cached_info, (abfd))
+
+#define bfd_get_dynamic_symtab_upper_bound(abfd) \
+       BFD_SEND (abfd, _bfd_get_dynamic_symtab_upper_bound, (abfd))
+
+#define bfd_print_private_bfd_data(abfd, file)\
+       BFD_SEND (abfd, _bfd_print_private_bfd_data, (abfd, file))
+
+#define bfd_canonicalize_dynamic_symtab(abfd, asymbols) \
+       BFD_SEND (abfd, _bfd_canonicalize_dynamic_symtab, (abfd, asymbols))
+
+#define bfd_get_dynamic_reloc_upper_bound(abfd) \
+       BFD_SEND (abfd, _bfd_get_dynamic_reloc_upper_bound, (abfd))
+
+#define bfd_canonicalize_dynamic_reloc(abfd, arels, asyms) \
+       BFD_SEND (abfd, _bfd_canonicalize_dynamic_reloc, (abfd, arels, asyms))
+
+extern bfd_byte *bfd_get_relocated_section_contents
+       PARAMS ((bfd *, struct bfd_link_info *,
+                 struct bfd_link_order *, bfd_byte *,
+                 boolean, asymbol **));
+
+boolean
+bfd_alt_mach_code PARAMS ((bfd *abfd, int index));
+
+symindex
+bfd_get_next_mapent PARAMS ((bfd *abfd, symindex previous, carsym **sym));
+
+boolean
+bfd_set_archive_head PARAMS ((bfd *output, bfd *new_head));
+
+bfd *
+bfd_openr_next_archived_file PARAMS ((bfd *archive, bfd *previous));
+
+const char *
+bfd_core_file_failing_command PARAMS ((bfd *abfd));
+
+int
+bfd_core_file_failing_signal PARAMS ((bfd *abfd));
+
+boolean
+core_file_matches_executable_p PARAMS ((bfd *core_bfd, bfd *exec_bfd));
+
+#define BFD_SEND(bfd, message, arglist) \
+               ((*((bfd)->xvec->message)) arglist)
+
+#ifdef DEBUG_BFD_SEND
+#undef BFD_SEND
+#define BFD_SEND(bfd, message, arglist) \
+  (((bfd) && (bfd)->xvec && (bfd)->xvec->message) ? \
+    ((*((bfd)->xvec->message)) arglist) : \
+    (bfd_assert (__FILE__,__LINE__), NULL))
+#endif
+#define BFD_SEND_FMT(bfd, message, arglist) \
+            (((bfd)->xvec->message[(int) ((bfd)->format)]) arglist)
+
+#ifdef DEBUG_BFD_SEND
+#undef BFD_SEND_FMT
+#define BFD_SEND_FMT(bfd, message, arglist) \
+  (((bfd) && (bfd)->xvec && (bfd)->xvec->message) ? \
+   (((bfd)->xvec->message[(int) ((bfd)->format)]) arglist) : \
+   (bfd_assert (__FILE__,__LINE__), NULL))
+#endif
+enum bfd_flavour {
+  bfd_target_unknown_flavour,
+  bfd_target_aout_flavour,
+  bfd_target_coff_flavour,
+  bfd_target_ecoff_flavour,
+  bfd_target_xcoff_flavour,
+  bfd_target_elf_flavour,
+  bfd_target_ieee_flavour,
+  bfd_target_nlm_flavour,
+  bfd_target_oasys_flavour,
+  bfd_target_tekhex_flavour,
+  bfd_target_srec_flavour,
+  bfd_target_ihex_flavour,
+  bfd_target_som_flavour,
+  bfd_target_os9k_flavour,
+  bfd_target_versados_flavour,
+  bfd_target_msdos_flavour,
+  bfd_target_ovax_flavour,
+  bfd_target_evax_flavour
+};
+
+enum bfd_endian { BFD_ENDIAN_BIG, BFD_ENDIAN_LITTLE, BFD_ENDIAN_UNKNOWN };
+
+/* Forward declaration.  */
+typedef struct bfd_link_info _bfd_link_info;
+
+typedef struct bfd_target
+{
+  char *name;
+  enum bfd_flavour flavour;
+  enum bfd_endian byteorder;
+  enum bfd_endian header_byteorder;
+  flagword object_flags;
+  flagword section_flags;
+  char symbol_leading_char;
+  char ar_pad_char;
+  unsigned short ar_max_namelen;
+  bfd_vma        (*bfd_getx64) PARAMS ((const bfd_byte *));
+  bfd_signed_vma (*bfd_getx_signed_64) PARAMS ((const bfd_byte *));
+  void           (*bfd_putx64) PARAMS ((bfd_vma, bfd_byte *));
+  bfd_vma        (*bfd_getx32) PARAMS ((const bfd_byte *));
+  bfd_signed_vma (*bfd_getx_signed_32) PARAMS ((const bfd_byte *));
+  void           (*bfd_putx32) PARAMS ((bfd_vma, bfd_byte *));
+  bfd_vma        (*bfd_getx16) PARAMS ((const bfd_byte *));
+  bfd_signed_vma (*bfd_getx_signed_16) PARAMS ((const bfd_byte *));
+  void           (*bfd_putx16) PARAMS ((bfd_vma, bfd_byte *));
+  bfd_vma        (*bfd_h_getx64) PARAMS ((const bfd_byte *));
+  bfd_signed_vma (*bfd_h_getx_signed_64) PARAMS ((const bfd_byte *));
+  void           (*bfd_h_putx64) PARAMS ((bfd_vma, bfd_byte *));
+  bfd_vma        (*bfd_h_getx32) PARAMS ((const bfd_byte *));
+  bfd_signed_vma (*bfd_h_getx_signed_32) PARAMS ((const bfd_byte *));
+  void           (*bfd_h_putx32) PARAMS ((bfd_vma, bfd_byte *));
+  bfd_vma        (*bfd_h_getx16) PARAMS ((const bfd_byte *));
+  bfd_signed_vma (*bfd_h_getx_signed_16) PARAMS ((const bfd_byte *));
+  void           (*bfd_h_putx16) PARAMS ((bfd_vma, bfd_byte *));
+  const struct bfd_target *(*_bfd_check_format[bfd_type_end]) PARAMS ((bfd *));
+  boolean  (*_bfd_set_format[bfd_type_end]) PARAMS ((bfd *));
+  boolean  (*_bfd_write_contents[bfd_type_end]) PARAMS ((bfd *));
+
+  /* Generic entry points.  */
+#define BFD_JUMP_TABLE_GENERIC(NAME) \
+CONCAT2 (NAME,_close_and_cleanup), \
+CONCAT2 (NAME,_bfd_free_cached_info), \
+CONCAT2 (NAME,_new_section_hook), \
+CONCAT2 (NAME,_get_section_contents), \
+CONCAT2 (NAME,_get_section_contents_in_window)
+
+  /* Called when the BFD is being closed to do any necessary cleanup.  */
+  boolean  (*_close_and_cleanup) PARAMS ((bfd *));
+  /* Ask the BFD to free all cached information.  */
+  boolean  (*_bfd_free_cached_info) PARAMS ((bfd *));
+  /* Called when a new section is created.  */
+  boolean  (*_new_section_hook) PARAMS ((bfd *, sec_ptr));
+  /* Read the contents of a section.  */
+  boolean  (*_bfd_get_section_contents) PARAMS ((bfd *, sec_ptr, PTR,
+                                                 file_ptr, bfd_size_type));
+  boolean  (*_bfd_get_section_contents_in_window)
+    PARAMS ((bfd *, sec_ptr, bfd_window *, file_ptr, bfd_size_type));
+
+  /* Entry points to copy private data.  */
+#define BFD_JUMP_TABLE_COPY(NAME) \
+CONCAT2 (NAME,_bfd_copy_private_bfd_data), \
+CONCAT2 (NAME,_bfd_merge_private_bfd_data), \
+CONCAT2 (NAME,_bfd_copy_private_section_data), \
+CONCAT2 (NAME,_bfd_copy_private_symbol_data), \
+CONCAT2 (NAME,_bfd_set_private_flags), \
+CONCAT2 (NAME,_bfd_print_private_bfd_data) \
+  /* Called to copy BFD general private data from one object file
+     to another.  */
+  boolean  (*_bfd_copy_private_bfd_data) PARAMS ((bfd *, bfd *));
+  /* Called to merge BFD general private data from one object file
+     to a common output file when linking.  */
+  boolean  (*_bfd_merge_private_bfd_data) PARAMS ((bfd *, bfd *));
+  /* Called to copy BFD private section data from one object file
+     to another.  */
+  boolean  (*_bfd_copy_private_section_data) PARAMS ((bfd *, sec_ptr,
+                                                      bfd *, sec_ptr));
+  /* Called to copy BFD private symbol data from one symbol
+     to another.  */
+  boolean  (*_bfd_copy_private_symbol_data) PARAMS ((bfd *, asymbol *,
+                                                     bfd *, asymbol *));
+  /* Called to set private backend flags */
+  boolean  (*_bfd_set_private_flags) PARAMS ((bfd *, flagword));
+
+  /* Called to print private BFD data */
+  boolean  (*_bfd_print_private_bfd_data) PARAMS ((bfd *, PTR));
+
+  /* Core file entry points.  */
+#define BFD_JUMP_TABLE_CORE(NAME) \
+CONCAT2 (NAME,_core_file_failing_command), \
+CONCAT2 (NAME,_core_file_failing_signal), \
+CONCAT2 (NAME,_core_file_matches_executable_p)
+  char *   (*_core_file_failing_command) PARAMS ((bfd *));
+  int      (*_core_file_failing_signal) PARAMS ((bfd *));
+  boolean  (*_core_file_matches_executable_p) PARAMS ((bfd *, bfd *));
+
+  /* Archive entry points.  */
+#define BFD_JUMP_TABLE_ARCHIVE(NAME) \
+CONCAT2 (NAME,_slurp_armap), \
+CONCAT2 (NAME,_slurp_extended_name_table), \
+CONCAT2 (NAME,_construct_extended_name_table), \
+CONCAT2 (NAME,_truncate_arname), \
+CONCAT2 (NAME,_write_armap), \
+CONCAT2 (NAME,_read_ar_hdr), \
+CONCAT2 (NAME,_openr_next_archived_file), \
+CONCAT2 (NAME,_get_elt_at_index), \
+CONCAT2 (NAME,_generic_stat_arch_elt), \
+CONCAT2 (NAME,_update_armap_timestamp)
+  boolean  (*_bfd_slurp_armap) PARAMS ((bfd *));
+  boolean  (*_bfd_slurp_extended_name_table) PARAMS ((bfd *));
+  boolean  (*_bfd_construct_extended_name_table)
+    PARAMS ((bfd *, char **, bfd_size_type *, const char **));
+  void     (*_bfd_truncate_arname) PARAMS ((bfd *, const char *, char *));
+  boolean  (*write_armap)
+    PARAMS ((bfd *, unsigned int, struct orl *, unsigned int, int));
+  PTR      (*_bfd_read_ar_hdr_fn) PARAMS ((bfd *));
+  bfd *    (*openr_next_archived_file) PARAMS ((bfd *, bfd *));
+#define bfd_get_elt_at_index(b,i) BFD_SEND(b, _bfd_get_elt_at_index, (b,i))
+  bfd *    (*_bfd_get_elt_at_index) PARAMS ((bfd *, symindex));
+  int      (*_bfd_stat_arch_elt) PARAMS ((bfd *, struct stat *));
+  boolean  (*_bfd_update_armap_timestamp) PARAMS ((bfd *));
+
+  /* Entry points used for symbols.  */
+#define BFD_JUMP_TABLE_SYMBOLS(NAME) \
+CONCAT2 (NAME,_get_symtab_upper_bound), \
+CONCAT2 (NAME,_get_symtab), \
+CONCAT2 (NAME,_make_empty_symbol), \
+CONCAT2 (NAME,_print_symbol), \
+CONCAT2 (NAME,_get_symbol_info), \
+CONCAT2 (NAME,_bfd_is_local_label_name), \
+CONCAT2 (NAME,_get_lineno), \
+CONCAT2 (NAME,_find_nearest_line), \
+CONCAT2 (NAME,_bfd_make_debug_symbol), \
+CONCAT2 (NAME,_read_minisymbols), \
+CONCAT2 (NAME,_minisymbol_to_symbol)
+  long     (*_bfd_get_symtab_upper_bound) PARAMS ((bfd *));
+  long     (*_bfd_canonicalize_symtab) PARAMS ((bfd *,
+                                                struct symbol_cache_entry **));
+  struct symbol_cache_entry *
+           (*_bfd_make_empty_symbol) PARAMS ((bfd *));
+  void     (*_bfd_print_symbol) PARAMS ((bfd *, PTR,
+                                         struct symbol_cache_entry *,
+                                         bfd_print_symbol_type));
+#define bfd_print_symbol(b,p,s,e) BFD_SEND(b, _bfd_print_symbol, (b,p,s,e))
+  void     (*_bfd_get_symbol_info) PARAMS ((bfd *,
+                                            struct symbol_cache_entry *,
+                                            symbol_info *));
+#define bfd_get_symbol_info(b,p,e) BFD_SEND(b, _bfd_get_symbol_info, (b,p,e))
+  boolean  (*_bfd_is_local_label_name) PARAMS ((bfd *, const char *));
+
+  alent *  (*_get_lineno) PARAMS ((bfd *, struct symbol_cache_entry *));
+  boolean  (*_bfd_find_nearest_line)
+    PARAMS ((bfd *, struct sec *, struct symbol_cache_entry **, bfd_vma,
+             const char **, const char **, unsigned int *));
+ /* Back-door to allow format-aware applications to create debug symbols
+    while using BFD for everything else.  Currently used by the assembler
+    when creating COFF files.  */
+  asymbol *(*_bfd_make_debug_symbol) PARAMS ((bfd *, void *,
+                                              unsigned long size));
+#define bfd_read_minisymbols(b, d, m, s) \
+  BFD_SEND (b, _read_minisymbols, (b, d, m, s))
+  long     (*_read_minisymbols) PARAMS ((bfd *, boolean, PTR *,
+                                         unsigned int *));
+#define bfd_minisymbol_to_symbol(b, d, m, f) \
+  BFD_SEND (b, _minisymbol_to_symbol, (b, d, m, f))
+  asymbol *(*_minisymbol_to_symbol) PARAMS ((bfd *, boolean, const PTR,
+                                             asymbol *));
+
+  /* Routines for relocs.  */
+#define BFD_JUMP_TABLE_RELOCS(NAME) \
+CONCAT2 (NAME,_get_reloc_upper_bound), \
+CONCAT2 (NAME,_canonicalize_reloc), \
+CONCAT2 (NAME,_bfd_reloc_type_lookup)
+  long     (*_get_reloc_upper_bound) PARAMS ((bfd *, sec_ptr));
+  long     (*_bfd_canonicalize_reloc) PARAMS ((bfd *, sec_ptr, arelent **,
+                                               struct symbol_cache_entry **));
+  /* See documentation on reloc types.  */
+  reloc_howto_type *
+           (*reloc_type_lookup) PARAMS ((bfd *, bfd_reloc_code_real_type));
+
+  /* Routines used when writing an object file.  */
+#define BFD_JUMP_TABLE_WRITE(NAME) \
+CONCAT2 (NAME,_set_arch_mach), \
+CONCAT2 (NAME,_set_section_contents)
+  boolean  (*_bfd_set_arch_mach) PARAMS ((bfd *, enum bfd_architecture,
+                                          unsigned long));
+  boolean  (*_bfd_set_section_contents) PARAMS ((bfd *, sec_ptr, PTR,
+                                                 file_ptr, bfd_size_type));
+
+  /* Routines used by the linker.  */
+#define BFD_JUMP_TABLE_LINK(NAME) \
+CONCAT2 (NAME,_sizeof_headers), \
+CONCAT2 (NAME,_bfd_get_relocated_section_contents), \
+CONCAT2 (NAME,_bfd_relax_section), \
+CONCAT2 (NAME,_bfd_link_hash_table_create), \
+CONCAT2 (NAME,_bfd_link_add_symbols), \
+CONCAT2 (NAME,_bfd_final_link), \
+CONCAT2 (NAME,_bfd_link_split_section), \
+CONCAT2 (NAME,_bfd_gc_sections), \
+CONCAT2 (NAME,_bfd_merge_sections)
+  int      (*_bfd_sizeof_headers) PARAMS ((bfd *, boolean));
+  bfd_byte *(*_bfd_get_relocated_section_contents)
+    PARAMS ((bfd *, struct bfd_link_info *, struct bfd_link_order *,
+             bfd_byte *, boolean, struct symbol_cache_entry **));
+
+  boolean  (*_bfd_relax_section)
+    PARAMS ((bfd *, struct sec *, struct bfd_link_info *, boolean *));
+
+  /* Create a hash table for the linker.  Different backends store
+     different information in this table.  */
+  struct bfd_link_hash_table *(*_bfd_link_hash_table_create) PARAMS ((bfd *));
+
+  /* Add symbols from this object file into the hash table.  */
+  boolean  (*_bfd_link_add_symbols) PARAMS ((bfd *, struct bfd_link_info *));
+
+  /* Do a link based on the link_order structures attached to each
+     section of the BFD.  */
+  boolean  (*_bfd_final_link) PARAMS ((bfd *, struct bfd_link_info *));
+
+  /* Should this section be split up into smaller pieces during linking.  */
+  boolean  (*_bfd_link_split_section) PARAMS ((bfd *, struct sec *));
+
+  /* Remove sections that are not referenced from the output.  */
+  boolean  (*_bfd_gc_sections) PARAMS ((bfd *, struct bfd_link_info *));
+
+  /* Attempt to merge SEC_MERGE sections.  */
+  boolean  (*_bfd_merge_sections) PARAMS ((bfd *, struct bfd_link_info *));
+
+  /* Routines to handle dynamic symbols and relocs.  */
+#define BFD_JUMP_TABLE_DYNAMIC(NAME) \
+CONCAT2 (NAME,_get_dynamic_symtab_upper_bound), \
+CONCAT2 (NAME,_canonicalize_dynamic_symtab), \
+CONCAT2 (NAME,_get_dynamic_reloc_upper_bound), \
+CONCAT2 (NAME,_canonicalize_dynamic_reloc)
+  /* Get the amount of memory required to hold the dynamic symbols. */
+  long     (*_bfd_get_dynamic_symtab_upper_bound) PARAMS ((bfd *));
+  /* Read in the dynamic symbols.  */
+  long     (*_bfd_canonicalize_dynamic_symtab)
+    PARAMS ((bfd *, struct symbol_cache_entry **));
+  /* Get the amount of memory required to hold the dynamic relocs.  */
+  long     (*_bfd_get_dynamic_reloc_upper_bound) PARAMS ((bfd *));
+  /* Read in the dynamic relocs.  */
+  long     (*_bfd_canonicalize_dynamic_reloc)
+    PARAMS ((bfd *, arelent **, struct symbol_cache_entry **));
+
+ /* Opposite endian version of this target.  */
+ const struct bfd_target * alternative_target;
+
+ PTR backend_data;
+
+} bfd_target;
+boolean
+bfd_set_default_target PARAMS ((const char *name));
+
+const bfd_target *
+bfd_find_target PARAMS ((const char *target_name, bfd *abfd));
+
+const char **
+bfd_target_list PARAMS ((void));
+
+const bfd_target *
+bfd_search_for_target PARAMS ((int (* search_func) (const bfd_target *, void *), void *));
+
+boolean
+bfd_check_format PARAMS ((bfd *abfd, bfd_format format));
+
+boolean
+bfd_check_format_matches PARAMS ((bfd *abfd, bfd_format format, char ***matching));
+
+boolean
+bfd_set_format PARAMS ((bfd *abfd, bfd_format format));
+
+const char *
+bfd_format_string PARAMS ((bfd_format format));
+
+#ifdef __cplusplus
+}
+#endif
+#endif
diff -purN linux-2.5/arch/ppc64/kdb/kdba_bp.c linuxppc64-2.5/arch/ppc64/kdb/kdba_bp.c
--- linux-2.5/arch/ppc64/kdb/kdba_bp.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/kdba_bp.c	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,789 @@
+/*
+ * Kernel Debugger Architecture Dependent Breakpoint Handling
+ *
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) Scott Lurndal (slurn@engr.sgi.com)
+ * Copyright (C) Scott Foehner (sfoehner@engr.sgi.com)
+ * Copyright (C) Srinivasa Thirumalachar (sprasad@engr.sgi.com)
+ *
+ * See the file LIA-COPYRIGHT for additional information.
+ *
+ * Written March 1999 by Scott Lurndal at Silicon Graphics, Inc.
+ *
+ * Modifications from:
+ *      Richard Bass                    1999/07/20
+ *              Many bug fixes and enhancements.
+ *      Scott Foehner
+ *              Port to ia64
+ *	Scott Lurndal			1999/12/12
+ *		v1.0 restructuring.
+ *	Keith Owens			2000/05/23
+ *		KDB v1.2
+ */
+
+#include <linux/string.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/smp.h>
+#include <linux/ptrace.h>
+#include <linux/kdb.h>
+#include <linux/kdbprivate.h>
+#include "privinst.h"
+
+static char *kdba_rwtypes[] = { "Instruction(Register)", "Data Write",
+			"I/O", "Data Access"};
+
+extern void set_all_DABR(unsigned long val);
+
+/*
+ * Table describing processor architecture hardware
+ * breakpoint registers.
+ */
+
+kdbhard_bp_t	kdb_hardbreaks[KDB_MAXHARDBPT];
+
+/*
+ * kdba_db_trap
+ *
+ * 	Perform breakpoint processing upon entry to the
+ *	processor debugger fault.   Determine and print
+ *	the active breakpoint.
+ *
+ * Parameters:
+ *	ef	Exception frame containing machine register state
+ *	error	Error number passed to kdb.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	KDB_DB_BPT	Standard instruction or data breakpoint encountered
+ *	KDB_DB_SS	Single Step fault ('ss' command or end of 'ssb' command)
+ *	KDB_DB_SSB	Single Step fault, caller should continue ('ssb' command)
+ *	KDB_DB_SSBPT	Single step over breakpoint
+ *	KDB_DB_NOBPT	No existing kdb breakpoint matches this debug exception
+ * Locking:
+ *	None.
+ * Remarks:
+ *	Yup, there be goto's here.
+ *
+ *	If multiple processors receive debug exceptions simultaneously,
+ *	one may be waiting at the kdb fence in kdb() while the user
+ *	issues a 'bc' command to clear the breakpoint the processor
+ *	which is waiting has already encountered.  If this is the case,
+ *	the debug registers will no longer match any entry in the
+ *	breakpoint table, and we'll return the value KDB_DB_NOBPT.
+ *	This can cause a panic in die_if_kernel().  It is safer to
+ *	disable the breakpoint (bd), go until all processors are past
+ *	the breakpoint then clear the breakpoint (bc).  This code
+ *	recognises a breakpoint even when disabled but not when it has
+ *	been cleared.
+ *
+ *	WARNING: This routine clears the debug state.  It should be called
+ *		 once per debug and the result cached.
+ */
+
+kdb_dbtrap_t
+kdba_db_trap(kdb_eframe_t ef, int error_unused)
+{
+	kdb_machreg_t  msr,trap;
+	int rw, reg;
+	int i;
+	kdb_dbtrap_t rv = KDB_DB_BPT;
+	kdb_bp_t *bp;
+	unsigned long primary;
+	unsigned long extended;
+
+	msr = get_msr();
+	trap = ef->trap;
+	if (KDB_DEBUG(BP))
+		kdb_printf("kdb: msr 0x%lx trap 0x%lx\n", msr,trap);
+	if (msr & MSR_SE || ((trap & 0x700) || (trap & 0xd00))) 
+	{
+		if (KDB_STATE(SSBPT)) {
+			if (KDB_DEBUG(BP))
+				kdb_printf("ssbpt\n");
+			KDB_STATE_CLEAR(SSBPT);
+			for(i=0,bp=kdb_breakpoints;
+			    i < KDB_MAXBPT;
+			    i++, bp++) {
+				if (KDB_DEBUG(BP))
+					kdb_printf("bp 0x%p enabled %d delayed %d global %d cpu %d\n",
+						   bp, bp->bp_enabled, bp->bp_delayed, bp->bp_global, bp->bp_cpu);
+				if (!bp->bp_enabled)
+					continue;
+				if (!bp->bp_global && bp->bp_cpu != smp_processor_id())
+					continue;
+				if (KDB_DEBUG(BP))
+					kdb_printf("bp for this cpu\n");
+				if (bp->bp_delayed) {
+					bp->bp_delayed = 0;
+					if (KDB_DEBUG(BP))
+						kdb_printf("kdba_installbp\n");
+					kdba_installbp(ef, bp);
+					if (!KDB_STATE(DOING_SS)) {
+						set_msr(get_msr() & ~MSR_SE);
+						return(KDB_DB_SSBPT);
+					}
+					break;
+				}
+			}
+			if (i == KDB_MAXBPT) {
+				kdb_printf("kdb: Unable to find delayed breakpoint\n");
+			}
+			if (!KDB_STATE(DOING_SS)) {
+				set_msr(get_msr() & ~MSR_SE);
+				return(KDB_DB_NOBPT);
+			}
+			/* FALLTHROUGH */
+		}
+
+		/*
+		 * KDB_STATE_DOING_SS is set when the kernel debugger is using
+		 * the processor trap flag to single-step a processor.  If a
+		 * single step trap occurs and this flag is clear, the SS trap
+		 * will be ignored by KDB and the kernel will be allowed to deal
+		 * with it as necessary (e.g. for ptrace).
+		 */
+		if (!KDB_STATE(DOING_SS))
+			goto unknown;
+
+		/* single step */
+		rv = KDB_DB_SS;		/* Indicate single step */
+		if (KDB_STATE(DOING_SSB)) {
+		    unsigned long instruction;
+
+			kdb_id1(ef->nip);
+			kdb_getarea(instruction,ef->nip);
+			primary=instruction & 0xfc000000;
+			extended=instruction & 0x000007fe;
+			if (kdb_getarea(instruction, ef->nip) ||   /* read failure */
+/* branch conditional */
+			    (primary==16 )||
+/* branch */
+			    (primary==18 )||    
+/* branch conditional to LR, or branch conditional to CR */
+			    (primary==19 && (extended==16 || extended == 528) 
+			     )) {
+				/*
+				 * End the ssb command here.
+				 */
+			    KDB_STATE_CLEAR(DOING_SSB);
+			    KDB_STATE_CLEAR(DOING_SS);
+			    }
+			rv = KDB_DB_SSB; /* Indicate ssb - dismiss immediately */
+		} else {
+			/*
+			 * Print current insn
+			 */
+			kdb_printf("SS trap at ");
+			kdb_symbol_print(ef->nip, NULL, KDB_SP_DEFAULT|KDB_SP_NEWLINE);
+			kdb_printf(" "); /* wms */
+			kdb_id1(ef->nip);
+			KDB_STATE_CLEAR(DOING_SS);
+		}
+
+		if (rv != KDB_DB_SSB)
+			set_msr(get_msr() & ~MSR_SE);
+	}
+	if (rv > 0)
+		goto handled;
+	
+	goto handle;
+
+
+handle:
+
+	/*
+	 * Determine which breakpoint was encountered.
+	 */
+	for(i=0, bp=kdb_breakpoints; i<KDB_MAXBPT; i++, bp++) {
+		if (!(bp->bp_free)
+		 && (bp->bp_global || bp->bp_cpu == smp_processor_id())
+		 && (bp->bp_hard)
+		 && (bp->bp_hard->bph_reg == reg)) {
+			/*
+			 * Hit this breakpoint.
+			 */
+			kdb_printf("%s breakpoint #%d at " kdb_bfd_vma_fmt "\n", 
+				  kdba_rwtypes[rw],
+				  i, (long )bp->bp_addr);
+
+			/*
+			 * For an instruction breakpoint, disassemble
+			 * the current instruction.
+			 */
+			if (rw == 0) {
+				kdb_id1(ef->nip);
+			}
+
+			goto handled;
+		}
+	}
+
+unknown:
+	rv = KDB_DB_NOBPT;	/* Cause kdb() to return */
+
+handled:
+
+
+	return rv;
+}
+
+/*
+ * kdba_bp_trap
+ *
+ * 	Perform breakpoint processing upon entry to the
+ *	processor breakpoint instruction fault.   Determine and print
+ *	the active breakpoint.
+ *
+ * Parameters:
+ *	ef	Exception frame containing machine register state
+ *	error	Error number passed to kdb.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	0	Standard instruction or data breakpoint encountered
+ *	1	Single Step fault ('ss' command)
+ *	2	Single Step fault, caller should continue ('ssb' command)
+ *	3	No existing kdb breakpoint matches this debug exception
+ * Locking:
+ *	None.
+ * Remarks:
+ *
+ * 	If multiple processors receive debug exceptions simultaneously,
+ *	one may be waiting at the kdb fence in kdb() while the user
+ *	issues a 'bc' command to clear the breakpoint the processor which
+ * 	is waiting has already encountered.   If this is the case, the
+ *	debug registers will no longer match any entry in the breakpoint
+ *	table, and we'll return the value '3'.  This can cause a panic
+ *	in die_if_kernel().  It is safer to disable the breakpoint (bd),
+ *	'go' until all processors are past the breakpoint then clear the
+ *	breakpoint (bc).  This code recognises a breakpoint even when
+ *	disabled but not when it has been cleared.
+ *
+ *	WARNING: This routine resets the eip.  It should be called
+ *		 once per breakpoint and the result cached.
+ */
+
+kdb_dbtrap_t
+kdba_bp_trap(kdb_eframe_t ef, int error_unused)
+{
+	int i;
+	kdb_dbtrap_t rv;
+	kdb_bp_t *bp;
+
+	/*
+	 * Determine which breakpoint was encountered.
+	 */
+	if (KDB_DEBUG(BP))
+		kdb_printf("kdba_bp_trap: eip=0x%lx (not adjusted) "
+			   "msr=0x%lx trap=0x%lx ef=0x%p esp=0x%lx\n",
+			   ef->nip, ef->msr, ef->trap, ef, ef->gpr[1]);
+
+	rv = KDB_DB_NOBPT;	/* Cause kdb() to return */
+
+	for(i=0, bp=kdb_breakpoints; i<KDB_MAXBPT; i++, bp++) {
+		if (bp->bp_free)
+			continue;
+		if (!bp->bp_global && bp->bp_cpu != smp_processor_id())
+			continue;
+		 if (bp->bp_addr == (ef->nip - bp->bp_adjust)) {
+			/* Hit this breakpoint.  */
+			ef->nip -= bp->bp_adjust;
+			kdb_printf("Instruction(i) breakpoint #%d at 0x%lx (adjusted)\n",
+				  i, ef->nip);
+			kdb_id1(ef->nip);
+			rv = KDB_DB_BPT;
+			bp->bp_delay = 1;
+			break;
+		}
+	}
+
+	return rv;
+}
+
+/*
+ * kdba_handle_bp
+ *
+ *	Handle an instruction-breakpoint trap.  Called when re-installing
+ *	an enabled breakpoint which has has the bp_delay bit set.
+ *
+ * Parameters:
+ * Returns:
+ * Locking:
+ * Remarks:
+ *
+ * Ok, we really need to:
+ *	1) Restore the original instruction byte
+ *	2) Single Step
+ *	3) Restore breakpoint instruction
+ *	4) Continue.
+ *
+ *
+ */
+
+static void
+kdba_handle_bp(kdb_eframe_t ef, kdb_bp_t *bp)
+{
+	if (!ef) {
+		kdb_printf("kdba_handle_bp: ef == NULL\n");
+		return;
+	}
+
+	if (KDB_DEBUG(BP))
+		kdb_printf("ef->eip = 0x%lx\n", ef->nip);
+
+	/*
+	 * Setup single step
+	 */
+	kdba_setsinglestep(ef);
+
+	/* KDB_STATE_SSBPT is set when the kernel debugger must single step
+	 * a task in order to re-establish an instruction breakpoint which
+	 * uses the instruction replacement mechanism. 
+	 */
+	KDB_STATE_SET(SSBPT);
+
+	/*
+	 * Reset delay attribute
+	 */
+	bp->bp_delay = 0;
+	bp->bp_delayed = 1;
+}
+
+
+/*
+ * kdba_bptype
+ *
+ *	Return a string describing type of breakpoint.
+ *
+ * Parameters:
+ *	bph	Pointer to hardware breakpoint description
+ * Outputs:
+ *	None.
+ * Returns:
+ *	Character string.
+ * Locking:
+ *	None.
+ * Remarks:
+ */
+
+char *
+kdba_bptype(kdbhard_bp_t *bph)
+{
+	char *mode;
+
+	mode = kdba_rwtypes[bph->bph_mode];
+
+	return mode;
+}
+
+/*
+ * kdba_printbpreg
+ *
+ *	Print register name assigned to breakpoint
+ *
+ * Parameters:
+ *	bph	Pointer hardware breakpoint structure
+ * Outputs:
+ *	None.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ */
+
+void
+kdba_printbpreg(kdbhard_bp_t *bph)
+{
+	kdb_printf(" in dr%ld", bph->bph_reg);
+}
+
+/*
+ * kdba_printbp
+ *
+ *	Print string describing hardware breakpoint.
+ *
+ * Parameters:
+ *	bph	Pointer to hardware breakpoint description
+ * Outputs:
+ *	None.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ */
+
+void
+kdba_printbp(kdb_bp_t *bp)
+{
+	kdb_printf("\n    is enabled");
+	if (bp->bp_hardtype) {
+		kdba_printbpreg(bp->bp_hard);
+		if (bp->bp_hard->bph_mode != 0) {
+			kdb_printf(" for %d bytes",
+				   bp->bp_hard->bph_length+1);
+		}
+	}
+}
+
+/*
+ * kdba_parsebp
+ *
+ *	Parse architecture dependent portion of the
+ *	breakpoint command.
+ *
+ * Parameters:
+ *	None.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	Zero for success, a kdb diagnostic for failure
+ * Locking:
+ *	None.
+ * Remarks:
+ *	for Ia32 architure, data access, data write and
+ *	I/O breakpoints are supported in addition to instruction
+ * 	breakpoints.
+ *
+ *	{datar|dataw|io|inst} [length]
+ */
+
+int
+kdba_parsebp(int argc, const char **argv, int *nextargp, kdb_bp_t *bp)
+{
+	int		nextarg = *nextargp;
+	int		diag;
+	kdbhard_bp_t 	*bph = &bp->bp_template;
+
+	bph->bph_mode = 0;		/* Default to instruction breakpoint */
+	bph->bph_length = 0;		/* Length must be zero for insn bp */
+	if ((argc + 1) != nextarg) {
+		if (strnicmp(argv[nextarg], "datar", sizeof("datar")) == 0) {
+			bph->bph_mode = 3;
+		} else if (strnicmp(argv[nextarg], "dataw", sizeof("dataw")) == 0) {
+			bph->bph_mode = 1;
+		} else if (strnicmp(argv[nextarg], "io", sizeof("io")) == 0) {
+			bph->bph_mode = 2;
+		} else if (strnicmp(argv[nextarg], "inst", sizeof("inst")) == 0) {
+			bph->bph_mode = 0;
+		} else {
+			return KDB_ARGCOUNT;
+		}
+
+		bph->bph_length = 3;	/* Default to 4 byte */
+
+		nextarg++;
+
+		if ((argc + 1) != nextarg) {
+			unsigned long len;
+
+			diag = kdbgetularg((char *)argv[nextarg],
+					   &len);
+			if (diag)
+				return diag;
+
+
+			if ((len > 4) || (len == 3))
+				return KDB_BADLENGTH;
+
+			bph->bph_length = len;
+			bph->bph_length--; /* Normalize for debug register */
+			nextarg++;
+		}
+
+		if ((argc + 1) != nextarg)
+			return KDB_ARGCOUNT;
+
+		/*
+		 * Indicate to architecture independent level that
+		 * a hardware register assignment is required to enable
+		 * this breakpoint.
+		 */
+
+		bph->bph_free = 0;
+	} else {
+		if (KDB_DEBUG(BP))
+			kdb_printf("kdba_bp: no args, forcehw is %d\n", bp->bp_forcehw);
+		if (bp->bp_forcehw) {
+			/*
+			 * We are forced to use a hardware register for this
+			 * breakpoint because either the bph or bpha
+			 * commands were used to establish this breakpoint.
+			 */
+			bph->bph_free = 0;
+		} else {
+			/*
+			 * Indicate to architecture dependent level that
+			 * the instruction replacement breakpoint technique
+			 * should be used for this breakpoint.
+			 */
+			bph->bph_free = 1;
+			bp->bp_adjust = PPC64_ADJUST_OFFSET;
+		}
+	}
+
+	*nextargp = nextarg;
+	return 0;
+}
+
+/*
+ * kdba_allocbp
+ *
+ *	Associate a hardware register with a breakpoint.
+ *
+ * Parameters:
+ *	None.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	A pointer to the allocated register kdbhard_bp_t structure for
+ *	success, Null and a non-zero diagnostic for failure.
+ * Locking:
+ *	None.
+ * Remarks:
+ */
+
+kdbhard_bp_t *
+kdba_allocbp(kdbhard_bp_t *bph, int *diagp)
+{
+	int i;
+	kdbhard_bp_t *newbph;
+
+	for(i=0,newbph=kdb_hardbreaks; i < KDB_MAXHARDBPT; i++, newbph++) {
+		if (newbph->bph_free) {
+			break;
+		}
+	}
+
+	if (i == KDB_MAXHARDBPT) {
+		*diagp = KDB_TOOMANYDBREGS;
+		return NULL;
+	}
+
+	*diagp = 0;
+
+	/*
+	 * Copy data from template.  Can't just copy the entire template
+	 * here because the register number in kdb_hardbreaks must be
+	 * preserved.
+	 */
+	newbph->bph_data = bph->bph_data;
+	newbph->bph_write = bph->bph_write;
+	newbph->bph_mode = bph->bph_mode;
+	newbph->bph_length = bph->bph_length;
+
+	/*
+	 * Mark entry allocated.
+	 */
+	newbph->bph_free = 0;
+
+	return newbph;
+}
+
+/*
+ * kdba_freebp
+ *
+ *	Deallocate a hardware breakpoint
+ *
+ * Parameters:
+ *	None.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	Zero for success, a kdb diagnostic for failure
+ * Locking:
+ *	None.
+ * Remarks:
+ */
+
+void
+kdba_freebp(kdbhard_bp_t *bph)
+{
+	bph->bph_free = 1;
+}
+
+/*
+ * kdba_initbp
+ *
+ *	Initialize the breakpoint table for the hardware breakpoint
+ *	register.
+ *
+ * Parameters:
+ *	None.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	Zero for success, a kdb diagnostic for failure
+ * Locking:
+ *	None.
+ * Remarks:
+ *
+ *	There is one entry per register.  On the ia32 architecture
+ *	all the registers are interchangeable, so no special allocation
+ *	criteria are required.
+ */
+
+void
+kdba_initbp(void)
+{
+	int i;
+	kdbhard_bp_t *bph;
+
+	/*
+	 * Clear the hardware breakpoint table
+	 */
+
+	memset(kdb_hardbreaks, '\0', sizeof(kdb_hardbreaks));
+
+	for(i=0,bph=kdb_hardbreaks; i<KDB_MAXHARDBPT; i++, bph++) {
+		bph->bph_reg = i;
+		bph->bph_free = 1;
+	}
+}
+
+/*
+ * kdba_installbp
+ *
+ *	Install a breakpoint
+ *
+ * Parameters:
+ *	ef	Exception frame
+ *	bp	Breakpoint structure for the breakpoint to be installed
+ * Outputs:
+ *	None.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ *	For hardware breakpoints, a debug register is allocated
+ *	and assigned to the breakpoint.  If no debug register is
+ *	available, a warning message is printed and the breakpoint
+ *	is disabled.
+ *
+ *	For instruction replacement breakpoints, we must single-step
+ *	over the replaced instruction at this point so we can re-install
+ *	the breakpoint instruction after the single-step.
+ */
+
+int
+kdba_installbp(kdb_eframe_t ef, kdb_bp_t *bp)
+{
+    int rc;
+	/*
+	 * Install the breakpoint, if it is not already installed.
+	 */
+
+	if (KDB_DEBUG(BP)) {
+		kdb_printf("kdba_installbp bp_installed %d\n", bp->bp_installed);
+	}
+	if (!bp->bp_installed) {
+		if (bp->bp_hardtype) {
+			kdba_installdbreg(bp); 
+			bp->bp_installed = 1;
+			if (KDB_DEBUG(BP)) {
+				kdb_printf("kdba_installbp hardware reg %ld at " kdb_bfd_vma_fmt "\n",
+					   (long unsigned int) bp->bp_hard->bph_reg, (long unsigned int) bp->bp_addr);
+			}
+		} else if (bp->bp_delay) {
+			if (KDB_DEBUG(BP))
+				kdb_printf("kdba_installbp delayed bp\n");
+			kdba_handle_bp(ef, bp);
+		} else {
+		    if (KDB_DEBUG(BP))
+			kdb_printf("0x%lx 0x%lx 0x%lx\n",bp->bp_inst,bp->bp_addr,sizeof(bp->bp_addr));
+		    rc = kdb_getword(&bp->bp_inst, bp->bp_addr,sizeof(bp->bp_addr));
+		    kdb_putword(bp->bp_addr, PPC64_BREAKPOINT_INSTRUCTION,sizeof(PPC64_BREAKPOINT_INSTRUCTION));
+		    if (KDB_DEBUG(BP))
+			kdb_printf("kdba_installbp instruction 0x%x at " kdb_bfd_vma_fmt "\n",
+				   PPC64_BREAKPOINT_INSTRUCTION, bp->bp_addr);
+		    bp->bp_installed = 1;
+		}
+	}
+return 0;
+}
+
+/*
+ * kdba_removebp
+ *
+ *	Make a breakpoint ineffective.
+ *
+ * Parameters:
+ *	None.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ */
+
+int
+kdba_removebp(kdb_bp_t *bp)
+{
+	/*
+	 * For hardware breakpoints, remove it from the active register,
+	 * for software breakpoints, restore the instruction stream.
+	 */
+	if (KDB_DEBUG(BP)) {
+		kdb_printf("kdba_removebp bp_installed %d\n", bp->bp_installed);
+	}
+	if (bp->bp_installed) {
+		if (bp->bp_hardtype) {
+			if (KDB_DEBUG(BP)) {
+				kdb_printf("kdb: removing hardware reg %ld at " kdb_bfd_vma_fmt "\n",
+					   bp->bp_hard->bph_reg, bp->bp_addr);
+			}
+			kdba_removedbreg(bp);
+		} else
+		{
+			if (KDB_DEBUG(BP))
+				kdb_printf("kdb: restoring instruction 0x%lx at " kdb_bfd_vma_fmt "\n",
+					   bp->bp_inst, bp->bp_addr);
+			kdb_putword(bp->bp_addr, bp->bp_inst,sizeof(bp->bp_inst));
+		}
+		bp->bp_installed = 0;
+	}
+return 0;
+}
+
+#if 0
+#define systemcfg naca
+#endif
+
+/* install data breakpoint */
+void
+kdba_installdbreg(kdb_bp_t *bp) {
+    if (systemcfg->platform==PLATFORM_PSERIES)
+    {
+    /* set_dabr is the kdb form, using mtspr instructions */
+	set_dabr(bp->bp_addr); 
+    } else if (systemcfg->platform==PLATFORM_PSERIES_LPAR ) {
+	/*set_all_DABR(bp->bp_addr); missing from 2.5? */
+#if 0
+	HvCall_setDABR(bp->bp_addr);
+#endif
+    } else if (systemcfg->platform==PLATFORM_ISERIES_LPAR ) {
+	/* different hcall interface needed here. */
+    }
+}
+
+/* remove data breakpoint-- set it to zero. */
+void
+kdba_removedbreg(kdb_bp_t *bp) {
+    if (systemcfg->platform==PLATFORM_PSERIES)
+    {
+    /* set_dabr is the kdb form, using mtspr instructions */
+	set_dabr(0x0); 
+    } else if (systemcfg->platform==PLATFORM_PSERIES_LPAR ) {
+	/*set_all_DABR(bp->bp_addr); missing from 2.5? */
+#if 0
+	HvCall_setDABR(0x0);
+#endif
+    } else if (systemcfg->platform==PLATFORM_ISERIES_LPAR ) {
+	/* different hcall interface needed here. */
+    }
+}
diff -purN linux-2.5/arch/ppc64/kdb/kdba_bt.c linuxppc64-2.5/arch/ppc64/kdb/kdba_bt.c
--- linux-2.5/arch/ppc64/kdb/kdba_bt.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/kdba_bt.c	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,281 @@
+/*
+ * Minimalist Kernel Debugger - Architecture Dependent Stack Traceback
+ *
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) Scott Lurndal (slurn@engr.sgi.com)
+ * Copyright (C) Scott Foehner (sfoehner@engr.sgi.com)
+ * Copyright (C) Srinivasa Thirumalachar (sprasad@engr.sgi.com)
+ *
+ * See the file LIA-COPYRIGHT for additional information.
+ *
+ * Written March 1999 by Scott Lurndal at Silicon Graphics, Inc.
+ *
+ * Modifications from:
+ *      Richard Bass                    1999/07/20
+ *              Many bug fixes and enhancements.
+ *      Scott Foehner
+ *              Port to ia64
+ *      Srinivasa Thirumalachar
+ *              RSE support for ia64
+ *	Masahiro Adegawa                1999/12/01
+ *		'sr' command, active flag in 'ps'
+ *	Scott Lurndal			1999/12/12
+ *		Significantly restructure for linux2.3
+ *	Keith Owens			2000/05/23
+ *		KDB v1.2
+ *
+ */
+
+#include <linux/ctype.h>
+#include <linux/string.h>
+#include <linux/kernel.h>
+#include <linux/sched.h>
+#include <linux/kallsyms.h>
+#include <linux/kdb.h>
+#include <linux/kdbprivate.h>
+#include <linux/ptrace.h>	/* for STACK_FRAME_OVERHEAD */
+#include <asm/system.h>
+#include "privinst.h"
+
+void systemreset(struct pt_regs *regs)
+{
+	udbg_printf("Oh no!\n");
+	kdb_printf("Oh no!\n");
+	kdb(KDB_REASON_OOPS, 0, (kdb_eframe_t) regs);
+	for (;;);
+}
+
+/* human name vector lookup. */
+static
+const char *getvecname(unsigned long vec)
+{
+	char *ret;
+	switch (vec) {
+	case 0x100:	ret = "(System Reset)"; break; 
+	case 0x200:	ret = "(Machine Check)"; break; 
+	case 0x300:	ret = "(Data Access)"; break; 
+	case 0x400:	ret = "(Instruction Access)"; break; 
+	case 0x500:	ret = "(Hardware Interrupt)"; break; 
+	case 0x600:	ret = "(Alignment)"; break; 
+	case 0x700:	ret = "(Program Check)"; break; 
+	case 0x800:	ret = "(FPU Unavailable)"; break; 
+	case 0x900:	ret = "(Decrementer)"; break; 
+	case 0xc00:	ret = "(System Call)"; break; 
+	case 0xd00:	ret = "(Single Step)"; break; 
+	case 0xf00:	ret = "(Performance Monitor)"; break; 
+	default: ret = "";
+	}
+	return ret;
+}
+
+
+extern unsigned long kdba_getword(unsigned long addr, size_t width);
+
+/* Copy a block of memory using kdba_getword().
+ * This is not efficient.
+ */
+static void kdba_getmem(unsigned long addr, void *p, int size)
+{
+	unsigned char *dst = (unsigned char *)p;
+	while (size > 0) {
+		*dst++ = kdba_getword(addr++, 1);
+		size--;
+	}
+}
+
+
+/*
+ * kdba_bt_stack_ppc
+ *
+ *	kdba_bt_stack with ppc specific parameters.
+ *	Specification as kdba_bt_stack plus :-
+ *
+ * Inputs:
+ *	As kba_bt_stack plus
+ *	regs_esp If 1 get esp from the registers (exception frame), if 0
+ *		 get esp from kdba_getregcontents.
+ */
+
+static int
+kdba_bt_stack_ppc(struct pt_regs *regs, kdb_machreg_t *addr, int argcount,
+		   struct task_struct *p, int regs_esp)
+{
+
+	kdb_machreg_t	esp,eip,ebp,old_esp;
+	kdb_symtab_t	symtab, *sym;
+	kdbtbtable_t	tbtab;
+	/* declare these as raw ptrs so we don't get func descriptors */
+	extern void *ret_from_except, *ret_from_syscall_1;
+/*	int do_bottom_half_ret=0; */
+
+if (!regs && !addr)
+{
+    kdb_printf(" invalid regs pointer \n");
+    return 0;
+}
+
+	/*
+	 * The caller may have supplied an address at which the
+	 * stack traceback operation should begin.  This address
+	 * is assumed by this code to point to a return-address
+	 * on the stack to be traced back.
+	 *
+	 * The end result of this will make it appear as if a function
+	 * entitled '<unknown>' was called from the function which
+	 * contains return-address.
+	 */
+	if (addr) {
+		eip = 0;
+		esp = *addr;
+		ebp=0;
+	} else {
+		ebp=regs->link;
+		eip = regs->nip;
+		if (regs_esp)
+			esp = regs->gpr[1];
+		else
+			kdba_getregcontents("esp", regs, &esp);
+	}
+
+	kdb_printf("          SP(esp)            PC(eip)      Function(args)\n");
+
+	/* (Ref: 64-bit PowerPC ELF ABI Spplement; Ian Lance Taylor, Zembu Labs).
+	 A PPC stack frame looks like this:
+
+	 High Address
+	 Back Chain
+	 FP reg save area
+	 GP reg save area
+	 Local var space
+	 Parameter save area		(SP+48)
+	 TOC save area		(SP+40)
+	 link editor doubleword	(SP+32)
+	 compiler doubleword		(SP+24)
+	 LR save			(SP+16)
+	 CR save			(SP+8)
+	 Back Chain			(SP+0)
+
+	 Note that the LR (ret addr) may not be saved in the *current* frame if
+	 no functions have been called from the current function.
+	 */
+
+	/*
+	 * Run through the activation records and print them.
+	 */
+	while (1) {
+		kdb_printf("0x%016lx  0x%016lx  ", esp, eip);
+		kdbnearsym(eip, &symtab);
+		kdba_find_tb_table(eip, &tbtab);
+		sym = symtab.sym_name ? &symtab : &tbtab.symtab; /* use fake symtab if necessary */
+		if (esp >= PAGE_OFFSET) { 
+		    if ((sym) && sym->sym_name) {
+			{
+
+/* if this fails, eip is outside of kernel space, dont trust it. */
+			    if (eip > PAGE_OFFSET) { 
+				    kdb_printf("%s", sym->sym_name);
+			    } else {
+				    kdb_printf("NO_SYMBOL");
+			    }
+			}
+/* if this fails, eip is outside of kernel space, dont trust data. */
+			if (eip > PAGE_OFFSET) { 
+			    if (eip - sym->sym_start > 0) {
+				kdb_printf(" +0x%lx", eip - sym->sym_start);
+			    }
+			}
+		    } else
+			kdb_printf("NO_SYMBOL");
+		}
+		else  /* userspace... */ {
+		    kdb_printf("UserSpace function");
+		    /* more code here to look up userspace function names..*/
+		}
+
+		kdb_printf("\n");
+		/* ret_from_except=0xa5e0 ret_from_syscall_1=a378 do_bottom_half_ret=a5e0 */
+		if (esp < PAGE_OFFSET) { /* below kernelspace..   */
+                            kdb_printf("<Stack contents outside of kernel space.  %.16lx>\n", esp );
+			    break;
+		} else {
+		    if (eip == (kdb_machreg_t)ret_from_except ||
+			eip == (kdb_machreg_t)ret_from_syscall_1 /* ||
+			eip == (kdb_machreg_t)do_bottom_half_ret */) {
+			/* pull exception regs from the stack */
+			struct pt_regs eregs;
+			kdba_getmem(esp+STACK_FRAME_OVERHEAD, &eregs, sizeof(eregs));
+			kdb_printf("  [exception: %lx:%s regs 0x%lx] nip:[0x%x] gpr[1]:[0x%x]\n", eregs.trap,getvecname(eregs.trap), esp+STACK_FRAME_OVERHEAD,(unsigned int)eregs.nip,(unsigned int)eregs.gpr[1]);
+			old_esp = esp;
+			esp = kdba_getword(esp, 8);
+			if (!esp)
+			    break;
+			eip = kdba_getword(esp+16, 8);	/* saved lr */
+			if (esp < PAGE_OFFSET) {  /* userspace... */
+			    if (old_esp > PAGE_OFFSET) {
+				kdb_printf("<Stack drops into userspace here %.16lx>\n",esp);
+				break;
+			    }
+			}
+/* we want to follow exception registers, not into user stack.  ...   */
+			esp = eregs.gpr[1];
+			eip = eregs.nip;
+		    } else {
+			esp = kdba_getword(esp, 8);
+			if (!esp)
+			    break;
+			eip = kdba_getword(esp+16, 8);	/* saved lr */
+
+#if 0
+			if (esp < p) {
+			    kdb_printf("<Stack drops into userspace %.16lx  %.16lx >\n", esp,p );
+			    break;
+			}
+#endif
+		    }
+		}
+	}
+	return 0;
+}
+
+
+/*
+ * kdba_bt_stack
+ *
+ *	This function implements the 'bt' command.  Print a stack
+ *	traceback.
+ *
+ *	bt [<address-expression>]   (addr-exp is for alternate stacks)
+ *	btp <pid>		     (Kernel stack for <pid>)
+ *
+ * 	address expression refers to a return address on the stack.  It
+ *	may be preceeded by a frame pointer.
+ *
+ * Inputs:
+ *	regs	registers at time kdb was entered.
+ *	addr	Pointer to Address provided to 'bt' command, if any.
+ *	argcount
+ *	p	Pointer to task for 'btp' command.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	zero for success, a kdb diagnostic if error
+ * Locking:
+ *	none.
+ * Remarks:
+ *	mds comes in handy when examining the stack to do a manual
+ *	traceback.
+ */
+
+int
+kdba_bt_stack(struct pt_regs *regs, kdb_machreg_t *addr, int argcount,
+	      struct task_struct *p)
+{
+	return(kdba_bt_stack_ppc(regs, addr, argcount, p, 0));
+}
+
+int
+kdba_bt_process(struct task_struct *p, int argcount)
+{
+	return(kdba_bt_stack_ppc(p->thread.regs, (kdb_machreg_t *) p->thread.ksp, argcount, p, 0));
+}
+
diff -purN linux-2.5/arch/ppc64/kdb/kdba_id.c linuxppc64-2.5/arch/ppc64/kdb/kdba_id.c
--- linux-2.5/arch/ppc64/kdb/kdba_id.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/kdba_id.c	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,278 @@
+/*
+ * Minimalist Kernel Debugger - Architecture Dependent Instruction Disassembly
+ *
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ *
+ * See the file LIA-COPYRIGHT for additional information.
+ *
+ * Written March 1999 by Scott Lurndal at Silicon Graphics, Inc.
+ *
+ * Modifications from:
+ *      Richard Bass                    1999/07/20
+ *              Many bug fixes and enhancements.
+ *      Scott Foehner
+ *              Port to ia64
+ *      Srinivasa Thirumalachar
+ *              RSE support for ia64
+ *	Masahiro Adegawa                1999/12/01
+ *		'sr' command, active flag in 'ps'
+ *	Scott Lurndal			1999/12/12
+ *		Significantly restructure for linux2.3
+ *	Keith Owens			2000/05/23
+ *		KDB v1.2
+ *
+ */
+
+#include <stdarg.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/ctype.h>
+#include <linux/string.h>
+#include <linux/kdb.h>
+#include <linux/kdbprivate.h>
+
+/*
+ * kdba_dis_getsym
+ *
+ *	Get a symbol for the disassembler.
+ *
+ * Parameters:
+ *	addr	Address for which to get symbol
+ *	dip	Pointer to disassemble_info
+ * Returns:
+ *	0
+ * Locking:
+ * Remarks:
+ *	Not used for kdb.
+ */
+
+/* ARGSUSED */
+static int
+kdba_dis_getsym(bfd_vma addr, disassemble_info *dip)
+{
+
+	return 0;
+}
+
+/*
+ * kdba_printaddress
+ *
+ *	Print (symbolically) an address.
+ *
+ * Parameters:
+ *	addr	Address for which to get symbol
+ *	dip	Pointer to disassemble_info
+ *	flag	True if a ":<tab>" sequence should follow the address
+ * Returns:
+ *	number of chars printed
+ * Locking:
+ * Remarks:
+ *
+ */
+
+/* ARGSUSED */
+void
+kdba_printaddress(kdb_machreg_t addr, disassemble_info *dip, int flag)
+{
+	kdb_symtab_t symtab;
+
+	/*
+	 * Print a symbol name or address as necessary.
+	 */
+	kdbnearsym(addr, &symtab);
+	if (symtab.sym_name) {
+		/* Do not use kdb_symbol_print here, it always does
+		 * kdb_printf but we want dip->fprintf_func.
+		 */
+		dip->fprintf_func(dip->stream,
+			"0x%0*lx %s",
+			2*sizeof(addr), addr, symtab.sym_name);
+		/* Add offset if needed.  Pad output with blanks to get
+		 * consistent size symbols for disassembly listings.
+		 */
+		if (addr == symtab.sym_start) {
+			if (!flag)
+				dip->fprintf_func(dip->stream, "         ");
+		} else {
+			int len, i;
+			char buf[20];
+			sprintf(buf, "%lx", addr - symtab.sym_start);
+			dip->fprintf_func(dip->stream, "+0x%s", buf);
+			if (!flag) {
+				len = strlen(buf);
+				for (i = len; i < 6; i++)
+					dip->fprintf_func(dip->stream, " ");
+			}
+		}
+
+	} else {
+		dip->fprintf_func(dip->stream, "0x%0*lx", 2*sizeof(addr), addr);
+	}
+
+	if (flag)
+		dip->fprintf_func(dip->stream, ":   ");
+}
+
+/*
+ * kdba_dis_printaddr
+ *
+ *	Print (symbolically) an address.  Called by GNU disassembly
+ *	code via disassemble_info structure.
+ *
+ * Parameters:
+ *	addr	Address for which to get symbol
+ *	dip	Pointer to disassemble_info
+ * Returns:
+ *	number of chars printed.
+ * Locking:
+ * Remarks:
+ *	This function will never append ":<tab>" to the printed
+ *	symbolic address.
+ */
+
+static void
+kdba_dis_printaddr(bfd_vma addr, disassemble_info *dip)
+{
+	return kdba_printaddress(addr, dip, 0);
+}
+
+/*
+ * kdba_dis_getmem
+ *
+ *	Fetch 'length' bytes from 'addr' into 'buf'.
+ *
+ * Parameters:
+ *	addr	Address for which to get symbol
+ *	buf	Address of buffer to fill with bytes from 'addr'
+ *	length	Number of bytes to fetch
+ *	dip	Pointer to disassemble_info
+ * Returns:
+ *	0
+ * Locking:
+ * Remarks:
+ *
+ */
+extern int kdba_getword(unsigned long addr, size_t width);
+
+
+/* ARGSUSED */
+static int
+kdba_dis_getmem(bfd_vma addr, bfd_byte *buf, unsigned int length, disassemble_info *dip)
+{
+	bfd_byte	*bp = buf;
+	int		i;
+
+	/*
+	 * Fill the provided buffer with bytes from
+	 * memory, starting at address 'addr' for 'length bytes.
+	 *
+	 */
+
+	for(i=0; i<length; i++ ){
+		*bp++ = (bfd_byte)kdba_getword(addr++, sizeof(bfd_byte));
+	}
+
+	return 0;
+}
+
+/*
+ * kdba_id_parsemode
+ *
+ * 	Parse IDMODE environment variable string and
+ *	set appropriate value into "disassemble_info" structure.
+ *
+ * Parameters:
+ *	mode	Mode string
+ *	dip	Disassemble_info structure pointer
+ * Returns:
+ * Locking:
+ * Remarks:
+ *	We handle the values 'x86' and '8086' to enable either
+ *	32-bit instruction set or 16-bit legacy instruction set.
+ */
+
+int
+kdba_id_parsemode(const char *mode, disassemble_info *dip)
+{
+
+
+	return 0;
+}
+
+/*
+ * kdba_check_pc
+ *
+ * 	Check that the pc is satisfactory.
+ *
+ * Parameters:
+ *	pc	Program Counter Value.
+ * Returns:
+ *	None
+ * Locking:
+ *	None.
+ * Remarks:
+ *	Can change pc.
+ */
+
+void
+kdba_check_pc(kdb_machreg_t *pc)
+{
+	/* No action */
+}
+
+/*
+ * kdba_id_printinsn
+ *
+ * 	Format and print a single instruction at 'pc'. Return the
+ *	length of the instruction.
+ *
+ * Parameters:
+ *	pc	Program Counter Value.
+ *	dip	Disassemble_info structure pointer
+ * Returns:
+ *	Length of instruction, -1 for error.
+ * Locking:
+ *	None.
+ * Remarks:
+ *	Depends on 'IDMODE' environment variable.
+ */
+
+int
+kdba_id_printinsn(kdb_machreg_t pc, disassemble_info *dip)
+{
+	kdba_dis_printaddr(pc, dip);
+	return print_insn_big_powerpc(pc, dip);
+}
+
+/*
+ * kdba_id_init
+ *
+ * 	Initialize the architecture dependent elements of
+ *	the disassembly information structure
+ *	for the GNU disassembler.
+ *
+ * Parameters:
+ *	None.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ */
+
+void __init
+kdba_id_init(disassemble_info *dip)
+{
+	dip->read_memory_func       = kdba_dis_getmem;
+	dip->print_address_func     = kdba_dis_printaddr;
+	dip->symbol_at_address_func = kdba_dis_getsym;
+
+	dip->flavour                = bfd_target_elf_flavour;
+	dip->arch		    = bfd_arch_powerpc;
+	dip->mach		    = bfd_mach_ppc_750;
+	dip->endian	    	    = BFD_ENDIAN_BIG;
+
+	dip->display_endian         = BFD_ENDIAN_BIG;
+}
diff -purN linux-2.5/arch/ppc64/kdb/kdba_io.c linuxppc64-2.5/arch/ppc64/kdb/kdba_io.c
--- linux-2.5/arch/ppc64/kdb/kdba_io.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/kdba_io.c	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,99 @@
+/*
+ * Kernel Debugger Console I/O handler
+ *
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) Scott Lurndal (slurn@engr.sgi.com)
+ * Copyright (C) Scott Foehner (sfoehner@engr.sgi.com)
+ * Copyright (C) Srinivasa Thirumalachar (sprasad@engr.sgi.com)
+ *
+ * See the file LIA-COPYRIGHT for additional information.
+ *
+ * Written March 1999 by Scott Lurndal at Silicon Graphics, Inc.
+ *
+ * Modifications from:
+ *	Chuck Fleckenstein		1999/07/20
+ *		Move kdb_info struct declaration to this file
+ *		for cases where serial support is not compiled into
+ *		the kernel.
+ *
+ *	Masahiro Adegawa		1999/07/20
+ *		Handle some peculiarities of japanese 86/106
+ *		keyboards.
+ *
+ *	marc@mucom.co.il		1999/07/20
+ *		Catch buffer overflow for serial input.
+ *
+ *      Scott Foehner
+ *              Port to ia64
+ *
+ *	Scott Lurndal			2000/01/03
+ *		Restructure for v1.0
+ *
+ *	Keith Owens			2000/05/23
+ *		KDB v1.2
+ *
+ *	Andi Kleen			2000/03/19
+ *		Support simultaneous input from serial line and keyboard.
+ */
+
+#include <linux/kernel.h>
+#include <asm/io.h>
+#include <linux/wait.h>
+#include <linux/delay.h>
+#include <linux/console.h>
+#include <linux/ctype.h>
+#include <linux/keyboard.h>
+#include <linux/serial_reg.h>
+
+#include <linux/kdb.h>
+#include <linux/kdbprivate.h>
+#include <asm/machdep.h>
+#undef FILE
+
+int kdb_port;
+
+struct kdb_serial kdb_serial;
+/*{
+	int io_type;
+	unsigned long iobase;
+	unsigned long ioreg_shift;
+} kdb_serial_t;
+*/
+
+int inchar(void);
+
+
+char *
+kdba_read(char *buffer, size_t bufsize)
+{
+	char	*cp = buffer;
+	char	*bufend = buffer+bufsize-2;	/* Reserve space for newline and null byte */
+
+	for (;;) {
+	    unsigned char key = ppc_md.udbg_getc();
+		/* Echo is done in the low level functions */
+		switch (key) {
+		case '\b': /* backspace */
+		case '\x7f': /* delete */
+			if (cp > buffer) {
+				udbg_puts("\b \b");
+				--cp;
+			}
+			break;
+		case '\n': /* enter */
+		case '\r': /* - the other enter... */
+			ppc_md.udbg_putc('\n');
+			*cp++ = '\n';
+			*cp++ = '\0';
+			return buffer;
+		default:
+			if (cp < bufend)
+			ppc_md.udbg_putc(key);
+				*cp++ = key;
+			break;
+		}
+	}
+}
+
+
+
diff -purN linux-2.5/arch/ppc64/kdb/kdbasupport.c linuxppc64-2.5/arch/ppc64/kdb/kdbasupport.c
--- linux-2.5/arch/ppc64/kdb/kdbasupport.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/kdbasupport.c	2003-11-10 22:51:12.000000000 +0000
@@ -0,0 +1,2121 @@
+/*
+ * Kernel Debugger Architecture Independent Support Functions
+ *
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) Scott Lurndal (slurn@engr.sgi.com)
+ * Copyright (C) Scott Foehner (sfoehner@engr.sgi.com)
+ * Copyright (C) Srinivasa Thirumalachar (sprasad@engr.sgi.com)
+ *
+ * See the file LIA-COPYRIGHT for additional information.
+ *
+ * Written March 1999 by Scott Lurndal at Silicon Graphics, Inc.
+ *
+ * Modifications from:
+ *      Richard Bass                    1999/07/20
+ *              Many bug fixes and enhancements.
+ *      Scott Foehner
+ *              Port to ia64
+ *	Scott Lurndal			1999/12/12
+ *		v1.0 restructuring.
+ *	Keith Owens			2000/05/23
+ *		KDB v1.2
+ */
+
+#include <linux/string.h>
+#include <linux/stddef.h>
+#include <linux/kernel.h>
+#include <linux/init.h>
+#include <linux/ptrace.h>
+#include <linux/mm.h>
+#include <linux/sched.h>
+#include <linux/kdb.h>
+#include <linux/kdbprivate.h>
+
+#include <asm/processor.h>
+#include "privinst.h"
+#include <asm/uaccess.h>
+#include <asm/machdep.h>
+
+extern const char *kdb_diemsg;
+unsigned long cpus_in_kdb=0;
+volatile unsigned long kdb_do_reboot=0;
+
+/* prototypes */
+int valid_ppc64_kernel_address(unsigned long addr, unsigned long size);
+int kdba_excprint(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_super_regs(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_dissect_msr(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_halt(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_dump_tce_table(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_kernelversion(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_dmesg(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_dump_pci_info(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_rd(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+int kdba_bt(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+unsigned long kdba_getword(unsigned long addr, size_t width);
+
+
+extern int kdb_dmesg(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+extern int kdb_ps(int argc, const char **argv, const char **envp, struct pt_regs *regs);
+
+extern int kdb_parse(const char *cmdstr, struct pt_regs *regs);
+
+/* 60secs * 1000*1000 usecs/sec.  HMC interface requires larger amount of time,.. */
+#define KDB_RESET_TIMEOUT 60*1000*1000
+
+/* kdb will use UDBG */
+#define USE_UDBG
+
+#ifdef USE_UDBG
+#include <asm/udbg.h>
+#endif
+
+#include <linux/kbd_kern.h>
+#include <linux/sysrq.h>
+#include <linux/interrupt.h>
+
+#ifdef CONFIG_MAGIC_SYSRQ
+static void
+sysrq_handle_kdb(int key, struct pt_regs *pt_regs, struct kbd_struct *kbd, struct tty_struct *tty) 
+{
+  kdb(KDB_REASON_KEYBOARD,0,pt_regs);
+}
+
+static struct sysrq_key_op sysrq_kdb_op = 
+{
+	handler:	(void*)sysrq_handle_kdb,
+	help_msg:	"(x)kdb",
+	action_msg:	"Entering kdb\n",
+};
+
+void
+kdb_map_scc(void)
+{
+	/* register sysrq 'x' */
+	__sysrq_put_key_op('x', &sysrq_kdb_op);
+}
+#endif
+
+
+/*
+ * kdba_prologue
+ *
+ *	This function analyzes a gcc-generated function prototype
+ *	with or without frame pointers to determine the amount of
+ *	automatic storage and register save storage is used on the
+ *	stack of the target function.  It only counts instructions
+ *	that have been executed up to but excluding the current nip.
+ * Inputs:
+ *	code	Start address of function code to analyze
+ *	pc	Current program counter within function
+ *	sp	Current stack pointer for function
+ *	fp	Current frame pointer for function, may not be valid
+ *	ss	Start of stack for current process.
+ *	caller	1 if looking for data on the caller frame, 0 for callee.
+ * Outputs:
+ *	ar	Activation record, all fields may be set.  fp and oldfp
+ *		are 0 if they cannot be extracted.  return is 0 if the
+ *		code cannot find a valid return address.  args and arg0
+ *		are 0 if the number of arguments cannot be safely
+ *		calculated.
+ * Returns:
+ *	1 if prologue is valid, 0 otherwise.  If pc is 0 treat it as a
+ *	valid prologue to allow bt on wild branches.
+ * Locking:
+ *	None.
+ * Remarks:
+ *
+ */
+int
+kdba_prologue(const kdb_symtab_t *symtab, kdb_machreg_t pc, kdb_machreg_t sp,
+	      kdb_machreg_t fp, kdb_machreg_t ss, int caller, kdb_ar_t *ar)
+{
+	/* We don't currently use kdb's generic activation record scanning
+	 * code to handle backtrace.
+	 */
+	return 0;
+}
+
+
+
+/*
+ * kdba_getregcontents
+ *
+ *	Return the contents of the register specified by the
+ *	input string argument.   Return an error if the string
+ *	does not match a machine register.
+ *
+ *	The following pseudo register names are supported:
+ *	   &regs	 - Prints address of exception frame
+ *	   kesp		 - Prints kernel stack pointer at time of fault
+ *	   cesp		 - Prints current kernel stack pointer, inside kdb
+ *	   ceflags	 - Prints current flags, inside kdb
+ *	   %<regname>	 - Uses the value of the registers at the
+ *			   last time the user process entered kernel
+ *			   mode, instead of the registers at the time
+ *			   kdb was entered.
+ *
+ * Parameters:
+ *	regname		Pointer to string naming register
+ *	regs		Pointer to structure containing registers.
+ * Outputs:
+ *	*contents	Pointer to unsigned long to recieve register contents
+ * Returns:
+ *	0		Success
+ *	KDB_BADREG	Invalid register name
+ * Locking:
+ * 	None.
+ * Remarks:
+ * 	If kdb was entered via an interrupt from the kernel itself then
+ *	ss and esp are *not* on the stack.
+ */
+
+static struct kdbregs {
+	char   *reg_name;
+	size_t	reg_offset;
+} kdbreglist[] = {
+	{ "gpr0",	offsetof(struct pt_regs, gpr[0]) },
+	{ "gpr1",	offsetof(struct pt_regs, gpr[1]) },
+	{ "gpr2",	offsetof(struct pt_regs, gpr[2]) },
+	{ "gpr3",	offsetof(struct pt_regs, gpr[3]) },
+	{ "gpr4",	offsetof(struct pt_regs, gpr[4]) },
+	{ "gpr5",	offsetof(struct pt_regs, gpr[5]) },
+	{ "gpr6",	offsetof(struct pt_regs, gpr[6]) },
+	{ "gpr7",	offsetof(struct pt_regs, gpr[7]) },
+	{ "gpr8",	offsetof(struct pt_regs, gpr[8]) },
+	{ "gpr9",	offsetof(struct pt_regs, gpr[9]) },
+	{ "gpr10",	offsetof(struct pt_regs, gpr[10]) },
+	{ "gpr11",	offsetof(struct pt_regs, gpr[11]) },
+	{ "gpr12",	offsetof(struct pt_regs, gpr[12]) },
+	{ "gpr13",	offsetof(struct pt_regs, gpr[13]) },
+	{ "gpr14",	offsetof(struct pt_regs, gpr[14]) },
+	{ "gpr15",	offsetof(struct pt_regs, gpr[15]) },
+	{ "gpr16",	offsetof(struct pt_regs, gpr[16]) },
+	{ "gpr17",	offsetof(struct pt_regs, gpr[17]) },
+	{ "gpr18",	offsetof(struct pt_regs, gpr[18]) },
+	{ "gpr19",	offsetof(struct pt_regs, gpr[19]) },
+	{ "gpr20",	offsetof(struct pt_regs, gpr[20]) },
+	{ "gpr21",	offsetof(struct pt_regs, gpr[21]) },
+	{ "gpr22",	offsetof(struct pt_regs, gpr[22]) },
+	{ "gpr23",	offsetof(struct pt_regs, gpr[23]) },
+	{ "gpr24",	offsetof(struct pt_regs, gpr[24]) },
+	{ "gpr25",	offsetof(struct pt_regs, gpr[25]) },
+	{ "gpr26",	offsetof(struct pt_regs, gpr[26]) },
+	{ "gpr27",	offsetof(struct pt_regs, gpr[27]) },
+	{ "gpr28",	offsetof(struct pt_regs, gpr[28]) },
+	{ "gpr29",	offsetof(struct pt_regs, gpr[29]) },
+	{ "gpr30",	offsetof(struct pt_regs, gpr[30]) },
+	{ "gpr31",	offsetof(struct pt_regs, gpr[31]) },
+	{ "nip",	offsetof(struct pt_regs, nip) },
+	{ "msr",	offsetof(struct pt_regs, msr) },
+	{ "esp",	offsetof(struct pt_regs, gpr[1]) },
+  	{ "orig_gpr3",  offsetof(struct pt_regs, orig_gpr3) },
+	{ "ctr", 	offsetof(struct pt_regs, ctr) },
+	{ "link",	offsetof(struct pt_regs, link) },
+	{ "xer", 	offsetof(struct pt_regs, xer) },
+	{ "ccr",	offsetof(struct pt_regs, ccr) },
+	{ "mq",		offsetof(struct pt_regs, softe) /* mq */ },
+	{ "trap",	offsetof(struct pt_regs, trap) },
+	{ "dar",	offsetof(struct pt_regs, dar)  },
+	{ "dsisr",	offsetof(struct pt_regs, dsisr) },
+	{ "result",	offsetof(struct pt_regs, result) },
+};
+
+static const int nkdbreglist = sizeof(kdbreglist) / sizeof(struct kdbregs);
+
+unsigned long
+getsp(void)
+{
+	unsigned long x;
+	asm("mr %0,1" : "=r" (x):);
+	return x;
+}
+
+int
+kdba_getregcontents(const char *regname,
+		    struct pt_regs *regs,
+		    kdb_machreg_t *contents)
+{
+	int i;
+
+	if (strcmp(regname, "&regs") == 0) {
+		*contents = (unsigned long)regs;
+		return 0;
+	}
+
+	if (strcmp(regname, "kesp") == 0) {
+		*contents = (unsigned long) current->thread.ksp;
+		return 0;
+	}
+
+	if (strcmp(regname, "cesp") == 0) {
+		*contents = getsp();
+		return 0;
+	}
+
+	if (strcmp(regname, "ceflags") == 0) {
+		long flags;
+		local_save_flags(flags);
+		*contents = flags;
+		return 0;
+	}
+
+	if (regname[0] == '%') {
+		/* User registers:  %%e[a-c]x, etc */
+		regname++;
+		regs = (struct pt_regs *)
+			(current->thread.ksp - sizeof(struct pt_regs));
+	}
+
+	for (i=0; i<nkdbreglist; i++) {
+		if (strnicmp(kdbreglist[i].reg_name,
+			     regname,
+			     strlen(regname)) == 0)
+			break;
+	}
+
+	if ((i < nkdbreglist)
+	 && (strlen(kdbreglist[i].reg_name) == strlen(regname))) {
+		*contents = *(unsigned long *)((unsigned long)regs +
+				kdbreglist[i].reg_offset);
+		return(0);
+	}
+
+	return KDB_BADREG;
+}
+
+/*
+ * kdba_setregcontents
+ *
+ *	Set the contents of the register specified by the
+ *	input string argument.   Return an error if the string
+ *	does not match a machine register.
+ *
+ *	Supports modification of user-mode registers via
+ *	%<register-name>
+ *
+ * Parameters:
+ *	regname		Pointer to string naming register
+ *	regs		Pointer to structure containing registers.
+ *	contents	Unsigned long containing new register contents
+ * Outputs:
+ * Returns:
+ *	0		Success
+ *	KDB_BADREG	Invalid register name
+ * Locking:
+ * 	None.
+ * Remarks:
+ */
+
+int
+kdba_setregcontents(const char *regname,
+		  struct pt_regs *regs,
+		  unsigned long contents)
+{
+	int i;
+
+	if (regname[0] == '%') {
+		regname++;
+		regs = (struct pt_regs *)
+			(current->thread.ksp - sizeof(struct pt_regs));
+	}
+
+	for (i=0; i<nkdbreglist; i++) {
+		if (strnicmp(kdbreglist[i].reg_name,
+			     regname,
+			     strlen(regname)) == 0)
+			break;
+	}
+
+	if ((i < nkdbreglist)
+	 && (strlen(kdbreglist[i].reg_name) == strlen(regname))) {
+		*(unsigned long *)((unsigned long)regs
+				   + kdbreglist[i].reg_offset) = contents;
+		return 0;
+	}
+
+	return KDB_BADREG;
+}
+
+/*
+ * kdba_dumpregs
+ *
+ *	Dump the specified register set to the display.
+ *
+ * Parameters:
+ *	regs		Pointer to structure containing registers.
+ *	type		Character string identifying register set to dump
+ *	extra		string further identifying register (optional)
+ * Outputs:
+ * Returns:
+ *	0		Success
+ * Locking:
+ * 	None.
+ * Remarks:
+ *	This function will dump the general register set if the type
+ *	argument is NULL (struct pt_regs).   The alternate register
+ *	set types supported by this function:
+ *
+ *	d 		Debug registers
+ *	c		Control registers
+ *	u		User registers at most recent entry to kernel
+ * Following not yet implemented:
+ *	m		Model Specific Registers (extra defines register #)
+ *	r		Memory Type Range Registers (extra defines register)
+ */
+
+int
+kdba_dumpregs(struct pt_regs *regs,
+	    const char *type,
+	    const char *extra)
+{
+	int i;
+	int count = 0;
+
+	if (type
+	 && (type[0] == 'u')) {
+		type = NULL;
+		regs = (struct pt_regs *)
+			(current->thread.ksp - sizeof(struct pt_regs));
+	}
+
+	if (type == NULL) {
+		struct kdbregs *rlp;
+		kdb_machreg_t contents;
+
+		for (i=0, rlp=kdbreglist; i<nkdbreglist; i++,rlp++) {
+			kdba_getregcontents(rlp->reg_name, regs, &contents);
+			kdb_printf("%-5s = 0x%p%c", rlp->reg_name, (void *)contents, (++count % 2) ? ' ' : '\n');
+		}
+
+		kdb_printf("&regs = 0x%p\n", regs);
+		return 0;
+ 	} else {  /* dump a specific register */
+ 	    kdb_machreg_t contents;
+ 	    if (KDB_BADREG==kdba_getregcontents(type, regs, &contents)) 
+ 		kdb_printf("register %-5s not found \n",type);
+ 	    else
+ 		kdb_printf("%-5s = 0x%p%c", type, (void *)contents, '\n');
+ 	    return 0;
+	}
+
+	switch (type[0]) {
+	case 'm':
+		break;
+	case 'r':
+		break;
+	default:
+		return KDB_BADREG;
+	}
+
+	/* NOTREACHED */
+	return 0;
+}
+
+kdb_machreg_t
+kdba_getpc(kdb_eframe_t ef)
+{
+    return ef ? ef->nip : 0;
+}
+
+int
+kdba_setpc(kdb_eframe_t ef, kdb_machreg_t newpc)
+{
+/* for ppc64, newpc passed in is actually a function descriptor for kdb. */
+    ef->nip =     kdba_getword(newpc+8, 8);
+    KDB_STATE_SET(IP_ADJUSTED);
+    return 0;
+}
+
+/*
+ * kdba_main_loop
+ *
+ *	Do any architecture specific set up before entering the main kdb loop.
+ *	The primary function of this routine is to make all processes look the
+ *	same to kdb, kdb must be able to list a process without worrying if the
+ *	process is running or blocked, so make all process look as though they
+ *	are blocked.
+ *
+ * Inputs:
+ *	reason		The reason KDB was invoked
+ *	error		The hardware-defined error code
+ *	error2		kdb's current reason code.  Initially error but can change
+ *			acording to kdb state.
+ *	db_result	Result from break or debug point.
+ *	ef		The exception frame at time of fault/breakpoint.  If reason
+ *			is KDB_REASON_SILENT then ef is NULL, otherwise it should
+ *			always be valid.
+ * Returns:
+ *	0	KDB was invoked for an event which it wasn't responsible
+ *	1	KDB handled the event for which it was invoked.
+ * Outputs:
+ *	Sets nip and esp in current->thread.
+ * Locking:
+ *	None.
+ * Remarks:
+ *	none.
+ */
+
+int
+kdba_main_loop(kdb_reason_t reason, kdb_reason_t reason2, int error,
+	       kdb_dbtrap_t db_result, kdb_eframe_t ef)
+{
+	int rv;
+	kdb_do_reboot=0;
+
+	/* case where incoming registers are missing */
+	if (ef == NULL)
+	{
+		struct pt_regs regs;
+		asm volatile ("std	0,0(%0)\n\
+                               std	1,8(%0)\n\
+                               std	2,16(%0)\n\
+                               std	3,24(%0)\n\
+                               std	4,32(%0)\n\
+                               std	5,40(%0)\n\
+                               std	6,48(%0)\n\
+                               std	7,56(%0)\n\
+                               std	8,64(%0)\n\
+                               std	9,72(%0)\n\
+                               std	10,80(%0)\n\
+                               std	11,88(%0)\n\
+                               std	12,96(%0)\n\
+                               std	13,104(%0)\n\
+                               std	14,112(%0)\n\
+                               std	15,120(%0)\n\
+                               std	16,128(%0)\n\
+                               std	17,136(%0)\n\
+                               std	18,144(%0)\n\
+                               std	19,152(%0)\n\
+                               std	20,160(%0)\n\
+                               std	21,168(%0)\n\
+                               std	22,176(%0)\n\
+                               std	23,184(%0)\n\
+                               std	24,192(%0)\n\
+                               std	25,200(%0)\n\
+                               std	26,208(%0)\n\
+                               std	27,216(%0)\n\
+                               std	28,224(%0)\n\
+                               std	29,232(%0)\n\
+                               std	30,240(%0)\n\
+                               std	31,248(%0)" : : "b" (&regs));
+                /* one extra step back..  this frame disappears */
+		regs.gpr[1] = kdba_getword(regs.gpr[1], 8);
+		/* Fetch the link reg for this stack frame.
+		 NOTE: the prev kdb_printf fills in the lr. */
+		regs.nip = regs.link = ((unsigned long *)regs.gpr[1])[2];
+		regs.msr = get_msr();
+		regs.ctr = get_ctr();
+		regs.xer = get_xer();
+		regs.ccr = get_cr();
+		regs.trap = 0;
+		/*current->thread.regs = &regs; */
+		ef = &regs;
+	}
+	cpus_in_kdb++;
+	rv = kdb_main_loop(reason, reason2, error, db_result, ef);
+	cpus_in_kdb--;
+	return rv;
+}
+
+void
+kdba_disableint(kdb_intstate_t *state)
+{
+	unsigned long *fp = (unsigned long *)state;
+	unsigned long flags;
+	local_irq_save(flags);
+	*fp = flags;
+}
+
+void
+kdba_restoreint(kdb_intstate_t *state)
+{
+	unsigned long flags = *(unsigned long *)state;
+	local_irq_restore(flags);
+}
+
+void
+kdba_setsinglestep(struct pt_regs *regs)
+{
+	regs->msr |= MSR_SE;
+}
+
+void
+kdba_clearsinglestep(struct pt_regs *regs)
+{
+	
+	regs->msr &= ~MSR_SE;
+}
+
+int
+kdba_getcurrentframe(struct pt_regs *regs)
+{
+	regs->gpr[1] = getsp();
+	/* this stack pointer becomes invalid after we return, so take another step back.  */
+	regs->gpr[1] = kdba_getword(regs->gpr[1], 8);
+	return 0;
+}
+
+#ifdef KDB_HAVE_LONGJMP
+int
+kdba_setjmp(kdb_jmp_buf *buf)
+{
+    asm volatile (
+	"mflr 0; std 0,0(%0)\n\
+	 std	1,8(%0)\n\
+	 std	2,16(%0)\n\
+	 mfcr 0; std 0,24(%0)\n\
+	 std	13,32(%0)\n\
+	 std	14,40(%0)\n\
+	 std	15,48(%0)\n\
+	 std	16,56(%0)\n\
+	 std	17,64(%0)\n\
+	 std	18,72(%0)\n\
+	 std	19,80(%0)\n\
+	 std	20,88(%0)\n\
+	 std	21,96(%0)\n\
+	 std	22,104(%0)\n\
+	 std	23,112(%0)\n\
+	 std	24,120(%0)\n\
+	 std	25,128(%0)\n\
+	 std	26,136(%0)\n\
+	 std	27,144(%0)\n\
+	 std	28,152(%0)\n\
+	 std	29,160(%0)\n\
+	 std	30,168(%0)\n\
+	 std	31,176(%0)\n\
+	 " : : "r" (buf));
+    KDB_STATE_SET(LONGJMP);
+    return 0;
+}
+
+void
+kdba_longjmp(kdb_jmp_buf *buf, int val)
+{
+    if (val == 0)
+	val = 1;
+    asm volatile (
+	"ld	13,32(%0)\n\
+	 ld	14,40(%0)\n\
+	 ld	15,48(%0)\n\
+	 ld	16,56(%0)\n\
+	 ld	17,64(%0)\n\
+	 ld	18,72(%0)\n\
+	 ld	19,80(%0)\n\
+	 ld	20,88(%0)\n\
+	 ld	21,96(%0)\n\
+	 ld	22,104(%0)\n\
+	 ld	23,112(%0)\n\
+	 ld	24,120(%0)\n\
+	 ld	25,128(%0)\n\
+	 ld	26,136(%0)\n\
+	 ld	27,144(%0)\n\
+	 ld	28,152(%0)\n\
+	 ld	29,160(%0)\n\
+	 ld	30,168(%0)\n\
+	 ld	31,176(%0)\n\
+	 ld	0,24(%0)\n\
+	 mtcrf	0x38,0\n\
+	 ld	0,0(%0)\n\
+	 ld	1,8(%0)\n\
+	 ld	2,16(%0)\n\
+	 mtlr	0\n\
+	 mr	3,%1\n\
+	 " : : "r" (buf), "r" (val));
+}
+#endif
+
+/*
+ * kdba_enable_mce
+ *
+ *	This function is called once on each CPU to enable machine
+ *	check exception handling.
+ *
+ * Inputs:
+ *	None.
+ * Outputs:
+ *	None.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ *
+ */
+
+void
+kdba_enable_mce(void)
+{
+}
+
+/*
+ * kdba_enable_lbr
+ *
+ *	Enable last branch recording.
+ *
+ * Parameters:
+ *	None.
+ * Returns:
+ *	None
+ * Locking:
+ *	None
+ * Remarks:
+ *	None.
+ */
+
+void
+kdba_enable_lbr(void)
+{
+}
+
+/*
+ * kdba_disable_lbr
+ *
+ *	disable last branch recording.
+ *
+ * Parameters:
+ *	None.
+ * Returns:
+ *	None
+ * Locking:
+ *	None
+ * Remarks:
+ *	None.
+ */
+
+void
+kdba_disable_lbr(void)
+{
+}
+
+/*
+ * kdba_print_lbr
+ *
+ *	Print last branch and last exception addresses
+ *
+ * Parameters:
+ *	None.
+ * Returns:
+ *	None
+ * Locking:
+ *	None
+ * Remarks:
+ *	None.
+ */
+
+void
+kdba_print_lbr(void)
+{
+}
+
+/*
+ * kdba_getword
+ *
+ * 	Architecture specific function to access kernel virtual
+ *	address space.
+ *
+ * Parameters:
+ *	None.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ *	None.
+ */
+
+/* 	if (access_ok(VERIFY_READ,__gu_addr,size))			\ */
+ 
+extern inline void sync(void)
+{
+	asm volatile("sync; isync");
+}
+
+extern void (*debugger_fault_handler)(struct pt_regs *);
+extern void longjmp(u_int *, int);
+
+unsigned long
+kdba_getword(unsigned long addr, size_t width)
+{
+	/*
+	 * This function checks the address for validity.  Any address
+	 * in the range PAGE_OFFSET to high_memory is legal, any address
+	 * which maps to a vmalloc region is legal, and any address which
+	 * is a user address, we use get_user() to verify validity.
+	 */
+
+    if (!valid_ppc64_kernel_address(addr, width)) {
+		        /*
+			 * Would appear to be an illegal kernel address;
+			 * Print a message once, and don't print again until
+			 * a legal address is used.
+			 */
+			if (!KDB_STATE(SUPPRESS)) {
+				kdb_printf("    kdb: Not a kernel-space address 0x%lx \n",addr);
+				KDB_STATE_SET(SUPPRESS);
+			}
+			return 0L;
+	}
+
+
+	/*
+	 * A good address.  Reset error flag.
+	 */
+	KDB_STATE_CLEAR(SUPPRESS);
+
+	switch (width) {
+	case 8:
+	{	unsigned long *lp;
+
+		lp = (unsigned long *)(addr);
+		return *lp;
+	}
+	case 4:
+	{	unsigned int *ip;
+
+		ip = (unsigned int *)(addr);
+		return *ip;
+	}
+	case 2:
+	{	unsigned short *sp;
+
+		sp = (unsigned short *)(addr);
+		return *sp;
+	}
+	case 1:
+	{	unsigned char *cp;
+
+		cp = (unsigned char *)(addr);
+		return *cp;
+	}
+	}
+
+	kdb_printf("kdbgetword: Bad width\n");
+	return 0L;
+}
+
+
+
+/*
+ * kdba_putword
+ *
+ * 	Architecture specific function to access kernel virtual
+ *	address space.
+ *
+ * Parameters:
+ *	None.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ *	None.
+ */
+
+unsigned long
+kdba_putword(unsigned long addr, size_t size, unsigned long contents)
+{
+	/*
+	 * This function checks the address for validity.  Any address
+	 * in the range PAGE_OFFSET to high_memory is legal, any address
+	 * which maps to a vmalloc region is legal, and any address which
+	 * is a user address, we use get_user() to verify validity.
+	 */
+
+	if (addr < PAGE_OFFSET) {
+		/*
+		 * Usermode address.
+		 */
+		unsigned long diag;
+
+		switch (size) {
+		case 4:
+		{	unsigned long *lp;
+
+			lp = (unsigned long *) addr;
+			diag = put_user(contents, lp);
+			break;
+		}
+		case 2:
+		{	unsigned short *sp;
+
+			sp = (unsigned short *) addr;
+			diag = put_user(contents, sp);
+			break;
+		}
+		case 1:
+		{	unsigned char *cp;
+
+			cp = (unsigned char *) addr;
+			diag = put_user(contents, cp);
+			break;
+		}
+		default:
+			kdb_printf("kdba_putword: Bad width\n");
+			return 0;
+		}
+
+		if (diag) {
+			if (!KDB_STATE(SUPPRESS)) {
+				kdb_printf("kdb: Bad user address 0x%lx\n", addr);
+				KDB_STATE_SET(SUPPRESS);
+			}
+			return 0;
+		}
+		KDB_STATE_CLEAR(SUPPRESS);
+		return 0;
+	}
+
+#if 0
+	if (addr > (unsigned long)high_memory) {
+		if (!kdb_vmlist_check(addr, addr+size)) {
+			/*
+			 * Would appear to be an illegal kernel address;
+			 * Print a message once, and don't print again until
+			 * a legal address is used.
+			 */
+			if (!KDB_STATE(SUPPRESS)) {
+				kdb_printf("kdb: xx Bad kernel address 0x%lx\n", addr);
+				KDB_STATE_SET(SUPPRESS);
+			}
+			return 0L;
+		}
+	}
+#endif
+
+	/*
+	 * A good address.  Reset error flag.
+	 */
+	KDB_STATE_CLEAR(SUPPRESS);
+
+	switch (size) {
+	case 4:
+	{	unsigned long *lp;
+
+		lp = (unsigned long *)(addr);
+		*lp = contents;
+		return 0;
+	}
+	case 2:
+	{	unsigned short *sp;
+
+		sp = (unsigned short *)(addr);
+		*sp = (unsigned short) contents;
+		return 0;
+	}
+	case 1:
+	{	unsigned char *cp;
+
+		cp = (unsigned char *)(addr);
+		*cp = (unsigned char) contents;
+		return 0;
+	}
+	}
+
+	kdb_printf("kdba_putword: Bad width 0x%lx\n",size);
+	return 0;
+}
+
+/*
+ * kdba_callback_die
+ *
+ *	Callback function for kernel 'die' function.
+ *
+ * Parameters:
+ *	regs	Register contents at time of trap
+ *	error_code  Trap-specific error code value
+ *	trapno	Trap number
+ *	vp	Pointer to die message
+ * Returns:
+ *	Returns 1 if fault handled by kdb.
+ * Locking:
+ *	None.
+ * Remarks:
+ *
+ */
+int
+kdba_callback_die(struct pt_regs *regs, int error_code, long trapno, void *vp)
+{
+	/*
+	 * Save a pointer to the message provided to 'die()'.
+	 */
+	kdb_diemsg = (char *)vp;
+
+	return kdb(KDB_REASON_OOPS, error_code, (kdb_eframe_t) regs);
+}
+
+/*
+ * kdba_callback_bp
+ *
+ *	Callback function for kernel breakpoint trap.
+ *
+ * Parameters:
+ *	regs	Register contents at time of trap
+ *	error_code  Trap-specific error code value
+ *	trapno	Trap number
+ *	vp	Not Used.
+ * Returns:
+ *	Returns 1 if fault handled by kdb.
+ * Locking:
+ *	None.
+ * Remarks:
+ *
+ */
+
+int
+kdba_callback_bp(struct pt_regs *regs, int error_code, long trapno, void *vp)
+{
+	int diag;
+
+	if (KDB_DEBUG(BP))
+		kdb_printf("cb_bp: e_c = %d  tn = %ld regs = 0x%p\n", error_code,
+			   trapno, regs);
+
+	diag = kdb(KDB_REASON_BREAK, error_code, (kdb_eframe_t) regs);
+
+	if (KDB_DEBUG(BP))
+		kdb_printf("cb_bp: e_c = %d  tn = %ld regs = 0x%p diag = %d\n", error_code,
+			   trapno, regs, diag);
+	return diag;
+}
+
+/*
+ * kdba_callback_debug
+ *
+ *	Callback function for kernel debug register trap.
+ *
+ * Parameters:
+ *	regs	Register contents at time of trap
+ *	error_code  Trap-specific error code value
+ *	trapno	Trap number
+ *	vp	Not used.
+ * Returns:
+ *	Returns 1 if fault handled by kdb.
+ * Locking:
+ *	None.
+ * Remarks:
+ *
+ */
+
+int
+kdba_callback_debug(struct pt_regs *regs, int error_code, long trapno, void *vp)
+{
+	return kdb(KDB_REASON_DEBUG, error_code, (kdb_eframe_t) regs);
+}
+
+
+
+
+/*
+ * kdba_adjust_ip
+ *
+ * 	Architecture specific adjustment of instruction pointer before leaving
+ *	kdb.
+ *
+ * Parameters:
+ *	reason		The reason KDB was invoked
+ *	error		The hardware-defined error code
+ *	ef		The exception frame at time of fault/breakpoint.  If reason
+ *			is KDB_REASON_SILENT then ef is NULL, otherwise it should
+ *			always be valid.
+ * Returns:
+ *	None.
+ * Locking:
+ *	None.
+ * Remarks:
+ *	noop on ix86.
+ */
+
+void
+kdba_adjust_ip(kdb_reason_t reason, int error, kdb_eframe_t ef)
+{
+	return;
+}
+
+
+
+/*
+ * kdba_find_tb_table
+ *
+ * 	Find the traceback table (defined by the ELF64 ABI) located at
+ *	the end of the function containing pc.
+ *
+ * Parameters:
+ *	nip	starting instruction addr.  does not need to be at the start of the func.
+ *	tab	table to populate if successful
+ * Returns:
+ *	non-zero if successful.  unsuccessful means that a valid tb table was not found
+ * Locking:
+ *	None.
+ * Remarks:
+ *	None.
+ */
+int kdba_find_tb_table(kdb_machreg_t nip, kdbtbtable_t *tab)
+{
+	kdb_machreg_t codeaddr = nip;
+	kdb_machreg_t codeaddr_max;
+	kdb_machreg_t tbtab_start;
+	int instr;
+	int num_parms;
+
+	if (tab == NULL)
+		return 0;
+	memset(tab, 0, sizeof(tab));
+
+	if (nip < PAGE_OFFSET) {  /* this is gonna fail for userspace, at least for now.. */
+	    return 0;
+	}
+
+	/* Scan instructions starting at codeaddr for 128k max */
+	for (codeaddr_max = codeaddr + 128*1024*4;
+	     codeaddr < codeaddr_max;
+	     codeaddr += 4) {
+		instr = kdba_getword(codeaddr, 4);
+		if (instr == 0) {
+			/* table should follow. */
+			int version;
+			unsigned long flags;
+			tbtab_start = codeaddr;	/* save it to compute func start addr */
+			codeaddr += 4;
+			flags = kdba_getword(codeaddr, 8);
+			tab->flags = flags;
+			version = (flags >> 56) & 0xff;
+			if (version != 0)
+				continue;	/* No tb table here. */
+			/* Now, like the version, some of the flags are values
+			 that are more conveniently extracted... */
+			tab->fp_saved = (flags >> 24) & 0x3f;
+			tab->gpr_saved = (flags >> 16) & 0x3f;
+			tab->fixedparms = (flags >> 8) & 0xff;
+			tab->floatparms = (flags >> 1) & 0x7f;
+			codeaddr += 8;
+			num_parms = tab->fixedparms + tab->floatparms;
+			if (num_parms) {
+				unsigned int parminfo;
+				int parm;
+				if (num_parms > 32)
+					return 1;	/* incomplete */
+				parminfo = kdba_getword(codeaddr, 4);
+				/* decode parminfo...32 bits.
+				 A zero means fixed.  A one means float and the
+				 following bit determines single (0) or double (1).
+				 */
+				for (parm = 0; parm < num_parms; parm++) {
+					if (parminfo & 0x80000000) {
+						parminfo <<= 1;
+						if (parminfo & 0x80000000)
+							tab->parminfo[parm] = KDBTBTAB_PARMDFLOAT;
+						else
+							tab->parminfo[parm] = KDBTBTAB_PARMSFLOAT;
+					} else {
+						tab->parminfo[parm] = KDBTBTAB_PARMFIXED;
+					}
+					parminfo <<= 1;
+				}
+				codeaddr += 4;
+			}
+			if (flags & KDBTBTAB_FLAGSHASTBOFF) {
+				tab->tb_offset = kdba_getword(codeaddr, 4);
+				if (tab->tb_offset > 0) {
+					tab->funcstart = tbtab_start - tab->tb_offset;
+				}
+				codeaddr += 4;
+			}
+			/* hand_mask appears to be always be omitted. */
+			if (flags & KDBTBTAB_FLAGSHASCTL) {
+				/* Assume this will never happen for C or asm */
+				return 1;	/* incomplete */
+			}
+			if (flags & KDBTBTAB_FLAGSNAMEPRESENT) {
+				int i;
+				short namlen = kdba_getword(codeaddr, 2);
+				if (namlen >= sizeof(tab->name))
+					namlen = sizeof(tab->name)-1;
+				codeaddr += 2;
+				for (i = 0; i < namlen; i++) {
+					tab->name[i] = kdba_getword(codeaddr++, 1);
+				}
+				tab->name[namlen] = '\0';
+			}
+			/* Fake up a symtab entry in case the caller finds it useful */
+			tab->symtab.value = tab->symtab.sym_start = tab->funcstart;
+			tab->symtab.sym_name = tab->name;
+			tab->symtab.sym_end = tbtab_start;
+			return 1;
+		}
+	}
+	return 0;	/* hit max...sorry. */
+}
+
+int
+kdba_putarea_size(unsigned long to_xxx, void *from, size_t size)
+{
+    char c;
+    c = *((volatile char *)from);
+    c = *((volatile char *)from+size-1);
+    return __copy_to_user((void *)to_xxx,from,size);
+}
+
+
+
+/*
+ * valid_ppc64_kernel_address() returns '1' if the address passed in is
+ * within a valid range.  Function returns 0 if address is outside valid ranges.
+ */
+
+/*
+
+    KERNELBASE    c000000000000000
+        (good range)
+    high_memory   c0000000 20000000
+
+    VMALLOC_START d000000000000000
+        (good range)
+    VMALLOC_END   VMALLOC_START + VALID_EA_BITS  
+
+    IMALLOC_START e000000000000000
+        (good range)
+    IMALLOC_END   IMALLOC_START + VALID_EA_BITS
+
+*/
+
+int
+valid_ppc64_kernel_address(unsigned long addr, unsigned long size)
+{
+	unsigned long i;
+	unsigned long end = (addr + size - 1);	
+
+	int userspace_enabled=0;
+
+/* set USERSPACE=1 to enable userspace memory lookups*/
+	kdbgetintenv("USERSPACE", &userspace_enabled);	
+
+	for (i = addr; i <= end; i = i ++ ) {
+	    if (
+		(!userspace_enabled &&
+		 ((unsigned long)i < (unsigned long)KERNELBASE     ))  || 		
+		(((unsigned long)i > (unsigned long)high_memory) &&
+		 ((unsigned long)i < (unsigned long)VMALLOC_START) )  ||
+		(((unsigned long)i > (unsigned long)VMALLOC_END) &&
+		 ((unsigned long)i < (unsigned long)IMALLOC_START) )  ||
+		( (unsigned long)i > (unsigned long)IMALLOC_END    )       ) {
+		return 0;
+	    }
+	}
+	return 1;
+}
+
+
+int
+kdba_getarea_size(void *to, unsigned long from_xxx, size_t size)
+{
+	int is_valid_kern_addr = valid_ppc64_kernel_address(from_xxx, size);
+	int diag = 0;
+
+	*((volatile char *)to) = '\0';
+	*((volatile char *)to + size - 1) = '\0';
+
+	if (is_valid_kern_addr) {
+		memcpy(to, (void *)from_xxx, size);
+	} else {
+            /*  user space address, just return.  */
+	    diag = -1;
+	}
+
+	return diag;
+}
+
+
+
+/*
+ *  kdba_readarea_size, reads size-lump of memory into to* passed in, returns size.
+ * Making it feel a bit more like mread.. when i'm clearer on kdba end, probally will
+ * remove one of these.
+ */
+int
+kdba_readarea_size(unsigned long from_xxx,void *to, size_t size)
+{
+    int is_valid_kern_addr = valid_ppc64_kernel_address(from_xxx, size);
+
+    *((volatile char *)to) = '\0';
+    *((volatile char *)to + size - 1) = '\0';
+
+    if (is_valid_kern_addr) {
+	memcpy(to, (void *)from_xxx, size);
+	return size;
+    } else {
+	/*  user-space, just return...    */
+	return 0;
+    }
+    /* wont get here */
+    return 0;
+}
+
+
+/* utilities migrated from Xmon or other kernel debug tools. */
+
+/*
+Notes for migrating functions from xmon...
+Add functions to this file.  parmlist for functions must match
+   (int argc, const char **argv, const char **envp, struct pt_regs *fp)
+add function prototype to kdbasupport.c
+add function hook to kdba_init() within kdbasupport.c
+
+Common bits...
+mread() function calls need to be changed to kdba_readarea_size calls.  straightforward change.
+This:
+	nr = mread(codeaddr, &namlen, 2); 
+becomes this:
+	nr = kdba_readarea_size(codeaddr,&namlen,2);
+*/
+
+#define EOF	(-1)
+
+/* for traverse_all_pci_devices */
+#include "../kernel/pci.h"
+/* for NUM_TCE_LEVELS */
+#include <asm/pci_dma.h>
+
+
+/* prototypes */
+int scanhex(unsigned long *);
+int hexdigit(int c);
+/* int kdba_readarea_size(unsigned long from_xxx,void *to,  size_t size); */
+void machine_halt(void); 
+
+
+
+/*
+ A traceback table typically follows each function.
+ The find_tb_table() func will fill in this struct.  Note that the struct
+ is not an exact match with the encoded table defined by the ABI.  It is
+ defined here more for programming convenience.
+ */
+struct tbtable {
+	unsigned long	flags;		/* flags: */
+#define TBTAB_FLAGSGLOBALLINK	(1L<<47)
+#define TBTAB_FLAGSISEPROL	(1L<<46)
+#define TBTAB_FLAGSHASTBOFF	(1L<<45)
+#define TBTAB_FLAGSINTPROC	(1L<<44)
+#define TBTAB_FLAGSHASCTL	(1L<<43)
+#define TBTAB_FLAGSTOCLESS	(1L<<42)
+#define TBTAB_FLAGSFPPRESENT	(1L<<41)
+#define TBTAB_FLAGSNAMEPRESENT	(1L<<38)
+#define TBTAB_FLAGSUSESALLOCA	(1L<<37)
+#define TBTAB_FLAGSSAVESCR	(1L<<33)
+#define TBTAB_FLAGSSAVESLR	(1L<<32)
+#define TBTAB_FLAGSSTORESBC	(1L<<31)
+#define TBTAB_FLAGSFIXUP	(1L<<30)
+#define TBTAB_FLAGSPARMSONSTK	(1L<<0)
+	unsigned char	fp_saved;	/* num fp regs saved f(32-n)..f31 */
+	unsigned char	gpr_saved;	/* num gpr's saved */
+	unsigned char	fixedparms;	/* num fixed point parms */
+	unsigned char	floatparms;	/* num float parms */
+	unsigned char	parminfo[32];	/* types of args.  null terminated */
+#define TBTAB_PARMFIXED 1
+#define TBTAB_PARMSFLOAT 2
+#define TBTAB_PARMDFLOAT 3
+	unsigned int	tb_offset;	/* offset from start of func */
+	unsigned long	funcstart;	/* addr of start of function */
+	char		name[64];	/* name of function (null terminated)*/
+};
+
+
+static int find_tb_table(unsigned long codeaddr, struct tbtable *tab);
+
+
+/* Very cheap human name for vector lookup. */
+static
+const char *getvecname(unsigned long vec)
+{
+	char *ret;
+	switch (vec) {
+	case 0x100:	ret = "(System Reset)"; break; 
+	case 0x200:	ret = "(Machine Check)"; break; 
+	case 0x300:	ret = "(Data Access)"; break; 
+	case 0x400:	ret = "(Instruction Access)"; break; 
+	case 0x500:	ret = "(Hardware Interrupt)"; break; 
+	case 0x600:	ret = "(Alignment)"; break; 
+	case 0x700:	ret = "(Program Check)"; break; 
+	case 0x800:	ret = "(FPU Unavailable)"; break; 
+	case 0x900:	ret = "(Decrementer)"; break; 
+	case 0xc00:	ret = "(System Call)"; break; 
+	case 0xd00:	ret = "(Single Step)"; break; 
+	case 0xf00:	ret = "(Performance Monitor)"; break; 
+	default: ret = "";
+	}
+	return ret;
+}
+
+int
+kdba_halt(int argc, const char **argv, const char **envp, struct pt_regs *fp)
+{
+    kdb_printf("halting machine. ");
+    machine_halt();
+return 0;
+}
+
+
+int
+kdba_excprint(int argc, const char **argv, const char **envp, struct pt_regs *fp)
+{
+	struct task_struct *c;
+	struct tbtable tab;
+
+#ifdef CONFIG_SMP
+	kdb_printf("cpu %d: ", smp_processor_id());
+#endif /* CONFIG_SMP */
+
+	kdb_printf("Vector: %lx %s at  [%p]\n", fp->trap, getvecname(fp->trap), fp);
+	kdb_printf("    pc: %lx", fp->nip);
+	if (find_tb_table(fp->nip, &tab) && tab.name[0]) {
+		/* Got a nice name for it */
+		int delta = fp->nip - tab.funcstart;
+		kdb_printf(" (%s+0x%x)", tab.name, delta);
+	}
+	kdb_printf("\n");
+	kdb_printf("    lr: %lx", fp->link);
+	if (find_tb_table(fp->link, &tab) && tab.name[0]) {
+		/* Got a nice name for it */
+		int delta = fp->link - tab.funcstart;
+		kdb_printf(" (%s+0x%x)", tab.name, delta);
+	}
+	kdb_printf("\n");
+	kdb_printf("    sp: %lx\n", fp->gpr[1]);
+	kdb_printf("   msr: %lx\n", fp->msr);
+
+	if (fp->trap == 0x300 || fp->trap == 0x380 || fp->trap == 0x600) {
+		kdb_printf("   dar: %lx\n", fp->dar);
+		kdb_printf(" dsisr: %lx\n", fp->dsisr);
+	}
+
+	/* XXX: need to copy current or we die.  Why? */
+	c = current;
+	kdb_printf("  current = 0x%p\n", c);
+	kdb_printf("  paca    = 0x%p\n", get_paca());
+	if (c) {
+		kdb_printf("  current = %p, pid = %ld, comm = %s\n",
+		       c, (unsigned long)c->pid, (char *)c->comm);
+	}
+return 0;
+}
+
+
+/* Starting at codeaddr scan forward for a tbtable and fill in the
+ given table.  Return non-zero if successful at doing something.
+ */
+static int
+find_tb_table(unsigned long codeaddr, struct tbtable *tab)
+{
+	unsigned long codeaddr_max;
+	unsigned long tbtab_start;
+	int nr;
+	int instr;
+	int num_parms;
+
+	if (tab == NULL)
+		return 0;
+	memset(tab, 0, sizeof(tab));
+
+	/* Scan instructions starting at codeaddr for 128k max */
+	for (codeaddr_max = codeaddr + 128*1024*4;
+	     codeaddr < codeaddr_max;
+	     codeaddr += 4) {
+	    nr=kdba_readarea_size(codeaddr,&instr,4);
+		if (nr != 4)
+			return 0;	/* Bad read.  Give up promptly. */
+		if (instr == 0) {
+			/* table should follow. */
+			int version;
+			unsigned long flags;
+			tbtab_start = codeaddr;	/* save it to compute func start addr */
+			codeaddr += 4;
+			nr = kdba_readarea_size(codeaddr,&flags,8);
+			if (nr != 8)
+				return 0;	/* Bad read or no tb table. */
+			tab->flags = flags;
+			version = (flags >> 56) & 0xff;
+			if (version != 0)
+				continue;	/* No tb table here. */
+			/* Now, like the version, some of the flags are values
+			 that are more conveniently extracted... */
+			tab->fp_saved = (flags >> 24) & 0x3f;
+			tab->gpr_saved = (flags >> 16) & 0x3f;
+			tab->fixedparms = (flags >> 8) & 0xff;
+			tab->floatparms = (flags >> 1) & 0x7f;
+			codeaddr += 8;
+			num_parms = tab->fixedparms + tab->floatparms;
+			if (num_parms) {
+				unsigned int parminfo;
+				int parm;
+				if (num_parms > 32)
+					return 1;	/* incomplete */
+				nr = kdba_readarea_size(codeaddr,&parminfo,4);
+				if (nr != 4)
+					return 1;	/* incomplete */
+				/* decode parminfo...32 bits.
+				 A zero means fixed.  A one means float and the
+				 following bit determines single (0) or double (1).
+				 */
+				for (parm = 0; parm < num_parms; parm++) {
+					if (parminfo & 0x80000000) {
+						parminfo <<= 1;
+						if (parminfo & 0x80000000)
+							tab->parminfo[parm] = TBTAB_PARMDFLOAT;
+						else
+							tab->parminfo[parm] = TBTAB_PARMSFLOAT;
+					} else {
+						tab->parminfo[parm] = TBTAB_PARMFIXED;
+					}
+					parminfo <<= 1;
+				}
+				codeaddr += 4;
+			}
+			if (flags & TBTAB_FLAGSHASTBOFF) {
+			    nr = kdba_readarea_size(codeaddr,&tab->tb_offset,4);
+				if (nr != 4)
+					return 1;	/* incomplete */
+				if (tab->tb_offset > 0) {
+					tab->funcstart = tbtab_start - tab->tb_offset;
+				}
+				codeaddr += 4;
+			}
+			/* hand_mask appears to be always be omitted. */
+			if (flags & TBTAB_FLAGSHASCTL) {
+				/* Assume this will never happen for C or asm */
+				return 1;	/* incomplete */
+			}
+			if (flags & TBTAB_FLAGSNAMEPRESENT) {
+				short namlen;
+				nr = kdba_readarea_size(codeaddr,&namlen,2);
+				if (nr != 2)
+					return 1;	/* incomplete */
+				if (namlen >= sizeof(tab->name))
+					namlen = sizeof(tab->name)-1;
+				codeaddr += 2;
+				nr = kdba_readarea_size(codeaddr,tab->name,namlen);
+				tab->name[namlen] = '\0';
+				codeaddr += namlen;
+			}
+			return 1;
+		}
+	}
+	return 0;	/* hit max...sorry. */
+}
+
+
+int
+kdba_dissect_msr(int argc, const char **argv, const char **envp, struct pt_regs *regs)
+{
+   long int msr;
+
+   if (argc==0)
+       msr = regs->msr;
+/*       msr = get_msr(); */
+    else 
+	kdbgetularg(argv[1], &msr);
+
+   kdb_printf("msr: %lx (",msr);
+   {
+       if (msr & MSR_SF)   kdb_printf("SF ");
+       if (msr & MSR_ISF)  kdb_printf("ISF ");
+       if (msr & MSR_HV)   kdb_printf("HV ");
+       if (msr & MSR_VEC)  kdb_printf("VEC ");
+       if (msr & MSR_POW)  kdb_printf("POW/");  /* pow/we share */
+       if (msr & MSR_WE)   kdb_printf("WE ");
+       if (msr & MSR_TGPR) kdb_printf("TGPR/"); /* tgpr/ce share */
+       if (msr & MSR_CE)   kdb_printf("CE ");
+       if (msr & MSR_ILE)  kdb_printf("ILE ");
+       if (msr & MSR_EE)   kdb_printf("EE ");
+       if (msr & MSR_PR)   kdb_printf("PR ");
+       if (msr & MSR_FP)   kdb_printf("FP ");
+       if (msr & MSR_ME)   kdb_printf("ME ");
+       if (msr & MSR_FE0)  kdb_printf("FE0 ");
+       if (msr & MSR_SE)   kdb_printf("SE ");
+       if (msr & MSR_BE)   kdb_printf("BE/");   /* be/de share */
+       if (msr & MSR_DE)   kdb_printf("DE ");
+       if (msr & MSR_FE1)  kdb_printf("FE1 ");
+       if (msr & MSR_IP)   kdb_printf("IP ");
+       if (msr & MSR_IR)   kdb_printf("IR ");
+       if (msr & MSR_DR)   kdb_printf("DR ");
+       if (msr & MSR_PE)   kdb_printf("PE ");
+       if (msr & MSR_PX)   kdb_printf("PX ");
+       if (msr & MSR_RI)   kdb_printf("RI ");
+       if (msr & MSR_LE)   kdb_printf("LE ");
+   }
+   kdb_printf(")\n");
+
+   if (msr & MSR_SF)   kdb_printf(" 64 bit mode enabled \n");
+   if (msr & MSR_ISF)  kdb_printf(" Interrupt 64b mode valid on 630 \n");
+   if (msr & MSR_HV)   kdb_printf(" Hypervisor State \n");
+   if (msr & MSR_VEC)  kdb_printf(" Enable Altivec \n");
+   if (msr & MSR_POW)  kdb_printf(" Enable Power Management  \n");
+   if (msr & MSR_WE)   kdb_printf(" Wait State Enable   \n");
+   if (msr & MSR_TGPR) kdb_printf(" TLB Update registers in use   \n");
+   if (msr & MSR_CE)   kdb_printf(" Critical Interrupt Enable   \n");
+   if (msr & MSR_ILE)  kdb_printf(" Interrupt Little Endian   \n");
+   if (msr & MSR_EE)   kdb_printf(" External Interrupt Enable   \n");
+   if (msr & MSR_PR)   kdb_printf(" Problem State / Privilege Level  \n"); 
+   if (msr & MSR_FP)   kdb_printf(" Floating Point enable   \n");
+   if (msr & MSR_ME)   kdb_printf(" Machine Check Enable   \n");
+   if (msr & MSR_FE0)  kdb_printf(" Floating Exception mode 0  \n"); 
+   if (msr & MSR_SE)   kdb_printf(" Single Step   \n");
+   if (msr & MSR_BE)   kdb_printf(" Branch Trace   \n");
+   if (msr & MSR_DE)   kdb_printf(" Debug Exception Enable   \n");
+   if (msr & MSR_FE1)  kdb_printf(" Floating Exception mode 1   \n");
+   if (msr & MSR_IP)   kdb_printf(" Exception prefix 0x000/0xFFF   \n");
+   if (msr & MSR_IR)   kdb_printf(" Instruction Relocate   \n");
+   if (msr & MSR_DR)   kdb_printf(" Data Relocate   \n");
+   if (msr & MSR_PE)   kdb_printf(" Protection Enable   \n");
+   if (msr & MSR_PX)   kdb_printf(" Protection Exclusive Mode   \n");
+   if (msr & MSR_RI)   kdb_printf(" Recoverable Exception   \n");
+   if (msr & MSR_LE)   kdb_printf(" Little Endian   \n");
+   kdb_printf(".\n");
+
+return 0;
+}
+
+int
+kdba_super_regs(int argc, const char **argv, const char **envp, struct pt_regs *regs){
+	int i;
+	struct paca_struct*  ptrPaca = NULL;
+	struct ItLpPaca*  ptrLpPaca = NULL;
+	struct ItLpRegSave*  ptrLpRegSave = NULL;
+
+	{
+	        unsigned long sp, toc;
+		kdb_printf("sr::");
+		asm("mr %0,1" : "=r" (sp) :);
+		asm("mr %0,2" : "=r" (toc) :);
+
+		kdb_printf("msr  = %.16lx  sprg0= %.16lx\n", get_msr(), get_sprg0());
+		kdb_printf("pvr  = %.16lx  sprg1= %.16lx\n", get_pvr(), get_sprg1()); 
+		kdb_printf("dec  = %.16lx  sprg2= %.16lx\n", get_dec(), get_sprg2());
+		kdb_printf("sp   = %.16lx  sprg3= %.16lx\n", sp, get_sprg3());
+		kdb_printf("toc  = %.16lx  dar  = %.16lx\n", toc, get_dar());
+		kdb_printf("srr0 = %.16lx  srr1 = %.16lx\n", get_srr0(), get_srr1());
+		kdb_printf("asr  = %.16lx\n", mfasr());
+		for (i = 0; i < 8; ++i)
+			kdb_printf("sr%.2ld = %.16lx  sr%.2ld = %.16lx\n", (long int)i, (unsigned long)get_sr(i), (long int)(i+8), (long unsigned int) get_sr(i+8));
+
+		// Dump out relevant Paca data areas.
+		kdb_printf("Paca: \n");
+		ptrPaca = (struct paca_struct*)get_sprg3();
+    
+		kdb_printf("  Local Processor Control Area (LpPaca): \n");
+		ptrLpPaca = ptrPaca->xLpPacaPtr;
+		kdb_printf("    Saved Srr0=%.16lx  Saved Srr1=%.16lx \n", ptrLpPaca->xSavedSrr0, ptrLpPaca->xSavedSrr1);
+		kdb_printf("    Saved Gpr3=%.16lx  Saved Gpr4=%.16lx \n", ptrLpPaca->xSavedGpr3, ptrLpPaca->xSavedGpr4);
+		kdb_printf("    Saved Gpr5=%.16lx \n", ptrLpPaca->xSavedGpr5);
+    
+		kdb_printf("  Local Processor Register Save Area (LpRegSave): \n");
+		ptrLpRegSave = ptrPaca->xLpRegSavePtr;
+		kdb_printf("    Saved Sprg0=%.16lx  Saved Sprg1=%.16lx \n", ptrLpRegSave->xSPRG0, ptrLpRegSave->xSPRG0);
+		kdb_printf("    Saved Sprg2=%.16lx  Saved Sprg3=%.16lx \n", ptrLpRegSave->xSPRG2, ptrLpRegSave->xSPRG3);
+		kdb_printf("    Saved Msr  =%.16lx  Saved Nia  =%.16lx \n", ptrLpRegSave->xMSR, ptrLpRegSave->xNIA);
+    
+		return 0;
+	} 
+}
+
+
+
+	
+int
+kdba_dump_tce_table(int argc, const char **argv, const char **envp, struct pt_regs *regs){
+    struct TceTable kt; 
+    long tce_table_address;
+    int nr;
+    int i,j,k;
+    int full,empty;
+    int fulldump=0;
+    u64 mapentry;
+    int totalpages;
+    int levelpages;
+
+    if (argc == 0) {
+	kdb_printf("need address\n");
+	return 0;
+    }
+    else 
+	kdbgetularg(argv[1], &tce_table_address);
+
+    if (argc==2)
+	if (strcmp(argv[2], "full") == 0) 
+	    fulldump=1;
+
+    /* with address, read contents of memory and dump tce table. */
+    /* possibly making some assumptions on the depth and size of table..*/
+
+    nr = kdba_readarea_size(tce_table_address+0 ,&kt.busNumber,8);
+    nr = kdba_readarea_size(tce_table_address+8 ,&kt.size,8);
+    nr = kdba_readarea_size(tce_table_address+16,&kt.startOffset,8);
+    nr = kdba_readarea_size(tce_table_address+24,&kt.base,8);
+    nr = kdba_readarea_size(tce_table_address+32,&kt.index,8);
+    nr = kdba_readarea_size(tce_table_address+40,&kt.tceType,8);
+    nr = kdba_readarea_size(tce_table_address+48,&kt.lock,8);
+
+    kdb_printf("\n");
+    kdb_printf("TceTable at address %s:\n",argv[1]);
+    kdb_printf("BusNumber:   0x%x \n",(uint)kt.busNumber);
+    kdb_printf("size:        0x%x \n",(uint)kt.size);
+    kdb_printf("startOffset: 0x%x \n",(uint)kt.startOffset);
+    kdb_printf("base:        0x%x \n",(uint)kt.base);
+    kdb_printf("index:       0x%x \n",(uint)kt.index);
+    kdb_printf("tceType:     0x%x \n",(uint)kt.tceType);
+#ifdef CONFIG_SMP
+    kdb_printf("lock:        0x%x \n",(uint)kt.lock.lock);
+#endif
+
+    nr = kdba_readarea_size(tce_table_address+56,&kt.mlbm.maxLevel,8);
+    kdb_printf(" maxLevel:        0x%x \n",(uint)kt.mlbm.maxLevel);
+    totalpages=0;
+    for (i=0;i<NUM_TCE_LEVELS;i++) {
+	nr = kdba_readarea_size(tce_table_address+64+i*24,&kt.mlbm.level[i].numBits,8);
+	nr = kdba_readarea_size(tce_table_address+72+i*24,&kt.mlbm.level[i].numBytes,8);
+	nr = kdba_readarea_size(tce_table_address+80+i*24,&kt.mlbm.level[i].map,8);
+	kdb_printf("   level[%d]\n",i);
+	kdb_printf("   numBits:   0x%x\n",(uint)kt.mlbm.level[i].numBits);
+	kdb_printf("   numBytes:  0x%x\n",(uint)kt.mlbm.level[i].numBytes);
+	kdb_printf("   map*:      %p\n",kt.mlbm.level[i].map);
+
+	 /* if these dont match, this might not be a valid tce table, so
+	    dont try to iterate the map entries. */
+	if (kt.mlbm.level[i].numBits == 8*kt.mlbm.level[i].numBytes) {
+	    full=0;empty=0;levelpages=0;
+	    for (j=0;j<kt.mlbm.level[i].numBytes; j++) {
+		mapentry=0;
+		nr = kdba_readarea_size((long int)(kt.mlbm.level[i].map+j),&mapentry,1);
+		if (mapentry)
+		    full++;
+		else
+		    empty++;
+		if (mapentry && fulldump) {
+		    kdb_printf("0x%lx\n",mapentry);
+		}
+		for (k=0;(k<=64) && ((0x1UL<<k) <= mapentry);k++) {
+		    if ((0x1UL<<k) & mapentry) levelpages++;
+		}
+	    }
+	    kdb_printf("      full:0x%x empty:0x%x pages:0x%x\n",full,empty,levelpages);
+	} else {
+	    kdb_printf("      numBits/numBytes mismatch..? \n");
+	}
+	totalpages+=levelpages;
+    }
+    kdb_printf("      Total pages:0x%x\n",totalpages);
+    kdb_printf("\n");
+    return 0;
+}
+
+int
+kdba_kernelversion(int argc, const char **argv, const char **envp, struct pt_regs *regs){
+    extern char *linux_banner;
+
+    kdb_printf("%s\n",linux_banner);
+
+    return 0;
+}
+
+/* this function obsoleted with newer kdb-common patch */
+int
+kdba_dmesg(int argc, const char **argv, const char **envp, struct pt_regs *regs){
+    kdb_symtab_t   symtab;
+    long log_buf_addr=0;
+    long log_start_addr=0;
+    int nr;                 
+    unsigned long default_lines;   /* number of lines to read */
+    long index_into_log_buf; /* pointer into log_buf */
+    long saved_index;  /* saved pointer into log_buf */
+    char current_char; /* temp char value */
+    int line_count=0;  /* temp counter for # lines*/
+    long log_size;  /* size of log_buf */
+    int wrapped; 
+
+    if (argc == 0)
+	default_lines=25; 
+    else 
+	kdbgetularg(argv[1], &default_lines);
+
+    log_buf_addr = kdbgetsymval("log_buf", &symtab);
+    if (log_buf_addr) {
+	log_buf_addr = symtab.sym_start;
+    } else {
+	kdb_printf("log_buf symbol not found! Can't do dmesg.\n");
+	return 0;
+    }
+    log_start_addr = kdbgetsymval("log_start", &symtab);
+    if (log_start_addr) {
+	log_start_addr = symtab.sym_start;
+    } else {
+	kdb_printf("log_start symbol not found! Can't do dmesg.\n");
+	return 0;
+    }
+
+    log_size = log_start_addr - log_buf_addr;
+
+    nr = kdba_readarea_size(log_start_addr,&index_into_log_buf,8);
+
+    saved_index=index_into_log_buf;
+    if (index_into_log_buf > log_size ) {
+	wrapped=1;
+    } else {
+	wrapped=0;
+    }
+
+    while ((index_into_log_buf > 0 ) && (line_count <= default_lines)) {
+	nr = kdba_readarea_size(log_buf_addr+(index_into_log_buf%log_size),&current_char,1);
+	if (current_char == 0x0a ) {
+	    line_count++;
+	}	
+	index_into_log_buf--;
+    }
+
+    if (line_count < default_lines ) {
+	kdb_printf("Something went wrong trying to count %ld lines\n",default_lines);
+    }
+
+    while ((index_into_log_buf < saved_index+1) && line_count >= 0 ) {
+	nr = kdba_readarea_size(log_buf_addr+index_into_log_buf%log_size,&current_char,1);
+	kdb_printf("%c",current_char);
+	if (current_char == 0x0a) line_count--;
+	index_into_log_buf++;
+    }
+
+    return 0; 
+}
+
+
+static void * 
+kdba_dump_pci(struct device_node *dn, void *data)
+{
+    struct pci_controller *phb;
+    char *device_type;
+    char *status;
+
+    phb = (struct pci_controller *)data;
+    device_type = get_property(dn, "device_type", 0);
+    status = get_property(dn, "status", 0);
+
+    dn->phb = phb;
+    kdb_printf("dn:   %p \n",dn);
+    kdb_printf("    phb      : %p\n",dn->phb);
+    kdb_printf("    name     : %s\n",dn->name);
+    kdb_printf("    full_name: %s\n",dn->full_name);
+    kdb_printf("    busno    : 0x%x\n",dn->busno);
+    kdb_printf("    devfn    : 0x%x\n",dn->devfn);
+    kdb_printf("    tce_table: %p\n",dn->tce_table);
+    return NULL;
+}
+
+int
+kdba_dump_pci_info(int argc, const char **argv, const char **envp, struct pt_regs *regs){
+
+    kdb_printf("kdba_dump_pci_info\n");
+
+/* call this traverse function with my function pointer.. it takes care of traversing, my func just needs to parse the device info.. */
+    traverse_all_pci_devices(kdba_dump_pci);
+    return 0;
+}
+
+
+char *kdb_dumpall_cmds[] = {
+    "excp\n",
+    "bt\n",
+    "rd\n",
+    "dmesg\n",
+    "msr\n",
+    "superreg\n",
+    "pci_info\n",
+    "ps\n",
+    "cpu\n",
+    "set BTAPROMPT=none\n",
+    "bta\n",
+    0
+};
+
+char *kdb_dumpbasic_cmds[] = {
+    "excp\n",
+    "bt\n",
+    "rd\n",
+    "dmesg 25\n",
+    "msr\n",
+    "superreg\n",
+    "ps\n",
+    "cpu\n",
+    0
+};
+
+
+/* dump with "all" parm will dump all.  all other variations dump basic.  See the dump*_cmds defined above */
+int
+kdba_dump(int argc, const char **argv, const char **envp, struct pt_regs *fp)
+{
+    int i, diag;
+    kdb_printf("dump-all\n");
+    if ((argc==1)&& (strcmp(argv[1], "all")==0))	{
+	for (i = 0; kdb_dumpall_cmds[i]; ++i) {
+	    kdb_printf("kdb_cmd[%d]%s: %s",
+		       i, " ", kdb_dumpall_cmds[i]);
+	    diag = kdb_parse(kdb_dumpall_cmds[i], fp);
+	    if (diag)
+		kdb_printf("command failed, kdb diag %d\n", diag);
+	}
+    } else {
+	kdb_printf("dump-basic\n");
+	for (i = 0; kdb_dumpbasic_cmds[i]; ++i) {
+	    kdb_printf("kdb_cmd[%d]%s: %s",
+		       i, " ", kdb_dumpbasic_cmds[i]);
+	    diag = kdb_parse(kdb_dumpbasic_cmds[i], fp);
+	    if (diag)
+		kdb_printf("command failed, kdb diag %d\n", diag);
+	}
+    }
+    return 0;
+}
+
+
+/* Toggle the ppcdbg options.   kdb_parse tokenizes the parms, so need to account for that here.  */
+int
+kdba_ppcdbg(int argc, const char **argv, const char **envp, struct pt_regs *fp) {
+    extern char *trace_names[PPCDBG_NUM_FLAGS];
+
+    int i,j;
+    unsigned long mask;
+    int onoff;
+    if (argc==0)
+	goto ppcdbg_exit;
+
+    for (i=1;i<=argc;i++) {
+	onoff = 1;	/* default */
+	if (argv[i][0] == '+' || argv[i][0] == '-') {
+			/* explicit on or off */
+	    onoff = (argv[i][0] == '+');
+	    argv[i]++;
+	}
+
+	for (j=0;j<PPCDBG_NUM_FLAGS;j++) {
+	    if (trace_names[j] && strcmp(trace_names[j],argv[i])==0) {
+		/* have a match */
+		mask = (1 << j);
+		/* check special case */
+		if (strcmp(argv[i],"all")==0) {
+		    mask = PPCDBG_ALL;
+		}
+		if (mask) {
+		    if (onoff)
+			naca->debug_switch |= mask;
+		    else
+			naca->debug_switch &= ~mask;
+		}
+	    } 
+	}
+    }
+    ppcdbg_exit:
+      kdb_printf("naca->debug_switch 0x%lx\n",naca->debug_switch);
+    return 0;
+}
+
+/* enable or disable surveillance.. based on rtasd.c function.
+  no arguments - display current timeout value.
+  one argument - 'off' or '0' turn off surveillance.
+               - '1-255' set surveillance timeout to argument. */
+int
+kdba_surveillance(int argc, const char **argv, const char **envp, struct pt_regs *fp)
+{
+    unsigned long timeout;
+    int ibm_indicator_token = 9000;
+    int error;
+    unsigned long ret;
+
+    if (argc==0) {
+	goto surveillance_status;
+    } else if (((argc==1)&& (strcmp(argv[1], "off")==0))) {
+	timeout=0;
+    } else {
+	kdbgetularg(argv[1], &timeout);
+    }
+
+    error = rtas_call(rtas_token("set-indicator"), 3, 1, &ret,
+		      ibm_indicator_token, 0, timeout);
+    /*    kdb_printf("Surveillance set-indicator returned value: 0x%x\n",ret); */
+
+    if (error) 
+	kdb_printf("surveillance rtas_call failure 0x%x \n",error);
+
+    surveillance_status:
+      rtas_call(rtas_token("get-sensor-state"), 2, 2, &ret, 
+		ibm_indicator_token, 
+		0/* instance */);
+    kdb_printf("Current surveillance timeout is %ld minutes%s",ret,
+	       ret==0?" (disabled).\n":".\n");
+    return 0;
+}
+
+/* generic debugger() hooks into kdb.  These eliminate the need to add
+  ifdef CONFIG_KDB goop to traps.c and fault.c */
+
+void
+kdb_reset_debugger(struct pt_regs *regs) {
+    int cpu=smp_processor_id();
+    static int reset_cpu = -1;
+    static spinlock_t reset_lock = SPIN_LOCK_UNLOCKED;
+    spin_lock(&reset_lock);
+    if (reset_cpu == -1 || reset_cpu == cpu) {
+	reset_cpu = cpu;
+	spin_unlock(&reset_lock);
+	if (kdb_on) {
+	    ppc64_attention_msg(0x3200+cpu,"KDB Call        ");
+	    kdb(KDB_REASON_ENTER, regs->trap, (kdb_eframe_t) regs);
+	    ppc64_attention_msg(0x3300+cpu,"KDB Done        ");
+	} else {
+	    kdb_on=1;
+	    kdb_do_reboot=1;
+	    ppc64_attention_msg(0x3600+cpu,"KDB Enabled     ");
+	    udelay(KDB_RESET_TIMEOUT);
+	    kdb_on=0;
+	    if (kdb_do_reboot) {
+		ppc64_attention_msg(0x3900+cpu,"Rebooting       ");
+		ppc_md.restart("rebooting...");
+		return;	/* not reached */
+	    } else {
+		ppc64_attention_msg(0x3800+cpu,"KDB skip reboot ");
+		return;
+	    }
+	}
+    } else {
+	spin_unlock(&reset_lock);
+	return;
+    }
+}
+
+void
+kdb_debugger(struct pt_regs *regs) {
+    if (regs)
+	if (regs->trap==0x100) {
+	    kdb_reset_debugger(regs);
+	} else
+	    kdb(KDB_REASON_ENTER,regs->trap,regs);   /* ok */
+    else  /* regs invalid */
+	kdb(KDB_REASON_SILENT,0,regs);
+}
+
+int
+kdb_debugger_bpt(struct pt_regs *regs) {
+    if (regs)
+	return kdb(KDB_REASON_BREAK,regs->trap,regs);
+    else  /* regs invalid */
+	return kdb(KDB_REASON_SILENT,0,regs);
+}
+
+int
+kdb_debugger_sstep(struct pt_regs *regs) {
+    if (regs)
+	return kdb(KDB_REASON_DEBUG,regs->trap,regs); /* ok */
+    else  /* regs invalid */
+	return kdb(KDB_REASON_SILENT,0,regs);
+}
+
+int
+kdb_debugger_iabr_match(struct pt_regs *regs) {
+    if (regs)
+	return kdb(KDB_REASON_BREAK,regs->trap,regs);
+    else  /* regs invalid */
+	return kdb(KDB_REASON_SILENT,0,regs);
+}
+
+int
+kdb_debugger_dabr_match(struct pt_regs *regs) {
+    if (regs)
+	return kdb(KDB_REASON_BREAK,regs->trap,regs);
+    else  /* regs invalid */
+	return kdb(KDB_REASON_SILENT,0,regs);
+}
+
+void
+kdb_debugger_fault_handler(struct pt_regs *regs) {
+    if (regs)
+	kdb(KDB_REASON_FAULT,regs->trap,regs);
+    else  /* regs invalid */
+	kdb(KDB_REASON_SILENT,0,regs);
+    return;
+}
+
+
+
+int
+kdba_state(int argc, const char **argv, const char **envp, struct pt_regs *fp)
+{
+    int i;
+    for (i=0;i<NR_CPUS;i++) {
+	if ( kdb_state[i] != 0 ) {
+	    kdb_printf("kdb_state[%d] = %x" ,i,kdb_state[i]);
+	    kdb_printf(" [");
+	    if KDB_STATE_CPU(KDB,i) kdb_printf("KDB,");
+	    if KDB_STATE_CPU(LEAVING,i) kdb_printf("LEAVING,");
+	    if KDB_STATE_CPU(CMD,i) kdb_printf("CMD,");
+	    if KDB_STATE_CPU(KDB_CONTROL,i) kdb_printf("KDB_CONTROL,");
+	    if KDB_STATE_CPU(HOLD_CPU,i) kdb_printf("HOLD_CPU,");
+	    if KDB_STATE_CPU(DOING_SS,i) kdb_printf("DOING_SS,");
+	    if KDB_STATE_CPU(DOING_SSB,i) kdb_printf("DOING_SSB,");
+	    if KDB_STATE_CPU(SSBPT,i) kdb_printf("SSBPT,");
+	    if KDB_STATE_CPU(REENTRY,i) kdb_printf("REENTRY,");
+	    if KDB_STATE_CPU(SUPPRESS,i) kdb_printf("SUPPRESS,");
+	    if KDB_STATE_CPU(LONGJMP,i) kdb_printf("LONGJMP,");
+	    if KDB_STATE_CPU(PRINTF_LOCK,i) kdb_printf("PRINTF_LOCK,");
+	    if KDB_STATE_CPU(WAIT_IPI,i) kdb_printf("WAIT_IPI,");
+	    if KDB_STATE_CPU(RECURSE,i) kdb_printf("RECURSE,");
+	    if KDB_STATE_CPU(IP_ADJUSTED,i) kdb_printf("IP_ADJUSTED,");
+	    if KDB_STATE_CPU(NO_BP_DELAY,i) kdb_printf("NO_BP_DELAY");
+	    kdb_printf("]\n");
+	}
+    }
+return 0;
+}
+
+
+/*
+ * kdba_init
+ * 	Architecture specific initialization.
+ */
+/*
+kdb_register("commandname",              # name of command user will use to invoke function  
+             function_name,              # name of function within the code 
+             "function example usage",   # sample usage 
+             "function description",     # brief description. 
+             0                           # if i hit enter again, will command repeat itself ?
+Note: functions must take parameters as such:
+functionname(int argc, const char **argv, const char **envp, struct pt_regs *regs)
+*/
+
+void __init
+kdba_init(void)
+{
+#ifdef CONFIG_MAGIC_SYSRQ
+	kdb_map_scc();		/* map sysrq key */
+#endif
+
+	debugger = kdb_debugger;
+	debugger_bpt = kdb_debugger_bpt;
+	debugger_sstep = kdb_debugger_sstep;
+	debugger_iabr_match = kdb_debugger_iabr_match;
+	debugger_dabr_match = kdb_debugger_dabr_match;
+	debugger_fault_handler = NULL; /* this guy is normally off. */
+				    /* = kdb_debugger_fault_handler; */
+
+	kdba_enable_lbr();
+	kdb_register("excp", kdba_excprint, "excp", "print exception info", 0);
+	kdb_register("superreg", kdba_super_regs, "superreg", "display super_regs", 0);
+	kdb_register("msr", kdba_dissect_msr, "msr", "dissect msr", 0);
+	kdb_register("halt", kdba_halt, "halt", "halt machine", 0);
+	kdb_register("tce_table", kdba_dump_tce_table, "tce_table <addr> [full]", "dump the tce table located at <addr>", 0);
+	kdb_register("kernel", kdba_kernelversion, "version", "display running kernel version", 0);
+	kdb_register("_dmesg", kdba_dmesg, "dmesg <lines>", "display lines from dmesg (log_buf) buffer", 0);
+	kdb_register("pci_info", kdba_dump_pci_info, "dump_pci_info", "dump pci device info", 0);
+	kdb_register("dump", kdba_dump, "dump (all|basic)", "dump all info", 0); 
+	kdb_register("state", kdba_state, "state ", "dump state of all processors", 0); 
+	kdb_register("surv", kdba_surveillance, "surv [off|1-255] ", "disable/change surveillance timeout", 0); 
+	kdb_register("ppcdbg", kdba_ppcdbg, "ppcdbg (a,+b,-c)","toggle PPCDBG options",0);
+	if (!ppc_md.udbg_getc_poll)
+		kdb_on = 0;
+}
diff -purN linux-2.5/arch/ppc64/kdb/opintl.h linuxppc64-2.5/arch/ppc64/kdb/opintl.h
--- linux-2.5/arch/ppc64/kdb/opintl.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/opintl.h	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,42 @@
+/* opintl.h - opcodes specific header for gettext code.
+   Copyright (C) 1998, 1999 Free Software Foundation, Inc.
+
+   Written by Tom Tromey <tromey@cygnus.com>
+
+   This file is part of the opcodes library used by GAS and the GNU binutils.
+
+   You should have received a copy of the GNU General Public License
+   along with GAS; see the file COPYING.  If not, write to the Free
+   Software Foundation, 59 Temple Place - Suite 330, Boston, MA
+   02111-1307, USA. */
+
+#ifdef ENABLE_NLS
+# include <libintl.h>
+/* Note the use of dgetext() and PACKAGE here, rather than gettext().
+   
+   This is because the code in this directory is used to build a library which
+   will be linked with code in other directories to form programs.  We want to
+   maintain a seperate translation file for this directory however, rather
+   than being forced to merge it with that of any program linked to
+   libopcodes.  This is a library, so it cannot depend on the catalog
+   currently loaded.
+
+   In order to do this, we have to make sure that when we extract messages we
+   use the OPCODES domain rather than the domain of the program that included
+   the opcodes library, (eg OBJDUMP).  Hence we use dgettext (PACKAGE, String)
+   and define PACKAGE to be 'opcodes'.  (See the code in configure).  */
+# define _(String) dgettext (PACKAGE, String)
+# ifdef gettext_noop
+#  define N_(String) gettext_noop (String)
+# else
+#  define N_(String) (String)
+# endif
+#else
+# define gettext(Msgid) (Msgid)
+# define dgettext(Domainname, Msgid) (Msgid)
+# define dcgettext(Domainname, Msgid, Category) (Msgid)
+# define textdomain(Domainname) while (0) /* nothing */
+# define bindtextdomain(Domainname, Dirname) while (0) /* nothing */
+# define _(String) (String)
+# define N_(String) (String)
+#endif
diff -purN linux-2.5/arch/ppc64/kdb/ppc-dis.c linuxppc64-2.5/arch/ppc64/kdb/ppc-dis.c
--- linux-2.5/arch/ppc64/kdb/ppc-dis.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/ppc-dis.c	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,281 @@
+/* ppc-dis.c -- Disassemble PowerPC instructions
+   Copyright 1994 Free Software Foundation, Inc.
+   Written by Ian Lance Taylor, Cygnus Support
+
+This file is part of GDB, GAS, and the GNU binutils.
+
+GDB, GAS, and the GNU binutils are free software; you can redistribute
+them and/or modify them under the terms of the GNU General Public
+License as published by the Free Software Foundation; either version
+2, or (at your option) any later version.
+
+GDB, GAS, and the GNU binutils are distributed in the hope that they
+will be useful, but WITHOUT ANY WARRANTY; without even the implied
+warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+the GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this file; see the file COPYING.  If not, write to the Free
+Software Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  */
+#ifdef __KERNEL__
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/dis-asm.h>
+#include <linux/kdb.h>
+#include "ppc.h"
+
+#if 0
+#include <setjmp.h>
+#endif
+
+#else
+#include <stdio.h>
+#include "sysdep.h"
+#include "dis-asm.h"
+#include "opcode/ppc.h"
+#endif
+bfd_vma
+bfd_getb32 (addr)
+     register const bfd_byte *addr;
+{
+  unsigned long v;
+
+  v = (unsigned long) addr[0] << 24;
+  v |= (unsigned long) addr[1] << 16;
+  v |= (unsigned long) addr[2] << 8;
+  v |= (unsigned long) addr[3];
+  return (bfd_vma) v;
+}
+
+bfd_vma
+bfd_getl32 (addr)
+     register const bfd_byte *addr;
+{
+  unsigned long v;
+
+  v = (unsigned long) addr[0];
+  v |= (unsigned long) addr[1] << 8;
+  v |= (unsigned long) addr[2] << 16;
+  v |= (unsigned long) addr[3] << 24;
+  return (bfd_vma) v;
+}
+/* This file provides several disassembler functions, all of which use
+   the disassembler interface defined in dis-asm.h.  Several functions
+   are provided because this file handles disassembly for the PowerPC
+   in both big and little endian mode and also for the POWER (RS/6000)
+   chip.  */
+
+static int print_insn_powerpc PARAMS ((bfd_vma, struct disassemble_info *,
+				       int bigendian, int dialect));
+
+/* Print a big endian PowerPC instruction.  For convenience, also
+   disassemble instructions supported by the Motorola PowerPC 601
+   and the Altivec vector unit.  */
+
+int
+print_insn_big_powerpc (memaddr, info)
+     bfd_vma memaddr;
+     struct disassemble_info *info;
+{
+  return print_insn_powerpc (memaddr, info, 1,
+			     PPC_OPCODE_PPC | PPC_OPCODE_601 |
+			     PPC_OPCODE_ALTIVEC);
+}
+
+/* Print a little endian PowerPC instruction.  For convenience, also
+   disassemble instructions supported by the Motorola PowerPC 601
+   and the Altivec vector unit.  */
+
+int
+print_insn_little_powerpc (memaddr, info)
+     bfd_vma memaddr;
+     struct disassemble_info *info;
+{
+  return print_insn_powerpc (memaddr, info, 0,
+			     PPC_OPCODE_PPC | PPC_OPCODE_601 |
+			     PPC_OPCODE_ALTIVEC);
+}
+
+/* Print a POWER (RS/6000) instruction.  */
+
+int
+print_insn_rs6000 (memaddr, info)
+     bfd_vma memaddr;
+     struct disassemble_info *info;
+{
+  return print_insn_powerpc (memaddr, info, 1, PPC_OPCODE_POWER);
+}
+
+/* Print a PowerPC or POWER instruction.  */
+
+static int
+print_insn_powerpc (memaddr, info, bigendian, dialect)
+     bfd_vma memaddr;
+     struct disassemble_info *info;
+     int bigendian;
+     int dialect;
+{
+  bfd_byte buffer[4];
+  int status;
+  unsigned long insn;
+  const struct powerpc_opcode *opcode;
+  const struct powerpc_opcode *opcode_end;
+  unsigned long op;
+
+  (*info->fprintf_func) (info->stream, "  ");
+
+  status = (*info->read_memory_func) (memaddr, buffer, 4, info);
+  if (status != 0)
+    {
+      (*info->memory_error_func) (status, memaddr, info);
+      return -1;
+    }
+
+  if (bigendian)
+    insn = bfd_getb32 (buffer);
+  else
+    insn = bfd_getl32 (buffer);
+
+  /* Get the major opcode of the instruction.  */
+  op = PPC_OP (insn);
+
+  /* Find the first match in the opcode table.  We could speed this up
+     a bit by doing a binary search on the major opcode.  */
+  opcode_end = powerpc_opcodes + powerpc_num_opcodes;
+  for (opcode = powerpc_opcodes; opcode < opcode_end; opcode++)
+    {
+      unsigned long table_op;
+      const unsigned char *opindex;
+      const struct powerpc_operand *operand;
+      int invalid;
+      int need_comma;
+      int need_paren;
+
+      table_op = PPC_OP (opcode->opcode);
+      if (op < table_op)
+	break;
+      if (op > table_op)
+	continue;
+
+      if ((insn & opcode->mask) != opcode->opcode
+	  || (opcode->flags & dialect) == 0)
+	continue;
+
+      /* Make two passes over the operands.  First see if any of them
+	 have extraction functions, and, if they do, make sure the
+	 instruction is valid.  */
+      invalid = 0;
+      for (opindex = opcode->operands; *opindex != 0; opindex++)
+	{
+	  operand = powerpc_operands + *opindex;
+	  if (operand->extract)
+	    (*operand->extract) (insn, &invalid);
+	}
+      if (invalid)
+	continue;
+
+      /* The instruction is valid.  */
+      (*info->fprintf_func) (info->stream, "%-6s", opcode->name);
+      if (opcode->operands[0] != 0)
+	(*info->fprintf_func) (info->stream, "\t");
+
+      /* Now extract and print the operands.  */
+      need_comma = 0;
+      need_paren = 0;
+      for (opindex = opcode->operands; *opindex != 0; opindex++)
+	{
+	  long value;
+
+	  operand = powerpc_operands + *opindex;
+
+	  /* Operands that are marked FAKE are simply ignored.  We
+	     already made sure that the extract function considered
+	     the instruction to be valid.  */
+	  if ((operand->flags & PPC_OPERAND_FAKE) != 0)
+	    continue;
+
+	  /* Extract the value from the instruction.  */
+	  if (operand->extract)
+	    value = (*operand->extract) (insn, (int *) NULL);
+	  else
+	    {
+	      value = (insn >> operand->shift) & ((1 << operand->bits) - 1);
+	      if ((operand->flags & PPC_OPERAND_SIGNED) != 0
+		  && (value & (1 << (operand->bits - 1))) != 0)
+		value -= 1 << operand->bits;
+	    }
+
+	  /* If the operand is optional, and the value is zero, don't
+	     print anything.  */
+	  if ((operand->flags & PPC_OPERAND_OPTIONAL) != 0
+	      && (operand->flags & PPC_OPERAND_NEXT) == 0
+	      && value == 0)
+	    continue;
+
+	  if (need_comma)
+	    {
+	      (*info->fprintf_func) (info->stream, ",");
+	      need_comma = 0;
+	    }
+
+	  /* Print the operand as directed by the flags.  */
+	  if ((operand->flags & PPC_OPERAND_GPR) != 0)
+	    (*info->fprintf_func) (info->stream, "r%ld", value);
+	  else if ((operand->flags & PPC_OPERAND_FPR) != 0)
+	    (*info->fprintf_func) (info->stream, "f%ld", value);
+	  else if ((operand->flags & PPC_OPERAND_VR) != 0)
+	    (*info->fprintf_func) (info->stream, "v%ld", value);
+	  else if ((operand->flags & PPC_OPERAND_RELATIVE) != 0)
+	    (*info->print_address_func) (memaddr + value, info);
+	  else if ((operand->flags & PPC_OPERAND_ABSOLUTE) != 0)
+	    (*info->print_address_func) ((bfd_vma) value & 0xffffffff, info);
+	  else if ((operand->flags & PPC_OPERAND_CR) == 0
+		   || (dialect & PPC_OPCODE_PPC) == 0)
+	    (*info->fprintf_func) (info->stream, "%ld", value);
+	  else
+	    {
+	      if (operand->bits == 3)
+		(*info->fprintf_func) (info->stream, "cr%d", value);
+	      else
+		{
+		  static const char *cbnames[4] = { "lt", "gt", "eq", "so" };
+		  int cr;
+		  int cc;
+
+		  cr = value >> 2;
+		  if (cr != 0)
+		    (*info->fprintf_func) (info->stream, "4*cr%d", cr);
+		  cc = value & 3;
+		  if (cc != 0)
+		    {
+		      if (cr != 0)
+			(*info->fprintf_func) (info->stream, "+");
+		      (*info->fprintf_func) (info->stream, "%s", cbnames[cc]);
+		    }
+		}
+	    }
+
+	  if (need_paren)
+	    {
+	      (*info->fprintf_func) (info->stream, ")");
+	      need_paren = 0;
+	    }
+
+	  if ((operand->flags & PPC_OPERAND_PARENS) == 0)
+	    need_comma = 1;
+	  else
+	    {
+	      (*info->fprintf_func) (info->stream, "(");
+	      need_paren = 1;
+	    }
+	}
+
+      /* We have found and printed an instruction; return.  */
+      return 4;
+    }
+
+  /* We could not find a match.  */
+  (*info->fprintf_func) (info->stream, ".long 0x%lx", insn);
+
+  return 4;
+}
diff -purN linux-2.5/arch/ppc64/kdb/ppc-opc.c linuxppc64-2.5/arch/ppc64/kdb/ppc-opc.c
--- linux-2.5/arch/ppc64/kdb/ppc-opc.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/ppc-opc.c	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,3491 @@
+/* ppc-opc.c -- PowerPC opcode list
+   Copyright (c) 1994, 95, 96, 97, 98, 99, 2000 Free Software Foundation, Inc.
+   Written by Ian Lance Taylor, Cygnus Support
+
+This file is part of GDB, GAS, and the GNU binutils.
+
+GDB, GAS, and the GNU binutils are free software; you can redistribute
+them and/or modify them under the terms of the GNU General Public
+License as published by the Free Software Foundation; either version
+2, or (at your option) any later version.
+
+GDB, GAS, and the GNU binutils are distributed in the hope that they
+will be useful, but WITHOUT ANY WARRANTY; without even the implied
+warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+the GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this file; see the file COPYING.  If not, write to the Free
+Software Foundation, 59 Temple Place - Suite 330, Boston, MA
+02111-1307, USA.  */
+#ifndef __KERNEL__
+#include <stdio.h>
+#include "sysdep.h"
+#include "opcode/ppc.h"
+#include "opintl.h"
+#else
+#include <linux/kernel.h>
+#include <linux/string.h>
+#include <linux/dis-asm.h>
+#include <linux/kdb.h>
+#include "ppc.h"
+#include "opintl.h"
+#endif
+/* This file holds the PowerPC opcode table.  The opcode table
+   includes almost all of the extended instruction mnemonics.  This
+   permits the disassembler to use them, and simplifies the assembler
+   logic, at the cost of increasing the table size.  The table is
+   strictly constant data, so the compiler should be able to put it in
+   the .text section.
+
+   This file also holds the operand table.  All knowledge about
+   inserting operands into instructions and vice-versa is kept in this
+   file.  */
+
+/* Local insertion and extraction functions.  */
+
+static unsigned long insert_bat PARAMS ((unsigned long, long, const char **));
+static long extract_bat PARAMS ((unsigned long, int *));
+static unsigned long insert_bba PARAMS ((unsigned long, long, const char **));
+static long extract_bba PARAMS ((unsigned long, int *));
+static unsigned long insert_bd PARAMS ((unsigned long, long, const char **));
+static long extract_bd PARAMS ((unsigned long, int *));
+static unsigned long insert_bdm PARAMS ((unsigned long, long, const char **));
+static long extract_bdm PARAMS ((unsigned long, int *));
+static unsigned long insert_bdp PARAMS ((unsigned long, long, const char **));
+static long extract_bdp PARAMS ((unsigned long, int *));
+static int valid_bo PARAMS ((long));
+static unsigned long insert_bo PARAMS ((unsigned long, long, const char **));
+static long extract_bo PARAMS ((unsigned long, int *));
+static unsigned long insert_boe PARAMS ((unsigned long, long, const char **));
+static long extract_boe PARAMS ((unsigned long, int *));
+static unsigned long insert_ds PARAMS ((unsigned long, long, const char **));
+static long extract_ds PARAMS ((unsigned long, int *));
+static unsigned long insert_li PARAMS ((unsigned long, long, const char **));
+static long extract_li PARAMS ((unsigned long, int *));
+static unsigned long insert_mbe PARAMS ((unsigned long, long, const char **));
+static long extract_mbe PARAMS ((unsigned long, int *));
+static unsigned long insert_mb6 PARAMS ((unsigned long, long, const char **));
+static long extract_mb6 PARAMS ((unsigned long, int *));
+static unsigned long insert_nb PARAMS ((unsigned long, long, const char **));
+static long extract_nb PARAMS ((unsigned long, int *));
+static unsigned long insert_nsi PARAMS ((unsigned long, long, const char **));
+static long extract_nsi PARAMS ((unsigned long, int *));
+static unsigned long insert_ral PARAMS ((unsigned long, long, const char **));
+static unsigned long insert_ram PARAMS ((unsigned long, long, const char **));
+static unsigned long insert_ras PARAMS ((unsigned long, long, const char **));
+static unsigned long insert_rbs PARAMS ((unsigned long, long, const char **));
+static long extract_rbs PARAMS ((unsigned long, int *));
+static unsigned long insert_sh6 PARAMS ((unsigned long, long, const char **));
+static long extract_sh6 PARAMS ((unsigned long, int *));
+static unsigned long insert_spr PARAMS ((unsigned long, long, const char **));
+static long extract_spr PARAMS ((unsigned long, int *));
+static unsigned long insert_tbr PARAMS ((unsigned long, long, const char **));
+static long extract_tbr PARAMS ((unsigned long, int *));
+
+/* The operands table.
+
+   The fields are bits, shift, insert, extract, flags.
+
+   We used to put parens around the various additions, like the one
+   for BA just below.  However, that caused trouble with feeble
+   compilers with a limit on depth of a parenthesized expression, like
+   (reportedly) the compiler in Microsoft Developer Studio 5.  So we
+   omit the parens, since the macros are never used in a context where
+   the addition will be ambiguous.  */
+
+const struct powerpc_operand powerpc_operands[] =
+{
+  /* The zero index is used to indicate the end of the list of
+     operands.  */
+#define UNUSED 0
+  { 0, 0, 0, 0, 0 },
+
+  /* The BA field in an XL form instruction.  */
+#define BA UNUSED + 1
+#define BA_MASK (0x1f << 16)
+  { 5, 16, 0, 0, PPC_OPERAND_CR },
+
+  /* The BA field in an XL form instruction when it must be the same
+     as the BT field in the same instruction.  */
+#define BAT BA + 1
+  { 5, 16, insert_bat, extract_bat, PPC_OPERAND_FAKE },
+
+  /* The BB field in an XL form instruction.  */
+#define BB BAT + 1
+#define BB_MASK (0x1f << 11)
+  { 5, 11, 0, 0, PPC_OPERAND_CR },
+
+  /* The BB field in an XL form instruction when it must be the same
+     as the BA field in the same instruction.  */
+#define BBA BB + 1
+  { 5, 11, insert_bba, extract_bba, PPC_OPERAND_FAKE },
+
+  /* The BD field in a B form instruction.  The lower two bits are
+     forced to zero.  */
+#define BD BBA + 1
+  { 16, 0, insert_bd, extract_bd, PPC_OPERAND_RELATIVE | PPC_OPERAND_SIGNED },
+
+  /* The BD field in a B form instruction when absolute addressing is
+     used.  */
+#define BDA BD + 1
+  { 16, 0, insert_bd, extract_bd, PPC_OPERAND_ABSOLUTE | PPC_OPERAND_SIGNED },
+
+  /* The BD field in a B form instruction when the - modifier is used.
+     This sets the y bit of the BO field appropriately.  */
+#define BDM BDA + 1
+  { 16, 0, insert_bdm, extract_bdm,
+      PPC_OPERAND_RELATIVE | PPC_OPERAND_SIGNED },
+
+  /* The BD field in a B form instruction when the - modifier is used
+     and absolute address is used.  */
+#define BDMA BDM + 1
+  { 16, 0, insert_bdm, extract_bdm,
+      PPC_OPERAND_ABSOLUTE | PPC_OPERAND_SIGNED },
+
+  /* The BD field in a B form instruction when the + modifier is used.
+     This sets the y bit of the BO field appropriately.  */
+#define BDP BDMA + 1
+  { 16, 0, insert_bdp, extract_bdp,
+      PPC_OPERAND_RELATIVE | PPC_OPERAND_SIGNED },
+
+  /* The BD field in a B form instruction when the + modifier is used
+     and absolute addressing is used.  */
+#define BDPA BDP + 1
+  { 16, 0, insert_bdp, extract_bdp,
+      PPC_OPERAND_ABSOLUTE | PPC_OPERAND_SIGNED },
+
+  /* The BF field in an X or XL form instruction.  */
+#define BF BDPA + 1
+  { 3, 23, 0, 0, PPC_OPERAND_CR },
+
+  /* An optional BF field.  This is used for comparison instructions,
+     in which an omitted BF field is taken as zero.  */
+#define OBF BF + 1
+  { 3, 23, 0, 0, PPC_OPERAND_CR | PPC_OPERAND_OPTIONAL },
+
+  /* The BFA field in an X or XL form instruction.  */
+#define BFA OBF + 1
+  { 3, 18, 0, 0, PPC_OPERAND_CR },
+
+  /* The BI field in a B form or XL form instruction.  */
+#define BI BFA + 1
+#define BI_MASK (0x1f << 16)
+  { 5, 16, 0, 0, PPC_OPERAND_CR },
+
+  /* The BO field in a B form instruction.  Certain values are
+     illegal.  */
+#define BO BI + 1
+#define BO_MASK (0x1f << 21)
+  { 5, 21, insert_bo, extract_bo, 0 },
+
+  /* The BO field in a B form instruction when the + or - modifier is
+     used.  This is like the BO field, but it must be even.  */
+#define BOE BO + 1
+  { 5, 21, insert_boe, extract_boe, 0 },
+
+  /* The BT field in an X or XL form instruction.  */
+#define BT BOE + 1
+  { 5, 21, 0, 0, PPC_OPERAND_CR },
+
+  /* The condition register number portion of the BI field in a B form
+     or XL form instruction.  This is used for the extended
+     conditional branch mnemonics, which set the lower two bits of the
+     BI field.  This field is optional.  */
+#define CR BT + 1
+  { 3, 18, 0, 0, PPC_OPERAND_CR | PPC_OPERAND_OPTIONAL },
+
+  /* The D field in a D form instruction.  This is a displacement off
+     a register, and implies that the next operand is a register in
+     parentheses.  */
+#define D CR + 1
+  { 16, 0, 0, 0, PPC_OPERAND_PARENS | PPC_OPERAND_SIGNED },
+
+  /* The DS field in a DS form instruction.  This is like D, but the
+     lower two bits are forced to zero.  */
+#define DS D + 1
+  { 16, 0, insert_ds, extract_ds, PPC_OPERAND_PARENS | PPC_OPERAND_SIGNED },
+
+  /* The E field in a wrteei instruction.  */
+#define E DS + 1
+  { 1, 15, 0, 0, 0 },
+
+  /* The FL1 field in a POWER SC form instruction.  */
+#define FL1 E + 1
+  { 4, 12, 0, 0, 0 },
+
+  /* The FL2 field in a POWER SC form instruction.  */
+#define FL2 FL1 + 1
+  { 3, 2, 0, 0, 0 },
+
+  /* The FLM field in an XFL form instruction.  */
+#define FLM FL2 + 1
+  { 8, 17, 0, 0, 0 },
+
+  /* The FRA field in an X or A form instruction.  */
+#define FRA FLM + 1
+#define FRA_MASK (0x1f << 16)
+  { 5, 16, 0, 0, PPC_OPERAND_FPR },
+
+  /* The FRB field in an X or A form instruction.  */
+#define FRB FRA + 1
+#define FRB_MASK (0x1f << 11)
+  { 5, 11, 0, 0, PPC_OPERAND_FPR },
+
+  /* The FRC field in an A form instruction.  */
+#define FRC FRB + 1
+#define FRC_MASK (0x1f << 6)
+  { 5, 6, 0, 0, PPC_OPERAND_FPR },
+
+  /* The FRS field in an X form instruction or the FRT field in a D, X
+     or A form instruction.  */
+#define FRS FRC + 1
+#define FRT FRS
+  { 5, 21, 0, 0, PPC_OPERAND_FPR },
+
+  /* The FXM field in an XFX instruction.  */
+#define FXM FRS + 1
+#define FXM_MASK (0xff << 12)
+  { 8, 12, 0, 0, 0 },
+
+  /* The L field in a D or X form instruction.  */
+#define L FXM + 1
+  { 1, 21, 0, 0, PPC_OPERAND_OPTIONAL },
+
+  /* The LEV field in a POWER SC form instruction.  */
+#define LEV L + 1
+  { 7, 5, 0, 0, 0 },
+
+  /* The LI field in an I form instruction.  The lower two bits are
+     forced to zero.  */
+#define LI LEV + 1
+  { 26, 0, insert_li, extract_li, PPC_OPERAND_RELATIVE | PPC_OPERAND_SIGNED },
+
+  /* The LI field in an I form instruction when used as an absolute
+     address.  */
+#define LIA LI + 1
+  { 26, 0, insert_li, extract_li, PPC_OPERAND_ABSOLUTE | PPC_OPERAND_SIGNED },
+
+  /* The MB field in an M form instruction.  */
+#define MB LIA + 1
+#define MB_MASK (0x1f << 6)
+  { 5, 6, 0, 0, 0 },
+
+  /* The ME field in an M form instruction.  */
+#define ME MB + 1
+#define ME_MASK (0x1f << 1)
+  { 5, 1, 0, 0, 0 },
+
+  /* The MB and ME fields in an M form instruction expressed a single
+     operand which is a bitmask indicating which bits to select.  This
+     is a two operand form using PPC_OPERAND_NEXT.  See the
+     description in opcode/ppc.h for what this means.  */
+#define MBE ME + 1
+  { 5, 6, 0, 0, PPC_OPERAND_OPTIONAL | PPC_OPERAND_NEXT },
+  { 32, 0, insert_mbe, extract_mbe, 0 },
+
+  /* The MB or ME field in an MD or MDS form instruction.  The high
+     bit is wrapped to the low end.  */
+#define MB6 MBE + 2
+#define ME6 MB6
+#define MB6_MASK (0x3f << 5)
+  { 6, 5, insert_mb6, extract_mb6, 0 },
+
+  /* The NB field in an X form instruction.  The value 32 is stored as
+     0.  */
+#define NB MB6 + 1
+  { 6, 11, insert_nb, extract_nb, 0 },
+
+  /* The NSI field in a D form instruction.  This is the same as the
+     SI field, only negated.  */
+#define NSI NB + 1
+  { 16, 0, insert_nsi, extract_nsi,
+      PPC_OPERAND_NEGATIVE | PPC_OPERAND_SIGNED },
+
+  /* The RA field in an D, DS, X, XO, M, or MDS form instruction.  */
+#define RA NSI + 1
+#define RA_MASK (0x1f << 16)
+  { 5, 16, 0, 0, PPC_OPERAND_GPR },
+
+  /* The RA field in a D or X form instruction which is an updating
+     load, which means that the RA field may not be zero and may not
+     equal the RT field.  */
+#define RAL RA + 1
+  { 5, 16, insert_ral, 0, PPC_OPERAND_GPR },
+
+  /* The RA field in an lmw instruction, which has special value
+     restrictions.  */
+#define RAM RAL + 1
+  { 5, 16, insert_ram, 0, PPC_OPERAND_GPR },
+
+  /* The RA field in a D or X form instruction which is an updating
+     store or an updating floating point load, which means that the RA
+     field may not be zero.  */
+#define RAS RAM + 1
+  { 5, 16, insert_ras, 0, PPC_OPERAND_GPR },
+
+  /* The RB field in an X, XO, M, or MDS form instruction.  */
+#define RB RAS + 1
+#define RB_MASK (0x1f << 11)
+  { 5, 11, 0, 0, PPC_OPERAND_GPR },
+
+  /* The RB field in an X form instruction when it must be the same as
+     the RS field in the instruction.  This is used for extended
+     mnemonics like mr.  */
+#define RBS RB + 1
+  { 5, 1, insert_rbs, extract_rbs, PPC_OPERAND_FAKE },
+
+  /* The RS field in a D, DS, X, XFX, XS, M, MD or MDS form
+     instruction or the RT field in a D, DS, X, XFX or XO form
+     instruction.  */
+#define RS RBS + 1
+#define RT RS
+#define RT_MASK (0x1f << 21)
+  { 5, 21, 0, 0, PPC_OPERAND_GPR },
+
+  /* The SH field in an X or M form instruction.  */
+#define SH RS + 1
+#define SH_MASK (0x1f << 11)
+  { 5, 11, 0, 0, 0 },
+
+  /* The SH field in an MD form instruction.  This is split.  */
+#define SH6 SH + 1
+#define SH6_MASK ((0x1f << 11) | (1 << 1))
+  { 6, 1, insert_sh6, extract_sh6, 0 },
+
+  /* The SI field in a D form instruction.  */
+#define SI SH6 + 1
+  { 16, 0, 0, 0, PPC_OPERAND_SIGNED },
+
+  /* The SI field in a D form instruction when we accept a wide range
+     of positive values.  */
+#define SISIGNOPT SI + 1
+  { 16, 0, 0, 0, PPC_OPERAND_SIGNED | PPC_OPERAND_SIGNOPT },
+
+  /* The SPR field in an XFX form instruction.  This is flipped--the
+     lower 5 bits are stored in the upper 5 and vice- versa.  */
+#define SPR SISIGNOPT + 1
+#define SPR_MASK (0x3ff << 11)
+  { 10, 11, insert_spr, extract_spr, 0 },
+
+  /* The BAT index number in an XFX form m[ft]ibat[lu] instruction.  */
+#define SPRBAT SPR + 1
+#define SPRBAT_MASK (0x3 << 17)
+  { 2, 17, 0, 0, 0 },
+
+  /* The SPRG register number in an XFX form m[ft]sprg instruction.  */
+#define SPRG SPRBAT + 1
+#define SPRG_MASK (0x3 << 16)
+  { 2, 16, 0, 0, 0 },
+
+  /* The SR field in an X form instruction.  */
+#define SR SPRG + 1
+  { 4, 16, 0, 0, 0 },
+
+  /* The SV field in a POWER SC form instruction.  */
+#define SV SR + 1
+  { 14, 2, 0, 0, 0 },
+
+  /* The TBR field in an XFX form instruction.  This is like the SPR
+     field, but it is optional.  */
+#define TBR SV + 1
+  { 10, 11, insert_tbr, extract_tbr, PPC_OPERAND_OPTIONAL },
+
+  /* The TO field in a D or X form instruction.  */
+#define TO TBR + 1
+#define TO_MASK (0x1f << 21)
+  { 5, 21, 0, 0, 0 },
+
+  /* The U field in an X form instruction.  */
+#define U TO + 1
+  { 4, 12, 0, 0, 0 },
+
+  /* The UI field in a D form instruction.  */
+#define UI U + 1
+  { 16, 0, 0, 0, 0 },
+
+  /* The VA field in a VA, VX or VXR form instruction. */
+#define VA UI + 1
+#define VA_MASK	(0x1f << 16)
+  {5, 16, 0, 0, PPC_OPERAND_VR},
+
+  /* The VB field in a VA, VX or VXR form instruction. */
+#define VB VA + 1
+#define VB_MASK (0x1f << 11)
+  {5, 11, 0, 0, PPC_OPERAND_VR}, 
+
+  /* The VC field in a VA form instruction. */
+#define VC VB + 1
+#define VC_MASK (0x1f << 6)
+  {5, 6, 0, 0, PPC_OPERAND_VR},
+
+  /* The VD or VS field in a VA, VX, VXR or X form instruction. */
+#define VD VC + 1
+#define VS VD
+#define VD_MASK (0x1f << 21)
+  {5, 21, 0, 0, PPC_OPERAND_VR},
+
+  /* The SIMM field in a VX form instruction. */
+#define SIMM VD + 1
+  { 5, 16, 0, 0, PPC_OPERAND_SIGNED},
+
+  /* The UIMM field in a VX form instruction. */
+#define UIMM SIMM + 1
+  { 5, 16, 0, 0, 0 },
+
+  /* The SHB field in a VA form instruction. */
+#define SHB UIMM + 1
+  { 4, 6, 0, 0, 0 },
+};
+
+/* The functions used to insert and extract complicated operands.  */
+
+/* The BA field in an XL form instruction when it must be the same as
+   the BT field in the same instruction.  This operand is marked FAKE.
+   The insertion function just copies the BT field into the BA field,
+   and the extraction function just checks that the fields are the
+   same.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_bat (insn, value, errmsg)
+     unsigned long insn;
+     long value ATTRIBUTE_UNUSED;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | (((insn >> 21) & 0x1f) << 16);
+}
+
+static long
+extract_bat (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  if (invalid != (int *) NULL
+      && ((insn >> 21) & 0x1f) != ((insn >> 16) & 0x1f))
+    *invalid = 1;
+  return 0;
+}
+
+/* The BB field in an XL form instruction when it must be the same as
+   the BA field in the same instruction.  This operand is marked FAKE.
+   The insertion function just copies the BA field into the BB field,
+   and the extraction function just checks that the fields are the
+   same.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_bba (insn, value, errmsg)
+     unsigned long insn;
+     long value ATTRIBUTE_UNUSED;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | (((insn >> 16) & 0x1f) << 11);
+}
+
+static long
+extract_bba (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  if (invalid != (int *) NULL
+      && ((insn >> 16) & 0x1f) != ((insn >> 11) & 0x1f))
+    *invalid = 1;
+  return 0;
+}
+
+/* The BD field in a B form instruction.  The lower two bits are
+   forced to zero.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_bd (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | (value & 0xfffc);
+}
+
+/*ARGSUSED*/
+static long
+extract_bd (insn, invalid)
+     unsigned long insn;
+     int *invalid ATTRIBUTE_UNUSED;
+{
+  if ((insn & 0x8000) != 0)
+    return (insn & 0xfffc) - 0x10000;
+  else
+    return insn & 0xfffc;
+}
+
+/* The BD field in a B form instruction when the - modifier is used.
+   This modifier means that the branch is not expected to be taken.
+   We must set the y bit of the BO field to 1 if the offset is
+   negative.  When extracting, we require that the y bit be 1 and that
+   the offset be positive, since if the y bit is 0 we just want to
+   print the normal form of the instruction.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_bdm (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  if ((value & 0x8000) != 0)
+    insn |= 1 << 21;
+  return insn | (value & 0xfffc);
+}
+
+static long
+extract_bdm (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  if (invalid != (int *) NULL
+      && ((insn & (1 << 21)) == 0
+	  || (insn & (1 << 15)) == 0))
+    *invalid = 1;
+  if ((insn & 0x8000) != 0)
+    return (insn & 0xfffc) - 0x10000;
+  else
+    return insn & 0xfffc;
+}
+
+/* The BD field in a B form instruction when the + modifier is used.
+   This is like BDM, above, except that the branch is expected to be
+   taken.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_bdp (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  if ((value & 0x8000) == 0)
+    insn |= 1 << 21;
+  return insn | (value & 0xfffc);
+}
+
+static long
+extract_bdp (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  if (invalid != (int *) NULL
+      && ((insn & (1 << 21)) == 0
+	  || (insn & (1 << 15)) != 0))
+    *invalid = 1;
+  if ((insn & 0x8000) != 0)
+    return (insn & 0xfffc) - 0x10000;
+  else
+    return insn & 0xfffc;
+}
+
+/* Check for legal values of a BO field.  */
+
+static int
+valid_bo (value)
+     long value;
+{
+  /* Certain encodings have bits that are required to be zero.  These
+     are (z must be zero, y may be anything):
+         001zy
+	 011zy
+	 1z00y
+	 1z01y
+	 1z1zz
+     */
+  switch (value & 0x14)
+    {
+    default:
+    case 0:
+      return 1;
+    case 0x4:
+      return (value & 0x2) == 0;
+    case 0x10:
+      return (value & 0x8) == 0;
+    case 0x14:
+      return value == 0x14;
+    }
+}
+
+/* The BO field in a B form instruction.  Warn about attempts to set
+   the field to an illegal value.  */
+
+static unsigned long
+insert_bo (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg;
+{
+  if (errmsg != (const char **) NULL
+      && ! valid_bo (value))
+    *errmsg = _("invalid conditional option");
+  return insn | ((value & 0x1f) << 21);
+}
+
+static long
+extract_bo (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  long value;
+
+  value = (insn >> 21) & 0x1f;
+  if (invalid != (int *) NULL
+      && ! valid_bo (value))
+    *invalid = 1;
+  return value;
+}
+
+/* The BO field in a B form instruction when the + or - modifier is
+   used.  This is like the BO field, but it must be even.  When
+   extracting it, we force it to be even.  */
+
+static unsigned long
+insert_boe (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg;
+{
+  if (errmsg != (const char **) NULL)
+    {
+      if (! valid_bo (value))
+	*errmsg = _("invalid conditional option");
+      else if ((value & 1) != 0)
+	*errmsg = _("attempt to set y bit when using + or - modifier");
+    }
+  return insn | ((value & 0x1f) << 21);
+}
+
+static long
+extract_boe (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  long value;
+
+  value = (insn >> 21) & 0x1f;
+  if (invalid != (int *) NULL
+      && ! valid_bo (value))
+    *invalid = 1;
+  return value & 0x1e;
+}
+
+/* The DS field in a DS form instruction.  This is like D, but the
+   lower two bits are forced to zero.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_ds (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | (value & 0xfffc);
+}
+
+/*ARGSUSED*/
+static long
+extract_ds (insn, invalid)
+     unsigned long insn;
+     int *invalid ATTRIBUTE_UNUSED;
+{
+  if ((insn & 0x8000) != 0)
+    return (insn & 0xfffc) - 0x10000;
+  else
+    return insn & 0xfffc;
+}
+
+/* The LI field in an I form instruction.  The lower two bits are
+   forced to zero.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_li (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg;
+{
+  if ((value & 3) != 0 && errmsg != (const char **) NULL)
+    *errmsg = _("ignoring least significant bits in branch offset");
+  return insn | (value & 0x3fffffc);
+}
+
+/*ARGSUSED*/
+static long
+extract_li (insn, invalid)
+     unsigned long insn;
+     int *invalid ATTRIBUTE_UNUSED;
+{
+  if ((insn & 0x2000000) != 0)
+    return (insn & 0x3fffffc) - 0x4000000;
+  else
+    return insn & 0x3fffffc;
+}
+
+/* The MB and ME fields in an M form instruction expressed as a single
+   operand which is itself a bitmask.  The extraction function always
+   marks it as invalid, since we never want to recognize an
+   instruction which uses a field of this type.  */
+
+static unsigned long
+insert_mbe (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg;
+{
+  unsigned long uval, mask;
+  int mb, me, mx, count, last;
+
+  uval = value;
+
+  if (uval == 0)
+    {
+      if (errmsg != (const char **) NULL)
+	*errmsg = _("illegal bitmask");
+      return insn;
+    }
+
+  mb = 0;
+  me = 32;
+  if ((uval & 1) != 0)
+    last = 1;
+  else
+    last = 0;
+  count = 0;
+
+  /* mb: location of last 0->1 transition */
+  /* me: location of last 1->0 transition */
+  /* count: # transitions */
+
+  for (mx = 0, mask = 1 << 31; mx < 32; ++mx, mask >>= 1)
+    {
+      if ((uval & mask) && !last)
+	{
+	  ++count;
+	  mb = mx;
+	  last = 1;
+	}
+      else if (!(uval & mask) && last)
+	{
+	  ++count;
+	  me = mx;
+	  last = 0;
+	}
+    }
+  if (me == 0)
+    me = 32;
+
+  if (count != 2 && (count != 0 || ! last))
+    {
+      if (errmsg != (const char **) NULL)
+	*errmsg = _("illegal bitmask");
+    }
+
+  return insn | (mb << 6) | ((me - 1) << 1);
+}
+
+static long
+extract_mbe (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  long ret;
+  int mb, me;
+  int i;
+
+  if (invalid != (int *) NULL)
+    *invalid = 1;
+
+  mb = (insn >> 6) & 0x1f;
+  me = (insn >> 1) & 0x1f;
+  if (mb < me + 1)
+    {
+      ret = 0;
+      for (i = mb; i <= me; i++)
+	ret |= (long) 1 << (31 - i);
+    }
+  else if (mb == me + 1)
+    ret = ~0;
+  else /* (mb > me + 1) */
+    {
+      ret = ~ (long) 0;
+      for (i = me + 1; i < mb; i++)
+	ret &= ~ ((long) 1 << (31 - i));
+    }
+  return ret;
+}
+
+/* The MB or ME field in an MD or MDS form instruction.  The high bit
+   is wrapped to the low end.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_mb6 (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | ((value & 0x1f) << 6) | (value & 0x20);
+}
+
+/*ARGSUSED*/
+static long
+extract_mb6 (insn, invalid)
+     unsigned long insn;
+     int *invalid ATTRIBUTE_UNUSED;
+{
+  return ((insn >> 6) & 0x1f) | (insn & 0x20);
+}
+
+/* The NB field in an X form instruction.  The value 32 is stored as
+   0.  */
+
+static unsigned long
+insert_nb (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg;
+{
+  if (value < 0 || value > 32)
+    *errmsg = _("value out of range");
+  if (value == 32)
+    value = 0;
+  return insn | ((value & 0x1f) << 11);
+}
+
+/*ARGSUSED*/
+static long
+extract_nb (insn, invalid)
+     unsigned long insn;
+     int *invalid ATTRIBUTE_UNUSED;
+{
+  long ret;
+
+  ret = (insn >> 11) & 0x1f;
+  if (ret == 0)
+    ret = 32;
+  return ret;
+}
+
+/* The NSI field in a D form instruction.  This is the same as the SI
+   field, only negated.  The extraction function always marks it as
+   invalid, since we never want to recognize an instruction which uses
+   a field of this type.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_nsi (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | ((- value) & 0xffff);
+}
+
+static long
+extract_nsi (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  if (invalid != (int *) NULL)
+    *invalid = 1;
+  if ((insn & 0x8000) != 0)
+    return - ((long)(insn & 0xffff) - 0x10000);
+  else
+    return - (long)(insn & 0xffff);
+}
+
+/* The RA field in a D or X form instruction which is an updating
+   load, which means that the RA field may not be zero and may not
+   equal the RT field.  */
+
+static unsigned long
+insert_ral (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg;
+{
+  if (value == 0
+      || (unsigned long) value == ((insn >> 21) & 0x1f))
+    *errmsg = "invalid register operand when updating";
+  return insn | ((value & 0x1f) << 16);
+}
+
+/* The RA field in an lmw instruction, which has special value
+   restrictions.  */
+
+static unsigned long
+insert_ram (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg;
+{
+  if ((unsigned long) value >= ((insn >> 21) & 0x1f))
+    *errmsg = _("index register in load range");
+  return insn | ((value & 0x1f) << 16);
+}
+
+/* The RA field in a D or X form instruction which is an updating
+   store or an updating floating point load, which means that the RA
+   field may not be zero.  */
+
+static unsigned long
+insert_ras (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg;
+{
+  if (value == 0)
+    *errmsg = _("invalid register operand when updating");
+  return insn | ((value & 0x1f) << 16);
+}
+
+/* The RB field in an X form instruction when it must be the same as
+   the RS field in the instruction.  This is used for extended
+   mnemonics like mr.  This operand is marked FAKE.  The insertion
+   function just copies the BT field into the BA field, and the
+   extraction function just checks that the fields are the same.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_rbs (insn, value, errmsg)
+     unsigned long insn;
+     long value ATTRIBUTE_UNUSED;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | (((insn >> 21) & 0x1f) << 11);
+}
+
+static long
+extract_rbs (insn, invalid)
+     unsigned long insn;
+     int *invalid;
+{
+  if (invalid != (int *) NULL
+      && ((insn >> 21) & 0x1f) != ((insn >> 11) & 0x1f))
+    *invalid = 1;
+  return 0;
+}
+
+/* The SH field in an MD form instruction.  This is split.  */
+
+/*ARGSUSED*/
+static unsigned long
+insert_sh6 (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | ((value & 0x1f) << 11) | ((value & 0x20) >> 4);
+}
+
+/*ARGSUSED*/
+static long
+extract_sh6 (insn, invalid)
+     unsigned long insn;
+     int *invalid ATTRIBUTE_UNUSED;
+{
+  return ((insn >> 11) & 0x1f) | ((insn << 4) & 0x20);
+}
+
+/* The SPR field in an XFX form instruction.  This is flipped--the
+   lower 5 bits are stored in the upper 5 and vice- versa.  */
+
+static unsigned long
+insert_spr (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  return insn | ((value & 0x1f) << 16) | ((value & 0x3e0) << 6);
+}
+
+static long
+extract_spr (insn, invalid)
+     unsigned long insn;
+     int *invalid ATTRIBUTE_UNUSED;
+{
+  return ((insn >> 16) & 0x1f) | ((insn >> 6) & 0x3e0);
+}
+
+/* The TBR field in an XFX instruction.  This is just like SPR, but it
+   is optional.  When TBR is omitted, it must be inserted as 268 (the
+   magic number of the TB register).  These functions treat 0
+   (indicating an omitted optional operand) as 268.  This means that
+   ``mftb 4,0'' is not handled correctly.  This does not matter very
+   much, since the architecture manual does not define mftb as
+   accepting any values other than 268 or 269.  */
+
+#define TB (268)
+
+static unsigned long
+insert_tbr (insn, value, errmsg)
+     unsigned long insn;
+     long value;
+     const char **errmsg ATTRIBUTE_UNUSED;
+{
+  if (value == 0)
+    value = TB;
+  return insn | ((value & 0x1f) << 16) | ((value & 0x3e0) << 6);
+}
+
+static long
+extract_tbr (insn, invalid)
+     unsigned long insn;
+     int *invalid ATTRIBUTE_UNUSED;
+{
+  long ret;
+
+  ret = ((insn >> 16) & 0x1f) | ((insn >> 6) & 0x3e0);
+  if (ret == TB)
+    ret = 0;
+  return ret;
+}
+
+/* Macros used to form opcodes.  */
+
+/* The main opcode.  */
+#define OP(x) ((((unsigned long)(x)) & 0x3f) << 26)
+#define OP_MASK OP (0x3f)
+
+/* The main opcode combined with a trap code in the TO field of a D
+   form instruction.  Used for extended mnemonics for the trap
+   instructions.  */
+#define OPTO(x,to) (OP (x) | ((((unsigned long)(to)) & 0x1f) << 21))
+#define OPTO_MASK (OP_MASK | TO_MASK)
+
+/* The main opcode combined with a comparison size bit in the L field
+   of a D form or X form instruction.  Used for extended mnemonics for
+   the comparison instructions.  */
+#define OPL(x,l) (OP (x) | ((((unsigned long)(l)) & 1) << 21))
+#define OPL_MASK OPL (0x3f,1)
+
+/* An A form instruction.  */
+#define A(op, xop, rc) (OP (op) | ((((unsigned long)(xop)) & 0x1f) << 1) | (((unsigned long)(rc)) & 1))
+#define A_MASK A (0x3f, 0x1f, 1)
+
+/* An A_MASK with the FRB field fixed.  */
+#define AFRB_MASK (A_MASK | FRB_MASK)
+
+/* An A_MASK with the FRC field fixed.  */
+#define AFRC_MASK (A_MASK | FRC_MASK)
+
+/* An A_MASK with the FRA and FRC fields fixed.  */
+#define AFRAFRC_MASK (A_MASK | FRA_MASK | FRC_MASK)
+
+/* A B form instruction.  */
+#define B(op, aa, lk) (OP (op) | ((((unsigned long)(aa)) & 1) << 1) | ((lk) & 1))
+#define B_MASK B (0x3f, 1, 1)
+
+/* A B form instruction setting the BO field.  */
+#define BBO(op, bo, aa, lk) (B ((op), (aa), (lk)) | ((((unsigned long)(bo)) & 0x1f) << 21))
+#define BBO_MASK BBO (0x3f, 0x1f, 1, 1)
+
+/* A BBO_MASK with the y bit of the BO field removed.  This permits
+   matching a conditional branch regardless of the setting of the y
+   bit.  */
+#define Y_MASK (((unsigned long)1) << 21)
+#define BBOY_MASK (BBO_MASK &~ Y_MASK)
+
+/* A B form instruction setting the BO field and the condition bits of
+   the BI field.  */
+#define BBOCB(op, bo, cb, aa, lk) \
+  (BBO ((op), (bo), (aa), (lk)) | ((((unsigned long)(cb)) & 0x3) << 16))
+#define BBOCB_MASK BBOCB (0x3f, 0x1f, 0x3, 1, 1)
+
+/* A BBOCB_MASK with the y bit of the BO field removed.  */
+#define BBOYCB_MASK (BBOCB_MASK &~ Y_MASK)
+
+/* A BBOYCB_MASK in which the BI field is fixed.  */
+#define BBOYBI_MASK (BBOYCB_MASK | BI_MASK)
+
+/* The main opcode mask with the RA field clear.  */
+#define DRA_MASK (OP_MASK | RA_MASK)
+
+/* A DS form instruction.  */
+#define DSO(op, xop) (OP (op) | ((xop) & 0x3))
+#define DS_MASK DSO (0x3f, 3)
+
+/* An M form instruction.  */
+#define M(op, rc) (OP (op) | ((rc) & 1))
+#define M_MASK M (0x3f, 1)
+
+/* An M form instruction with the ME field specified.  */
+#define MME(op, me, rc) (M ((op), (rc)) | ((((unsigned long)(me)) & 0x1f) << 1))
+
+/* An M_MASK with the MB and ME fields fixed.  */
+#define MMBME_MASK (M_MASK | MB_MASK | ME_MASK)
+
+/* An M_MASK with the SH and ME fields fixed.  */
+#define MSHME_MASK (M_MASK | SH_MASK | ME_MASK)
+
+/* An MD form instruction.  */
+#define MD(op, xop, rc) (OP (op) | ((((unsigned long)(xop)) & 0x7) << 2) | ((rc) & 1))
+#define MD_MASK MD (0x3f, 0x7, 1)
+
+/* An MD_MASK with the MB field fixed.  */
+#define MDMB_MASK (MD_MASK | MB6_MASK)
+
+/* An MD_MASK with the SH field fixed.  */
+#define MDSH_MASK (MD_MASK | SH6_MASK)
+
+/* An MDS form instruction.  */
+#define MDS(op, xop, rc) (OP (op) | ((((unsigned long)(xop)) & 0xf) << 1) | ((rc) & 1))
+#define MDS_MASK MDS (0x3f, 0xf, 1)
+
+/* An MDS_MASK with the MB field fixed.  */
+#define MDSMB_MASK (MDS_MASK | MB6_MASK)
+
+/* An SC form instruction.  */
+#define SC(op, sa, lk) (OP (op) | ((((unsigned long)(sa)) & 1) << 1) | ((lk) & 1))
+#define SC_MASK (OP_MASK | (((unsigned long)0x3ff) << 16) | (((unsigned long)1) << 1) | 1)
+
+/* An VX form instruction. */
+#define VX(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x7ff))
+
+/* The mask for an VX form instruction. */
+#define VX_MASK	VX(0x3f, 0x7ff)
+
+/* An VA form instruction. */
+#define VXA(op, xop) (OP (op) | (((unsigned long)(xop)) & 0x07f))
+
+/* The mask for an VA form instruction. */
+#define VXA_MASK VXA(0x3f, 0x7f)
+
+/* An VXR form instruction. */
+#define VXR(op, xop, rc) (OP (op) | (((rc) & 1) << 10) | (((unsigned long)(xop)) & 0x3ff))
+
+/* The mask for a VXR form instruction. */
+#define VXR_MASK VXR(0x3f, 0x3ff, 1)
+
+/* An X form instruction.  */
+#define X(op, xop) (OP (op) | ((((unsigned long)(xop)) & 0x3ff) << 1))
+
+/* An X form instruction with the RC bit specified.  */
+#define XRC(op, xop, rc) (X ((op), (xop)) | ((rc) & 1))
+
+/* The mask for an X form instruction.  */
+#define X_MASK XRC (0x3f, 0x3ff, 1)
+
+/* An X_MASK with the RA field fixed.  */
+#define XRA_MASK (X_MASK | RA_MASK)
+
+/* An X_MASK with the RB field fixed.  */
+#define XRB_MASK (X_MASK | RB_MASK)
+
+/* An X_MASK with the RT field fixed.  */
+#define XRT_MASK (X_MASK | RT_MASK)
+
+/* An X_MASK with the RA and RB fields fixed.  */
+#define XRARB_MASK (X_MASK | RA_MASK | RB_MASK)
+
+/* An X_MASK with the RT and RA fields fixed.  */
+#define XRTRA_MASK (X_MASK | RT_MASK | RA_MASK)
+
+/* An X form comparison instruction.  */
+#define XCMPL(op, xop, l) (X ((op), (xop)) | ((((unsigned long)(l)) & 1) << 21))
+
+/* The mask for an X form comparison instruction.  */
+#define XCMP_MASK (X_MASK | (((unsigned long)1) << 22))
+
+/* The mask for an X form comparison instruction with the L field
+   fixed.  */
+#define XCMPL_MASK (XCMP_MASK | (((unsigned long)1) << 21))
+
+/* An X form trap instruction with the TO field specified.  */
+#define XTO(op, xop, to) (X ((op), (xop)) | ((((unsigned long)(to)) & 0x1f) << 21))
+#define XTO_MASK (X_MASK | TO_MASK)
+
+/* An X form tlb instruction with the SH field specified.  */
+#define XTLB(op, xop, sh) (X ((op), (xop)) | ((((unsigned long)(sh)) & 0x1f) << 11))
+#define XTLB_MASK (X_MASK | SH_MASK)
+
+/* An XFL form instruction.  */
+#define XFL(op, xop, rc) (OP (op) | ((((unsigned long)(xop)) & 0x3ff) << 1) | (((unsigned long)(rc)) & 1))
+#define XFL_MASK (XFL (0x3f, 0x3ff, 1) | (((unsigned long)1) << 25) | (((unsigned long)1) << 16))
+
+/* An XL form instruction with the LK field set to 0.  */
+#define XL(op, xop) (OP (op) | ((((unsigned long)(xop)) & 0x3ff) << 1))
+
+/* An XL form instruction which uses the LK field.  */
+#define XLLK(op, xop, lk) (XL ((op), (xop)) | ((lk) & 1))
+
+/* The mask for an XL form instruction.  */
+#define XL_MASK XLLK (0x3f, 0x3ff, 1)
+
+/* An XL form instruction which explicitly sets the BO field.  */
+#define XLO(op, bo, xop, lk) \
+  (XLLK ((op), (xop), (lk)) | ((((unsigned long)(bo)) & 0x1f) << 21))
+#define XLO_MASK (XL_MASK | BO_MASK)
+
+/* An XL form instruction which explicitly sets the y bit of the BO
+   field.  */
+#define XLYLK(op, xop, y, lk) (XLLK ((op), (xop), (lk)) | ((((unsigned long)(y)) & 1) << 21))
+#define XLYLK_MASK (XL_MASK | Y_MASK)
+
+/* An XL form instruction which sets the BO field and the condition
+   bits of the BI field.  */
+#define XLOCB(op, bo, cb, xop, lk) \
+  (XLO ((op), (bo), (xop), (lk)) | ((((unsigned long)(cb)) & 3) << 16))
+#define XLOCB_MASK XLOCB (0x3f, 0x1f, 0x3, 0x3ff, 1)
+
+/* An XL_MASK or XLYLK_MASK or XLOCB_MASK with the BB field fixed.  */
+#define XLBB_MASK (XL_MASK | BB_MASK)
+#define XLYBB_MASK (XLYLK_MASK | BB_MASK)
+#define XLBOCBBB_MASK (XLOCB_MASK | BB_MASK)
+
+/* An XL_MASK with the BO and BB fields fixed.  */
+#define XLBOBB_MASK (XL_MASK | BO_MASK | BB_MASK)
+
+/* An XL_MASK with the BO, BI and BB fields fixed.  */
+#define XLBOBIBB_MASK (XL_MASK | BO_MASK | BI_MASK | BB_MASK)
+
+/* An XO form instruction.  */
+#define XO(op, xop, oe, rc) \
+  (OP (op) | ((((unsigned long)(xop)) & 0x1ff) << 1) | ((((unsigned long)(oe)) & 1) << 10) | (((unsigned long)(rc)) & 1))
+#define XO_MASK XO (0x3f, 0x1ff, 1, 1)
+
+/* An XO_MASK with the RB field fixed.  */
+#define XORB_MASK (XO_MASK | RB_MASK)
+
+/* An XS form instruction.  */
+#define XS(op, xop, rc) (OP (op) | ((((unsigned long)(xop)) & 0x1ff) << 2) | (((unsigned long)(rc)) & 1))
+#define XS_MASK XS (0x3f, 0x1ff, 1)
+
+/* A mask for the FXM version of an XFX form instruction.  */
+#define XFXFXM_MASK (X_MASK | (((unsigned long)1) << 20) | (((unsigned long)1) << 11))
+
+/* An XFX form instruction with the FXM field filled in.  */
+#define XFXM(op, xop, fxm) \
+  (X ((op), (xop)) | ((((unsigned long)(fxm)) & 0xff) << 12))
+
+/* An XFX form instruction with the SPR field filled in.  */
+#define XSPR(op, xop, spr) \
+  (X ((op), (xop)) | ((((unsigned long)(spr)) & 0x1f) << 16) | ((((unsigned long)(spr)) & 0x3e0) << 6))
+#define XSPR_MASK (X_MASK | SPR_MASK)
+
+/* An XFX form instruction with the SPR field filled in except for the
+   SPRBAT field.  */
+#define XSPRBAT_MASK (XSPR_MASK &~ SPRBAT_MASK)
+
+/* An XFX form instruction with the SPR field filled in except for the
+   SPRG field.  */
+#define XSPRG_MASK (XSPR_MASK &~ SPRG_MASK)
+
+/* An X form instruction with everything filled in except the E field.  */
+#define XE_MASK (0xffff7fff)
+
+/* The BO encodings used in extended conditional branch mnemonics.  */
+#define BODNZF	(0x0)
+#define BODNZFP	(0x1)
+#define BODZF	(0x2)
+#define BODZFP	(0x3)
+#define BOF	(0x4)
+#define BOFP	(0x5)
+#define BODNZT	(0x8)
+#define BODNZTP	(0x9)
+#define BODZT	(0xa)
+#define BODZTP	(0xb)
+#define BOT	(0xc)
+#define BOTP	(0xd)
+#define BODNZ	(0x10)
+#define BODNZP	(0x11)
+#define BODZ	(0x12)
+#define BODZP	(0x13)
+#define BOU	(0x14)
+
+/* The BI condition bit encodings used in extended conditional branch
+   mnemonics.  */
+#define CBLT	(0)
+#define CBGT	(1)
+#define CBEQ	(2)
+#define CBSO	(3)
+
+/* The TO encodings used in extended trap mnemonics.  */
+#define TOLGT	(0x1)
+#define TOLLT	(0x2)
+#define TOEQ	(0x4)
+#define TOLGE	(0x5)
+#define TOLNL	(0x5)
+#define TOLLE	(0x6)
+#define TOLNG	(0x6)
+#define TOGT	(0x8)
+#define TOGE	(0xc)
+#define TONL	(0xc)
+#define TOLT	(0x10)
+#define TOLE	(0x14)
+#define TONG	(0x14)
+#define TONE	(0x18)
+#define TOU	(0x1f)
+
+/* Smaller names for the flags so each entry in the opcodes table will
+   fit on a single line.  */
+#undef	PPC
+#define PPC     PPC_OPCODE_PPC | PPC_OPCODE_ANY
+#define PPCCOM	PPC_OPCODE_PPC | PPC_OPCODE_COMMON | PPC_OPCODE_ANY
+#define PPC32   PPC_OPCODE_PPC | PPC_OPCODE_32 | PPC_OPCODE_ANY
+#undef PPC64
+#define PPC64   PPC_OPCODE_PPC | PPC_OPCODE_64 | PPC_OPCODE_ANY
+#define PPCONLY	PPC_OPCODE_PPC
+#define PPC403	PPC
+#define PPC405	PPC403
+#define PPC750	PPC
+#define PPC860	PPC
+#define PPCVEC	PPC_OPCODE_ALTIVEC | PPC_OPCODE_ANY
+#define	POWER   PPC_OPCODE_POWER | PPC_OPCODE_ANY
+#define	POWER2	PPC_OPCODE_POWER | PPC_OPCODE_POWER2 | PPC_OPCODE_ANY
+#define PPCPWR2	PPC_OPCODE_PPC | PPC_OPCODE_POWER | PPC_OPCODE_POWER2 | PPC_OPCODE_ANY
+#define	POWER32	PPC_OPCODE_POWER | PPC_OPCODE_ANY | PPC_OPCODE_32
+#define	COM     PPC_OPCODE_POWER | PPC_OPCODE_PPC | PPC_OPCODE_COMMON | PPC_OPCODE_ANY
+#define	COM32   PPC_OPCODE_POWER | PPC_OPCODE_PPC | PPC_OPCODE_COMMON | PPC_OPCODE_ANY | PPC_OPCODE_32
+#define	M601    PPC_OPCODE_POWER | PPC_OPCODE_601 | PPC_OPCODE_ANY
+#define PWRCOM	PPC_OPCODE_POWER | PPC_OPCODE_601 | PPC_OPCODE_COMMON | PPC_OPCODE_ANY
+#define	MFDEC1	PPC_OPCODE_POWER
+#define	MFDEC2	PPC_OPCODE_PPC | PPC_OPCODE_601
+
+/* The opcode table.
+
+   The format of the opcode table is:
+
+   NAME	     OPCODE	MASK		FLAGS		{ OPERANDS }
+
+   NAME is the name of the instruction.
+   OPCODE is the instruction opcode.
+   MASK is the opcode mask; this is used to tell the disassembler
+     which bits in the actual opcode must match OPCODE.
+   FLAGS are flags indicated what processors support the instruction.
+   OPERANDS is the list of operands.
+
+   The disassembler reads the table in order and prints the first
+   instruction which matches, so this table is sorted to put more
+   specific instructions before more general instructions.  It is also
+   sorted by major opcode.  */
+
+const struct powerpc_opcode powerpc_opcodes[] = {
+{ "tdlgti",  OPTO(2,TOLGT), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdllti",  OPTO(2,TOLLT), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdeqi",   OPTO(2,TOEQ), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdlgei",  OPTO(2,TOLGE), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdlnli",  OPTO(2,TOLNL), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdllei",  OPTO(2,TOLLE), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdlngi",  OPTO(2,TOLNG), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdgti",   OPTO(2,TOGT), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdgei",   OPTO(2,TOGE), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdnli",   OPTO(2,TONL), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdlti",   OPTO(2,TOLT), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdlei",   OPTO(2,TOLE), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdngi",   OPTO(2,TONG), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdnei",   OPTO(2,TONE), OPTO_MASK,	PPC64,		{ RA, SI } },
+{ "tdi",     OP(2),	OP_MASK,	PPC64,		{ TO, RA, SI } },
+
+{ "twlgti",  OPTO(3,TOLGT), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tlgti",   OPTO(3,TOLGT), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twllti",  OPTO(3,TOLLT), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tllti",   OPTO(3,TOLLT), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "tweqi",   OPTO(3,TOEQ), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "teqi",    OPTO(3,TOEQ), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twlgei",  OPTO(3,TOLGE), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tlgei",   OPTO(3,TOLGE), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twlnli",  OPTO(3,TOLNL), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tlnli",   OPTO(3,TOLNL), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twllei",  OPTO(3,TOLLE), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tllei",   OPTO(3,TOLLE), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twlngi",  OPTO(3,TOLNG), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tlngi",   OPTO(3,TOLNG), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twgti",   OPTO(3,TOGT), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tgti",    OPTO(3,TOGT), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twgei",   OPTO(3,TOGE), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tgei",    OPTO(3,TOGE), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twnli",   OPTO(3,TONL), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tnli",    OPTO(3,TONL), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twlti",   OPTO(3,TOLT), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tlti",    OPTO(3,TOLT), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twlei",   OPTO(3,TOLE), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tlei",    OPTO(3,TOLE), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twngi",   OPTO(3,TONG), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tngi",    OPTO(3,TONG), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twnei",   OPTO(3,TONE), OPTO_MASK,	PPCCOM,		{ RA, SI } },
+{ "tnei",    OPTO(3,TONE), OPTO_MASK,	PWRCOM,		{ RA, SI } },
+{ "twi",     OP(3),	OP_MASK,	PPCCOM,		{ TO, RA, SI } },
+{ "ti",      OP(3),	OP_MASK,	PWRCOM,		{ TO, RA, SI } },
+
+{ "macchw",	XO(4,172,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchw.",	XO(4,172,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwo",	XO(4,172,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwo.",	XO(4,172,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchws",	XO(4,236,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchws.",	XO(4,236,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwso",	XO(4,236,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwso.",	XO(4,236,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwsu",	XO(4,204,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwsu.",	XO(4,204,0,1), XO_MASK, PPC405,		{ RT, RA, RB } },
+{ "macchwsuo",	XO(4,204,1,0), XO_MASK, PPC405,		{ RT, RA, RB } },
+{ "macchwsuo.",	XO(4,204,1,1), XO_MASK, PPC405,		{ RT, RA, RB } },
+{ "macchwu",	XO(4,140,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwu.",	XO(4,140,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwuo",	XO(4,140,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "macchwuo.",	XO(4,140,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhw",	XO(4,44,0,0),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhw.",	XO(4,44,0,1),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwo",	XO(4,44,1,0),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwo.",	XO(4,44,1,1),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhws",	XO(4,108,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhws.",	XO(4,108,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwso",	XO(4,108,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwso.",	XO(4,108,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwsu",	XO(4,76,0,0),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwsu.",	XO(4,76,0,1),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwsuo",	XO(4,76,1,0),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwsuo.",	XO(4,76,1,1),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwu",	XO(4,12,0,0),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwu.",	XO(4,12,0,1),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwuo",	XO(4,12,1,0),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "machhwuo.",	XO(4,12,1,1),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhw",	XO(4,428,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhw.",	XO(4,428,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwo",	XO(4,428,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwo.",	XO(4,428,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhws",	XO(4,492,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhws.",	XO(4,492,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwso",	XO(4,492,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwso.",	XO(4,492,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwsu",	XO(4,460,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwsu.",	XO(4,460,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwsuo",	XO(4,460,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwsuo.",	XO(4,460,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwu",	XO(4,396,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwu.",	XO(4,396,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwuo",	XO(4,396,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "maclhwuo.",	XO(4,396,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mulchw",	XRC(4,168,0),  X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mulchw.",	XRC(4,168,1),  X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mulchwu",	XRC(4,136,0),  X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mulchwu.",	XRC(4,136,1),  X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mulhhw",	XRC(4,40,0),   X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mulhhw.",	XRC(4,40,1),   X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mulhhwu",	XRC(4,8,0),    X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mulhhwu.",	XRC(4,8,1),    X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mullhw",	XRC(4,424,0),  X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mullhw.",	XRC(4,424,1),  X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mullhwu",	XRC(4,392,0),  X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mullhwu.",	XRC(4,392,1),  X_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmacchw",	XO(4,174,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmacchw.",	XO(4,174,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmacchwo",	XO(4,174,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmacchwo.",	XO(4,174,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmacchws",	XO(4,238,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmacchws.",	XO(4,238,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmacchwso",	XO(4,238,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmacchwso.",	XO(4,238,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmachhw",	XO(4,46,0,0),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmachhw.",	XO(4,46,0,1),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmachhwo",	XO(4,46,1,0),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmachhwo.",	XO(4,46,1,1),  XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmachhws",	XO(4,110,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmachhws.",	XO(4,110,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmachhwso",	XO(4,110,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmachhwso.",	XO(4,110,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmaclhw",	XO(4,430,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmaclhw.",	XO(4,430,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmaclhwo",	XO(4,430,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmaclhwo.",	XO(4,430,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmaclhws",	XO(4,494,0,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmaclhws.",	XO(4,494,0,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmaclhwso",	XO(4,494,1,0), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "nmaclhwso.",	XO(4,494,1,1), XO_MASK,	PPC405,		{ RT, RA, RB } },
+{ "mfvscr",  VX(4, 1540), VX_MASK,	PPCVEC,		{ VD } },
+{ "mtvscr",  VX(4, 1604), VX_MASK,	PPCVEC,		{ VD } },
+{ "vaddcuw", VX(4,  384), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vaddfp",  VX(4,   10), VX_MASK, 	PPCVEC,		{ VD, VA, VB } },
+{ "vaddsbs", VX(4,  768), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vaddshs", VX(4,  832), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vaddsws", VX(4,  896), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vaddubm", VX(4,    0), VX_MASK, 	PPCVEC,		{ VD, VA, VB } },
+{ "vaddubs", VX(4,  512), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vadduhm", VX(4,   64), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vadduhs", VX(4,  576), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vadduwm", VX(4,  128), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vadduws", VX(4,  640), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vand",    VX(4, 1028), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vandc",   VX(4, 1092), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vavgsb",  VX(4, 1282), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vavgsh",  VX(4, 1346), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vavgsw",  VX(4, 1410), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vavgub",  VX(4, 1026), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vavguh",  VX(4, 1090), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vavguw",  VX(4, 1154), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vcfsx",   VX(4,  842), VX_MASK,	PPCVEC,		{ VD, VB, UIMM } },
+{ "vcfux",   VX(4,  778), VX_MASK,	PPCVEC,		{ VD, VB, UIMM } },
+{ "vcmpbfp",   VXR(4, 966, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpbfp.",  VXR(4, 966, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpeqfp",  VXR(4, 198, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpeqfp.", VXR(4, 198, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpequb",  VXR(4,   6, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpequb.", VXR(4,   6, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpequh",  VXR(4,  70, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpequh.", VXR(4,  70, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpequw",  VXR(4, 134, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpequw.", VXR(4, 134, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgefp",  VXR(4, 454, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgefp.", VXR(4, 454, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtfp",  VXR(4, 710, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtfp.", VXR(4, 710, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtsb",  VXR(4, 774, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtsb.", VXR(4, 774, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtsh",  VXR(4, 838, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtsh.", VXR(4, 838, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtsw",  VXR(4, 902, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtsw.", VXR(4, 902, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtub",  VXR(4, 518, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtub.", VXR(4, 518, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtuh",  VXR(4, 582, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtuh.", VXR(4, 582, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtuw",  VXR(4, 646, 0), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vcmpgtuw.", VXR(4, 646, 1), VXR_MASK, PPCVEC,	{ VD, VA, VB } },
+{ "vctsxs",    VX(4,  970), VX_MASK,	PPCVEC,		{ VD, VB, UIMM } },
+{ "vctuxs",    VX(4,  906), VX_MASK,	PPCVEC,		{ VD, VB, UIMM } },
+{ "vexptefp",  VX(4,  394), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vlogefp",   VX(4,  458), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vmaddfp",   VXA(4,  46), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmaxfp",    VX(4, 1034), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmaxsb",    VX(4,  258), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmaxsh",    VX(4,  322), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmaxsw",    VX(4,  386), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmaxub",    VX(4,    2), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmaxuh",    VX(4,   66), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmaxuw",    VX(4,  130), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmhaddshs", VXA(4,  32), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmhraddshs", VXA(4, 33), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vminfp",    VX(4, 1098), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vminsb",    VX(4,  770), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vminsh",    VX(4,  834), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vminsw",    VX(4,  898), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vminub",    VX(4,  514), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vminuh",    VX(4,  578), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vminuw",    VX(4,  642), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmladduhm", VXA(4,  34), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmrghb",    VX(4,   12), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmrghh",    VX(4,   76), VX_MASK,    PPCVEC,		{ VD, VA, VB } },
+{ "vmrghw",    VX(4,  140), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmrglb",    VX(4,  268), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmrglh",    VX(4,  332), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmrglw",    VX(4,  396), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmsummbm",  VXA(4,  37), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmsumshm",  VXA(4,  40), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmsumshs",  VXA(4,  41), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmsumubm",  VXA(4,  36), VXA_MASK,   PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmsumuhm",  VXA(4,  38), VXA_MASK,   PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmsumuhs",  VXA(4,  39), VXA_MASK,   PPCVEC,		{ VD, VA, VB, VC } },
+{ "vmulesb",   VX(4,  776), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmulesh",   VX(4,  840), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmuleub",   VX(4,  520), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmuleuh",   VX(4,  584), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmulosb",   VX(4,  264), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmulosh",   VX(4,  328), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmuloub",   VX(4,    8), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vmulouh",   VX(4,   72), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vnmsubfp",  VXA(4,  47), VXA_MASK,	PPCVEC,		{ VD, VA, VC, VB } },
+{ "vnor",      VX(4, 1284), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vor",       VX(4, 1156), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vperm",     VXA(4,  43), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vpkpx",     VX(4,  782), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vpkshss",   VX(4,  398), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vpkshus",   VX(4,  270), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vpkswss",   VX(4,  462), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vpkswus",   VX(4,  334), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vpkuhum",   VX(4,   14), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vpkuhus",   VX(4,  142), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vpkuwum",   VX(4,   78), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vpkuwus",   VX(4,  206), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vrefp",     VX(4,  266), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vrfim",     VX(4,  714), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vrfin",     VX(4,  522), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vrfip",     VX(4,  650), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vrfiz",     VX(4,  586), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vrlb",      VX(4,    4), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vrlh",      VX(4,   68), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vrlw",      VX(4,  132), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vrsqrtefp", VX(4,  330), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vsel",      VXA(4,  42), VXA_MASK,	PPCVEC,		{ VD, VA, VB, VC } },
+{ "vsl",       VX(4,  452), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vslb",      VX(4,  260), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsldoi",    VXA(4,  44), VXA_MASK,	PPCVEC,		{ VD, VA, VB, SHB } },
+{ "vslh",      VX(4,  324), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vslo",      VX(4, 1036), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vslw",      VX(4,  388), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vspltb",    VX(4,  524), VX_MASK,	PPCVEC,		{ VD, VB, UIMM } },
+{ "vsplth",    VX(4,  588), VX_MASK,	PPCVEC,		{ VD, VB, UIMM } },
+{ "vspltisb",  VX(4,  780), VX_MASK,	PPCVEC,		{ VD, SIMM } },
+{ "vspltish",  VX(4,  844), VX_MASK,	PPCVEC,		{ VD, SIMM } },
+{ "vspltisw",  VX(4,  908), VX_MASK,	PPCVEC,		{ VD, SIMM } },
+{ "vspltw",    VX(4,  652), VX_MASK,	PPCVEC,		{ VD, VB, UIMM } },
+{ "vsr",       VX(4,  708), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsrab",     VX(4,  772), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsrah",     VX(4,  836), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsraw",     VX(4,  900), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsrb",      VX(4,  516), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsrh",      VX(4,  580), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsro",      VX(4, 1100), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsrw",      VX(4,  644), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubcuw",   VX(4, 1408), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubfp",    VX(4,   74), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubsbs",   VX(4, 1792), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubshs",   VX(4, 1856), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubsws",   VX(4, 1920), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsububm",   VX(4, 1024), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsububs",   VX(4, 1536), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubuhm",   VX(4, 1088), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubuhs",   VX(4, 1600), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubuwm",   VX(4, 1152), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsubuws",   VX(4, 1664), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsumsws",   VX(4, 1928), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsum2sws",  VX(4, 1672), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsum4sbs",  VX(4, 1800), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsum4shs",  VX(4, 1608), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vsum4ubs",  VX(4, 1544), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+{ "vupkhpx",   VX(4,  846), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vupkhsb",   VX(4,  526), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vupkhsh",   VX(4,  590), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vupklpx",   VX(4,  974), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vupklsb",   VX(4,  654), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vupklsh",   VX(4,  718), VX_MASK,	PPCVEC,		{ VD, VB } },
+{ "vxor",      VX(4, 1220), VX_MASK,	PPCVEC,		{ VD, VA, VB } },
+
+{ "mulli",   OP(7),	OP_MASK,	PPCCOM,		{ RT, RA, SI } },
+{ "muli",    OP(7),	OP_MASK,	PWRCOM,		{ RT, RA, SI } },
+
+{ "subfic",  OP(8),	OP_MASK,	PPCCOM,		{ RT, RA, SI } },
+{ "sfi",     OP(8),	OP_MASK,	PWRCOM,		{ RT, RA, SI } },
+
+{ "dozi",    OP(9),	OP_MASK,	M601,		{ RT, RA, SI } },
+
+{ "cmplwi",  OPL(10,0),	OPL_MASK,	PPCCOM,		{ OBF, RA, UI } },
+{ "cmpldi",  OPL(10,1), OPL_MASK,	PPC64,		{ OBF, RA, UI } },
+{ "cmpli",   OP(10),	OP_MASK,	PPCONLY,	{ BF, L, RA, UI } },
+{ "cmpli",   OP(10),	OP_MASK,	PWRCOM,		{ BF, RA, UI } },
+
+{ "cmpwi",   OPL(11,0),	OPL_MASK,	PPCCOM,		{ OBF, RA, SI } },
+{ "cmpdi",   OPL(11,1),	OPL_MASK,	PPC64,		{ OBF, RA, SI } },
+{ "cmpi",    OP(11),	OP_MASK,	PPCONLY,	{ BF, L, RA, SI } },
+{ "cmpi",    OP(11),	OP_MASK,	PWRCOM,		{ BF, RA, SI } },
+
+{ "addic",   OP(12),	OP_MASK,	PPCCOM,		{ RT, RA, SI } },
+{ "ai",	     OP(12),	OP_MASK,	PWRCOM,		{ RT, RA, SI } },
+{ "subic",   OP(12),	OP_MASK,	PPCCOM,		{ RT, RA, NSI } },
+
+{ "addic.",  OP(13),	OP_MASK,	PPCCOM,		{ RT, RA, SI } },
+{ "ai.",     OP(13),	OP_MASK,	PWRCOM,		{ RT, RA, SI } },
+{ "subic.",  OP(13),	OP_MASK,	PPCCOM,		{ RT, RA, NSI } },
+
+{ "li",	     OP(14),	DRA_MASK,	PPCCOM,		{ RT, SI } },
+{ "lil",     OP(14),	DRA_MASK,	PWRCOM,		{ RT, SI } },
+{ "addi",    OP(14),	OP_MASK,	PPCCOM,		{ RT, RA, SI } },
+{ "cal",     OP(14),	OP_MASK,	PWRCOM,		{ RT, D, RA } },
+{ "subi",    OP(14),	OP_MASK,	PPCCOM,		{ RT, RA, NSI } },
+{ "la",	     OP(14),	OP_MASK,	PPCCOM,		{ RT, D, RA } },
+
+{ "lis",     OP(15),	DRA_MASK,	PPCCOM,		{ RT, SISIGNOPT } },
+{ "liu",     OP(15),	DRA_MASK,	PWRCOM,		{ RT, SISIGNOPT } },
+{ "addis",   OP(15),	OP_MASK,	PPCCOM,		{ RT,RA,SISIGNOPT } },
+{ "cau",     OP(15),	OP_MASK,	PWRCOM,		{ RT,RA,SISIGNOPT } },
+{ "subis",   OP(15),	OP_MASK,	PPCCOM,		{ RT, RA, NSI } },
+
+{ "bdnz-",   BBO(16,BODNZ,0,0), BBOYBI_MASK, PPCCOM,	{ BDM } },
+{ "bdnz+",   BBO(16,BODNZ,0,0), BBOYBI_MASK, PPCCOM,	{ BDP } },
+{ "bdnz",    BBO(16,BODNZ,0,0), BBOYBI_MASK, PPCCOM,	{ BD } },
+{ "bdn",     BBO(16,BODNZ,0,0), BBOYBI_MASK, PWRCOM,	{ BD } },
+{ "bdnzl-",  BBO(16,BODNZ,0,1), BBOYBI_MASK, PPCCOM,	{ BDM } },
+{ "bdnzl+",  BBO(16,BODNZ,0,1), BBOYBI_MASK, PPCCOM,	{ BDP } },
+{ "bdnzl",   BBO(16,BODNZ,0,1), BBOYBI_MASK, PPCCOM,	{ BD } },
+{ "bdnl",    BBO(16,BODNZ,0,1), BBOYBI_MASK, PWRCOM,	{ BD } },
+{ "bdnza-",  BBO(16,BODNZ,1,0), BBOYBI_MASK, PPCCOM,	{ BDMA } },
+{ "bdnza+",  BBO(16,BODNZ,1,0), BBOYBI_MASK, PPCCOM,	{ BDPA } },
+{ "bdnza",   BBO(16,BODNZ,1,0), BBOYBI_MASK, PPCCOM,	{ BDA } },
+{ "bdna",    BBO(16,BODNZ,1,0), BBOYBI_MASK, PWRCOM,	{ BDA } },
+{ "bdnzla-", BBO(16,BODNZ,1,1), BBOYBI_MASK, PPCCOM,	{ BDMA } },
+{ "bdnzla+", BBO(16,BODNZ,1,1), BBOYBI_MASK, PPCCOM,	{ BDPA } },
+{ "bdnzla",  BBO(16,BODNZ,1,1), BBOYBI_MASK, PPCCOM,	{ BDA } },
+{ "bdnla",   BBO(16,BODNZ,1,1), BBOYBI_MASK, PWRCOM,	{ BDA } },
+{ "bdz-",    BBO(16,BODZ,0,0),  BBOYBI_MASK, PPCCOM,	{ BDM } },
+{ "bdz+",    BBO(16,BODZ,0,0),  BBOYBI_MASK, PPCCOM,	{ BDP } },
+{ "bdz",     BBO(16,BODZ,0,0),  BBOYBI_MASK, COM,	{ BD } },
+{ "bdzl-",   BBO(16,BODZ,0,1),  BBOYBI_MASK, PPCCOM,	{ BDM } },
+{ "bdzl+",   BBO(16,BODZ,0,1),  BBOYBI_MASK, PPCCOM,	{ BDP } },
+{ "bdzl",    BBO(16,BODZ,0,1),  BBOYBI_MASK, COM,	{ BD } },
+{ "bdza-",   BBO(16,BODZ,1,0),  BBOYBI_MASK, PPCCOM,	{ BDMA } },
+{ "bdza+",   BBO(16,BODZ,1,0),  BBOYBI_MASK, PPCCOM,	{ BDPA } },
+{ "bdza",    BBO(16,BODZ,1,0),  BBOYBI_MASK, COM,	{ BDA } },
+{ "bdzla-",  BBO(16,BODZ,1,1),  BBOYBI_MASK, PPCCOM,	{ BDMA } },
+{ "bdzla+",  BBO(16,BODZ,1,1),  BBOYBI_MASK, PPCCOM,	{ BDPA } },
+{ "bdzla",   BBO(16,BODZ,1,1),  BBOYBI_MASK, COM,	{ BDA } },
+{ "blt-",    BBOCB(16,BOT,CBLT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "blt+",    BBOCB(16,BOT,CBLT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "blt",     BBOCB(16,BOT,CBLT,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bltl-",   BBOCB(16,BOT,CBLT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bltl+",   BBOCB(16,BOT,CBLT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bltl",    BBOCB(16,BOT,CBLT,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "blta-",   BBOCB(16,BOT,CBLT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "blta+",   BBOCB(16,BOT,CBLT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "blta",    BBOCB(16,BOT,CBLT,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bltla-",  BBOCB(16,BOT,CBLT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bltla+",  BBOCB(16,BOT,CBLT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bltla",   BBOCB(16,BOT,CBLT,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bgt-",    BBOCB(16,BOT,CBGT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bgt+",    BBOCB(16,BOT,CBGT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bgt",     BBOCB(16,BOT,CBGT,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bgtl-",   BBOCB(16,BOT,CBGT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bgtl+",   BBOCB(16,BOT,CBGT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bgtl",    BBOCB(16,BOT,CBGT,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bgta-",   BBOCB(16,BOT,CBGT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bgta+",   BBOCB(16,BOT,CBGT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bgta",    BBOCB(16,BOT,CBGT,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bgtla-",  BBOCB(16,BOT,CBGT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bgtla+",  BBOCB(16,BOT,CBGT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bgtla",   BBOCB(16,BOT,CBGT,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "beq-",    BBOCB(16,BOT,CBEQ,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "beq+",    BBOCB(16,BOT,CBEQ,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "beq",     BBOCB(16,BOT,CBEQ,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "beql-",   BBOCB(16,BOT,CBEQ,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "beql+",   BBOCB(16,BOT,CBEQ,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "beql",    BBOCB(16,BOT,CBEQ,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "beqa-",   BBOCB(16,BOT,CBEQ,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "beqa+",   BBOCB(16,BOT,CBEQ,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "beqa",    BBOCB(16,BOT,CBEQ,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "beqla-",  BBOCB(16,BOT,CBEQ,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "beqla+",  BBOCB(16,BOT,CBEQ,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "beqla",   BBOCB(16,BOT,CBEQ,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bso-",    BBOCB(16,BOT,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bso+",    BBOCB(16,BOT,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bso",     BBOCB(16,BOT,CBSO,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bsol-",   BBOCB(16,BOT,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bsol+",   BBOCB(16,BOT,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bsol",    BBOCB(16,BOT,CBSO,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bsoa-",   BBOCB(16,BOT,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bsoa+",   BBOCB(16,BOT,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bsoa",    BBOCB(16,BOT,CBSO,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bsola-",  BBOCB(16,BOT,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bsola+",  BBOCB(16,BOT,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bsola",   BBOCB(16,BOT,CBSO,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bun-",    BBOCB(16,BOT,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bun+",    BBOCB(16,BOT,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bun",     BBOCB(16,BOT,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BD } },
+{ "bunl-",   BBOCB(16,BOT,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bunl+",   BBOCB(16,BOT,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bunl",    BBOCB(16,BOT,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BD } },
+{ "buna-",   BBOCB(16,BOT,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "buna+",   BBOCB(16,BOT,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "buna",    BBOCB(16,BOT,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDA } },
+{ "bunla-",  BBOCB(16,BOT,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bunla+",  BBOCB(16,BOT,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bunla",   BBOCB(16,BOT,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDA } },
+{ "bge-",    BBOCB(16,BOF,CBLT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bge+",    BBOCB(16,BOF,CBLT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bge",     BBOCB(16,BOF,CBLT,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bgel-",   BBOCB(16,BOF,CBLT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bgel+",   BBOCB(16,BOF,CBLT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bgel",    BBOCB(16,BOF,CBLT,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bgea-",   BBOCB(16,BOF,CBLT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bgea+",   BBOCB(16,BOF,CBLT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bgea",    BBOCB(16,BOF,CBLT,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bgela-",  BBOCB(16,BOF,CBLT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bgela+",  BBOCB(16,BOF,CBLT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bgela",   BBOCB(16,BOF,CBLT,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bnl-",    BBOCB(16,BOF,CBLT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bnl+",    BBOCB(16,BOF,CBLT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bnl",     BBOCB(16,BOF,CBLT,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bnll-",   BBOCB(16,BOF,CBLT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bnll+",   BBOCB(16,BOF,CBLT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bnll",    BBOCB(16,BOF,CBLT,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bnla-",   BBOCB(16,BOF,CBLT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnla+",   BBOCB(16,BOF,CBLT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnla",    BBOCB(16,BOF,CBLT,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bnlla-",  BBOCB(16,BOF,CBLT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnlla+",  BBOCB(16,BOF,CBLT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnlla",   BBOCB(16,BOF,CBLT,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "ble-",    BBOCB(16,BOF,CBGT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "ble+",    BBOCB(16,BOF,CBGT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "ble",     BBOCB(16,BOF,CBGT,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "blel-",   BBOCB(16,BOF,CBGT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "blel+",   BBOCB(16,BOF,CBGT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "blel",    BBOCB(16,BOF,CBGT,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "blea-",   BBOCB(16,BOF,CBGT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "blea+",   BBOCB(16,BOF,CBGT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "blea",    BBOCB(16,BOF,CBGT,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "blela-",  BBOCB(16,BOF,CBGT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "blela+",  BBOCB(16,BOF,CBGT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "blela",   BBOCB(16,BOF,CBGT,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bng-",    BBOCB(16,BOF,CBGT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bng+",    BBOCB(16,BOF,CBGT,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bng",     BBOCB(16,BOF,CBGT,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bngl-",   BBOCB(16,BOF,CBGT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bngl+",   BBOCB(16,BOF,CBGT,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bngl",    BBOCB(16,BOF,CBGT,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bnga-",   BBOCB(16,BOF,CBGT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnga+",   BBOCB(16,BOF,CBGT,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnga",    BBOCB(16,BOF,CBGT,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bngla-",  BBOCB(16,BOF,CBGT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bngla+",  BBOCB(16,BOF,CBGT,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bngla",   BBOCB(16,BOF,CBGT,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bne-",    BBOCB(16,BOF,CBEQ,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bne+",    BBOCB(16,BOF,CBEQ,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bne",     BBOCB(16,BOF,CBEQ,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bnel-",   BBOCB(16,BOF,CBEQ,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bnel+",   BBOCB(16,BOF,CBEQ,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bnel",    BBOCB(16,BOF,CBEQ,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bnea-",   BBOCB(16,BOF,CBEQ,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnea+",   BBOCB(16,BOF,CBEQ,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnea",    BBOCB(16,BOF,CBEQ,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bnela-",  BBOCB(16,BOF,CBEQ,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnela+",  BBOCB(16,BOF,CBEQ,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnela",   BBOCB(16,BOF,CBEQ,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bns-",    BBOCB(16,BOF,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bns+",    BBOCB(16,BOF,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bns",     BBOCB(16,BOF,CBSO,0,0), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bnsl-",   BBOCB(16,BOF,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bnsl+",   BBOCB(16,BOF,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bnsl",    BBOCB(16,BOF,CBSO,0,1), BBOYCB_MASK, COM,		{ CR, BD } },
+{ "bnsa-",   BBOCB(16,BOF,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnsa+",   BBOCB(16,BOF,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnsa",    BBOCB(16,BOF,CBSO,1,0), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bnsla-",  BBOCB(16,BOF,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnsla+",  BBOCB(16,BOF,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnsla",   BBOCB(16,BOF,CBSO,1,1), BBOYCB_MASK, COM,		{ CR, BDA } },
+{ "bnu-",    BBOCB(16,BOF,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bnu+",    BBOCB(16,BOF,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bnu",     BBOCB(16,BOF,CBSO,0,0), BBOYCB_MASK, PPCCOM,	{ CR, BD } },
+{ "bnul-",   BBOCB(16,BOF,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDM } },
+{ "bnul+",   BBOCB(16,BOF,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BDP } },
+{ "bnul",    BBOCB(16,BOF,CBSO,0,1), BBOYCB_MASK, PPCCOM,	{ CR, BD } },
+{ "bnua-",   BBOCB(16,BOF,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnua+",   BBOCB(16,BOF,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnua",    BBOCB(16,BOF,CBSO,1,0), BBOYCB_MASK, PPCCOM,	{ CR, BDA } },
+{ "bnula-",  BBOCB(16,BOF,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDMA } },
+{ "bnula+",  BBOCB(16,BOF,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDPA } },
+{ "bnula",   BBOCB(16,BOF,CBSO,1,1), BBOYCB_MASK, PPCCOM,	{ CR, BDA } },
+{ "bdnzt-",  BBO(16,BODNZT,0,0), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bdnzt+",  BBO(16,BODNZT,0,0), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bdnzt",   BBO(16,BODNZT,0,0), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bdnztl-", BBO(16,BODNZT,0,1), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bdnztl+", BBO(16,BODNZT,0,1), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bdnztl",  BBO(16,BODNZT,0,1), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bdnzta-", BBO(16,BODNZT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bdnzta+", BBO(16,BODNZT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bdnzta",  BBO(16,BODNZT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bdnztla-",BBO(16,BODNZT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bdnztla+",BBO(16,BODNZT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bdnztla", BBO(16,BODNZT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bdnzf-",  BBO(16,BODNZF,0,0), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bdnzf+",  BBO(16,BODNZF,0,0), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bdnzf",   BBO(16,BODNZF,0,0), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bdnzfl-", BBO(16,BODNZF,0,1), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bdnzfl+", BBO(16,BODNZF,0,1), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bdnzfl",  BBO(16,BODNZF,0,1), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bdnzfa-", BBO(16,BODNZF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bdnzfa+", BBO(16,BODNZF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bdnzfa",  BBO(16,BODNZF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bdnzfla-",BBO(16,BODNZF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bdnzfla+",BBO(16,BODNZF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bdnzfla", BBO(16,BODNZF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bt-",     BBO(16,BOT,0,0), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bt+",     BBO(16,BOT,0,0), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bt",	     BBO(16,BOT,0,0), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bbt",     BBO(16,BOT,0,0), BBOY_MASK, PWRCOM,	{ BI, BD } },
+{ "btl-",    BBO(16,BOT,0,1), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "btl+",    BBO(16,BOT,0,1), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "btl",     BBO(16,BOT,0,1), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bbtl",    BBO(16,BOT,0,1), BBOY_MASK, PWRCOM,	{ BI, BD } },
+{ "bta-",    BBO(16,BOT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bta+",    BBO(16,BOT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bta",     BBO(16,BOT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bbta",    BBO(16,BOT,1,0), BBOY_MASK, PWRCOM,	{ BI, BDA } },
+{ "btla-",   BBO(16,BOT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "btla+",   BBO(16,BOT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "btla",    BBO(16,BOT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bbtla",   BBO(16,BOT,1,1), BBOY_MASK, PWRCOM,	{ BI, BDA } },
+{ "bf-",     BBO(16,BOF,0,0), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bf+",     BBO(16,BOF,0,0), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bf",	     BBO(16,BOF,0,0), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bbf",     BBO(16,BOF,0,0), BBOY_MASK, PWRCOM,	{ BI, BD } },
+{ "bfl-",    BBO(16,BOF,0,1), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bfl+",    BBO(16,BOF,0,1), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bfl",     BBO(16,BOF,0,1), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bbfl",    BBO(16,BOF,0,1), BBOY_MASK, PWRCOM,	{ BI, BD } },
+{ "bfa-",    BBO(16,BOF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bfa+",    BBO(16,BOF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bfa",     BBO(16,BOF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bbfa",    BBO(16,BOF,1,0), BBOY_MASK, PWRCOM,	{ BI, BDA } },
+{ "bfla-",   BBO(16,BOF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bfla+",   BBO(16,BOF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bfla",    BBO(16,BOF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bbfla",   BBO(16,BOF,1,1), BBOY_MASK, PWRCOM,	{ BI, BDA } },
+{ "bdzt-",   BBO(16,BODZT,0,0), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bdzt+",   BBO(16,BODZT,0,0), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bdzt",    BBO(16,BODZT,0,0), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bdztl-",  BBO(16,BODZT,0,1), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bdztl+",  BBO(16,BODZT,0,1), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bdztl",   BBO(16,BODZT,0,1), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bdzta-",  BBO(16,BODZT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bdzta+",  BBO(16,BODZT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bdzta",   BBO(16,BODZT,1,0), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bdztla-", BBO(16,BODZT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bdztla+", BBO(16,BODZT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bdztla",  BBO(16,BODZT,1,1), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bdzf-",   BBO(16,BODZF,0,0), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bdzf+",   BBO(16,BODZF,0,0), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bdzf",    BBO(16,BODZF,0,0), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bdzfl-",  BBO(16,BODZF,0,1), BBOY_MASK, PPCCOM,	{ BI, BDM } },
+{ "bdzfl+",  BBO(16,BODZF,0,1), BBOY_MASK, PPCCOM,	{ BI, BDP } },
+{ "bdzfl",   BBO(16,BODZF,0,1), BBOY_MASK, PPCCOM,	{ BI, BD } },
+{ "bdzfa-",  BBO(16,BODZF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bdzfa+",  BBO(16,BODZF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bdzfa",   BBO(16,BODZF,1,0), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bdzfla-", BBO(16,BODZF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDMA } },
+{ "bdzfla+", BBO(16,BODZF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDPA } },
+{ "bdzfla",  BBO(16,BODZF,1,1), BBOY_MASK, PPCCOM,	{ BI, BDA } },
+{ "bc-",     B(16,0,0),	B_MASK,		PPCCOM,		{ BOE, BI, BDM } },
+{ "bc+",     B(16,0,0),	B_MASK,		PPCCOM,		{ BOE, BI, BDP } },
+{ "bc",	     B(16,0,0),	B_MASK,		COM,		{ BO, BI, BD } },
+{ "bcl-",    B(16,0,1),	B_MASK,		PPCCOM,		{ BOE, BI, BDM } },
+{ "bcl+",    B(16,0,1),	B_MASK,		PPCCOM,		{ BOE, BI, BDP } },
+{ "bcl",     B(16,0,1),	B_MASK,		COM,		{ BO, BI, BD } },
+{ "bca-",    B(16,1,0),	B_MASK,		PPCCOM,		{ BOE, BI, BDMA } },
+{ "bca+",    B(16,1,0),	B_MASK,		PPCCOM,		{ BOE, BI, BDPA } },
+{ "bca",     B(16,1,0),	B_MASK,		COM,		{ BO, BI, BDA } },
+{ "bcla-",   B(16,1,1),	B_MASK,		PPCCOM,		{ BOE, BI, BDMA } },
+{ "bcla+",   B(16,1,1),	B_MASK,		PPCCOM,		{ BOE, BI, BDPA } },
+{ "bcla",    B(16,1,1),	B_MASK,		COM,		{ BO, BI, BDA } },
+
+{ "sc",      SC(17,1,0), 0xffffffff,	PPC,		{ 0 } },
+{ "svc",     SC(17,0,0), SC_MASK,	POWER,		{ LEV, FL1, FL2 } },
+{ "svcl",    SC(17,0,1), SC_MASK,	POWER,		{ LEV, FL1, FL2 } },
+{ "svca",    SC(17,1,0), SC_MASK,	PWRCOM,		{ SV } },
+{ "svcla",   SC(17,1,1), SC_MASK,	POWER,		{ SV } },
+
+{ "b",	     B(18,0,0),	B_MASK,		COM,	{ LI } },
+{ "bl",      B(18,0,1),	B_MASK,		COM,	{ LI } },
+{ "ba",      B(18,1,0),	B_MASK,		COM,	{ LIA } },
+{ "bla",     B(18,1,1),	B_MASK,		COM,	{ LIA } },
+
+{ "mcrf",    XL(19,0),	XLBB_MASK|(3<<21)|(3<<16), COM,	{ BF, BFA } },
+
+{ "blr",     XLO(19,BOU,16,0), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "br",      XLO(19,BOU,16,0), XLBOBIBB_MASK, PWRCOM,	{ 0 } },
+{ "blrl",    XLO(19,BOU,16,1), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "brl",     XLO(19,BOU,16,1), XLBOBIBB_MASK, PWRCOM,	{ 0 } },
+{ "bdnzlr",  XLO(19,BODNZ,16,0), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdnzlr-", XLO(19,BODNZ,16,0), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdnzlr+", XLO(19,BODNZP,16,0), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdnzlrl", XLO(19,BODNZ,16,1), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdnzlrl-",XLO(19,BODNZ,16,1), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdnzlrl+",XLO(19,BODNZP,16,1), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdzlr",   XLO(19,BODZ,16,0), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdzlr-",  XLO(19,BODZ,16,0), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdzlr+",  XLO(19,BODZP,16,0), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdzlrl",  XLO(19,BODZ,16,1), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdzlrl-", XLO(19,BODZ,16,1), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bdzlrl+", XLO(19,BODZP,16,1), XLBOBIBB_MASK, PPCCOM,	{ 0 } },
+{ "bltlr",   XLOCB(19,BOT,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bltlr-",  XLOCB(19,BOT,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bltlr+",  XLOCB(19,BOTP,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bltr",    XLOCB(19,BOT,CBLT,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bltlrl",  XLOCB(19,BOT,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bltlrl-", XLOCB(19,BOT,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bltlrl+", XLOCB(19,BOTP,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bltrl",   XLOCB(19,BOT,CBLT,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bgtlr",   XLOCB(19,BOT,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgtlr-",  XLOCB(19,BOT,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgtlr+",  XLOCB(19,BOTP,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgtr",    XLOCB(19,BOT,CBGT,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bgtlrl",  XLOCB(19,BOT,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgtlrl-", XLOCB(19,BOT,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgtlrl+", XLOCB(19,BOTP,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgtrl",   XLOCB(19,BOT,CBGT,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "beqlr",   XLOCB(19,BOT,CBEQ,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "beqlr-",  XLOCB(19,BOT,CBEQ,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "beqlr+",  XLOCB(19,BOTP,CBEQ,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "beqr",    XLOCB(19,BOT,CBEQ,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "beqlrl",  XLOCB(19,BOT,CBEQ,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "beqlrl-", XLOCB(19,BOT,CBEQ,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "beqlrl+", XLOCB(19,BOTP,CBEQ,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "beqrl",   XLOCB(19,BOT,CBEQ,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bsolr",   XLOCB(19,BOT,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bsolr-",  XLOCB(19,BOT,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bsolr+",  XLOCB(19,BOTP,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bsor",    XLOCB(19,BOT,CBSO,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bsolrl",  XLOCB(19,BOT,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bsolrl-", XLOCB(19,BOT,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bsolrl+", XLOCB(19,BOTP,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bsorl",   XLOCB(19,BOT,CBSO,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bunlr",   XLOCB(19,BOT,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bunlr-",  XLOCB(19,BOT,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bunlr+",  XLOCB(19,BOTP,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bunlrl",  XLOCB(19,BOT,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bunlrl-", XLOCB(19,BOT,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bunlrl+", XLOCB(19,BOTP,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgelr",   XLOCB(19,BOF,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgelr-",  XLOCB(19,BOF,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgelr+",  XLOCB(19,BOFP,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bger",    XLOCB(19,BOF,CBLT,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bgelrl",  XLOCB(19,BOF,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgelrl-", XLOCB(19,BOF,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgelrl+", XLOCB(19,BOFP,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bgerl",   XLOCB(19,BOF,CBLT,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnllr",   XLOCB(19,BOF,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnllr-",  XLOCB(19,BOF,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnllr+",  XLOCB(19,BOFP,CBLT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnlr",    XLOCB(19,BOF,CBLT,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnllrl",  XLOCB(19,BOF,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnllrl-", XLOCB(19,BOF,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnllrl+", XLOCB(19,BOFP,CBLT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnlrl",   XLOCB(19,BOF,CBLT,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "blelr",   XLOCB(19,BOF,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "blelr-",  XLOCB(19,BOF,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "blelr+",  XLOCB(19,BOFP,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bler",    XLOCB(19,BOF,CBGT,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "blelrl",  XLOCB(19,BOF,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "blelrl-", XLOCB(19,BOF,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "blelrl+", XLOCB(19,BOFP,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "blerl",   XLOCB(19,BOF,CBGT,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnglr",   XLOCB(19,BOF,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnglr-",  XLOCB(19,BOF,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnglr+",  XLOCB(19,BOFP,CBGT,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bngr",    XLOCB(19,BOF,CBGT,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnglrl",  XLOCB(19,BOF,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnglrl-", XLOCB(19,BOF,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnglrl+", XLOCB(19,BOFP,CBGT,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bngrl",   XLOCB(19,BOF,CBGT,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnelr",   XLOCB(19,BOF,CBEQ,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnelr-",  XLOCB(19,BOF,CBEQ,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnelr+",  XLOCB(19,BOFP,CBEQ,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bner",    XLOCB(19,BOF,CBEQ,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnelrl",  XLOCB(19,BOF,CBEQ,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnelrl-", XLOCB(19,BOF,CBEQ,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnelrl+", XLOCB(19,BOFP,CBEQ,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnerl",   XLOCB(19,BOF,CBEQ,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnslr",   XLOCB(19,BOF,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnslr-",  XLOCB(19,BOF,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnslr+",  XLOCB(19,BOFP,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnsr",    XLOCB(19,BOF,CBSO,16,0), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnslrl",  XLOCB(19,BOF,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnslrl-", XLOCB(19,BOF,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnslrl+", XLOCB(19,BOFP,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnsrl",   XLOCB(19,BOF,CBSO,16,1), XLBOCBBB_MASK, PWRCOM, { CR } },
+{ "bnulr",   XLOCB(19,BOF,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnulr-",  XLOCB(19,BOF,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnulr+",  XLOCB(19,BOFP,CBSO,16,0), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnulrl",  XLOCB(19,BOF,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnulrl-", XLOCB(19,BOF,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "bnulrl+", XLOCB(19,BOFP,CBSO,16,1), XLBOCBBB_MASK, PPCCOM, { CR } },
+{ "btlr",    XLO(19,BOT,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btlr-",   XLO(19,BOT,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btlr+",   XLO(19,BOTP,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bbtr",    XLO(19,BOT,16,0), XLBOBB_MASK, PWRCOM,	{ BI } },
+{ "btlrl",   XLO(19,BOT,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btlrl-",  XLO(19,BOT,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btlrl+",  XLO(19,BOTP,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bbtrl",   XLO(19,BOT,16,1), XLBOBB_MASK, PWRCOM,	{ BI } },
+{ "bflr",    XLO(19,BOF,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bflr-",   XLO(19,BOF,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bflr+",   XLO(19,BOFP,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bbfr",    XLO(19,BOF,16,0), XLBOBB_MASK, PWRCOM,	{ BI } },
+{ "bflrl",   XLO(19,BOF,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bflrl-",  XLO(19,BOF,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bflrl+",  XLO(19,BOFP,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bbfrl",   XLO(19,BOF,16,1), XLBOBB_MASK, PWRCOM,	{ BI } },
+{ "bdnztlr", XLO(19,BODNZT,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnztlr-",XLO(19,BODNZT,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnztlr+",XLO(19,BODNZTP,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnztlrl",XLO(19,BODNZT,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnztlrl-",XLO(19,BODNZT,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnztlrl+",XLO(19,BODNZTP,16,1), XLBOBB_MASK, PPCCOM,{ BI } },
+{ "bdnzflr", XLO(19,BODNZF,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnzflr-",XLO(19,BODNZF,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnzflr+",XLO(19,BODNZFP,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnzflrl",XLO(19,BODNZF,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnzflrl-",XLO(19,BODNZF,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdnzflrl+",XLO(19,BODNZFP,16,1), XLBOBB_MASK, PPCCOM,{ BI } },
+{ "bdztlr",  XLO(19,BODZT,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdztlr-", XLO(19,BODZT,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdztlr+", XLO(19,BODZTP,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdztlrl", XLO(19,BODZT,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdztlrl-",XLO(19,BODZT,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdztlrl+",XLO(19,BODZTP,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdzflr",  XLO(19,BODZF,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdzflr-", XLO(19,BODZF,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdzflr+", XLO(19,BODZFP,16,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdzflrl", XLO(19,BODZF,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdzflrl-",XLO(19,BODZF,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bdzflrl+",XLO(19,BODZFP,16,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bclr",    XLLK(19,16,0), XLYBB_MASK,	PPCCOM,		{ BO, BI } },
+{ "bclrl",   XLLK(19,16,1), XLYBB_MASK,	PPCCOM,		{ BO, BI } },
+{ "bclr+",   XLYLK(19,16,1,0), XLYBB_MASK, PPCCOM,	{ BOE, BI } },
+{ "bclrl+",  XLYLK(19,16,1,1), XLYBB_MASK, PPCCOM,	{ BOE, BI } },
+{ "bclr-",   XLYLK(19,16,0,0), XLYBB_MASK, PPCCOM,	{ BOE, BI } },
+{ "bclrl-",  XLYLK(19,16,0,1), XLYBB_MASK, PPCCOM,	{ BOE, BI } },
+{ "bcr",     XLLK(19,16,0), XLBB_MASK,	PWRCOM,		{ BO, BI } },
+{ "bcrl",    XLLK(19,16,1), XLBB_MASK,	PWRCOM,		{ BO, BI } },
+
+{ "rfid",    XL(19,18),	0xffffffff,	PPC64,		{ 0 } },
+
+{ "crnot",   XL(19,33), XL_MASK,	PPCCOM,		{ BT, BA, BBA } },
+{ "crnor",   XL(19,33),	XL_MASK,	COM,		{ BT, BA, BB } },
+
+{ "rfi",     XL(19,50),	0xffffffff,	COM,		{ 0 } },
+{ "rfci",    XL(19,51),	0xffffffff,	PPC403,		{ 0 } },
+
+{ "rfsvc",   XL(19,82),	0xffffffff,	POWER,		{ 0 } },
+
+{ "crandc",  XL(19,129), XL_MASK,	COM,		{ BT, BA, BB } },
+
+{ "isync",   XL(19,150), 0xffffffff,	PPCCOM,		{ 0 } },
+{ "ics",     XL(19,150), 0xffffffff,	PWRCOM,		{ 0 } },
+
+{ "crclr",   XL(19,193), XL_MASK,	PPCCOM,		{ BT, BAT, BBA } },
+{ "crxor",   XL(19,193), XL_MASK,	COM,		{ BT, BA, BB } },
+
+{ "crnand",  XL(19,225), XL_MASK,	COM,		{ BT, BA, BB } },
+
+{ "crand",   XL(19,257), XL_MASK,	COM,		{ BT, BA, BB } },
+
+{ "crset",   XL(19,289), XL_MASK,	PPCCOM,		{ BT, BAT, BBA } },
+{ "creqv",   XL(19,289), XL_MASK,	COM,		{ BT, BA, BB } },
+
+{ "crorc",   XL(19,417), XL_MASK,	COM,		{ BT, BA, BB } },
+
+{ "crmove",  XL(19,449), XL_MASK,	PPCCOM,		{ BT, BA, BBA } },
+{ "cror",    XL(19,449), XL_MASK,	COM,		{ BT, BA, BB } },
+
+{ "bctr",    XLO(19,BOU,528,0), XLBOBIBB_MASK, COM,	{ 0 } },
+{ "bctrl",   XLO(19,BOU,528,1), XLBOBIBB_MASK, COM,	{ 0 } },
+{ "bltctr",  XLOCB(19,BOT,CBLT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bltctr-", XLOCB(19,BOT,CBLT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bltctr+", XLOCB(19,BOTP,CBLT,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bltctrl", XLOCB(19,BOT,CBLT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bltctrl-",XLOCB(19,BOT,CBLT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bltctrl+",XLOCB(19,BOTP,CBLT,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgtctr",  XLOCB(19,BOT,CBGT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgtctr-", XLOCB(19,BOT,CBGT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgtctr+", XLOCB(19,BOTP,CBGT,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgtctrl", XLOCB(19,BOT,CBGT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgtctrl-",XLOCB(19,BOT,CBGT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgtctrl+",XLOCB(19,BOTP,CBGT,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "beqctr",  XLOCB(19,BOT,CBEQ,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "beqctr-", XLOCB(19,BOT,CBEQ,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "beqctr+", XLOCB(19,BOTP,CBEQ,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "beqctrl", XLOCB(19,BOT,CBEQ,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "beqctrl-",XLOCB(19,BOT,CBEQ,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "beqctrl+",XLOCB(19,BOTP,CBEQ,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bsoctr",  XLOCB(19,BOT,CBSO,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bsoctr-", XLOCB(19,BOT,CBSO,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bsoctr+", XLOCB(19,BOTP,CBSO,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bsoctrl", XLOCB(19,BOT,CBSO,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bsoctrl-",XLOCB(19,BOT,CBSO,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bsoctrl+",XLOCB(19,BOTP,CBSO,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bunctr",  XLOCB(19,BOT,CBSO,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bunctr-", XLOCB(19,BOT,CBSO,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bunctr+", XLOCB(19,BOTP,CBSO,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bunctrl", XLOCB(19,BOT,CBSO,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bunctrl-",XLOCB(19,BOT,CBSO,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bunctrl+",XLOCB(19,BOTP,CBSO,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgectr",  XLOCB(19,BOF,CBLT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgectr-", XLOCB(19,BOF,CBLT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgectr+", XLOCB(19,BOFP,CBLT,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgectrl", XLOCB(19,BOF,CBLT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgectrl-",XLOCB(19,BOF,CBLT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bgectrl+",XLOCB(19,BOFP,CBLT,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnlctr",  XLOCB(19,BOF,CBLT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnlctr-", XLOCB(19,BOF,CBLT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnlctr+", XLOCB(19,BOFP,CBLT,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnlctrl", XLOCB(19,BOF,CBLT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnlctrl-",XLOCB(19,BOF,CBLT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnlctrl+",XLOCB(19,BOFP,CBLT,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "blectr",  XLOCB(19,BOF,CBGT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "blectr-", XLOCB(19,BOF,CBGT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "blectr+", XLOCB(19,BOFP,CBGT,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "blectrl", XLOCB(19,BOF,CBGT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "blectrl-",XLOCB(19,BOF,CBGT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "blectrl+",XLOCB(19,BOFP,CBGT,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bngctr",  XLOCB(19,BOF,CBGT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bngctr-", XLOCB(19,BOF,CBGT,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bngctr+", XLOCB(19,BOFP,CBGT,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bngctrl", XLOCB(19,BOF,CBGT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bngctrl-",XLOCB(19,BOF,CBGT,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bngctrl+",XLOCB(19,BOFP,CBGT,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnectr",  XLOCB(19,BOF,CBEQ,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnectr-", XLOCB(19,BOF,CBEQ,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnectr+", XLOCB(19,BOFP,CBEQ,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnectrl", XLOCB(19,BOF,CBEQ,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnectrl-",XLOCB(19,BOF,CBEQ,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnectrl+",XLOCB(19,BOFP,CBEQ,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnsctr",  XLOCB(19,BOF,CBSO,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnsctr-", XLOCB(19,BOF,CBSO,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnsctr+", XLOCB(19,BOFP,CBSO,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnsctrl", XLOCB(19,BOF,CBSO,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnsctrl-",XLOCB(19,BOF,CBSO,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnsctrl+",XLOCB(19,BOFP,CBSO,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnuctr",  XLOCB(19,BOF,CBSO,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnuctr-", XLOCB(19,BOF,CBSO,528,0),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnuctr+", XLOCB(19,BOFP,CBSO,528,0), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnuctrl", XLOCB(19,BOF,CBSO,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnuctrl-",XLOCB(19,BOF,CBSO,528,1),  XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "bnuctrl+",XLOCB(19,BOFP,CBSO,528,1), XLBOCBBB_MASK, PPCCOM,	{ CR } },
+{ "btctr",   XLO(19,BOT,528,0),  XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btctr-",  XLO(19,BOT,528,0),  XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btctr+",  XLO(19,BOTP,528,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btctrl",  XLO(19,BOT,528,1),  XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btctrl-", XLO(19,BOT,528,1),  XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "btctrl+", XLO(19,BOTP,528,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bfctr",   XLO(19,BOF,528,0),  XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bfctr-",  XLO(19,BOF,528,0),  XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bfctr+",  XLO(19,BOFP,528,0), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bfctrl",  XLO(19,BOF,528,1),  XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bfctrl-", XLO(19,BOF,528,1),  XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bfctrl+", XLO(19,BOFP,528,1), XLBOBB_MASK, PPCCOM,	{ BI } },
+{ "bcctr",   XLLK(19,528,0),     XLYBB_MASK,  PPCCOM,	{ BO, BI } },
+{ "bcctr-",  XLYLK(19,528,0,0),  XLYBB_MASK,  PPCCOM,	{ BOE, BI } },
+{ "bcctr+",  XLYLK(19,528,1,0),  XLYBB_MASK,  PPCCOM,	{ BOE, BI } },
+{ "bcctrl",  XLLK(19,528,1),     XLYBB_MASK,  PPCCOM,	{ BO, BI } },
+{ "bcctrl-", XLYLK(19,528,0,1),  XLYBB_MASK,  PPCCOM,	{ BOE, BI } },
+{ "bcctrl+", XLYLK(19,528,1,1),  XLYBB_MASK,  PPCCOM,	{ BOE, BI } },
+{ "bcc",     XLLK(19,528,0),     XLBB_MASK,   PWRCOM,	{ BO, BI } },
+{ "bccl",    XLLK(19,528,1),     XLBB_MASK,   PWRCOM,	{ BO, BI } },
+
+{ "rlwimi",  M(20,0),	M_MASK,		PPCCOM,		{ RA,RS,SH,MBE,ME } },
+{ "rlimi",   M(20,0),	M_MASK,		PWRCOM,		{ RA,RS,SH,MBE,ME } },
+
+{ "rlwimi.", M(20,1),	M_MASK,		PPCCOM,		{ RA,RS,SH,MBE,ME } },
+{ "rlimi.",  M(20,1),	M_MASK,		PWRCOM,		{ RA,RS,SH,MBE,ME } },
+
+{ "rotlwi",  MME(21,31,0), MMBME_MASK,	PPCCOM,		{ RA, RS, SH } },
+{ "clrlwi",  MME(21,31,0), MSHME_MASK,	PPCCOM,		{ RA, RS, MB } },
+{ "rlwinm",  M(21,0),	M_MASK,		PPCCOM,		{ RA,RS,SH,MBE,ME } },
+{ "rlinm",   M(21,0),	M_MASK,		PWRCOM,		{ RA,RS,SH,MBE,ME } },
+{ "rotlwi.", MME(21,31,1), MMBME_MASK,	PPCCOM,		{ RA,RS,SH } },
+{ "clrlwi.", MME(21,31,1), MSHME_MASK,	PPCCOM,		{ RA, RS, MB } },
+{ "rlwinm.", M(21,1),	M_MASK,		PPCCOM,		{ RA,RS,SH,MBE,ME } },
+{ "rlinm.",  M(21,1),	M_MASK,		PWRCOM,		{ RA,RS,SH,MBE,ME } },
+
+{ "rlmi",    M(22,0),	M_MASK,		M601,		{ RA,RS,RB,MBE,ME } },
+{ "rlmi.",   M(22,1),	M_MASK,		M601,		{ RA,RS,RB,MBE,ME } },
+
+{ "rotlw",   MME(23,31,0), MMBME_MASK,	PPCCOM,		{ RA, RS, RB } },
+{ "rlwnm",   M(23,0),	M_MASK,		PPCCOM,		{ RA,RS,RB,MBE,ME } },
+{ "rlnm",    M(23,0),	M_MASK,		PWRCOM,		{ RA,RS,RB,MBE,ME } },
+{ "rotlw.",  MME(23,31,1), MMBME_MASK,	PPCCOM,		{ RA, RS, RB } },
+{ "rlwnm.",  M(23,1),	M_MASK,		PPCCOM,		{ RA,RS,RB,MBE,ME } },
+{ "rlnm.",   M(23,1),	M_MASK,		PWRCOM,		{ RA,RS,RB,MBE,ME } },
+
+{ "nop",     OP(24),	0xffffffff,	PPCCOM,		{ 0 } },
+{ "ori",     OP(24),	OP_MASK,	PPCCOM,		{ RA, RS, UI } },
+{ "oril",    OP(24),	OP_MASK,	PWRCOM,		{ RA, RS, UI } },
+
+{ "oris",    OP(25),	OP_MASK,	PPCCOM,		{ RA, RS, UI } },
+{ "oriu",    OP(25),	OP_MASK,	PWRCOM,		{ RA, RS, UI } },
+
+{ "xori",    OP(26),	OP_MASK,	PPCCOM,		{ RA, RS, UI } },
+{ "xoril",   OP(26),	OP_MASK,	PWRCOM,		{ RA, RS, UI } },
+
+{ "xoris",   OP(27),	OP_MASK,	PPCCOM,		{ RA, RS, UI } },
+{ "xoriu",   OP(27),	OP_MASK,	PWRCOM,		{ RA, RS, UI } },
+
+{ "andi.",   OP(28),	OP_MASK,	PPCCOM,		{ RA, RS, UI } },
+{ "andil.",  OP(28),	OP_MASK,	PWRCOM,		{ RA, RS, UI } },
+
+{ "andis.",  OP(29),	OP_MASK,	PPCCOM,		{ RA, RS, UI } },
+{ "andiu.",  OP(29),	OP_MASK,	PWRCOM,		{ RA, RS, UI } },
+
+{ "rotldi",  MD(30,0,0), MDMB_MASK,	PPC64,		{ RA, RS, SH6 } },
+{ "clrldi",  MD(30,0,0), MDSH_MASK,	PPC64,		{ RA, RS, MB6 } },
+{ "rldicl",  MD(30,0,0), MD_MASK,	PPC64,		{ RA, RS, SH6, MB6 } },
+{ "rotldi.", MD(30,0,1), MDMB_MASK,	PPC64,		{ RA, RS, SH6 } },
+{ "clrldi.", MD(30,0,1), MDSH_MASK,	PPC64,		{ RA, RS, MB6 } },
+{ "rldicl.", MD(30,0,1), MD_MASK,	PPC64,		{ RA, RS, SH6, MB6 } },
+
+{ "rldicr",  MD(30,1,0), MD_MASK,	PPC64,		{ RA, RS, SH6, ME6 } },
+{ "rldicr.", MD(30,1,1), MD_MASK,	PPC64,		{ RA, RS, SH6, ME6 } },
+
+{ "rldic",   MD(30,2,0), MD_MASK,	PPC64,		{ RA, RS, SH6, MB6 } },
+{ "rldic.",  MD(30,2,1), MD_MASK,	PPC64,		{ RA, RS, SH6, MB6 } },
+
+{ "rldimi",  MD(30,3,0), MD_MASK,	PPC64,		{ RA, RS, SH6, MB6 } },
+{ "rldimi.", MD(30,3,1), MD_MASK,	PPC64,		{ RA, RS, SH6, MB6 } },
+
+{ "rotld",   MDS(30,8,0), MDSMB_MASK,	PPC64,		{ RA, RS, RB } },
+{ "rldcl",   MDS(30,8,0), MDS_MASK,	PPC64,		{ RA, RS, RB, MB6 } },
+{ "rotld.",  MDS(30,8,1), MDSMB_MASK,	PPC64,		{ RA, RS, RB } },
+{ "rldcl.",  MDS(30,8,1), MDS_MASK,	PPC64,		{ RA, RS, RB, MB6 } },
+
+{ "rldcr",   MDS(30,9,0), MDS_MASK,	PPC64,		{ RA, RS, RB, ME6 } },
+{ "rldcr.",  MDS(30,9,1), MDS_MASK,	PPC64,		{ RA, RS, RB, ME6 } },
+
+{ "cmpw",    XCMPL(31,0,0), XCMPL_MASK, PPCCOM,		{ OBF, RA, RB } },
+{ "cmpd",    XCMPL(31,0,1), XCMPL_MASK, PPC64,		{ OBF, RA, RB } },
+{ "cmp",     X(31,0),	XCMP_MASK,	PPCONLY,	{ BF, L, RA, RB } },
+{ "cmp",     X(31,0),	XCMPL_MASK,	PWRCOM,		{ BF, RA, RB } },
+
+{ "twlgt",   XTO(31,4,TOLGT), XTO_MASK, PPCCOM,		{ RA, RB } },
+{ "tlgt",    XTO(31,4,TOLGT), XTO_MASK, PWRCOM,		{ RA, RB } },
+{ "twllt",   XTO(31,4,TOLLT), XTO_MASK, PPCCOM,		{ RA, RB } },
+{ "tllt",    XTO(31,4,TOLLT), XTO_MASK, PWRCOM,		{ RA, RB } },
+{ "tweq",    XTO(31,4,TOEQ), XTO_MASK,	PPCCOM,		{ RA, RB } },
+{ "teq",     XTO(31,4,TOEQ), XTO_MASK,	PWRCOM,		{ RA, RB } },
+{ "twlge",   XTO(31,4,TOLGE), XTO_MASK, PPCCOM,		{ RA, RB } },
+{ "tlge",    XTO(31,4,TOLGE), XTO_MASK, PWRCOM,		{ RA, RB } },
+{ "twlnl",   XTO(31,4,TOLNL), XTO_MASK, PPCCOM,		{ RA, RB } },
+{ "tlnl",    XTO(31,4,TOLNL), XTO_MASK, PWRCOM,		{ RA, RB } },
+{ "twlle",   XTO(31,4,TOLLE), XTO_MASK, PPCCOM,		{ RA, RB } },
+{ "tlle",    XTO(31,4,TOLLE), XTO_MASK, PWRCOM,		{ RA, RB } },
+{ "twlng",   XTO(31,4,TOLNG), XTO_MASK, PPCCOM,		{ RA, RB } },
+{ "tlng",    XTO(31,4,TOLNG), XTO_MASK, PWRCOM,		{ RA, RB } },
+{ "twgt",    XTO(31,4,TOGT), XTO_MASK,	PPCCOM,		{ RA, RB } },
+{ "tgt",     XTO(31,4,TOGT), XTO_MASK,	PWRCOM,		{ RA, RB } },
+{ "twge",    XTO(31,4,TOGE), XTO_MASK,	PPCCOM,		{ RA, RB } },
+{ "tge",     XTO(31,4,TOGE), XTO_MASK,	PWRCOM,		{ RA, RB } },
+{ "twnl",    XTO(31,4,TONL), XTO_MASK,	PPCCOM,		{ RA, RB } },
+{ "tnl",     XTO(31,4,TONL), XTO_MASK,	PWRCOM,		{ RA, RB } },
+{ "twlt",    XTO(31,4,TOLT), XTO_MASK,	PPCCOM,		{ RA, RB } },
+{ "tlt",     XTO(31,4,TOLT), XTO_MASK,	PWRCOM,		{ RA, RB } },
+{ "twle",    XTO(31,4,TOLE), XTO_MASK,	PPCCOM,		{ RA, RB } },
+{ "tle",     XTO(31,4,TOLE), XTO_MASK,	PWRCOM,		{ RA, RB } },
+{ "twng",    XTO(31,4,TONG), XTO_MASK,	PPCCOM,		{ RA, RB } },
+{ "tng",     XTO(31,4,TONG), XTO_MASK,	PWRCOM,		{ RA, RB } },
+{ "twne",    XTO(31,4,TONE), XTO_MASK,	PPCCOM,		{ RA, RB } },
+{ "tne",     XTO(31,4,TONE), XTO_MASK,	PWRCOM,		{ RA, RB } },
+{ "trap",    XTO(31,4,TOU), 0xffffffff,	PPCCOM,		{ 0 } },
+{ "tw",      X(31,4),	X_MASK,		PPCCOM,		{ TO, RA, RB } },
+{ "t",       X(31,4),	X_MASK,		PWRCOM,		{ TO, RA, RB } },
+
+{ "subfc",   XO(31,8,0,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "sf",      XO(31,8,0,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "subc",    XO(31,8,0,0), XO_MASK,	PPC,		{ RT, RB, RA } },
+{ "subfc.",  XO(31,8,0,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "sf.",     XO(31,8,0,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "subc.",   XO(31,8,0,1), XO_MASK,	PPCCOM,		{ RT, RB, RA } },
+{ "subfco",  XO(31,8,1,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "sfo",     XO(31,8,1,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "subco",   XO(31,8,1,0), XO_MASK,	PPC,		{ RT, RB, RA } },
+{ "subfco.", XO(31,8,1,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "sfo.",    XO(31,8,1,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "subco.",  XO(31,8,1,1), XO_MASK,	PPC,		{ RT, RB, RA } },
+
+{ "mulhdu",  XO(31,9,0,0), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "mulhdu.", XO(31,9,0,1), XO_MASK,	PPC64,		{ RT, RA, RB } },
+
+{ "addc",    XO(31,10,0,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "a",       XO(31,10,0,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "addc.",   XO(31,10,0,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "a.",      XO(31,10,0,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "addco",   XO(31,10,1,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "ao",      XO(31,10,1,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "addco.",  XO(31,10,1,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "ao.",     XO(31,10,1,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+
+{ "mulhwu",  XO(31,11,0,0), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "mulhwu.", XO(31,11,0,1), XO_MASK,	PPC,		{ RT, RA, RB } },
+
+{ "mfcr",    X(31,19),	XRARB_MASK,	COM,		{ RT } },
+
+{ "lwarx",   X(31,20),	X_MASK,		PPC,		{ RT, RA, RB } },
+
+{ "ldx",     X(31,21),	X_MASK,		PPC64,		{ RT, RA, RB } },
+
+{ "lwzx",    X(31,23),	X_MASK,		PPCCOM,		{ RT, RA, RB } },
+{ "lx",      X(31,23),	X_MASK,		PWRCOM,		{ RT, RA, RB } },
+
+{ "slw",     XRC(31,24,0), X_MASK,	PPCCOM,		{ RA, RS, RB } },
+{ "sl",      XRC(31,24,0), X_MASK,	PWRCOM,		{ RA, RS, RB } },
+{ "slw.",    XRC(31,24,1), X_MASK,	PPCCOM,		{ RA, RS, RB } },
+{ "sl.",     XRC(31,24,1), X_MASK,	PWRCOM,		{ RA, RS, RB } },
+
+{ "cntlzw",  XRC(31,26,0), XRB_MASK,	PPCCOM,		{ RA, RS } },
+{ "cntlz",   XRC(31,26,0), XRB_MASK,	PWRCOM,		{ RA, RS } },
+{ "cntlzw.", XRC(31,26,1), XRB_MASK,	PPCCOM,		{ RA, RS } },
+{ "cntlz.",  XRC(31,26,1), XRB_MASK, 	PWRCOM,		{ RA, RS } },
+
+{ "sld",     XRC(31,27,0), X_MASK,	PPC64,		{ RA, RS, RB } },
+{ "sld.",    XRC(31,27,1), X_MASK,	PPC64,		{ RA, RS, RB } },
+
+{ "and",     XRC(31,28,0), X_MASK,	COM,		{ RA, RS, RB } },
+{ "and.",    XRC(31,28,1), X_MASK,	COM,		{ RA, RS, RB } },
+
+{ "maskg",   XRC(31,29,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "maskg.",  XRC(31,29,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "cmplw",   XCMPL(31,32,0), XCMPL_MASK, PPCCOM,	{ OBF, RA, RB } },
+{ "cmpld",   XCMPL(31,32,1), XCMPL_MASK, PPC64,		{ OBF, RA, RB } },
+{ "cmpl",    X(31,32),	XCMP_MASK,	 PPCONLY,	{ BF, L, RA, RB } },
+{ "cmpl",    X(31,32),	XCMPL_MASK,	 PWRCOM,	{ BF, RA, RB } },
+
+{ "subf",    XO(31,40,0,0), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "sub",     XO(31,40,0,0), XO_MASK,	PPC,		{ RT, RB, RA } },
+{ "subf.",   XO(31,40,0,1), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "sub.",    XO(31,40,0,1), XO_MASK,	PPC,		{ RT, RB, RA } },
+{ "subfo",   XO(31,40,1,0), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "subo",    XO(31,40,1,0), XO_MASK,	PPC,		{ RT, RB, RA } },
+{ "subfo.",  XO(31,40,1,1), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "subo.",   XO(31,40,1,1), XO_MASK,	PPC,		{ RT, RB, RA } },
+
+{ "ldux",    X(31,53),	X_MASK,		PPC64,		{ RT, RAL, RB } },
+
+{ "dcbst",   X(31,54),	XRT_MASK,	PPC,		{ RA, RB } },
+
+{ "lwzux",   X(31,55),	X_MASK,		PPCCOM,		{ RT, RAL, RB } },
+{ "lux",     X(31,55),	X_MASK,		PWRCOM,		{ RT, RA, RB } },
+
+{ "cntlzd",  XRC(31,58,0), XRB_MASK,	PPC64,		{ RA, RS } },
+{ "cntlzd.", XRC(31,58,1), XRB_MASK,	PPC64,		{ RA, RS } },
+
+{ "andc",    XRC(31,60,0), X_MASK,	COM,	{ RA, RS, RB } },
+{ "andc.",   XRC(31,60,1), X_MASK,	COM,	{ RA, RS, RB } },
+
+{ "tdlgt",   XTO(31,68,TOLGT), XTO_MASK, PPC64,		{ RA, RB } },
+{ "tdllt",   XTO(31,68,TOLLT), XTO_MASK, PPC64,		{ RA, RB } },
+{ "tdeq",    XTO(31,68,TOEQ), XTO_MASK,  PPC64,		{ RA, RB } },
+{ "tdlge",   XTO(31,68,TOLGE), XTO_MASK, PPC64,		{ RA, RB } },
+{ "tdlnl",   XTO(31,68,TOLNL), XTO_MASK, PPC64,		{ RA, RB } },
+{ "tdlle",   XTO(31,68,TOLLE), XTO_MASK, PPC64,		{ RA, RB } },
+{ "tdlng",   XTO(31,68,TOLNG), XTO_MASK, PPC64,		{ RA, RB } },
+{ "tdgt",    XTO(31,68,TOGT), XTO_MASK,  PPC64,		{ RA, RB } },
+{ "tdge",    XTO(31,68,TOGE), XTO_MASK,  PPC64,		{ RA, RB } },
+{ "tdnl",    XTO(31,68,TONL), XTO_MASK,  PPC64,		{ RA, RB } },
+{ "tdlt",    XTO(31,68,TOLT), XTO_MASK,  PPC64,		{ RA, RB } },
+{ "tdle",    XTO(31,68,TOLE), XTO_MASK,  PPC64,		{ RA, RB } },
+{ "tdng",    XTO(31,68,TONG), XTO_MASK,  PPC64,		{ RA, RB } },
+{ "tdne",    XTO(31,68,TONE), XTO_MASK,  PPC64,		{ RA, RB } },
+{ "td",	     X(31,68),	X_MASK,		 PPC64,		{ TO, RA, RB } },
+
+{ "mulhd",   XO(31,73,0,0), XO_MASK,	 PPC64,		{ RT, RA, RB } },
+{ "mulhd.",  XO(31,73,0,1), XO_MASK,	 PPC64,		{ RT, RA, RB } },
+
+{ "mulhw",   XO(31,75,0,0), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "mulhw.",  XO(31,75,0,1), XO_MASK,	PPC,		{ RT, RA, RB } },
+
+{ "mtsrd",   X(31,82),	XRB_MASK|(1<<20), PPC64,	{ SR, RS } },
+
+{ "mfmsr",   X(31,83),	XRARB_MASK,	COM,		{ RT } },
+
+{ "ldarx",   X(31,84),	X_MASK,		PPC64,		{ RT, RA, RB } },
+
+{ "dcbf",    X(31,86),	XRT_MASK,	PPC,		{ RA, RB } },
+
+{ "lbzx",    X(31,87),	X_MASK,		COM,		{ RT, RA, RB } },
+
+{ "neg",     XO(31,104,0,0), XORB_MASK,	COM,		{ RT, RA } },
+{ "neg.",    XO(31,104,0,1), XORB_MASK,	COM,		{ RT, RA } },
+{ "nego",    XO(31,104,1,0), XORB_MASK,	COM,		{ RT, RA } },
+{ "nego.",   XO(31,104,1,1), XORB_MASK,	COM,		{ RT, RA } },
+
+{ "mul",     XO(31,107,0,0), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "mul.",    XO(31,107,0,1), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "mulo",    XO(31,107,1,0), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "mulo.",   XO(31,107,1,1), XO_MASK,	M601,		{ RT, RA, RB } },
+
+{ "mtsrdin", X(31,114),	XRA_MASK,	PPC64,		{ RS, RB } },
+
+{ "clf",     X(31,118), XRB_MASK,	POWER,		{ RT, RA } },
+
+{ "lbzux",   X(31,119),	X_MASK,		COM,		{ RT, RAL, RB } },
+
+{ "not",     XRC(31,124,0), X_MASK,	COM,		{ RA, RS, RBS } },
+{ "nor",     XRC(31,124,0), X_MASK,	COM,		{ RA, RS, RB } },
+{ "not.",    XRC(31,124,1), X_MASK,	COM,		{ RA, RS, RBS } },
+{ "nor.",    XRC(31,124,1), X_MASK,	COM,		{ RA, RS, RB } },
+
+{ "wrtee",   X(31,131),	XRARB_MASK,	PPC403,		{ RS } },
+
+{ "subfe",   XO(31,136,0,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "sfe",     XO(31,136,0,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "subfe.",  XO(31,136,0,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "sfe.",    XO(31,136,0,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "subfeo",  XO(31,136,1,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "sfeo",    XO(31,136,1,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "subfeo.", XO(31,136,1,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "sfeo.",   XO(31,136,1,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+
+{ "adde",    XO(31,138,0,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "ae",      XO(31,138,0,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "adde.",   XO(31,138,0,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "ae.",     XO(31,138,0,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "addeo",   XO(31,138,1,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "aeo",     XO(31,138,1,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "addeo.",  XO(31,138,1,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "aeo.",    XO(31,138,1,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+
+{ "mtcr",    XFXM(31,144,0xff), XFXFXM_MASK|FXM_MASK, COM,	{ RS }},
+{ "mtcrf",   X(31,144),	XFXFXM_MASK,	COM,		{ FXM, RS } },
+
+{ "mtmsr",   X(31,146),	XRARB_MASK,	COM,		{ RS } },
+
+{ "stdx",    X(31,149), X_MASK,		PPC64,		{ RS, RA, RB } },
+
+{ "stwcx.",  XRC(31,150,1), X_MASK,	PPC,		{ RS, RA, RB } },
+
+{ "stwx",    X(31,151), X_MASK,		PPCCOM,		{ RS, RA, RB } },
+{ "stx",     X(31,151), X_MASK,		PWRCOM,		{ RS, RA, RB } },
+
+{ "slq",     XRC(31,152,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "slq.",    XRC(31,152,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "sle",     XRC(31,153,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "sle.",    XRC(31,153,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "wrteei",  X(31,163),	XE_MASK,	PPC403,		{ E } },
+
+{ "mtmsrd",  X(31,178),	XRARB_MASK,	PPC64,		{ RS } },
+
+{ "stdux",   X(31,181),	X_MASK,		PPC64,		{ RS, RAS, RB } },
+
+{ "stwux",   X(31,183),	X_MASK,		PPCCOM,		{ RS, RAS, RB } },
+{ "stux",    X(31,183),	X_MASK,		PWRCOM,		{ RS, RA, RB } },
+
+{ "sliq",    XRC(31,184,0), X_MASK,	M601,		{ RA, RS, SH } },
+{ "sliq.",   XRC(31,184,1), X_MASK,	M601,		{ RA, RS, SH } },
+
+{ "subfze",  XO(31,200,0,0), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "sfze",    XO(31,200,0,0), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "subfze.", XO(31,200,0,1), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "sfze.",   XO(31,200,0,1), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "subfzeo", XO(31,200,1,0), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "sfzeo",   XO(31,200,1,0), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "subfzeo.",XO(31,200,1,1), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "sfzeo.",  XO(31,200,1,1), XORB_MASK, PWRCOM,		{ RT, RA } },
+
+{ "addze",   XO(31,202,0,0), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "aze",     XO(31,202,0,0), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "addze.",  XO(31,202,0,1), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "aze.",    XO(31,202,0,1), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "addzeo",  XO(31,202,1,0), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "azeo",    XO(31,202,1,0), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "addzeo.", XO(31,202,1,1), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "azeo.",   XO(31,202,1,1), XORB_MASK, PWRCOM,		{ RT, RA } },
+
+{ "mtsr",    X(31,210),	XRB_MASK|(1<<20), COM32,	{ SR, RS } },
+
+{ "stdcx.",  XRC(31,214,1), X_MASK,	PPC64,		{ RS, RA, RB } },
+
+{ "stbx",    X(31,215),	X_MASK,		COM,	{ RS, RA, RB } },
+
+{ "sllq",    XRC(31,216,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "sllq.",   XRC(31,216,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "sleq",    XRC(31,217,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "sleq.",   XRC(31,217,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "subfme",  XO(31,232,0,0), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "sfme",    XO(31,232,0,0), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "subfme.", XO(31,232,0,1), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "sfme.",   XO(31,232,0,1), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "subfmeo", XO(31,232,1,0), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "sfmeo",   XO(31,232,1,0), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "subfmeo.",XO(31,232,1,1), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "sfmeo.",  XO(31,232,1,1), XORB_MASK, PWRCOM,		{ RT, RA } },
+
+{ "mulld",   XO(31,233,0,0), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "mulld.",  XO(31,233,0,1), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "mulldo",  XO(31,233,1,0), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "mulldo.", XO(31,233,1,1), XO_MASK,	PPC64,		{ RT, RA, RB } },
+
+{ "addme",   XO(31,234,0,0), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "ame",     XO(31,234,0,0), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "addme.",  XO(31,234,0,1), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "ame.",    XO(31,234,0,1), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "addmeo",  XO(31,234,1,0), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "ameo",    XO(31,234,1,0), XORB_MASK, PWRCOM,		{ RT, RA } },
+{ "addmeo.", XO(31,234,1,1), XORB_MASK, PPCCOM,		{ RT, RA } },
+{ "ameo.",   XO(31,234,1,1), XORB_MASK, PWRCOM,		{ RT, RA } },
+
+{ "mullw",   XO(31,235,0,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "muls",    XO(31,235,0,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "mullw.",  XO(31,235,0,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "muls.",   XO(31,235,0,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "mullwo",  XO(31,235,1,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "mulso",   XO(31,235,1,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "mullwo.", XO(31,235,1,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "mulso.",  XO(31,235,1,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+
+{ "mtsrin",  X(31,242),	XRA_MASK,	PPC32,		{ RS, RB } },
+{ "mtsri",   X(31,242),	XRA_MASK,	POWER32,	{ RS, RB } },
+
+{ "dcbtst",  X(31,246),	XRT_MASK,	PPC,		{ RA, RB } },
+
+{ "stbux",   X(31,247),	X_MASK,		COM,		{ RS, RAS, RB } },
+
+{ "slliq",   XRC(31,248,0), X_MASK,	M601,		{ RA, RS, SH } },
+{ "slliq.",  XRC(31,248,1), X_MASK,	M601,		{ RA, RS, SH } },
+
+{ "doz",     XO(31,264,0,0), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "doz.",    XO(31,264,0,1), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "dozo",    XO(31,264,1,0), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "dozo.",   XO(31,264,1,1), XO_MASK,	M601,		{ RT, RA, RB } },
+
+{ "add",     XO(31,266,0,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "cax",     XO(31,266,0,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "add.",    XO(31,266,0,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "cax.",    XO(31,266,0,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "addo",    XO(31,266,1,0), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "caxo",    XO(31,266,1,0), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+{ "addo.",   XO(31,266,1,1), XO_MASK,	PPCCOM,		{ RT, RA, RB } },
+{ "caxo.",   XO(31,266,1,1), XO_MASK,	PWRCOM,		{ RT, RA, RB } },
+
+{ "lscbx",   XRC(31,277,0), X_MASK,	M601,		{ RT, RA, RB } },
+{ "lscbx.",  XRC(31,277,1), X_MASK,	M601,		{ RT, RA, RB } },
+
+{ "dcbt",    X(31,278),	XRT_MASK,	PPC,		{ RA, RB } },
+
+{ "lhzx",    X(31,279),	X_MASK,		COM,		{ RT, RA, RB } },
+
+{ "icbt",    X(31,262),	XRT_MASK,	PPC403,		{ RA, RB } },
+
+{ "eqv",     XRC(31,284,0), X_MASK,	COM,		{ RA, RS, RB } },
+{ "eqv.",    XRC(31,284,1), X_MASK,	COM,		{ RA, RS, RB } },
+
+{ "tlbie",   X(31,306),	XRTRA_MASK,	PPC,		{ RB } },
+{ "tlbi",    X(31,306),	XRT_MASK,	POWER,		{ RA, RB } },
+
+{ "eciwx",   X(31,310), X_MASK,		PPC,		{ RT, RA, RB } },
+
+{ "lhzux",   X(31,311),	X_MASK,		COM,		{ RT, RAL, RB } },
+
+{ "xor",     XRC(31,316,0), X_MASK,	COM,		{ RA, RS, RB } },
+{ "xor.",    XRC(31,316,1), X_MASK,	COM,		{ RA, RS, RB } },
+
+{ "mfexisr", XSPR(31,323,64), XSPR_MASK, PPC403,	{ RT } },
+{ "mfexier", XSPR(31,323,66), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbr0",   XSPR(31,323,128), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbr1",   XSPR(31,323,129), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbr2",   XSPR(31,323,130), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbr3",   XSPR(31,323,131), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbr4",   XSPR(31,323,132), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbr5",   XSPR(31,323,133), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbr6",   XSPR(31,323,134), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbr7",   XSPR(31,323,135), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbear",  XSPR(31,323,144), XSPR_MASK, PPC403,	{ RT } },
+{ "mfbesr",  XSPR(31,323,145), XSPR_MASK, PPC403,	{ RT } },
+{ "mfiocr",  XSPR(31,323,160), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmacr0", XSPR(31,323,192), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmact0", XSPR(31,323,193), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmada0", XSPR(31,323,194), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmasa0", XSPR(31,323,195), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmacc0", XSPR(31,323,196), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmacr1", XSPR(31,323,200), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmact1", XSPR(31,323,201), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmada1", XSPR(31,323,202), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmasa1", XSPR(31,323,203), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmacc1", XSPR(31,323,204), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmacr2", XSPR(31,323,208), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmact2", XSPR(31,323,209), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmada2", XSPR(31,323,210), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmasa2", XSPR(31,323,211), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmacc2", XSPR(31,323,212), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmacr3", XSPR(31,323,216), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmact3", XSPR(31,323,217), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmada3", XSPR(31,323,218), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmasa3", XSPR(31,323,219), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmacc3", XSPR(31,323,220), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdmasr", XSPR(31,323,224), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdcr",   X(31,323),	X_MASK,		PPC403,		{ RT, SPR } },
+
+{ "div",     XO(31,331,0,0), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "div.",    XO(31,331,0,1), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "divo",    XO(31,331,1,0), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "divo.",   XO(31,331,1,1), XO_MASK,	M601,		{ RT, RA, RB } },
+
+{ "mfmq",     XSPR(31,339,0),   XSPR_MASK, M601,	{ RT } },
+{ "mfxer",    XSPR(31,339,1),   XSPR_MASK, COM,		{ RT } },
+{ "mfrtcu",   XSPR(31,339,4),   XSPR_MASK, COM,		{ RT } },
+{ "mfrtcl",   XSPR(31,339,5),   XSPR_MASK, COM,		{ RT } },
+{ "mfdec",    XSPR(31,339,6),   XSPR_MASK, MFDEC1,	{ RT } },
+{ "mflr",     XSPR(31,339,8),   XSPR_MASK, COM,		{ RT } },
+{ "mfctr",    XSPR(31,339,9),   XSPR_MASK, COM,		{ RT } },
+{ "mftid",    XSPR(31,339,17),  XSPR_MASK, POWER,	{ RT } },
+{ "mfdsisr",  XSPR(31,339,18),  XSPR_MASK, COM,		{ RT } },
+{ "mfdar",    XSPR(31,339,19),  XSPR_MASK, COM,		{ RT } },
+{ "mfdec",    XSPR(31,339,22),  XSPR_MASK, MFDEC2,	{ RT } },
+{ "mfsdr0",   XSPR(31,339,24),  XSPR_MASK, POWER,	{ RT } },
+{ "mfsdr1",   XSPR(31,339,25),  XSPR_MASK, COM,		{ RT } },
+{ "mfsrr0",   XSPR(31,339,26),  XSPR_MASK, COM,		{ RT } },
+{ "mfsrr1",   XSPR(31,339,27),  XSPR_MASK, COM,		{ RT } },
+{ "mfcmpa",   XSPR(31,339,144), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcmpb",   XSPR(31,339,145), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcmpc",   XSPR(31,339,146), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcmpd",   XSPR(31,339,147), XSPR_MASK, PPC860,	{ RT } },
+{ "mficr",    XSPR(31,339,148), XSPR_MASK, PPC860,	{ RT } },
+{ "mfder",    XSPR(31,339,149), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcounta", XSPR(31,339,150), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcountb", XSPR(31,339,151), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcmpe",   XSPR(31,339,152), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcmpf",   XSPR(31,339,153), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcmpg",   XSPR(31,339,154), XSPR_MASK, PPC860,	{ RT } },
+{ "mfcmph",   XSPR(31,339,155), XSPR_MASK, PPC860,	{ RT } },
+{ "mflctrl1", XSPR(31,339,156), XSPR_MASK, PPC860,	{ RT } },
+{ "mflctrl2", XSPR(31,339,157), XSPR_MASK, PPC860,	{ RT } },
+{ "mfictrl",  XSPR(31,339,158), XSPR_MASK, PPC860,	{ RT } },
+{ "mfbar",    XSPR(31,339,159), XSPR_MASK, PPC860,	{ RT } },
+{ "mfsprg4",  XSPR(31,339,260), XSPR_MASK, PPC405,	{ RT } },
+{ "mfsprg5",  XSPR(31,339,261), XSPR_MASK, PPC405,	{ RT } },
+{ "mfsprg6",  XSPR(31,339,262), XSPR_MASK, PPC405,	{ RT } },
+{ "mfsprg7",  XSPR(31,339,263), XSPR_MASK, PPC405,	{ RT } },
+{ "mfsprg",   XSPR(31,339,272), XSPRG_MASK, PPC,	{ RT, SPRG } },
+{ "mfsprg0",  XSPR(31,339,272), XSPR_MASK, PPC,		{ RT } },
+{ "mfsprg1",  XSPR(31,339,273), XSPR_MASK, PPC,		{ RT } },
+{ "mfsprg2",  XSPR(31,339,274), XSPR_MASK, PPC,		{ RT } },
+{ "mfsprg3",  XSPR(31,339,275), XSPR_MASK, PPC,		{ RT } },
+{ "mfasr",    XSPR(31,339,280), XSPR_MASK, PPC64,	{ RT } },
+{ "mfear",    XSPR(31,339,282), XSPR_MASK, PPC,		{ RT } },
+{ "mfpvr",    XSPR(31,339,287), XSPR_MASK, PPC,		{ RT } },
+{ "mfibatu",  XSPR(31,339,528), XSPRBAT_MASK, PPC,	{ RT, SPRBAT } },
+{ "mfibatl",  XSPR(31,339,529), XSPRBAT_MASK, PPC,	{ RT, SPRBAT } },
+{ "mfdbatu",  XSPR(31,339,536), XSPRBAT_MASK, PPC,	{ RT, SPRBAT } },
+{ "mfdbatl",  XSPR(31,339,537), XSPRBAT_MASK, PPC,	{ RT, SPRBAT } },
+{ "mfic_cst", XSPR(31,339,560), XSPR_MASK, PPC860,	{ RT } },
+{ "mfic_adr", XSPR(31,339,561), XSPR_MASK, PPC860,	{ RT } },
+{ "mfic_dat", XSPR(31,339,562), XSPR_MASK, PPC860,	{ RT } },
+{ "mfdc_cst", XSPR(31,339,568), XSPR_MASK, PPC860,	{ RT } },
+{ "mfdc_adr", XSPR(31,339,569), XSPR_MASK, PPC860,	{ RT } },
+{ "mfdc_dat", XSPR(31,339,570), XSPR_MASK, PPC860,	{ RT } },
+{ "mfdpdr",   XSPR(31,339,630), XSPR_MASK, PPC860,	{ RT } },
+{ "mfdpir",   XSPR(31,339,631), XSPR_MASK, PPC860,	{ RT } },
+{ "mfimmr",   XSPR(31,339,638), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmi_ctr", XSPR(31,339,784), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmi_ap",  XSPR(31,339,786), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmi_epn", XSPR(31,339,787), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmi_twc", XSPR(31,339,789), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmi_rpn", XSPR(31,339,790), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_ctr", XSPR(31,339,792), XSPR_MASK, PPC860,	{ RT } },
+{ "mfm_casid",XSPR(31,339,793), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_ap",  XSPR(31,339,794), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_epn", XSPR(31,339,795), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_twb", XSPR(31,339,796), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_twc", XSPR(31,339,797), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_rpn", XSPR(31,339,798), XSPR_MASK, PPC860,	{ RT } },
+{ "mfm_tw",   XSPR(31,339,799), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmi_dbcam",XSPR(31,339,816), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmi_dbram0",XSPR(31,339,817), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmi_dbram1",XSPR(31,339,818), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_dbcam", XSPR(31,339,824), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_dbram0",XSPR(31,339,825), XSPR_MASK, PPC860,	{ RT } },
+{ "mfmd_dbram1",XSPR(31,339,826), XSPR_MASK, PPC860,	{ RT } },
+{ "mfzpr",   	XSPR(31,339,944), XSPR_MASK, PPC403,	{ RT } },
+{ "mfpid",   	XSPR(31,339,945), XSPR_MASK, PPC403,	{ RT } },
+{ "mfccr0",  	XSPR(31,339,947), XSPR_MASK, PPC405,	{ RT } },
+{ "mficdbdr",	XSPR(31,339,979), XSPR_MASK, PPC403,	{ RT } },
+{ "mfummcr0",	XSPR(31,339,936),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfupmc1",	XSPR(31,339,937),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfupmc2",	XSPR(31,339,938),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfusia",	XSPR(31,339,939),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfummcr1",	XSPR(31,339,940),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfupmc3",	XSPR(31,339,941),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfupmc4",	XSPR(31,339,942),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfiac3",     XSPR(31,339,948),  XSPR_MASK, PPC405,	{ RT } },
+{ "mfiac4",     XSPR(31,339,949),  XSPR_MASK, PPC405,	{ RT } },
+{ "mfdvc1",     XSPR(31,339,950),  XSPR_MASK, PPC405,	{ RT } },
+{ "mfdvc2",     XSPR(31,339,951),  XSPR_MASK, PPC405,	{ RT } },
+{ "mfmmcr0",	XSPR(31,339,952),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfpmc1",	XSPR(31,339,953),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfsgr",	XSPR(31,339,953),  XSPR_MASK, PPC403,	{ RT } },
+{ "mfpmc2",	XSPR(31,339,954),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfdcwr", 	XSPR(31,339,954),  XSPR_MASK, PPC403,	{ RT } },
+{ "mfsia",	XSPR(31,339,955),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfsler",	XSPR(31,339,955),  XSPR_MASK, PPC405,	{ RT } },
+{ "mfmmcr1",	XSPR(31,339,956),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfsu0r",	XSPR(31,339,956),  XSPR_MASK, PPC405,	{ RT } },
+{ "mfpmc3",	XSPR(31,339,957),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfdbcr1", 	XSPR(31,339,957),  XSPR_MASK, PPC405,	{ RT } },
+{ "mfpmc4",	XSPR(31,339,958),  XSPR_MASK, PPC750,	{ RT } },
+{ "mfesr",   XSPR(31,339,980), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdear",  XSPR(31,339,981), XSPR_MASK, PPC403,	{ RT } },
+{ "mfevpr",  XSPR(31,339,982), XSPR_MASK, PPC403,	{ RT } },
+{ "mfcdbcr", XSPR(31,339,983), XSPR_MASK, PPC403,	{ RT } },
+{ "mftsr",   XSPR(31,339,984), XSPR_MASK, PPC403,	{ RT } },
+{ "mftcr",   XSPR(31,339,986), XSPR_MASK, PPC403,	{ RT } },
+{ "mfpit",   XSPR(31,339,987), XSPR_MASK, PPC403,	{ RT } },
+{ "mftbhi",  XSPR(31,339,988), XSPR_MASK, PPC403,	{ RT } },
+{ "mftblo",  XSPR(31,339,989), XSPR_MASK, PPC403,	{ RT } },
+{ "mfsrr2",  XSPR(31,339,990), XSPR_MASK, PPC403,	{ RT } },
+{ "mfsrr3",  XSPR(31,339,991), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdbsr",  XSPR(31,339,1008), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdbcr0", XSPR(31,339,1010), XSPR_MASK, PPC405,	{ RT } },
+{ "mfiac1",  XSPR(31,339,1012), XSPR_MASK, PPC403,	{ RT } },
+{ "mfiac2",  XSPR(31,339,1013), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdac1",  XSPR(31,339,1014), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdac2",  XSPR(31,339,1015), XSPR_MASK, PPC403,	{ RT } },
+{ "mfdccr",  XSPR(31,339,1018), XSPR_MASK, PPC403,	{ RT } },
+{ "mficcr",  XSPR(31,339,1019), XSPR_MASK, PPC403,	{ RT } },
+{ "mfpbl1",  XSPR(31,339,1020), XSPR_MASK, PPC403,	{ RT } },
+{ "mfpbu1",  XSPR(31,339,1021), XSPR_MASK, PPC403,	{ RT } },
+{ "mfpbl2",  XSPR(31,339,1022), XSPR_MASK, PPC403,	{ RT } },
+{ "mfpbu2",  XSPR(31,339,1023), XSPR_MASK, PPC403,	{ RT } },
+{ "mfl2cr",	XSPR(31,339,1017), XSPR_MASK, PPC750,	{ RT } },
+{ "mfictc",	XSPR(31,339,1019), XSPR_MASK, PPC750,	{ RT } },
+{ "mfthrm1",	XSPR(31,339,1020), XSPR_MASK, PPC750,	{ RT } },
+{ "mfthrm2",	XSPR(31,339,1021), XSPR_MASK, PPC750,	{ RT } },
+{ "mfthrm3",	XSPR(31,339,1022), XSPR_MASK, PPC750,	{ RT } },
+{ "mfspr",   X(31,339),	X_MASK,		COM,		{ RT, SPR } },
+
+{ "lwax",    X(31,341),	X_MASK,		PPC64,		{ RT, RA, RB } },
+
+{ "lhax",    X(31,343),	X_MASK,		COM,		{ RT, RA, RB } },
+
+{ "dccci",   X(31,454),	XRT_MASK,	PPC403,		{ RA, RB } },
+
+{ "abs",     XO(31,360,0,0), XORB_MASK, M601,		{ RT, RA } },
+{ "abs.",    XO(31,360,0,1), XORB_MASK, M601,		{ RT, RA } },
+{ "abso",    XO(31,360,1,0), XORB_MASK, M601,		{ RT, RA } },
+{ "abso.",   XO(31,360,1,1), XORB_MASK, M601,		{ RT, RA } },
+
+{ "divs",    XO(31,363,0,0), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "divs.",   XO(31,363,0,1), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "divso",   XO(31,363,1,0), XO_MASK,	M601,		{ RT, RA, RB } },
+{ "divso.",  XO(31,363,1,1), XO_MASK,	M601,		{ RT, RA, RB } },
+
+{ "tlbia",   X(31,370),	0xffffffff,	PPC,		{ 0 } },
+
+{ "mftbl",   XSPR(31,371,268), XSPR_MASK, PPC,		{ RT } },
+{ "mftbu",   XSPR(31,371,269), XSPR_MASK, PPC,		{ RT } },
+{ "mftb",    X(31,371),	X_MASK,		PPC,		{ RT, TBR } },
+
+{ "lwaux",   X(31,373),	X_MASK,		PPC64,		{ RT, RAL, RB } },
+
+{ "lhaux",   X(31,375),	X_MASK,		COM,		{ RT, RAL, RB } },
+
+{ "sthx",    X(31,407),	X_MASK,		COM,		{ RS, RA, RB } },
+
+{ "lfqx",    X(31,791),	X_MASK,		POWER2,		{ FRT, RA, RB } },
+
+{ "lfqux",   X(31,823),	X_MASK,		POWER2,		{ FRT, RA, RB } },
+
+{ "stfqx",   X(31,919),	X_MASK,		POWER2,		{ FRS, RA, RB } },
+
+{ "stfqux",  X(31,951),	X_MASK,		POWER2,		{ FRS, RA, RB } },
+
+{ "orc",     XRC(31,412,0), X_MASK,	COM,		{ RA, RS, RB } },
+{ "orc.",    XRC(31,412,1), X_MASK,	COM,		{ RA, RS, RB } },
+
+{ "sradi",   XS(31,413,0), XS_MASK,	PPC64,		{ RA, RS, SH6 } },
+{ "sradi.",  XS(31,413,1), XS_MASK,	PPC64,		{ RA, RS, SH6 } },
+
+{ "slbie",   X(31,434),	XRTRA_MASK,	PPC64,		{ RB } },
+
+{ "ecowx",   X(31,438),	X_MASK,		PPC,		{ RT, RA, RB } },
+
+{ "sthux",   X(31,439),	X_MASK,		COM,		{ RS, RAS, RB } },
+
+{ "mr",	     XRC(31,444,0), X_MASK,	COM,		{ RA, RS, RBS } },
+{ "or",      XRC(31,444,0), X_MASK,	COM,		{ RA, RS, RB } },
+{ "mr.",     XRC(31,444,1), X_MASK,	COM,		{ RA, RS, RBS } },
+{ "or.",     XRC(31,444,1), X_MASK,	COM,		{ RA, RS, RB } },
+
+{ "mtexisr", XSPR(31,451,64), XSPR_MASK, PPC403,	{ RT } },
+{ "mtexier", XSPR(31,451,66), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbr0",   XSPR(31,451,128), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbr1",   XSPR(31,451,129), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbr2",   XSPR(31,451,130), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbr3",   XSPR(31,451,131), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbr4",   XSPR(31,451,132), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbr5",   XSPR(31,451,133), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbr6",   XSPR(31,451,134), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbr7",   XSPR(31,451,135), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbear",  XSPR(31,451,144), XSPR_MASK, PPC403,	{ RT } },
+{ "mtbesr",  XSPR(31,451,145), XSPR_MASK, PPC403,	{ RT } },
+{ "mtiocr",  XSPR(31,451,160), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmacr0", XSPR(31,451,192), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmact0", XSPR(31,451,193), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmada0", XSPR(31,451,194), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmasa0", XSPR(31,451,195), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmacc0", XSPR(31,451,196), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmacr1", XSPR(31,451,200), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmact1", XSPR(31,451,201), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmada1", XSPR(31,451,202), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmasa1", XSPR(31,451,203), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmacc1", XSPR(31,451,204), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmacr2", XSPR(31,451,208), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmact2", XSPR(31,451,209), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmada2", XSPR(31,451,210), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmasa2", XSPR(31,451,211), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmacc2", XSPR(31,451,212), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmacr3", XSPR(31,451,216), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmact3", XSPR(31,451,217), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmada3", XSPR(31,451,218), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmasa3", XSPR(31,451,219), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmacc3", XSPR(31,451,220), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdmasr", XSPR(31,451,224), XSPR_MASK, PPC403,	{ RT } },
+{ "mtummcr0",	XSPR(31,451,936),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtupmc1",	XSPR(31,451,937),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtupmc2",	XSPR(31,451,938),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtusia",	XSPR(31,451,939),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtummcr1",	XSPR(31,451,940),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtupmc3",	XSPR(31,451,941),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtupmc4",	XSPR(31,451,942),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtmmcr0",	XSPR(31,451,952),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtpmc1",	XSPR(31,451,953),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtpmc2",	XSPR(31,451,954),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtsia",	XSPR(31,451,955),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtmmcr1",	XSPR(31,451,956),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtpmc3",	XSPR(31,451,957),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtpmc4",	XSPR(31,451,958),  XSPR_MASK, PPC750,	{ RT } },
+{ "mtl2cr",	XSPR(31,451,1017), XSPR_MASK, PPC750,	{ RT } },
+{ "mtictc",	XSPR(31,451,1019), XSPR_MASK, PPC750,	{ RT } },
+{ "mtthrm1",	XSPR(31,451,1020), XSPR_MASK, PPC750,	{ RT } },
+{ "mtthrm2",	XSPR(31,451,1021), XSPR_MASK, PPC750,	{ RT } },
+{ "mtthrm3",	XSPR(31,451,1022), XSPR_MASK, PPC750,	{ RT } },
+{ "mtdcr",   X(31,451),	X_MASK,		PPC403,		{ SPR, RS } },
+
+{ "divdu",   XO(31,457,0,0), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "divdu.",  XO(31,457,0,1), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "divduo",  XO(31,457,1,0), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "divduo.", XO(31,457,1,1), XO_MASK,	PPC64,		{ RT, RA, RB } },
+
+{ "divwu",   XO(31,459,0,0), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "divwu.",  XO(31,459,0,1), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "divwuo",  XO(31,459,1,0), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "divwuo.", XO(31,459,1,1), XO_MASK,	PPC,		{ RT, RA, RB } },
+
+{ "mtmq",    XSPR(31,467,0),   XSPR_MASK,    M601,	{ RS } },
+{ "mtxer",   XSPR(31,467,1),   XSPR_MASK,    COM,	{ RS } },
+{ "mtlr",    XSPR(31,467,8),   XSPR_MASK,    COM,	{ RS } },
+{ "mtctr",   XSPR(31,467,9),   XSPR_MASK,    COM,	{ RS } },
+{ "mttid",   XSPR(31,467,17),  XSPR_MASK,    POWER,	{ RS } },
+{ "mtdsisr", XSPR(31,467,18),  XSPR_MASK,    COM,	{ RS } },
+{ "mtdar",   XSPR(31,467,19),  XSPR_MASK,    COM,	{ RS } },
+{ "mtrtcu",  XSPR(31,467,20),  XSPR_MASK,    COM,	{ RS } },
+{ "mtrtcl",  XSPR(31,467,21),  XSPR_MASK,    COM,	{ RS } },
+{ "mtdec",   XSPR(31,467,22),  XSPR_MASK,    COM,	{ RS } },
+{ "mtsdr0",  XSPR(31,467,24),  XSPR_MASK,    POWER,	{ RS } },
+{ "mtsdr1",  XSPR(31,467,25),  XSPR_MASK,    COM,	{ RS } },
+{ "mtsrr0",  XSPR(31,467,26),  XSPR_MASK,    COM,	{ RS } },
+{ "mtsrr1",  XSPR(31,467,27),  XSPR_MASK,    COM,	{ RS } },
+{ "mtcmpa",   XSPR(31,467,144), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcmpb",   XSPR(31,467,145), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcmpc",   XSPR(31,467,146), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcmpd",   XSPR(31,467,147), XSPR_MASK, PPC860,	{ RT } },
+{ "mticr",    XSPR(31,467,148), XSPR_MASK, PPC860,	{ RT } },
+{ "mtder",    XSPR(31,467,149), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcounta", XSPR(31,467,150), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcountb", XSPR(31,467,151), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcmpe",   XSPR(31,467,152), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcmpf",   XSPR(31,467,153), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcmpg",   XSPR(31,467,154), XSPR_MASK, PPC860,	{ RT } },
+{ "mtcmph",   XSPR(31,467,155), XSPR_MASK, PPC860,	{ RT } },
+{ "mtlctrl1", XSPR(31,467,156), XSPR_MASK, PPC860,	{ RT } },
+{ "mtlctrl2", XSPR(31,467,157), XSPR_MASK, PPC860,	{ RT } },
+{ "mtictrl",  XSPR(31,467,158), XSPR_MASK, PPC860,	{ RT } },
+{ "mtbar",    XSPR(31,467,159), XSPR_MASK, PPC860,	{ RT } },
+{ "mtsprg",  XSPR(31,467,272), XSPRG_MASK,   PPC,	{ SPRG, RS } },
+{ "mtsprg0", XSPR(31,467,272), XSPR_MASK,    PPC,	{ RT } },
+{ "mtsprg1", XSPR(31,467,273), XSPR_MASK,    PPC,	{ RT } },
+{ "mtsprg2", XSPR(31,467,274), XSPR_MASK,    PPC,	{ RT } },
+{ "mtsprg3", XSPR(31,467,275), XSPR_MASK,    PPC,	{ RT } },
+{ "mtsprg4", XSPR(31,467,276), XSPR_MASK,    PPC405,	{ RT } },
+{ "mtsprg5", XSPR(31,467,277), XSPR_MASK,    PPC405,	{ RT } },
+{ "mtsprg6", XSPR(31,467,278), XSPR_MASK,    PPC405,	{ RT } },
+{ "mtsprg7", XSPR(31,467,279), XSPR_MASK,    PPC405,	{ RT } },
+{ "mtasr",   XSPR(31,467,280), XSPR_MASK,    PPC64,	{ RS } },
+{ "mtear",   XSPR(31,467,282), XSPR_MASK,    PPC,	{ RS } },
+{ "mttbl",   XSPR(31,467,284), XSPR_MASK,    PPC,	{ RS } },
+{ "mttbu",   XSPR(31,467,285), XSPR_MASK,    PPC,	{ RS } },
+{ "mtibatu", XSPR(31,467,528), XSPRBAT_MASK, PPC,	{ SPRBAT, RS } },
+{ "mtibatl", XSPR(31,467,529), XSPRBAT_MASK, PPC,	{ SPRBAT, RS } },
+{ "mtdbatu", XSPR(31,467,536), XSPRBAT_MASK, PPC,	{ SPRBAT, RS } },
+{ "mtdbatl", XSPR(31,467,537), XSPRBAT_MASK, PPC,	{ SPRBAT, RS } },
+{ "mtzpr",   XSPR(31,467,944), XSPR_MASK, PPC403,	{ RT } },
+{ "mtpid",   XSPR(31,467,945), XSPR_MASK, PPC403,	{ RT } },
+{ "mtccr0",  XSPR(31,467,947), XSPR_MASK, PPC405,	{ RT } },
+{ "mtiac3",  XSPR(31,467,948), XSPR_MASK, PPC405,	{ RT } },
+{ "mtiac4",  XSPR(31,467,949), XSPR_MASK, PPC405,	{ RT } },
+{ "mtdvc1",  XSPR(31,467,950), XSPR_MASK, PPC405,	{ RT } },
+{ "mtdvc2",  XSPR(31,467,951), XSPR_MASK, PPC405,	{ RT } },
+{ "mtsgr",   XSPR(31,467,953), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdcwr",  XSPR(31,467,954), XSPR_MASK, PPC403,	{ RT } },
+{ "mtsler",  XSPR(31,467,955), XSPR_MASK, PPC405,	{ RT } },
+{ "mtsu0r",  XSPR(31,467,956), XSPR_MASK, PPC405,	{ RT } },
+{ "mtdbcr1", XSPR(31,467,957), XSPR_MASK, PPC405,	{ RT } },
+{ "mticdbdr",XSPR(31,467,979), XSPR_MASK, PPC403,	{ RT } },
+{ "mtesr",   XSPR(31,467,980), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdear",  XSPR(31,467,981), XSPR_MASK, PPC403,	{ RT } },
+{ "mtevpr",  XSPR(31,467,982), XSPR_MASK, PPC403,	{ RT } },
+{ "mtcdbcr", XSPR(31,467,983), XSPR_MASK, PPC403,	{ RT } },
+{ "mttsr",   XSPR(31,467,984), XSPR_MASK, PPC403,	{ RT } },
+{ "mttcr",   XSPR(31,467,986), XSPR_MASK, PPC403,	{ RT } },
+{ "mtpit",   XSPR(31,467,987), XSPR_MASK, PPC403,	{ RT } },
+{ "mttbhi",  XSPR(31,467,988), XSPR_MASK, PPC403,	{ RT } },
+{ "mttblo",  XSPR(31,467,989), XSPR_MASK, PPC403,	{ RT } },
+{ "mtsrr2",  XSPR(31,467,990), XSPR_MASK, PPC403,	{ RT } },
+{ "mtsrr3",  XSPR(31,467,991), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdbsr",  XSPR(31,467,1008), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdbcr0", XSPR(31,467,1010), XSPR_MASK, PPC405,	{ RT } },
+{ "mtiac1",  XSPR(31,467,1012), XSPR_MASK, PPC403,	{ RT } },
+{ "mtiac2",  XSPR(31,467,1013), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdac1",  XSPR(31,467,1014), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdac2",  XSPR(31,467,1015), XSPR_MASK, PPC403,	{ RT } },
+{ "mtdccr",  XSPR(31,467,1018), XSPR_MASK, PPC403,	{ RT } },
+{ "mticcr",  XSPR(31,467,1019), XSPR_MASK, PPC403,	{ RT } },
+{ "mtpbl1",  XSPR(31,467,1020), XSPR_MASK, PPC403,	{ RT } },
+{ "mtpbu1",  XSPR(31,467,1021), XSPR_MASK, PPC403,	{ RT } },
+{ "mtpbl2",  XSPR(31,467,1022), XSPR_MASK, PPC403,	{ RT } },
+{ "mtpbu2",  XSPR(31,467,1023), XSPR_MASK, PPC403,	{ RT } },
+{ "mtspr",   X(31,467),	       X_MASK,	     COM,	{ SPR, RS } },
+
+{ "dcbi",    X(31,470),	XRT_MASK,	PPC,		{ RA, RB } },
+
+{ "nand",    XRC(31,476,0), X_MASK,	COM,		{ RA, RS, RB } },
+{ "nand.",   XRC(31,476,1), X_MASK,	COM,		{ RA, RS, RB } },
+
+{ "dcread",  X(31,486),	X_MASK,		PPC403,		{ RT, RA, RB }},
+
+{ "nabs",    XO(31,488,0,0), XORB_MASK, M601,		{ RT, RA } },
+{ "nabs.",   XO(31,488,0,1), XORB_MASK, M601,		{ RT, RA } },
+{ "nabso",   XO(31,488,1,0), XORB_MASK, M601,		{ RT, RA } },
+{ "nabso.",  XO(31,488,1,1), XORB_MASK, M601,		{ RT, RA } },
+
+{ "divd",    XO(31,489,0,0), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "divd.",   XO(31,489,0,1), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "divdo",   XO(31,489,1,0), XO_MASK,	PPC64,		{ RT, RA, RB } },
+{ "divdo.",  XO(31,489,1,1), XO_MASK,	PPC64,		{ RT, RA, RB } },
+
+{ "divw",    XO(31,491,0,0), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "divw.",   XO(31,491,0,1), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "divwo",   XO(31,491,1,0), XO_MASK,	PPC,		{ RT, RA, RB } },
+{ "divwo.",  XO(31,491,1,1), XO_MASK,	PPC,		{ RT, RA, RB } },
+
+{ "slbia",   X(31,498),	0xffffffff,	PPC64,		{ 0 } },
+
+{ "cli",     X(31,502), XRB_MASK,	POWER,		{ RT, RA } },
+
+{ "mcrxr",   X(31,512),	XRARB_MASK|(3<<21), COM,	{ BF } },
+
+{ "clcs",    X(31,531), XRB_MASK,	M601,		{ RT, RA } },
+
+{ "lswx",    X(31,533),	X_MASK,		PPCCOM,		{ RT, RA, RB } },
+{ "lsx",     X(31,533),	X_MASK,		PWRCOM,		{ RT, RA, RB } },
+
+{ "lwbrx",   X(31,534),	X_MASK,		PPCCOM,		{ RT, RA, RB } },
+{ "lbrx",    X(31,534),	X_MASK,		PWRCOM,		{ RT, RA, RB } },
+
+{ "lfsx",    X(31,535),	X_MASK,		COM,		{ FRT, RA, RB } },
+
+{ "srw",     XRC(31,536,0), X_MASK,	PPCCOM,		{ RA, RS, RB } },
+{ "sr",      XRC(31,536,0), X_MASK,	PWRCOM,		{ RA, RS, RB } },
+{ "srw.",    XRC(31,536,1), X_MASK,	PPCCOM,		{ RA, RS, RB } },
+{ "sr.",     XRC(31,536,1), X_MASK,	PWRCOM,		{ RA, RS, RB } },
+
+{ "rrib",    XRC(31,537,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "rrib.",   XRC(31,537,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "srd",     XRC(31,539,0), X_MASK,	PPC64,		{ RA, RS, RB } },
+{ "srd.",    XRC(31,539,1), X_MASK,	PPC64,		{ RA, RS, RB } },
+
+{ "maskir",  XRC(31,541,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "maskir.", XRC(31,541,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "tlbsync", X(31,566),	0xffffffff,	PPC,		{ 0 } },
+
+{ "lfsux",   X(31,567),	X_MASK,		COM,		{ FRT, RAS, RB } },
+
+{ "mfsr",    X(31,595),	XRB_MASK|(1<<20), COM32,	{ RT, SR } },
+
+{ "lswi",    X(31,597),	X_MASK,		PPCCOM,		{ RT, RA, NB } },
+{ "lsi",     X(31,597),	X_MASK,		PWRCOM,		{ RT, RA, NB } },
+
+{ "sync",    X(31,598), 0xffffffff,	PPCCOM,		{ 0 } },
+{ "dcs",     X(31,598), 0xffffffff,	PWRCOM,		{ 0 } },
+
+{ "lfdx",    X(31,599), X_MASK,		COM,		{ FRT, RA, RB } },
+
+{ "mfsri",   X(31,627), X_MASK,		PWRCOM,		{ RT, RA, RB } },
+
+{ "dclst",   X(31,630), XRB_MASK,	PWRCOM,		{ RS, RA } },
+
+{ "lfdux",   X(31,631), X_MASK,		COM,		{ FRT, RAS, RB } },
+
+{ "mfsrin",  X(31,659), XRA_MASK,	PPC32,		{ RT, RB } },
+
+{ "stswx",   X(31,661), X_MASK,		PPCCOM,		{ RS, RA, RB } },
+{ "stsx",    X(31,661), X_MASK,		PWRCOM,		{ RS, RA, RB } },
+
+{ "stwbrx",  X(31,662), X_MASK,		PPCCOM,		{ RS, RA, RB } },
+{ "stbrx",   X(31,662), X_MASK,		PWRCOM,		{ RS, RA, RB } },
+
+{ "stfsx",   X(31,663), X_MASK,		COM,		{ FRS, RA, RB } },
+
+{ "srq",     XRC(31,664,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "srq.",    XRC(31,664,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "sre",     XRC(31,665,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "sre.",    XRC(31,665,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "stfsux",  X(31,695),	X_MASK,		COM,		{ FRS, RAS, RB } },
+
+{ "sriq",    XRC(31,696,0), X_MASK,	M601,		{ RA, RS, SH } },
+{ "sriq.",   XRC(31,696,1), X_MASK,	M601,		{ RA, RS, SH } },
+
+{ "stswi",   X(31,725),	X_MASK,		PPCCOM,		{ RS, RA, NB } },
+{ "stsi",    X(31,725),	X_MASK,		PWRCOM,		{ RS, RA, NB } },
+
+{ "stfdx",   X(31,727),	X_MASK,		COM,		{ FRS, RA, RB } },
+
+{ "srlq",    XRC(31,728,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "srlq.",   XRC(31,728,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "sreq",    XRC(31,729,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "sreq.",   XRC(31,729,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "dcba",    X(31,758),	XRT_MASK,	PPC405,		{ RA, RB } },
+
+{ "stfdux",  X(31,759),	X_MASK,		COM,		{ FRS, RAS, RB } },
+
+{ "srliq",   XRC(31,760,0), X_MASK,	M601,		{ RA, RS, SH } },
+{ "srliq.",  XRC(31,760,1), X_MASK,	M601,		{ RA, RS, SH } },
+
+{ "lhbrx",   X(31,790),	X_MASK,		COM,		{ RT, RA, RB } },
+
+{ "sraw",    XRC(31,792,0), X_MASK,	PPCCOM,		{ RA, RS, RB } },
+{ "sra",     XRC(31,792,0), X_MASK,	PWRCOM,		{ RA, RS, RB } },
+{ "sraw.",   XRC(31,792,1), X_MASK,	PPCCOM,		{ RA, RS, RB } },
+{ "sra.",    XRC(31,792,1), X_MASK,	PWRCOM,		{ RA, RS, RB } },
+
+{ "srad",    XRC(31,794,0), X_MASK,	PPC64,		{ RA, RS, RB } },
+{ "srad.",   XRC(31,794,1), X_MASK,	PPC64,		{ RA, RS, RB } },
+
+{ "rac",     X(31,818),	X_MASK,		PWRCOM,		{ RT, RA, RB } },
+
+{ "srawi",   XRC(31,824,0), X_MASK,	PPCCOM,		{ RA, RS, SH } },
+{ "srai",    XRC(31,824,0), X_MASK,	PWRCOM,		{ RA, RS, SH } },
+{ "srawi.",  XRC(31,824,1), X_MASK,	PPCCOM,		{ RA, RS, SH } },
+{ "srai.",   XRC(31,824,1), X_MASK,	PWRCOM,		{ RA, RS, SH } },
+
+{ "eieio",   X(31,854),	0xffffffff,	PPC,		{ 0 } },
+
+{ "tlbsx",   XRC(31,914,0), X_MASK, PPC403,	{ RT, RA, RB } },
+{ "tlbsx.",  XRC(31,914,1), X_MASK, PPC403,	{ RT, RA, RB } },
+
+{ "sthbrx",  X(31,918),	X_MASK,		COM,		{ RS, RA, RB } },
+
+{ "sraq",    XRC(31,920,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "sraq.",   XRC(31,920,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "srea",    XRC(31,921,0), X_MASK,	M601,		{ RA, RS, RB } },
+{ "srea.",   XRC(31,921,1), X_MASK,	M601,		{ RA, RS, RB } },
+
+{ "extsh",   XRC(31,922,0), XRB_MASK,	PPCCOM,		{ RA, RS } },
+{ "exts",    XRC(31,922,0), XRB_MASK,	PWRCOM,		{ RA, RS } },
+{ "extsh.",  XRC(31,922,1), XRB_MASK,	PPCCOM,		{ RA, RS } },
+{ "exts.",   XRC(31,922,1), XRB_MASK,	PWRCOM,		{ RA, RS } },
+
+{ "tlbrehi", XTLB(31,946,0), XTLB_MASK,	PPC403,		{ RT, RA } },
+{ "tlbrelo", XTLB(31,946,1), XTLB_MASK,	PPC403,		{ RT, RA } },
+{ "tlbre",   X(31,946),	X_MASK,		PPC403,		{ RT, RA, SH } },
+
+{ "sraiq",   XRC(31,952,0), X_MASK,	M601,		{ RA, RS, SH } },
+{ "sraiq.",  XRC(31,952,1), X_MASK,	M601,		{ RA, RS, SH } },
+
+{ "extsb",   XRC(31,954,0), XRB_MASK,	PPC,		{ RA, RS} },
+{ "extsb.",  XRC(31,954,1), XRB_MASK,	PPC,		{ RA, RS} },
+
+{ "iccci",   X(31,966),	XRT_MASK,	PPC403,		{ RA, RB } },
+
+{ "tlbld",   X(31,978),	XRTRA_MASK,	PPC,		{ RB } },
+
+{ "tlbwehi", XTLB(31,978,0), XTLB_MASK,	PPC403,		{ RT, RA } },
+{ "tlbwelo", XTLB(31,978,1), XTLB_MASK,	PPC403,		{ RT, RA } },
+{ "tlbwe",   X(31,978),	X_MASK,		PPC403,		{ RS, RA, SH } },
+
+{ "icbi",    X(31,982),	XRT_MASK,	PPC,		{ RA, RB } },
+
+{ "stfiwx",  X(31,983),	X_MASK,		PPC,		{ FRS, RA, RB } },
+
+{ "extsw",   XRC(31,986,0), XRB_MASK,	PPC,		{ RA, RS } },
+{ "extsw.",  XRC(31,986,1), XRB_MASK,	PPC,		{ RA, RS } },
+
+{ "icread",  X(31,998),	XRT_MASK,	PPC403,		{ RA, RB } },
+
+{ "tlbli",   X(31,1010), XRTRA_MASK,	PPC,		{ RB } },
+
+{ "dcbz",    X(31,1014), XRT_MASK,	PPC,		{ RA, RB } },
+{ "dclz",    X(31,1014), XRT_MASK,	PPC,		{ RA, RB } },
+
+{ "lvebx",   X(31,   7), X_MASK,	PPCVEC,		{ VD, RA, RB } },
+{ "lvehx",   X(31,  39), X_MASK,	PPCVEC,		{ VD, RA, RB } },
+{ "lvewx",   X(31,  71), X_MASK,	PPCVEC,		{ VD, RA, RB } },
+{ "lvsl",    X(31,   6), X_MASK,	PPCVEC,		{ VD, RA, RB } },
+{ "lvsr",    X(31,  38), X_MASK,	PPCVEC,		{ VD, RA, RB } },
+{ "lvx",     X(31, 103), X_MASK,	PPCVEC,		{ VD, RA, RB } },
+{ "lvxl",    X(31, 359), X_MASK,	PPCVEC,		{ VD, RA, RB } },
+{ "stvebx",  X(31, 135), X_MASK,	PPCVEC,		{ VS, RA, RB } },
+{ "stvehx",  X(31, 167), X_MASK,	PPCVEC,		{ VS, RA, RB } },
+{ "stvewx",  X(31, 199), X_MASK,	PPCVEC,		{ VS, RA, RB } },
+{ "stvx",    X(31, 231), X_MASK,	PPCVEC,		{ VS, RA, RB } },
+{ "stvxl",   X(31, 487), X_MASK,	PPCVEC,		{ VS, RA, RB } },
+
+{ "lwz",     OP(32),	OP_MASK,	PPCCOM,		{ RT, D, RA } },
+{ "l",	     OP(32),	OP_MASK,	PWRCOM,		{ RT, D, RA } },
+
+{ "lwzu",    OP(33),	OP_MASK,	PPCCOM,		{ RT, D, RAL } },
+{ "lu",      OP(33),	OP_MASK,	PWRCOM,		{ RT, D, RA } },
+
+{ "lbz",     OP(34),	OP_MASK,	COM,		{ RT, D, RA } },
+
+{ "lbzu",    OP(35),	OP_MASK,	COM,		{ RT, D, RAL } },
+
+{ "stw",     OP(36),	OP_MASK,	PPCCOM,		{ RS, D, RA } },
+{ "st",      OP(36),	OP_MASK,	PWRCOM,		{ RS, D, RA } },
+
+{ "stwu",    OP(37),	OP_MASK,	PPCCOM,		{ RS, D, RAS } },
+{ "stu",     OP(37),	OP_MASK,	PWRCOM,		{ RS, D, RA } },
+
+{ "stb",     OP(38),	OP_MASK,	COM,		{ RS, D, RA } },
+
+{ "stbu",    OP(39),	OP_MASK,	COM,		{ RS, D, RAS } },
+
+{ "lhz",     OP(40),	OP_MASK,	COM,		{ RT, D, RA } },
+
+{ "lhzu",    OP(41),	OP_MASK,	COM,		{ RT, D, RAL } },
+
+{ "lha",     OP(42),	OP_MASK,	COM,		{ RT, D, RA } },
+
+{ "lhau",    OP(43),	OP_MASK,	COM,		{ RT, D, RAL } },
+
+{ "sth",     OP(44),	OP_MASK,	COM,		{ RS, D, RA } },
+
+{ "sthu",    OP(45),	OP_MASK,	COM,		{ RS, D, RAS } },
+
+{ "lmw",     OP(46),	OP_MASK,	PPCCOM,		{ RT, D, RAM } },
+{ "lm",      OP(46),	OP_MASK,	PWRCOM,		{ RT, D, RA } },
+
+{ "stmw",    OP(47),	OP_MASK,	PPCCOM,		{ RS, D, RA } },
+{ "stm",     OP(47),	OP_MASK,	PWRCOM,		{ RS, D, RA } },
+
+{ "lfs",     OP(48),	OP_MASK,	COM,		{ FRT, D, RA } },
+
+{ "lfsu",    OP(49),	OP_MASK,	COM,		{ FRT, D, RAS } },
+
+{ "lfd",     OP(50),	OP_MASK,	COM,		{ FRT, D, RA } },
+
+{ "lfdu",    OP(51),	OP_MASK,	COM,		{ FRT, D, RAS } },
+
+{ "stfs",    OP(52),	OP_MASK,	COM,		{ FRS, D, RA } },
+
+{ "stfsu",   OP(53),	OP_MASK,	COM,		{ FRS, D, RAS } },
+
+{ "stfd",    OP(54),	OP_MASK,	COM,		{ FRS, D, RA } },
+
+{ "stfdu",   OP(55),	OP_MASK,	COM,		{ FRS, D, RAS } },
+
+{ "lfq",     OP(56),	OP_MASK,	POWER2,		{ FRT, D, RA } },
+
+{ "lfqu",    OP(57),	OP_MASK,	POWER2,		{ FRT, D, RA } },
+
+{ "ld",      DSO(58,0),	DS_MASK,	PPC64,		{ RT, DS, RA } },
+
+{ "ldu",     DSO(58,1), DS_MASK,	PPC64,		{ RT, DS, RAL } },
+
+{ "lwa",     DSO(58,2), DS_MASK,	PPC64,		{ RT, DS, RA } },
+
+{ "fdivs",   A(59,18,0), AFRC_MASK,	PPC,		{ FRT, FRA, FRB } },
+{ "fdivs.",  A(59,18,1), AFRC_MASK,	PPC,		{ FRT, FRA, FRB } },
+
+{ "fsubs",   A(59,20,0), AFRC_MASK,	PPC,		{ FRT, FRA, FRB } },
+{ "fsubs.",  A(59,20,1), AFRC_MASK,	PPC,		{ FRT, FRA, FRB } },
+
+{ "fadds",   A(59,21,0), AFRC_MASK,	PPC,		{ FRT, FRA, FRB } },
+{ "fadds.",  A(59,21,1), AFRC_MASK,	PPC,		{ FRT, FRA, FRB } },
+
+{ "fsqrts",  A(59,22,0), AFRAFRC_MASK,	PPC,		{ FRT, FRB } },
+{ "fsqrts.", A(59,22,1), AFRAFRC_MASK,	PPC,		{ FRT, FRB } },
+
+{ "fres",    A(59,24,0), AFRAFRC_MASK,	PPC,		{ FRT, FRB } },
+{ "fres.",   A(59,24,1), AFRAFRC_MASK,	PPC,		{ FRT, FRB } },
+
+{ "fmuls",   A(59,25,0), AFRB_MASK,	PPC,		{ FRT, FRA, FRC } },
+{ "fmuls.",  A(59,25,1), AFRB_MASK,	PPC,		{ FRT, FRA, FRC } },
+
+{ "fmsubs",  A(59,28,0), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+{ "fmsubs.", A(59,28,1), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+
+{ "fmadds",  A(59,29,0), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+{ "fmadds.", A(59,29,1), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+
+{ "fnmsubs", A(59,30,0), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+{ "fnmsubs.",A(59,30,1), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+
+{ "fnmadds", A(59,31,0), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+{ "fnmadds.",A(59,31,1), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+
+{ "stfq",    OP(60),	OP_MASK,	POWER2,		{ FRS, D, RA } },
+
+{ "stfqu",   OP(61),	OP_MASK,	POWER2,		{ FRS, D, RA } },
+
+{ "std",     DSO(62,0),	DS_MASK,	PPC64,		{ RS, DS, RA } },
+
+{ "stdu",    DSO(62,1),	DS_MASK,	PPC64,		{ RS, DS, RAS } },
+
+{ "fcmpu",   X(63,0),	X_MASK|(3<<21),	COM,		{ BF, FRA, FRB } },
+
+{ "frsp",    XRC(63,12,0), XRA_MASK,	COM,		{ FRT, FRB } },
+{ "frsp.",   XRC(63,12,1), XRA_MASK,	COM,		{ FRT, FRB } },
+
+{ "fctiw",   XRC(63,14,0), XRA_MASK,	PPCCOM,		{ FRT, FRB } },
+{ "fcir",    XRC(63,14,0), XRA_MASK,	POWER2,		{ FRT, FRB } },
+{ "fctiw.",  XRC(63,14,1), XRA_MASK,	PPCCOM,		{ FRT, FRB } },
+{ "fcir.",   XRC(63,14,1), XRA_MASK,	POWER2,		{ FRT, FRB } },
+
+{ "fctiwz",  XRC(63,15,0), XRA_MASK,	PPCCOM,		{ FRT, FRB } },
+{ "fcirz",   XRC(63,15,0), XRA_MASK,	POWER2,		{ FRT, FRB } },
+{ "fctiwz.", XRC(63,15,1), XRA_MASK,	PPCCOM,		{ FRT, FRB } },
+{ "fcirz.",  XRC(63,15,1), XRA_MASK,	POWER2,		{ FRT, FRB } },
+
+{ "fdiv",    A(63,18,0), AFRC_MASK,	PPCCOM,		{ FRT, FRA, FRB } },
+{ "fd",      A(63,18,0), AFRC_MASK,	PWRCOM,		{ FRT, FRA, FRB } },
+{ "fdiv.",   A(63,18,1), AFRC_MASK,	PPCCOM,		{ FRT, FRA, FRB } },
+{ "fd.",     A(63,18,1), AFRC_MASK,	PWRCOM,		{ FRT, FRA, FRB } },
+
+{ "fsub",    A(63,20,0), AFRC_MASK,	PPCCOM,		{ FRT, FRA, FRB } },
+{ "fs",      A(63,20,0), AFRC_MASK,	PWRCOM,		{ FRT, FRA, FRB } },
+{ "fsub.",   A(63,20,1), AFRC_MASK,	PPCCOM,		{ FRT, FRA, FRB } },
+{ "fs.",     A(63,20,1), AFRC_MASK,	PWRCOM,		{ FRT, FRA, FRB } },
+
+{ "fadd",    A(63,21,0), AFRC_MASK,	PPCCOM,		{ FRT, FRA, FRB } },
+{ "fa",      A(63,21,0), AFRC_MASK,	PWRCOM,		{ FRT, FRA, FRB } },
+{ "fadd.",   A(63,21,1), AFRC_MASK,	PPCCOM,		{ FRT, FRA, FRB } },
+{ "fa.",     A(63,21,1), AFRC_MASK,	PWRCOM,		{ FRT, FRA, FRB } },
+
+{ "fsqrt",   A(63,22,0), AFRAFRC_MASK,	PPCPWR2,	{ FRT, FRB } },
+{ "fsqrt.",  A(63,22,1), AFRAFRC_MASK,	PPCPWR2,	{ FRT, FRB } },
+
+{ "fsel",    A(63,23,0), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+{ "fsel.",   A(63,23,1), A_MASK,	PPC,		{ FRT,FRA,FRC,FRB } },
+
+{ "fmul",    A(63,25,0), AFRB_MASK,	PPCCOM,		{ FRT, FRA, FRC } },
+{ "fm",      A(63,25,0), AFRB_MASK,	PWRCOM,		{ FRT, FRA, FRC } },
+{ "fmul.",   A(63,25,1), AFRB_MASK,	PPCCOM,		{ FRT, FRA, FRC } },
+{ "fm.",     A(63,25,1), AFRB_MASK,	PWRCOM,		{ FRT, FRA, FRC } },
+
+{ "frsqrte", A(63,26,0), AFRAFRC_MASK,	PPC,		{ FRT, FRB } },
+{ "frsqrte.",A(63,26,1), AFRAFRC_MASK,	PPC,		{ FRT, FRB } },
+
+{ "fmsub",   A(63,28,0), A_MASK,	PPCCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fms",     A(63,28,0), A_MASK,	PWRCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fmsub.",  A(63,28,1), A_MASK,	PPCCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fms.",    A(63,28,1), A_MASK,	PWRCOM,		{ FRT,FRA,FRC,FRB } },
+
+{ "fmadd",   A(63,29,0), A_MASK,	PPCCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fma",     A(63,29,0), A_MASK,	PWRCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fmadd.",  A(63,29,1), A_MASK,	PPCCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fma.",    A(63,29,1), A_MASK,	PWRCOM,		{ FRT,FRA,FRC,FRB } },
+
+{ "fnmsub",  A(63,30,0), A_MASK,	PPCCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fnms",    A(63,30,0), A_MASK,	PWRCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fnmsub.", A(63,30,1), A_MASK,	PPCCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fnms.",   A(63,30,1), A_MASK,	PWRCOM,		{ FRT,FRA,FRC,FRB } },
+
+{ "fnmadd",  A(63,31,0), A_MASK,	PPCCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fnma",    A(63,31,0), A_MASK,	PWRCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fnmadd.", A(63,31,1), A_MASK,	PPCCOM,		{ FRT,FRA,FRC,FRB } },
+{ "fnma.",   A(63,31,1), A_MASK,	PWRCOM,		{ FRT,FRA,FRC,FRB } },
+
+{ "fcmpo",   X(63,32),	X_MASK|(3<<21),	COM,		{ BF, FRA, FRB } },
+
+{ "mtfsb1",  XRC(63,38,0), XRARB_MASK,	COM,		{ BT } },
+{ "mtfsb1.", XRC(63,38,1), XRARB_MASK,	COM,		{ BT } },
+
+{ "fneg",    XRC(63,40,0), XRA_MASK,	COM,		{ FRT, FRB } },
+{ "fneg.",   XRC(63,40,1), XRA_MASK,	COM,		{ FRT, FRB } },
+
+{ "mcrfs",   X(63,64),	XRB_MASK|(3<<21)|(3<<16), COM,	{ BF, BFA } },
+
+{ "mtfsb0",  XRC(63,70,0), XRARB_MASK,	COM,		{ BT } },
+{ "mtfsb0.", XRC(63,70,1), XRARB_MASK,	COM,		{ BT } },
+
+{ "fmr",     XRC(63,72,0), XRA_MASK,	COM,		{ FRT, FRB } },
+{ "fmr.",    XRC(63,72,1), XRA_MASK,	COM,		{ FRT, FRB } },
+
+{ "mtfsfi",  XRC(63,134,0), XRA_MASK|(3<<21)|(1<<11), COM, { BF, U } },
+{ "mtfsfi.", XRC(63,134,1), XRA_MASK|(3<<21)|(1<<11), COM, { BF, U } },
+
+{ "fnabs",   XRC(63,136,0), XRA_MASK,	COM,		{ FRT, FRB } },
+{ "fnabs.",  XRC(63,136,1), XRA_MASK,	COM,		{ FRT, FRB } },
+
+{ "fabs",    XRC(63,264,0), XRA_MASK,	COM,		{ FRT, FRB } },
+{ "fabs.",   XRC(63,264,1), XRA_MASK,	COM,		{ FRT, FRB } },
+
+{ "mffs",    XRC(63,583,0), XRARB_MASK,	COM,		{ FRT } },
+{ "mffs.",   XRC(63,583,1), XRARB_MASK,	COM,		{ FRT } },
+
+{ "mtfsf",   XFL(63,711,0), XFL_MASK,	COM,		{ FLM, FRB } },
+{ "mtfsf.",  XFL(63,711,1), XFL_MASK,	COM,		{ FLM, FRB } },
+
+{ "fctid",   XRC(63,814,0), XRA_MASK,	PPC64,		{ FRT, FRB } },
+{ "fctid.",  XRC(63,814,1), XRA_MASK,	PPC64,		{ FRT, FRB } },
+
+{ "fctidz",  XRC(63,815,0), XRA_MASK,	PPC64,		{ FRT, FRB } },
+{ "fctidz.", XRC(63,815,1), XRA_MASK,	PPC64,		{ FRT, FRB } },
+
+{ "fcfid",   XRC(63,846,0), XRA_MASK,	PPC64,		{ FRT, FRB } },
+{ "fcfid.",  XRC(63,846,1), XRA_MASK,	PPC64,		{ FRT, FRB } },
+
+};
+
+const int powerpc_num_opcodes =
+  sizeof (powerpc_opcodes) / sizeof (powerpc_opcodes[0]);
+
+/* The macro table.  This is only used by the assembler.  */
+
+/* The expressions of the form (-x ! 31) & (x | 31) have the value 0
+   when x=0; 32-x when x is between 1 and 31; are negative if x is
+   negative; and are 32 or more otherwise.  This is what you want
+   when, for instance, you are emulating a right shift by a
+   rotate-left-and-mask, because the underlying instructions support
+   shifts of size 0 but not shifts of size 32.  By comparison, when
+   extracting x bits from some word you want to use just 32-x, because
+   the underlying instructions don't support extracting 0 bits but do
+   support extracting the whole word (32 bits in this case).  */
+
+const struct powerpc_macro powerpc_macros[] = {
+{ "extldi",  4,   PPC64,	"rldicr %0,%1,%3,(%2)-1" },
+{ "extldi.", 4,   PPC64,	"rldicr. %0,%1,%3,(%2)-1" },
+{ "extrdi",  4,   PPC64,	"rldicl %0,%1,(%2)+(%3),64-(%2)" },
+{ "extrdi.", 4,   PPC64,	"rldicl. %0,%1,(%2)+(%3),64-(%2)" },
+{ "insrdi",  4,   PPC64,	"rldimi %0,%1,64-((%2)+(%3)),%3" },
+{ "insrdi.", 4,   PPC64,	"rldimi. %0,%1,64-((%2)+(%3)),%3" },
+{ "rotrdi",  3,   PPC64,	"rldicl %0,%1,(-(%2)!63)&((%2)|63),0" },
+{ "rotrdi.", 3,   PPC64,	"rldicl. %0,%1,(-(%2)!63)&((%2)|63),0" },
+{ "sldi",    3,   PPC64,	"rldicr %0,%1,%2,63-(%2)" },
+{ "sldi.",   3,   PPC64,	"rldicr. %0,%1,%2,63-(%2)" },
+{ "srdi",    3,   PPC64,	"rldicl %0,%1,(-(%2)!63)&((%2)|63),%2" },
+{ "srdi.",   3,   PPC64,	"rldicl. %0,%1,(-(%2)!63)&((%2)|63),%2" },
+{ "clrrdi",  3,   PPC64,	"rldicr %0,%1,0,63-(%2)" },
+{ "clrrdi.", 3,   PPC64,	"rldicr. %0,%1,0,63-(%2)" },
+{ "clrlsldi",4,   PPC64,	"rldic %0,%1,%3,(%2)-(%3)" },
+{ "clrlsldi.",4,  PPC64,	"rldic. %0,%1,%3,(%2)-(%3)" },
+
+{ "extlwi",  4,   PPCCOM,	"rlwinm %0,%1,%3,0,(%2)-1" },
+{ "extlwi.", 4,   PPCCOM,	"rlwinm. %0,%1,%3,0,(%2)-1" },
+{ "extrwi",  4,   PPCCOM,	"rlwinm %0,%1,(%2)+(%3),32-(%2),31" },
+{ "extrwi.", 4,   PPCCOM,	"rlwinm. %0,%1,(%2)+(%3),32-(%2),31" },
+{ "inslwi",  4,   PPCCOM,	"rlwimi %0,%1,(-(%3)!31)&((%3)|31),%3,(%2)+(%3)-1" },
+{ "inslwi.", 4,   PPCCOM,	"rlwimi. %0,%1,(-(%3)!31)&((%3)|31),%3,(%2)+(%3)-1"},
+{ "insrwi",  4,   PPCCOM,	"rlwimi %0,%1,32-((%2)+(%3)),%3,(%2)+(%3)-1" },
+{ "insrwi.", 4,   PPCCOM,	"rlwimi. %0,%1,32-((%2)+(%3)),%3,(%2)+(%3)-1"},
+{ "rotrwi",  3,   PPCCOM,	"rlwinm %0,%1,(-(%2)!31)&((%2)|31),0,31" },
+{ "rotrwi.", 3,   PPCCOM,	"rlwinm. %0,%1,(-(%2)!31)&((%2)|31),0,31" },
+{ "slwi",    3,   PPCCOM,	"rlwinm %0,%1,%2,0,31-(%2)" },
+{ "sli",     3,   PWRCOM,	"rlinm %0,%1,%2,0,31-(%2)" },
+{ "slwi.",   3,   PPCCOM,	"rlwinm. %0,%1,%2,0,31-(%2)" },
+{ "sli.",    3,   PWRCOM,	"rlinm. %0,%1,%2,0,31-(%2)" },
+{ "srwi",    3,   PPCCOM,	"rlwinm %0,%1,(-(%2)!31)&((%2)|31),%2,31" },
+{ "sri",     3,   PWRCOM,	"rlinm %0,%1,(-(%2)!31)&((%2)|31),%2,31" },
+{ "srwi.",   3,   PPCCOM,	"rlwinm. %0,%1,(-(%2)!31)&((%2)|31),%2,31" },
+{ "sri.",    3,   PWRCOM,	"rlinm. %0,%1,(-(%2)!31)&((%2)|31),%2,31" },
+{ "clrrwi",  3,   PPCCOM,	"rlwinm %0,%1,0,0,31-(%2)" },
+{ "clrrwi.", 3,   PPCCOM,	"rlwinm. %0,%1,0,0,31-(%2)" },
+{ "clrlslwi",4,   PPCCOM,	"rlwinm %0,%1,%3,(%2)-(%3),31-(%3)" },
+{ "clrlslwi.",4,  PPCCOM,	"rlwinm. %0,%1,%3,(%2)-(%3),31-(%3)" },
+
+};
+
+const int powerpc_num_macros =
+  sizeof (powerpc_macros) / sizeof (powerpc_macros[0]);
diff -purN linux-2.5/arch/ppc64/kdb/ppc.h linuxppc64-2.5/arch/ppc64/kdb/ppc.h
--- linux-2.5/arch/ppc64/kdb/ppc.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/ppc.h	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,259 @@
+/* ppc.h -- Header file for PowerPC opcode table
+   Copyright 1994, 1995 Free Software Foundation, Inc.
+   Written by Ian Lance Taylor, Cygnus Support
+
+This file is part of GDB, GAS, and the GNU binutils.
+
+GDB, GAS, and the GNU binutils are free software; you can redistribute
+them and/or modify them under the terms of the GNU General Public
+License as published by the Free Software Foundation; either version
+1, or (at your option) any later version.
+
+GDB, GAS, and the GNU binutils are distributed in the hope that they
+will be useful, but WITHOUT ANY WARRANTY; without even the implied
+warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See
+the GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this file; see the file COPYING.  If not, write to the Free
+Software Foundation, 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  */
+
+#ifndef PPC_H
+#define PPC_H
+
+/* The opcode table is an array of struct powerpc_opcode.  */
+
+struct powerpc_opcode
+{
+  /* The opcode name.  */
+  const char *name;
+
+  /* The opcode itself.  Those bits which will be filled in with
+     operands are zeroes.  */
+  unsigned long opcode;
+
+  /* The opcode mask.  This is used by the disassembler.  This is a
+     mask containing ones indicating those bits which must match the
+     opcode field, and zeroes indicating those bits which need not
+     match (and are presumably filled in by operands).  */
+  unsigned long mask;
+
+  /* One bit flags for the opcode.  These are used to indicate which
+     specific processors support the instructions.  The defined values
+     are listed below.  */
+  unsigned long flags;
+
+  /* An array of operand codes.  Each code is an index into the
+     operand table.  They appear in the order which the operands must
+     appear in assembly code, and are terminated by a zero.  */
+  unsigned char operands[8];
+};
+
+/* The table itself is sorted by major opcode number, and is otherwise
+   in the order in which the disassembler should consider
+   instructions.  */
+extern const struct powerpc_opcode powerpc_opcodes[];
+extern const int powerpc_num_opcodes;
+
+/* Values defined for the flags field of a struct powerpc_opcode.  */
+
+/* Opcode is defined for the PowerPC architecture.  */
+#define PPC_OPCODE_PPC (01)
+
+/* Opcode is defined for the POWER (RS/6000) architecture.  */
+#define PPC_OPCODE_POWER (02)
+
+/* Opcode is defined for the POWER2 (Rios 2) architecture.  */
+#define PPC_OPCODE_POWER2 (04)
+
+/* Opcode is only defined on 32 bit architectures.  */
+#define PPC_OPCODE_32 (010)
+
+/* Opcode is only defined on 64 bit architectures.  */
+#define PPC_OPCODE_64 (020)
+
+/* Opcode is supported by the Motorola PowerPC 601 processor.  The 601
+   is assumed to support all PowerPC (PPC_OPCODE_PPC) instructions,
+   but it also supports many additional POWER instructions.  */
+#define PPC_OPCODE_601 (040)
+
+/* Opcode is supported in both the Power and PowerPC architectures
+   (ie, compiler's -mcpu=common or assembler's -mcom).  */
+#define PPC_OPCODE_COMMON (0100)
+
+/* Opcode is supported for any Power or PowerPC platform (this is
+   for the assembler's -many option, and it eliminates duplicates).  */
+#define PPC_OPCODE_ANY (0200)
+
+/* Opcode is supported as part of the 64-bit bridge.  */
+#define PPC_OPCODE_64_BRIDGE (0400)
+
+/* Opcode is supported by Altivec Vector Unit */
+#define PPC_OPCODE_ALTIVEC   (01000)
+
+/* A macro to extract the major opcode from an instruction.  */
+#define PPC_OP(i) (((i) >> 26) & 0x3f)
+
+/* The operands table is an array of struct powerpc_operand.  */
+
+struct powerpc_operand
+{
+  /* The number of bits in the operand.  */
+  int bits;
+
+  /* How far the operand is left shifted in the instruction.  */
+  int shift;
+
+  /* Insertion function.  This is used by the assembler.  To insert an
+     operand value into an instruction, check this field.
+
+     If it is NULL, execute
+         i |= (op & ((1 << o->bits) - 1)) << o->shift;
+     (i is the instruction which we are filling in, o is a pointer to
+     this structure, and op is the opcode value; this assumes twos
+     complement arithmetic).
+
+     If this field is not NULL, then simply call it with the
+     instruction and the operand value.  It will return the new value
+     of the instruction.  If the ERRMSG argument is not NULL, then if
+     the operand value is illegal, *ERRMSG will be set to a warning
+     string (the operand will be inserted in any case).  If the
+     operand value is legal, *ERRMSG will be unchanged (most operands
+     can accept any value).  */
+  unsigned long (*insert) PARAMS ((unsigned long instruction, long op,
+				   const char **errmsg));
+
+  /* Extraction function.  This is used by the disassembler.  To
+     extract this operand type from an instruction, check this field.
+
+     If it is NULL, compute
+         op = ((i) >> o->shift) & ((1 << o->bits) - 1);
+	 if ((o->flags & PPC_OPERAND_SIGNED) != 0
+	     && (op & (1 << (o->bits - 1))) != 0)
+	   op -= 1 << o->bits;
+     (i is the instruction, o is a pointer to this structure, and op
+     is the result; this assumes twos complement arithmetic).
+
+     If this field is not NULL, then simply call it with the
+     instruction value.  It will return the value of the operand.  If
+     the INVALID argument is not NULL, *INVALID will be set to
+     non-zero if this operand type can not actually be extracted from
+     this operand (i.e., the instruction does not match).  If the
+     operand is valid, *INVALID will not be changed.  */
+  long (*extract) PARAMS ((unsigned long instruction, int *invalid));
+
+  /* One bit syntax flags.  */
+  unsigned long flags;
+};
+
+/* Elements in the table are retrieved by indexing with values from
+   the operands field of the powerpc_opcodes table.  */
+
+extern const struct powerpc_operand powerpc_operands[];
+
+/* Values defined for the flags field of a struct powerpc_operand.  */
+
+/* This operand takes signed values.  */
+#define PPC_OPERAND_SIGNED (01)
+
+/* This operand takes signed values, but also accepts a full positive
+   range of values when running in 32 bit mode.  That is, if bits is
+   16, it takes any value from -0x8000 to 0xffff.  In 64 bit mode,
+   this flag is ignored.  */
+#define PPC_OPERAND_SIGNOPT (02)
+
+/* This operand does not actually exist in the assembler input.  This
+   is used to support extended mnemonics such as mr, for which two
+   operands fields are identical.  The assembler should call the
+   insert function with any op value.  The disassembler should call
+   the extract function, ignore the return value, and check the value
+   placed in the valid argument.  */
+#define PPC_OPERAND_FAKE (04)
+
+/* The next operand should be wrapped in parentheses rather than
+   separated from this one by a comma.  This is used for the load and
+   store instructions which want their operands to look like
+       reg,displacement(reg)
+   */
+#define PPC_OPERAND_PARENS (010)
+
+/* This operand may use the symbolic names for the CR fields, which
+   are
+       lt  0	gt  1	eq  2	so  3	un  3
+       cr0 0	cr1 1	cr2 2	cr3 3
+       cr4 4	cr5 5	cr6 6	cr7 7
+   These may be combined arithmetically, as in cr2*4+gt.  These are
+   only supported on the PowerPC, not the POWER.  */
+#define PPC_OPERAND_CR (020)
+
+/* This operand names a register.  The disassembler uses this to print
+   register names with a leading 'r'.  */
+#define PPC_OPERAND_GPR (040)
+
+/* This operand names a floating point register.  The disassembler
+   prints these with a leading 'f'.  */
+#define PPC_OPERAND_FPR (0100)
+
+/* This operand is a relative branch displacement.  The disassembler
+   prints these symbolically if possible.  */
+#define PPC_OPERAND_RELATIVE (0200)
+
+/* This operand is an absolute branch address.  The disassembler
+   prints these symbolically if possible.  */
+#define PPC_OPERAND_ABSOLUTE (0400)
+
+/* This operand is optional, and is zero if omitted.  This is used for
+   the optional BF and L fields in the comparison instructions.  The
+   assembler must count the number of operands remaining on the line,
+   and the number of operands remaining for the opcode, and decide
+   whether this operand is present or not.  The disassembler should
+   print this operand out only if it is not zero.  */
+#define PPC_OPERAND_OPTIONAL (01000)
+
+/* This flag is only used with PPC_OPERAND_OPTIONAL.  If this operand
+   is omitted, then for the next operand use this operand value plus
+   1, ignoring the next operand field for the opcode.  This wretched
+   hack is needed because the Power rotate instructions can take
+   either 4 or 5 operands.  The disassembler should print this operand
+   out regardless of the PPC_OPERAND_OPTIONAL field.  */
+#define PPC_OPERAND_NEXT (02000)
+
+/* This operand should be regarded as a negative number for the
+   purposes of overflow checking (i.e., the normal most negative
+   number is disallowed and one more than the normal most positive
+   number is allowed).  This flag will only be set for a signed
+   operand.  */
+#define PPC_OPERAND_NEGATIVE (04000)
+
+/* This operand names a vector unit register.  The disassembler
+   prints these with a leading 'v'.  */
+#define PPC_OPERAND_VR (010000)
+
+
+/* The POWER and PowerPC assemblers use a few macros.  We keep them
+   with the operands table for simplicity.  The macro table is an
+   array of struct powerpc_macro.  */
+
+struct powerpc_macro
+{
+  /* The macro name.  */
+  const char *name;
+
+  /* The number of operands the macro takes.  */
+  unsigned int operands;
+
+  /* One bit flags for the opcode.  These are used to indicate which
+     specific processors support the instructions.  The values are the
+     same as those for the struct powerpc_opcode flags field.  */
+  unsigned long flags;
+
+  /* A format string to turn the macro into a normal instruction.
+     Each %N in the string is replaced with operand number N (zero
+     based).  */
+  const char *format;
+};
+
+extern const struct powerpc_macro powerpc_macros[];
+extern const int powerpc_num_macros;
+
+#endif /* PPC_H */
diff -purN linux-2.5/arch/ppc64/kdb/privinst.h linuxppc64-2.5/arch/ppc64/kdb/privinst.h
--- linux-2.5/arch/ppc64/kdb/privinst.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/privinst.h	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,95 @@
+/*
+ * Copyright (C) 1996 Paul Mackerras.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+#include <linux/config.h>
+
+#define GETREG(reg)		\
+    static inline unsigned long get_ ## reg (void)	\
+	{ unsigned long ret; asm volatile ("mf" #reg " %0" : "=r" (ret) :); return ret; }
+
+#define SETREG(reg)		\
+    static inline void set_ ## reg (unsigned long val)	\
+	{ asm volatile ("mt" #reg " %0" : : "r" (val)); }
+
+GETREG(msr)
+SETREG(msr)
+SETREG(msrd)
+GETREG(cr)
+
+#define GSETSPR(n, name)	\
+    static inline long get_ ## name (void) \
+	{ long ret; asm volatile ("mfspr %0," #n : "=r" (ret) : ); return ret; } \
+    static inline void set_ ## name (long val) \
+	{ asm volatile ("mtspr " #n ",%0" : : "r" (val)); }
+
+GSETSPR(0, mq)
+GSETSPR(1, xer)
+GSETSPR(4, rtcu)
+GSETSPR(5, rtcl)
+GSETSPR(8, lr)
+GSETSPR(9, ctr)
+GSETSPR(18, dsisr)
+GSETSPR(19, dar)
+GSETSPR(22, dec)
+GSETSPR(25, sdr1)
+GSETSPR(26, srr0)
+GSETSPR(27, srr1)
+GSETSPR(272, sprg0)
+GSETSPR(273, sprg1)
+GSETSPR(274, sprg2)
+GSETSPR(275, sprg3)
+GSETSPR(282, ear)
+GSETSPR(287, pvr)
+GSETSPR(528, bat0u)
+GSETSPR(529, bat0l)
+GSETSPR(530, bat1u)
+GSETSPR(531, bat1l)
+GSETSPR(532, bat2u)
+GSETSPR(533, bat2l)
+GSETSPR(534, bat3u)
+GSETSPR(535, bat3l)
+GSETSPR(1008, hid0)
+GSETSPR(1009, hid1)
+GSETSPR(1010, iabr)
+GSETSPR(1013, dabr)
+GSETSPR(1023, pir)
+
+static inline int get_sr(int n)
+{
+    int ret;
+
+#if 0
+// DRENG does not assemble 
+    asm (" mfsrin %0,%1" : "=r" (ret) : "r" (n << 28));
+#endif
+    return ret;
+}
+
+static inline void set_sr(int n, int val)
+{
+#if 0
+// DRENG does not assemble 
+    asm ("mtsrin %0,%1" : : "r" (val), "r" (n << 28));
+#endif
+}
+
+static inline void store_inst(void *p)
+{
+    asm volatile ("dcbst 0,%0; sync; icbi 0,%0; isync" : : "r" (p));
+}
+
+static inline void cflush(void *p)
+{
+    asm volatile ("dcbf 0,%0; icbi 0,%0" : : "r" (p));
+}
+
+static inline void cinval(void *p)
+{
+    asm volatile ("dcbi 0,%0; icbi 0,%0" : : "r" (p));
+}
+
diff -purN linux-2.5/arch/ppc64/kdb/symcat.h linuxppc64-2.5/arch/ppc64/kdb/symcat.h
--- linux-2.5/arch/ppc64/kdb/symcat.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kdb/symcat.h	2003-10-13 16:16:57.000000000 +0000
@@ -0,0 +1,49 @@
+/* Symbol concatenation utilities.
+
+   Copyright (C) 1998, 2000 Free Software Foundation, Inc.
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 2 of the License, or
+   (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+ 
+   You should have received a copy of the GNU General Public License along
+   with this program; if not, write to the Free Software Foundation, Inc.,
+   59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.  */
+
+#ifndef SYM_CAT_H
+#define SYM_CAT_H
+
+#if defined (__STDC__) || defined (ALMOST_STDC) || defined (HAVE_STRINGIZE)
+#define CONCAT2(a,b)	 a##b
+#define CONCAT3(a,b,c)	 a##b##c
+#define CONCAT4(a,b,c,d) a##b##c##d
+#define STRINGX(s) #s
+#else
+/* Note one should never pass extra whitespace to the CONCATn macros,
+   e.g. CONCAT2(foo, bar) because traditonal C will keep the space between
+   the two labels instead of concatenating them.  Instead, make sure to
+   write CONCAT2(foo,bar).  */
+#define CONCAT2(a,b)	 a/**/b
+#define CONCAT3(a,b,c)	 a/**/b/**/c
+#define CONCAT4(a,b,c,d) a/**/b/**/c/**/d
+#define STRINGX(s) "s"
+#endif
+
+#define XCONCAT2(a,b)     CONCAT2(a,b)
+#define XCONCAT3(a,b,c)   CONCAT3(a,b,c)
+#define XCONCAT4(a,b,c,d) CONCAT4(a,b,c,d)
+
+/* Note the layer of indirection here is typically used to allow
+   stringification of the expansion of macros.  I.e. "#define foo
+   bar", "XSTRING(foo)", to yield "bar".  Be aware that this only
+   works for __STDC__, not for traditional C which will still resolve
+   to "foo".  */
+#define XSTRING(s) STRINGX(s) 
+
+#endif /* SYM_CAT_H */
diff -purN linux-2.5/arch/ppc64/kernel/HvCall.c linuxppc64-2.5/arch/ppc64/kernel/HvCall.c
--- linux-2.5/arch/ppc64/kernel/HvCall.c	2002-02-14 12:14:35.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/HvCall.c	2003-09-12 08:26:25.000000000 +0000
@@ -90,11 +90,11 @@ void HvCall_writeLogBuffer(const void *b
 	struct HvLpBufferList bufList;
 	u64 bytesLeft = bufLen;
 	u64 leftThisPage;
-	u64 curPtr = virt_to_absolute( (unsigned long) buffer );
+	u64 curPtr = virt_to_absolute((unsigned long) buffer);
 
 	while (bytesLeft) {
 		bufList.addr = curPtr;
-      
+
 		leftThisPage = ((curPtr & PAGE_MASK) + PAGE_SIZE) - curPtr;
 
 		if (leftThisPage > bytesLeft) {
@@ -105,11 +105,11 @@ void HvCall_writeLogBuffer(const void *b
 			bytesLeft -= leftThisPage;
 		}
 
-		curPtr = (curPtr & PAGE_MASK) + PAGE_SIZE;
-	}
-
 
-	HvCall2(HvCallBaseWriteLogBuffer,
-		virt_to_absolute((unsigned long)&bufList), bufLen);
+		HvCall2(HvCallBaseWriteLogBuffer,
+			virt_to_absolute((unsigned long) &bufList),
+			bufList.len);
 
+		curPtr = (curPtr & PAGE_MASK) + PAGE_SIZE;
+	}
 }
diff -purN linux-2.5/arch/ppc64/kernel/LparData.c linuxppc64-2.5/arch/ppc64/kernel/LparData.c
--- linux-2.5/arch/ppc64/kernel/LparData.c	2003-03-26 04:30:58.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/LparData.c	2003-10-09 04:34:18.000000000 +0000
@@ -71,7 +71,7 @@ struct HvReleaseData hvReleaseData = {
 	6,		/* TEMP: This allows non-GA driver */
 	4,		/* We are v5r2m0               */
 	3,		/* Min supported PLIC = v5r1m0 */
-	3,		/* Min usuable PLIC   = v5r1m0 */
+	3,		/* Min usable PLIC   = v5r1m0 */
 	{ 0xd3, 0x89, 0x95, 0xa4, /* "Linux 2.4   "*/
 	  0xa7, 0x40, 0xf2, 0x4b,
 	  0xf4, 0x4b, 0xf6, 0xf4 },
@@ -175,7 +175,7 @@ struct ItVpdAreas itVpdAreas = {
 	0, 0,
 	26,		/* # VPD array entries */
 	10,		/* # DMA array entries */
-	MAX_PROCESSORS*2, maxPhysicalProcessors,	/* Max logical, physical procs */
+	NR_CPUS*2, maxPhysicalProcessors,	/* Max logical, physical procs */
 	offsetof(struct ItVpdAreas,xPlicDmaToks),/* offset to DMA toks */
 	offsetof(struct ItVpdAreas,xSlicVpdAdrs),/* offset to VPD addrs */
 	offsetof(struct ItVpdAreas,xPlicDmaLens),/* offset to DMA lens */
diff -purN linux-2.5/arch/ppc64/kernel/Makefile linuxppc64-2.5/arch/ppc64/kernel/Makefile
--- linux-2.5/arch/ppc64/kernel/Makefile	2003-08-05 03:55:20.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/Makefile	2003-11-21 06:45:02.000000000 +0000
@@ -10,21 +10,26 @@ obj-y               :=	setup.o entry.o t
 			align.o semaphore.o bitops.o stab.o htab.o pacaData.o \
 			udbg.o binfmt_elf32.o sys_ppc32.o ioctl32.o \
 			ptrace32.o signal32.o pmc.o rtc.o init_task.o \
-			lmb.o pci.o pci_dn.o pci_dma.o cputable.o
+			lmb.o cputable.o
 
-obj-$(CONFIG_PPC_ISERIES) += iSeries_pci.o       iSeries_pci_reset.o \
-			     iSeries_IoMmTable.o iSeries_irq.o \
-			     iSeries_VpdInfo.o   XmPciLpEvent.o \
+obj-$(CONFIG_PCI)	+= pci.o pci_dn.o pci_dma.o
+
+ifdef CONFIG_PPC_ISERIES
+obj-$(CONFIG_PCI)	+= iSeries_pci.o iSeries_pci_reset.o \
+			     iSeries_IoMmTable.o 
+endif
+
+obj-$(CONFIG_PPC_ISERIES) += iSeries_irq.o \
+			     iSeries_VpdInfo.o XmPciLpEvent.o \
 			     HvCall.o HvLpConfig.o LparData.o mf_proc.o \
 			     iSeries_setup.o ItLpQueue.o hvCall.o \
-			     mf.o HvLpEvent.o iSeries_proc.o 
+			     mf.o HvLpEvent.o iSeries_proc.o iSeries_htab.o \
+			     proc_pmc.o
 
 obj-$(CONFIG_PPC_PSERIES) += pSeries_pci.o pSeries_lpar.o pSeries_hvCall.o \
-			     eeh.o rtasd.o nvram.o ras.o
-
-# Change this to pSeries only once we've got iSeries up to date
-obj-y			  += open_pic.o xics.o pSeries_htab.o rtas.o \
-			     chrp_setup.o i8259.o prom.o 
+			     eeh.o nvram.o rtasd.o ras.o \
+			     open_pic.o xics.o pSeries_htab.o rtas.o \
+			     chrp_setup.o i8259.o prom.o
 
 obj-$(CONFIG_PROC_FS)		+= proc_ppc64.o
 obj-$(CONFIG_RTAS_FLASH)	+= rtas_flash.o
@@ -32,5 +37,6 @@ obj-$(CONFIG_SMP)		+= smp.o
 obj-$(CONFIG_MODULES)		+= module.o ppc_ksyms.o
 obj-$(CONFIG_PPC_RTAS)		+= rtas-proc.o
 obj-$(CONFIG_SCANLOG)		+= scanlog.o
+obj-$(CONFIG_VIOPATH)		+= viopath.o
 
 CFLAGS_ioctl32.o += -Ifs/
diff -purN linux-2.5/arch/ppc64/kernel/XmPciLpEvent.c linuxppc64-2.5/arch/ppc64/kernel/XmPciLpEvent.c
--- linux-2.5/arch/ppc64/kernel/XmPciLpEvent.c	2003-05-02 17:21:13.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/XmPciLpEvent.c	2003-10-27 06:38:22.000000000 +0000
@@ -20,13 +20,13 @@
 #include <asm/iSeries/XmPciLpEvent.h>
 #include <asm/ppcdebug.h>
 
-long Pci_Interrupt_Count = 0;
-long Pci_Event_Count     = 0;
+static long Pci_Interrupt_Count;
+static long Pci_Event_Count;
 
 enum XmPciLpEvent_Subtype {
 	XmPciLpEvent_BusCreated	   = 0,		// PHB has been created
 	XmPciLpEvent_BusError	   = 1,		// PHB has failed
-	XmPciLpEvent_BusFailed	   = 2,		// Msg to Seconday, Primary failed bus
+	XmPciLpEvent_BusFailed	   = 2,		// Msg to Secondary, Primary failed bus
 	XmPciLpEvent_NodeFailed	   = 4,		// Multi-adapter bridge has failed
 	XmPciLpEvent_NodeRecovered = 5,		// Multi-adapter bridge has recovered
 	XmPciLpEvent_BusRecovered  = 12,	// PHB has been recovered
@@ -90,7 +90,7 @@ static void XmPciLpEvent_handler( struct
 			break;
 		}
 	}
-	else if (event) {
+	else if (eventParm) {
 		printk(KERN_ERR "XmPciLpEvent.c: Unrecognized PCI event type 0x%x\n",(int)eventParm->xType);
 	}
 	else {
diff -purN linux-2.5/arch/ppc64/kernel/chrp_setup.c linuxppc64-2.5/arch/ppc64/kernel/chrp_setup.c
--- linux-2.5/arch/ppc64/kernel/chrp_setup.c	2003-09-02 06:46:41.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/chrp_setup.c	2003-11-21 06:45:02.000000000 +0000
@@ -57,6 +57,7 @@
 #include <asm/irq.h>
 #include <asm/naca.h>
 #include <asm/time.h>
+#include <asm/nvram.h>
 
 #include "i8259.h"
 #include "open_pic.h"
@@ -64,11 +65,10 @@
 #include <asm/ppcdebug.h>
 #include <asm/cputable.h>
 
-extern volatile unsigned char *chrp_int_ack_special;
-
 void chrp_progress(char *, unsigned short);
 
 extern void openpic_init_IRQ(void);
+extern void openpic_init_irq_desc(irq_desc_t *);
 
 extern void find_and_init_phbs(void);
 
@@ -96,16 +96,19 @@ chrp_get_cpuinfo(struct seq_file *m)
 
 	seq_printf(m, "timebase\t: %lu\n", ppc_tb_freq);
 
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	if (root)
 		model = get_property(root, "model", NULL);
 	seq_printf(m, "machine\t\t: CHRP %s\n", model);
+	of_node_put(root);
 }
 
 #define I8042_DATA_REG 0x60
 
-void __init chrp_request_regions(void) 
+void __init chrp_request_regions(void)
 {
+	struct device_node *i8042;
+
 	request_region(0x20,0x20,"pic1");
 	request_region(0xa0,0x20,"pic2");
 	request_region(0x00,0x20,"dma1");
@@ -118,8 +121,9 @@ void __init chrp_request_regions(void) 
 	 * tree and reserve the region if it does not appear. Later on
 	 * the i8042 code will try and reserve this region and fail.
 	 */
-	if (!find_type_devices("8042"))
+	if (!(i8042 = of_find_node_by_type(NULL, "8042")))
 		request_region(I8042_DATA_REG, 16, "reserved (no i8042)");
+	of_node_put(i8042);
 }
 
 void __init
@@ -158,7 +162,7 @@ chrp_setup_arch(void)
 #endif
 
 	/* Find the Open PIC if present */
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	opprop = (unsigned int *) get_property(root,
 				"platform-open-pic", NULL);
 	if (opprop != 0) {
@@ -170,6 +174,7 @@ chrp_setup_arch(void)
 		printk(KERN_DEBUG "OpenPIC addr: %lx\n", openpic);
 		OpenPIC_Addr = __ioremap(openpic, 0x40000, _PAGE_NO_CACHE);
 	}
+	of_node_put(root);
 
 #ifdef CONFIG_DUMMY_CONSOLE
 	conswitchp = &dummy_con;
@@ -229,6 +234,10 @@ void __init
 chrp_init(unsigned long r3, unsigned long r4, unsigned long r5,
 	  unsigned long r6, unsigned long r7)
 {
+	struct device_node * dn;
+	char * hypertas;
+	unsigned int len;
+
 #if 0 /* PPPBBB remove this later... -Peter */
 #ifdef CONFIG_BLK_DEV_INITRD
 	/* take care of initrd if we have one */
@@ -244,10 +253,12 @@ chrp_init(unsigned long r3, unsigned lon
 	ppc_md.setup_residual = NULL;
 	ppc_md.get_cpuinfo    = chrp_get_cpuinfo;
 	if(naca->interrupt_controller == IC_OPEN_PIC) {
-		ppc_md.init_IRQ       = openpic_init_IRQ; 
+		ppc_md.init_IRQ       = openpic_init_IRQ;
+		ppc_md.init_irq_desc  = openpic_init_irq_desc;
 		ppc_md.get_irq        = openpic_get_irq;
 	} else {
 		ppc_md.init_IRQ       = xics_init_IRQ;
+		ppc_md.init_irq_desc  = xics_init_irq_desc;
 		ppc_md.get_irq        = xics_get_irq;
 	}
 
@@ -262,36 +273,40 @@ chrp_init(unsigned long r3, unsigned lon
 	ppc_md.set_rtc_time   = pSeries_set_rtc_time;
 	ppc_md.calibrate_decr = pSeries_calibrate_decr;
 
-	ppc_md.progress = chrp_progress;
+	ppc_md.progress       = chrp_progress;
+
+	ppc_md.nvram_read     = pSeries_nvram_read;
+	ppc_md.nvram_write    = pSeries_nvram_write;
 
-        /* build up the firmware_features bitmask field
+        /* Build up the firmware_features bitmask field
          * using contents of device-tree/ibm,hypertas-functions.
          * Ultimately this functionality may be moved into prom.c prom_init().
          */
-	struct device_node * dn;
-	char * hypertas;
-	unsigned int len;
-	dn = find_path_device("/rtas");
+	dn = of_find_node_by_path("/rtas");
 	cur_cpu_spec->firmware_features = 0;
 	hypertas = get_property(dn, "ibm,hypertas-functions", &len);
 	if (hypertas) {
-	    while (len > 0){
-		int i;
-		/* check value against table of strings */
-		for(i=0; i < FIRMWARE_MAX_FEATURES ;i++) {
-		    if ((firmware_features_table[i].name) && (strcmp(firmware_features_table[i].name,hypertas))==0) {
-			/* we have a match */
-			cur_cpu_spec->firmware_features |= (1UL << firmware_features_table[i].val);
-			break;
-		    } 
+		while (len > 0){
+			int i, hypertas_len;
+			/* check value against table of strings */
+			for(i=0; i < FIRMWARE_MAX_FEATURES ;i++) {
+				if ((firmware_features_table[i].name) &&
+				    (strcmp(firmware_features_table[i].name,hypertas))==0) {
+					/* we have a match */
+					cur_cpu_spec->firmware_features |= 
+						(firmware_features_table[i].val);
+					break;
+				} 
+			}
+			hypertas_len = strlen(hypertas);
+			len -= hypertas_len +1;
+			hypertas+= hypertas_len +1;
 		}
-		int hypertas_len = strlen(hypertas);
-		len -= hypertas_len +1;
-		hypertas+= hypertas_len +1;
-	    }
 	}
-	udbg_printf("firmware_features bitmask: 0x%x \n",
-		    cur_cpu_spec->firmware_features);
+
+	of_node_put(dn);
+	printk(KERN_INFO "firmware_features = 0x%lx\n", 
+	       cur_cpu_spec->firmware_features);
 }
 
 void
@@ -319,6 +334,13 @@ chrp_progress(char *s, unsigned short he
 		display_character = rtas_token("display-character");
 		set_indicator = rtas_token("set-indicator");
 	}
+	if (display_character == RTAS_UNKNOWN_SERVICE) {
+		/* use hex display */
+		if (set_indicator == RTAS_UNKNOWN_SERVICE)
+			return;
+		rtas_call(set_indicator, 3, 1, NULL, 6, 0, hex);
+		return;
+	}
 
 	if(display_character == RTAS_UNKNOWN_SERVICE) {
 		/* use hex display if available */
@@ -405,11 +427,11 @@ void __init pSeries_calibrate_decr(void)
 
 	/*
 	 * The cpu node should have a timebase-frequency property
-	 * to tell us the rate at which the decrementer counts. 
+	 * to tell us the rate at which the decrementer counts.
 	 */
 	freq = 16666000;        /* hardcoded default */
-	cpu = find_type_devices("cpu");
-	if (cpu != 0) { 
+	cpu = of_find_node_by_type(NULL, "cpu");
+	if (cpu != 0) {
 		fp = (int *) get_property(cpu, "timebase-frequency", NULL);
 		if (fp != 0)
 			freq = *fp;
@@ -422,11 +444,12 @@ void __init pSeries_calibrate_decr(void)
 			processor_freq = *fp;
 	}
 	ppc_proc_freq = processor_freq;
-	
-        printk("time_init: decrementer frequency = %lu.%.6lu MHz\n", 
-	       freq/1000000, freq%1000000 );
+	of_node_put(cpu);
+
+	printk("time_init: decrementer frequency = %lu.%.6lu MHz\n",
+	       freq/1000000, freq%1000000);
 	printk("time_init: processor frequency   = %lu.%.6lu MHz\n",
-		processor_freq/1000000, processor_freq%1000000 );
+	       processor_freq/1000000, processor_freq%1000000);
 
 	tb_ticks_per_jiffy = freq / HZ;
 	tb_ticks_per_sec = tb_ticks_per_jiffy * HZ;
diff -purN linux-2.5/arch/ppc64/kernel/cputable.c linuxppc64-2.5/arch/ppc64/kernel/cputable.c
--- linux-2.5/arch/ppc64/kernel/cputable.c	2003-06-24 04:58:49.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/cputable.c	2003-10-28 18:47:22.000000000 +0000
@@ -30,8 +30,10 @@ extern void __setup_cpu_power4(unsigned 
  */
 #ifdef CONFIG_ALTIVEC
 #define CPU_FTR_ALTIVEC_COMP	CPU_FTR_ALTIVEC
+#define PPC_FEATURE_HAS_ALTIVEC_COMP PPC_FEATURE_HAS_ALTIVEC
 #else
 #define CPU_FTR_ALTIVEC_COMP	0
+#define PPC_FEATURE_HAS_ALTIVEC_COMP    0
 #endif
 
 struct cpu_spec	cpu_specs[] = {
@@ -107,6 +109,24 @@ struct cpu_spec	cpu_specs[] = {
 	    __setup_cpu_power4,
 	    COMMON_PPC64_FW
     },
+    {	/* PPC970 */
+	    0xffff0000, 0x00390000, "PPC970",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
+	    CPU_FTR_PPCAS_ARCH_V2 | CPU_FTR_ALTIVEC_COMP,
+	    COMMON_USER_PPC64 | PPC_FEATURE_HAS_ALTIVEC_COMP,
+	    128, 128,
+	    __setup_cpu_power4,
+	    COMMON_PPC64_FW
+    },
+    {	/* Power5 */
+	    0xffff0000, 0x003a0000, "Power5",
+	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
+	    CPU_FTR_PPCAS_ARCH_V2,
+	    COMMON_USER_PPC64,
+	    128, 128,
+	    __setup_cpu_power4,
+	    COMMON_PPC64_FW
+    },
     {	/* default match */
 	    0x00000000, 0x00000000, "(Power4-Compatible)",
   	    CPU_FTR_SPLIT_ID_CACHE | CPU_FTR_USE_TB | CPU_FTR_HPTE_TABLE |
@@ -130,4 +150,13 @@ firmware_feature_t firmware_features_tab
     {FW_FEATURE_DUMP,		"hcall-dump"},
     {FW_FEATURE_INTERRUPT,	"hcall-interrupt"},
     {FW_FEATURE_MIGRATE,	"hcall-migrate"},
+    {FW_FEATURE_PERFMON,	"hcall-perfmon"},
+    {FW_FEATURE_CRQ,    	"hcall-crq"},
+    {FW_FEATURE_VIO,	        "hcall-vio"},
+    {FW_FEATURE_RDMA,	        "hcall-rdma"},
+    {FW_FEATURE_LLAN,	        "hcall-lLAN"},
+    {FW_FEATURE_BULK,   	"hcall-bulk"},
+    {FW_FEATURE_XDABR,  	"hcall-xdabr"},
+    {FW_FEATURE_MULTITCE,	"hcall-multi-tce"},
+    {FW_FEATURE_SPLPAR,	        "hcall-splpar"},
 };
diff -purN linux-2.5/arch/ppc64/kernel/eeh.c linuxppc64-2.5/arch/ppc64/kernel/eeh.c
--- linux-2.5/arch/ppc64/kernel/eeh.c	2003-08-17 19:52:50.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/eeh.c	2003-09-25 07:00:39.000000000 +0000
@@ -257,7 +257,7 @@ void eeh_init(void)
 
 	/* Enable EEH for all adapters.  Note that eeh requires buid's */
 	info.adapters_enabled = 0;
-	for (phb = find_devices("pci"); phb; phb = phb->next) {
+	for (phb = of_find_node_by_name(NULL, "pci"); phb; phb = of_find_node_by_name(phb, "pci")) {
 		int len;
 		int *buid_vals = (int *) get_property(phb, "ibm,fw-phb-id", &len);
 		if (!buid_vals)
diff -purN linux-2.5/arch/ppc64/kernel/entry.S linuxppc64-2.5/arch/ppc64/kernel/entry.S
--- linux-2.5/arch/ppc64/kernel/entry.S	2003-06-26 00:01:14.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/entry.S	2003-11-21 06:45:02.000000000 +0000
@@ -275,15 +275,6 @@ _GLOBAL(_switch)
 	addi	r6,r4,-THREAD	/* Convert THREAD to 'current' */
 	std	r6,PACACURRENT(r13)	/* Set new 'current' */
 
-#ifdef CONFIG_PPC_ISERIES
-#error fixme
-	ld	r7,TI_FLAGS(r4)	/* Get run light flag */
-	mfspr	r9,CTRLF
-	srdi	r7,r7,1		/* Align to run light bit in CTRL reg */
-	insrdi	r9,r7,1,63	/* Insert run light into CTRL */
-	mtspr	CTRLT,r9
-#endif
-
 	ld	r1,KSP(r4)	/* Load new stack pointer */
 	ld	r6,_CCR(r1)
 	mtcrf	0xFF,r6
@@ -291,6 +282,15 @@ _GLOBAL(_switch)
 	REST_8GPRS(14, r1)
 	REST_10GPRS(22, r1)
 
+#ifdef CONFIG_PPC_ISERIES
+	clrrdi	r7,r1,THREAD_SHIFT	/* get current_thread_info() */
+	ld	r7,TI_FLAGS(r7)		/* Get run light flag */
+	mfspr	r9,CTRLF
+	srdi	r7,r7,TIF_RUN_LIGHT
+	insrdi	r9,r7,1,63		/* Insert run light into CTRL */
+	mtspr	CTRLT,r9
+#endif
+
 	/* convert old thread to its task_struct for return value */
 	addi	r3,r3,-THREAD
 	ld	r7,_NIP(r1)	/* Return to _switch caller in new task */
@@ -308,39 +308,16 @@ _GLOBAL(ret_from_fork)
 	b	.ret_from_except
 
 _GLOBAL(ret_from_except)
-#ifdef CONFIG_PPC_ISERIES
-	ld	r5,SOFTE(r1)
-	cmpdi	0,r5,0
-	beq	4f
-irq_recheck:
-	/* Check for pending interrupts (iSeries) */
-	CHECKANYINT(r3,r4)
-	beq+	4f	/* skip do_IRQ if no interrupts */
-
-#warning FIX ISERIES
-	mfspr	r5,SPRG3
-	li	r3,0
-	stb	r3,PACAPROCENABLED(r5)	/* ensure we are disabled */
-	addi	r3,r1,STACK_FRAME_OVERHEAD
-	bl	.do_IRQ
-	b	irq_recheck	/* loop back and handle more */
-4:
-#endif
 	/*
 	 * Disable interrupts so that current_thread_info()->flags
 	 * can't change between when we test it and when we return
 	 * from the interrupt.
 	 */
-recheck:
 	mfmsr	r10		/* Get current interrupt state */
 	li	r4,0
 	ori	r4,r4,MSR_EE
-	andc	r10,r10,r4	/* clear MSR_EE */
-	mtmsrd	r10,1		/* Update machine state */
-
-#ifdef CONFIG_PPC_ISERIES
-#error fix iSeries soft disable
-#endif
+	andc	r9,r10,r4	/* clear MSR_EE */
+	mtmsrd	r9,1		/* Update machine state */
 
 	ld	r3,_MSR(r1)	/* Returning to user mode? */
 	andi.	r3,r3,MSR_PR
@@ -364,6 +341,28 @@ recheck:
 	REST_GPR(13,r1)
 
 restore:
+#ifdef CONFIG_PPC_ISERIES
+	ld	r5,SOFTE(r1)
+	mfspr	r4,SPRG3		/* get paca address */
+	cmpdi	0,r5,0
+	beq	4f
+	/* Check for pending interrupts (iSeries) */
+	/* this is CHECKANYINT except that we already have the paca address */
+	ld	r3,PACALPPACA+LPPACAANYINT(r4)
+	cmpdi	r3,0
+	beq+	4f			/* skip do_IRQ if no interrupts */
+
+	mfspr	r13,SPRG3		/* get paca pointer back */
+	li	r3,0
+	stb	r3,PACAPROCENABLED(r13)	/* ensure we are soft-disabled */
+	mtmsrd	r10			/* hard-enable again */
+	addi	r3,r1,STACK_FRAME_OVERHEAD
+	bl	.do_IRQ
+	b	.ret_from_except		/* loop back and handle more */
+
+4:	stb	r5,PACAPROCENABLED(r4)
+#endif
+
 	ld	r3,_CTR(r1)
 	ld	r0,_LINK(r1)
 	mtctr	r3
@@ -377,12 +376,6 @@ restore:
 
 	stdcx.	r0,0,r1		/* to clear the reservation */
 
-#ifdef DO_SOFT_DISABLE
-	/* XXX do this in do_work, r13 isnt valid here */
-	ld	r0,SOFTE(r1)
-	stb	r0,PACAPROCENABLED(r13)
-#endif
-
 	mfmsr	r0
 	li	r2, MSR_RI
 	andc	r0,r0,r2
@@ -407,21 +400,21 @@ restore:
 /* Note: this must change if we start using the  TIF_NOTIFY_RESUME bit */
 do_work:
 	/* Enable interrupts */
-	ori	r10,r10,MSR_EE
 	mtmsrd	r10,1
 
 	andi.	r0,r3,_TIF_NEED_RESCHED
 	beq	1f
 	bl	.schedule
-	b	recheck
+	b	.ret_from_except
 
 1:	andi.	r0,r3,_TIF_SIGPENDING
-	beq	recheck
+	beq	.ret_from_except
 	li	r3,0
 	addi	r4,r1,STACK_FRAME_OVERHEAD
 	bl	.do_signal
-	b	recheck
+	b	.ret_from_except
 
+#ifdef CONFIG_PPC_PSERIES
 /*
  * On CHRP, the Run-Time Abstraction Services (RTAS) have to be
  * called with the MMU off.
@@ -498,6 +491,12 @@ _STATIC(rtas_return_loc)
 	mfspr	r4,SPRG3	        /* Get PACA */
 	SET_REG_TO_CONST(r5, KERNELBASE)
         sub     r4,r4,r5                /* RELOC the PACA base pointer */
+
+	mfmsr   r6
+	li	r0,MSR_RI
+	andc	r6,r6,r0
+	sync	
+	mtmsrd  r6
         
         ld	r1,PACAR1(r4)           /* Restore our SP */
 	LOADADDR(r3,.rtas_restore_regs)
@@ -626,3 +625,4 @@ _GLOBAL(enter_prom)
 
 	mtlr    r0
         blr				/* return to caller */
+#endif	/* defined(CONFIG_PPC_PSERIES) */
diff -purN linux-2.5/arch/ppc64/kernel/head.S linuxppc64-2.5/arch/ppc64/kernel/head.S
--- linux-2.5/arch/ppc64/kernel/head.S	2003-10-01 22:41:11.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/head.S	2003-11-21 07:20:34.000000000 +0000
@@ -52,7 +52,7 @@
 /*
  * hcall interface to pSeries LPAR
  */
-#define HSC .long 0x44000022
+#define HVSC .long 0x44000022
 #define H_SET_ASR		0x30
 
 /*
@@ -91,20 +91,26 @@
 	.text
 	.globl  _stext
 _stext:
+#ifdef CONFIG_PPC_PSERIES
 _STATIC(__start)
 	b .__start_initialization_pSeries
+#endif
 #ifdef CONFIG_PPC_ISERIES
-	/* At offset 0x20, there is a pointer to iSeries LPAR data.
-	 * This is required by the hypervisor */
+	/*
+	 * At offset 0x20, there is a pointer to iSeries LPAR data.
+	 * This is required by the hypervisor
+	 */
 	. = 0x20
 	.llong hvReleaseData-KERNELBASE
 
-	/* At offset 0x28 and 0x30 are offsets to the msChunks
+	/*
+	 * At offset 0x28 and 0x30 are offsets to the msChunks
 	 * array (used by the iSeries LPAR debugger to do translation
 	 * between physical addresses and absolute addresses) and
-	 * to the pidhash table (also used by the debugger) */
+	 * to the pidhash table (also used by the debugger)
+	 */
 	.llong msChunks-KERNELBASE
-	.llong pidhash-KERNELBASE
+	.llong 0 /* pidhash-KERNELBASE SFRXXX */
 
 	/* Offset 0x38 - Pointer to start of embedded System.map */
 	.globl	embedded_sysmap_start
@@ -114,7 +120,7 @@ embedded_sysmap_start:
 	.globl	embedded_sysmap_end
 embedded_sysmap_end:
 	.llong	0
-#endif
+#else
 
 	/* Secondary processors spin on this value until it goes to 1. */
 	.globl  __secondary_hold_spinloop
@@ -147,6 +153,7 @@ _GLOBAL(__secondary_hold)
 	/* Relocation is off & we are located at an address less */
 	/* than 0x100, so only need to grab low order offset.    */
 	std     r24,__secondary_hold_acknowledge@l(0)
+	sync
 
 	/* All secondary cpu's wait here until told to start. */
 100:    ld      r4,__secondary_hold_spinloop@l(0)
@@ -163,6 +170,7 @@ _GLOBAL(__secondary_hold)
 	BUG_OPCODE
 #endif
 #endif
+#endif
 
 /*
  * The following macros define the code that appears as
@@ -244,6 +252,14 @@ _GLOBAL(__secondary_hold)
 	std	r22,EX_SRR0(r21);	    /* save SRR0 in exc. frame     */ \
 	ld      r23,LPPACA+LPPACASRR1(r20); /* Get SRR1 from ItLpPaca      */ \
 	std	r23,EX_SRR1(r21);	    /* save SRR1 in exc. frame     */ \
+                                                                         \
+	mfspr   r23,DAR;                /* Save DAR in exc. frame      */ \
+	std	r23,EX_DAR(r21);	                                  \
+	mfspr	r23,DSISR;		/* Save DSISR in exc. frame    */ \
+	stw	r23,EX_DSISR(r21);	                                  \
+	mfspr	r23,SPRG2;		/* Save r20 in exc. frame      */ \
+	std	r23,EX_R20(r21);	                                  \
+                                                                         \
 	mfcr    r23;                        /* save CR in r23              */
 
 /*
@@ -1113,7 +1129,6 @@ _GLOBAL(save_remaining_regs)
 	SET_REG_TO_CONST(r22, MSR_KERNEL)
 
 #ifdef DO_SOFT_DISABLE
-#warning FIX ISERIES
 	stb	r20,PACAPROCENABLED(r13) /* possibly soft enable */
 	ori	r22,r22,MSR_EE		/* always hard enable */
 #else
@@ -1219,6 +1234,7 @@ _GLOBAL(__start_initialization_iSeries)
 	b	.start_here_common
 #endif
 
+#ifdef CONFIG_PPC_PSERIES
 _GLOBAL(__start_initialization_pSeries)
 	mr	r31,r3			/* save parameters */
 	mr	r30,r4
@@ -1328,6 +1344,7 @@ _STATIC(__after_prom_start)
 	sub	r5,r5,r27
 	bl	.copy_and_flush		/* copy the rest */
 	b	.start_here_pSeries
+#endif
 
 /*
  * Copy routine used to copy the kernel to start at physical address 0
@@ -1535,7 +1552,7 @@ _GLOBAL(__secondary_start)
 	cmpwi	r3,0x34         /* Pulsar */
 	bne	98f
 97:	li	r3,H_SET_ASR    /* hcall = H_SET_ASR */
-	HSC     		/* Invoking hcall */
+	HVSC     		/* Invoking hcall */
 	b	99f
 98:                             /* !(rpa hypervisor) || !(star)  */
 	mtasr	r4	        /* set the stab location         */
@@ -1594,6 +1611,7 @@ _GLOBAL(enable_32b_mode)
 	isync
 	blr
 
+#ifdef CONFIG_PPC_PSERIES
 /*
  * This is where the main kernel code starts.
  */
@@ -1703,7 +1721,7 @@ _STATIC(start_here_pSeries)
 	cmpwi	r3,0x34         /* Pulsar */
 	bne	98f
 97:	li	r3,H_SET_ASR    /* hcall = H_SET_ASR */
-	HSC     	        /* Invoking hcall */
+	HVSC     	        /* Invoking hcall */
 	b     	99f
 98:                             /* !(rpa hypervisor) || !(star) */
 	mtasr	r4	        /* set the stab location         */
@@ -1729,6 +1747,7 @@ _STATIC(start_here_pSeries)
 	mtspr	SRR0,r3
 	mtspr	SRR1,r4
 	rfid
+#endif	/* CONFIG_PPC_PSERIES */
 
 	/* This is where all platforms converge execution */
 _STATIC(start_here_common)
@@ -1803,10 +1822,8 @@ _STATIC(start_here_common)
 	/* Load up the kernel context */
 5:
 #ifdef DO_SOFT_DISABLE
-#warning FIX ISERIES
-	mfspr	r4,SPRG3
 	li	r5,0
-	stb	r5,PACAPROCENABLED(r4)	/* Soft Disabled */
+	stb	r5,PACAPROCENABLED(r13)	/* Soft Disabled */
 	mfmsr	r5
 	ori	r5,r5,MSR_EE		/* Hard Enabled */
 	mtmsrd	r5
diff -purN linux-2.5/arch/ppc64/kernel/htab.c linuxppc64-2.5/arch/ppc64/kernel/htab.c
--- linux-2.5/arch/ppc64/kernel/htab.c	2003-09-07 01:24:09.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/htab.c	2003-11-21 06:45:02.000000000 +0000
@@ -75,6 +75,7 @@ loop_forever(void)
 		;
 }
 
+#ifdef CONFIG_PPC_PSERIES
 static inline void
 create_pte_mapping(unsigned long start, unsigned long end,
 		   unsigned long mode, int large)
@@ -181,6 +182,7 @@ htab_initialize(void)
 }
 #undef KB
 #undef MB
+#endif
 
 /*
  * find_linux_pte returns the address of a linux pte for a given 
diff -purN linux-2.5/arch/ppc64/kernel/i8259.c linuxppc64-2.5/arch/ppc64/kernel/i8259.c
--- linux-2.5/arch/ppc64/kernel/i8259.c	2003-02-11 11:51:44.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/i8259.c	2003-09-12 19:50:39.000000000 +0000
@@ -124,8 +124,8 @@ static void i8259_unmask_irq(unsigned in
 
 static void i8259_end_irq(unsigned int irq)
 {
-	if (!(irq_desc[irq].status & (IRQ_DISABLED|IRQ_INPROGRESS)) &&
-	    irq_desc[irq].action)
+	if (!(get_irq_desc(irq)->status & (IRQ_DISABLED|IRQ_INPROGRESS)) &&
+	    get_irq_desc(irq)->action)
 		i8259_unmask_irq(irq);
 }
 
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_IoMmTable.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_IoMmTable.c
--- linux-2.5/arch/ppc64/kernel/iSeries_IoMmTable.c	2002-08-28 07:54:04.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_IoMmTable.c	2003-11-21 06:45:02.000000000 +0000
@@ -1,3 +1,4 @@
+#define PCIFR(...)
 /************************************************************************/
 /* This module supports the iSeries I/O Address translation mapping     */
 /* Copyright (C) 20yy  <Allan H Trautman> <IBM Corp>                    */
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_htab.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_htab.c
--- linux-2.5/arch/ppc64/kernel/iSeries_htab.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_htab.c	2003-11-21 05:35:46.000000000 +0000
@@ -0,0 +1,197 @@
+/*
+ * iSeries hashtable management.
+ * 	Derived from pSeries_htab.c
+ *
+ * SMP scalability work:
+ *    Copyright (C) 2001 Anton Blanchard <anton@au.ibm.com>, IBM
+ * 
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+#include <asm/machdep.h>
+#include <asm/pgtable.h>
+#include <asm/mmu.h>
+#include <asm/mmu_context.h>
+#include <asm/iSeries/HvCallHpt.h>
+#include <asm/abs_addr.h>
+
+#if 0
+#include <linux/spinlock.h>
+#include <linux/bitops.h>
+#include <linux/threads.h>
+#include <linux/smp.h>
+
+#include <asm/tlbflush.h>
+#include <asm/tlb.h>
+#include <asm/cputable.h>
+#endif
+
+static long iSeries_hpte_insert(unsigned long hpte_group, unsigned long va,
+			 unsigned long prpn, int secondary,
+			 unsigned long hpteflags, int bolted, int large)
+{
+	long slot;
+	HPTE lhpte;
+
+	/*
+	 * The hypervisor tries both primary and secondary.
+	 * If we are being called to insert in the secondary,
+	 * it means we have already tried both primary and secondary,
+	 * so we return failure immediately.
+	 */
+	if (secondary)
+		return -1;
+
+	slot = HvCallHpt_findValid(&lhpte, va >> PAGE_SHIFT);
+	if (lhpte.dw0.dw0.v)
+		panic("select_hpte_slot found entry already valid\n");
+
+	if (slot == -1)	/* No available entry found in either group */
+		return -1;
+
+	if (slot < 0) {		/* MSB set means secondary group */
+		secondary = 1;
+		slot &= 0x7fffffffffffffff;
+	}
+
+	lhpte.dw1.dword1      = 0;
+	lhpte.dw1.dw1.rpn     = physRpn_to_absRpn(prpn);
+	lhpte.dw1.flags.flags = hpteflags;
+
+	lhpte.dw0.dword0      = 0;
+	lhpte.dw0.dw0.avpn    = va >> 23;
+	lhpte.dw0.dw0.h       = secondary;
+	lhpte.dw0.dw0.bolted  = bolted;
+	lhpte.dw0.dw0.v       = 1;
+
+	/* Now fill in the actual HPTE */
+	HvCallHpt_addValidate(slot, secondary, &lhpte);
+
+	return (secondary << 3) | (slot & 7);
+}
+
+static unsigned long iSeries_hpte_getword0(unsigned long slot)
+{
+	unsigned long dword0;
+	HPTE hpte;
+
+	HvCallHpt_get(&hpte, slot);
+	dword0 = hpte.dw0.dword0;
+
+	return dword0;
+}
+
+static long iSeries_hpte_remove(unsigned long hpte_group)
+{
+	unsigned long slot_offset;
+	int i;
+	HPTE lhpte;
+
+	/* Pick a random slot to start at */
+	slot_offset = mftb() & 0x7;
+
+	for (i = 0; i < HPTES_PER_GROUP; i++) {
+		lhpte.dw0.dword0 = 
+			iSeries_hpte_getword0(hpte_group + slot_offset);
+
+		if (!lhpte.dw0.dw0.bolted) {
+			HvCallHpt_invalidateSetSwBitsGet(hpte_group + 
+							 slot_offset, 0, 0);
+			return i;
+		}
+
+		slot_offset++;
+		slot_offset &= 0x7;
+	}
+
+	return -1;
+}
+
+static long iSeries_hpte_updatepp(unsigned long slot, unsigned long newpp,
+				  unsigned long va, int large, int local)
+{
+	HPTE hpte;
+	unsigned long avpn = va >> 23;
+
+	HvCallHpt_get(&hpte, slot);
+	if ((hpte.dw0.dw0.avpn == avpn) && (hpte.dw0.dw0.v)) {
+		HvCallHpt_setPp(slot, newpp);
+		return 0;
+	}
+	return -1;
+}
+
+/*
+ * Functions used to find the PTE for a particular virtual address. 
+ * Only used during boot when bolting pages.
+ *
+ * Input : vpn      : virtual page number
+ * Output: PTE index within the page table of the entry
+ *         -1 on failure
+ */
+static long iSeries_hpte_find(unsigned long vpn)
+{
+	HPTE hpte;
+	long slot;
+
+	/*
+	 * The HvCallHpt_findValid interface is as follows:
+	 * 0xffffffffffffffff : No entry found.
+	 * 0x00000000xxxxxxxx : Entry found in primary group, slot x
+	 * 0x80000000xxxxxxxx : Entry found in secondary group, slot x
+	 */
+	slot = HvCallHpt_findValid(&hpte, vpn); 
+	if (hpte.dw0.dw0.v) {
+		if (slot < 0) {
+			slot &= 0x7fffffffffffffff;
+			slot = -slot;
+		}
+	} else
+		slot = -1;
+	return slot;
+}
+
+/*
+ * Update the page protection bits. Intended to be used to create
+ * guard pages for kernel data structures on pages which are bolted
+ * in the HPT. Assumes pages being operated on will not be stolen.
+ * Does not work on large pages.
+ *
+ * No need to lock here because we should be the only user.
+ */
+static void iSeries_hpte_updateboltedpp(unsigned long newpp, unsigned long ea)
+{
+	unsigned long vsid,va,vpn;
+	long slot;
+
+	vsid = get_kernel_vsid(ea);
+	va = (vsid << 28) | (ea & 0x0fffffff);
+	vpn = va >> PAGE_SHIFT;
+	slot = iSeries_hpte_find(vpn); 
+	if (slot == -1)
+		panic("updateboltedpp: Could not find page to bolt\n");
+	HvCallHpt_setPp(slot, newpp);
+}
+
+static void iSeries_hpte_invalidate(unsigned long slot, unsigned long va,
+				    int large, int local)
+{
+	HPTE lhpte;
+	unsigned long avpn = va >> 23;
+
+	lhpte.dw0.dword0 = iSeries_hpte_getword0(slot);
+	
+	if ((lhpte.dw0.dw0.avpn == avpn) && lhpte.dw0.dw0.v)
+		HvCallHpt_invalidateSetSwBitsGet(slot, 0, 0);
+}
+
+void hpte_init_iSeries(void)
+{
+	ppc_md.hpte_invalidate	= iSeries_hpte_invalidate;
+	ppc_md.hpte_updatepp	= iSeries_hpte_updatepp;
+	ppc_md.hpte_updateboltedpp = iSeries_hpte_updateboltedpp;
+	ppc_md.hpte_insert	= iSeries_hpte_insert;
+	ppc_md.hpte_remove     	= iSeries_hpte_remove;
+}
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_irq.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_irq.c
--- linux-2.5/arch/ppc64/kernel/iSeries_irq.c	2003-05-02 17:21:54.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_irq.c	2003-11-21 06:45:02.000000000 +0000
@@ -40,19 +40,21 @@
 #include <asm/iSeries/iSeries_irq.h>
 #include <asm/iSeries/XmPciLpEvent.h>
 
-
-hw_irq_controller iSeries_IRQ_handler = {
-	"iSeries irq controller",
-	iSeries_startup_IRQ,	/* startup */
-	iSeries_shutdown_IRQ,	/* shutdown */
-	iSeries_enable_IRQ,	/* enable */
-	iSeries_disable_IRQ,	/* disable */
-	NULL,			/* ack  */
-	iSeries_end_IRQ,	/* end  */
-	NULL			/* set_affinity */
+static unsigned int iSeries_startup_IRQ(unsigned int irq);
+static void iSeries_shutdown_IRQ(unsigned int irq);
+static void iSeries_enable_IRQ(unsigned int irq);
+static void iSeries_disable_IRQ(unsigned int irq);
+static void iSeries_end_IRQ(unsigned int irq);
+
+static hw_irq_controller iSeries_IRQ_handler = {
+	.typename = "iSeries irq controller",
+	.startup = iSeries_startup_IRQ,
+	.shutdown = iSeries_shutdown_IRQ,
+	.enable = iSeries_enable_IRQ,
+	.disable = iSeries_disable_IRQ,
+	.end = iSeries_end_IRQ
 };
 
-
 struct iSeries_irqEntry {
 	u32 dsa;
 	struct iSeries_irqEntry* next;
@@ -65,73 +67,97 @@ struct iSeries_irqAnchor {
 	struct iSeries_irqEntry* head;
 };
 
-struct iSeries_irqAnchor iSeries_irqMap[NR_IRQS];
+static struct iSeries_irqAnchor iSeries_irqMap[NR_IRQS];
 
-void iSeries_init_irqMap(int irq);
+#if 0
+static void iSeries_init_irqMap(int irq);
+#endif
 
-/*  This is called by init_IRQ.  set in ppc_md.init_IRQ by iSeries_setup.c */
+void iSeries_init_irq_desc(irq_desc_t *desc)
+{
+	desc->handler = &iSeries_IRQ_handler;
+}
+
+/* This is called by init_IRQ.  set in ppc_md.init_IRQ by iSeries_setup.c */
 void __init iSeries_init_IRQ(void)
 {
+#if 0
 	int i;
+	irq_desc_t *desc;
+
 	for (i = 0; i < NR_IRQS; i++) {
-		irq_desc[i].handler = &iSeries_IRQ_handler;
-		irq_desc[i].status = 0;
-		irq_desc[i].status |= IRQ_DISABLED;
-		irq_desc[i].depth = 1;
+		desc = get_irq_desc(i);
+		desc->handler = &iSeries_IRQ_handler;
+		desc->status = 0;
+		desc->status |= IRQ_DISABLED;
+		desc->depth = 1;
 		iSeries_init_irqMap(i);
 	}
+#endif
 	/* Register PCI event handler and open an event path */
-	PPCDBG(PPCDBG_BUSWALK,"Register PCI event handler and open an event path\n");
+	PPCDBG(PPCDBG_BUSWALK,
+			"Register PCI event handler and open an event path\n");
 	XmPciLpEvent_init();
 	return;
 }
 
-/**********************************************************************
+#if 0
+/*
  *  Called by iSeries_init_IRQ 
  * Prevent IRQs 0 and 255 from being used.  IRQ 0 appears in
  * uninitialized devices.  IRQ 255 appears in the PCI interrupt
  * line register if a PCI error occurs,
- *********************************************************************/
-void __init iSeries_init_irqMap(int irq)
+ */
+static void __init iSeries_init_irqMap(int irq)
 {
-	iSeries_irqMap[irq].valid = (irq == 0 || irq == 255)? 0 : 1;
+	iSeries_irqMap[irq].valid = ((irq == 0) || (irq == 255)) ? 0 : 1;
 	iSeries_irqMap[irq].entryCount = 0;
 	iSeries_irqMap[irq].head = NULL;
 }
+#endif
 
-/* This is called out of iSeries_scan_slot to allocate an IRQ for an EADS slot */
-/* It calculates the irq value for the slot.                                   */
-int __init iSeries_allocate_IRQ(HvBusNumber busNumber, HvSubBusNumber subBusNumber, HvAgentId deviceId)
+/*
+ * This is called out of iSeries_scan_slot to allocate an IRQ for an EADS slot
+ * It calculates the irq value for the slot.
+ */
+int __init iSeries_allocate_IRQ(HvBusNumber busNumber,
+		HvSubBusNumber subBusNumber, HvAgentId deviceId)
 {
 	u8 idsel = (deviceId >> 4);
 	u8 function = deviceId & 0x0F;
-	int irq = ((((busNumber-1)*16 + (idsel-1)*8 + function)*9/8) % 253) + 2;
-	return irq;
+
+	return ((((busNumber - 1) * 16 + (idsel - 1) * 8
+					+ function) * 9 / 8) % 253) + 2;
 }
 
-/* This is called out of iSeries_scan_slot to assign the EADS slot to its IRQ number */
-int __init iSeries_assign_IRQ(int irq, HvBusNumber busNumber, HvSubBusNumber subBusNumber, HvAgentId deviceId)
+/*
+ * This is called out of iSeries_scan_slot to assign the EADS slot
+ * to its IRQ number
+ */
+int __init iSeries_assign_IRQ(int irq, HvBusNumber busNumber,
+		HvSubBusNumber subBusNumber, HvAgentId deviceId)
 {
 	int rc;
 	u32 dsa = (busNumber << 16) | (subBusNumber << 8) | deviceId;
-	struct iSeries_irqEntry* newEntry;
+	struct iSeries_irqEntry *newEntry;
 	unsigned long flags;
+	irq_desc_t *desc = get_irq_desc(irq);
 
-	if (irq < 0 || irq >= NR_IRQS) {
+	if ((irq < 0) || (irq >= NR_IRQS))
 		return -1;
-	}
+
 	newEntry = kmalloc(sizeof(*newEntry), GFP_KERNEL);
-	if (newEntry == NULL) {
+	if (newEntry == NULL)
 		return -ENOMEM;
-	}
+
 	newEntry->dsa  = dsa;
 	newEntry->next = NULL;
-	/********************************************************************
-	* Probably not necessary to lock the irq since allocation is only 
-	* done during buswalk, but it should not hurt anything except a 
-	* little performance to be smp safe.
-	*******************************************************************/
-	spin_lock_irqsave(&irq_desc[irq].lock, flags);
+	/*
+	 * Probably not necessary to lock the irq since allocation is only 
+	 * done during buswalk, but it should not hurt anything except a 
+	 * little performance to be smp safe.
+	 */
+	spin_lock_irqsave(&desc->lock, flags);
 
 	if (iSeries_irqMap[irq].valid) {
 		/* Push the new element onto the irq stack */
@@ -139,26 +165,28 @@ int __init iSeries_assign_IRQ(int irq, H
 		iSeries_irqMap[irq].head = newEntry;
 		++iSeries_irqMap[irq].entryCount;
 		rc = 0;
-		PPCDBG(PPCDBG_BUSWALK,"iSeries_assign_IRQ   0x%04X.%02X.%02X = 0x%04X\n",busNumber, subBusNumber, deviceId, irq);
-	}
-	else {
-		printk("PCI: Something is wrong with the iSeries_irqMap. \n");
+		PPCDBG(PPCDBG_BUSWALK, "iSeries_assign_IRQ   0x%04X.%02X.%02X = 0x%04X\n",
+				busNumber, subBusNumber, deviceId, irq);
+	} else {
+		printk("PCI: Something is wrong with the iSeries_irqMap.\n");
 		kfree(newEntry);
 		rc = -1;
-    }
-	spin_unlock_irqrestore(&irq_desc[irq].lock, flags);
+	}
+	spin_unlock_irqrestore(&desc->lock, flags);
 	return rc;
 }
 
 
 /* This is called by iSeries_activate_IRQs */
-unsigned int iSeries_startup_IRQ(unsigned int irq)
+static unsigned int iSeries_startup_IRQ(unsigned int irq)
 {
-	struct iSeries_irqEntry* entry;
+	struct iSeries_irqEntry *entry;
 	u32 bus, subBus, deviceId, function, mask;
-	for(entry=iSeries_irqMap[irq].head; entry!=NULL; entry=entry->next) {
-		bus      = (entry->dsa >> 16) & 0xFFFF;
-		subBus   = (entry->dsa >> 8) & 0xFF;
+
+	for (entry = iSeries_irqMap[irq].head; entry != NULL;
+			entry = entry->next) {
+		bus = (entry->dsa >> 16) & 0xFFFF;
+		subBus = (entry->dsa >> 8) & 0xFF;
 		deviceId = entry->dsa & 0xFF;
 		function = deviceId & 0x0F;
 		/* Link the IRQ number to the bridge */
@@ -166,32 +194,41 @@ unsigned int iSeries_startup_IRQ(unsigne
         	/* Unmask bridge interrupts in the FISR */
 		mask = 0x01010000 << function;
 		HvCallPci_unmaskFisr(bus, subBus, deviceId, mask);
-		PPCDBG(PPCDBG_BUSWALK,"iSeries_activate_IRQ 0x%02X.%02X.%02X  Irq:0x%02X\n",bus,subBus,deviceId,irq);
+		PPCDBG(PPCDBG_BUSWALK, "iSeries_activate_IRQ 0x%02X.%02X.%02X  Irq:0x%02X\n",
+				bus, subBus, deviceId, irq);
 	}
 	return 0;
 }
 
-/* This is called out of iSeries_fixup to activate interrupt
- * generation for usable slots                              */
+/*
+ * This is called out of iSeries_fixup to activate interrupt
+ * generation for usable slots
+ */
 void __init iSeries_activate_IRQs()
 {
 	int irq;
 	unsigned long flags;
-	for (irq=0; irq < NR_IRQS; irq++) {
-		spin_lock_irqsave(&irq_desc[irq].lock, flags);
-		irq_desc[irq].handler->startup(irq);
-		spin_unlock_irqrestore(&irq_desc[irq].lock, flags);
+
+	for (irq = 0; irq < NR_IRQS; irq++) {
+		irq_desc_t *desc = get_irq_desc(irq);
+
+		if (desc && desc->handler && desc->handler->startup) {
+			spin_lock_irqsave(&desc->lock, flags);
+			desc->handler->startup(irq);
+			spin_unlock_irqrestore(&desc->lock, flags);
+		}
     	}
 }
 
 /*  this is not called anywhere currently */
-void iSeries_shutdown_IRQ(unsigned int irq) {
-	struct iSeries_irqEntry* entry;
+static void iSeries_shutdown_IRQ(unsigned int irq)
+{
+	struct iSeries_irqEntry *entry;
 	u32 bus, subBus, deviceId, function, mask;
 
 	/* irq should be locked by the caller */
 
-	for (entry=iSeries_irqMap[irq].head; entry; entry=entry->next) {
+	for (entry = iSeries_irqMap[irq].head; entry; entry = entry->next) {
 		bus = (entry->dsa >> 16) & 0xFFFF;
 		subBus = (entry->dsa >> 8) & 0xFF;
 		deviceId = entry->dsa & 0xFF;
@@ -202,57 +239,60 @@ void iSeries_shutdown_IRQ(unsigned int i
 		mask = 0x01010000 << function;
 		HvCallPci_maskFisr(bus, subBus, deviceId, mask);
 	}
-
 }
 
-/***********************************************************
+/*
  * This will be called by device drivers (via disable_IRQ)
  * to disable INTA in the bridge interrupt status register.
- ***********************************************************/
-void iSeries_disable_IRQ(unsigned int irq)
+ */
+static void iSeries_disable_IRQ(unsigned int irq)
 {
-	struct iSeries_irqEntry* entry;
+	struct iSeries_irqEntry *entry;
 	u32 bus, subBus, deviceId, mask;
 
 	/* The IRQ has already been locked by the caller */
-
-	for (entry=iSeries_irqMap[irq].head; entry; entry=entry->next) {
-		bus      = (entry->dsa >> 16) & 0xFFFF;
-		subBus   = (entry->dsa >> 8) & 0xFF;
+	for (entry = iSeries_irqMap[irq].head; entry; entry = entry->next) {
+		bus = (entry->dsa >> 16) & 0xFFFF;
+		subBus = (entry->dsa >> 8) & 0xFF;
 		deviceId = entry->dsa & 0xFF;
 		/* Mask secondary INTA   */
 		mask = 0x80000000;
 		HvCallPci_maskInterrupts(bus, subBus, deviceId, mask);
-		PPCDBG(PPCDBG_BUSWALK,"iSeries_disable_IRQ 0x%02X.%02X.%02X 0x%04X\n",bus,subBus,deviceId,irq);
+		PPCDBG(PPCDBG_BUSWALK,
+				"iSeries_disable_IRQ 0x%02X.%02X.%02X 0x%04X\n",
+				bus, subBus, deviceId, irq);
     	}
 }
 
-/***********************************************************
+/*
  * This will be called by device drivers (via enable_IRQ)
  * to enable INTA in the bridge interrupt status register.
- ***********************************************************/
-void iSeries_enable_IRQ(unsigned int irq)
+ */
+static void iSeries_enable_IRQ(unsigned int irq)
 {
-	struct iSeries_irqEntry* entry;
+	struct iSeries_irqEntry *entry;
 	u32 bus, subBus, deviceId, mask;
 
 	/* The IRQ has already been locked by the caller */
-	for (entry=iSeries_irqMap[irq].head; entry; entry=entry->next) {
-		bus      = (entry->dsa >> 16) & 0xFFFF;
-		subBus   = (entry->dsa >> 8) & 0xFF;
+	for (entry = iSeries_irqMap[irq].head; entry; entry = entry->next) {
+		bus = (entry->dsa >> 16) & 0xFFFF;
+		subBus = (entry->dsa >> 8) & 0xFF;
 		deviceId = entry->dsa & 0xFF;
 		/* Unmask secondary INTA */
 		mask = 0x80000000;
 		HvCallPci_unmaskInterrupts(bus, subBus, deviceId, mask);
-		PPCDBG(PPCDBG_BUSWALK,"iSeries_enable_IRQ 0x%02X.%02X.%02X 0x%04X\n",bus,subBus,deviceId,irq);
+		PPCDBG(PPCDBG_BUSWALK,
+				"iSeries_enable_IRQ 0x%02X.%02X.%02X 0x%04X\n",
+				bus, subBus, deviceId, irq);
 	}
 }
 
-/* Need to define this so ppc_irq_dispatch_handler will NOT call
-   enable_IRQ at the end of interrupt handling.  However, this
-   does nothing because there is not enough information provided
-   to do the EOI HvCall.  This is done by XmPciLpEvent.c */
-void iSeries_end_IRQ(unsigned int irq)
+/*
+ * Need to define this so ppc_irq_dispatch_handler will NOT call
+ * enable_IRQ at the end of interrupt handling.  However, this does
+ * nothing because there is not enough information provided to do
+ * the EOI HvCall.  This is done by XmPciLpEvent.c
+ */
+static void iSeries_end_IRQ(unsigned int irq)
 {
 }
-
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_pci.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_pci.c
--- linux-2.5/arch/ppc64/kernel/iSeries_pci.c	2003-06-04 14:34:46.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_pci.c	2003-11-21 06:45:02.000000000 +0000
@@ -1,3 +1,4 @@
+#define PCIFR(...)
 /*
  * iSeries_pci.c
  *
@@ -49,171 +50,160 @@
 #include "iSeries_IoMmTable.h"
 #include "pci.h"
 
-extern struct pci_controller* hose_head;
-extern struct pci_controller** hose_tail;
-extern int    global_phb_number;
-extern int    panic_timeout;
+extern struct pci_controller *hose_head;
+extern struct pci_controller **hose_tail;
+extern int global_phb_number;
+extern int panic_timeout;
 
 extern struct device_node *allnodes;
 extern unsigned long iSeries_Base_Io_Memory;    
 
 extern struct pci_ops iSeries_pci_ops;
-extern struct flightRecorder* PciFr;
-extern struct TceTable* tceTables[256];
-
-/*******************************************************************
- * Counters and control flags. 
- *******************************************************************/
-extern long   Pci_Io_Read_Count;
-extern long   Pci_Io_Write_Count;
-extern long   Pci_Cfg_Read_Count;
-extern long   Pci_Cfg_Write_Count;
-extern long   Pci_Error_Count;
-
-extern int    Pci_Retry_Max;	
-extern int    Pci_Error_Flag;
-extern int    Pci_Trace_Flag;
+extern struct flightRecorder *PciFr;
+extern struct TceTable *tceTables[256];
 
 extern void iSeries_MmIoTest(void);
 
-
-/*******************************************************************
+/*
  * Forward declares of prototypes. 
- *******************************************************************/
-struct iSeries_Device_Node* find_Device_Node(struct pci_dev* PciDev);
-struct iSeries_Device_Node* get_Device_Node(struct pci_dev* PciDev);
-
+ */
+static struct iSeries_Device_Node *find_Device_Node(struct pci_dev *PciDev);
 unsigned long find_and_init_phbs(void);
-struct        pci_controller* alloc_phb(struct device_node *dev, char *model, unsigned int addr_size_words) ;
-
-void  iSeries_Scan_PHBs_Slots(struct pci_controller* Phb);
-void  iSeries_Scan_EADs_Bridge(HvBusNumber Bus, HvSubBusNumber SubBus, int IdSel);
-int   iSeries_Scan_Bridge_Slot(HvBusNumber Bus, struct HvCallPci_BridgeInfo* Info);
-void  list_device_nodes(void);
-
-struct pci_dev;
+static void iSeries_Scan_PHBs_Slots(struct pci_controller *Phb);
+static void iSeries_Scan_EADs_Bridge(HvBusNumber Bus, HvSubBusNumber SubBus,
+		int IdSel);
+static int iSeries_Scan_Bridge_Slot(HvBusNumber Bus,
+		struct HvCallPci_BridgeInfo *Info);
 
 LIST_HEAD(iSeries_Global_Device_List);
 
-int DeviceCount = 0;
-
+static int DeviceCount;
 
 /* Counters and control flags. */
-static long   Pci_Io_Read_Count  = 0;
-static long   Pci_Io_Write_Count = 0;
-static long   Pci_Cfg_Read_Count = 0;
-static long   Pci_Cfg_Write_Count= 0;
-static long   Pci_Error_Count    = 0;
-
-static int    Pci_Retry_Max      = 3;	/* Only retry 3 times  */	
-static int    Pci_Error_Flag     = 1;	/* Set Retry Error on. */
-static int    Pci_Trace_Flag     = 0;
-
+static long Pci_Io_Read_Count;
+static long Pci_Io_Write_Count;
+#if 0
+static long Pci_Cfg_Read_Count;
+static long Pci_Cfg_Write_Count;
+#endif
+static long Pci_Error_Count;
+
+static int Pci_Retry_Max = 3;	/* Only retry 3 times  */	
+static int Pci_Error_Flag = 1;	/* Set Retry Error on. */
+static int Pci_Trace_Flag;
 
-/**********************************************************************************
+/*
  * Log Error infor in Flight Recorder to system Console.
  * Filter out the device not there errors.
  * PCI: EADs Connect Failed 0x18.58.10 Rc: 0x00xx
  * PCI: Read Vendor Failed 0x18.58.10 Rc: 0x00xx
  * PCI: Connect Bus Unit Failed 0x18.58.10 Rc: 0x00xx
- **********************************************************************************/
-void  pci_Log_Error(char* Error_Text, int Bus, int SubBus, int AgentId, int HvRc)
+ */
+static void pci_Log_Error(char *Error_Text, int Bus, int SubBus,
+		int AgentId, int HvRc)
 {
-	if( HvRc != 0x0302) { 
+	if (HvRc != 0x0302) { 
 		char ErrorString[128];
-		sprintf(ErrorString,"%s Failed: 0x%02X.%02X.%02X Rc: 0x%04X",Error_Text,Bus,SubBus,AgentId,HvRc);
+
+		sprintf(ErrorString, "%s Failed: 0x%02X.%02X.%02X Rc: 0x%04X",
+				Error_Text, Bus, SubBus, AgentId, HvRc);
 		PCIFR(ErrorString);
-		printk("PCI: %s\n",ErrorString);
+		printk("PCI: %s\n", ErrorString);
 	}
 }
 
-/**********************************************************************************
+#if 0
+/*
  * Dump the iSeries Temp Device Node 
- *<4>buswalk [swapper : - DeviceNode: 0xC000000000634300
- *<4>00. Device Node   = 0xC000000000634300
- *<4>    - PciDev      = 0x0000000000000000
- *<4>    - tDevice     = 0x  17:01.00  0x1022 00
- *<4>  4. Device Node = 0xC000000000634480
- *<4>     - PciDev    = 0x0000000000000000
- *<4>     - Device    = 0x  18:38.16 Irq:0xA7 Vendor:0x1014  Flags:0x00
- *<4>     - Devfn     = 0xB0: 22.18
- **********************************************************************************/
-void dumpDevice_Node(struct iSeries_Device_Node* DevNode)
+ * <4>buswalk [swapper : - DeviceNode: 0xC000000000634300
+ * <4>00. Device Node   = 0xC000000000634300
+ * <4>    - PciDev      = 0x0000000000000000
+ * <4>    - tDevice     = 0x  17:01.00  0x1022 00
+ * <4>  4. Device Node = 0xC000000000634480
+ * <4>     - PciDev    = 0x0000000000000000
+ * <4>     - Device    = 0x  18:38.16 Irq:0xA7 Vendor:0x1014  Flags:0x00
+ * <4>     - Devfn     = 0xB0: 22.18
+ */
+void dumpDevice_Node(struct iSeries_Device_Node *DevNode)
 {
-	udbg_printf("Device Node      = 0x%p\n",DevNode);
-	udbg_printf("     - PciDev    = 0x%p\n",DevNode->PciDev);
+	udbg_printf("Device Node      = 0x%p\n", DevNode);
+	udbg_printf("     - PciDev    = 0x%p\n", DevNode->PciDev);
 	udbg_printf("     - Device    = 0x%4X:%02X.%02X (0x%02X)\n",
-		    ISERIES_BUS(DevNode),
-		    ISERIES_SUBBUS(DevNode),
-		    DevNode->AgentId,
-		    DevNode->DevFn);
-	udbg_printf("     - LSlot     = 0x%02X\n",DevNode->LogicalSlot);
-	udbg_printf("     - TceTable  = 0x%p\n  ",DevNode->DevTceTable);
-
-	udbg_printf("     - DSA       = 0x%04X\n",ISERIES_DSA(DevNode)>>32 );
-
+			ISERIES_BUS(DevNode), ISERIES_SUBBUS(DevNode),
+			DevNode->AgentId, DevNode->DevFn);
+	udbg_printf("     - LSlot     = 0x%02X\n", DevNode->LogicalSlot);
+	udbg_printf("     - TceTable  = 0x%p\n  ", DevNode->DevTceTable);
+	udbg_printf("     - DSA       = 0x%04X\n", ISERIES_DSA(DevNode) >> 32);
 	udbg_printf("                 = Irq:0x%02X Vendor:0x%04X  Flags:0x%02X\n",
-		    DevNode->Irq,
-		    DevNode->Vendor,
-		    DevNode->Flags );
-	udbg_printf("     - Location  = %s\n",DevNode->CardLocation);
-
-
+			DevNode->Irq, DevNode->Vendor, DevNode->Flags);
+	udbg_printf("     - Location  = %s\n", DevNode->CardLocation);
 }
-/**********************************************************************************
+
+/*
  * Walk down the device node chain 
- **********************************************************************************/
-void  list_device_nodes(void)
+ */
+static void list_device_nodes(void)
 {
-	struct list_head* Device_Node_Ptr = iSeries_Global_Device_List.next;
-	while(Device_Node_Ptr != &iSeries_Global_Device_List) {
-		dumpDevice_Node( (struct iSeries_Device_Node*)Device_Node_Ptr );
+	struct list_head *Device_Node_Ptr = iSeries_Global_Device_List.next;
+
+	while (Device_Node_Ptr != &iSeries_Global_Device_List) {
+		dumpDevice_Node((struct iSeries_Device_Node*)Device_Node_Ptr);
 		Device_Node_Ptr = Device_Node_Ptr->next;
 	}
 }
-	
+#endif
 
-/***********************************************************************
+/*
  * build_device_node(u16 Bus, int SubBus, u8 DevFn)
- *
- ***********************************************************************/
-struct iSeries_Device_Node* build_device_node(HvBusNumber Bus, HvSubBusNumber  SubBus, int AgentId, int Function)
+ */
+static struct iSeries_Device_Node *build_device_node(HvBusNumber Bus,
+		HvSubBusNumber SubBus, int AgentId, int Function)
 {
-	struct iSeries_Device_Node*  DeviceNode;
+	struct iSeries_Device_Node *DeviceNode;
 
-	PPCDBG(PPCDBG_BUSWALK,"-build_device_node 0x%02X.%02X.%02X Function: %02X\n",Bus,SubBus,AgentId, Function);
+	PPCDBG(PPCDBG_BUSWALK,
+			"-build_device_node 0x%02X.%02X.%02X Function: %02X\n",
+			Bus, SubBus, AgentId, Function);
 
 	DeviceNode = kmalloc(sizeof(struct iSeries_Device_Node), GFP_KERNEL);
-	if(DeviceNode == NULL) return NULL;
+	if (DeviceNode == NULL)
+		return NULL;
 
-	memset(DeviceNode,0,sizeof(struct iSeries_Device_Node) );
-	list_add_tail(&DeviceNode->Device_List,&iSeries_Global_Device_List);
-	/*DeviceNode->DsaAddr      = ((u64)Bus<<48)+((u64)SubBus<<40)+((u64)0x10<<32); */
-	ISERIES_BUS(DeviceNode)       = Bus;
-	ISERIES_SUBBUS(DeviceNode)    = SubBus;
-	DeviceNode->DsaAddr.deviceId  = 0x10;
-        DeviceNode->DsaAddr.barNumber = 0;
-	DeviceNode->AgentId           = AgentId;
-	DeviceNode->DevFn             = PCI_DEVFN(ISERIES_ENCODE_DEVICE(AgentId),Function );
-	DeviceNode->IoRetry           = 0;
+	memset(DeviceNode, 0, sizeof(struct iSeries_Device_Node));
+	list_add_tail(&DeviceNode->Device_List, &iSeries_Global_Device_List);
+	/* DeviceNode->DsaAddr =
+		((u64)Bus << 48) + ((u64)SubBus << 40) + ((u64)0x10 << 32); */
+	ISERIES_BUS(DeviceNode) = Bus;
+	ISERIES_SUBBUS(DeviceNode) = SubBus;
+	DeviceNode->DsaAddr.deviceId = 0x10;
+	DeviceNode->DsaAddr.barNumber = 0;
+	DeviceNode->AgentId = AgentId;
+	DeviceNode->DevFn = PCI_DEVFN(ISERIES_ENCODE_DEVICE(AgentId), Function);
+	DeviceNode->IoRetry = 0;
 	iSeries_Get_Location_Code(DeviceNode);
-	PCIFR("Device 0x%02X.%2X, Node:0x%p ",ISERIES_BUS(DeviceNode),ISERIES_DEVFUN(DeviceNode),DeviceNode);
+	PCIFR("Device 0x%02X.%2X, Node:0x%p ", ISERIES_BUS(DeviceNode),
+			ISERIES_DEVFUN(DeviceNode), DeviceNode);
 	return DeviceNode;
 }
-/****************************************************************************
-* 
-* Allocate pci_controller(phb) initialized common variables. 
-* 
-*****************************************************************************/
-struct pci_controller* pci_alloc_pci_controllerX(char *model, enum phb_types controller_type)
+
+/*
+ * Allocate pci_controller(phb) initialized common variables.
+ */
+static struct pci_controller *pci_alloc_pci_controllerX(char *model,
+		enum phb_types controller_type)
 {
 	struct pci_controller *hose;
-	hose = (struct pci_controller*)kmalloc(sizeof(struct pci_controller), GFP_KERNEL);
-	if(hose == NULL) return NULL;
+
+	hose = (struct pci_controller *)kmalloc(sizeof(struct pci_controller),
+			GFP_KERNEL);
+	if (hose == NULL)
+		return NULL;
 
 	memset(hose, 0, sizeof(struct pci_controller));
-	if(strlen(model) < 8) strcpy(hose->what,model);
-	else                  memcpy(hose->what,model,7);
+	if (strlen(model) < 8)
+		strcpy(hose->what, model);
+	else
+		memcpy(hose->what, model, 7);
 	hose->type = controller_type;
 	hose->global_number = global_phb_number;
 	global_phb_number++;
@@ -223,8 +213,7 @@ struct pci_controller* pci_alloc_pci_con
 	return hose;
 }
 
-/****************************************************************************
- *
+/*
  * unsigned int __init find_and_init_phbs(void)
  *
  * Description:
@@ -232,363 +221,388 @@ struct pci_controller* pci_alloc_pci_con
  *   PCI buses.  The system hypervisor is queried as to the guest partition
  *   ownership status.  A pci_controller is build for any bus which is partially
  *   owned or fully owned by this guest partition.
- ****************************************************************************/
+ */
 unsigned long __init find_and_init_phbs(void)
 {
-	struct      pci_controller* phb;
+	struct pci_controller *phb;
 	HvBusNumber BusNumber;
 
-	PPCDBG(PPCDBG_BUSWALK,"find_and_init_phbs Entry\n");
+	PPCDBG(PPCDBG_BUSWALK, "find_and_init_phbs Entry\n");
 
 	/* Check all possible buses. */
 	for (BusNumber = 0; BusNumber < 256; BusNumber++) {
 		int RtnCode = HvCallXm_testBus(BusNumber);
 		if (RtnCode == 0) {
-			phb = pci_alloc_pci_controllerX("PHB HV", phb_type_hypervisor);
-			if(phb == NULL) {
+			phb = pci_alloc_pci_controllerX("PHB HV",
+					phb_type_hypervisor);
+			if (phb == NULL) {
 				printk("PCI: Allocate pci_controller failed.\n");
-				PCIFR(      "Allocate pci_controller failed.");
+				PCIFR("Allocate pci_controller failed.");
 				return -1;
 			}
 			phb->pci_mem_offset = phb->local_number = BusNumber;
-			phb->first_busno  = BusNumber;
-			phb->last_busno   = BusNumber;
-			phb->ops          = &iSeries_pci_ops;
-
-			PPCDBG(PPCDBG_BUSWALK, "PCI:Create iSeries pci_controller(%p), Bus: %04X\n",phb,BusNumber);
-			PCIFR("Create iSeries PHB controller: %04X",BusNumber);
-
-			/***************************************************/
-			/* Find and connect the devices.                   */
-			/***************************************************/
+			phb->first_busno = BusNumber;
+			phb->last_busno = BusNumber;
+			phb->ops = &iSeries_pci_ops;
+
+			PPCDBG(PPCDBG_BUSWALK, "PCI:Create iSeries pci_controller(%p), Bus: %04X\n",
+					phb, BusNumber);
+			PCIFR("Create iSeries PHB controller: %04X", BusNumber);
+
+			/* Find and connect the devices. */
 			iSeries_Scan_PHBs_Slots(phb);
 		}
-		/* Check for Unexpected Return code, a clue that something */
-		/* has gone wrong.                                         */
-		else if(RtnCode != 0x0301) {
-			PCIFR("Unexpected Return on Probe(0x%04X): 0x%04X",BusNumber,RtnCode);
-		}
-
+		/*
+		 * Check for Unexpected Return code, a clue that something
+		 * has gone wrong.
+		 */
+		else if (RtnCode != 0x0301)
+			PCIFR("Unexpected Return on Probe(0x%04X): 0x%04X",
+					BusNumber, RtnCode);
 	}
 	return 0;
 }
-/*********************************************************************** 
+
+/*
  * iSeries_pcibios_init
  *  
  * Chance to initialize and structures or variable before PCI Bus walk.
  *  
- *<4>buswalk [swapper : iSeries_pcibios_init Entry.
- *<4>buswalk [swapper : IoMmTable Initialized 0xC00000000034BD30
- *<4>buswalk [swapper : find_and_init_phbs Entry
- *<4>buswalk [swapper : Create iSeries pci_controller:(0xC00000001F5C7000), Bus 0x0017
- *<4>buswalk [swapper : Connect EADs: 0x17.00.12 = 0x00
- *<4>buswalk [swapper : iSeries_assign_IRQ   0x0017.00.12 = 0x0091
- *<4>buswalk [swapper : - allocate and assign IRQ 0x17.00.12 = 0x91
- *<4>buswalk [swapper : - FoundDevice: 0x17.28.10 = 0x12AE
- *<4>buswalk [swapper : - build_device_node 0x17.28.12
- *<4>buswalk [swapper : iSeries_pcibios_init Exit.
- ***********************************************************************/
+ * <4>buswalk [swapper : iSeries_pcibios_init Entry.
+ * <4>buswalk [swapper : IoMmTable Initialized 0xC00000000034BD30
+ * <4>buswalk [swapper : find_and_init_phbs Entry
+ * <4>buswalk [swapper : Create iSeries pci_controller:(0xC00000001F5C7000), Bus 0x0017
+ * <4>buswalk [swapper : Connect EADs: 0x17.00.12 = 0x00
+ * <4>buswalk [swapper : iSeries_assign_IRQ   0x0017.00.12 = 0x0091
+ * <4>buswalk [swapper : - allocate and assign IRQ 0x17.00.12 = 0x91
+ * <4>buswalk [swapper : - FoundDevice: 0x17.28.10 = 0x12AE
+ * <4>buswalk [swapper : - build_device_node 0x17.28.12
+ * <4>buswalk [swapper : iSeries_pcibios_init Exit.
+ */
 void iSeries_pcibios_init(void)
 {
-	PPCDBG(PPCDBG_BUSWALK,"iSeries_pcibios_init Entry.\n"); 
-
+	PPCDBG(PPCDBG_BUSWALK, "iSeries_pcibios_init Entry.\n"); 
 	iSeries_IoMmTable_Initialize();
-
 	find_and_init_phbs();
-
-	pci_assign_all_busses = 0;
-	PPCDBG(PPCDBG_BUSWALK,"iSeries_pcibios_init Exit.\n"); 
+	/* pci_assign_all_busses = 0;		SFRXXX*/
+	PPCDBG(PPCDBG_BUSWALK, "iSeries_pcibios_init Exit.\n"); 
 }
-/***********************************************************************
+
+/*
  * pcibios_final_fixup(void)  
- ***********************************************************************/
+ */
 void __init pcibios_final_fixup(void)
 {
-	struct pci_dev* PciDev = NULL;
-	struct iSeries_Device_Node* DeviceNode;
-	char   Buffer[256];
-    	int    DeviceCount = 0;
+	struct pci_dev *PciDev = NULL;
+	struct iSeries_Device_Node *DeviceNode;
+	char Buffer[256];
+    	int DeviceCount = 0;
+
+	PPCDBG(PPCDBG_BUSWALK, "iSeries_pcibios_fixup Entry.\n"); 
 
-	PPCDBG(PPCDBG_BUSWALK,"iSeries_pcibios_fixup Entry.\n"); 
-	/******************************************************/
 	/* Fix up at the device node and pci_dev relationship */
-	/******************************************************/
 	mf_displaySrc(0xC9000100);
 
-	while ((PciDev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, PciDev)) != NULL) {
+	while ((PciDev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, PciDev))
+			!= NULL) {
 		DeviceNode = find_Device_Node(PciDev);
-		if(DeviceNode != NULL) {
+		if (DeviceNode != NULL) {
 			++DeviceCount;
-			PciDev->sysdata    = (void*)DeviceNode;
+			PciDev->sysdata = (void *)DeviceNode;
 			DeviceNode->PciDev = PciDev;
-
-			PPCDBG(PPCDBG_BUSWALK,"PciDev 0x%p <==> DevNode 0x%p\n",PciDev,DeviceNode );
-
+			PPCDBG(PPCDBG_BUSWALK,
+					"PciDev 0x%p <==> DevNode 0x%p\n",
+					PciDev, DeviceNode);
 			iSeries_allocateDeviceBars(PciDev);
-
-			iSeries_Device_Information(PciDev,Buffer, sizeof(Buffer) );
-			printk("%d. %s\n",DeviceCount,Buffer);
-
+			iSeries_Device_Information(PciDev, Buffer,
+					sizeof(Buffer));
+			printk("%d. %s\n", DeviceCount, Buffer);
 			create_pci_bus_tce_table((unsigned long)DeviceNode);
-		} else {
-			printk("PCI: Device Tree not found for 0x%016lX\n",(unsigned long)PciDev);
-		}
+		} else
+			printk("PCI: Device Tree not found for 0x%016lX\n",
+					(unsigned long)PciDev);
 	}
 	iSeries_IoMmTable_Status();
-
 	iSeries_activate_IRQs();
-
 	mf_displaySrc(0xC9000200);
 }
 
-void pcibios_fixup_bus(struct pci_bus* PciBus)
+void pcibios_fixup_bus(struct pci_bus *PciBus)
 {
-	PPCDBG(PPCDBG_BUSWALK,"iSeries_pcibios_fixup_bus(0x%04X) Entry.\n",PciBus->number); 
-
+	PPCDBG(PPCDBG_BUSWALK, "iSeries_pcibios_fixup_bus(0x%04X) Entry.\n",
+			PciBus->number); 
 }
 
-
-/***********************************************************************
- * pcibios_fixup_resources(struct pci_dev *dev) 
- *	
- ***********************************************************************/
 void pcibios_fixup_resources(struct pci_dev *PciDev)
 {
-	PPCDBG(PPCDBG_BUSWALK,"pcibios_fixup_resources PciDev %p\n",PciDev);
+	PPCDBG(PPCDBG_BUSWALK, "fixup_resources PciDev %p\n", PciDev);
 }   
 
+/*
+ * Loop through each node function to find usable EADs bridges.  
+ */
+static void iSeries_Scan_PHBs_Slots(struct pci_controller *Phb)
+{
+	struct HvCallPci_DeviceInfo *DevInfo;
+	HvBusNumber Bus = Phb->local_number;	/* System Bus */	
+	HvSubBusNumber SubBus = 0;		/* EADs is always 0. */
+	int HvRc = 0;
+	int IdSel = 1;	
+	int MaxAgents = 8;
+
+	DevInfo = (struct HvCallPci_DeviceInfo*)
+		kmalloc(sizeof(struct HvCallPci_DeviceInfo), GFP_KERNEL);
+	if (DevInfo == NULL)
+		return;
 
-/********************************************************************************
-* Loop through each node function to find usable EADs bridges.  
-*********************************************************************************/
-void  iSeries_Scan_PHBs_Slots(struct pci_controller* Phb)
-{
-	struct HvCallPci_DeviceInfo* DevInfo;
-	HvBusNumber    Bus       = Phb->local_number;       /* System Bus        */	
-	HvSubBusNumber SubBus    = 0;                       /* EADs is always 0. */
-	int            HvRc      = 0;
-	int            IdSel     = 1;	
-	int            MaxAgents = 8;
-
-	DevInfo    = (struct HvCallPci_DeviceInfo*)kmalloc(sizeof(struct HvCallPci_DeviceInfo), GFP_KERNEL);
-	if(DevInfo == NULL) return;
-
-	/********************************************************************************
+	/*
 	 * Probe for EADs Bridges      
-	 ********************************************************************************/
+	 */
 	for (IdSel=1; IdSel < MaxAgents; ++IdSel) {
-    		HvRc = HvCallPci_getDeviceInfo(Bus, SubBus, IdSel,REALADDR(DevInfo), sizeof(struct HvCallPci_DeviceInfo));
+    		HvRc = HvCallPci_getDeviceInfo(Bus, SubBus, IdSel,
+				REALADDR(DevInfo),
+				sizeof(struct HvCallPci_DeviceInfo));
 		if (HvRc == 0) {
-			if(DevInfo->deviceType == HvCallPci_NodeDevice) {
+			if (DevInfo->deviceType == HvCallPci_NodeDevice)
 				iSeries_Scan_EADs_Bridge(Bus, SubBus, IdSel);
-			}
-			else printk("PCI: Invalid System Configuration(0x%02X.\n",DevInfo->deviceType);
+			else
+				printk("PCI: Invalid System Configuration(0x%02X.\n",
+						DevInfo->deviceType);
 		}
-		else pci_Log_Error("getDeviceInfo",Bus, SubBus, IdSel,HvRc);
+		else
+			pci_Log_Error("getDeviceInfo",Bus, SubBus, IdSel,HvRc);
 	}
 	kfree(DevInfo);
 }
 
-/********************************************************************************
-* 
-*********************************************************************************/
-void  iSeries_Scan_EADs_Bridge(HvBusNumber Bus, HvSubBusNumber SubBus, int IdSel)
-{
-	struct HvCallPci_BridgeInfo* BridgeInfo;
-	HvAgentId      AgentId;
-	int            Function;
-	int            HvRc;
-
-	BridgeInfo = (struct HvCallPci_BridgeInfo*)kmalloc(sizeof(struct HvCallPci_BridgeInfo), GFP_KERNEL);
-	if(BridgeInfo == NULL) return;
-
-	/*********************************************************************
-	 * Note: hvSubBus and irq is always be 0 at this level!
-	 *********************************************************************/
-	for (Function=0; Function < 8; ++Function) {
+static void iSeries_Scan_EADs_Bridge(HvBusNumber Bus, HvSubBusNumber SubBus,
+		int IdSel)
+{
+	struct HvCallPci_BridgeInfo *BridgeInfo;
+	HvAgentId AgentId;
+	int Function;
+	int HvRc;
+
+	BridgeInfo = (struct HvCallPci_BridgeInfo *)
+		kmalloc(sizeof(struct HvCallPci_BridgeInfo), GFP_KERNEL);
+	if (BridgeInfo == NULL)
+		return;
+
+	/* Note: hvSubBus and irq is always be 0 at this level! */
+	for (Function = 0; Function < 8; ++Function) {
 	  	AgentId = ISERIES_PCI_AGENTID(IdSel, Function);
 		HvRc = HvCallXm_connectBusUnit(Bus, SubBus, AgentId, 0);
  		if (HvRc == 0) {
   			/*  Connect EADs: 0x18.00.12 = 0x00 */
-			PPCDBG(PPCDBG_BUSWALK,"PCI:Connect EADs: 0x%02X.%02X.%02X\n",Bus, SubBus, AgentId);
-			PCIFR(                    "Connect EADs: 0x%02X.%02X.%02X",  Bus, SubBus, AgentId);
-	    		HvRc = HvCallPci_getBusUnitInfo(Bus, SubBus, AgentId, 
-			                                REALADDR(BridgeInfo), sizeof(struct HvCallPci_BridgeInfo));
+			PPCDBG(PPCDBG_BUSWALK,
+					"PCI:Connect EADs: 0x%02X.%02X.%02X\n",
+					Bus, SubBus, AgentId);
+			PCIFR("Connect EADs: 0x%02X.%02X.%02X",
+					Bus, SubBus, AgentId);
+	    		HvRc = HvCallPci_getBusUnitInfo(Bus, SubBus, AgentId,
+					REALADDR(BridgeInfo),
+					sizeof(struct HvCallPci_BridgeInfo));
 	 		if (HvRc == 0) {
-				PPCDBG(PPCDBG_BUSWALK,"PCI: BridgeInfo, Type:0x%02X, SubBus:0x%02X, MaxAgents:0x%02X, MaxSubBus: 0x%02X, LSlot: 0x%02X\n",
-				       BridgeInfo->busUnitInfo.deviceType,
-				       BridgeInfo->subBusNumber,
-				       BridgeInfo->maxAgents,
-				       BridgeInfo->maxSubBusNumber,
-				       BridgeInfo->logicalSlotNumber);
-				PCIFR(                     "BridgeInfo, Type:0x%02X, SubBus:0x%02X, MaxAgents:0x%02X, MaxSubBus: 0x%02X, LSlot: 0x%02X",
-				       BridgeInfo->busUnitInfo.deviceType,
-				       BridgeInfo->subBusNumber,
-				       BridgeInfo->maxAgents,
-				       BridgeInfo->maxSubBusNumber,
-				       BridgeInfo->logicalSlotNumber);
+				PPCDBG(PPCDBG_BUSWALK,
+					"PCI: BridgeInfo, Type:0x%02X, SubBus:0x%02X, MaxAgents:0x%02X, MaxSubBus: 0x%02X, LSlot: 0x%02X\n",
+					BridgeInfo->busUnitInfo.deviceType,
+					BridgeInfo->subBusNumber,
+					BridgeInfo->maxAgents,
+					BridgeInfo->maxSubBusNumber,
+					BridgeInfo->logicalSlotNumber);
+				PCIFR("BridgeInfo, Type:0x%02X, SubBus:0x%02X, MaxAgents:0x%02X, MaxSubBus: 0x%02X, LSlot: 0x%02X",
+					BridgeInfo->busUnitInfo.deviceType,
+					BridgeInfo->subBusNumber,
+					BridgeInfo->maxAgents,
+					BridgeInfo->maxSubBusNumber,
+					BridgeInfo->logicalSlotNumber);
 
-				if (BridgeInfo->busUnitInfo.deviceType == HvCallPci_BridgeDevice)  {
+				if (BridgeInfo->busUnitInfo.deviceType ==
+						HvCallPci_BridgeDevice)  {
 					/* Scan_Bridge_Slot...: 0x18.00.12 */
-					iSeries_Scan_Bridge_Slot(Bus,BridgeInfo);
-				}
-				else printk("PCI: Invalid Bridge Configuration(0x%02X)",BridgeInfo->busUnitInfo.deviceType);
+					iSeries_Scan_Bridge_Slot(Bus,
+							BridgeInfo);
+				} else
+					printk("PCI: Invalid Bridge Configuration(0x%02X)",
+						BridgeInfo->busUnitInfo.deviceType);
 			}
     		}
-		else if(HvRc != 0x000B) pci_Log_Error("EADs Connect",Bus,SubBus,AgentId,HvRc);
+		else if (HvRc != 0x000B)
+			pci_Log_Error("EADs Connect",
+					Bus, SubBus, AgentId, HvRc);
 	}
 	kfree(BridgeInfo);
 }
 
-/********************************************************************************
-* 
-* This assumes that the node slot is always on the primary bus!
-*
-*********************************************************************************/
-int iSeries_Scan_Bridge_Slot(HvBusNumber Bus, struct HvCallPci_BridgeInfo* BridgeInfo)
+/*
+ * This assumes that the node slot is always on the primary bus!
+ */
+static int iSeries_Scan_Bridge_Slot(HvBusNumber Bus,
+		struct HvCallPci_BridgeInfo *BridgeInfo)
 {
-	struct iSeries_Device_Node* DeviceNode;
+	struct iSeries_Device_Node *DeviceNode;
 	HvSubBusNumber SubBus = BridgeInfo->subBusNumber;
-	u16       VendorId    = 0;
-	int       HvRc        = 0;
-	u8        Irq         = 0;
-	int       IdSel       = ISERIES_GET_DEVICE_FROM_SUBBUS(SubBus);
-	int       Function    = ISERIES_GET_FUNCTION_FROM_SUBBUS(SubBus);
-	HvAgentId AgentId     = ISERIES_PCI_AGENTID(IdSel, Function);
-	HvAgentId EADsIdSel   = ISERIES_PCI_AGENTID(IdSel, Function);
-	int       FirstSlotId = 0; 	
-
-	/**********************************************************/
-	/* iSeries_allocate_IRQ.: 0x18.00.12(0xA3)                */
-	/**********************************************************/
-  	Irq   = iSeries_allocate_IRQ(Bus, 0, AgentId);
+	u16 VendorId = 0;
+	int HvRc = 0;
+	u8 Irq = 0;
+	int IdSel = ISERIES_GET_DEVICE_FROM_SUBBUS(SubBus);
+	int Function = ISERIES_GET_FUNCTION_FROM_SUBBUS(SubBus);
+	HvAgentId AgentId = ISERIES_PCI_AGENTID(IdSel, Function);
+	HvAgentId EADsIdSel = ISERIES_PCI_AGENTID(IdSel, Function);
+	int FirstSlotId = 0; 	
+
+	/* iSeries_allocate_IRQ.: 0x18.00.12(0xA3) */
+  	Irq = iSeries_allocate_IRQ(Bus, 0, AgentId);
 	iSeries_assign_IRQ(Irq, Bus, 0, AgentId);
-	PPCDBG(PPCDBG_BUSWALK,"PCI:- allocate and assign IRQ 0x%02X.%02X.%02X = 0x%02X\n",Bus, 0, AgentId, Irq );
+	PPCDBG(PPCDBG_BUSWALK,
+		"PCI:- allocate and assign IRQ 0x%02X.%02X.%02X = 0x%02X\n",
+		Bus, 0, AgentId, Irq);
 
-	/****************************************************************************
+	/*
 	 * Connect all functions of any device found.  
-	 ****************************************************************************/
+	 */
   	for (IdSel = 1; IdSel <= BridgeInfo->maxAgents; ++IdSel) {
     		for (Function = 0; Function < 8; ++Function) {
 			AgentId = ISERIES_PCI_AGENTID(IdSel, Function);
-			HvRc = HvCallXm_connectBusUnit(Bus, SubBus, AgentId, Irq);
-			if( HvRc == 0) {
-				HvRc = HvCallPci_configLoad16(Bus, SubBus, AgentId, PCI_VENDOR_ID, &VendorId);
-				if( HvRc == 0) {
-					/**********************************************************/
-					/* FoundDevice: 0x18.28.10 = 0x12AE                       */
-					/**********************************************************/
-					PPCDBG(PPCDBG_BUSWALK,"PCI:- FoundDevice: 0x%02X.%02X.%02X = 0x%04X\n",
-					                                       Bus, SubBus, AgentId, VendorId);
-
-					HvRc = HvCallPci_configStore8(Bus, SubBus, AgentId, PCI_INTERRUPT_LINE, Irq);  
-					if( HvRc != 0) {
-						pci_Log_Error("PciCfgStore Irq Failed!",Bus,SubBus,AgentId,HvRc);
-					}
-
+			HvRc = HvCallXm_connectBusUnit(Bus, SubBus,
+					AgentId, Irq);
+			if (HvRc == 0) {
+				HvRc = HvCallPci_configLoad16(Bus, SubBus,
+						AgentId, PCI_VENDOR_ID,
+						&VendorId);
+				if (HvRc == 0) {
+					/* FoundDevice: 0x18.28.10 = 0x12AE */
+					PPCDBG(PPCDBG_BUSWALK,
+						"PCI:- FoundDevice: 0x%02X.%02X.%02X = 0x%04X\n",
+						Bus, SubBus, AgentId, VendorId);
+					HvRc = HvCallPci_configStore8(Bus,
+							SubBus, AgentId,
+							PCI_INTERRUPT_LINE, Irq);  
+					if (HvRc != 0)
+						pci_Log_Error("PciCfgStore Irq Failed!",
+								Bus, SubBus,
+								AgentId, HvRc);
 					++DeviceCount;
-					DeviceNode = build_device_node(Bus, SubBus, EADsIdSel, Function);
-					DeviceNode->Vendor      = VendorId;
-					DeviceNode->Irq         = Irq;
-					DeviceNode->LogicalSlot = BridgeInfo->logicalSlotNumber;
+					DeviceNode = build_device_node(Bus,
+							SubBus, EADsIdSel,
+							Function);
+					DeviceNode->Vendor = VendorId;
+					DeviceNode->Irq = Irq;
+					DeviceNode->LogicalSlot =
+						BridgeInfo->logicalSlotNumber;
 					PCIFR("Device(%4d): 0x%02X.%02X.%02X 0x%02X 0x%04X",
-					      DeviceCount,Bus, SubBus, AgentId,
-					      DeviceNode->LogicalSlot,DeviceNode->Vendor);
-
-					/***********************************************************
-					 * On the first device/function, assign irq to slot
-					 ***********************************************************/
-					if(Function == 0) { 
+						DeviceCount, Bus, SubBus,
+						AgentId,
+						DeviceNode->LogicalSlot,DeviceNode->Vendor);
+
+					/*
+					 * On the first device/function,
+					 * assign irq to slot
+					 */
+					if (Function == 0) { 
 						FirstSlotId = AgentId;
-						// AHT iSeries_assign_IRQ(Irq, Bus, SubBus, AgentId);
+						/* AHT iSeries_assign_IRQ(Irq,
+							Bus, SubBus, AgentId); */
     					}
-				}
-				else pci_Log_Error("Read Vendor",Bus,SubBus,AgentId,HvRc);
-			}
-			else pci_Log_Error("Connect Bus Unit",Bus,SubBus, AgentId,HvRc);
+				} else
+					pci_Log_Error("Read Vendor",
+						Bus, SubBus, AgentId, HvRc);
+			} else
+				pci_Log_Error("Connect Bus Unit",
+					Bus, SubBus, AgentId, HvRc);
 		} /* for (Function = 0; Function < 8; ++Function) */
 	} /* for (IdSel = 1; IdSel <= MaxAgents; ++IdSel) */
 	return HvRc;
 }
-/************************************************************************/
-/* I/0 Memory copy MUST use mmio commands on iSeries                    */
-/* To do; For performance, include the hv call directly                 */
-/************************************************************************/
-void* iSeries_memset_io(void* dest, char c, size_t Count)
-{
-	u8    ByteValue     = c;
-	long  NumberOfBytes = Count;
-	char* IoBuffer      = dest;
-	while(NumberOfBytes > 0) {
-		iSeries_Write_Byte( ByteValue, (void*)IoBuffer );
+
+/*
+ * I/0 Memory copy MUST use mmio commands on iSeries
+ * To do; For performance, include the hv call directly
+ */
+void *iSeries_memset_io(void *dest, char c, size_t Count)
+{
+	u8 ByteValue = c;
+	long NumberOfBytes = Count;
+	char *IoBuffer = dest;
+
+	while (NumberOfBytes > 0) {
+		iSeries_Write_Byte(ByteValue, (void *)IoBuffer);
 		++IoBuffer;
 		-- NumberOfBytes;
 	}
 	return dest;
-}	
-void* iSeries_memcpy_toio(void *dest, void *source, size_t count)
+}
+
+void *iSeries_memcpy_toio(void *dest, void *source, size_t count)
 {
-	char *dst           = dest;
-	char *src           = source;
-	long  NumberOfBytes = count;
-	while(NumberOfBytes > 0) {
-		iSeries_Write_Byte(*src++, (void*)dst++);
+	char *dst = dest;
+	char *src = source;
+	long NumberOfBytes = count;
+
+	while (NumberOfBytes > 0) {
+		iSeries_Write_Byte(*src++, (void *)dst++);
 		-- NumberOfBytes;
 	}
 	return dest;
 }
-void* iSeries_memcpy_fromio(void *dest, void *source, size_t count)
+
+void *iSeries_memcpy_fromio(void *dest, void *source, size_t count)
 {
 	char *dst = dest;
 	char *src = source;
-	long  NumberOfBytes = count;
-	while(NumberOfBytes > 0) {
-		*dst++ = iSeries_Read_Byte( (void*)src++);
+	long NumberOfBytes = count;
+
+	while (NumberOfBytes > 0) {
+		*dst++ = iSeries_Read_Byte((void *)src++);
 		-- NumberOfBytes;
 	}
 	return dest;
 }
-/**********************************************************************************
+
+/*
  * Look down the chain to find the matching Device Device
- **********************************************************************************/
-struct iSeries_Device_Node* find_Device_Node(struct pci_dev* PciDev)
+ */
+static struct iSeries_Device_Node *find_Device_Node(struct pci_dev *PciDev)
 {
-	struct list_head* Device_Node_Ptr = iSeries_Global_Device_List.next;
-	int Bus   = PciDev->bus->number;
+	struct list_head *Device_Node_Ptr = iSeries_Global_Device_List.next;
+	int Bus = PciDev->bus->number;
 	int DevFn = PciDev->devfn;
-	
-	while(Device_Node_Ptr != &iSeries_Global_Device_List) { 
-		struct iSeries_Device_Node* DevNode = (struct iSeries_Device_Node*)Device_Node_Ptr;
-		if(Bus == ISERIES_BUS(DevNode) && DevFn == DevNode->DevFn) {
+
+	while (Device_Node_Ptr != &iSeries_Global_Device_List) { 
+		struct iSeries_Device_Node *DevNode =
+			(struct iSeries_Device_Node*)Device_Node_Ptr;
+
+		if ((Bus == ISERIES_BUS(DevNode)) && (DevFn == DevNode->DevFn))
 			return DevNode;
-		}
 		Device_Node_Ptr = Device_Node_Ptr->next;
 	}
 	return NULL;
 }
-/******************************************************************/
-/* Returns the device node for the passed pci_dev                 */
-/* Sanity Check Node PciDev to passed pci_dev                     */
-/* If none is found, returns a NULL which the client must handle. */
-/******************************************************************/
-struct iSeries_Device_Node* get_Device_Node(struct pci_dev* PciDev)
-{
-	struct iSeries_Device_Node* Node;
-	Node = (struct iSeries_Device_Node*)PciDev->sysdata;
-	if(Node == NULL ) {
+
+#if 0
+/*
+ * Returns the device node for the passed pci_dev
+ * Sanity Check Node PciDev to passed pci_dev
+ * If none is found, returns a NULL which the client must handle.
+ */
+static struct iSeries_Device_Node *get_Device_Node(struct pci_dev *PciDev)
+{
+	struct iSeries_Device_Node *Node;
+
+	Node = (struct iSeries_Device_Node *)PciDev->sysdata;
+	if (Node == NULL)
 		Node = find_Device_Node(PciDev);
-	}
-	else if(Node->PciDev != PciDev) { 
+	else if (Node->PciDev != PciDev)
 		Node = find_Device_Node(PciDev);
-	}
 	return Node;
 }
-/**********************************************************************************
- *
+#endif
+
+/*
  * Read PCI Config Space Code 
- *
- **********************************************************************************/
-/** BYTE  *************************************************************************/
+ */
+#if 0
+/** BYTE  ********************************************************************/
 int iSeries_Node_read_config_byte(struct iSeries_Device_Node* DevNode, int Offset, u8* ReadValue)
 {
 	u8  ReadData; 
@@ -606,63 +620,25 @@ int iSeries_Node_read_config_byte(struct
 	*ReadValue = ReadData; 
  	return DevNode->ReturnCode;
 }
-/** WORD  *************************************************************************/
-int iSeries_Node_read_config_word(struct iSeries_Device_Node* DevNode, int Offset, u16* ReadValue)
-{
-	u16  ReadData; 
-	if(DevNode == NULL) { return 0x301; } 
-	++Pci_Cfg_Read_Count;
-	DevNode->ReturnCode = HvCallPci_configLoad16(ISERIES_BUS(DevNode),ISERIES_SUBBUS(DevNode),0x10,
-	                                                Offset,&ReadData);
-	if(Pci_Trace_Flag == 1) {
-		PCIFR("RCW: 0x%04X.%02X 0x%04X = 0x%04X",ISERIES_BUS(DevNode),DevNode->DevFn,Offset,ReadData);
-	}
-	if(DevNode->ReturnCode != 0 ) { 
-		printk("PCI: RCW: 0x%04X.%02X  Error: 0x%04X\n",ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->ReturnCode);
-		PCIFR(      "RCW: 0x%04X.%02X  Error: 0x%04X",  ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->ReturnCode);
 
-	}
-	*ReadValue = ReadData; 
- 	return DevNode->ReturnCode;
-}
-/** DWORD *************************************************************************/
-int iSeries_Node_read_config_dword(struct iSeries_Device_Node* DevNode, int Offset, u32* ReadValue)
-{
- 	u32  ReadData; 
-	if(DevNode == NULL) { return 0x301; } 
-	++Pci_Cfg_Read_Count;
-	DevNode->ReturnCode = HvCallPci_configLoad32(ISERIES_BUS(DevNode),ISERIES_SUBBUS(DevNode),0x10,
-	                                                Offset,&ReadData);
-	if(Pci_Trace_Flag == 1) {
-		PCIFR("RCL: 0x%04X.%02X 0x%04X = 0x%08X",ISERIES_BUS(DevNode),DevNode->DevFn,Offset,ReadData);
-	}
-	if(DevNode->ReturnCode != 0 ) { 
-		printk("PCI: RCL: 0x%04X.%02X  Error: 0x%04X\n",ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->ReturnCode);
-		PCIFR(      "RCL: 0x%04X.%02X  Error: 0x%04X",  ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->ReturnCode);
-	}
-	*ReadValue = ReadData; 
- 	return DevNode->ReturnCode;
-}
 int iSeries_pci_read_config_byte(struct pci_dev* PciDev, int Offset, u8* ReadValue) { 
 	struct iSeries_Device_Node* DevNode = get_Device_Node(PciDev);
 	if(DevNode == NULL) return 0x0301;
 	return iSeries_Node_read_config_byte( DevNode ,Offset,ReadValue);
 }
-int iSeries_pci_read_config_word(struct pci_dev* PciDev, int Offset, u16* ReadValue) { 
-	struct iSeries_Device_Node* DevNode = get_Device_Node(PciDev);
-	if(DevNode == NULL) return 0x0301;
-	return iSeries_Node_read_config_word( DevNode ,Offset,ReadValue );
-}
-int iSeries_pci_read_config_dword(struct pci_dev* PciDev, int Offset, u32* ReadValue) { 
-	struct iSeries_Device_Node* DevNode = get_Device_Node(PciDev);
-	if(DevNode == NULL) return 0x0301;
-	return iSeries_Node_read_config_dword(DevNode ,Offset,ReadValue  );
+#endif
+
+static int iSeries_pci_read_config(struct pci_bus *bus, unsigned int devfn,
+		int offset, int size, u32 *val)
+{
+	return PCIBIOS_DEVICE_NOT_FOUND;
 }
-/**********************************************************************************/
-/*                                                                                */
-/* Write PCI Config Space                                                         */
-/*                                                                                */
-/** BYTE  *************************************************************************/
+
+/*
+ * Write PCI Config Space
+ */
+#if 0
+/** BYTE  ********************************************************************/
 int iSeries_Node_write_config_byte(struct iSeries_Device_Node* DevNode, int Offset, u8 WriteData)
 {
 	++Pci_Cfg_Write_Count;
@@ -677,228 +653,220 @@ int iSeries_Node_write_config_byte(struc
 	}
  	return DevNode->ReturnCode;
 }
-/** WORD  *************************************************************************/
-int iSeries_Node_write_config_word(struct iSeries_Device_Node* DevNode, int Offset, u16 WriteData)
-{
-	++Pci_Cfg_Write_Count;
-	DevNode->ReturnCode = HvCallPci_configStore16(ISERIES_BUS(DevNode),ISERIES_SUBBUS(DevNode),0x10,
-	                                                  Offset,WriteData);
-	if(Pci_Trace_Flag == 1) {
-		PCIFR("WCW: 0x%04X.%02X 0x%04X = 0x%04X",ISERIES_BUS(DevNode),DevNode->DevFn,Offset,WriteData);
-	}
-	if(DevNode->ReturnCode != 0 ) { 
-		printk("PCI: WCW: 0x%04X.%02X  Error: 0x%04X\n",ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->ReturnCode);
-		PCIFR(      "WCW: 0x%04X.%02X  Error: 0x%04X",  ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->ReturnCode);
-	}
- 	return DevNode->ReturnCode;
-}
-/** DWORD *************************************************************************/
-int iSeries_Node_write_config_dword(struct iSeries_Device_Node* DevNode, int Offset, u32 WriteData)
-{
-	++Pci_Cfg_Write_Count;
-	DevNode->ReturnCode = HvCallPci_configStore32(ISERIES_BUS(DevNode),ISERIES_SUBBUS(DevNode),0x10,
-	                                                  Offset,WriteData);
-	if(Pci_Trace_Flag == 1) {
-		PCIFR("WCL: 0x%04X.%02X 0x%04X = 0x%08X",ISERIES_BUS(DevNode),DevNode->DevFn,Offset,WriteData);
-	}
-	if(DevNode->ReturnCode != 0 ) { 
-		printk("PCI: WCL: 0x%04X.%02X  Error: 0x%04X\n",ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->ReturnCode);
-		PCIFR(      "WCL: 0x%04X.%02X  Error: 0x%04X",  ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->ReturnCode);
-	}
-	return DevNode->ReturnCode;
-}
+
 int iSeries_pci_write_config_byte( struct pci_dev* PciDev,int Offset, u8 WriteValue)
 {
 	struct iSeries_Device_Node* DevNode = get_Device_Node(PciDev);
 	if(DevNode == NULL) return 0x0301;
 	return iSeries_Node_write_config_byte( DevNode,Offset,WriteValue);
 }
-int iSeries_pci_write_config_word( struct pci_dev* PciDev,int Offset,u16 WriteValue)
+#endif
+
+static int iSeries_pci_write_config(struct pci_bus *bus, unsigned int devfn,
+		int offset, int size, u32 val)
 {
-	struct iSeries_Device_Node* DevNode = get_Device_Node(PciDev);
-	if(DevNode == NULL) return 0x0301;
-	return iSeries_Node_write_config_word( DevNode,Offset,WriteValue);
-}
-int iSeries_pci_write_config_dword(struct pci_dev* PciDev,int Offset,u32 WriteValue)
-{
-	struct iSeries_Device_Node* DevNode = get_Device_Node(PciDev);
-	if(DevNode == NULL) return 0x0301;
-	return iSeries_Node_write_config_dword(DevNode,Offset,WriteValue);
+	return PCIBIOS_DEVICE_NOT_FOUND;
 }
 
-/************************************************************************/
-/* Branch Table                                                         */
-/************************************************************************/
 struct pci_ops iSeries_pci_ops = {
-	iSeries_pci_read_config_byte,
-	iSeries_pci_read_config_word,
-	iSeries_pci_read_config_dword,
-	iSeries_pci_write_config_byte,
-	iSeries_pci_write_config_word,
-	iSeries_pci_write_config_dword 
+	.read = iSeries_pci_read_config,
+	.write = iSeries_pci_write_config
 };
 
-/************************************************************************
+/*
  * Check Return Code
  * -> On Failure, print and log information.
  *    Increment Retry Count, if exceeds max, panic partition.
  * -> If in retry, print and log success 
- ************************************************************************
+ *
  * PCI: Device 23.90 ReadL I/O Error( 0): 0x1234
  * PCI: Device 23.90 ReadL Retry( 1)
  * PCI: Device 23.90 ReadL Retry Successful(1)
- ************************************************************************/
-int  CheckReturnCode(char* TextHdr, struct iSeries_Device_Node* DevNode, u64 RtnCode)
+ */
+int CheckReturnCode(char *TextHdr, struct iSeries_Device_Node *DevNode,
+		u64 RtnCode)
 {
-	if(RtnCode != 0)  {
+	if (RtnCode != 0)  {
 		++Pci_Error_Count;
 		++DevNode->IoRetry;
-		PCIFR(      "%s: Device 0x%04X:%02X  I/O Error(%2d): 0x%04X",
-			    TextHdr,ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->IoRetry,(int)RtnCode);
+		PCIFR("%s: Device 0x%04X:%02X  I/O Error(%2d): 0x%04X",
+				TextHdr, ISERIES_BUS(DevNode), DevNode->DevFn,
+				DevNode->IoRetry, (int)RtnCode);
 		printk("PCI: %s: Device 0x%04X:%02X  I/O Error(%2d): 0x%04X\n",
-		            TextHdr,ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->IoRetry,(int)RtnCode);
-		/*******************************************************/
-		/* Bump the retry and check for retry count exceeded.  */
-		/* If, Exceeded, panic the system.                     */           
-		/*******************************************************/
-		if(DevNode->IoRetry > Pci_Retry_Max && Pci_Error_Flag > 0 ) {
+				TextHdr, ISERIES_BUS(DevNode), DevNode->DevFn,
+				DevNode->IoRetry, (int)RtnCode);
+		/*
+		 * Bump the retry and check for retry count exceeded.
+		 * If, Exceeded, panic the system.
+		 */
+		if ((DevNode->IoRetry > Pci_Retry_Max) &&
+				(Pci_Error_Flag > 0)) {
 			mf_displaySrc(0xB6000103);
 			panic_timeout = 0; 
-			panic("PCI: Hardware I/O Error, SRC B6000103, Automatic Reboot Disabled.\n");
+			panic("PCI: Hardware I/O Error, SRC B6000103, "
+					"Automatic Reboot Disabled.\n");
 		}
 		return -1;	/* Retry Try */
 	}
-	/********************************************************************
-	* If retry was in progress, log success and rest retry count        *
-	*********************************************************************/
-	else if(DevNode->IoRetry > 0) {
+	/* If retry was in progress, log success and rest retry count */
+	if (DevNode->IoRetry > 0) {
 		PCIFR("%s: Device 0x%04X:%02X Retry Successful(%2d).",
-		      TextHdr,ISERIES_BUS(DevNode),DevNode->DevFn,DevNode->IoRetry);
+				TextHdr, ISERIES_BUS(DevNode), DevNode->DevFn,
+				DevNode->IoRetry);
 		DevNode->IoRetry = 0;
-		return 0; 
 	}
 	return 0; 
 }
-/************************************************************************/
-/* Translate the I/O Address into a device node, bar, and bar offset.   */
-/* Note: Make sure the passed variable end up on the stack to avoid     */
-/* the exposure of being device global.                                 */
-/************************************************************************/
-static inline struct iSeries_Device_Node* xlateIoMmAddress(void* IoAddress,
-							    union HvDsaMap* DsaPtr,
-							   u64* BarOffsetPtr) {
-
-	unsigned long BaseIoAddr = (unsigned long)IoAddress-iSeries_Base_Io_Memory;
-	long          TableIndex = BaseIoAddr/iSeries_IoMmTable_Entry_Size;
-	struct iSeries_Device_Node* DevNode = *(iSeries_IoMmTable +TableIndex);
-	if(DevNode != NULL) {
-		DsaPtr->DsaAddr       = ISERIES_DSA(DevNode);
-		DsaPtr->Dsa.barNumber = *(iSeries_IoBarTable+TableIndex);
-		*BarOffsetPtr         = BaseIoAddr % iSeries_IoMmTable_Entry_Size;
-	}
-	else {
+
+/*
+ * Translate the I/O Address into a device node, bar, and bar offset.
+ * Note: Make sure the passed variable end up on the stack to avoid
+ * the exposure of being device global.
+ */
+static inline struct iSeries_Device_Node *xlateIoMmAddress(void *IoAddress,
+		union HvDsaMap *DsaPtr, u64 *BarOffsetPtr)
+{
+	unsigned long BaseIoAddr =
+		(unsigned long)IoAddress - iSeries_Base_Io_Memory;
+	long TableIndex = BaseIoAddr / iSeries_IoMmTable_Entry_Size;
+	struct iSeries_Device_Node *DevNode = *(iSeries_IoMmTable + TableIndex);
+
+	if (DevNode != NULL) {
+		DsaPtr->DsaAddr = ISERIES_DSA(DevNode);
+		DsaPtr->Dsa.barNumber = *(iSeries_IoBarTable + TableIndex);
+		*BarOffsetPtr = BaseIoAddr % iSeries_IoMmTable_Entry_Size;
+	} else
 		panic("PCI: Invalid PCI IoAddress detected!\n");
-	}
 	return DevNode;
 }
 
-/************************************************************************/
-/* Read MM I/O Instructions for the iSeries                             */
-/* On MM I/O error, all ones are returned and iSeries_pci_IoError is cal*/
-/* else, data is returned in big Endian format.                         */
-/************************************************************************/
-/* iSeries_Read_Byte = Read Byte  ( 8 bit)                              */
-/* iSeries_Read_Word = Read Word  (16 bit)                              */
-/* iSeries_Read_Long = Read Long  (32 bit)                              */
-/************************************************************************/
-u8  iSeries_Read_Byte(void* IoAddress)
+/*
+ * Read MM I/O Instructions for the iSeries
+ * On MM I/O error, all ones are returned and iSeries_pci_IoError is cal
+ * else, data is returned in big Endian format.
+ *
+ * iSeries_Read_Byte = Read Byte  ( 8 bit)
+ * iSeries_Read_Word = Read Word  (16 bit)
+ * iSeries_Read_Long = Read Long  (32 bit)
+ */
+u8 iSeries_Read_Byte(void *IoAddress)
 {
-	u64    BarOffset;
-	union  HvDsaMap DsaData;
+	u64 BarOffset;
+	union HvDsaMap DsaData;
 	struct HvCallPci_LoadReturn Return;
-	struct iSeries_Device_Node* DevNode = xlateIoMmAddress(IoAddress,&DsaData,&BarOffset);
+	struct iSeries_Device_Node *DevNode =
+		xlateIoMmAddress(IoAddress, &DsaData, &BarOffset);
 
 	do {
 		++Pci_Io_Read_Count;
-		HvCall3Ret16(HvCallPciBarLoad8, &Return, DsaData.DsaAddr,BarOffset, 0);
-	} while (CheckReturnCode("RDB",DevNode, Return.rc) != 0);
-
-	if(Pci_Trace_Flag == 1)	PCIFR("RDB: IoAddress 0x%p = 0x%02X",IoAddress, (u8)Return.value); 
+		HvCall3Ret16(HvCallPciBarLoad8, &Return, DsaData.DsaAddr,
+				BarOffset, 0);
+	} while (CheckReturnCode("RDB", DevNode, Return.rc) != 0);
+
+	if (Pci_Trace_Flag == 1)
+		PCIFR("RDB: IoAddress 0x%p = 0x%02X", IoAddress,
+				(u8)Return.value); 
 	return (u8)Return.value;
 }
-u16  iSeries_Read_Word(void* IoAddress)
+
+u16 iSeries_Read_Word(void *IoAddress)
 {
-	u64    BarOffset;
-	union  HvDsaMap DsaData;
+	u64 BarOffset;
+	union HvDsaMap DsaData;
 	struct HvCallPci_LoadReturn Return;
-	struct iSeries_Device_Node* DevNode = xlateIoMmAddress(IoAddress,&DsaData,&BarOffset);
+	struct iSeries_Device_Node *DevNode =
+		xlateIoMmAddress(IoAddress, &DsaData, &BarOffset);
 
 	do {
 		++Pci_Io_Read_Count;
-		HvCall3Ret16(HvCallPciBarLoad16,&Return, DsaData.DsaAddr,BarOffset, 0);
-	} while (CheckReturnCode("RDW",DevNode, Return.rc) != 0);
-
-	if(Pci_Trace_Flag == 1) PCIFR("RDW: IoAddress 0x%p = 0x%04X",IoAddress, swab16((u16)Return.value));
+		HvCall3Ret16(HvCallPciBarLoad16, &Return, DsaData.DsaAddr,
+				BarOffset, 0);
+	} while (CheckReturnCode("RDW", DevNode, Return.rc) != 0);
+
+	if (Pci_Trace_Flag == 1)
+		PCIFR("RDW: IoAddress 0x%p = 0x%04X", IoAddress,
+				swab16((u16)Return.value));
 	return swab16((u16)Return.value);
 }
-u32  iSeries_Read_Long(void* IoAddress)
+
+u32 iSeries_Read_Long(void *IoAddress)
 {
-	u64    BarOffset;
-	union  HvDsaMap DsaData;
+	u64 BarOffset;
+	union HvDsaMap DsaData;
 	struct HvCallPci_LoadReturn Return;
-	struct iSeries_Device_Node* DevNode = xlateIoMmAddress(IoAddress,&DsaData,&BarOffset);
+	struct iSeries_Device_Node *DevNode =
+		xlateIoMmAddress(IoAddress, &DsaData, &BarOffset);
 
 	do {
 		++Pci_Io_Read_Count;
-		HvCall3Ret16(HvCallPciBarLoad32,&Return, DsaData.DsaAddr,BarOffset, 0);
-	} while (CheckReturnCode("RDL",DevNode, Return.rc) != 0);
-
-	if(Pci_Trace_Flag == 1) PCIFR("RDL: IoAddress 0x%p = 0x%04X",IoAddress, swab32((u32)Return.value));
+		HvCall3Ret16(HvCallPciBarLoad32, &Return, DsaData.DsaAddr,
+				BarOffset, 0);
+	} while (CheckReturnCode("RDL", DevNode, Return.rc) != 0);
+
+	if (Pci_Trace_Flag == 1)
+		PCIFR("RDL: IoAddress 0x%p = 0x%04X", IoAddress,
+				swab32((u32)Return.value));
 	return swab32((u32)Return.value);
 }
-/************************************************************************/
-/* Write MM I/O Instructions for the iSeries                            */
-/************************************************************************/
-/* iSeries_Write_Byte = Write Byte (8 bit)                              */
-/* iSeries_Write_Word = Write Word(16 bit)                              */
-/* iSeries_Write_Long = Write Long(32 bit)                              */
-/************************************************************************/
-void iSeries_Write_Byte(u8 Data, void* IoAddress)
+
+/*
+ * Write MM I/O Instructions for the iSeries
+ *
+ * iSeries_Write_Byte = Write Byte (8 bit)
+ * iSeries_Write_Word = Write Word(16 bit)
+ * iSeries_Write_Long = Write Long(32 bit)
+ */
+void iSeries_Write_Byte(u8 Data, void *IoAddress)
 {
-	u64    BarOffset;
-	union  HvDsaMap DsaData;
+	u64 BarOffset;
+	union HvDsaMap DsaData;
 	struct HvCallPci_LoadReturn Return;
-	struct iSeries_Device_Node* DevNode = xlateIoMmAddress(IoAddress,&DsaData,&BarOffset);
+	struct iSeries_Device_Node *DevNode =
+		xlateIoMmAddress(IoAddress, &DsaData, &BarOffset);
 
 	do {
 		++Pci_Io_Write_Count;
-		Return.rc = HvCall4(HvCallPciBarStore8, DsaData.DsaAddr,BarOffset, Data, 0);
-	} while (CheckReturnCode("WWB",DevNode, Return.rc) != 0);
-	if(Pci_Trace_Flag == 1) PCIFR("WWB: IoAddress 0x%p = 0x%02X",IoAddress,Data);
+		Return.rc = HvCall4(HvCallPciBarStore8, DsaData.DsaAddr,
+				BarOffset, Data, 0);
+	} while (CheckReturnCode("WWB", DevNode, Return.rc) != 0);
+	if (Pci_Trace_Flag == 1)
+		PCIFR("WWB: IoAddress 0x%p = 0x%02X", IoAddress, Data);
 }
-void iSeries_Write_Word(u16 Data, void* IoAddress)
+
+void iSeries_Write_Word(u16 Data, void *IoAddress)
 {
-	u64    BarOffset;
-	union  HvDsaMap DsaData;
+	u64 BarOffset;
+	union HvDsaMap DsaData;
 	struct HvCallPci_LoadReturn Return;
-	struct iSeries_Device_Node* DevNode = xlateIoMmAddress(IoAddress,&DsaData,&BarOffset);
+	struct iSeries_Device_Node *DevNode =
+		xlateIoMmAddress(IoAddress, &DsaData, &BarOffset);
 
 	do {
 		++Pci_Io_Write_Count;
-		Return.rc = HvCall4(HvCallPciBarStore16,DsaData.DsaAddr,BarOffset, swab16(Data), 0);
-	} while (CheckReturnCode("WWW",DevNode, Return.rc) != 0);
-	if(Pci_Trace_Flag == 1) PCIFR("WWW: IoAddress 0x%p = 0x%04X",IoAddress,Data);
+		Return.rc = HvCall4(HvCallPciBarStore16, DsaData.DsaAddr,
+				BarOffset, swab16(Data), 0);
+	} while (CheckReturnCode("WWW", DevNode, Return.rc) != 0);
+	if (Pci_Trace_Flag == 1)
+		PCIFR("WWW: IoAddress 0x%p = 0x%04X", IoAddress, Data);
 }
-void iSeries_Write_Long(u32 Data, void* IoAddress)
+
+void iSeries_Write_Long(u32 Data, void *IoAddress)
 {
-	u64    BarOffset;
-	union  HvDsaMap DsaData;
+	u64 BarOffset;
+	union HvDsaMap DsaData;
 	struct HvCallPci_LoadReturn Return;
-	struct iSeries_Device_Node* DevNode = xlateIoMmAddress(IoAddress,&DsaData,&BarOffset);
+	struct iSeries_Device_Node *DevNode =
+		xlateIoMmAddress(IoAddress, &DsaData, &BarOffset);
 
 	do {
 		++Pci_Io_Write_Count;
-		Return.rc = HvCall4(HvCallPciBarStore32,DsaData.DsaAddr,BarOffset, swab32(Data), 0);
-	} while (CheckReturnCode("WWL",DevNode, Return.rc) != 0);
-	if(Pci_Trace_Flag == 1) PCIFR("WWL: IoAddress 0x%p = 0x%08X",IoAddress, Data);
+		Return.rc = HvCall4(HvCallPciBarStore32, DsaData.DsaAddr,
+				BarOffset, swab32(Data), 0);
+	} while (CheckReturnCode("WWL", DevNode, Return.rc) != 0);
+	if (Pci_Trace_Flag == 1)
+		PCIFR("WWL: IoAddress 0x%p = 0x%08X", IoAddress, Data);
+}
+
+void pcibios_name_device(struct pci_dev *dev)
+{
 }
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_pci_reset.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_pci_reset.c
--- linux-2.5/arch/ppc64/kernel/iSeries_pci_reset.c	2002-06-10 03:44:23.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_pci_reset.c	2003-11-21 06:45:02.000000000 +0000
@@ -1,3 +1,4 @@
+#define PCIFR(...)
 /************************************************************************/
 /* File iSeries_pci_reset.c created by Allan Trautman on Mar 21 2001.   */
 /************************************************************************/
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_proc.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_proc.c
--- linux-2.5/arch/ppc64/kernel/iSeries_proc.c	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_proc.c	2003-11-21 06:45:02.000000000 +0000
@@ -27,9 +27,8 @@
 #include <asm/iSeries/iSeries_proc.h>
 #endif
 
-
-static struct proc_dir_entry * iSeries_proc_root = NULL;
-static int iSeries_proc_initializationDone = 0;
+static struct proc_dir_entry *iSeries_proc_root;
+static int iSeries_proc_initializationDone;
 static spinlock_t iSeries_proc_lock;
 
 struct iSeries_proc_registration
@@ -96,21 +95,22 @@ void iSeries_proc_create(void)
 {
 	unsigned long flags;
 	struct iSeries_proc_registration *reg = NULL;
-	spin_lock_irqsave(&iSeries_proc_lock, flags);
+
 	printk("iSeries_proc: Creating /proc/iSeries\n");
 
+	spin_lock_irqsave(&iSeries_proc_lock, flags);
 	iSeries_proc_root = proc_mkdir("iSeries", 0);
-	if (!iSeries_proc_root) return;
+	if (!iSeries_proc_root)
+		goto out;
 
 	MYQUEUEDEQ(&iSeries_queued, reg);
-
 	while (reg != NULL) {
 		(*(reg->functionMember))(iSeries_proc_root);
-
 		MYQUEUEDEQ(&iSeries_queued, reg);
 	}
 
 	iSeries_proc_initializationDone = 1;
+out:
 	spin_unlock_irqrestore(&iSeries_proc_lock, flags);
 }
 
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_setup.c linuxppc64-2.5/arch/ppc64/kernel/iSeries_setup.c
--- linux-2.5/arch/ppc64/kernel/iSeries_setup.c	2003-07-28 04:00:17.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_setup.c	2003-11-21 06:45:02.000000000 +0000
@@ -25,6 +25,8 @@
 #include <linux/bootmem.h>
 #include <linux/initrd.h>
 #include <linux/seq_file.h>
+#include <linux/kdev_t.h>
+#include <linux/major.h>
 #include <linux/root_dev.h>
 
 #include <asm/processor.h>
@@ -53,34 +55,34 @@
 #include <asm/iSeries/mf.h>
 
 /* Function Prototypes */
-
 extern void abort(void);
-#ifdef CONFIG_PPC_ISERIES
-static void build_iSeries_Memory_Map( void );
-static void setup_iSeries_cache_sizes( void );
-static void iSeries_bolt_kernel(unsigned long saddr, unsigned long eaddr);
-#endif
-void build_valid_hpte( unsigned long vsid, unsigned long ea, unsigned long pa,
-		       pte_t * ptep, unsigned hpteflags, unsigned bolted );
 extern void ppcdbg_initialize(void);
 extern void iSeries_pcibios_init(void);
+
+static void build_iSeries_Memory_Map(void);
+static void setup_iSeries_cache_sizes(void);
+static void iSeries_bolt_kernel(unsigned long saddr, unsigned long eaddr);
+void build_valid_hpte(unsigned long vsid, unsigned long ea, unsigned long pa,
+		pte_t *ptep, unsigned hpteflags, unsigned bolted);
 static void iSeries_setup_dprofile(void);
+void iSeries_setup_arch(void);
 
 /* Global Variables */
+static unsigned long procFreqHz;
+static unsigned long procFreqMhz;
+static unsigned long procFreqMhzHundreths;
+
+static unsigned long tbFreqHz;
+static unsigned long tbFreqMhz;
+static unsigned long tbFreqMhzHundreths;
 
-static unsigned long procFreqHz = 0;
-static unsigned long procFreqMhz = 0;
-static unsigned long procFreqMhzHundreths = 0;
-
-static unsigned long tbFreqHz = 0;
-static unsigned long tbFreqMhz = 0;
-static unsigned long tbFreqMhzHundreths = 0;
-
-unsigned long dprof_shift = 0;
-unsigned long dprof_len = 0;
-unsigned int * dprof_buffer = NULL;
+unsigned long dprof_shift;
+unsigned long dprof_len;
+unsigned int *dprof_buffer;
 
-int piranha_simulator = 0;
+int piranha_simulator;
+
+int boot_cpuid;
 
 extern char _end[];
 
@@ -92,7 +94,7 @@ extern unsigned long embedded_sysmap_end
 extern unsigned long iSeries_recal_tb;
 extern unsigned long iSeries_recal_titan;
 
-static int mf_initialized = 0;
+static int mf_initialized;
 
 struct MemoryBlock {
 	unsigned long absStart;
@@ -106,30 +108,30 @@ struct MemoryBlock {
  * and return the number of physical blocks and fill in the array of
  * block data.
  */
-
-unsigned long iSeries_process_Condor_mainstore_vpd( struct MemoryBlock *mb_array, unsigned long max_entries )
+unsigned long iSeries_process_Condor_mainstore_vpd(struct MemoryBlock *mb_array,
+		unsigned long max_entries)
 {
-	/* Determine if absolute memory has any
-	 * holes so that we can interpret the
-	 * access map we get back from the hypervisor
-	 * correctly.
-	 */
-	
 	unsigned long holeFirstChunk, holeSizeChunks;
 	unsigned long numMemoryBlocks = 1;
-	struct IoHriMainStoreSegment4 * msVpd = (struct IoHriMainStoreSegment4 *)xMsVpd;
+	struct IoHriMainStoreSegment4 *msVpd =
+		(struct IoHriMainStoreSegment4 *)xMsVpd;
 	unsigned long holeStart = msVpd->nonInterleavedBlocksStartAdr;
-	unsigned long holeEnd   = msVpd->nonInterleavedBlocksEndAdr;
+	unsigned long holeEnd = msVpd->nonInterleavedBlocksEndAdr;
 	unsigned long holeSize = holeEnd - holeStart;
 
 	printk("Mainstore_VPD: Condor\n");
-
+	/*
+	 * Determine if absolute memory has any
+	 * holes so that we can interpret the
+	 * access map we get back from the hypervisor
+	 * correctly.
+	 */
 	mb_array[0].logicalStart = 0;
-	mb_array[0].logicalEnd   = 0x100000000;
-	mb_array[0].absStart     = 0;
-	mb_array[0].absEnd       = 0x100000000;
+	mb_array[0].logicalEnd = 0x100000000;
+	mb_array[0].absStart = 0;
+	mb_array[0].absEnd = 0x100000000;
 
-	if ( holeSize ) {
+	if (holeSize) {
 		numMemoryBlocks = 2;
 		holeStart = holeStart & 0x000fffffffffffff;
 		holeStart = addr_to_chunk(holeStart);
@@ -138,275 +140,264 @@ unsigned long iSeries_process_Condor_mai
 		holeSizeChunks = holeSize;
 		printk( "Main store hole: start chunk = %0lx, size = %0lx chunks\n",
 				holeFirstChunk, holeSizeChunks );
-		mb_array[0].logicalEnd   = holeFirstChunk;
-		mb_array[0].absEnd       = holeFirstChunk;
+		mb_array[0].logicalEnd = holeFirstChunk;
+		mb_array[0].absEnd = holeFirstChunk;
 		mb_array[1].logicalStart = holeFirstChunk;
-		mb_array[1].logicalEnd   = 0x100000000 - holeSizeChunks;
-		mb_array[1].absStart     = holeFirstChunk + holeSizeChunks;
-		mb_array[1].absEnd       = 0x100000000;
+		mb_array[1].logicalEnd = 0x100000000 - holeSizeChunks;
+		mb_array[1].absStart = holeFirstChunk + holeSizeChunks;
+		mb_array[1].absEnd = 0x100000000;
 	}
-
-	
 	return numMemoryBlocks;
 }
 
-#define MaxSegmentAreas 32
-#define MaxSegmentAdrRangeBlocks 128
-#define MaxAreaRangeBlocks 4
-unsigned long iSeries_process_Regatta_mainstore_vpd( struct MemoryBlock *mb_array, unsigned long max_entries )
+#define MaxSegmentAreas			32
+#define MaxSegmentAdrRangeBlocks	128
+#define MaxAreaRangeBlocks		4
+
+unsigned long iSeries_process_Regatta_mainstore_vpd(
+		struct MemoryBlock *mb_array, unsigned long max_entries)
 {
-	struct IoHriMainStoreSegment5 * msVpdP = (struct IoHriMainStoreSegment5 *)xMsVpd;
+	struct IoHriMainStoreSegment5 *msVpdP =
+		(struct IoHriMainStoreSegment5 *)xMsVpd;
 	unsigned long numSegmentBlocks = 0;
 	u32 existsBits = msVpdP->msAreaExists;
 	unsigned long area_num;
 
 	printk("Mainstore_VPD: Regatta\n");
 
-	for ( area_num = 0; area_num < MaxSegmentAreas; ++area_num ) {
+	for (area_num = 0; area_num < MaxSegmentAreas; ++area_num ) {
 		unsigned long numAreaBlocks;
-		struct IoHriMainStoreArea4 * currentArea;
+		struct IoHriMainStoreArea4 *currentArea;
 
-		if ( existsBits & 0x80000000 ) {
+		if (existsBits & 0x80000000) {
 			unsigned long block_num;
 
 			currentArea = &msVpdP->msAreaArray[area_num];
 			numAreaBlocks = currentArea->numAdrRangeBlocks;
-
-			printk("ms_vpd: processing area %2ld  blocks=%ld", area_num, numAreaBlocks);
-
-			for ( block_num = 0; block_num < numAreaBlocks; ++block_num ) {
+			printk("ms_vpd: processing area %2ld  blocks=%ld",
+					area_num, numAreaBlocks);
+			for (block_num = 0; block_num < numAreaBlocks;
+					++block_num ) {
 				/* Process an address range block */
 				struct MemoryBlock tempBlock;
 				unsigned long i;
 
-				tempBlock.absStart = (unsigned long)currentArea->xAdrRangeBlock[block_num].blockStart;
-				tempBlock.absEnd   = (unsigned long)currentArea->xAdrRangeBlock[block_num].blockEnd;
+				tempBlock.absStart =
+					(unsigned long)currentArea->xAdrRangeBlock[block_num].blockStart;
+				tempBlock.absEnd =
+					(unsigned long)currentArea->xAdrRangeBlock[block_num].blockEnd;
 				tempBlock.logicalStart = 0;
 				tempBlock.logicalEnd   = 0;
-
-				printk("\n          block %ld absStart=%016lx absEnd=%016lx", block_num,
-							tempBlock.absStart, tempBlock.absEnd);
-
-				for ( i=0; i<numSegmentBlocks; ++i ) {
-					if ( mb_array[i].absStart == tempBlock.absStart )
+				printk("\n          block %ld absStart=%016lx absEnd=%016lx",
+						block_num, tempBlock.absStart,
+						tempBlock.absEnd);
+
+				for (i = 0; i < numSegmentBlocks; ++i) {
+					if (mb_array[i].absStart ==
+							tempBlock.absStart)
 						break;
 				}
-				if ( i == numSegmentBlocks ) {
-					if ( numSegmentBlocks == max_entries ) {
+				if (i == numSegmentBlocks) {
+					if (numSegmentBlocks == max_entries)
 						panic("iSeries_process_mainstore_vpd: too many memory blocks");
-					}
 					mb_array[numSegmentBlocks] = tempBlock;
 					++numSegmentBlocks;
-				}
-				else {
+				} else
 					printk(" (duplicate)");
-				}
 			}
 			printk("\n");
 		}
 		existsBits <<= 1;
 	}
 	/* Now sort the blocks found into ascending sequence */
-	if ( numSegmentBlocks > 1 ) {
+	if (numSegmentBlocks > 1) {
 		unsigned long m, n;
-		for ( m=0; m<numSegmentBlocks-1; ++m ) {
-			for ( n=numSegmentBlocks-1; m<n; --n ) {
-				if ( mb_array[n].absStart < mb_array[n-1].absStart ) {
+
+		for (m = 0; m < numSegmentBlocks - 1; ++m) {
+			for (n = numSegmentBlocks - 1; m < n; --n) {
+				if (mb_array[n].absStart <
+						mb_array[n-1].absStart) {
 					struct MemoryBlock tempBlock;
+
 					tempBlock = mb_array[n];
 					mb_array[n] = mb_array[n-1];
 					mb_array[n-1] = tempBlock;
 				}
-				
 			}
 		}
 	}
-	/* Assign "logical" addresses to each block.  These
+	/*
+	 * Assign "logical" addresses to each block.  These
 	 * addresses correspond to the hypervisor "bitmap" space.
 	 * Convert all addresses into units of 256K chunks.
 	 */
 	{
 	unsigned long i, nextBitmapAddress;
+
 	printk("ms_vpd: %ld sorted memory blocks\n", numSegmentBlocks);
 	nextBitmapAddress = 0;
-	for ( i=0; i<numSegmentBlocks; ++i ) {
-		unsigned long length = mb_array[i].absEnd - mb_array[i].absStart;
+	for (i = 0; i < numSegmentBlocks; ++i) {
+		unsigned long length = mb_array[i].absEnd -
+			mb_array[i].absStart;
+
 		mb_array[i].logicalStart = nextBitmapAddress;
 		mb_array[i].logicalEnd = nextBitmapAddress + length;
 		nextBitmapAddress += length;
 		printk("          Bitmap range: %016lx - %016lx\n"
-		       "        Absolute range: %016lx - %016lx\n",
-				mb_array[i].logicalStart, mb_array[i].logicalEnd, 
+				"        Absolute range: %016lx - %016lx\n",
+				mb_array[i].logicalStart,
+				mb_array[i].logicalEnd, 
 				mb_array[i].absStart, mb_array[i].absEnd);
-		mb_array[i].absStart     = addr_to_chunk( mb_array[i].absStart & 0x000fffffffffffff );
-		mb_array[i].absEnd       = addr_to_chunk( mb_array[i].absEnd & 0x000fffffffffffff );
-		mb_array[i].logicalStart = addr_to_chunk( mb_array[i].logicalStart );
-		mb_array[i].logicalEnd   = addr_to_chunk( mb_array[i].logicalEnd );
+		mb_array[i].absStart = addr_to_chunk(mb_array[i].absStart &
+				0x000fffffffffffff);
+		mb_array[i].absEnd = addr_to_chunk(mb_array[i].absEnd &
+				0x000fffffffffffff);
+		mb_array[i].logicalStart =
+			addr_to_chunk(mb_array[i].logicalStart);
+		mb_array[i].logicalEnd = addr_to_chunk(mb_array[i].logicalEnd);
 	}
 	}
 
 	return numSegmentBlocks;
-
 }
 
-unsigned long iSeries_process_mainstore_vpd( struct MemoryBlock *mb_array, unsigned long max_entries )
+unsigned long iSeries_process_mainstore_vpd(struct MemoryBlock *mb_array,
+		unsigned long max_entries)
 {
 	unsigned long i;
 	unsigned long mem_blocks = 0;
+
 	if (cur_cpu_spec->cpu_features & CPU_FTR_SLB)
-		mem_blocks = iSeries_process_Regatta_mainstore_vpd( mb_array, max_entries );
+		mem_blocks = iSeries_process_Regatta_mainstore_vpd(mb_array,
+				max_entries);
 	else
-		mem_blocks = iSeries_process_Condor_mainstore_vpd( mb_array, max_entries );
+		mem_blocks = iSeries_process_Condor_mainstore_vpd(mb_array,
+				max_entries);
 
 	printk("Mainstore_VPD: numMemoryBlocks = %ld \n", mem_blocks);
-	for ( i=0; i<mem_blocks; ++i ) {
+	for (i = 0; i < mem_blocks; ++i) {
 		printk("Mainstore_VPD: block %3ld logical chunks %016lx - %016lx\n"
 		       "                             abs chunks %016lx - %016lx\n",
 			i, mb_array[i].logicalStart, mb_array[i].logicalEnd,
 			mb_array[i].absStart, mb_array[i].absEnd);
 	}
-
 	return mem_blocks;
 }
 
-/*
- * void __init iSeries_init_early()
- */
-
-
-
-void __init
-iSeries_init_early(void)
+void __init iSeries_init_early(void)
 {
-#ifdef CONFIG_PPC_ISERIES
 	ppcdbg_initialize();
-	
+
 #if defined(CONFIG_BLK_DEV_INITRD)
 	/*
 	 * If the init RAM disk has been configured and there is
 	 * a non-zero starting address for it, set it up
 	 */
-
-	if ( naca->xRamDisk ) {
+	if (naca->xRamDisk) {
 		initrd_start = (unsigned long)__va(naca->xRamDisk);
-		initrd_end   = initrd_start + naca->xRamDiskSize * PAGE_SIZE;
+		initrd_end = initrd_start + naca->xRamDiskSize * PAGE_SIZE;
 		initrd_below_start_ok = 1;	// ramdisk in kernel space
 		ROOT_DEV = Root_RAM0;
-
-		if ( ((rd_size*1024)/PAGE_SIZE) < naca->xRamDiskSize )
-			rd_size = (naca->xRamDiskSize*PAGE_SIZE)/1024;
+		if (((rd_size * 1024) / PAGE_SIZE) < naca->xRamDiskSize)
+			rd_size = (naca->xRamDiskSize * PAGE_SIZE) / 1024;
 	} else
-	
 #endif /* CONFIG_BLK_DEV_INITRD */
-	  {
-                
-	    /*		ROOT_DEV = MKDEV( VIODASD_MAJOR, 1 ); */
-	  }
+	{
+	    /* ROOT_DEV = MKDEV(VIODASD_MAJOR, 1); */
+	}
 
 	iSeries_recal_tb = get_tb();
 	iSeries_recal_titan = HvCallXm_loadTod();
 
-	ppc_md.setup_arch	 	= iSeries_setup_arch;
-	ppc_md.setup_residual	 	= iSeries_setup_residual;
-	ppc_md.get_cpuinfo	 	= iSeries_get_cpuinfo;
-	ppc_md.init_IRQ		 	= iSeries_init_IRQ;
-	ppc_md.get_irq		 	= iSeries_get_irq;
-	ppc_md.init		 	= NULL;
-
-	ppc_md.restart		 	= iSeries_restart;
-	ppc_md.power_off	 	= iSeries_power_off;
-	ppc_md.halt		 	= iSeries_halt;
-
-	ppc_md.get_boot_time		= iSeries_get_boot_time;
-	ppc_md.set_rtc_time	 	= iSeries_set_rtc_time;
-	ppc_md.get_rtc_time	 	= iSeries_get_rtc_time;
-	ppc_md.calibrate_decr	 	= iSeries_calibrate_decr;
-	ppc_md.progress			= iSeries_progress;
+	ppc_md.setup_arch = iSeries_setup_arch;
+	ppc_md.setup_residual = iSeries_setup_residual;
+	ppc_md.get_cpuinfo = iSeries_get_cpuinfo;
+	ppc_md.init_IRQ = iSeries_init_IRQ;
+	ppc_md.init_irq_desc = iSeries_init_irq_desc;
+	ppc_md.get_irq = iSeries_get_irq;
+	ppc_md.init = NULL;
+
+	ppc_md.restart = iSeries_restart;
+	ppc_md.power_off = iSeries_power_off;
+	ppc_md.halt = iSeries_halt;
+
+	ppc_md.get_boot_time = iSeries_get_boot_time;
+	ppc_md.set_rtc_time = iSeries_set_rtc_time;
+	ppc_md.get_rtc_time = iSeries_get_rtc_time;
+	ppc_md.calibrate_decr = iSeries_calibrate_decr;
+	ppc_md.progress = iSeries_progress;
 
 	hpte_init_iSeries();
 	tce_init_iSeries();
 
-	/* Initialize the table which translate Linux physical addresses to
+	/*
+	 * Initialize the table which translate Linux physical addresses to
 	 * AS/400 absolute addresses
 	 */
-
 	build_iSeries_Memory_Map();
-
 	setup_iSeries_cache_sizes();
-
 	/* Initialize machine-dependency vectors */
-
-
 #ifdef CONFIG_SMP
 	smp_init_iSeries();
 #endif
-
-	if ( itLpNaca.xPirEnvironMode == 0 ) 
+	if (itLpNaca.xPirEnvironMode == 0) 
 		piranha_simulator = 1;
-#endif
 }
 
-/*
- * void __init iSeries_init()
- */
-
-void __init
-iSeries_init(unsigned long r3, unsigned long r4, unsigned long r5, 
+void __init iSeries_init(unsigned long r3, unsigned long r4, unsigned long r5, 
 	   unsigned long r6, unsigned long r7)
 {
+	char *p, *q;
+
 	/* Associate Lp Event Queue 0 with processor 0 */
-	HvCallEvent_setLpEventQueueInterruptProc( 0, 0 );
+	HvCallEvent_setLpEventQueueInterruptProc(0, 0);
 
-	{
-		/* copy the command line parameter from the primary VSP  */
-		char *p, *q;
-		HvCallEvent_dmaToSp( cmd_line,
-				     2*64*1024,
-				     256,
-				     HvLpDma_Direction_RemoteToLocal );
-
-		p = q = cmd_line + 255;
-		while( p > cmd_line ) {
-			if ((*p == 0) || (*p == ' ') || (*p == '\n'))
-				--p;
-			else
-				break;
-		}
-		if ( p < q )
-			*(p+1) = 0;
+	/* copy the command line parameter from the primary VSP  */
+	HvCallEvent_dmaToSp(cmd_line, 2 * 64* 1024, 256,
+			HvLpDma_Direction_RemoteToLocal);
+
+	p = q = cmd_line + 255;
+	while (p > cmd_line) {
+		if ((*p == 0) || (*p == ' ') || (*p == '\n'))
+			--p;
+		else
+			break;
 	}
+	if (p < q)
+		*(p + 1) = 0;
 
         if (strstr(cmd_line, "dprofile=")) {
-                char *p, *q;
-
                 for (q = cmd_line; (p = strstr(q, "dprofile=")) != 0; ) {
 			unsigned long size, new_klimit;
+
                         q = p + 9;
-                        if (p > cmd_line && p[-1] != ' ')
+                        if ((p > cmd_line) && (p[-1] != ' '))
                                 continue;
                         dprof_shift = simple_strtoul(q, &q, 0);
-			dprof_len = (unsigned long)_etext - (unsigned long)_stext;
+			dprof_len = (unsigned long)_etext -
+				(unsigned long)_stext;
 			dprof_len >>= dprof_shift;
-			size = ((dprof_len * sizeof(unsigned int)) + (PAGE_SIZE-1)) & PAGE_MASK;
-			dprof_buffer = (unsigned int *)((klimit + (PAGE_SIZE-1)) & PAGE_MASK);
+			size = ((dprof_len * sizeof(unsigned int)) +
+					(PAGE_SIZE-1)) & PAGE_MASK;
+			dprof_buffer = (unsigned int *)((klimit +
+						(PAGE_SIZE-1)) & PAGE_MASK);
 			new_klimit = ((unsigned long)dprof_buffer) + size;
-			lmb_reserve( __pa(klimit), (new_klimit-klimit));
+			lmb_reserve(__pa(klimit), (new_klimit-klimit));
 			klimit = new_klimit;
-			memset( dprof_buffer, 0, size );
+			memset(dprof_buffer, 0, size);
                 }
         }
 
 	iSeries_setup_dprofile();
 
-	iSeries_proc_early_init();	
+	iSeries_proc_early_init();
 	mf_init();
 	mf_initialized = 1;
 	mb();
 
-	iSeries_proc_callback( &pmc_proc_init );
+	iSeries_proc_callback(&pmc_proc_init);
 }
 
-#ifdef CONFIG_PPC_ISERIES
 /*
  * The iSeries may have very large memories ( > 128 GB ) and a partition
  * may get memory in "chunks" that may be anywhere in the 2**52 real
@@ -444,9 +435,10 @@ static void __init build_iSeries_Memory_
 
 	/* Chunk size on iSeries is 256K bytes */
 	totalChunks = (u32)HvLpConfig_getMsChunks();
-	klimit = msChunks_alloc(klimit, totalChunks, 1UL<<18);
+	klimit = msChunks_alloc(klimit, totalChunks, 1UL << 18);
 
-	/* Get absolute address of our load area
+	/*
+	 * Get absolute address of our load area
 	 * and map it to physical address 0
 	 * This guarantees that the loadarea ends up at physical 0
 	 * otherwise, it might not be returned by PLIC as the first
@@ -456,63 +448,68 @@ static void __init build_iSeries_Memory_
 	loadAreaFirstChunk = (u32)addr_to_chunk(itLpNaca.xLoadAreaAddr);
 	loadAreaSize =  itLpNaca.xLoadAreaChunks;
 
-	/* Only add the pages already mapped here.  
+	/*
+	 * Only add the pages already mapped here.  
 	 * Otherwise we might add the hpt pages 
 	 * The rest of the pages of the load area
 	 * aren't in the HPT yet and can still
 	 * be assigned an arbitrary physical address
 	 */
-	if ( (loadAreaSize * 64) > HvPagesToMap )
+	if ((loadAreaSize * 64) > HvPagesToMap)
 		loadAreaSize = HvPagesToMap / 64;
 
 	loadAreaLastChunk = loadAreaFirstChunk + loadAreaSize - 1;
 
-	/* TODO Do we need to do something if the HPT is in the 64MB load area?
+	/*
+	 * TODO Do we need to do something if the HPT is in the 64MB load area?
 	 * This would be required if the itLpNaca.xLoadAreaChunks includes 
 	 * the HPT size
 	 */
 
-	printk( "Mapping load area - physical addr = 0000000000000000\n"
-                "                    absolute addr = %016lx\n", 
-			chunk_to_addr(loadAreaFirstChunk) );
-	printk( "Load area size %dK\n", loadAreaSize*256 );
+	printk("Mapping load area - physical addr = 0000000000000000\n"
+		"                    absolute addr = %016lx\n",
+		chunk_to_addr(loadAreaFirstChunk));
+	printk("Load area size %dK\n", loadAreaSize * 256);
+	
+	for (nextPhysChunk = 0; nextPhysChunk < loadAreaSize; ++nextPhysChunk)
+		msChunks.abs[nextPhysChunk] =
+			loadAreaFirstChunk + nextPhysChunk;
 	
-	for (	nextPhysChunk = 0; 
-		nextPhysChunk < loadAreaSize; 
-		++nextPhysChunk ) {
-		msChunks.abs[nextPhysChunk] = loadAreaFirstChunk+nextPhysChunk;
-	}
-	
-	/* Get absolute address of our HPT and remember it so
+	/*
+	 * Get absolute address of our HPT and remember it so
 	 * we won't map it to any physical address
 	 */
-
 	hptFirstChunk = (u32)addr_to_chunk(HvCallHpt_getHptAddress());
-	hptSizePages =  (u32)(HvCallHpt_getHptPages());
-	hptSizeChunks = hptSizePages >> (msChunks.chunk_shift-PAGE_SHIFT);
+	hptSizePages = (u32)HvCallHpt_getHptPages();
+	hptSizeChunks = hptSizePages >> (msChunks.chunk_shift - PAGE_SHIFT);
 	hptLastChunk = hptFirstChunk + hptSizeChunks - 1;
-	
-	printk( "HPT absolute addr = %016lx, size = %dK\n",
-			chunk_to_addr(hptFirstChunk), hptSizeChunks*256 );
+
+	printk("HPT absolute addr = %016lx, size = %dK\n",
+			chunk_to_addr(hptFirstChunk), hptSizeChunks * 256);
 
 	/* Fill in the htab_data structure */
-	
 	/* Fill in size of hashed page table */
-	num_ptegs = hptSizePages * (PAGE_SIZE/(sizeof(HPTE)*HPTES_PER_GROUP));
+	num_ptegs = hptSizePages *
+		(PAGE_SIZE / (sizeof(HPTE) * HPTES_PER_GROUP));
 	htab_data.htab_num_ptegs = num_ptegs;
 	htab_data.htab_hash_mask = num_ptegs - 1;
 	
-	/* The actual hashed page table is in the hypervisor, we have no direct access */
+	/*
+	 * The actual hashed page table is in the hypervisor,
+	 * we have no direct access
+	 */
 	htab_data.htab = NULL;
 
-	/* Determine if absolute memory has any
+	/*
+	 * Determine if absolute memory has any
 	 * holes so that we can interpret the
 	 * access map we get back from the hypervisor
 	 * correctly.
 	 */
-	numMemoryBlocks = iSeries_process_mainstore_vpd( mb, 32 );
+	numMemoryBlocks = iSeries_process_mainstore_vpd(mb, 32);
 
-	/* Process the main store access map from the hypervisor
+	/*
+	 * Process the main store access map from the hypervisor
 	 * to build up our physical -> absolute translation table
 	 */
 	curBlock = 0;
@@ -520,30 +517,29 @@ static void __init build_iSeries_Memory_
 	currDword = 0;
 	moreChunks = totalChunks;
 
-	while ( moreChunks ) {
-		map = HvCallSm_get64BitsOfAccessMap( itLpNaca.xLpIndex,
-						     currDword );
+	while (moreChunks) {
+		map = HvCallSm_get64BitsOfAccessMap(itLpNaca.xLpIndex,
+				currDword);
 		thisChunk = currChunk;
-		while ( map ) {
+		while (map) {
 			chunkBit = map >> 63;
 			map <<= 1;
-			if ( chunkBit ) {
+			if (chunkBit) {
 				--moreChunks;
-
-				while ( thisChunk >= mb[curBlock].logicalEnd ) {
+				while (thisChunk >= mb[curBlock].logicalEnd) {
 					++curBlock;
-					if ( curBlock >= numMemoryBlocks )
+					if (curBlock >= numMemoryBlocks)
 						panic("out of memory blocks");
 				}
-				if ( thisChunk < mb[curBlock].logicalStart )
+				if (thisChunk < mb[curBlock].logicalStart)
 					panic("memory block error");
 
-				absChunk = mb[curBlock].absStart + ( thisChunk - mb[curBlock].logicalStart );
-
-				if ( ( ( absChunk < hptFirstChunk ) ||
-				       ( absChunk > hptLastChunk ) ) &&
-				     ( ( absChunk < loadAreaFirstChunk ) ||
-				       ( absChunk > loadAreaLastChunk ) ) ) {
+				absChunk = mb[curBlock].absStart +
+					(thisChunk - mb[curBlock].logicalStart);
+				if (((absChunk < hptFirstChunk) ||
+				     (absChunk > hptLastChunk)) &&
+				    ((absChunk < loadAreaFirstChunk) ||
+				     (absChunk > loadAreaLastChunk))) {
 					msChunks.abs[nextPhysChunk] = absChunk;
 					++nextPhysChunk;
 				}
@@ -553,8 +549,9 @@ static void __init build_iSeries_Memory_
 		++currDword;
 		currChunk += 64;
 	}
-					
-	/* main store size (in chunks) is 
+
+	/*
+	 * main store size (in chunks) is 
 	 *   totalChunks - hptSizeChunks
 	 * which should be equal to 
 	 *   nextPhysChunk
@@ -562,12 +559,12 @@ static void __init build_iSeries_Memory_
 	systemcfg->physicalMemorySize = chunk_to_addr(nextPhysChunk);
 
 	/* Bolt kernel mappings for all of memory */
-	iSeries_bolt_kernel( 0, systemcfg->physicalMemorySize );
+	iSeries_bolt_kernel(0, systemcfg->physicalMemorySize);
 
 	lmb_init();
-	lmb_add( 0, systemcfg->physicalMemorySize );
+	lmb_add(0, systemcfg->physicalMemorySize);
 	lmb_analyze();	/* ?? */
-	lmb_reserve( 0, __pa(klimit));
+	lmb_reserve(0, __pa(klimit));
 
 	/* 
 	 * Hardcode to GP size.  I am not sure where to get this info. DRENG
@@ -579,59 +576,94 @@ static void __init build_iSeries_Memory_
  * Set up the variables that describe the cache line sizes
  * for this machine.
  */
-
 static void __init setup_iSeries_cache_sizes(void)
 {
 	unsigned int i, n;
 	unsigned int procIx = get_paca()->xLpPaca.xDynHvPhysicalProcIndex;
 
-	systemcfg->iCacheL1Size = xIoHriProcessorVpd[procIx].xInstCacheSize * 1024;
-	systemcfg->iCacheL1LineSize = xIoHriProcessorVpd[procIx].xInstCacheOperandSize;
-	systemcfg->dCacheL1Size = xIoHriProcessorVpd[procIx].xDataL1CacheSizeKB * 1024;
-	systemcfg->dCacheL1LineSize = xIoHriProcessorVpd[procIx].xDataCacheOperandSize;
+	systemcfg->iCacheL1Size =
+		xIoHriProcessorVpd[procIx].xInstCacheSize * 1024;
+	systemcfg->iCacheL1LineSize =
+		xIoHriProcessorVpd[procIx].xInstCacheOperandSize;
+	systemcfg->dCacheL1Size =
+		xIoHriProcessorVpd[procIx].xDataL1CacheSizeKB * 1024;
+	systemcfg->dCacheL1LineSize =
+		xIoHriProcessorVpd[procIx].xDataCacheOperandSize;
 	naca->iCacheL1LinesPerPage = PAGE_SIZE / systemcfg->iCacheL1LineSize;
 	naca->dCacheL1LinesPerPage = PAGE_SIZE / systemcfg->dCacheL1LineSize;
 
 	i = systemcfg->iCacheL1LineSize;
 	n = 0;
-	while ((i=(i/2))) ++n;
+	while ((i = (i / 2)))
+		++n;
 	naca->iCacheL1LogLineSize = n;
 
 	i = systemcfg->dCacheL1LineSize;
 	n = 0;
-	while ((i=(i/2))) ++n;
+	while ((i = (i / 2)))
+		++n;
 	naca->dCacheL1LogLineSize = n;
 
-	printk( "D-cache line size = %d\n", (unsigned int)systemcfg->dCacheL1LineSize);
-	printk( "I-cache line size = %d\n", (unsigned int)systemcfg->iCacheL1LineSize);
+	printk("D-cache line size = %d\n",
+			(unsigned int)systemcfg->dCacheL1LineSize);
+	printk("I-cache line size = %d\n",
+			(unsigned int)systemcfg->iCacheL1LineSize);
 }
 
 /*
- * Bolt the kernel addr space into the HPT
+ * Create a pte. Used during initialization only.
  */
+static void iSeries_make_pte(unsigned long va, unsigned long pa,
+			     int mode)
+{
+	HPTE local_hpte, rhpte;
+	unsigned long hash, vpn;
+	long slot;
+
+	vpn = va >> PAGE_SHIFT;
+	hash = hpt_hash(vpn, 0);
+
+	local_hpte.dw1.dword1 = pa | mode;
+	local_hpte.dw0.dword0 = 0;
+	local_hpte.dw0.dw0.avpn = va >> 23;
+	local_hpte.dw0.dw0.bolted = 1;		/* bolted */
+	local_hpte.dw0.dw0.v = 1;
+
+	slot = HvCallHpt_findValid(&rhpte, vpn);
+	if (slot < 0) {
+		/* Must find space in primary group */
+		panic("hash_page: hpte already exists\n");
+	}
+	HvCallHpt_addValidate(slot, 0, (HPTE *)&local_hpte );
+}
 
+/*
+ * Bolt the kernel addr space into the HPT
+ */
 static void __init iSeries_bolt_kernel(unsigned long saddr, unsigned long eaddr)
 {
 	unsigned long pa;
 	unsigned long mode_rw = _PAGE_ACCESSED | _PAGE_COHERENT | PP_RWXX;
 	HPTE hpte;
 
-	for (pa=saddr; pa < eaddr ;pa+=PAGE_SIZE) {
+	for (pa = saddr; pa < eaddr ;pa += PAGE_SIZE) {
 		unsigned long ea = (unsigned long)__va(pa);
-		unsigned long vsid = get_kernel_vsid( ea );
-		unsigned long va = ( vsid << 28 ) | ( pa & 0xfffffff );
+		unsigned long vsid = get_kernel_vsid(ea);
+		unsigned long va = (vsid << 28) | (pa & 0xfffffff);
 		unsigned long vpn = va >> PAGE_SHIFT;
-		unsigned long slot = HvCallHpt_findValid( &hpte, vpn );
-		if ( hpte.dw0.dw0.v ) {
+		unsigned long slot = HvCallHpt_findValid(&hpte, vpn);
+
+		if (hpte.dw0.dw0.v) {
 			/* HPTE exists, so just bolt it */
-			HvCallHpt_setSwBits( slot, 0x10, 0 );
-		} else {
+			HvCallHpt_setSwBits(slot, 0x10, 0);
+			/* And make sure the pp bits are correct */
+			HvCallHpt_setPp(slot, PP_RWXX);
+		} else
 			/* No HPTE exists, so create a new bolted one */
-			build_valid_hpte(vsid, ea, pa, NULL, mode_rw, 1);
-		}
+			iSeries_make_pte(va, (unsigned long)__v2a(ea),
+					mode_rw);
 	}
 }
-#endif /* CONFIG_PPC_ISERIES */
 
 extern unsigned long ppc_proc_freq;
 extern unsigned long ppc_tb_freq;
@@ -639,10 +671,9 @@ extern unsigned long ppc_tb_freq;
 /*
  * Document me.
  */
-void __init
-iSeries_setup_arch(void)
+void __init iSeries_setup_arch(void)
 {
-	void *	eventStack;
+	void *eventStack;
 	unsigned procIx = get_paca()->xLpPaca.xDynHvPhysicalProcIndex;
 
 	/* Add an eye catcher and the systemcfg layout version number */
@@ -657,50 +688,43 @@ iSeries_setup_arch(void)
 	 * we subtract out the KERNELBASE and add in the
 	 * absolute real address of the kernel load area
 	 */
-	
-	eventStack = alloc_bootmem_pages( LpEventStackSize );
-	
-	memset( eventStack, 0, LpEventStackSize );
+	eventStack = alloc_bootmem_pages(LpEventStackSize);
+	memset(eventStack, 0, LpEventStackSize);
 	
 	/* Invoke the hypervisor to initialize the event stack */
-	
-	HvCallEvent_setLpEventStack( 0, eventStack, LpEventStackSize );
-	
+	HvCallEvent_setLpEventStack(0, eventStack, LpEventStackSize);
+
 	/* Initialize fields in our Lp Event Queue */
-	
 	xItLpQueue.xSlicEventStackPtr = (char *)eventStack;
 	xItLpQueue.xSlicCurEventPtr = (char *)eventStack;
 	xItLpQueue.xSlicLastValidEventPtr = (char *)eventStack + 
 					(LpEventStackSize - LpEventMaxSize);
 	xItLpQueue.xIndex = 0;
-	
+
 	/* Compute processor frequency */
-	procFreqHz = (((1UL<<34) * 1000000) / xIoHriProcessorVpd[procIx].xProcFreq );
+	procFreqHz = ((1UL << 34) * 1000000) /
+			xIoHriProcessorVpd[procIx].xProcFreq;
 	procFreqMhz = procFreqHz / 1000000;
-	procFreqMhzHundreths = (procFreqHz/10000) - (procFreqMhz*100);
-
+	procFreqMhzHundreths = (procFreqHz / 10000) - (procFreqMhz * 100);
 	ppc_proc_freq = procFreqHz;
 
 	/* Compute time base frequency */
-	tbFreqHz = (((1UL<<32) * 1000000) / xIoHriProcessorVpd[procIx].xTimeBaseFreq );
+	tbFreqHz = ((1UL << 32) * 1000000) /
+		xIoHriProcessorVpd[procIx].xTimeBaseFreq;
 	tbFreqMhz = tbFreqHz / 1000000;
-	tbFreqMhzHundreths = (tbFreqHz/10000) - (tbFreqMhz*100);
-
+	tbFreqMhzHundreths = (tbFreqHz / 10000) - (tbFreqMhz * 100);
 	ppc_tb_freq = tbFreqHz;
 
 	printk("Max  logical processors = %d\n", 
-			itVpdAreas.xSlicMaxLogicalProcs );
+			itVpdAreas.xSlicMaxLogicalProcs);
 	printk("Max physical processors = %d\n",
-			itVpdAreas.xSlicMaxPhysicalProcs );
-	printk("Processor frequency = %lu.%02lu\n",
-			procFreqMhz, 
-			procFreqMhzHundreths );
-	printk("Time base frequency = %lu.%02lu\n",
-			tbFreqMhz,
-			tbFreqMhzHundreths );
+			itVpdAreas.xSlicMaxPhysicalProcs);
+	printk("Processor frequency = %lu.%02lu\n", procFreqMhz,
+			procFreqMhzHundreths);
+	printk("Time base frequency = %lu.%02lu\n", tbFreqMhz,
+			tbFreqMhzHundreths);
 	systemcfg->processor = xIoHriProcessorVpd[procIx].xPVR;
 	printk("Processor version = %x\n", systemcfg->processor);
-
 }
 
 /*
@@ -715,38 +739,27 @@ iSeries_setup_arch(void)
  *
  * Output(s):
  *  *buffer - Buffer with CPU data.
- *
- * Returns:
- *   The number of bytes copied into 'buffer' if OK, otherwise zero or less
- *   on error.
  */
-void iSeries_setup_residual(struct seq_file *m)
+void iSeries_setup_residual(struct seq_file *m, int cpu_id)
 {
-	
-	seq_printf(m,"clock\t\t: %lu.%02luMhz\n",
-		procFreqMhz, procFreqMhzHundreths );
-	seq_printf(m,"time base\t: %lu.%02luMHz\n",
-		tbFreqMhz, tbFreqMhzHundreths );
-	seq_printf(m,"i-cache\t\t: %d\n",
-		systemcfg->iCacheL1LineSize);
-	seq_printf(m,"d-cache\t\t: %d\n",
-		systemcfg->dCacheL1LineSize);
-
+	seq_printf(m, "clock\t\t: %lu.%02luMhz\n", procFreqMhz,
+			procFreqMhzHundreths);
+	seq_printf(m, "time base\t: %lu.%02luMHz\n", tbFreqMhz,
+			tbFreqMhzHundreths);
+	seq_printf(m, "i-cache\t\t: %d\n", systemcfg->iCacheL1LineSize);
+	seq_printf(m, "d-cache\t\t: %d\n", systemcfg->dCacheL1LineSize);
 }
 
 void iSeries_get_cpuinfo(struct seq_file *m)
 {
-
-	seq_printf(m,"machine\t\t: 64-bit iSeries Logical Partition\n");
-
+	seq_printf(m, "machine\t\t: 64-bit iSeries Logical Partition\n");
 }
 
 /*
  * Document me.
  * and Implement me.
  */
-int
-iSeries_get_irq(struct pt_regs *regs)
+int iSeries_get_irq(struct pt_regs *regs)
 {
 	/* -2 means ignore this interrupt */
 	return -2;
@@ -755,8 +768,7 @@ iSeries_get_irq(struct pt_regs *regs)
 /*
  * Document me.
  */
-void
-iSeries_restart(char *cmd)
+void iSeries_restart(char *cmd)
 {
 	mf_reboot();
 }
@@ -764,8 +776,7 @@ iSeries_restart(char *cmd)
 /*
  * Document me.
  */
-void
-iSeries_power_off(void)
+void iSeries_power_off(void)
 {
 	mf_powerOff();
 }
@@ -773,8 +784,7 @@ iSeries_power_off(void)
 /*
  * Document me.
  */
-void
-iSeries_halt(void)
+void iSeries_halt(void)
 {
 	mf_powerOff();
 }
@@ -792,24 +802,19 @@ extern void setup_default_decr(void);
  *   and sets up the kernel timer decrementer based on that value.
  *
  */
-void __init
-iSeries_calibrate_decr(void)
+void __init iSeries_calibrate_decr(void)
 {
 	unsigned long	cyclesPerUsec;
-
 	struct div_result divres;
 	
-	/* Compute decrementer (and TB) frequency 
-	 * in cycles/sec 
-	 */
+	/* Compute decrementer (and TB) frequency in cycles/sec */
+	cyclesPerUsec = ppc_tb_freq / 1000000;
 
-	cyclesPerUsec = ppc_tb_freq / 1000000;	/* cycles / usec */
-
-	/* Set the amount to refresh the decrementer by.  This
+	/*
+	 * Set the amount to refresh the decrementer by.  This
 	 * is the number of decrementer ticks it takes for 
 	 * 1/HZ seconds.
 	 */
-
 	tb_ticks_per_jiffy = ppc_tb_freq / HZ;
 
 #if 0
@@ -824,47 +829,54 @@ iSeries_calibrate_decr(void)
 	 * that jiffies (and xtime) will match the time returned
 	 * by do_gettimeofday.
 	 */
-	tb_ticks_per_sec   = tb_ticks_per_jiffy * HZ;
+	tb_ticks_per_sec = tb_ticks_per_jiffy * HZ;
 	tb_ticks_per_usec = cyclesPerUsec;
 	tb_to_us = mulhwu_scale_factor(ppc_tb_freq, 1000000);
-	div128_by_32( 1024*1024, 0, tb_ticks_per_sec, &divres );
+	div128_by_32(1024 * 1024, 0, tb_ticks_per_sec, &divres);
 	tb_to_xs = divres.result_low;
 	setup_default_decr();
 }
 
-void __init
-iSeries_progress( char * st, unsigned short code )
+void __init iSeries_progress(char * st, unsigned short code)
 {
-	printk( "Progress: [%04x] - %s\n", (unsigned)code, st );
-	if ( !piranha_simulator && mf_initialized ) {
-	    if (code != 0xffff)
-		mf_displayProgress( code );
-	    else
-		mf_clearSrc();
+	printk("Progress: [%04x] - %s\n", (unsigned)code, st);
+	if (!piranha_simulator && mf_initialized) {
+		if (code != 0xffff)
+			mf_displayProgress(code);
+		else
+			mf_clearSrc();
 	}
 }
 
-
 void iSeries_fixup_klimit(void)
 {
-	/* Change klimit to take into account any ram disk that may be included */
+	/*
+	 * Change klimit to take into account any ram disk
+	 * that may be included
+	 */
 	if (naca->xRamDisk)
-		klimit = KERNELBASE + (u64)naca->xRamDisk + (naca->xRamDiskSize * PAGE_SIZE);
+		klimit = KERNELBASE + (u64)naca->xRamDisk +
+			(naca->xRamDiskSize * PAGE_SIZE);
 	else {
-		/* No ram disk was included - check and see if there was an embedded system map */
-		/* Change klimit to take into account any embedded system map */
+		/*
+		 * No ram disk was included - check and see if there
+		 * was an embedded system map.  Change klimit to take
+		 * into account any embedded system map
+		 */
 		if (embedded_sysmap_end)
-			klimit = KERNELBASE + ((embedded_sysmap_end+4095) & 0xfffffffffffff000);
+			klimit = KERNELBASE + ((embedded_sysmap_end + 4095) &
+					0xfffffffffffff000);
 	}
 }
 
 static void iSeries_setup_dprofile(void)
 {
-	if ( dprof_buffer ) {
+	if (dprof_buffer) {
 		unsigned i;
-		for (i=0; i<NR_CPUS; ++i) {
+
+		for (i = 0; i < NR_CPUS; ++i) {
 			paca[i].prof_shift = dprof_shift;
-			paca[i].prof_len = dprof_len-1;
+			paca[i].prof_len = dprof_len - 1;
 			paca[i].prof_buffer = dprof_buffer;
 			paca[i].prof_stext = (unsigned *)_stext;
 			mb();
diff -purN linux-2.5/arch/ppc64/kernel/iSeries_setup.h linuxppc64-2.5/arch/ppc64/kernel/iSeries_setup.h
--- linux-2.5/arch/ppc64/kernel/iSeries_setup.h	2002-03-26 07:32:20.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/iSeries_setup.h	2003-11-21 06:45:02.000000000 +0000
@@ -19,25 +19,24 @@
 #ifndef	__ISERIES_SETUP_H__
 #define	__ISERIES_SETUP_H__
 
-extern void		 iSeries_init_early(void);
-extern void		 iSeries_init(unsigned long r3,
-			            unsigned long ird_start,
-				    unsigned long ird_end,
-				    unsigned long cline_start,
-				    unsigned long cline_end);
-extern void		 iSeries_setup_arch(void);
-extern void		 iSeries_setup_residual(struct seq_file *m);
-extern void		 iSeries_get_cpuinfo(struct seq_file *m);
-extern void		 iSeries_init_IRQ(void);
-extern int		 iSeries_get_irq(struct pt_regs *regs);
-extern void		 iSeries_restart(char *cmd);
-extern void		 iSeries_power_off(void);
-extern void		 iSeries_halt(void);
-extern void		 iSeries_time_init(void);
-extern void      iSeries_get_boot_time(struct rtc_time *tm);
-extern int		 iSeries_set_rtc_time(unsigned long now);
-extern unsigned long	 iSeries_get_rtc_time(void);
-extern void		 iSeries_calibrate_decr(void);
-extern void 	 iSeries_progress( char *, unsigned short );
+extern void iSeries_init_early(void);
+extern void iSeries_init(unsigned long r3, unsigned long ird_start,
+		unsigned long ird_end, unsigned long cline_start,
+		unsigned long cline_end);
+extern void iSeries_setup_arch(void);
+extern void iSeries_setup_residual(struct seq_file *m, int cpu_id);
+extern void iSeries_get_cpuinfo(struct seq_file *m);
+extern void iSeries_init_IRQ(void);
+extern void iSeries_init_irq_desc(irq_desc_t *);
+extern int iSeries_get_irq(struct pt_regs *regs);
+extern void iSeries_restart(char *cmd);
+extern void iSeries_power_off(void);
+extern void iSeries_halt(void);
+extern void iSeries_time_init(void);
+extern void iSeries_get_boot_time(struct rtc_time *tm);
+extern int iSeries_set_rtc_time(struct rtc_time *tm);
+extern void iSeries_get_rtc_time(struct rtc_time *tm);
+extern void iSeries_calibrate_decr(void);
+extern void iSeries_progress( char *, unsigned short );
 
 #endif /* __ISERIES_SETUP_H__ */
diff -purN linux-2.5/arch/ppc64/kernel/idle.c linuxppc64-2.5/arch/ppc64/kernel/idle.c
--- linux-2.5/arch/ppc64/kernel/idle.c	2003-09-11 04:07:58.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/idle.c	2003-11-21 06:45:02.000000000 +0000
@@ -1,5 +1,13 @@
 /*
- * idle.c
+ * Idle daemon for PowerPC.  Idle daemon will handle any action
+ * that needs to be taken when the system becomes idle.
+ *
+ * Originally Written by Cort Dougan (cort@cs.nmt.edu)
+ *
+ * iSeries supported added by Mike Corrigan <mikejc@us.ibm.com>
+ *
+ * Additional shared processor, SMT, and firmware support
+ *    Copyright (c) 2003 Dave Engebretsen <engebret@us.ibm.com>
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
@@ -26,64 +34,73 @@
 #include <asm/processor.h>
 #include <asm/mmu.h>
 #include <asm/cache.h>
+#include <asm/cputable.h>
 #include <asm/time.h>
-
-#ifdef CONFIG_PPC_ISERIES
-
 #include <asm/iSeries/LparData.h>
 #include <asm/iSeries/HvCall.h>
 #include <asm/iSeries/ItLpQueue.h>
 
-unsigned long maxYieldTime = 0;
-unsigned long minYieldTime = 0xffffffffffffffffUL;
+extern long cede_processor(void);
+extern long poll_pending(void);
+
+int (*idle_loop)(void);
 
+#ifdef CONFIG_PPC_ISERIES
 static void yield_shared_processor(void)
 {
-	unsigned long tb;
-	unsigned long yieldTime;
+	struct paca_struct *lpaca = get_paca();
 
 	HvCall_setEnabledInterrupts(HvCall_MaskIPI |
 				    HvCall_MaskLpEvent |
 				    HvCall_MaskLpProd |
 				    HvCall_MaskTimeout);
 
-	tb = get_tb();
-	/* Compute future tb value when yield should expire */
-	HvCall_yieldProcessor(HvCall_YieldTimed, tb+tb_ticks_per_jiffy);
-
-	yieldTime = get_tb() - tb;
-	if (yieldTime > maxYieldTime)
-		maxYieldTime = yieldTime;
+	if (!ItLpQueue_isLpIntPending(paca->lpQueuePtr)) {
+		/* 
+		 * Compute future tb value when yield should expire.
+		 * We want to be woken up when the next decrementer is
+		 * to fire.  
+		 */
+
+		local_irq_disable(); 
+		lpaca->yielded = 1;        /* Indicate a prod is desired */
+		lpaca->xLpPaca.xIdle = 1;  /* Inform the HV we are idle  */
+
+		HvCall_yieldProcessor(HvCall_YieldTimed, 
+				      lpaca->next_jiffy_update_tb);	  
 
-	if (yieldTime < minYieldTime)
-		minYieldTime = yieldTime;
+		lpaca->yielded = 0;        /* Back to IPI's */
+		local_irq_enable(); 
 	
-	/*
-	 * The decrementer stops during the yield.  Force a fake decrementer
-	 * here and let the timer_interrupt code sort out the actual time.
-	 */
-	get_paca()->xLpPaca.xIntDword.xFields.xDecrInt = 1;
+		/*
+		 * The decrementer stops during the yield.  Force a fake 
+		 * decrementer here and let the timer_interrupt code sort 
+		 * out the actual time.
+		 */
+		lpaca->xLpPaca.xIntDword.xFields.xDecrInt = 1;
+	}
+	  
 	process_iSeries_events();
 }
 
-int cpu_idle(void)
+int iSeries_idle(void)
 {
 	struct paca_struct *lpaca;
 	long oldval;
 	unsigned long CTRL;
 
-#warning fix iseries run light
-#if 0
 	/* ensure iSeries run light will be out when idle */
-	current->thread.flags &= ~PPC_FLAG_RUN_LIGHT;
+	clear_thread_flag(TIF_RUN_LIGHT);
 	CTRL = mfspr(CTRLF);
 	CTRL &= ~RUNLATCH;
 	mtspr(CTRLT, CTRL);
+#if 0
+	init_idle();	
 #endif
 
 	lpaca = get_paca();
 
-	while (1) {
+	for (;;) {
 		if (lpaca->xLpPaca.xSharedProc) {
 			if (ItLpQueue_isLpIntPending(lpaca->lpQueuePtr))
 				process_iSeries_events();
@@ -109,16 +126,13 @@ int cpu_idle(void)
 			}
 		}
 
-		if (need_resched())
-			schedule();
+		schedule();
 	}
-
 	return 0;
 }
+#endif
 
-#else /* CONFIG_PPC_ISERIES */
-
-int cpu_idle(void)
+int default_idle(void)
 {
 	long oldval;
 
@@ -145,9 +159,155 @@ int cpu_idle(void)
 	return 0;
 }
 
-#endif /* CONFIG_PPC_ISERIES */
+#ifdef CONFIG_PPC_PSERIES
+int dedicated_idle(void)
+{
+	long oldval;
+	struct paca_struct *lpaca = get_paca(), *ppaca;
+	unsigned long start_snooze;
+
+	ppaca = &paca[(lpaca->xPacaIndex) ^ 1];
 
-void default_idle(void)
+	while (1) {
+		/* Indicate to the HV that we are idle.  Now would be
+		 * a good time to find other work to dispatch. */
+		lpaca->xLpPaca.xIdle = 1;
+
+		oldval = test_and_clear_thread_flag(TIF_NEED_RESCHED);
+		if (!oldval) {
+			set_thread_flag(TIF_POLLING_NRFLAG);
+			start_snooze = __get_tb();
+			while (!need_resched()) {
+				/* need_resched could be 1 or 0 at this 
+				 * point.  If it is 0, set it to 0, so
+				 * an IPI/Prod is sent.  If it is 1, keep
+				 * it that way & schedule work.
+				 */
+				if (__get_tb() < 
+				    (start_snooze + 
+				     naca->smt_snooze_delay*tb_ticks_per_usec)) {  
+					HMT_low(); /* Low thread priority */
+					continue;
+				}
+
+				HMT_very_low(); /* Low power mode */
+
+				/* If the SMT mode is system controlled & the 
+				 * partner thread is doing work, switch into
+				 * ST mode.
+				 */
+				if((naca->smt_state == SMT_DYNAMIC) &&
+				   (!(ppaca->xLpPaca.xIdle))) {
+					/* Indicate we are no longer polling for
+					 * work, and then clear need_resched.  If
+					 * need_resched was 1, set it back to 1
+					 * and schedule work
+					 */
+					clear_thread_flag(TIF_POLLING_NRFLAG);
+					oldval = test_and_clear_thread_flag(TIF_NEED_RESCHED);
+					if(oldval == 1) {
+						set_need_resched();
+						break;
+					}
+
+					/* DRENG: Go HMT_medium here ? */
+					local_irq_disable(); 
+					lpaca->yielded = 1;
+
+					/* SMT dynamic mode.  Cede will result 
+					 * in this thread going dormant, if the
+					 * partner thread is still doing work.
+					 * Thread wakes up if partner goes idle,
+					 * an interrupt is presented, or a prod
+					 * occurs.  Returning from the cede
+					 * enables external interrupts.
+					 */
+					cede_processor();
+
+					lpaca->yielded = 0;
+				} else {
+					/* Give the HV an opportunity at the
+					 * processor, since we are not doing
+					 * any work.
+					 */
+					poll_pending();
+				}
+			}
+		} else {
+			set_need_resched();
+		}
+
+		HMT_medium();
+		lpaca->xLpPaca.xIdle = 0;
+		schedule();
+	}
+	return 0;
+}
+
+int shared_idle(void)
 {
-	barrier();
+	struct paca_struct *lpaca = get_paca();
+
+	while (1) {
+		/* Indicate to the HV that we are idle.  Now would be
+		 * a good time to find other work to dispatch. */
+		lpaca->xLpPaca.xIdle = 1;
+
+		if (!need_resched()) {
+			local_irq_disable(); 
+			lpaca->yielded = 1;
+			
+			/* 
+			 * Yield the processor to the hypervisor.  We return if
+			 * an external interrupt occurs (which are driven prior
+			 * to returning here) or if a prod occurs from another 
+			 * processor.  When returning here, external interrupts 
+			 * are enabled.
+			 */
+			cede_processor();
+			
+			lpaca->yielded = 0;
+		}
+
+		HMT_medium();
+		lpaca->xLpPaca.xIdle = 0;
+		schedule();
+	}
+
+	return 0;
 }
+#endif
+
+int cpu_idle(void)
+{
+	idle_loop();
+	return 0; 
+}
+
+int idle_setup(void)
+{
+#ifdef CONFIG_PPC_ISERIES
+	idle_loop = iSeries_idle;
+#else
+	if (systemcfg->platform & PLATFORM_PSERIES) {
+		if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
+			if(get_paca()->xLpPaca.xSharedProc) {
+				printk("idle = shared_idle\n");
+				idle_loop = shared_idle;
+			} else {
+				printk("idle = dedicated_idle\n");
+				idle_loop = dedicated_idle;
+			}
+		} else {
+			printk("idle = default_idle\n");
+			idle_loop = default_idle;
+		}
+	} else {
+		printk("idle_setup: unknown platform, use default_idle\n");
+		idle_loop = default_idle;
+	}
+#endif
+
+	return 1;
+}
+
diff -purN linux-2.5/arch/ppc64/kernel/irq.c linuxppc64-2.5/arch/ppc64/kernel/irq.c
--- linux-2.5/arch/ppc64/kernel/irq.c	2003-10-16 01:43:36.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/irq.c	2003-11-21 06:45:02.000000000 +0000
@@ -40,6 +40,7 @@
 #include <linux/irq.h>
 #include <linux/proc_fs.h>
 #include <linux/random.h>
+#include <linux/bootmem.h>
 #include <linux/kallsyms.h>
 
 #include <asm/uaccess.h>
@@ -55,30 +56,303 @@
 #include <asm/machdep.h>
 #include <asm/paca.h>
 
+/*
+ * Because the name space for interrupts is so large on ppc64 systems we
+ * avoid declaring a single array of "NR_IRQ" interrupts and instead build
+ * a three level tree leading to the irq_desc_t (similar to page tables).
+ *
+ * Currently we cover 24-bit irq values:
+ *    10-bits:  the "base" dir (2-pages)
+ *     9-bits:  the "middle" dir (1-page)
+ *     5-bits:  the "bottom" page (1-page) holding 128byte irq_desc's.
+ *
+ * We pack a hw_irq_stat struct directly after the irq_desc in the otherwise
+ * wasted space of the cacheline.
+ *
+ * MAX_IRQS is the max this implementation will support.
+ * It is much larger than NR_IRQS which is bogus on this arch and often used
+ * to declare arrays.
+ *
+ * Note that all "undefined" mid table and bottom table pointers will point
+ * to dummy tables.  Therefore, we don't need to check for NULL on spurious
+ * interrupts.
+ */
+
+#define MAX_IRQS (1<<24)
+#define IRQ_BASE_INDEX_SIZE  10
+#define IRQ_MID_INDEX_SIZE  9
+#define IRQ_BOT_DESC_SIZE 5
+
+#define IRQ_BASE_PTRS	(1 << IRQ_BASE_INDEX_SIZE)
+#define IRQ_MID_PTRS	(1 << IRQ_MID_INDEX_SIZE)
+#define IRQ_BOT_DESCS (1 << IRQ_BOT_DESC_SIZE)
+
+#define IRQ_BASE_IDX_SHIFT (IRQ_MID_INDEX_SIZE + IRQ_BOT_DESC_SIZE)
+#define IRQ_MID_IDX_SHIFT (IRQ_BOT_DESC_SIZE)
+
+#define IRQ_MID_IDX_MASK  ((1 << IRQ_MID_INDEX_SIZE) - 1)
+#define IRQ_BOT_IDX_MASK  ((1 << IRQ_BOT_DESC_SIZE) - 1)
+
+
+/* Define a way to iterate across irqs fairly efficiently. */
+#define for_each_irq(i) \
+	for ((i) = 0; (i) < MAX_IRQS; (i) = _next_irq(i))
+unsigned int _next_irq(unsigned int irq);
+
+/* The hw_irq_stat struct is stored directly after the irq_desc_t
+ * in the same cacheline.  We need to use care to make sure we don't
+ * overrun the size of the cacheline.
+ *
+ * Currently sizeof(irq_desc_t) is 32 bytes or less and this hw_irq_stat
+ * fills the rest of the cache line.
+ *
+ * The irqs_per_cpu field is an optimization for systems with 4 cpus or less
+ * to avoid allocating space for irq-per-cpu statistics (and hitting another
+ * cacheline to do the counting).  This field could be discarded.
+ */
+struct hw_irq_stat {
+	unsigned long irqs;		/* statistic per irq */
+	unsigned long *per_cpu_stats;
+	struct proc_dir_entry *irq_dir, *smp_affinity;
+	unsigned long irq_affinity;	/* ToDo: cpu bitmask */
+	unsigned long irqs_per_cpu[4];
+};
+static inline struct hw_irq_stat *get_irq_stat(irq_desc_t *desc)
+{
+	/* WARNING: this assume lock is the last field! */
+	return (struct hw_irq_stat *)(&desc->lock+1);
+}
+static inline unsigned long *get_irq_per_cpu(struct hw_irq_stat *hw)
+{
+	return hw->per_cpu_stats;
+}
+
 #ifdef CONFIG_SMP
 extern void iSeries_smp_message_recv( struct pt_regs * );
 #endif
 
-volatile unsigned char *chrp_int_ack_special;
 static void register_irq_proc (unsigned int irq);
-
-irq_desc_t irq_desc[NR_IRQS] __cacheline_aligned = {
-	[0 ... NR_IRQS-1] = {
-		.lock = SPIN_LOCK_UNLOCKED
-	}
-};
+static irq_desc_t *add_irq_desc(unsigned int irq);
 	
 int ppc_spurious_interrupts = 0;
 unsigned long lpEvent_count = 0;
 
+extern int mem_init_done;
+
+irq_desc_t **irq_desc_base_dir[IRQ_BASE_PTRS] __page_aligned = {0};
+irq_desc_t **irq_desc_mid_null;
+irq_desc_t *irq_desc_bot_null;
+
+static inline irq_desc_t **get_irq_mid_table(unsigned int irq)
+{
+	/* Assume irq < MAX_IRQS so we won't index off the end. */
+	return irq_desc_base_dir[irq >> IRQ_BASE_IDX_SHIFT];
+}
+
+static inline irq_desc_t *get_irq_bot_table(unsigned int irq,
+					    irq_desc_t **mid_ptr)
+{
+	return mid_ptr[(irq >> IRQ_MID_IDX_SHIFT) & IRQ_MID_IDX_MASK];
+}
+
+
+/* This should be inline. */
+void *_get_irq_desc(unsigned int irq)
+{
+	irq_desc_t **mid_table, *bot_table, *desc;
+
+	mid_table = get_irq_mid_table(irq);
+	bot_table = get_irq_bot_table(irq, mid_table);
+
+	desc = bot_table + (irq & IRQ_BOT_IDX_MASK);
+	return desc;
+}
+
+/* This is used by the for_each_irq(i) macro to iterate quickly over
+ * all interrupt.  It optimizes by skipping over ptrs to the null tables
+ * when possible, but it may produce false positives.
+ */
+unsigned int _next_irq(unsigned int irq)
+{
+	irq_desc_t **mid_table, *bot_table;
+
+	irq++;
+	/* Easy case first...staying on the current bot_table. */
+	if (irq & IRQ_BOT_IDX_MASK)
+		return irq;
+
+	/* Now skip empty mid tables */
+	while (irq < MAX_IRQS &&
+	       (mid_table = get_irq_mid_table(irq)) == irq_desc_mid_null) {
+		/* index to the next base index (i.e. the next mid table) */
+		irq = (irq & ~(IRQ_BASE_IDX_SHIFT-1)) + IRQ_BASE_IDX_SHIFT;
+	}
+	/* And skip empty bot tables */
+	while (irq < MAX_IRQS &&
+	       (bot_table = get_irq_bot_table(irq, mid_table)) == irq_desc_bot_null) {
+		/* index to the next mid index (i.e. the next bot table) */
+		irq = (irq & ~(IRQ_MID_IDX_SHIFT-1)) + IRQ_MID_IDX_SHIFT;
+	}
+	return irq;
+}
+
+
+/* Same as get_irq_desc(irq) except it will "fault in" a real desc as needed
+ * rather than return the null entry.
+ * This is used by code that is actually defining the irq.
+ *
+ * NULL may be returned on memory allocation failure.  In general, init code
+ * doesn't look for this, but setup_irq does.  In this failure case the desc
+ * is left pointing at the null pages so callers of get_irq_desc() should
+ * always return something.
+ */
+void *_get_real_irq_desc(unsigned int irq)
+{
+	irq_desc_t *desc = get_irq_desc(irq);
+	if (((unsigned long)desc & PAGE_MASK) ==
+	    (unsigned long)irq_desc_bot_null) {
+		desc = add_irq_desc(irq);
+	}
+	return desc;
+}
+
+/* Allocate an irq middle page and init entries to null page. */
+static irq_desc_t **alloc_irq_mid_page(void)
+{
+	irq_desc_t **m, **ent;
+
+	if (mem_init_done)
+		m = (irq_desc_t **)__get_free_page(GFP_KERNEL);
+	else
+		m = (irq_desc_t **)alloc_bootmem_pages(PAGE_SIZE);
+	if (m) {
+		for (ent = m; ent < m + IRQ_MID_PTRS; ent++) {
+			*ent = irq_desc_bot_null;
+		}
+	}
+	return m;
+}
+
+/* Allocate an irq bottom page and init the entries. */
+static irq_desc_t *alloc_irq_bot_page(void)
+{
+	irq_desc_t *b, *ent;
+	if (mem_init_done)
+		b = (irq_desc_t *)get_zeroed_page(GFP_KERNEL);
+	else
+		b = (irq_desc_t *)alloc_bootmem_pages(PAGE_SIZE);
+	if (b) {
+		for (ent = b; ent < b + IRQ_BOT_DESCS; ent++) {
+			ent->lock = SPIN_LOCK_UNLOCKED;
+		}
+	}
+	return b;
+}
+
+/*
+ * The universe of interrupt numbers ranges from 0 to 2^24.
+ * Use a sparsely populated tree to map from the irq to the handler.
+ * Top level is 2 contiguous pages, covering the 10 most significant 
+ * bits.  Mid level is 1 page, covering 9 bits.  Last page covering
+ * 5 bits is the irq_desc, each of which is 128B.
+ */
+static void irq_desc_init(void) {
+	irq_desc_t ***entry_p;
+
+	/* 
+	 * Now initialize the tables to point though the NULL tables for
+	 * the default case of no interrupt handler (spurious).
+	 */
+	irq_desc_bot_null = alloc_irq_bot_page();
+	irq_desc_mid_null = alloc_irq_mid_page();
+	if (!irq_desc_bot_null || !irq_desc_mid_null)
+		panic("irq_desc_init: could not allocate pages\n");
+	for(entry_p = irq_desc_base_dir;
+	    entry_p < irq_desc_base_dir + IRQ_BASE_PTRS;
+	    entry_p++) {
+		*entry_p = irq_desc_mid_null;
+	}
+}
+
+/*
+ * Add a new irq desc for the given irq if needed.
+ * This breaks any ptr to the "null" middle or "bottom" irq desc page.
+ * Note that we don't ever coalesce pages as the interrupts are released.
+ * This isn't worth the effort.  We add the cpu stats info when the
+ * interrupt is actually requested.
+ *
+ * May return NULL if memory could not be allocated.
+ */
+static irq_desc_t *add_irq_desc(unsigned int irq)
+{
+	irq_desc_t **mid_table_p, *bot_table_p;
+
+	mid_table_p = get_irq_mid_table(irq); 
+	if(mid_table_p == irq_desc_mid_null) {
+		/* No mid table for this IRQ - create it */
+		mid_table_p = alloc_irq_mid_page();
+		if (!mid_table_p) return NULL;
+		irq_desc_base_dir[irq >> IRQ_BASE_IDX_SHIFT] = mid_table_p;
+	}
+
+	bot_table_p = (irq_desc_t *)(*(mid_table_p + ((irq >> 5) & 0x1ff)));
+
+	if(bot_table_p == irq_desc_bot_null) {
+		/* No bot table for this IRQ - create it */
+		bot_table_p = alloc_irq_bot_page();
+		if (!bot_table_p) return NULL;
+		mid_table_p[(irq >> IRQ_MID_IDX_SHIFT) & IRQ_MID_IDX_MASK] = bot_table_p;
+	}
+
+	return bot_table_p + (irq & IRQ_BOT_IDX_MASK);
+}
+
+void allocate_per_cpu_stats(struct hw_irq_stat *hwstat)
+{
+	unsigned long *p;
+
+	if (naca->interrupt_controller == IC_OPEN_PIC) {
+		/* Cheap optimization -- assume max cpus on open pic is 4
+		 * and so they will fit in cacheline after desc.
+		 * ToDo: verify max cpus.  Assume no hot plug?
+		 */
+		hwstat->per_cpu_stats = hwstat->irqs_per_cpu;
+		return;
+	}
+	if (mem_init_done) {
+		p = (unsigned long *)kmalloc(sizeof(long)*NR_CPUS, GFP_KERNEL);
+		if (p) memset(p, 0, sizeof(long)*NR_CPUS);
+	} else
+		p = (unsigned long *)alloc_bootmem(sizeof(long)*NR_CPUS);
+	hwstat->per_cpu_stats = p;
+}
+
 int
 setup_irq(unsigned int irq, struct irqaction * new)
 {
 	int shared = 0;
 	unsigned long flags;
 	struct irqaction *old, **p;
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_real_irq_desc(irq);
+	struct hw_irq_stat *hwstat;
+
+	if (!desc)
+		return -ENOMEM;
+
+	ppc_md.init_irq_desc(desc);
+
+	hwstat = get_irq_stat(desc);
+
+#ifdef CONFIG_IRQ_ALL_CPUS
+	hwstat->irq_affinity = ~0;
+#else
+	hwstat->irq_affinity = 0;
+#endif
 
+	/* Now is the time to add per-cpu kstat data to the desc
+	 * since it appears we are actually going to use the irq.
+	 */
+	allocate_per_cpu_stats(hwstat);
 	/*
 	 * Some drivers like serial.c use request_irq() heavily,
 	 * so we have to be careful not to interfere with a
@@ -133,7 +407,7 @@ setup_irq(unsigned int irq, struct irqac
 
 inline void synchronize_irq(unsigned int irq)
 {
-	while (irq_desc[irq].status & IRQ_INPROGRESS)
+	while (get_irq_desc(irq)->status & IRQ_INPROGRESS)
 		cpu_relax();
 }
 
@@ -147,11 +421,10 @@ EXPORT_SYMBOL(synchronize_irq);
 static int
 do_free_irq(int irq, void* dev_id)
 {
-	irq_desc_t *desc;
+	irq_desc_t *desc = get_irq_desc(irq);
 	struct irqaction **p;
 	unsigned long flags;
 
-	desc = irq_desc + irq;
 	spin_lock_irqsave(&desc->lock,flags);
 	p = &desc->action;
 	for (;;) {
@@ -182,41 +455,6 @@ do_free_irq(int irq, void* dev_id)
 	return -ENOENT;
 }
 
-int request_irq(unsigned int irq,
-	irqreturn_t (*handler)(int, void *, struct pt_regs *),
-	unsigned long irqflags, const char * devname, void *dev_id)
-{
-	struct irqaction *action;
-	int retval;
-
-	if (irq >= NR_IRQS)
-		return -EINVAL;
-	if (!handler)
-		/* We could implement really free_irq() instead of that... */
-		return do_free_irq(irq, dev_id);
-	
-	action = (struct irqaction *)
-		kmalloc(sizeof(struct irqaction), GFP_KERNEL);
-	if (!action) {
-		printk(KERN_ERR "kmalloc() failed for irq %d !\n", irq);
-		return -ENOMEM;
-	}
-	
-	action->handler = handler;
-	action->flags = irqflags;					
-	action->mask = 0;
-	action->name = devname;
-	action->dev_id = dev_id;
-	action->next = NULL;
-	
-	retval = setup_irq(irq, action);
-	if (retval)
-		kfree(action);
-		
-	return 0;
-}
-
-EXPORT_SYMBOL(request_irq);
 
 void free_irq(unsigned int irq, void *dev_id)
 {
@@ -245,7 +483,7 @@ EXPORT_SYMBOL(free_irq);
  
 inline void disable_irq_nosync(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
@@ -274,7 +512,7 @@ EXPORT_SYMBOL(disable_irq_nosync);
  
 void disable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	disable_irq_nosync(irq);
 	if (desc->action)
 		synchronize_irq(irq);
@@ -294,13 +532,13 @@ EXPORT_SYMBOL(disable_irq);
  
 void enable_irq(unsigned int irq)
 {
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 
 	spin_lock_irqsave(&desc->lock, flags);
 	switch (desc->depth) {
 	case 1: {
-		unsigned int status = desc->status & ~(IRQ_DISABLED | IRQ_INPROGRESS);
+		unsigned int status = desc->status & ~IRQ_DISABLED;
 		desc->status = status;
 		if ((status & (IRQ_PENDING | IRQ_REPLAY)) == IRQ_PENDING) {
 			desc->status = status | IRQ_REPLAY;
@@ -321,10 +559,49 @@ void enable_irq(unsigned int irq)
 
 EXPORT_SYMBOL(enable_irq);
 
+int request_irq(unsigned int irq,
+	irqreturn_t (*handler)(int, void *, struct pt_regs *),
+	unsigned long irqflags, const char * devname, void *dev_id)
+{
+	struct irqaction *action;
+	int retval;
+
+	if (irq >= MAX_IRQS)
+		return -EINVAL;
+	if (!handler)
+		/* We could implement really free_irq() instead of that... */
+		return do_free_irq(irq, dev_id);
+	
+	action = (struct irqaction *)
+		kmalloc(sizeof(struct irqaction), GFP_KERNEL);
+	if (!action) {
+		printk(KERN_ERR "kmalloc() failed for irq %d !\n", irq);
+		return -ENOMEM;
+	}
+	
+	action->handler = handler;
+	action->flags = irqflags;					
+	action->mask = 0;
+	action->name = devname;
+	action->dev_id = dev_id;
+	action->next = NULL;
+	
+	retval = setup_irq(irq, action);
+	if (retval)
+		kfree(action);
+		
+	return 0;
+}
+
+EXPORT_SYMBOL(request_irq);
+
 int show_interrupts(struct seq_file *p, void *v)
 {
 	int i, j;
 	struct irqaction * action;
+	irq_desc_t *desc;
+	struct hw_irq_stat *hwstat;
+	unsigned long *per_cpus;
 	unsigned long flags;
 
 	seq_printf(p, "           ");
@@ -334,31 +611,35 @@ int show_interrupts(struct seq_file *p, 
 	}
 	seq_putc(p, '\n');
 
-	for (i = 0 ; i < NR_IRQS ; i++) {
-		spin_lock_irqsave(&irq_desc[i].lock, flags);
-		action = irq_desc[i].action;
+	for_each_irq(i) {
+		desc = get_irq_desc(i);
+		spin_lock_irqsave(&desc->lock, flags);
+		action = desc->action;
+
 		if (!action || !action->handler)
 			goto skip;
-		seq_printf(p, "%3d: ", i);		
-#ifdef CONFIG_SMP
-		for (j = 0; j < NR_CPUS; j++) {
-			if (cpu_online(j))
-				seq_printf(p, "%10u ", kstat_cpu(j).irqs[i]);
+		seq_printf(p, "%3d: ", i);
+		hwstat = get_irq_stat(desc);
+		per_cpus = get_irq_per_cpu(hwstat);
+		if (per_cpus) {
+			for (j = 0; j < NR_CPUS; j++) {
+				if (cpu_online(j))
+					seq_printf(p, "%10lu ", per_cpus[j]);
+			}
+		} else {
+			seq_printf(p, "%10lu ", hwstat->irqs);
 		}
-#else		
-		seq_printf(p, "%10u ", kstat_irqs(i));
-#endif /* CONFIG_SMP */
-		if (irq_desc[i].handler)		
-			seq_printf(p, " %s ", irq_desc[i].handler->typename );
+		if (get_irq_desc(i)->handler)		
+			seq_printf(p, " %s ", get_irq_desc(i)->handler->typename );
 		else
 			seq_printf(p, "  None      ");
-		seq_printf(p, "%s", (irq_desc[i].status & IRQ_LEVEL) ? "Level " : "Edge  ");
+		seq_printf(p, "%s", (get_irq_desc(i)->status & IRQ_LEVEL) ? "Level " : "Edge  ");
 		seq_printf(p, "    %s",action->name);
 		for (action=action->next; action; action = action->next)
 			seq_printf(p, ", %s", action->name);
 		seq_putc(p, '\n');
 skip:
-		spin_unlock_irqrestore(&irq_desc[i].lock, flags);
+		spin_unlock_irqrestore(&desc->lock, flags);
 	}
 	seq_printf(p, "BAD: %10u\n", ppc_spurious_interrupts);
 	return 0;
@@ -474,9 +755,17 @@ void ppc_irq_dispatch_handler(struct pt_
 	int status;
 	struct irqaction *action;
 	int cpu = smp_processor_id();
-	irq_desc_t *desc = irq_desc + irq;
+	irq_desc_t *desc = get_irq_desc(irq);
+	struct hw_irq_stat *hwstat;
+	unsigned long *per_cpus;
+
+	/* Statistics. */
+	hwstat = get_irq_stat(desc);	/* same cache line as desc */
+	hwstat->irqs++;
+	per_cpus = get_irq_per_cpu(hwstat); /* same cache line for < 8 cpus */
+	if (per_cpus)
+		per_cpus[cpu]++;
 
-	kstat_cpu(cpu).irqs[irq]++;
 	spin_lock(&desc->lock);
 	ack_irq(irq);	
 	/*
@@ -550,26 +839,23 @@ out:
 	 * The ->end() handler has to deal with interrupts which got
 	 * disabled while the handler was running.
 	 */
-	if (irq_desc[irq].handler) {
-		if (irq_desc[irq].handler->end)
-			irq_desc[irq].handler->end(irq);
-		else if (irq_desc[irq].handler->enable)
-			irq_desc[irq].handler->enable(irq);
+	if (desc->handler) {
+		if (desc->handler->end)
+			desc->handler->end(irq);
+		else if (desc->handler->enable)
+			desc->handler->enable(irq);
 	}
 	spin_unlock(&desc->lock);
 }
 
+#ifdef CONFIG_PPC_ISERIES
 int do_IRQ(struct pt_regs *regs)
 {
-	int irq, first = 1;
-#ifdef CONFIG_PPC_ISERIES
 	struct paca_struct *lpaca;
 	struct ItLpQueue *lpq;
-#endif
 
 	irq_enter();
 
-#ifdef CONFIG_PPC_ISERIES
 	lpaca = get_paca();
 #ifdef CONFIG_SMP
 	if (lpaca->xLpPaca.xIntDword.xFields.xIpiCnt) {
@@ -580,7 +866,24 @@ int do_IRQ(struct pt_regs *regs)
 	lpq = lpaca->lpQueuePtr;
 	if (lpq && ItLpQueue_isLpIntPending(lpq))
 		lpEvent_count += ItLpQueue_process(lpq, regs);
-#else
+
+	irq_exit();
+
+	if (lpaca->xLpPaca.xIntDword.xFields.xDecrInt) {
+		lpaca->xLpPaca.xIntDword.xFields.xDecrInt = 0;
+		/* Signal a fake decrementer interrupt */
+		timer_interrupt(regs);
+	}
+
+	return 1; /* lets ret_from_int know we can do checks */
+}
+#else	/* CONFIG_PPC_ISERIES */
+int do_IRQ(struct pt_regs *regs)
+{
+	int irq, first = 1;
+
+	irq_enter();
+
 	/*
 	 * Every arch is required to implement ppc_md.get_irq.
 	 * This function will either return an irq number or -1 to
@@ -596,20 +899,12 @@ int do_IRQ(struct pt_regs *regs)
 	if (irq != -2 && first)
 		/* That's not SMP safe ... but who cares ? */
 		ppc_spurious_interrupts++;
-#endif
 
 	irq_exit();
 
-#ifdef CONFIG_PPC_ISERIES
-	if (lpaca->xLpPaca.xIntDword.xFields.xDecrInt) {
-		lpaca->xLpPaca.xIntDword.xFields.xDecrInt = 0;
-		/* Signal a fake decrementer interrupt */
-		timer_interrupt(regs);
-	}
-#endif
-
 	return 1; /* lets ret_from_int know we can do checks */
 }
+#endif	/* CONFIG_PPC_ISERIES */
 
 unsigned long probe_irq_on (void)
 {
@@ -634,47 +929,48 @@ void __init init_IRQ(void)
 {
 	static int once = 0;
 
-	if ( once )
+	if (once)
 		return;
-	else
-		once++;
-	
+
+	once++;
+
+	/* Initialize the irq tree */
+	irq_desc_init();
+
 	ppc_md.init_IRQ();
 }
 
 static struct proc_dir_entry * root_irq_dir;
-static struct proc_dir_entry * irq_dir [NR_IRQS];
-static struct proc_dir_entry * smp_affinity_entry [NR_IRQS];
 
 #ifdef CONFIG_IRQ_ALL_CPUS
-cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
+  cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_ALL };
 #else  /* CONFIG_IRQ_ALL_CPUS */
-cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_NONE };
+  cpumask_t irq_affinity [NR_IRQS] = { [0 ... NR_IRQS-1] = CPU_MASK_NONE };
 #endif /* CONFIG_IRQ_ALL_CPUS */
-
+  
 #define HEX_DIGITS (2*sizeof(cpumask_t))
 
 static int irq_affinity_read_proc (char *page, char **start, off_t off,
 			int count, int *eof, void *data)
 {
-	int k, len;
-	cpumask_t tmp = irq_affinity[(long)data];
+ 	int k, len;
+ 	cpumask_t tmp = irq_affinity[(long)data];
 
 	if (count < HEX_DIGITS+1)
 		return -EINVAL;
 
-	for (k = 0; k < sizeof(cpumask_t) / sizeof(u16); ++k) {
-		int j = sprintf(page, "%04hx", (u16)cpus_coerce(tmp));
-		len += j;
-		page += j;
-		cpus_shift_right(tmp, tmp, 16);
-	}
-	len += sprintf(page, "\n");
-	return len;
+ 	for (k = 0; k < sizeof(cpumask_t) / sizeof(u16); ++k) {
+ 		int j = sprintf(page, "%04hx", (u16)cpus_coerce(tmp));
+ 		len += j;
+ 		page += j;
+ 		cpus_shift_right(tmp, tmp, 16);
+ 	}
+ 	len += sprintf(page, "\n");
+ 	return len;
 }
 
 static unsigned int parse_hex_value (const char *buffer,
-		unsigned long count, cpumask_t *ret)
+		unsigned long count, long *ret)
 {
 	unsigned char hexnum[HEX_DIGITS];
 	cpumask_t value = CPU_MASK_NONE;
@@ -716,10 +1012,13 @@ out:
 static int irq_affinity_write_proc (struct file *file, const char *buffer,
 					unsigned long count, void *data)
 {
-	int irq = (long)data, full_count = count, err;
+	unsigned int irq = (long)data;
+	irq_desc_t *desc = get_irq_desc(irq);
+	struct hw_irq_stat *hwstat = get_irq_stat(desc);
+	int full_count = count, err;
 	cpumask_t new_value, tmp;
 
-	if (!irq_desc[irq].handler->set_affinity)
+	if (!desc->handler->set_affinity)
 		return -EIO;
 
 	err = parse_hex_value(buffer, count, &new_value);
@@ -735,9 +1034,8 @@ static int irq_affinity_write_proc (stru
 	if (cpus_empty(tmp))
 		return -EINVAL;
 
-	irq_affinity[irq] = new_value;
-	irq_desc[irq].handler->set_affinity(irq, new_value);
-
+	hwstat->irq_affinity = new_value;
+	desc->handler->set_affinity(irq, new_value);
 	return full_count;
 }
 
@@ -785,18 +1083,24 @@ static void register_irq_proc (unsigned 
 {
 	struct proc_dir_entry *entry;
 	char name [MAX_NAMELEN];
+	irq_desc_t *desc;
+	struct hw_irq_stat *hwstat;
 
-	if (!root_irq_dir || (irq_desc[irq].handler == NULL) || irq_dir[irq])
+	desc = get_real_irq_desc(irq);
+	if (!root_irq_dir || !desc || !desc->handler)
+		return;
+	hwstat = get_irq_stat(desc);
+	if (hwstat->irq_dir)
 		return;
 
 	memset(name, 0, MAX_NAMELEN);
 	sprintf(name, "%d", irq);
 
 	/* create /proc/irq/1234 */
-	irq_dir[irq] = proc_mkdir(name, root_irq_dir);
+	hwstat->irq_dir = proc_mkdir(name, root_irq_dir);	
 
 	/* create /proc/irq/1234/smp_affinity */
-	entry = create_proc_entry("smp_affinity", 0600, irq_dir[irq]);
+	entry = create_proc_entry("smp_affinity", 0600, hwstat->irq_dir);
 
 	if (entry) {
 		entry->nlink = 1;
@@ -804,8 +1108,7 @@ static void register_irq_proc (unsigned 
 		entry->read_proc = irq_affinity_read_proc;
 		entry->write_proc = irq_affinity_write_proc;
 	}
-
-	smp_affinity_entry[irq] = entry;
+	hwstat->smp_affinity = entry;
 }
 
 unsigned long prof_cpu_mask = -1;
@@ -832,8 +1135,8 @@ void init_irq_proc (void)
 	/*
 	 * Create entries for all existing IRQs.
 	 */
-	for (i = 0; i < NR_IRQS; i++) {
-		if (irq_desc[i].handler == NULL)
+	for_each_irq(i) {
+		if (get_irq_desc(i)->handler == NULL)
 			continue;
 		register_irq_proc(i);
 	}
diff -purN linux-2.5/arch/ppc64/kernel/mf.c linuxppc64-2.5/arch/ppc64/kernel/mf.c
--- linux-2.5/arch/ppc64/kernel/mf.c	2002-12-30 12:29:15.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/mf.c	2003-11-21 06:45:02.000000000 +0000
@@ -42,160 +42,120 @@
 #include <linux/pci.h>
 #include <linux/bcd.h>
 
-extern struct pci_dev * iSeries_vio_dev;
+extern struct pci_dev *iSeries_vio_dev;
 
 /*
  * This is the structure layout for the Machine Facilites LPAR event
  * flows.
  */
-struct VspCmdData;
-struct CeMsgData;
-union SafeCast
-{
-	u64 ptrAsU64;
+union safe_cast {
+	u64 ptr_as_u64;
 	void *ptr;
 };
 
+struct VspCmdData {
+	union safe_cast token;
+	u16 cmd;
+	HvLpIndex lp_index;
+	u8 result_code;
+	u32 reserved;
+	union {
+		u64 state;	/* GetStateOut */
+		u64 ipl_type;	/* GetIplTypeOut, Function02SelectIplTypeIn */
+		u64 ipl_mode;	/* GetIplModeOut, Function02SelectIplModeIn */
+		u64 page[4];	/* GetSrcHistoryIn */
+		u64 flag;	/* GetAutoIplWhenPrimaryIplsOut,
+				   SetAutoIplWhenPrimaryIplsIn,
+				   WhiteButtonPowerOffIn,
+				   Function08FastPowerOffIn,
+				   IsSpcnRackPowerIncompleteOut */
+		struct {
+			u64 token;
+			u64 address_type;
+			u64 side;
+			u32 length;
+			u32 offset;
+		} kern;		/* SetKernelImageIn, GetKernelImageIn,
+				   SetKernelCmdLineIn, GetKernelCmdLineIn */
+		u32 length_out;	/* GetKernelImageOut, GetKernelCmdLineOut */
+		u8 reserved[80];
+	} sub_data;
+};
 
-typedef void (*CeMsgCompleteHandler)( void *token, struct CeMsgData *vspCmdRsp );
-
-struct CeMsgCompleteData
-{
-	CeMsgCompleteHandler xHdlr;
-	void *xToken;
+struct VspRspData {
+	struct semaphore *sem;
+	struct VspCmdData *response;
 };
 
-struct VspRspData
-{
-	struct semaphore *xSemaphore;
-	struct VspCmdData *xResponse;
+struct AllocData {
+	u16 size;
+	u16 type;
+	u32 count;
+	u16 reserved1;
+	u8 reserved2;
+	HvLpIndex target_lp;
 };
 
-struct IoMFLpEvent
-{
-	struct HvLpEvent xHvLpEvent;
+struct CeMsgData;
 
-	u16 xSubtypeRc;
-	u16 xRsvd1;
-	u32 xRsvd2;
-
-	union
-	{
-
-		struct AllocData
-		{
-			u16 xSize;
-			u16 xType;
-			u32 xCount;
-			u16 xRsvd3;
-			u8 xRsvd4;
-			HvLpIndex xTargetLp;
-		} xAllocData;
-
-		struct CeMsgData
-		{
-			u8 xCEMsg[12];
-			char xReserved[4];
-			struct CeMsgCompleteData *xToken;
-		} xCEMsgData;
-
-		struct VspCmdData
-		{
-			union SafeCast xTokenUnion;
-			u16 xCmd;
-			HvLpIndex xLpIndex;
-			u8 xRc;
-			u32 xReserved1;
+typedef void (*CeMsgCompleteHandler)(void *token, struct CeMsgData *vspCmdRsp);
 
-			union VspCmdSubData
-			{
-				struct
-				{
-					u64 xState;
-				} xGetStateOut;
-
-				struct
-				{
-					u64 xIplType;
-				} xGetIplTypeOut, xFunction02SelectIplTypeIn;
-
-				struct
-				{
-					u64 xIplMode;
-				} xGetIplModeOut, xFunction02SelectIplModeIn;
-
-				struct
-				{
-					u64 xPage[4];
-				} xGetSrcHistoryIn;
-
-				struct
-				{
-					u64 xFlag;
-				} xGetAutoIplWhenPrimaryIplsOut,
-					xSetAutoIplWhenPrimaryIplsIn,
-					xWhiteButtonPowerOffIn,
-					xFunction08FastPowerOffIn,
-					xIsSpcnRackPowerIncompleteOut;
-
-				struct
-				{
-					u64 xToken;
-					u64 xAddressType;
-					u64 xSide;
-					u32 xTransferLength;
-					u32 xOffset;
-				} xSetKernelImageIn,
-					xGetKernelImageIn,
-					xSetKernelCmdLineIn,
-					xGetKernelCmdLineIn;
-
-				struct
-				{
-					u32 xTransferLength;
-				} xGetKernelImageOut,xGetKernelCmdLineOut;
-
-
-				u8 xReserved2[80];
-
-			} xSubData;
-		} xVspCmd;
-	} xUnion;
+struct CeMsgCompleteData {
+	CeMsgCompleteHandler handler;
+	void *token;
 };
 
+struct CeMsgData {
+	u8 ce_msg[12];
+	char reserved[4];
+	struct CeMsgCompleteData *completion;
+};
+
+struct IoMFLpEvent {
+	struct HvLpEvent hp_lp_event;
+	u16 subtype_result_code;
+	u16 reserved1;
+	u32 reserved2;
+	union {
+		struct AllocData alloc;
+		struct CeMsgData ce_msg;
+		struct VspCmdData vsp_cmd;
+	} data;
+};
+
+#define subtype_data(a, b, c, d)	\
+		(((a) << 24) + ((b) << 16) + ((c) << 8) + (d))
 
 /*
  * All outgoing event traffic is kept on a FIFO queue.  The first
  * pointer points to the one that is outstanding, and all new
  * requests get stuck on the end.  Also, we keep a certain number of
- * preallocated stack elements so that we can operate very early in
+ * preallocated pending events so that we can operate very early in
  * the boot up sequence (before kmalloc is ready).
  */
-struct StackElement
-{
-	struct StackElement * next;
+struct pending_event {
+	struct pending_event *next;
 	struct IoMFLpEvent event;
 	MFCompleteHandler hdlr;
-	char dmaData[72];
-	unsigned dmaDataLength;
-	unsigned remoteAddress;
+	char dma_data[72];
+	unsigned dma_data_length;
+	unsigned remote_address;
 };
-static spinlock_t spinlock;
-static struct StackElement * head = NULL;
-static struct StackElement * tail = NULL;
-static struct StackElement * avail = NULL;
-static struct StackElement prealloc[16];
+static spinlock_t pending_event_spinlock;
+static struct pending_event *pending_event_head;
+static struct pending_event *pending_event_tail;
+static struct pending_event *pending_event_avail;
+static struct pending_event pending_event_prealloc[16];
 
 /*
- * Put a stack element onto the available queue, so it can get reused.
- * Attention! You must have the spinlock before calling!
+ * Put a pending event onto the available queue, so it can get reused.
+ * Attention! You must have the pending_event_spinlock before calling!
  */
-void free( struct StackElement * element )
+static void free_pending_event(struct pending_event *ev)
 {
-	if ( element != NULL )
-	{
-		element->next = avail;
-		avail = element;
+	if (ev != NULL) {
+		ev->next = pending_event_avail;
+		pending_event_avail = ev;
 	}
 }
 
@@ -203,68 +163,68 @@ void free( struct StackElement * element
  * Enqueue the outbound event onto the stack.  If the queue was
  * empty to begin with, we must also issue it via the Hypervisor
  * interface.  There is a section of code below that will touch
- * the first stack pointer without the protection of the spinlock.
+ * the first stack pointer without the protection of the pending_event_spinlock.
  * This is OK, because we know that nobody else will be modifying
  * the first pointer when we do this.
  */
-static int signalEvent( struct StackElement * newElement )
+static int signal_event(struct pending_event *ev)
 {
 	int rc = 0;
 	unsigned long flags;
 	int go = 1;
-	struct StackElement * element;
+	struct pending_event *ev1;
 	HvLpEvent_Rc hvRc;
 
 	/* enqueue the event */
-	if ( newElement != NULL )
-	{
-		spin_lock_irqsave( &spinlock, flags );
-		if ( head == NULL )
-			head = newElement;
+	if (ev != NULL) {
+		ev->next = NULL;
+		spin_lock_irqsave(&pending_event_spinlock, flags);
+		if (pending_event_head == NULL)
+			pending_event_head = ev;
 		else {
 			go = 0;
-			tail->next = newElement;
+			pending_event_tail->next = ev;
 		}
-		newElement->next = NULL;
-		tail = newElement;
-		spin_unlock_irqrestore( &spinlock, flags );
+		pending_event_tail = ev;
+		spin_unlock_irqrestore(&pending_event_spinlock, flags);
 	}
 
 	/* send the event */
-	while ( go )
-	{
+	while (go) {
 		go = 0;
 
 		/* any DMA data to send beforehand? */
-		if ( head->dmaDataLength > 0 )
-			HvCallEvent_dmaToSp( head->dmaData, head->remoteAddress, head->dmaDataLength, HvLpDma_Direction_LocalToRemote );
-
-		hvRc = HvCallEvent_signalLpEvent(&head->event.xHvLpEvent);
-		if ( hvRc != HvLpEvent_Rc_Good )
-		{
-			printk( KERN_ERR "mf.c: HvCallEvent_signalLpEvent() failed with %d\n", (int)hvRc );
-
-			spin_lock_irqsave( &spinlock, flags );
-			element = head;
-			head = head->next;
-			if ( head != NULL )
+		if (pending_event_head->dma_data_length > 0)
+			HvCallEvent_dmaToSp(pending_event_head->dma_data,
+					pending_event_head->remote_address,
+					pending_event_head->dma_data_length,
+					HvLpDma_Direction_LocalToRemote);
+
+		hvRc = HvCallEvent_signalLpEvent(
+				&pending_event_head->event.hp_lp_event);
+		if (hvRc != HvLpEvent_Rc_Good) {
+			printk(KERN_ERR "mf.c: HvCallEvent_signalLpEvent() failed with %d\n",
+					(int)hvRc);
+
+			spin_lock_irqsave(&pending_event_spinlock, flags);
+			ev1 = pending_event_head;
+			pending_event_head = pending_event_head->next;
+			if (pending_event_head != NULL)
 				go = 1;
-			spin_unlock_irqrestore( &spinlock, flags );
+			spin_unlock_irqrestore(&pending_event_spinlock, flags);
 
-			if ( element == newElement )
+			if (ev1 == ev)
 				rc = -EIO;
-			else {
-				if ( element->hdlr != NULL )
-				{
-					union SafeCast mySafeCast;
-					mySafeCast.ptrAsU64 = element->event.xHvLpEvent.xCorrelationToken;
-					(*element->hdlr)( mySafeCast.ptr, -EIO );
-				}
+			else if (ev1->hdlr != NULL) {
+				union safe_cast mySafeCast;
+
+				mySafeCast.ptr_as_u64 = ev1->event.hp_lp_event.xCorrelationToken;
+				(*ev1->hdlr)(mySafeCast.ptr, -EIO);
 			}
 
-			spin_lock_irqsave( &spinlock, flags );
-			free( element );
-			spin_unlock_irqrestore( &spinlock, flags );
+			spin_lock_irqsave(&pending_event_spinlock, flags);
+			free_pending_event(ev1);
+			spin_unlock_irqrestore(&pending_event_spinlock, flags);
 		}
 	}
 
@@ -272,80 +232,74 @@ static int signalEvent( struct StackElem
 }
 
 /*
- * Allocate a new StackElement structure, and initialize it.
+ * Allocate a new pending_event structure, and initialize it.
  */
-static struct StackElement * newStackElement( void )
+static struct pending_event *new_pending_event(void)
 {
-	struct StackElement * newElement = NULL;
+	struct pending_event *ev = NULL;
 	HvLpIndex primaryLp = HvLpConfig_getPrimaryLpIndex();
 	unsigned long flags;
+	struct HvLpEvent *hev;
 
-	if ( newElement == NULL )
-	{
-		spin_lock_irqsave( &spinlock, flags );
-		if ( avail != NULL )
-		{
-			newElement = avail;
-			avail = avail->next;
-		}
-		spin_unlock_irqrestore( &spinlock, flags );
-	}
-
-	if ( newElement == NULL )
-		newElement = kmalloc(sizeof(struct StackElement),GFP_ATOMIC);
-
-	if ( newElement == NULL )
-	{
-		printk( KERN_ERR "mf.c: unable to kmalloc %ld bytes\n", sizeof(struct StackElement) );
+	spin_lock_irqsave(&pending_event_spinlock, flags);
+	if (pending_event_avail != NULL) {
+		ev = pending_event_avail;
+		pending_event_avail = pending_event_avail->next;
+	}
+	spin_unlock_irqrestore(&pending_event_spinlock, flags);
+	if (ev == NULL)
+		ev = kmalloc(sizeof(struct pending_event),GFP_ATOMIC);
+	if (ev == NULL) {
+		printk(KERN_ERR "mf.c: unable to kmalloc %ld bytes\n",
+				sizeof(struct pending_event));
 		return NULL;
 	}
+	memset(ev, 0, sizeof(struct pending_event));
+	hev = &ev->event.hp_lp_event;
+	hev->xFlags.xValid = 1;
+	hev->xFlags.xAckType = HvLpEvent_AckType_ImmediateAck;
+	hev->xFlags.xAckInd = HvLpEvent_AckInd_DoAck;
+	hev->xFlags.xFunction = HvLpEvent_Function_Int;
+	hev->xType = HvLpEvent_Type_MachineFac;
+	hev->xSourceLp = HvLpConfig_getLpIndex();
+	hev->xTargetLp = primaryLp;
+	hev->xSizeMinus1 = sizeof(ev->event)-1;
+	hev->xRc = HvLpEvent_Rc_Good;
+	hev->xSourceInstanceId = HvCallEvent_getSourceLpInstanceId(primaryLp,
+			HvLpEvent_Type_MachineFac);
+	hev->xTargetInstanceId = HvCallEvent_getTargetLpInstanceId(primaryLp,
+			HvLpEvent_Type_MachineFac);
 
-	memset( newElement, 0, sizeof(struct StackElement) );
-	newElement->event.xHvLpEvent.xFlags.xValid = 1;
-	newElement->event.xHvLpEvent.xFlags.xAckType = HvLpEvent_AckType_ImmediateAck;
-	newElement->event.xHvLpEvent.xFlags.xAckInd = HvLpEvent_AckInd_DoAck;
-	newElement->event.xHvLpEvent.xFlags.xFunction = HvLpEvent_Function_Int;
-	newElement->event.xHvLpEvent.xType = HvLpEvent_Type_MachineFac;
-	newElement->event.xHvLpEvent.xSourceLp = HvLpConfig_getLpIndex();
-	newElement->event.xHvLpEvent.xTargetLp = primaryLp;
-	newElement->event.xHvLpEvent.xSizeMinus1 = sizeof(newElement->event)-1;
-	newElement->event.xHvLpEvent.xRc = HvLpEvent_Rc_Good;
-	newElement->event.xHvLpEvent.xSourceInstanceId = HvCallEvent_getSourceLpInstanceId(primaryLp,HvLpEvent_Type_MachineFac);
-	newElement->event.xHvLpEvent.xTargetInstanceId = HvCallEvent_getTargetLpInstanceId(primaryLp,HvLpEvent_Type_MachineFac);
-
-	return newElement;
+	return ev;
 }
 
-static int signalVspInstruction( struct VspCmdData *vspCmd )
+static int signal_vsp_instruction(struct VspCmdData *vspCmd)
 {
-	struct StackElement * newElement = newStackElement();
-	int rc = 0;
+	struct pending_event *ev = new_pending_event();
+	int rc;
 	struct VspRspData response;
 	DECLARE_MUTEX_LOCKED(Semaphore);
-	response.xSemaphore = &Semaphore;
-	response.xResponse = vspCmd;
 
-	if ( newElement == NULL )
-		rc = -ENOMEM;
-	else {
-		newElement->event.xHvLpEvent.xSubtype = 6;
-		newElement->event.xHvLpEvent.x.xSubtypeData = ('M'<<24)+('F'<<16)+('V'<<8)+('I'<<0);
-		newElement->event.xUnion.xVspCmd.xTokenUnion.ptr = &response;
-		newElement->event.xUnion.xVspCmd.xCmd = vspCmd->xCmd;
-		newElement->event.xUnion.xVspCmd.xLpIndex = HvLpConfig_getLpIndex();
-		newElement->event.xUnion.xVspCmd.xRc = 0xFF;
-		newElement->event.xUnion.xVspCmd.xReserved1 = 0;
-		memcpy(&(newElement->event.xUnion.xVspCmd.xSubData),&(vspCmd->xSubData), sizeof(vspCmd->xSubData));
-		mb();
+	if (ev == NULL)
+		return -ENOMEM;
 
-		rc = signalEvent(newElement);
-	}
+	response.sem = &Semaphore;
+	response.response = vspCmd;
+	ev->event.hp_lp_event.xSubtype = 6;
+	ev->event.hp_lp_event.x.xSubtypeData =
+		subtype_data('M', 'F',  'V',  'I');
+	ev->event.data.vsp_cmd.token.ptr = &response;
+	ev->event.data.vsp_cmd.cmd = vspCmd->cmd;
+	ev->event.data.vsp_cmd.lp_index = HvLpConfig_getLpIndex();
+	ev->event.data.vsp_cmd.result_code = 0xFF;
+	ev->event.data.vsp_cmd.reserved = 0;
+	memcpy(&(ev->event.data.vsp_cmd.sub_data),
+			&(vspCmd->sub_data), sizeof(vspCmd->sub_data));
+	mb();
 
+	rc = signal_event(ev);
 	if (rc == 0)
-	{
 		down(&Semaphore);
-	}
-
 	return rc;
 }
 
@@ -353,46 +307,42 @@ static int signalVspInstruction( struct 
 /*
  * Send a 12-byte CE message to the primary partition VSP object
  */
-static int signalCEMsg( char * ceMsg, void * token )
+static int signal_ce_msg(char *ce_msg, struct CeMsgCompleteData *completion)
 {
-	struct StackElement * newElement = newStackElement();
-	int rc = 0;
+	struct pending_event *ev = new_pending_event();
 
-	if ( newElement == NULL )
-		rc = -ENOMEM;
-	else {
-		newElement->event.xHvLpEvent.xSubtype = 0;
-		newElement->event.xHvLpEvent.x.xSubtypeData = ('M'<<24)+('F'<<16)+('C'<<8)+('E'<<0);
-		memcpy( newElement->event.xUnion.xCEMsgData.xCEMsg, ceMsg, 12 );
-		newElement->event.xUnion.xCEMsgData.xToken = token;
-		rc = signalEvent(newElement);
-	}
+	if (ev == NULL)
+		return -ENOMEM;
 
-	return rc;
+	ev->event.hp_lp_event.xSubtype = 0;
+	ev->event.hp_lp_event.x.xSubtypeData =
+		subtype_data('M',  'F',  'C',  'E');
+	memcpy(ev->event.data.ce_msg.ce_msg, ce_msg, 12);
+	ev->event.data.ce_msg.completion = completion;
+	return signal_event(ev);
 }
 
 /*
  * Send a 12-byte CE message and DMA data to the primary partition VSP object
  */
-static int dmaAndSignalCEMsg( char * ceMsg, void * token, void * dmaData, unsigned dmaDataLength, unsigned remoteAddress )
+static int dma_and_signal_ce_msg(char *ce_msg,
+		struct CeMsgCompleteData *completion, void *dma_data,
+		unsigned dma_data_length, unsigned remote_address)
 {
-	struct StackElement * newElement = newStackElement();
-	int rc = 0;
+	struct pending_event *ev = new_pending_event();
 
-	if ( newElement == NULL )
-		rc = -ENOMEM;
-	else {
-		newElement->event.xHvLpEvent.xSubtype = 0;
-		newElement->event.xHvLpEvent.x.xSubtypeData = ('M'<<24)+('F'<<16)+('C'<<8)+('E'<<0);
-		memcpy( newElement->event.xUnion.xCEMsgData.xCEMsg, ceMsg, 12 );
-		newElement->event.xUnion.xCEMsgData.xToken = token;
-		memcpy( newElement->dmaData, dmaData, dmaDataLength );
-		newElement->dmaDataLength = dmaDataLength;
-		newElement->remoteAddress = remoteAddress;
-		rc = signalEvent(newElement);
-	}
+	if (ev == NULL)
+		return -ENOMEM;
 
-	return rc;
+	ev->event.hp_lp_event.xSubtype = 0;
+	ev->event.hp_lp_event.x.xSubtypeData =
+		subtype_data('M', 'F', 'C', 'E');
+	memcpy(ev->event.data.ce_msg.ce_msg, ce_msg, 12);
+	ev->event.data.ce_msg.completion = completion;
+	memcpy(ev->dma_data, dma_data, dma_data_length);
+	ev->dma_data_length = dma_data_length;
+	ev->remote_address = remote_address;
+	return signal_event(ev);
 }
 
 /*
@@ -401,18 +351,17 @@ static int dmaAndSignalCEMsg( char * ceM
  * this fails (why?), we'll simply force it off in a not-so-nice
  * manner.
  */
-static int shutdown( void )
+static int shutdown(void)
 {
-	int rc = kill_proc(1,SIGINT,1);
+	int rc = kill_proc(1, SIGINT, 1);
 
-	if ( rc )
-	{
-		printk( KERN_ALERT "mf.c: SIGINT to init failed (%d), hard shutdown commencing\n", rc );
+	if (rc) {
+		printk(KERN_ALERT "mf.c: SIGINT to init failed (%d), "
+				"hard shutdown commencing\n", rc);
 		mf_powerOff();
-	}
-	else
-		printk( KERN_INFO "mf.c: init has been successfully notified to proceed with shutdown\n" );
-
+	} else
+		printk(KERN_INFO "mf.c: init has been successfully notified "
+				"to proceed with shutdown\n");
 	return rc;
 }
 
@@ -420,67 +369,64 @@ static int shutdown( void )
  * The primary partition VSP object is sending us a new
  * event flow.  Handle it...
  */
-static void intReceived( struct IoMFLpEvent * event )
+static void intReceived(struct IoMFLpEvent *event)
 {
 	int freeIt = 0;
-	struct StackElement * two = NULL;
+	struct pending_event *two = NULL;
+
 	/* ack the interrupt */
-	event->xHvLpEvent.xRc = HvLpEvent_Rc_Good;
-	HvCallEvent_ackLpEvent( &event->xHvLpEvent );
+	event->hp_lp_event.xRc = HvLpEvent_Rc_Good;
+	HvCallEvent_ackLpEvent(&event->hp_lp_event);
 
-    /* process interrupt */
-	switch( event->xHvLpEvent.xSubtype )
-	{
+	/* process interrupt */
+	switch (event->hp_lp_event.xSubtype) {
 	case 0:	/* CE message */
-		switch( event->xUnion.xCEMsgData.xCEMsg[3] )
-		{
+		switch (event->data.ce_msg.ce_msg[3]) {
 		case 0x5B:	/* power control notification */
-			if ( (event->xUnion.xCEMsgData.xCEMsg[5]&0x20) != 0 )
-			{
-				printk( KERN_INFO "mf.c: Commencing partition shutdown\n" );
-				if ( shutdown() == 0 )
-					signalCEMsg( "\x00\x00\x00\xDB\x00\x00\x00\x00\x00\x00\x00\x00", NULL );
+			if ((event->data.ce_msg.ce_msg[5] & 0x20) != 0) {
+				printk(KERN_INFO "mf.c: Commencing partition shutdown\n");
+				if (shutdown() == 0)
+					signal_ce_msg("\x00\x00\x00\xDB\x00\x00\x00\x00\x00\x00\x00\x00", NULL);
 			}
 			break;
 		case 0xC0:	/* get time */
-			{
-				if ( (head != NULL) && ( head->event.xUnion.xCEMsgData.xCEMsg[3] == 0x40 ) )
-				{
-					freeIt = 1;
-					if ( head->event.xUnion.xCEMsgData.xToken != 0 )
-					{
-						CeMsgCompleteHandler xHdlr = head->event.xUnion.xCEMsgData.xToken->xHdlr;
-						void * token = head->event.xUnion.xCEMsgData.xToken->xToken;
+			if ((pending_event_head == NULL) ||
+			    (pending_event_head->event.data.ce_msg.ce_msg[3]
+			     != 0x40))
+				break;
+			freeIt = 1;
+			if (pending_event_head->event.data.ce_msg.completion != 0) {
+				CeMsgCompleteHandler handler = pending_event_head->event.data.ce_msg.completion->handler;
+				void *token = pending_event_head->event.data.ce_msg.completion->token;
 
-						if (xHdlr != NULL)
-							(*xHdlr)( token, &(event->xUnion.xCEMsgData) );
-					}
-				}
+				if (handler != NULL)
+					(*handler)(token, &(event->data.ce_msg));
 			}
 			break;
 		}
 
 		/* remove from queue */
-		if ( freeIt == 1 )
-		{
+		if (freeIt == 1) {
 			unsigned long flags;
-			spin_lock_irqsave( &spinlock, flags );
-			if ( head != NULL )
-			{
-				struct StackElement *oldHead = head;
-				head = head->next;
-				two = head;
-				free( oldHead );
+
+			spin_lock_irqsave(&pending_event_spinlock, flags);
+			if (pending_event_head != NULL) {
+				struct pending_event *oldHead =
+					pending_event_head;
+
+				pending_event_head = pending_event_head->next;
+				two = pending_event_head;
+				free_pending_event(oldHead);
 			}
-			spin_unlock_irqrestore( &spinlock, flags );
+			spin_unlock_irqrestore(&pending_event_spinlock, flags);
 		}
 
 		/* send next waiting event */
-		if ( two != NULL )
-			signalEvent( NULL );
+		if (two != NULL)
+			signal_event(NULL);
 		break;
 	case 1:	/* IT sys shutdown */
-		printk( KERN_INFO "mf.c: Commencing system shutdown\n" );
+		printk(KERN_INFO "mf.c: Commencing system shutdown\n");
 		shutdown();
 		break;
 	}
@@ -491,81 +437,74 @@ static void intReceived( struct IoMFLpEv
  * of a flow we sent to them.  If there are other flows queued
  * up, we must send another one now...
  */
-static void ackReceived( struct IoMFLpEvent * event )
+static void ackReceived(struct IoMFLpEvent *event)
 {
 	unsigned long flags;
-	struct StackElement * two = NULL;
+	struct pending_event * two = NULL;
 	unsigned long freeIt = 0;
 
-    /* handle current event */
-	if ( head != NULL )
-	{
-		switch( event->xHvLpEvent.xSubtype )
-		{
+	/* handle current event */
+	if (pending_event_head != NULL) {
+		switch (event->hp_lp_event.xSubtype) {
 		case 0:     /* CE msg */
-			if ( event->xUnion.xCEMsgData.xCEMsg[3] == 0x40 )
-			{
-				if ( event->xUnion.xCEMsgData.xCEMsg[2] != 0 )
-				{
+			if (event->data.ce_msg.ce_msg[3] == 0x40) {
+				if (event->data.ce_msg.ce_msg[2] != 0) {
 					freeIt = 1;
-					if ( head->event.xUnion.xCEMsgData.xToken != 0 )
-					{
-						CeMsgCompleteHandler xHdlr = head->event.xUnion.xCEMsgData.xToken->xHdlr;
-						void * token = head->event.xUnion.xCEMsgData.xToken->xToken;
+					if (pending_event_head->event.data.ce_msg.completion
+							!= 0) {
+						CeMsgCompleteHandler handler = pending_event_head->event.data.ce_msg.completion->handler;
+						void *token = pending_event_head->event.data.ce_msg.completion->token;
 
-						if (xHdlr != NULL)
-							(*xHdlr)( token, &(event->xUnion.xCEMsgData) );
+						if (handler != NULL)
+							(*handler)(token, &(event->data.ce_msg));
 					}
 				}
-			} else {
+			} else
 				freeIt = 1;
-			}
 			break;
 		case 4:	/* allocate */
 		case 5:	/* deallocate */
-			if ( head->hdlr != NULL )
-			{
-				union SafeCast mySafeCast;
-				mySafeCast.ptrAsU64 = event->xHvLpEvent.xCorrelationToken;
-				(*head->hdlr)( mySafeCast.ptr, event->xUnion.xAllocData.xCount );
+			if (pending_event_head->hdlr != NULL) {
+				union safe_cast mySafeCast;
+
+				mySafeCast.ptr_as_u64 = event->hp_lp_event.xCorrelationToken;
+				(*pending_event_head->hdlr)(mySafeCast.ptr, event->data.alloc.count);
 			}
 			freeIt = 1;
 			break;
 		case 6:
 			{
-				struct VspRspData *rsp = (struct VspRspData *)event->xUnion.xVspCmd.xTokenUnion.ptr;
+				struct VspRspData *rsp = (struct VspRspData *)event->data.vsp_cmd.token.ptr;
 
-				if (rsp != NULL)
-				{
-					if (rsp->xResponse != NULL)
-						memcpy(rsp->xResponse, &(event->xUnion.xVspCmd), sizeof(event->xUnion.xVspCmd));
-					if (rsp->xSemaphore != NULL)
-						up(rsp->xSemaphore);
-				} else {
-					printk( KERN_ERR "mf.c: no rsp\n");
-				}
+				if (rsp != NULL) {
+					if (rsp->response != NULL)
+						memcpy(rsp->response, &(event->data.vsp_cmd), sizeof(event->data.vsp_cmd));
+					if (rsp->sem != NULL)
+						up(rsp->sem);
+				} else
+					printk(KERN_ERR "mf.c: no rsp\n");
 				freeIt = 1;
 			}
 			break;
 		}
 	}
 	else
-		printk( KERN_ERR "mf.c: stack empty for receiving ack\n" );
+		printk(KERN_ERR "mf.c: stack empty for receiving ack\n");
 
-    /* remove from queue */
-	spin_lock_irqsave( &spinlock, flags );
-	if (( head != NULL ) && ( freeIt == 1 ))
-	{
-		struct StackElement *oldHead = head;
-		head = head->next;
-		two = head;
-		free( oldHead );
+	/* remove from queue */
+	spin_lock_irqsave(&pending_event_spinlock, flags);
+	if ((pending_event_head != NULL) && (freeIt == 1)) {
+		struct pending_event *oldHead = pending_event_head;
+
+		pending_event_head = pending_event_head->next;
+		two = pending_event_head;
+		free_pending_event(oldHead);
 	} 
-	spin_unlock_irqrestore( &spinlock, flags );
+	spin_unlock_irqrestore(&pending_event_spinlock, flags);
 
-    /* send next waiting event */
-	if ( two != NULL )
-		signalEvent( NULL );
+	/* send next waiting event */
+	if (two != NULL)
+		signal_event(NULL);
 }
 
 /*
@@ -574,101 +513,94 @@ static void ackReceived( struct IoMFLpEv
  * parse it enough to know if it is an interrupt or an
  * acknowledge.
  */
-static void hvHandler( struct HvLpEvent * event, struct pt_regs * regs )
+static void hvHandler(struct HvLpEvent *event, struct pt_regs *regs)
 {
-	if ( (event != NULL) && (event->xType == HvLpEvent_Type_MachineFac) )
-	{
-		switch( event->xFlags.xFunction )
-		{
+	if ((event != NULL) && (event->xType == HvLpEvent_Type_MachineFac)) {
+		switch(event->xFlags.xFunction) {
 		case HvLpEvent_Function_Ack:
-			ackReceived( (struct IoMFLpEvent *)event );
+			ackReceived((struct IoMFLpEvent *)event);
 			break;
 		case HvLpEvent_Function_Int:
-			intReceived( (struct IoMFLpEvent *)event );
+			intReceived((struct IoMFLpEvent *)event);
 			break;
 		default:
-			printk( KERN_ERR "mf.c: non ack/int event received\n" );
+			printk(KERN_ERR "mf.c: non ack/int event received\n");
 			break;
 		}
-	}
-	else
-		printk( KERN_ERR "mf.c: alien event received\n" );
+	} else
+		printk(KERN_ERR "mf.c: alien event received\n");
 }
 
 /*
  * Global kernel interface to allocate and seed events into the
  * Hypervisor.
  */
-void mf_allocateLpEvents( HvLpIndex targetLp,
-			  HvLpEvent_Type type,
-			  unsigned size,
-			  unsigned count,
-			  MFCompleteHandler hdlr,
-			  void * userToken )
+void mf_allocateLpEvents(HvLpIndex targetLp, HvLpEvent_Type type,
+		unsigned size, unsigned count, MFCompleteHandler hdlr,
+		void *userToken)
 {
-	struct StackElement * newElement = newStackElement();
-	int rc = 0;
+	struct pending_event *ev = new_pending_event();
+	int rc;
 
-	if ( newElement == NULL )
+	if (ev == NULL) {
 		rc = -ENOMEM;
-	else {
-		union SafeCast mine;
+	} else {
+		union safe_cast mine;
+
 		mine.ptr = userToken;
-		newElement->event.xHvLpEvent.xSubtype = 4;
-		newElement->event.xHvLpEvent.xCorrelationToken = mine.ptrAsU64;
-		newElement->event.xHvLpEvent.x.xSubtypeData = ('M'<<24)+('F'<<16)+('M'<<8)+('A'<<0);
-		newElement->event.xUnion.xAllocData.xTargetLp = targetLp;
-		newElement->event.xUnion.xAllocData.xType = type;
-		newElement->event.xUnion.xAllocData.xSize = size;
-		newElement->event.xUnion.xAllocData.xCount = count;
-		newElement->hdlr = hdlr;
-		rc = signalEvent(newElement);
+		ev->event.hp_lp_event.xSubtype = 4;
+		ev->event.hp_lp_event.xCorrelationToken = mine.ptr_as_u64;
+		ev->event.hp_lp_event.x.xSubtypeData =
+			subtype_data('M', 'F', 'M', 'A');
+		ev->event.data.alloc.target_lp = targetLp;
+		ev->event.data.alloc.type = type;
+		ev->event.data.alloc.size = size;
+		ev->event.data.alloc.count = count;
+		ev->hdlr = hdlr;
+		rc = signal_event(ev);
 	}
-
-	if ( (rc != 0) && (hdlr != NULL) )
-		(*hdlr)( userToken, rc );
+	if ((rc != 0) && (hdlr != NULL))
+		(*hdlr)(userToken, rc);
 }
 
 /*
  * Global kernel interface to unseed and deallocate events already in
  * Hypervisor.
  */
-void mf_deallocateLpEvents( HvLpIndex targetLp,
-			    HvLpEvent_Type type,
-			    unsigned count,
-			    MFCompleteHandler hdlr,
-			    void * userToken )
+void mf_deallocateLpEvents(HvLpIndex targetLp, HvLpEvent_Type type,
+		unsigned count, MFCompleteHandler hdlr, void *userToken)
 {
-	struct StackElement * newElement = newStackElement();
-	int rc = 0;
+	struct pending_event *ev = new_pending_event();
+	int rc;
 
-	if ( newElement == NULL )
+	if (ev == NULL)
 		rc = -ENOMEM;
 	else {
-		union SafeCast mine;
+		union safe_cast mine;
+
 		mine.ptr = userToken;
-		newElement->event.xHvLpEvent.xSubtype = 5;
-		newElement->event.xHvLpEvent.xCorrelationToken = mine.ptrAsU64;
-		newElement->event.xHvLpEvent.x.xSubtypeData = ('M'<<24)+('F'<<16)+('M'<<8)+('D'<<0);
-		newElement->event.xUnion.xAllocData.xTargetLp = targetLp;
-		newElement->event.xUnion.xAllocData.xType = type;
-		newElement->event.xUnion.xAllocData.xCount = count;
-		newElement->hdlr = hdlr;
-		rc = signalEvent(newElement);
+		ev->event.hp_lp_event.xSubtype = 5;
+		ev->event.hp_lp_event.xCorrelationToken = mine.ptr_as_u64;
+		ev->event.hp_lp_event.x.xSubtypeData =
+			subtype_data('M', 'F', 'M', 'D');
+		ev->event.data.alloc.target_lp = targetLp;
+		ev->event.data.alloc.type = type;
+		ev->event.data.alloc.count = count;
+		ev->hdlr = hdlr;
+		rc = signal_event(ev);
 	}
-
-	if ( (rc != 0) && (hdlr != NULL) )
-		(*hdlr)( userToken, rc );
+	if ((rc != 0) && (hdlr != NULL))
+		(*hdlr)(userToken, rc);
 }
 
 /*
  * Global kernel interface to tell the VSP object in the primary
  * partition to power this partition off.
  */
-void mf_powerOff( void )
+void mf_powerOff(void)
 {
-	printk( KERN_INFO "mf.c: Down it goes...\n" );
-	signalCEMsg( "\x00\x00\x00\x4D\x00\x00\x00\x00\x00\x00\x00\x00", NULL );
+	printk(KERN_INFO "mf.c: Down it goes...\n");
+	signal_ce_msg("\x00\x00\x00\x4D\x00\x00\x00\x00\x00\x00\x00\x00", NULL);
 	for (;;);
 }
 
@@ -676,111 +608,104 @@ void mf_powerOff( void )
  * Global kernel interface to tell the VSP object in the primary
  * partition to reboot this partition.
  */
-void mf_reboot( void )
+void mf_reboot(void)
 {
-	printk( KERN_INFO "mf.c: Preparing to bounce...\n" );
-	signalCEMsg( "\x00\x00\x00\x4E\x00\x00\x00\x00\x00\x00\x00\x00", NULL );
+	printk(KERN_INFO "mf.c: Preparing to bounce...\n");
+	signal_ce_msg("\x00\x00\x00\x4E\x00\x00\x00\x00\x00\x00\x00\x00", NULL);
 	for (;;);
 }
 
 /*
  * Display a single word SRC onto the VSP control panel.
  */
-void mf_displaySrc( u32 word )
+void mf_displaySrc(u32 word)
 {
 	u8 ce[12];
 
-	memcpy( ce, "\x00\x00\x00\x4A\x00\x00\x00\x01\x00\x00\x00\x00", 12 );
-	ce[8] = word>>24;
-	ce[9] = word>>16;
-	ce[10] = word>>8;
+	memcpy(ce, "\x00\x00\x00\x4A\x00\x00\x00\x01\x00\x00\x00\x00", 12);
+	ce[8] = word >> 24;
+	ce[9] = word >> 16;
+	ce[10] = word >> 8;
 	ce[11] = word;
-	signalCEMsg( ce, NULL );
+	signal_ce_msg(ce, NULL);
 }
 
 /*
  * Display a single word SRC of the form "PROGXXXX" on the VSP control panel.
  */
-void mf_displayProgress( u16 value )
+void mf_displayProgress(u16 value)
 {
 	u8 ce[12];
 	u8 src[72];
 
-	memcpy( ce, "\x00\x00\x04\x4A\x00\x00\x00\x48\x00\x00\x00\x00", 12 );
-	memcpy( src,
-		"\x01\x00\x00\x01"
-		"\x00\x00\x00\x00"
-		"\x00\x00\x00\x00"
-		"\x00\x00\x00\x00"
-		"\x00\x00\x00\x00"
-		"\x00\x00\x00\x00"
-		"\x00\x00\x00\x00"
-		"\x00\x00\x00\x00"
-		"\x00\x00\x00\x00"
-		"\x00\x00\x00\x00"
-		"PROGxxxx"
-		"                        ",
-		72 );
-	src[6] = value>>8;
-	src[7] = value&255;
-	src[44] = "0123456789ABCDEF"[(value>>12)&15];
-	src[45] = "0123456789ABCDEF"[(value>>8)&15];
-	src[46] = "0123456789ABCDEF"[(value>>4)&15];
-	src[47] = "0123456789ABCDEF"[value&15];
-	dmaAndSignalCEMsg( ce, NULL, src, sizeof(src), 9*64*1024 );
+	memcpy(ce, "\x00\x00\x04\x4A\x00\x00\x00\x48\x00\x00\x00\x00", 12);
+	memcpy(src, "\x01\x00\x00\x01\x00\x00\x00\x00\x00\x00\x00\x00"
+		"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
+		"\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00\x00"
+		"\x00\x00\x00\x00PROGxxxx                        ",
+		72);
+	src[6] = value >> 8;
+	src[7] = value & 255;
+	src[44] = "0123456789ABCDEF"[(value >> 12) & 15];
+	src[45] = "0123456789ABCDEF"[(value >> 8) & 15];
+	src[46] = "0123456789ABCDEF"[(value >> 4) & 15];
+	src[47] = "0123456789ABCDEF"[value & 15];
+	dma_and_signal_ce_msg(ce, NULL, src, sizeof(src), 9 * 64 * 1024);
 }
 
 /*
  * Clear the VSP control panel.  Used to "erase" an SRC that was
  * previously displayed.
  */
-void mf_clearSrc( void )
+void mf_clearSrc(void)
 {
-	signalCEMsg( "\x00\x00\x00\x4B\x00\x00\x00\x00\x00\x00\x00\x00", NULL );
+	signal_ce_msg("\x00\x00\x00\x4B\x00\x00\x00\x00\x00\x00\x00\x00", NULL);
 }
 
 /*
  * Initialization code here.
  */
-void mf_init( void )
+void mf_init(void)
 {
 	int i;
 
-    /* initialize */
-	spin_lock_init( &spinlock );
-	for ( i = 0; i < sizeof(prealloc)/sizeof(*prealloc); ++i )
-		free( &prealloc[i] );
-	HvLpEvent_registerHandler( HvLpEvent_Type_MachineFac, &hvHandler );
+	/* initialize */
+	spin_lock_init(&pending_event_spinlock);
+	for (i = 0;
+	     i < sizeof(pending_event_prealloc) / sizeof(*pending_event_prealloc);
+	     ++i)
+		free_pending_event(&pending_event_prealloc[i]);
+	HvLpEvent_registerHandler(HvLpEvent_Type_MachineFac, &hvHandler);
 
 	/* virtual continue ack */
-	signalCEMsg( "\x00\x00\x00\x57\x00\x00\x00\x00\x00\x00\x00\x00", NULL );
+	signal_ce_msg("\x00\x00\x00\x57\x00\x00\x00\x00\x00\x00\x00\x00", NULL);
 
 	/* initialization complete */
-	printk( KERN_NOTICE "mf.c: iSeries Linux LPAR Machine Facilities initialized\n" );
+	printk(KERN_NOTICE "mf.c: iSeries Linux LPAR Machine Facilities initialized\n");
 
 	iSeries_proc_callback(&mf_proc_init);
 }
 
 void mf_setSide(char side)
 {
-	int rc = 0;
-	u64 newSide = 0;
+	u64 newSide;
 	struct VspCmdData myVspCmd;
 
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
-	if (side == 'A')
-		newSide = 0;
-	else if (side == 'B')
-		newSide = 1;
-	else if (side == 'C')
-		newSide = 2; 
-	else
-		newSide = 3;
-
-	myVspCmd.xSubData.xFunction02SelectIplTypeIn.xIplType = newSide;
-	myVspCmd.xCmd = 10;
+	switch (side) {
+	case 'A':	newSide = 0;
+			break;
+	case 'B':	newSide = 1;
+			break;
+	case 'C':	newSide = 2; 
+			break;
+	default:	newSide = 3;
+			break;
+	}
+	myVspCmd.sub_data.ipl_type = newSide;
+	myVspCmd.cmd = 10;
 
-	rc = signalVspInstruction(&myVspCmd);
+	(void)signal_vsp_instruction(&myVspCmd);
 }
 
 char mf_getSide(void)
@@ -790,91 +715,82 @@ char mf_getSide(void)
 	struct VspCmdData myVspCmd;
 
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
-	myVspCmd.xCmd = 2;
-	myVspCmd.xSubData.xFunction02SelectIplTypeIn.xIplType = 0;
+	myVspCmd.cmd = 2;
+	myVspCmd.sub_data.ipl_type = 0;
 	mb();
-	rc = signalVspInstruction(&myVspCmd);
+	rc = signal_vsp_instruction(&myVspCmd);
 
 	if (rc != 0)
-	{
 		return returnValue;
-	} else {
-		if (myVspCmd.xRc == 0)
-		{
-			if (myVspCmd.xSubData.xGetIplTypeOut.xIplType == 0)
-				returnValue = 'A';
-			else if (myVspCmd.xSubData.xGetIplTypeOut.xIplType == 1)
-				returnValue = 'B';
-			else if (myVspCmd.xSubData.xGetIplTypeOut.xIplType == 2)
-				returnValue = 'C';
-			else
-				returnValue = 'D';
+
+	if (myVspCmd.result_code == 0) {
+		switch (myVspCmd.sub_data.ipl_type) {
+		case 0:	returnValue = 'A';
+			break;
+		case 1:	returnValue = 'B';
+			break;
+		case 2:	returnValue = 'C';
+			break;
+		default:	returnValue = 'D';
+			break;
 		}
 	}
-
 	return returnValue;
 }
 
 void mf_getSrcHistory(char *buffer, int size)
 {
-    /*    struct IplTypeReturnStuff returnStuff;
-     struct StackElement * newElement = newStackElement();
-     int rc = 0;
-     char *pages[4];
-
-     pages[0] = kmalloc(4096, GFP_ATOMIC);
-     pages[1] = kmalloc(4096, GFP_ATOMIC);
-     pages[2] = kmalloc(4096, GFP_ATOMIC);
-     pages[3] = kmalloc(4096, GFP_ATOMIC);
-     if (( newElement == NULL ) || (pages[0] == NULL) || (pages[1] == NULL) || (pages[2] == NULL) || (pages[3] == NULL))
-     rc = -ENOMEM;
-     else
-     {
-     returnStuff.xType = 0;
-     returnStuff.xRc = 0;
-     returnStuff.xDone = 0;
-     newElement->event.xHvLpEvent.xSubtype = 6;
-     newElement->event.xHvLpEvent.x.xSubtypeData = ('M'<<24)+('F'<<16)+('V'<<8)+('I'<<0);
-     newElement->event.xUnion.xVspCmd.xEvent = &returnStuff;
-     newElement->event.xUnion.xVspCmd.xCmd = 4;
-     newElement->event.xUnion.xVspCmd.xLpIndex = HvLpConfig_getLpIndex();
-     newElement->event.xUnion.xVspCmd.xRc = 0xFF;
-     newElement->event.xUnion.xVspCmd.xReserved1 = 0;
-     newElement->event.xUnion.xVspCmd.xSubData.xGetSrcHistoryIn.xPage[0] = (0x8000000000000000ULL | virt_to_absolute((unsigned long)pages[0]));
-     newElement->event.xUnion.xVspCmd.xSubData.xGetSrcHistoryIn.xPage[1] = (0x8000000000000000ULL | virt_to_absolute((unsigned long)pages[1]));
-     newElement->event.xUnion.xVspCmd.xSubData.xGetSrcHistoryIn.xPage[2] = (0x8000000000000000ULL | virt_to_absolute((unsigned long)pages[2]));
-     newElement->event.xUnion.xVspCmd.xSubData.xGetSrcHistoryIn.xPage[3] = (0x8000000000000000ULL | virt_to_absolute((unsigned long)pages[3]));
-     mb();
-     rc = signalEvent(newElement);
-     }
-
-     if (rc != 0)
-     {
-     return;
-     }
-     else
-     {
-     while (returnStuff.xDone != 1)
-     {
-     udelay(10);
-     }
-
-     if (returnStuff.xRc == 0)
-     {
-     memcpy(buffer, pages[0], size);
-     }
-     }
-
-     kfree(pages[0]);
-     kfree(pages[1]);
-     kfree(pages[2]);
-     kfree(pages[3]);*/
+#if 0
+	struct IplTypeReturnStuff returnStuff;
+	struct pending_event *ev = new_pending_event();
+	int rc = 0;
+	char *pages[4];
+
+	pages[0] = kmalloc(4096, GFP_ATOMIC);
+	pages[1] = kmalloc(4096, GFP_ATOMIC);
+	pages[2] = kmalloc(4096, GFP_ATOMIC);
+	pages[3] = kmalloc(4096, GFP_ATOMIC);
+	if ((ev == NULL) || (pages[0] == NULL) || (pages[1] == NULL)
+			 || (pages[2] == NULL) || (pages[3] == NULL))
+		return -ENOMEM;
+
+	returnStuff.xType = 0;
+	returnStuff.xRc = 0;
+	returnStuff.xDone = 0;
+	ev->event.hp_lp_event.xSubtype = 6;
+	ev->event.hp_lp_event.x.xSubtypeData =
+		subtype_data('M', 'F', 'V', 'I');
+	ev->event.data.vsp_cmd.xEvent = &returnStuff;
+	ev->event.data.vsp_cmd.cmd = 4;
+	ev->event.data.vsp_cmd.lp_index = HvLpConfig_getLpIndex();
+	ev->event.data.vsp_cmd.result_code = 0xFF;
+	ev->event.data.vsp_cmd.reserved = 0;
+	ev->event.data.vsp_cmd.sub_data.page[0] =
+		(0x8000000000000000ULL | virt_to_absolute((unsigned long)pages[0]));
+	ev->event.data.vsp_cmd.sub_data.page[1] =
+		(0x8000000000000000ULL | virt_to_absolute((unsigned long)pages[1]));
+	ev->event.data.vsp_cmd.sub_data.page[2] =
+		(0x8000000000000000ULL | virt_to_absolute((unsigned long)pages[2]));
+	ev->event.data.vsp_cmd.sub_data.page[3] =
+		(0x8000000000000000ULL | virt_to_absolute((unsigned long)pages[3]));
+	mb();
+	if (signal_event(ev) != 0)
+		return;
+
+ 	while (returnStuff.xDone != 1)
+ 		udelay(10);
+ 	if (returnStuff.xRc == 0)
+ 		memcpy(buffer, pages[0], size);
+	kfree(pages[0]);
+	kfree(pages[1]);
+	kfree(pages[2]);
+	kfree(pages[3]);
+#endif
 }
 
 void mf_setCmdLine(const char *cmdline, int size, u64 side)
 {
 	struct VspCmdData myVspCmd;
-	int rc = 0;
 	dma_addr_t dma_addr = 0;
 	char *page = pci_alloc_consistent(iSeries_vio_dev, size, &dma_addr);
 
@@ -886,13 +802,13 @@ void mf_setCmdLine(const char *cmdline, 
 	copy_from_user(page, cmdline, size);
 
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
-	myVspCmd.xCmd = 31;
-	myVspCmd.xSubData.xSetKernelCmdLineIn.xToken = dma_addr;
-	myVspCmd.xSubData.xSetKernelCmdLineIn.xAddressType = HvLpDma_AddressType_TceIndex;
-	myVspCmd.xSubData.xSetKernelCmdLineIn.xSide = side;
-	myVspCmd.xSubData.xSetKernelCmdLineIn.xTransferLength = size;
+	myVspCmd.cmd = 31;
+	myVspCmd.sub_data.kern.token = dma_addr;
+	myVspCmd.sub_data.kern.address_type = HvLpDma_AddressType_TceIndex;
+	myVspCmd.sub_data.kern.side = side;
+	myVspCmd.sub_data.kern.length = size;
 	mb();
-	rc = signalVspInstruction(&myVspCmd);
+	(void)signal_vsp_instruction(&myVspCmd);
 
 	pci_free_consistent(iSeries_vio_dev, size, page, dma_addr);
 }
@@ -900,31 +816,29 @@ void mf_setCmdLine(const char *cmdline, 
 int mf_getCmdLine(char *cmdline, int *size, u64 side)
 {
 	struct VspCmdData myVspCmd;
-	int rc = 0;
+	int rc;
 	int len = *size;
-	dma_addr_t dma_addr = pci_map_single(iSeries_vio_dev, cmdline, *size, PCI_DMA_FROMDEVICE);
+	dma_addr_t dma_addr;
 
-	memset(cmdline, 0, *size);
+	dma_addr = pci_map_single(iSeries_vio_dev, cmdline, len,
+			PCI_DMA_FROMDEVICE);
+	memset(cmdline, 0, len);
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
-	myVspCmd.xCmd = 33;
-	myVspCmd.xSubData.xGetKernelCmdLineIn.xToken = dma_addr;
-	myVspCmd.xSubData.xGetKernelCmdLineIn.xAddressType = HvLpDma_AddressType_TceIndex;
-	myVspCmd.xSubData.xGetKernelCmdLineIn.xSide = side;
-	myVspCmd.xSubData.xGetKernelCmdLineIn.xTransferLength = *size;
+	myVspCmd.cmd = 33;
+	myVspCmd.sub_data.kern.token = dma_addr;
+	myVspCmd.sub_data.kern.address_type = HvLpDma_AddressType_TceIndex;
+	myVspCmd.sub_data.kern.side = side;
+	myVspCmd.sub_data.kern.length = len;
 	mb();
-	rc = signalVspInstruction(&myVspCmd);
-
-	if ( ! rc ) {
+	rc = signal_vsp_instruction(&myVspCmd);
 
-		if (myVspCmd.xRc == 0)
-		{
-			len = myVspCmd.xSubData.xGetKernelCmdLineOut.xTransferLength;
-		}
-		/* else
-			{
+	if (rc == 0) {
+		if (myVspCmd.result_code == 0)
+			len = myVspCmd.sub_data.length_out;
+#if 0
+		else
 			memcpy(cmdline, "Bad cmdline", 11);
-			}
-		*/
+#endif
 	}
 
 	pci_unmap_single(iSeries_vio_dev, dma_addr, *size, PCI_DMA_FROMDEVICE);
@@ -936,10 +850,8 @@ int mf_getCmdLine(char *cmdline, int *si
 int mf_setVmlinuxChunk(const char *buffer, int size, int offset, u64 side)
 {
 	struct VspCmdData myVspCmd;
-	int rc = 0;
-
+	int rc;
 	dma_addr_t dma_addr = 0;
-
 	char *page = pci_alloc_consistent(iSeries_vio_dev, size, &dma_addr);
 
 	if (page == NULL) {
@@ -950,23 +862,19 @@ int mf_setVmlinuxChunk(const char *buffe
 	copy_from_user(page, buffer, size);
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
 
-	myVspCmd.xCmd = 30;
-	myVspCmd.xSubData.xGetKernelImageIn.xToken = dma_addr;
-	myVspCmd.xSubData.xGetKernelImageIn.xAddressType = HvLpDma_AddressType_TceIndex;
-	myVspCmd.xSubData.xGetKernelImageIn.xSide = side;
-	myVspCmd.xSubData.xGetKernelImageIn.xOffset = offset;
-	myVspCmd.xSubData.xGetKernelImageIn.xTransferLength = size;
+	myVspCmd.cmd = 30;
+	myVspCmd.sub_data.kern.token = dma_addr;
+	myVspCmd.sub_data.kern.address_type = HvLpDma_AddressType_TceIndex;
+	myVspCmd.sub_data.kern.side = side;
+	myVspCmd.sub_data.kern.offset = offset;
+	myVspCmd.sub_data.kern.length = size;
 	mb();
-	rc = signalVspInstruction(&myVspCmd);
-
-	if (rc == 0)
-	{
-		if (myVspCmd.xRc == 0)
-		{
+	rc = signal_vsp_instruction(&myVspCmd);
+	if (rc == 0) {
+		if (myVspCmd.result_code == 0)
 			rc = 0;
-		} else {
+		else
 			rc = -ENOMEM;
-		}
 	}
 
 	pci_free_consistent(iSeries_vio_dev, size, page, dma_addr);
@@ -977,31 +885,27 @@ int mf_setVmlinuxChunk(const char *buffe
 int mf_getVmlinuxChunk(char *buffer, int *size, int offset, u64 side)
 {
 	struct VspCmdData myVspCmd;
-	int rc = 0;
+	int rc;
 	int len = *size;
+	dma_addr_t dma_addr;
 
-	dma_addr_t dma_addr = pci_map_single(iSeries_vio_dev, buffer, *size, PCI_DMA_FROMDEVICE);
-
+	dma_addr = pci_map_single(iSeries_vio_dev, buffer, len,
+			PCI_DMA_FROMDEVICE);
 	memset(buffer, 0, len);
-
 	memset(&myVspCmd, 0, sizeof(myVspCmd));
-	myVspCmd.xCmd = 32;
-	myVspCmd.xSubData.xGetKernelImageIn.xToken = dma_addr;
-	myVspCmd.xSubData.xGetKernelImageIn.xAddressType = HvLpDma_AddressType_TceIndex;
-	myVspCmd.xSubData.xGetKernelImageIn.xSide = side;
-	myVspCmd.xSubData.xGetKernelImageIn.xOffset = offset;
-	myVspCmd.xSubData.xGetKernelImageIn.xTransferLength = len;
+	myVspCmd.cmd = 32;
+	myVspCmd.sub_data.kern.token = dma_addr;
+	myVspCmd.sub_data.kern.address_type = HvLpDma_AddressType_TceIndex;
+	myVspCmd.sub_data.kern.side = side;
+	myVspCmd.sub_data.kern.offset = offset;
+	myVspCmd.sub_data.kern.length = len;
 	mb();
-	rc = signalVspInstruction(&myVspCmd);
-
-	if (rc == 0)
-	{
-		if (myVspCmd.xRc == 0)
-		{
-			*size = myVspCmd.xSubData.xGetKernelImageOut.xTransferLength;
-		} else {
+	rc = signal_vsp_instruction(&myVspCmd);
+	if (rc == 0) {
+		if (myVspCmd.result_code == 0)
+			*size = myVspCmd.sub_data.length_out;
+		else
 			rc = -ENOMEM;
-		}
 	}
 
 	pci_unmap_single(iSeries_vio_dev, dma_addr, len, PCI_DMA_FROMDEVICE);
@@ -1015,12 +919,11 @@ int mf_setRtcTime(unsigned long time)
 
 	to_tm(time, &tm);
 
-	return mf_setRtc( &tm );
+	return mf_setRtc(&tm);
 }
 
-struct RtcTimeData
-{
-	struct semaphore *xSemaphore;
+struct RtcTimeData {
+	struct semaphore *sem;
 	struct CeMsgData xCeMsg;
 	int xRc;
 };
@@ -1030,26 +933,23 @@ void getRtcTimeComplete(void * token, st
 	struct RtcTimeData *rtc = (struct RtcTimeData *)token;
 
 	memcpy(&(rtc->xCeMsg), ceMsg, sizeof(rtc->xCeMsg));
-
 	rtc->xRc = 0;
-	up(rtc->xSemaphore);
+	up(rtc->sem);
 }
 
 static unsigned long lastsec = 1;
 
 int mf_getRtcTime(unsigned long *time)
 {
-/*    unsigned long usec, tsec; */
-	
 	u32 dataWord1 = *((u32 *)(&xSpCommArea.xBcdTimeAtIplStart));
 	u32 dataWord2 = *(((u32 *)&(xSpCommArea.xBcdTimeAtIplStart)) + 1);
 	int year = 1970;
-	int year1 = ( dataWord1 >> 24 ) & 0x000000FF;
-	int year2 = ( dataWord1 >> 16 ) & 0x000000FF;
-	int sec = ( dataWord1 >> 8 ) & 0x000000FF;
+	int year1 = (dataWord1 >> 24) & 0x000000FF;
+	int year2 = (dataWord1 >> 16) & 0x000000FF;
+	int sec = (dataWord1 >> 8) & 0x000000FF;
 	int min = dataWord1 & 0x000000FF;
-	int hour = ( dataWord2 >> 24 ) & 0x000000FF;
-	int day = ( dataWord2 >> 8 ) & 0x000000FF;
+	int hour = (dataWord2 >> 24) & 0x000000FF;
+	int day = (dataWord2 >> 8) & 0x000000FF;
 	int mon = dataWord2 & 0x000000FF;
 
 	BCD_TO_BIN(sec);
@@ -1062,49 +962,41 @@ int mf_getRtcTime(unsigned long *time)
 	year = year1 * 100 + year2;
 
 	*time = mktime(year, mon, day, hour, min, sec);
-
-	*time += ( jiffies / HZ );
+	*time += (jiffies / HZ);
     
-	/* Now THIS is a nasty hack!
+	/*
+	 * Now THIS is a nasty hack!
 	 * It ensures that the first two calls to mf_getRtcTime get different
 	 * answers.  That way the loop in init_time (time.c) will not think
 	 * the clock is stuck.
 	 */
-	if ( lastsec ) {
+	if (lastsec) {
 		*time -= lastsec;
 		--lastsec;
 	}
-    
 	return 0;
-
 }
 
-int mf_getRtc( struct rtc_time * tm )
+int mf_getRtc(struct rtc_time *tm)
 {
-
 	struct CeMsgCompleteData ceComplete;
 	struct RtcTimeData rtcData;
-	int rc = 0;
+	int rc;
 	DECLARE_MUTEX_LOCKED(Semaphore);
 
 	memset(&ceComplete, 0, sizeof(ceComplete));
 	memset(&rtcData, 0, sizeof(rtcData));
-
-	rtcData.xSemaphore = &Semaphore;
-
-	ceComplete.xHdlr = &getRtcTimeComplete;
-	ceComplete.xToken = (void *)&rtcData;
-
-	rc = signalCEMsg( "\x00\x00\x00\x40\x00\x00\x00\x00\x00\x00\x00\x00", &ceComplete );
-
-	if ( rc == 0 )
-	{
+	rtcData.sem = &Semaphore;
+	ceComplete.handler = &getRtcTimeComplete;
+	ceComplete.token = (void *)&rtcData;
+	rc = signal_ce_msg("\x00\x00\x00\x40\x00\x00\x00\x00\x00\x00\x00\x00",
+			&ceComplete);
+	if (rc == 0) {
 		down(&Semaphore);
 
-		if ( rtcData.xRc == 0)
-		{
-			if ( ( rtcData.xCeMsg.xCEMsg[2] == 0xa9 ) ||
-			     ( rtcData.xCeMsg.xCEMsg[2] == 0xaf ) ) {
+		if (rtcData.xRc == 0) {
+			if ((rtcData.xCeMsg.ce_msg[2] == 0xa9) ||
+			    (rtcData.xCeMsg.ce_msg[2] == 0xaf)) {
 				/* TOD clock is not set */
 				tm->tm_sec = 1;
 				tm->tm_min = 1;
@@ -1112,16 +1004,16 @@ int mf_getRtc( struct rtc_time * tm )
 				tm->tm_mday = 10;
 				tm->tm_mon = 8;
 				tm->tm_year = 71;
-				mf_setRtc( tm );
+				mf_setRtc(tm);
 			}
 			{
-				u32 dataWord1 = *((u32 *)(rtcData.xCeMsg.xCEMsg+4));
-				u32 dataWord2 = *((u32 *)(rtcData.xCeMsg.xCEMsg+8));
-				u8 year = (dataWord1 >> 16 ) & 0x000000FF;
-				u8 sec = ( dataWord1 >> 8 ) & 0x000000FF;
+				u32 dataWord1 = *((u32 *)(rtcData.xCeMsg.ce_msg+4));
+				u32 dataWord2 = *((u32 *)(rtcData.xCeMsg.ce_msg+8));
+				u8 year = (dataWord1 >> 16) & 0x000000FF;
+				u8 sec = (dataWord1 >> 8) & 0x000000FF;
 				u8 min = dataWord1 & 0x000000FF;
-				u8 hour = ( dataWord2 >> 24 ) & 0x000000FF;
-				u8 day = ( dataWord2 >> 8 ) & 0x000000FF;
+				u8 hour = (dataWord2 >> 24) & 0x000000FF;
+				u8 day = (dataWord2 >> 8) & 0x000000FF;
 				u8 mon = dataWord2 & 0x000000FF;
 
 				BCD_TO_BIN(sec);
@@ -1131,7 +1023,7 @@ int mf_getRtc( struct rtc_time * tm )
 				BCD_TO_BIN(mon);
 				BCD_TO_BIN(year);
 
-				if ( year <= 69 )
+				if (year <= 69)
 					year += 100;
 	    
 				tm->tm_sec = sec;
@@ -1154,17 +1046,14 @@ int mf_getRtc( struct rtc_time * tm )
 		tm->tm_wday = 0;
 		tm->tm_yday = 0;
 		tm->tm_isdst = 0;
-
 	}
 
 	return rc;
-
 }
 
 int mf_setRtc(struct rtc_time * tm)
 {
 	char ceTime[12] = "\x00\x00\x00\x41\x00\x00\x00\x00\x00\x00\x00\x00";
-	int rc = 0;
 	u8 day, mon, hour, min, sec, y1, y2;
 	unsigned year;
     
@@ -1194,10 +1083,5 @@ int mf_setRtc(struct rtc_time * tm)
 	ceTime[10] = day;
 	ceTime[11] = mon;
    
-	rc = signalCEMsg( ceTime, NULL );
-
-	return rc;
+	return signal_ce_msg(ceTime, NULL);
 }
-
-
-
diff -purN linux-2.5/arch/ppc64/kernel/misc.S linuxppc64-2.5/arch/ppc64/kernel/misc.S
--- linux-2.5/arch/ppc64/kernel/misc.S	2003-10-16 13:54:39.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/misc.S	2003-11-21 06:45:02.000000000 +0000
@@ -66,32 +66,31 @@ _GLOBAL(get_sp)
 	blr
 		
 #ifdef CONFIG_PPC_ISERIES
-/* unsigned long __no_use_save_flags(void) */
-_GLOBAL(__no_use_save_flags)
-#warning FIX ISERIES
-	mfspr	r4,SPRG3
-	lbz	r3,PACAPROCENABLED(r4)
+/* unsigned long local_save_flags(void) */
+_GLOBAL(local_get_flags)
+	lbz	r3,PACAPROCENABLED(r13)
 	blr
 
-/* void __no_use_restore_flags(unsigned long flags) */	
-_GLOBAL(__no_use_restore_flags)
-/*
- * Just set/clear the MSR_EE bit through restore/flags but do not
- * change anything else.  This is needed by the RT system and makes
- * sense anyway.
- *    -- Cort
- */
-#warning FIX ISERIES
-	mfspr	r6,SPRG3
-	lbz	r5,PACAPROCENABLED(r6)
+/* unsigned long local_irq_disable(void) */
+_GLOBAL(local_irq_disable)
+	lbz	r3,PACAPROCENABLED(r13)
+	li	r4,0
+	stb	r4,PACAPROCENABLED(r13)
+	blr			/* Done */
+
+/* void local_irq_restore(unsigned long flags) */	
+_GLOBAL(local_irq_restore)
+	lbz	r5,PACAPROCENABLED(r13)
 	 /* Check if things are setup the way we want _already_. */
 	cmpw	0,r3,r5
 	beqlr
 	/* are we enabling interrupts? */
 	cmpi	0,r3,0
-	stb	r3,PACAPROCENABLED(r6)
+	stb	r3,PACAPROCENABLED(r13)
 	beqlr
 	/* Check pending interrupts */
+	/*   A decrementer, IPI or PMC interrupt may have occurred
+	 *   while we were in the hypervisor (which enables) */
 	CHECKANYINT(r4,r5)
 	beqlr
 
@@ -101,35 +100,8 @@ _GLOBAL(__no_use_restore_flags)
 	li	r0,0x5555
 	sc
 	blr
+#endif /* CONFIG_PPC_ISERIES */
 
-_GLOBAL(__no_use_cli)
-#warning FIX ISERIES
-	mfspr	r5,SPRG3
-	lbz	r3,PACAPROCENABLED(r5)
-	li	r4,0
-	stb	r4,PACAPROCENABLED(r5)
-	blr			/* Done */
-
-_GLOBAL(__no_use_sti)
-#warning FIX ISERIES
-	mfspr	r6,SPRG3
-	li	r3,1
-	stb	r3,PACAPROCENABLED(r6)
-
-	/* Check for pending interrupts
-	 *   A decrementer, IPI or PMC interrupt may have occurred
-	 *   while we were in the hypervisor (which enables)
-	 */
-	CHECKANYINT(r4,r5)
-	beqlr
-
-	/* 
-	 * Handle pending interrupts in interrupt context
-	 */
-	li	r0,0x5555
-	sc	
-	blr
-#endif
 /*
  * Flush instruction cache.
  */
@@ -595,6 +567,10 @@ SYSCALL(dup)
 SYSCALL(execve)
 SYSCALL(waitpid)
 
+#ifdef CONFIG_PPC_ISERIES	/* hack hack hack */
+#define ppc_rtas	sys_ni_syscall
+#endif
+
 /* Why isn't this a) automatic, b) written in 'C'? */	
 	.balign 8
 _GLOBAL(sys_call_table32)
@@ -838,20 +814,22 @@ _GLOBAL(sys_call_table32)
 	.llong .sys_epoll_ctl
 	.llong .sys_epoll_wait
 	.llong .sys_remap_file_pages
-	.llong .sys_ni_syscall		/* 240 */
-	.llong .sys_ni_syscall
-	.llong .sys_ni_syscall
-	.llong .sys_ni_syscall
-	.llong .sys_ni_syscall
-	.llong .sys_ni_syscall		/* 245 */
-	.llong .sys_ni_syscall
-	.llong .sys_ni_syscall
-	.llong .sys_ni_syscall
+	.llong .ppc32_timer_create	/* 240 */
+	.llong .compat_timer_settime
+	.llong .compat_timer_gettime
+	.llong .sys_timer_getoverrun
+	.llong .sys_timer_delete
+	.llong .compat_clock_settime	/* 245 */
+	.llong .compat_clock_gettime
+	.llong .compat_clock_getres
+	.llong .compat_clock_nanosleep
 	.llong .sys_ni_syscall
 	.llong .sys32_tgkill		/* 250 */
 	.llong .sys32_utimes
-	.llong .sys_statfs64
-	.llong .sys_fstatfs64
+	.llong .compat_statfs64
+	.llong .compat_fstatfs64
+	.llong .ppc32_fadvise64_64	/* 32bit only fadvise64_64 */
+	.llong .ppc_rtas		/* 255 */
 
 	.balign 8
 _GLOBAL(sys_call_table)
@@ -1109,3 +1087,5 @@ _GLOBAL(sys_call_table)
 	.llong .sys_utimes
 	.llong .sys_statfs64
 	.llong .sys_fstatfs64
+	.llong .sys_ni_syscall		/* 32bit only fadvise64_64 */
+	.llong .ppc_rtas		/* 255 */
diff -purN linux-2.5/arch/ppc64/kernel/nvram.c linuxppc64-2.5/arch/ppc64/kernel/nvram.c
--- linux-2.5/arch/ppc64/kernel/nvram.c	2002-11-08 08:42:53.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/nvram.c	2003-11-21 04:51:10.000000000 +0000
@@ -20,23 +20,50 @@
 #include <linux/fcntl.h>
 #include <linux/nvram.h>
 #include <linux/init.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
 #include <asm/uaccess.h>
 #include <asm/nvram.h>
 #include <asm/rtas.h>
 #include <asm/prom.h>
+#include <asm/machdep.h>
 
-static unsigned int rtas_nvram_size;
+#define DEBUG_NVRAM
+
+static int nvram_scan_partitions(void);
+static int nvram_setup_partition(void);
+static int nvram_create_os_partition(void);
+static int nvram_remove_os_partition(void);
+static unsigned char nvram_checksum(struct nvram_header *p);
+static int nvram_write_header(struct nvram_partition * part);
+
+static unsigned int nvram_size;
 static unsigned int nvram_fetch, nvram_store;
-static char nvram_buf[4];	/* assume this is in the first 4GB */
+static char nvram_buf[NVRW_CNT];	/* assume this is in the first 4GB */
+static struct nvram_partition * nvram_part;
+static long nvram_error_log_index = -1;
+static long nvram_error_log_size = 0;
+static spinlock_t nvram_lock = SPIN_LOCK_UNLOCKED;
+
+volatile int no_more_logging = 1; /* Until we initialize everything,
+				   * make sure we don't try logging
+				   * anything */
+
+extern volatile int error_log_cnt;
+
+struct err_log_info {
+	int error_type;
+	unsigned int seq_num;
+};
 
-static loff_t nvram_llseek(struct file *file, loff_t offset, int origin)
+static loff_t dev_nvram_llseek(struct file *file, loff_t offset, int origin)
 {
 	switch (origin) {
 	case 1:
 		offset += file->f_pos;
 		break;
 	case 2:
-		offset += rtas_nvram_size;
+		offset += nvram_size;
 		break;
 	}
 	if (offset < 0)
@@ -46,53 +73,76 @@ static loff_t nvram_llseek(struct file *
 }
 
 
-static ssize_t read_nvram(struct file *file, char *buf,
+static ssize_t dev_nvram_read(struct file *file, char *buf,
 			  size_t count, loff_t *ppos)
 {
-	unsigned int i;
-	unsigned long len;
-	char *p = buf;
+	ssize_t len;
+	char *tmp_buffer;
 
 	if (verify_area(VERIFY_WRITE, buf, count))
 		return -EFAULT;
-	if (*ppos >= rtas_nvram_size)
+	if (*ppos >= nvram_size)
 		return 0;
-	for (i = *ppos; count > 0 && i < rtas_nvram_size; ++i, ++p, --count) {
-		if ((rtas_call(nvram_fetch, 3, 2, &len, i, __pa(nvram_buf), 1) != 0) ||
-		    len != 1)
-			return -EIO;
-		if (__put_user(nvram_buf[0], p))
-			return -EFAULT;
+	if (count > nvram_size) 
+		count = nvram_size;
+
+	tmp_buffer = (char *) kmalloc(count, GFP_KERNEL);
+	if (!tmp_buffer) {
+		printk(KERN_ERR "dev_read_nvram: kmalloc failed\n");
+		return -ENOMEM;
 	}
-	*ppos = i;
-	return p - buf;
+
+	len = ppc_md.nvram_read(tmp_buffer, count, ppos);
+	if ((long)len <= 0) {
+		kfree(tmp_buffer);
+		return len;
+	}
+
+	if (copy_to_user(buf, tmp_buffer, len)) {
+		kfree(tmp_buffer);
+		return -EFAULT;
+	}
+
+	kfree(tmp_buffer);
+	return len;
+
 }
 
-static ssize_t write_nvram(struct file *file, const char *buf,
+static ssize_t dev_nvram_write(struct file *file, const char *buf,
 			   size_t count, loff_t *ppos)
 {
-	unsigned int i;
-	unsigned long len;
-	const char *p = buf;
-	char c;
+	ssize_t len;
+	char * tmp_buffer;
 
 	if (verify_area(VERIFY_READ, buf, count))
 		return -EFAULT;
-	if (*ppos >= rtas_nvram_size)
+	if (*ppos >= nvram_size)
 		return 0;
-	for (i = *ppos; count > 0 && i < rtas_nvram_size; ++i, ++p, --count) {
-		if (__get_user(c, p))
-			return -EFAULT;
-		nvram_buf[0] = c;
-		if ((rtas_call(nvram_store, 3, 2, &len, i, __pa(nvram_buf), 1) != 0) ||
-		    len != 1)
-			return -EIO;
+	if (count > nvram_size)
+		count = nvram_size;
+
+	tmp_buffer = (char *) kmalloc(count, GFP_KERNEL);
+	if (!tmp_buffer) {
+		printk(KERN_ERR "dev_nvram_write: kmalloc failed\n");
+		return -ENOMEM;
 	}
-	*ppos = i;
-	return p - buf;
+	
+	if (copy_from_user(tmp_buffer, buf, count)) {
+		kfree(tmp_buffer);
+		return -EFAULT;
+	}
+
+	len = ppc_md.nvram_write(tmp_buffer, count, ppos);
+	if ((long)len <= 0) {
+		kfree(tmp_buffer);
+		return len;
+	}
+
+	kfree(tmp_buffer);
+	return len;
 }
 
-static int nvram_ioctl(struct inode *inode, struct file *file,
+static int dev_nvram_ioctl(struct inode *inode, struct file *file,
 	unsigned int cmd, unsigned long arg)
 {
 	return -EINVAL;
@@ -100,10 +150,10 @@ static int nvram_ioctl(struct inode *ino
 
 struct file_operations nvram_fops = {
 	.owner =	THIS_MODULE,
-	.llseek =	nvram_llseek,
-	.read =		read_nvram,
-	.write =	write_nvram,
-	.ioctl =	nvram_ioctl,
+	.llseek =	dev_nvram_llseek,
+	.read =		dev_nvram_read,
+	.write =	dev_nvram_write,
+	.ioctl =	dev_nvram_ioctl,
 };
 
 static struct miscdevice nvram_dev = {
@@ -112,21 +162,135 @@ static struct miscdevice nvram_dev = {
 	&nvram_fops
 };
 
+ssize_t pSeries_nvram_read(char *buf, size_t count, loff_t *index)
+{
+	unsigned int i;
+	unsigned long len, done;
+	unsigned long flags;
+	char *p = buf;
+
+	if (*index >= nvram_size)
+		return 0;
+
+	i = *index;
+	if (i + count > nvram_size)
+		count = nvram_size - i;
+
+	spin_lock_irqsave(&nvram_lock, flags);
+
+	for (; count != 0; count -= len) {
+		len = count;
+		if (len > NVRW_CNT)
+			len = NVRW_CNT;
+		
+		if ((rtas_call(nvram_fetch, 3, 2, &done, i, __pa(nvram_buf),
+			       len) != 0) || len != done) {
+			spin_unlock_irqrestore(&nvram_lock, flags);
+			return -EIO;
+		}
+		
+		memcpy(p, nvram_buf, len);
+
+		p += len;
+		i += len;
+	}
+
+	spin_unlock_irqrestore(&nvram_lock, flags);
+	
+	*index = i;
+	return p - buf;
+}
+
+ssize_t pSeries_nvram_write(char *buf, size_t count, loff_t *index)
+{
+	unsigned int i;
+	unsigned long len, done;
+	unsigned long flags;
+	const char *p = buf;
+
+	if (*index >= nvram_size)
+		return 0;
+
+	i = *index;
+	if (i + count > nvram_size)
+		count = nvram_size - i;
+
+	spin_lock_irqsave(&nvram_lock, flags);
+
+	for (; count != 0; count -= len) {
+		len = count;
+		if (len > NVRW_CNT)
+			len = NVRW_CNT;
+
+		memcpy(nvram_buf, p, len);
+
+		if ((rtas_call(nvram_store, 3, 2, &done, i, __pa(nvram_buf),
+			       len) != 0) || len != done) {
+			spin_unlock_irqrestore(&nvram_lock, flags);
+			return -EIO;
+		}
+		
+		p += len;
+		i += len;
+	}
+	spin_unlock_irqrestore(&nvram_lock, flags);
+	
+	*index = i;
+	return p - buf;
+}
+ 
 int __init nvram_init(void)
 {
 	struct device_node *nvram;
 	unsigned int *nbytes_p, proplen;
-	if ((nvram = find_type_devices("nvram")) != NULL) {
+	int error;
+	int rc;
+	
+	if ((nvram = of_find_node_by_type(NULL, "nvram")) != NULL) {
 		nbytes_p = (unsigned int *)get_property(nvram, "#bytes", &proplen);
 		if (nbytes_p && proplen == sizeof(unsigned int)) {
-			rtas_nvram_size = *nbytes_p;
+			nvram_size = *nbytes_p;
+		} else {
+			return -EIO;
 		}
 	}
 	nvram_fetch = rtas_token("nvram-fetch");
 	nvram_store = rtas_token("nvram-store");
-	printk(KERN_INFO "PPC64 nvram contains %d bytes\n", rtas_nvram_size);
+	printk(KERN_INFO "PPC64 nvram contains %d bytes\n", nvram_size);
+	of_node_put(nvram);
+
+  	rc = misc_register(&nvram_dev);
+  
+  	/* If we don't know how big NVRAM is then we shouldn't touch
+  	   the nvram partitions */
+  	if (nvram == NULL) {
+  		return rc;
+  	}
+  	
+  	/* initialize our anchor for the nvram partition list */
+  	nvram_part = (struct nvram_partition *) kmalloc(sizeof(struct nvram_partition), GFP_KERNEL);
+  	if (!nvram_part) {
+  		printk(KERN_ERR "nvram_init: Failed kmalloc\n");
+  		return -ENOMEM;
+  	}
+  	INIT_LIST_HEAD(&nvram_part->partition);
+  
+  	/* Get all the NVRAM partitions */
+  	error = nvram_scan_partitions();
+  	if (error) {
+  		printk(KERN_ERR "nvram_init: Failed nvram_scan_partitions\n");
+  		return error;
+  	}
+  		
+  	if(nvram_setup_partition()) 
+  		printk(KERN_WARNING "nvram_init: Could not find nvram partition"
+  		       " for nvram buffered error logging.\n");
+  
+#ifdef DEBUG_NVRAM
+	nvram_print_partitions("NVRAM Partitions");
+#endif
 
-	return misc_register(&nvram_dev);
+  	return rc;
 }
 
 void __exit nvram_cleanup(void)
@@ -134,6 +298,444 @@ void __exit nvram_cleanup(void)
         misc_deregister( &nvram_dev );
 }
 
+static int nvram_scan_partitions(void)
+{
+	loff_t cur_index = 0;
+	struct nvram_header phead;
+	struct nvram_partition * tmp_part;
+	unsigned char c_sum;
+	char * header;
+	long size;
+	
+	header = (char *) kmalloc(NVRAM_HEADER_LEN, GFP_KERNEL);
+	if (!header) {
+		printk(KERN_ERR "nvram_scan_partitions: Failed kmalloc\n");
+		return -ENOMEM;
+	}
+
+	while (cur_index < nvram_size) {
+
+		size = ppc_md.nvram_read(header, NVRAM_HEADER_LEN, &cur_index);
+		if (size != NVRAM_HEADER_LEN) {
+			printk(KERN_ERR "nvram_scan_partitions: Error parsing "
+			       "nvram partitions\n");
+			kfree(header);
+			return size;
+		}
+
+		cur_index -= NVRAM_HEADER_LEN; /* nvram_read will advance us */
+
+		memcpy(&phead, header, NVRAM_HEADER_LEN);
+
+		c_sum = nvram_checksum(&phead);
+		if (c_sum != phead.checksum)
+			printk(KERN_WARNING "WARNING: nvram partition checksum "
+			       "was %02x, should be %02x!\n", phead.checksum, c_sum);
+		
+		tmp_part = (struct nvram_partition *)
+			kmalloc(sizeof(struct nvram_partition), GFP_KERNEL);
+		if (!tmp_part) {
+			printk(KERN_ERR "nvram_scan_partitions: kmalloc failed\n");
+			kfree(header);
+			return -ENOMEM;
+		}
+		
+		memcpy(&tmp_part->header, &phead, NVRAM_HEADER_LEN);
+		tmp_part->index = cur_index;
+		list_add_tail(&tmp_part->partition, &nvram_part->partition);
+		
+		cur_index += phead.length * NVRAM_BLOCK_LEN;
+	}
+
+	kfree(header);
+	return 0;
+}
+
+/* nvram_setup_partition
+ *
+ * This will setup the partition we need for buffering the
+ * error logs and cleanup partitions if needed.
+ *
+ * The general strategy is the following:
+ * 1.) If there is ppc64,linux partition large enough then use it.
+ * 2.) If there is not a ppc64,linux partition large enough, search
+ * for a free partition that is large enough.
+ * 3.) If there is not a free partition large enough remove 
+ * _all_ OS partitions and consolidate the space.
+ * 4.) Will first try getting a chunk that will satisfy the maximum
+ * error log size (NVRAM_MAX_REQ).
+ * 5.) If the max chunk cannot be allocated then try finding a chunk
+ * that will satisfy the minum needed (NVRAM_MIN_REQ).
+ */
+static int nvram_setup_partition(void)
+{
+	struct list_head * p;
+	struct nvram_partition * part;
+	int rc;
+
+	/* see if we have an OS partition that meets our needs.
+	   will try getting the max we need.  If not we'll delete
+	   partitions and try again. */
+	list_for_each(p, &nvram_part->partition) {
+		part = list_entry(p, struct nvram_partition, partition);
+		if (part->header.signature != NVRAM_SIG_OS)
+			continue;
+
+		if (strcmp(part->header.name, "ppc64,linux"))
+			continue;
+
+		if (part->header.length >= NVRAM_MIN_REQ) {
+			/* found our partition */
+			nvram_error_log_index = part->index + NVRAM_HEADER_LEN;
+			nvram_error_log_size = ((part->header.length - 1) *
+						NVRAM_BLOCK_LEN) - sizeof(struct err_log_info);
+			return 0;
+		}
+	}
+	
+	/* try creating a partition with the free space we have */
+	rc = nvram_create_os_partition();
+	if (!rc) {
+		return 0;
+	}
+		
+	/* need to free up some space */
+	rc = nvram_remove_os_partition();
+	if (rc) {
+		return rc;
+	}
+	
+	/* create a partition in this new space */
+	rc = nvram_create_os_partition();
+	if (rc) {
+		printk(KERN_ERR "nvram_create_os_partition: Could not find a "
+		       "NVRAM partition large enough\n");
+		return rc;
+	}
+	
+	return 0;
+}
+
+static int nvram_remove_os_partition(void)
+{
+	struct list_head *i;
+	struct list_head *j;
+	struct nvram_partition * part;
+	struct nvram_partition * cur_part;
+	int rc;
+
+	list_for_each(i, &nvram_part->partition) {
+		part = list_entry(i, struct nvram_partition, partition);
+		if (part->header.signature != NVRAM_SIG_OS)
+			continue;
+		
+		/* Make os partition a free partition */
+		part->header.signature = NVRAM_SIG_FREE;
+		sprintf(part->header.name, "wwwwwwwwwwww");
+		part->header.checksum = nvram_checksum(&part->header);
+
+		/* Merge contiguous free partitions backwards */
+		list_for_each_prev(j, &part->partition) {
+			cur_part = list_entry(j, struct nvram_partition, partition);
+			if (cur_part == nvram_part || cur_part->header.signature != NVRAM_SIG_FREE) {
+				break;
+			}
+			
+			part->header.length += cur_part->header.length;
+			part->header.checksum = nvram_checksum(&part->header);
+			part->index = cur_part->index;
+
+			list_del(&cur_part->partition);
+			kfree(cur_part);
+			j = &part->partition; /* fixup our loop */
+		}
+		
+		/* Merge contiguous free partitions forwards */
+		list_for_each(j, &part->partition) {
+			cur_part = list_entry(j, struct nvram_partition, partition);
+			if (cur_part == nvram_part || cur_part->header.signature != NVRAM_SIG_FREE) {
+				break;
+			}
+
+			part->header.length += cur_part->header.length;
+			part->header.checksum = nvram_checksum(&part->header);
+
+			list_del(&cur_part->partition);
+			kfree(cur_part);
+			j = &part->partition; /* fixup our loop */
+		}
+		
+		rc = nvram_write_header(part);
+		if (rc <= 0) {
+			printk(KERN_ERR "nvram_remove_os_partition: nvram_write failed (%d)\n", rc);
+			return rc;
+		}
+
+	}
+	
+	return 0;
+}
+
+/* nvram_create_os_partition
+ *
+ * Create a OS linux partition to buffer error logs.
+ * Will create a partition starting at the first free
+ * space found if space has enough room.
+ */
+static int nvram_create_os_partition(void)
+{
+	struct list_head * p;
+	struct nvram_partition * part;
+	struct nvram_partition * new_part = NULL;
+	struct nvram_partition * free_part;
+	int seq_init[2] = { 0, 0 };
+	loff_t tmp_index;
+	long size = 0;
+	int rc;
+	
+	/* Find a free partition that will give us the maximum needed size 
+	   If can't find one that will give us the minimum size needed */
+	list_for_each(p, &nvram_part->partition) {
+		part = list_entry(p, struct nvram_partition, partition);
+		if (part->header.signature != NVRAM_SIG_FREE)
+			continue;
+
+		if (part->header.length >= NVRAM_MAX_REQ) {
+			size = NVRAM_MAX_REQ;
+			free_part = part;
+			break;
+		}
+		if (!size && part->header.length >= NVRAM_MIN_REQ) {
+			size = NVRAM_MIN_REQ;
+			free_part = part;
+		}
+	}
+	if (!size) {
+		return -ENOSPC;
+	}
+	
+	/* Create our OS partition */
+	new_part = (struct nvram_partition *)
+		kmalloc(sizeof(struct nvram_partition), GFP_KERNEL);
+	if (!new_part) {
+		printk(KERN_ERR "nvram_create_os_partition: kmalloc failed\n");
+		return -ENOMEM;
+	}
+
+	new_part->index = free_part->index;
+	new_part->header.signature = NVRAM_SIG_OS;
+	new_part->header.length = size;
+	sprintf(new_part->header.name, "ppc64,linux");
+	new_part->header.checksum = nvram_checksum(&new_part->header);
+
+	rc = nvram_write_header(new_part);
+	if (rc <= 0) {
+		printk(KERN_ERR "nvram_create_os_partition: nvram_write_header \
+				failed (%d)\n", rc);
+		return rc;
+	}
+
+	/* make sure and initialize to zero the sequence number and the error
+	   type logged */
+	tmp_index = new_part->index + NVRAM_HEADER_LEN;
+	rc = ppc_md.nvram_write((char *)&seq_init, sizeof(seq_init), &tmp_index);
+	if (rc <= 0) {
+		printk(KERN_ERR "nvram_create_os_partition: nvram_write failed (%d)\n", rc);
+		return rc;
+	}
+	
+	nvram_error_log_index = new_part->index + NVRAM_HEADER_LEN;
+	nvram_error_log_size = ((part->header.length - 1) *
+				NVRAM_BLOCK_LEN) - sizeof(struct err_log_info);
+	
+	list_add_tail(&new_part->partition, &free_part->partition);
+
+	if (free_part->header.length <= size) {
+		list_del(&free_part->partition);
+		kfree(free_part);
+		return 0;
+	} 
+
+	/* Adjust the partition we stole the space from */
+	free_part->index += size * NVRAM_BLOCK_LEN;
+	free_part->header.length -= size;
+	free_part->header.checksum = nvram_checksum(&free_part->header);
+	
+	rc = nvram_write_header(free_part);
+	if (rc <= 0) {
+		printk(KERN_ERR "nvram_create_os_partition: nvram_write_header "
+		       "failed (%d)\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+
+void nvram_print_partitions(char * label)
+{
+	struct list_head * p;
+	struct nvram_partition * tmp_part;
+	
+	printk(KERN_WARNING "--------%s---------\n", label);
+	printk(KERN_WARNING "indx\t\tsig\tchks\tlen\tname\n");
+	list_for_each(p, &nvram_part->partition) {
+		tmp_part = list_entry(p, struct nvram_partition, partition);
+		printk(KERN_WARNING "%d    \t%02x\t%02x\t%d\t%s\n",
+		       tmp_part->index, tmp_part->header.signature,
+		       tmp_part->header.checksum, tmp_part->header.length,
+		       tmp_part->header.name);
+	}
+}
+
+/* nvram_write_error_log
+ *
+ * We need to buffer the error logs into nvram to ensure that we have
+ * the failure information to decode.  If we have a severe error there
+ * is no way to guarantee that the OS or the machine is in a state to
+ * get back to user land and write the error to disk.  For example if
+ * the SCSI device driver causes a Machine Check by writing to a bad
+ * IO address, there is no way of guaranteeing that the device driver
+ * is in any state that is would also be able to write the error data
+ * captured to disk, thus we buffer it in NVRAM for analysis on the
+ * next boot.
+ *
+ * In NVRAM the partition containing the error log buffer will looks like:
+ * Header (in bytes):
+ * +-----------+----------+--------+------------+------------------+
+ * | signature | checksum | length | name       | data             |
+ * |0          |1         |2      3|4         15|16        length-1|
+ * +-----------+----------+--------+------------+------------------+
+ *
+ * The 'data' section would look like (in bytes):
+ * +--------------+------------+-----------------------------------+
+ * | event_logged | sequence # | error log                         |
+ * |0            3|4          7|8            nvram_error_log_size-1|
+ * +--------------+------------+-----------------------------------+
+ *
+ * event_logged: 0 if event has not been logged to syslog, 1 if it has
+ * sequence #: The unique sequence # for each event. (until it wraps)
+ * error log: The error log from event_scan
+ */
+int nvram_write_error_log(char * buff, int length, unsigned int err_type)
+{
+	int rc;
+	loff_t tmp_index;
+	struct err_log_info info;
+	
+	if (no_more_logging) {
+		return -EPERM;
+	}
+
+	if (nvram_error_log_index == -1) {
+		return -ESPIPE;
+	}
+
+	if (length > nvram_error_log_size) {
+		length = nvram_error_log_size;
+	}
+
+	info.error_type = err_type;
+	info.seq_num = error_log_cnt;
+
+	tmp_index = nvram_error_log_index;
+
+	rc = ppc_md.nvram_write((char *)&info, sizeof(struct err_log_info), &tmp_index);
+	if (rc <= 0) {
+		printk(KERN_ERR "nvram_write_error_log: Failed nvram_write (%d)\n", rc);
+		return rc;
+	}
+
+	rc = ppc_md.nvram_write(buff, length, &tmp_index);
+	if (rc <= 0) {
+		printk(KERN_ERR "nvram_write_error_log: Failed nvram_write (%d)\n", rc);
+		return rc;
+	}
+	
+	return 0;
+}
+
+/* nvram_read_error_log
+ *
+ * Reads nvram for error log for at most 'length'
+ */
+int nvram_read_error_log(char * buff, int length, unsigned int * err_type)
+{
+	int rc;
+	loff_t tmp_index;
+	struct err_log_info info;
+	
+	if (nvram_error_log_index == -1)
+		return -1;
+
+	if (length > nvram_error_log_size)
+		length = nvram_error_log_size;
+
+	tmp_index = nvram_error_log_index;
+
+	rc = ppc_md.nvram_read((char *)&info, sizeof(struct err_log_info), &tmp_index);
+	if (rc <= 0) {
+		printk(KERN_ERR "nvram_read_error_log: Failed nvram_read (%d)\n", rc);
+		return rc;
+	}
+
+	rc = ppc_md.nvram_read(buff, length, &tmp_index);
+	if (rc <= 0) {
+		printk(KERN_ERR "nvram_read_error_log: Failed nvram_read (%d)\n", rc);
+		return rc;
+	}
+
+	error_log_cnt = info.seq_num;
+	*err_type = info.error_type;
+
+	return 0;
+}
+
+/* This doesn't actually zero anything, but it sets the event_logged
+ * word to tell that this event is safely in syslog.
+ */
+int nvram_clear_error_log()
+{
+	loff_t tmp_index;
+	int clear_word = ERR_FLAG_ALREADY_LOGGED;
+	int rc;
+
+	tmp_index = nvram_error_log_index;
+	
+	rc = ppc_md.nvram_write((char *)&clear_word, sizeof(int), &tmp_index);
+	if (rc <= 0) {
+		printk(KERN_ERR "nvram_clear_error_log: Failed nvram_write (%d)\n", rc);
+		return rc;
+	}
+
+	return 0;
+}
+
+static int nvram_write_header(struct nvram_partition * part)
+{
+	loff_t tmp_index;
+	int rc;
+	
+	tmp_index = part->index;
+	rc = ppc_md.nvram_write((char *)&part->header, NVRAM_HEADER_LEN, &tmp_index); 
+
+	return rc;
+}
+
+static unsigned char nvram_checksum(struct nvram_header *p)
+{
+	unsigned int c_sum, c_sum2;
+	unsigned short *sp = (unsigned short *)p->name; /* assume 6 shorts */
+	c_sum = p->signature + p->length + sp[0] + sp[1] + sp[2] + sp[3] + sp[4] + sp[5];
+
+	/* The sum may have spilled into the 3rd byte.  Fold it back. */
+	c_sum = ((c_sum & 0xffff) + (c_sum >> 16)) & 0xffff;
+	/* The sum cannot exceed 2 bytes.  Fold it into a checksum */
+	c_sum2 = (c_sum >> 8) + (c_sum << 8);
+	c_sum = ((c_sum + c_sum2) >> 8) & 0xff;
+	return c_sum;
+}
+
 module_init(nvram_init);
 module_exit(nvram_cleanup);
 MODULE_LICENSE("GPL");
diff -purN linux-2.5/arch/ppc64/kernel/open_pic.c linuxppc64-2.5/arch/ppc64/kernel/open_pic.c
--- linux-2.5/arch/ppc64/kernel/open_pic.c	2003-08-19 02:46:23.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/open_pic.c	2003-11-07 22:47:21.000000000 +0000
@@ -85,10 +85,10 @@ unsigned int openpic_vec_spurious;
  */
 #ifdef CONFIG_SMP
 #define THIS_CPU		Processor[cpu]
-#define DECL_THIS_CPU		int cpu = smp_processor_id()
+#define DECL_THIS_CPU		int cpu = hard_smp_processor_id()
 #define CHECK_THIS_CPU		check_arg_cpu(cpu)
 #else
-#define THIS_CPU		Processor[smp_processor_id()]
+#define THIS_CPU		Processor[hard_smp_processor_id()]
 #define DECL_THIS_CPU
 #define CHECK_THIS_CPU
 #endif /* CONFIG_SMP */
@@ -130,19 +130,29 @@ unsigned int openpic_vec_spurious;
 
 #define GET_ISU(source)	ISU[(source) >> 4][(source) & 0xf]
 
+void
+openpic_init_irq_desc(irq_desc_t *desc)
+{
+	/* Don't mess with the handler if already set.
+	 * This leaves the setup of isa/ipi handlers undisturbed.
+	 */
+	if (!desc->handler)
+		desc->handler = &open_pic;
+}
+
 void __init openpic_init_IRQ(void)
 {
         struct device_node *np;
         int i;
         unsigned int *addrp;
         unsigned char* chrp_int_ack_special = 0;
-        unsigned char init_senses[NR_IRQS - NUM_8259_INTERRUPTS];
+        unsigned char init_senses[NR_IRQS - NUM_ISA_INTERRUPTS];
         int nmi_irq = -1;
 #if defined(CONFIG_VT) && defined(CONFIG_ADB_KEYBOARD) && defined(XMON)
         struct device_node *kbd;
 #endif
 
-        if (!(np = find_devices("pci"))
+        if (!(np = of_find_node_by_name(NULL, "pci"))
             || !(addrp = (unsigned int *)
                  get_property(np, "8259-interrupt-acknowledge", NULL)))
                 printk(KERN_ERR "Cannot find pci to get ack address\n");
@@ -151,13 +161,14 @@ void __init openpic_init_IRQ(void)
 			__ioremap(addrp[prom_n_addr_cells(np)-1], 1, _PAGE_NO_CACHE);
         /* hydra still sets OpenPIC_InitSenses to a static set of values */
         if (OpenPIC_InitSenses == NULL) {
-                prom_get_irq_senses(init_senses, NUM_8259_INTERRUPTS, NR_IRQS);
+                prom_get_irq_senses(init_senses, NUM_ISA_INTERRUPTS, NR_IRQS);
                 OpenPIC_InitSenses = init_senses;
-                OpenPIC_NumInitSenses = NR_IRQS - NUM_8259_INTERRUPTS;
+                OpenPIC_NumInitSenses = NR_IRQS - NUM_ISA_INTERRUPTS;
         }
-        openpic_init(1, NUM_8259_INTERRUPTS, chrp_int_ack_special, nmi_irq);
-        for ( i = 0 ; i < NUM_8259_INTERRUPTS  ; i++ )
-                irq_desc[i].handler = &i8259_pic;
+        openpic_init(1, NUM_ISA_INTERRUPTS, chrp_int_ack_special, nmi_irq);
+        for ( i = 0 ; i < NUM_ISA_INTERRUPTS  ; i++ )
+                get_real_irq_desc(i)->handler = &i8259_pic;
+	of_node_put(np);
 }
 
 static inline u_int openpic_read(volatile u_int *addr)
@@ -341,8 +352,8 @@ void __init openpic_init(int main_pic, i
 		/* Disabled, Priority 10..13 */
 		openpic_initipi(i, 10+i, openpic_vec_ipi+i);
 		/* IPIs are per-CPU */
-		irq_desc[openpic_vec_ipi+i].status |= IRQ_PER_CPU;
-		irq_desc[openpic_vec_ipi+i].handler = &open_pic_ipi;
+		get_real_irq_desc(openpic_vec_ipi+i)->status |= IRQ_PER_CPU;
+		get_real_irq_desc(openpic_vec_ipi+i)->handler = &open_pic_ipi;
 	}
 #endif
 
@@ -354,7 +365,7 @@ void __init openpic_init(int main_pic, i
 	/* SIOint (8259 cascade) is special */
 	if (offset) {
 		openpic_initirq(0, 8, offset, 1, 1);
-		openpic_mapirq(0, 1 << boot_cpuid);
+		openpic_mapirq(0, 1 << get_hard_smp_processor_id(boot_cpuid));
 	}
 
 	/* Init all external sources */
@@ -367,18 +378,14 @@ void __init openpic_init(int main_pic, i
 		pri = (i == programmer_switch_irq)? 9: 8;
 		sense = (i < OpenPIC_NumInitSenses)? OpenPIC_InitSenses[i]: 1;
 		if (sense)
-			irq_desc[i+offset].status = IRQ_LEVEL;
+			get_real_irq_desc(i+offset)->status = IRQ_LEVEL;
 
 		/* Enabled, Priority 8 or 9 */
 		openpic_initirq(i, pri, i+offset, !sense, sense);
 		/* Processor 0 */
-		openpic_mapirq(i, 1 << boot_cpuid);
+		openpic_mapirq(i, 1 << get_hard_smp_processor_id(boot_cpuid));
 	}
 
-	/* Init descriptors */
-	for (i = offset; i < NumSources + offset; i++)
-		irq_desc[i].handler = &open_pic;
-
 	/* Initialize the spurious interrupt */
 	ppc64_boot_msg(0x24, "OpenPic Spurious");
 	openpic_set_spurious(openpic_vec_spurious);
@@ -397,7 +404,7 @@ static int __init openpic_setup_i8259(vo
 {
 	if (naca->interrupt_controller == IC_OPEN_PIC) {
 		/* Initialize the cascade */
-		if (request_irq(NUM_8259_INTERRUPTS, no_action, SA_INTERRUPT,
+		if (request_irq(NUM_ISA_INTERRUPTS, no_action, SA_INTERRUPT,
 				"82c59 cascade", NULL))
 			printk(KERN_ERR "Unable to get OpenPIC IRQ 0 for cascade\n");
 		i8259_init();
@@ -513,10 +520,23 @@ static void openpic_set_spurious(u_int v
 			   vec);
 }
 
+/*
+ * Convert a cpu mask from logical to physical cpu numbers.
+ */
+static inline u32 physmask(u32 cpumask)
+{
+	int i;
+	u32 mask = 0;
+
+	for (i = 0; i < NR_CPUS; ++i, cpumask >>= 1)
+		mask |= (cpumask & 1) << get_hard_smp_processor_id(i);
+	return mask;
+}
+
 void openpic_init_processor(u_int cpumask)
 {
 	openpic_write(&OpenPIC->Global.Processor_Initialization,
-		      cpumask & cpus_coerce(cpu_online_map));
+		      physmask(cpumask & cpus_coerce(cpu_online_map)));
 }
 
 #ifdef CONFIG_SMP
@@ -550,7 +570,7 @@ void openpic_cause_IPI(u_int ipi, u_int 
 	CHECK_THIS_CPU;
 	check_arg_ipi(ipi);
 	openpic_write(&OpenPIC->THIS_CPU.IPI_Dispatch(ipi),
-		      cpumask & cpus_coerce(cpu_online_map));
+		      physmask(cpumask & cpus_coerce(cpu_online_map)));
 }
 
 void openpic_request_IPIs(void)
@@ -591,7 +611,7 @@ void __devinit do_openpic_setup_cpu(void
 {
 #ifdef CONFIG_IRQ_ALL_CPUS
  	int i;
-	u32 msk = 1 << smp_processor_id();
+	u32 msk = 1 << hard_smp_processor_id();
 #endif
 
 	spin_lock(&openpic_setup_lock);
@@ -636,7 +656,7 @@ static void __init openpic_maptimer(u_in
 {
 	check_arg_timer(timer);
 	openpic_write(&OpenPIC->Global.Timer[timer].Destination,
-		      cpumask & cpus_coerce(cpu_online_map));
+		      physmask(cpumask & cpus_coerce(cpu_online_map)));
 }
 
 
@@ -753,7 +773,7 @@ static inline void openpic_set_sense(u_i
 
 static void openpic_end_irq(unsigned int irq_nr)
 {
-	if ((irq_desc[irq_nr].status & IRQ_LEVEL) != 0)
+	if ((get_irq_desc(irq_nr)->status & IRQ_LEVEL) != 0)
 		openpic_eoi();
 }
 
@@ -762,7 +782,7 @@ static void openpic_set_affinity(unsigne
 	cpumask_t tmp;
 
 	cpus_and(tmp, cpumask, cpu_online_map);
-	openpic_mapirq(irq_nr - open_pic_irq_offset, cpus_coerce(tmp));
+	openpic_mapirq(irq_nr - open_pic_irq_offset, physmask(cpus_coerce(tmp)));
 }
 
 #ifdef CONFIG_SMP
diff -purN linux-2.5/arch/ppc64/kernel/open_pic.h linuxppc64-2.5/arch/ppc64/kernel/open_pic.h
--- linux-2.5/arch/ppc64/kernel/open_pic.h	2003-08-19 02:46:23.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/open_pic.h	2003-09-12 11:01:38.000000000 +0000
@@ -38,9 +38,4 @@ extern void openpic_init_processor(u_int
 extern void openpic_setup_ISU(int isu_num, unsigned long addr);
 extern void openpic_cause_IPI(u_int ipi, u_int cpumask);
 
-extern inline int openpic_to_irq(int irq)
-{
-	return irq += NUM_8259_INTERRUPTS;
-}
-/*extern int open_pic_irq_offset;*/
 #endif /* _PPC64_KERNEL_OPEN_PIC_H */
diff -purN linux-2.5/arch/ppc64/kernel/pSeries_htab.c linuxppc64-2.5/arch/ppc64/kernel/pSeries_htab.c
--- linux-2.5/arch/ppc64/kernel/pSeries_htab.c	2003-06-07 01:19:27.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pSeries_htab.c	2003-09-25 07:00:40.000000000 +0000
@@ -389,10 +389,11 @@ void hpte_init_pSeries(void)
 	ppc_md.hpte_remove     	= pSeries_hpte_remove;
 
 	/* Disable TLB batching on nighthawk */
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	if (root) {
 		model = get_property(root, "model", NULL);
 		if (strcmp(model, "CHRP IBM,9076-N81"))
 			ppc_md.flush_hash_range = pSeries_flush_hash_range;
+		of_node_put(root);
 	}
 }
diff -purN linux-2.5/arch/ppc64/kernel/pSeries_hvCall.S linuxppc64-2.5/arch/ppc64/kernel/pSeries_hvCall.S
--- linux-2.5/arch/ppc64/kernel/pSeries_hvCall.S	2002-09-17 23:32:53.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pSeries_hvCall.S	2003-11-14 04:34:13.000000000 +0000
@@ -22,7 +22,7 @@
 /*
  * hcall interface to pSeries LPAR
  */
-#define HSC .long 0x44000022
+#define HVSC .long 0x44000022
 
 /* long plpar_hcall(unsigned long opcode,	 R3 
 		 unsigned long arg1,		 R4 
@@ -44,7 +44,7 @@ _GLOBAL(plpar_hcall)
         std     r9,-16(r1)
         std     r10,-24(r1)
 	
-	HSC                     /* invoke the hypervisor */
+	HVSC                    /* invoke the hypervisor */
 
         ld      r10,-8(r1)      /* Fetch r4-r7 ret args. */
         std     r4,0(r10)
@@ -63,7 +63,39 @@ _GLOBAL(plpar_hcall)
 _GLOBAL(plpar_hcall_norets)
 	mfcr	r0
 	std	r0,-8(r1)
-	HSC                     /* invoke the hypervisor */
+	HVSC                    /* invoke the hypervisor */
+	ld	r0,-8(r1)
+	mtcrf	0xff,r0
+	blr                     /* return r3 = status */
+
+
+/* long plpar_hcall_8arg_2ret(unsigned long opcode,		 R3 
+			     unsigned long arg1,		 R4 
+		 	     unsigned long arg2,		 R5 
+			     unsigned long arg3,		 R6 
+	 		     unsigned long arg4,		 R7 
+	 		     unsigned long arg5,		 R8 
+			     unsigned long arg6,		 R9 
+	 		     unsigned long arg7,		 R10 
+	 		     unsigned long arg8,		 R11
+	 		     unsigned long *out1);		 R12	
+
+ */
+
+	.text
+_GLOBAL(plpar_hcall_8arg_2ret)
+	mfcr	r0
+	std	r0,-8(r1)
+	stdu	r1,-32(r1)
+
+        std     r12,-8(r1)      /* Save out ptr */
+	
+	HVSC                    /* invoke the hypervisor */
+
+        ld      r10,-8(r1)      /* Fetch r4 ret arg */
+        std     r4,0(r10)
+
+	ld	r1,0(r1)
 	ld	r0,-8(r1)
 	mtcrf	0xff,r0
 	blr                     /* return r3 = status */
diff -purN linux-2.5/arch/ppc64/kernel/pSeries_lpar.c linuxppc64-2.5/arch/ppc64/kernel/pSeries_lpar.c
--- linux-2.5/arch/ppc64/kernel/pSeries_lpar.c	2003-09-07 01:40:37.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pSeries_lpar.c	2003-11-04 20:32:24.000000000 +0000
@@ -35,6 +35,32 @@
 #include <asm/tlbflush.h>
 #include <asm/tlb.h>
 #include <asm/hvcall.h>
+#include <asm/prom.h>
+
+long poll_pending(void)
+{
+	unsigned long dummy;
+	return plpar_hcall(H_POLL_PENDING, 0, 0, 0, 0,
+			   &dummy, &dummy, &dummy);
+}
+
+long prod_processor(void)
+{
+	plpar_hcall_norets(H_PROD);
+	return(0); 
+}
+
+long cede_processor(void)
+{
+	plpar_hcall_norets(H_CEDE);
+	return(0); 
+}
+
+long register_vpa(unsigned long flags, unsigned long proc, unsigned long vpa)
+{
+	plpar_hcall_norets(H_REGISTER_VPA, flags, proc, vpa);
+	return(0); 
+}
 
 long plpar_pte_remove(unsigned long flags,
 		      unsigned long ptex,
@@ -206,6 +232,61 @@ static unsigned char udbg_getcLP(void)
 	}
 }
 
+/* returns 0 if couldn't find or use /chosen/stdout as console */
+static int find_udbg_vterm(void)
+{
+	struct device_node *stdout_node;
+	u32 *termno;
+	char *name;
+	int found = 0;
+
+	/* find the boot console from /chosen/stdout */
+	if (!of_stdout_device) {
+		printk(KERN_WARNING "couldn't get path from /chosen/stdout!\n");
+		return found;
+	}
+	stdout_node = of_find_node_by_path(of_stdout_device);
+	if (!stdout_node) {
+		printk(KERN_WARNING "couldn't find node from /chosen/stdout\n");
+		return found;
+	}
+
+	/* now we have the stdout node; figure out what type of device it is. */
+	name = (char *)get_property(stdout_node, "name", 0);
+	if (!name) {
+		printk(KERN_WARNING "stdout node missing 'name' property!\n");
+		goto out;
+	}
+
+	if (strncmp(name, "vty", 3) == 0) {
+		if (device_is_compatible(stdout_node, "hvterm1")) {
+			termno = (u32 *)get_property(stdout_node, "reg", 0);
+			if (termno) {
+				vtermno = termno[0];
+				ppc_md.udbg_putc = udbg_putcLP;
+				ppc_md.udbg_getc = udbg_getcLP;
+				ppc_md.udbg_getc_poll = udbg_getc_pollLP;
+				found = 1;
+			}
+		} else {
+			/* XXX implement udbg_putcLP_vtty for hvterm-protocol1 case */
+			printk(KERN_WARNING "%s doesn't speak hvterm1; "
+					"can't print udbg messages\n", of_stdout_device);
+		}
+	} else if (strncmp(name, "serial", 6)) {
+		/* XXX fix ISA serial console */
+		printk(KERN_WARNING "serial stdout on LPAR ('%s')! "
+				"can't print udbg messages\n", of_stdout_device);
+	} else {
+		printk(KERN_WARNING "don't know how to print to stdout '%s'\n",
+				of_stdout_device);
+	}
+
+out:
+	of_node_put(stdout_node);
+	return found;
+}
+
 void pSeries_lpar_mm_init(void);
 
 /* This is called early in setup.c.
@@ -213,8 +294,6 @@ void pSeries_lpar_mm_init(void);
  */
 void pSeriesLP_init_early(void)
 {
-	struct device_node *np;
-
 	pSeries_lpar_mm_init();
 
 	ppc_md.tce_build	 = tce_build_pSeriesLP;
@@ -225,24 +304,13 @@ void pSeriesLP_init_early(void)
 #endif
 
 	/* The keyboard is not useful in the LPAR environment.
-	 * Leave all the interfaces NULL.
+	 * Leave all the ppc_md keyboard interfaces NULL.
 	 */
 
-	/* lookup the first virtual terminal number in case we don't have a
-	 * com port. Zero is probably correct in case someone calls udbg
-	 * before the init. The property is a pair of numbers.  The first
-	 * is the starting termno (the one we use) and the second is the
-	 * number of terminals.
-	 */
-	np = find_path_device("/rtas");
-	if (np) {
-		u32 *termno = (u32 *)get_property(np, "ibm,termno", 0);
-		if (termno)
-			vtermno = termno[0];
-	}
-	ppc_md.udbg_putc = udbg_putcLP;
-	ppc_md.udbg_getc = udbg_getcLP;
-	ppc_md.udbg_getc_poll = udbg_getc_pollLP;
+	if (0 == find_udbg_vterm()) {
+		printk(KERN_WARNING
+			"can't use stdout; can't print early debug messages.\n");
+	}
 }
 
 int hvc_get_chars(int index, char *buf, int count)
@@ -285,23 +353,28 @@ int hvc_put_chars(int index, const char 
 	return -1;
 }
 
+/* return the number of client vterms present */
+/* XXX this requires an interface change to handle multiple discontiguous
+ * vterms */
 int hvc_count(int *start_termno)
 {
-	u32 *termno;
-	struct device_node *dn;
+	struct device_node *vty;
+	int num_found = 0;
 
-	if ((dn = find_path_device("/rtas")) != NULL) {
-		if ((termno = (u32 *)get_property(dn, "ibm,termno", 0)) != NULL) {
-			if (start_termno)
-				*start_termno = termno[0];
-			return termno[1];
-		}
+	/* consider only the first vty node.
+	 * we should _always_ be able to find one. */
+	vty = of_find_node_by_name(NULL, "vty");
+	if (vty && device_is_compatible(vty, "hvterm1")) {
+		u32 *termno = (u32 *)get_property(vty, "reg", 0);
+
+		if (termno && start_termno)
+			*start_termno = *termno;
+		num_found = 1;
+		of_node_put(vty);
 	}
-	return 0;
-}
-
-
 
+	return num_found;
+}
 
 long pSeries_lpar_hpte_insert(unsigned long hpte_group,
 			      unsigned long va, unsigned long prpn,
diff -purN linux-2.5/arch/ppc64/kernel/pSeries_pci.c linuxppc64-2.5/arch/ppc64/kernel/pSeries_pci.c
--- linux-2.5/arch/ppc64/kernel/pSeries_pci.c	2003-08-17 19:52:50.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pSeries_pci.c	2003-11-19 17:10:13.000000000 +0000
@@ -176,6 +176,55 @@ int pci_read_irq_line(struct pci_dev *pc
 	       pci_name(pci_dev), pci_dev->irq);
 	return 0;
 }
+EXPORT_SYMBOL(pci_read_irq_line);
+
+#define ISA_SPACE_MASK 0x1
+#define ISA_SPACE_IO 0x1
+
+static void pci_process_ISA_OF_ranges(struct device_node *isa_node,
+		                      unsigned long phb_io_base_phys,
+				      void * phb_io_base_virt)
+{
+	struct isa_range *range;
+	unsigned long pci_addr;
+	unsigned int isa_addr;
+	unsigned int size;
+	int rlen = 0;
+
+	range = (struct isa_range *) get_property(isa_node, "ranges", &rlen);
+	if (rlen < sizeof(struct isa_range)) {
+		printk(KERN_ERR "unexpected isa range size: %s\n", 
+				__FUNCTION__);
+		return;	
+	}
+	
+	/* From "ISA Binding to 1275"
+	 * The ranges property is laid out as an array of elements,
+	 * each of which comprises:
+	 *   cells 0 - 1:	an ISA address
+	 *   cells 2 - 4:	a PCI address 
+	 *			(size depending on dev->n_addr_cells)
+	 *   cell 5:		the size of the range
+	 */
+	if ((range->isa_addr.a_hi && ISA_SPACE_MASK) == ISA_SPACE_IO) {
+		isa_addr = range->isa_addr.a_lo;
+		pci_addr = (unsigned long) range->pci_addr.a_mid << 32 | 
+			range->pci_addr.a_lo;
+
+		/* Assume these are both zero */
+		if ((pci_addr != 0) || (isa_addr != 0)) {
+			printk(KERN_ERR "unexpected isa to pci mapping: %s\n",
+					__FUNCTION__);
+			return;
+		}
+		
+		size = PAGE_ALIGN(range->size);
+
+		__ioremap_explicit(phb_io_base_phys, 
+				   (unsigned long) phb_io_base_virt, 
+				   size, _PAGE_NO_CACHE);
+	}
+}
 
 static void __init pci_process_bridge_OF_ranges(struct pci_controller *hose,
 						struct device_node *dev,
@@ -188,10 +237,11 @@ static void __init pci_process_bridge_OF
 	struct resource *res;
 	int np, na = prom_n_addr_cells(dev);
 	unsigned long pci_addr, cpu_phys_addr;
+	struct device_node *isa_dn;
 
 	np = na + 5;
 
-	/*
+	/* From "PCI Binding to 1275"
 	 * The ranges property is laid out as an array of elements,
 	 * each of which comprises:
 	 *   cells 0 - 2:	a PCI address
@@ -215,12 +265,22 @@ static void __init pci_process_bridge_OF
 		switch (ranges[0] >> 24) {
 		case 1:		/* I/O space */
 			hose->io_base_phys = cpu_phys_addr;
-			hose->io_base_virt = __ioremap(hose->io_base_phys,
-						       size, _PAGE_NO_CACHE);
+			hose->io_base_virt = reserve_phb_iospace(size);
+			PPCDBG(PPCDBG_PHBINIT, 
+			       "phb%d io_base_phys 0x%lx io_base_virt 0x%lx\n", 
+			       hose->global_number, hose->io_base_phys, 
+			       (unsigned long) hose->io_base_virt);
+
 			if (primary) {
 				pci_io_base = (unsigned long)hose->io_base_virt;
-				if (find_type_devices("isa"))
+				isa_dn = of_find_node_by_type(NULL, "isa");
+				if (isa_dn) {
 					isa_io_base = pci_io_base;
+					of_node_put(isa_dn);
+					pci_process_ISA_OF_ranges(isa_dn,
+						hose->io_base_phys,
+						hose->io_base_virt);
+				}
 			}
 
 			res = &hose->io_resource;
@@ -386,7 +446,7 @@ unsigned long __init find_and_init_phbs(
 	unsigned int root_size_cells = 0;
 	unsigned int index;
 	unsigned int *opprop;
-	struct device_node *root = find_path_device("/");
+	struct device_node *root = of_find_node_by_path("/");
 
 	read_pci_config = rtas_token("read-pci-config");
 	write_pci_config = rtas_token("write-pci-config");
@@ -402,7 +462,9 @@ unsigned long __init find_and_init_phbs(
 
 	index = 0;
 
-	for (node = root->child; node != NULL; node = node->sibling) {
+	for (node = of_get_next_child(root, NULL);
+	     node != NULL;
+	     node = of_get_next_child(root, node)) {
 		if (node->type == NULL || strcmp(node->type, "pci") != 0)
 			continue;
 
@@ -420,6 +482,7 @@ unsigned long __init find_and_init_phbs(
 		index++;
 	}
 
+	of_node_put(root);
 	pci_devs_phb_init();
 
 	return 0;
@@ -450,7 +513,7 @@ void pcibios_name_device(struct pci_dev 
 #endif
 }   
 
-void __init pcibios_fixup_device_resources(struct pci_dev *dev,
+void __devinit pcibios_fixup_device_resources(struct pci_dev *dev,
 					   struct pci_bus *bus)
 {
 	/* Update device resources.  */
@@ -469,8 +532,9 @@ void __init pcibios_fixup_device_resourc
 		}
         }
 }
+EXPORT_SYMBOL(pcibios_fixup_device_resources);
 
-void __init pcibios_fixup_bus(struct pci_bus *bus)
+void __devinit pcibios_fixup_bus(struct pci_bus *bus)
 {
 	struct pci_controller *hose = PCI_GET_PHB_PTR(bus);
 	struct list_head *ln;
@@ -519,18 +583,106 @@ void __init pcibios_fixup_bus(struct pci
 			pcibios_fixup_device_resources(dev, bus);
 	}
 }
+EXPORT_SYMBOL(pcibios_fixup_bus);
 
 static void check_s7a(void)
 {
 	struct device_node *root;
 	char *model;
 
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	if (root) {
 		model = get_property(root, "model", NULL);
 		if (model && !strcmp(model, "IBM,7013-S7A"))
 			s7a_workaround = 1;
+		of_node_put(root);
+	}
+}
+
+static int get_bus_io_range(struct pci_bus *bus, unsigned long *start_phys,
+				unsigned long *start_virt, unsigned long *size)
+{
+	struct pci_controller *hose = PCI_GET_PHB_PTR(bus);
+	struct pci_bus_region region;
+	struct resource *res;
+
+	if (bus->self) {
+		res = bus->resource[0];
+		pcibios_resource_to_bus(bus->self, &region, res);
+		*start_phys = hose->io_base_phys + region.start;
+		*start_virt = (unsigned long) hose->io_base_virt + 
+				region.start;
+		if (region.end > region.start) 
+			*size = region.end - region.start + 1;
+		else {
+			printk("%s(): unexpected region 0x%lx->0x%lx\n", 
+					__FUNCTION__, region.start, region.end);
+			return 1;
+		}
+		
+	} else {
+		/* Root Bus */
+		res = &hose->io_resource;
+		*start_phys = hose->io_base_phys;
+		*start_virt = (unsigned long) hose->io_base_virt;
+		if (res->end > res->start)
+			*size = res->end - res->start + 1;
+		else {
+			printk("%s(): unexpected region 0x%lx->0x%lx\n", 
+					__FUNCTION__, res->start, res->end);
+			return 1;
+		}
 	}
+
+	return 0;
+}
+
+int unmap_bus_range(struct pci_bus *bus)
+{
+	unsigned long start_phys;
+	unsigned long start_virt;
+	unsigned long size;
+
+	if (!bus) {
+		printk(KERN_ERR "%s() expected bus\n", __FUNCTION__);
+		return 1;
+	}
+	
+	if (get_bus_io_range(bus, &start_phys, &start_virt, &size))
+		return 1;
+	if (iounmap_explicit((void *) start_virt, size))
+		return 1;
+
+	return 0;
+}
+EXPORT_SYMBOL(unmap_bus_range);
+
+int remap_bus_range(struct pci_bus *bus)
+{
+	unsigned long start_phys;
+	unsigned long start_virt;
+	unsigned long size;
+
+	if (!bus) {
+		printk(KERN_ERR "%s() expected bus\n", __FUNCTION__);
+		return 1;
+	}
+	
+	if (get_bus_io_range(bus, &start_phys, &start_virt, &size))
+		return 1;
+	if (__ioremap_explicit(start_phys, start_virt, size, _PAGE_NO_CACHE))
+		return 1;
+
+	return 0;
+}
+EXPORT_SYMBOL(remap_bus_range);
+
+static void phbs_fixup_io(void)
+{
+	struct pci_controller *hose;
+
+	for (hose=hose_head;hose;hose=hose->next) 
+		remap_bus_range(hose->bus);
 }
 
 extern void chrp_request_regions(void);
@@ -544,6 +696,7 @@ void __init pcibios_final_fixup(void)
 	while ((dev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL)
 		pci_read_irq_line(dev);
 
+	phbs_fixup_io();
 	chrp_request_regions();
 	pci_fix_bus_sysdata();
 	create_tce_tables();
diff -purN linux-2.5/arch/ppc64/kernel/pci.c linuxppc64-2.5/arch/ppc64/kernel/pci.c
--- linux-2.5/arch/ppc64/kernel/pci.c	2003-07-31 23:47:19.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pci.c	2003-11-17 23:08:19.000000000 +0000
@@ -126,6 +126,7 @@ struct pci_dev *pci_find_dev_by_addr(uns
 	while ((dev = pci_find_device(PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL) {
 		if ((dev->class >> 16) == PCI_BASE_CLASS_BRIDGE)
 			continue;
+		
 		for (i = 0; i < DEVICE_COUNT_RESOURCE; i++) {
 			unsigned long start = pci_resource_start(dev,i);
 			unsigned long end = pci_resource_end(dev,i);
@@ -144,7 +145,7 @@ struct pci_dev *pci_find_dev_by_addr(uns
 	return NULL;
 }
 
-void __devinit
+void 
 pcibios_resource_to_bus(struct pci_dev *dev, struct pci_bus_region *region,
 			struct resource *res)
 {
@@ -380,6 +381,8 @@ int pci_domain_nr(struct pci_bus *bus)
 	return hose->global_number;
 }
 
+EXPORT_SYMBOL(pci_domain_nr);
+
 /* Set the name of the bus as it appears in /proc/bus/pci */
 int pci_name_bus(char *name, struct pci_bus *bus)
 {
diff -purN linux-2.5/arch/ppc64/kernel/pci_dma.c linuxppc64-2.5/arch/ppc64/kernel/pci_dma.c
--- linux-2.5/arch/ppc64/kernel/pci_dma.c	2003-10-01 22:32:13.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pci_dma.c	2003-11-21 06:45:02.000000000 +0000
@@ -48,11 +48,13 @@
 /* #define MONITOR_TCE 1 */ /* Turn on to sanity check TCE generation. */
 
 
+#ifdef CONFIG_PPC_PSERIES
 /* Initialize so this guy does not end up in the BSS section.
  * Only used to pass OF initialization data set in prom.c into the main 
  * kernel code -- data ultimately copied into tceTables[].
  */
 extern struct _of_tce_table of_tce_table[];
+#endif
 
 extern struct pci_controller* hose_head;
 extern struct pci_controller** hose_tail;
@@ -98,7 +100,7 @@ void free_tce_range_nolock(struct TceTab
 			   unsigned order );
 
 /* allocates a range of tces and sets them to the pages  */
-inline dma_addr_t get_tces( struct TceTable *, 
+static inline dma_addr_t get_tces( struct TceTable *, 
 				   unsigned order, 
 				   void *page, 
 				   unsigned numPages,
@@ -210,7 +212,7 @@ static void tce_build_pSeries(struct Tce
  * Build a TceTable structure.  This contains a multi-level bit map which
  * is used to manage allocation of the tce space.
  */
-struct TceTable *build_tce_table( struct TceTable * tbl )
+static struct TceTable *build_tce_table( struct TceTable * tbl )
 {
 	unsigned long bits, bytes, totalBytes;
 	unsigned long numBits[NUM_TCE_LEVELS], numBytes[NUM_TCE_LEVELS];
@@ -518,7 +520,7 @@ static long test_tce_range( struct TceTa
 	return retval;
 }
 
-inline dma_addr_t get_tces( struct TceTable *tbl, unsigned order, void *page, unsigned numPages, int direction )
+static inline dma_addr_t get_tces( struct TceTable *tbl, unsigned order, void *page, unsigned numPages, int direction )
 {
 	long tcenum;
 	unsigned long uaddr;
@@ -581,7 +583,7 @@ static void tce_free_one_pSeries( struct
 }
 #endif
 
-void tce_free(struct TceTable *tbl, dma_addr_t dma_addr, 
+static void tce_free(struct TceTable *tbl, dma_addr_t dma_addr, 
 			     unsigned order, unsigned num_pages)
 {
 	long tcenum, total_tces, free_tce;
@@ -701,6 +703,7 @@ void create_tce_tables_for_buses(struct 
 	}
 }
 
+#ifdef CONFIG_PPC_PSERIES
 void create_tce_tables_for_busesLP(struct list_head *bus_list)
 {
 	struct list_head *ln;
@@ -722,15 +725,19 @@ void create_tce_tables_for_busesLP(struc
 		create_tce_tables_for_busesLP(&bus->children);
 	}
 }
+#endif
 
 void create_tce_tables(void) {
 	struct pci_dev *dev = NULL;
 	struct device_node *dn, *mydn;
 
+#ifdef CONFIG_PPC_PSERIES
 	if (systemcfg->platform == PLATFORM_PSERIES_LPAR) {
 		create_tce_tables_for_busesLP(&pci_root_buses);
 	}
-	else {
+	else
+#endif
+	{
 		create_tce_tables_for_buses(&pci_root_buses);
 	}
 	/* Now copy the tce_table ptr from the bus devices down to every
@@ -884,6 +891,7 @@ static void getTceTableParmsiSeries(stru
 static void getTceTableParmsPSeries(struct pci_controller *phb,
 				    struct device_node *dn,
 				    struct TceTable *newTceTable ) {
+#ifdef CONFIG_PPC_PSERIES
 	phandle node;
 	unsigned long i;
 
@@ -953,6 +961,7 @@ static void getTceTableParmsPSeries(stru
 		}
 		i++;
 	}
+#endif
 }
 
 /*
@@ -970,6 +979,7 @@ static void getTceTableParmsPSeries(stru
 static void getTceTableParmsPSeriesLP(struct pci_controller *phb,
 				    struct device_node *dn,
 				    struct TceTable *newTceTable ) {
+#ifdef CONFIG_PPC_PSERIES
 	u32 *dma_window = (u32 *)get_property(dn, "ibm,dma-window", 0);
 	if (!dma_window) {
 		panic("PCI_DMA: getTceTableParmsPSeriesLP: device %s has no ibm,dma-window property!\n", dn->full_name);
@@ -985,6 +995,7 @@ static void getTceTableParmsPSeriesLP(st
 	PPCDBG(PPCDBG_TCEINIT, "\tnewTceTable->index       = 0x%lx\n", newTceTable->index);
 	PPCDBG(PPCDBG_TCEINIT, "\tnewTceTable->startOffset = 0x%lx\n", newTceTable->startOffset);
 	PPCDBG(PPCDBG_TCEINIT, "\tnewTceTable->size        = 0x%lx\n", newTceTable->size);
+#endif
 }
 
 /* Allocates a contiguous real buffer and creates TCEs over it.
diff -purN linux-2.5/arch/ppc64/kernel/pci_dn.c linuxppc64-2.5/arch/ppc64/kernel/pci_dn.c
--- linux-2.5/arch/ppc64/kernel/pci_dn.c	2003-06-24 04:03:30.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/pci_dn.c	2003-11-21 06:45:02.000000000 +0000
@@ -46,6 +46,7 @@
 static void * __init
 update_dn_pci_info(struct device_node *dn, void *data)
 {
+#ifdef CONFIG_PPC_PSERIES
 	struct pci_controller *phb = (struct pci_controller *)data;
 	u32 *regs;
 	char *device_type = get_property(dn, "device_type", 0);
@@ -64,6 +65,7 @@ update_dn_pci_info(struct device_node *d
 			dn->devfn = (regs[0] >> 8) & 0xff;
 		}
 	}
+#endif
 	return NULL;
 }
 
@@ -97,6 +99,7 @@ void *traverse_pci_devices(struct device
 		return ret;
 	for (dn = start->child; dn; dn = nextdn) {
 		nextdn = NULL;
+#ifdef CONFIG_PPC_PSERIES
 		if (get_property(dn, "class-code", 0)) {
 			if (pre && (ret = pre(dn, data)) != NULL)
 				return ret;
@@ -112,6 +115,7 @@ void *traverse_pci_devices(struct device
 					post(dn, data);
 			}
 		}
+#endif
 		if (!nextdn) {
 			/* Walk up to next valid sibling. */
 			do {
diff -purN linux-2.5/arch/ppc64/kernel/ppc_ksyms.c linuxppc64-2.5/arch/ppc64/kernel/ppc_ksyms.c
--- linux-2.5/arch/ppc64/kernel/ppc_ksyms.c	2003-10-16 01:43:36.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/ppc_ksyms.c	2003-11-21 06:45:02.000000000 +0000
@@ -39,6 +39,7 @@
 #include <asm/hw_irq.h>
 #include <asm/abs_addr.h>
 #include <asm/cacheflush.h>
+#include <asm/proc_fs.h>
 #ifdef CONFIG_PPC_ISERIES
 #include <asm/iSeries/iSeries_pci.h>
 #include <asm/iSeries/iSeries_proc.h>
@@ -169,15 +170,15 @@ EXPORT_SYMBOL(flush_icache_user_range);
 EXPORT_SYMBOL(flush_dcache_page);
 #ifdef CONFIG_SMP
 #ifdef CONFIG_PPC_ISERIES
-EXPORT_SYMBOL(__no_use_restore_flags);
-EXPORT_SYMBOL(__no_use_save_flags);
-EXPORT_SYMBOL(__no_use_sti);
-EXPORT_SYMBOL(__no_use_cli);
+EXPORT_SYMBOL(local_get_flags);
+EXPORT_SYMBOL(local_irq_disable);
+EXPORT_SYMBOL(local_irq_restore);
 #endif
 #endif
 
 EXPORT_SYMBOL(ppc_md);
 
+#ifdef CONFIG_PPC_PSERIES
 EXPORT_SYMBOL(find_devices);
 EXPORT_SYMBOL(find_type_devices);
 EXPORT_SYMBOL(find_compatible_devices);
@@ -186,6 +187,7 @@ EXPORT_SYMBOL(device_is_compatible);
 EXPORT_SYMBOL(machine_is_compatible);
 EXPORT_SYMBOL(find_all_nodes);
 EXPORT_SYMBOL(get_property);
+#endif
 
 
 EXPORT_SYMBOL_NOVERS(memcpy);
@@ -197,7 +199,6 @@ EXPORT_SYMBOL_NOVERS(memcmp);
 EXPORT_SYMBOL(abs);
 
 EXPORT_SYMBOL(timer_interrupt);
-EXPORT_SYMBOL(irq_desc);
 EXPORT_SYMBOL(get_wchan);
 EXPORT_SYMBOL(console_drivers);
 #ifdef CONFIG_XMON
@@ -222,3 +223,4 @@ EXPORT_SYMBOL(debugger_fault_handler);
 
 EXPORT_SYMBOL(tb_ticks_per_usec);
 EXPORT_SYMBOL(paca);
+EXPORT_SYMBOL(proc_ppc64);
diff -purN linux-2.5/arch/ppc64/kernel/proc_pmc.c linuxppc64-2.5/arch/ppc64/kernel/proc_pmc.c
--- linux-2.5/arch/ppc64/kernel/proc_pmc.c	2002-09-18 02:00:50.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/proc_pmc.c	2003-11-21 06:45:02.000000000 +0000
@@ -82,8 +82,8 @@ int proc_pmc_set_pmc6(  struct file *fil
 int proc_pmc_set_pmc7(  struct file *file, const char *buffer, unsigned long count, void *data);
 int proc_pmc_set_pmc8(  struct file *file, const char *buffer, unsigned long count, void *data);
 
-
-void proc_ppc64_init(void)
+#if 0
+int proc_ppc64_init(void)
 {
 	unsigned long i;
 	struct proc_dir_entry *ent = NULL;
@@ -97,15 +97,21 @@ void proc_ppc64_init(void)
 	 *   /proc/ppc64/pmc/cpu0 
 	 */
 	spin_lock(&proc_ppc64_lock);
-	proc_ppc64_root = proc_mkdir("ppc64", 0);
-	if (!proc_ppc64_root) return;
+	if (proc_ppc64.root == NULL) {
+		proc_ppc64_init();
+		if (!proc_ppc64.root) {
+			spin_unlock(&proc_ppc64_lock);
+			return;
+		}
+	}
 	spin_unlock(&proc_ppc64_lock);
 
 	/* Placeholder for rtas interfaces. */
-	rtas_proc_dir = proc_mkdir("rtas", proc_ppc64_root);
-
+	if (proc_ppc64.rtas == NULL) {
+		return;
+	}
 
-	proc_ppc64_pmc_root = proc_mkdir("pmc", proc_ppc64_root);
+	proc_ppc64_pmc_root = proc_mkdir("pmc", proc_ppc64.root);
 
 	proc_ppc64_pmc_system_root = proc_mkdir("system", proc_ppc64_pmc_root);
 	for (i = 0; i < NR_CPUS; i++) {
@@ -116,7 +122,6 @@ void proc_ppc64_init(void)
 		}
 	}
 
-
 	/* Create directories for the software counters. */
 	for (i = 0; i < NR_CPUS; i++) {
 		if (!cpu_online(i))
@@ -181,6 +186,7 @@ void proc_ppc64_init(void)
 		ent->write_proc = (void *)proc_ppc64_pmc_hw_read;
 	}
 }
+#endif
 
 /*
  * Find the requested 'file' given a proc token.
diff -purN linux-2.5/arch/ppc64/kernel/proc_ppc64.c linuxppc64-2.5/arch/ppc64/kernel/proc_ppc64.c
--- linux-2.5/arch/ppc64/kernel/proc_ppc64.c	2003-08-31 23:14:08.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/proc_ppc64.c	2003-11-21 06:45:02.000000000 +0000
@@ -30,6 +30,8 @@
 #include <linux/init.h>
 #include <linux/mm.h>
 #include <linux/proc_fs.h>
+#include <linux/slab.h>
+#include <linux/kernel.h>
 
 #include <asm/proc_fs.h>
 #include <asm/naca.h>
@@ -37,10 +39,12 @@
 #include <asm/systemcfg.h>
 #include <asm/rtas.h>
 #include <asm/uaccess.h>
+#include <asm/prom.h>
 
 struct proc_ppc64_t proc_ppc64;
 
 void proc_ppc64_create_paca(int num);
+void proc_ppc64_create_smt(void);
 
 static loff_t  page_map_seek( struct file *file, loff_t off, int whence);
 static ssize_t page_map_read( struct file *file, char *buf, size_t nbytes, loff_t *ppos);
@@ -52,15 +56,32 @@ static struct file_operations page_map_f
 	.mmap	= page_map_mmap
 };
 
+#ifdef CONFIG_PPC_PSERIES
+/* routines for /proc/ppc64/ofdt */
+static ssize_t ofdt_write(struct file *, const char __user *, size_t, loff_t *);
+static void proc_ppc64_create_ofdt(struct proc_dir_entry *);
+static int do_remove_node(char *);
+static int do_add_node(char *, size_t);
+static void release_prop_list(const struct property *);
+static struct property *new_property(const char *, const int, const unsigned char *, struct property *);
+static char * parse_next_property(char *, char *, char **, int *, unsigned char**);
+static struct file_operations ofdt_fops = {
+	.write = ofdt_write
+};
+#endif
 
-static int __init proc_ppc64_init(void)
+int __init proc_ppc64_init(void)
 {
 
-	printk(KERN_INFO "proc_ppc64: Creating /proc/ppc64/\n");
 
-	proc_ppc64.root = proc_mkdir("ppc64", 0);
-	if (!proc_ppc64.root)
+	if (proc_ppc64.root == NULL) {
+		printk(KERN_INFO "proc_ppc64: Creating /proc/ppc64/\n");
+		proc_ppc64.root = proc_mkdir("ppc64", 0);
+		if (!proc_ppc64.root)
+			return 0;
+	} else {
 		return 0;
+	}
 
 	proc_ppc64.naca = create_proc_entry("naca", S_IRUSR, proc_ppc64.root);
 	if ( proc_ppc64.naca ) {
@@ -90,8 +111,18 @@ static int __init proc_ppc64_init(void)
 		}
 	}
 
+#ifdef CONFIG_PPC_PSERIES
 	/* Placeholder for rtas interfaces. */
-	proc_ppc64.rtas = proc_mkdir("rtas", proc_ppc64.root);
+	if (proc_ppc64.rtas == NULL)
+		proc_ppc64.rtas = proc_mkdir("rtas", proc_ppc64.root);
+
+	if (proc_ppc64.rtas)
+		proc_symlink("rtas", 0, "ppc64/rtas");
+
+	proc_ppc64_create_smt();
+
+	proc_ppc64_create_ofdt(proc_ppc64.root);
+#endif
 
 	return 0;
 }
@@ -173,5 +204,309 @@ static int page_map_mmap( struct file *f
 	return 0;
 }
 
-fs_initcall(proc_ppc64_init);
+#ifdef CONFIG_PPC_PSERIES
+/* create /proc/ppc64/ofdt write-only by root */
+static void proc_ppc64_create_ofdt(struct proc_dir_entry *parent)
+{
+	struct proc_dir_entry *ent;
+
+	ent = create_proc_entry("ofdt", S_IWUSR, parent);
+	if (ent) {
+		ent->nlink = 1;
+		ent->data = NULL;
+		ent->size = 0;
+		ent->proc_fops = &ofdt_fops;
+	}
+}
+
+/**
+ * ofdt_write - perform operations on the Open Firmware device tree
+ *
+ * @file: not used
+ * @buf: command and arguments
+ * @count: size of the command buffer
+ * @off: not used
+ *
+ * Operations supported at this time are addition and removal of
+ * whole nodes along with their properties.  Operations on individual
+ * properties are not implemented (yet).
+ */
+static ssize_t ofdt_write(struct file *file, const char __user *buf, size_t count, loff_t *off)
+{
+	int rv = 0;
+	char *kbuf;
+	char *tmp;
+
+	if (!(kbuf = kmalloc(count + 1, GFP_KERNEL))) {
+		rv = -ENOMEM;
+		goto out;
+	}
+	if (copy_from_user(kbuf, buf, count)) {
+		rv = -EFAULT;
+		goto out;
+	}
+
+	kbuf[count] = '\0';
+
+	tmp = strchr(kbuf, ' ');
+	if (!tmp) {
+		rv = -EINVAL;
+		goto out;
+	}
+	*tmp = '\0';
+	tmp++;
+
+	if (!strcmp(kbuf, "add_node"))
+		rv = do_add_node(tmp, 1 + count - (tmp - kbuf));
+	else if (!strcmp(kbuf, "remove_node"))
+		rv = do_remove_node(tmp);
+	else
+		rv = -EINVAL;
+out:
+	kfree(kbuf);
+	return rv ? rv : count;
+}
+
+static int do_remove_node(char *buf)
+{
+	struct device_node *node;
+	int rv = 0;
+
+	if ((node = of_find_node_by_path(buf)))
+		of_remove_node(node);
+	else
+		rv = -ENODEV;
+
+	of_node_put(node);
+	return rv;
+}
+
+static int do_add_node(char *buf, size_t bufsize)
+{
+	char *path, *end, *name;
+	struct device_node *np;
+	struct property *prop = NULL;
+	unsigned char* value;
+	int length, rv = 0;
+
+	end = buf + bufsize;
+	path = buf;
+	buf = strchr(buf, ' ');
+	if (!buf)
+		return -EINVAL;
+	*buf = '\0';
+	buf++;
+
+	if ((np = of_find_node_by_path(path))) {
+		of_node_put(np);
+		return -EINVAL;
+	}
+
+	/* rv = build_prop_list(tmp, bufsize - (tmp - buf), &proplist); */
+	while (buf < end &&
+	       (buf = parse_next_property(buf, end, &name, &length, &value))) {
+		struct property *last = prop;
+
+		prop = new_property(name, length, value, last);
+		if (!prop) {
+			rv = -ENOMEM;
+			prop = last;
+			goto out;
+		}
+	}
+	if (!buf) {
+		rv = -EINVAL;
+		goto out;
+	}
+
+	rv = of_add_node(path, prop);
+
+out:
+	if (rv)
+		release_prop_list(prop);
+	return rv;
+}
+
+static struct property *new_property(const char *name, const int length, const unsigned char *value, struct property *last)
+{
+	struct property *new = kmalloc(sizeof(*new), GFP_KERNEL);
+
+	if (!new)
+		return NULL;
+	memset(new, 0, sizeof(*new));
+
+	if (!(new->name = kmalloc(strlen(name) + 1, GFP_KERNEL)))
+		goto cleanup;
+	if (!(new->value = kmalloc(length, GFP_KERNEL)))
+		goto cleanup;
+
+	strcpy(new->name, name);
+	memcpy(new->value, value, length);
+	new->length = length;
+	new->next = last;
+	return new;
+
+cleanup:
+	if (new->name)
+		kfree(new->name);
+	if (new->value)
+		kfree(new->value);
+	kfree(new);
+	return NULL;
+}
+
+/**
+ * parse_next_property - process the next property from raw input buffer
+ * @buf: input buffer, must be nul-terminated
+ * @end: end of the input buffer + 1, for validation
+ * @name: return value; set to property name in buf
+ * @length: return value; set to length of value
+ * @value: return value; set to the property value in buf
+ *
+ * Note that the caller must make copies of the name and value returned,
+ * this function does no allocation or copying of the data.  Return value
+ * is set to the next name in buf, or NULL on error.
+ */
+static char * parse_next_property(char *buf, char *end, char **name, int *length, unsigned char **value)
+{
+	char *tmp;
+
+	*name = buf;
+
+	tmp = strchr(buf, ' ');
+	if (!tmp) {
+		printk(KERN_ERR "property parse failed in %s at line %d\n", __FUNCTION__, __LINE__);
+		return NULL;
+	}
+	*tmp = '\0';
+
+	if (++tmp >= end) {
+		printk(KERN_ERR "property parse failed in %s at line %d\n", __FUNCTION__, __LINE__);
+		return NULL;
+	}
+
+	/* now we're on the length */
+	*length = -1;
+	*length = simple_strtoul(tmp, &tmp, 10);
+	if (*length == -1) {
+		printk(KERN_ERR "property parse failed in %s at line %d\n", __FUNCTION__, __LINE__);
+		return NULL;
+	}
+	if (*tmp != ' ' || ++tmp >= end) {
+		printk(KERN_ERR "property parse failed in %s at line %d\n", __FUNCTION__, __LINE__);
+		return NULL;
+	}
+
+	/* now we're on the value */
+	*value = tmp;
+	tmp += *length;
+	if (tmp > end) {
+		printk(KERN_ERR "property parse failed in %s at line %d\n", __FUNCTION__, __LINE__);
+		return NULL;
+	}
+	else if (tmp < end && *tmp != ' ' && *tmp != '\0') {
+		printk(KERN_ERR "property parse failed in %s at line %d\n", __FUNCTION__, __LINE__);
+		return NULL;
+	}
+	tmp++;
+
+	/* and now we should be on the next name, or the end */
+	return tmp;
+}
+
+static void release_prop_list(const struct property *prop)
+{
+	struct property *next;
+	for (; prop; prop = next) {
+		next = prop->next;
+		kfree(prop->name);
+		kfree(prop->value);
+		kfree(prop);
+	}
+
+}
+#endif	/* defined(CONFIG_PPC_PSERIES) */
+
+static int proc_ppc64_smt_snooze_read(char *page, char **start, off_t off,
+				      int count, int *eof, void *data)
+{
+	if (naca->smt_snooze_delay)
+		return sprintf(page, "%lu\n", naca->smt_snooze_delay);
+	else 
+		return sprintf(page, "disabled\n");
+}
+ 
+static int proc_ppc64_smt_snooze_write(struct file* file, const char *buffer,
+				       unsigned long count, void *data)
+{
+	unsigned long val;
+	char val_string[22];
 
+	if (!capable(CAP_SYS_ADMIN))
+		return -EACCES;
+
+	if (count > sizeof(val_string) - 1)
+		return -EINVAL;
+
+	if (copy_from_user(val_string, buffer, count))
+		return -EFAULT;
+
+	val_string[count] = '\0';
+
+	if (val_string[0] == '0' && (val_string[1] == '\n' || val_string[1] == '\0')) {
+		naca->smt_snooze_delay = 0;
+		return count;
+	}
+ 
+	val = simple_strtoul(val_string, NULL, 10);
+	if (val != 0) 
+		naca->smt_snooze_delay = val;
+	else
+		return -EINVAL;
+
+	return count;
+}
+ 
+static int proc_ppc64_smt_state_read(char *page, char **start, off_t off,
+				      int count, int *eof, void *data)
+{
+	switch(naca->smt_state) {
+	case SMT_OFF:
+		return sprintf(page, "off\n");
+		break;
+	case SMT_ON:
+		return sprintf(page, "on\n");
+		break;
+	case SMT_DYNAMIC:
+		return sprintf(page, "dynamic\n");
+		break;
+	default:
+		return sprintf(page, "unknown\n");
+		break;
+	}
+}
+ 
+void proc_ppc64_create_smt(void)
+{
+	struct proc_dir_entry *ent_snooze = 
+		create_proc_entry("smt-snooze-delay", S_IRUGO | S_IWUSR, 
+				  proc_ppc64.root);
+	struct proc_dir_entry *ent_enabled = 
+		create_proc_entry("smt-enabled", S_IRUGO | S_IWUSR, 
+				  proc_ppc64.root);
+	if (ent_snooze) {
+		ent_snooze->nlink = 1;
+		ent_snooze->data = NULL;
+		ent_snooze->read_proc = (void *)proc_ppc64_smt_snooze_read;
+		ent_snooze->write_proc = (void *)proc_ppc64_smt_snooze_write;
+	}
+
+	if (ent_enabled) {
+		ent_enabled->nlink = 1;
+		ent_enabled->data = NULL;
+		ent_enabled->read_proc = (void *)proc_ppc64_smt_state_read;
+		ent_enabled->write_proc = NULL;
+	}
+}
+
+fs_initcall(proc_ppc64_init);
diff -purN linux-2.5/arch/ppc64/kernel/prom.c linuxppc64-2.5/arch/ppc64/kernel/prom.c
--- linux-2.5/arch/ppc64/kernel/prom.c	2003-08-19 02:46:23.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/prom.c	2003-11-19 17:10:13.000000000 +0000
@@ -29,6 +29,7 @@
 #include <linux/spinlock.h>
 #include <linux/types.h>
 #include <linux/pci.h>
+#include <linux/proc_fs.h>
 #include <asm/prom.h>
 #include <asm/rtas.h>
 #include <asm/lmb.h>
@@ -44,6 +45,7 @@
 #include <asm/bitops.h>
 #include <asm/naca.h>
 #include <asm/pci.h>
+#include <asm/pci_dma.h>
 #include <asm/bootinfo.h>
 #include <asm/ppcdebug.h>
 #include "open_pic.h"
@@ -147,16 +149,16 @@ char *bootpath = 0;
 char *bootdevice = 0;
 
 int boot_cpuid = 0;
+#define MAX_CPU_THREADS 2
 
 struct device_node *allnodes = 0;
-
-#define UNDEFINED_IRQ 0xffff
-unsigned short real_irq_to_virt_map[NR_HW_IRQS];
-unsigned short virt_irq_to_real_map[NR_IRQS];
-int last_virt_irq = 2;	/* index of last virt_irq.  Skip through IPI */
+/* use when traversing tree through the allnext, child, sibling,
+ * or parent members of struct device_node.
+ */
+static rwlock_t devtree_lock = RW_LOCK_UNLOCKED;
 
 static unsigned long call_prom(const char *service, int nargs, int nret, ...);
-static void prom_exit(void);
+static void prom_panic(const char *reason);
 static unsigned long copy_device_tree(unsigned long);
 static unsigned long inspect_node(phandle, struct device_node *, unsigned long,
 				  unsigned long, struct device_node ***);
@@ -168,6 +170,11 @@ static int prom_next_node(phandle *);
 static struct bi_record * prom_bi_rec_verify(struct bi_record *);
 static unsigned long prom_bi_rec_reserve(unsigned long);
 static struct device_node *find_phandle(phandle);
+static void of_node_cleanup(struct device_node *);
+static struct device_node *derive_parent(const char *);
+static void add_node_proc_entries(struct device_node *);
+static void remove_node_proc_entries(struct device_node *);
+static int of_finish_dynamic_node(struct device_node *);
 
 #ifdef DEBUG_PROM
 void prom_dump_lmb(void);
@@ -223,10 +230,12 @@ call_prom(const char *service, int nargs
 
 
 static void __init
-prom_exit()
+prom_panic(const char *reason)
 {
 	unsigned long offset = reloc_offset();
 
+	prom_print(reason);
+	/* ToDo: should put up an SRC here */
 	call_prom(RELOC("exit"), 0, 0);
 
 	for (;;)			/* should never get here */
@@ -602,6 +611,9 @@ prom_instantiate_rtas(void)
 						      _rtas->base) >= 0) {
 				_rtas->entry = (long)_prom->args.rets[1];
 			}
+			RELOC(rtas_rmo_buf)
+				= lmb_alloc_base(RTAS_RMOBUF_MAX, PAGE_SIZE,
+							rtas_region);
 		}
 
 		if (_rtas->entry <= 0) {
@@ -785,8 +797,7 @@ prom_initialize_tce_table(void)
 		base = lmb_alloc(minsize, align);
 
 		if ( !base ) {
-			prom_print(RELOC("ERROR, cannot find space for TCE table.\n"));
-			prom_exit();
+			prom_panic(RELOC("ERROR, cannot find space for TCE table.\n"));
 		}
 
 		vbase = absolute_to_virt(base);
@@ -884,16 +895,21 @@ static void
 prom_hold_cpus(unsigned long mem)
 {
 	unsigned long i;
-	unsigned int cpuid;
+	unsigned int reg;
 	phandle node;
 	unsigned long offset = reloc_offset();
 	char type[64], *path;
+	int cpuid = 0;
+	unsigned int interrupt_server[MAX_CPU_THREADS];
+	unsigned int cpu_threads, hw_cpu_num;
+	int propsize;
 	extern void __secondary_hold(void);
         extern unsigned long __secondary_hold_spinloop;
         extern unsigned long __secondary_hold_acknowledge;
         unsigned long *spinloop     = __v2a(&__secondary_hold_spinloop);
         unsigned long *acknowledge  = __v2a(&__secondary_hold_acknowledge);
         unsigned long secondary_hold = (unsigned long)__v2a(*PTRRELOC((unsigned long *)__secondary_hold));
+        struct naca_struct *_naca = RELOC(naca);
         struct systemcfg *_systemcfg = RELOC(systemcfg);
 	struct paca_struct *_xPaca = PTRRELOC(&paca[0]);
 	struct prom_t *_prom = PTRRELOC(&prom);
@@ -946,13 +962,9 @@ prom_hold_cpus(unsigned long mem)
 		if (strcmp(type, RELOC("okay")) != 0)
 			continue;
 
-                cpuid = -1;
+                reg = -1;
 		call_prom(RELOC("getprop"), 4, 1, node, RELOC("reg"),
-			  &cpuid, sizeof(cpuid));
-
-		/* Only need to start secondary procs, not ourself. */
-		if ( cpuid == _prom->cpu )
-			continue;
+			  &reg, sizeof(reg));
 
 		path = (char *) mem;
 		memset(path, 0, 256);
@@ -962,12 +974,14 @@ prom_hold_cpus(unsigned long mem)
 
 #ifdef DEBUG_PROM
 		prom_print_nl();
-		prom_print(RELOC("cpu hw idx   = 0x"));
+		prom_print(RELOC("cpuid        = 0x"));
 		prom_print_hex(cpuid);
 		prom_print_nl();
+		prom_print(RELOC("cpu hw idx   = 0x"));
+		prom_print_hex(reg);
+		prom_print_nl();
 #endif
-		prom_print(RELOC("starting cpu "));
-		prom_print(path);
+		_xPaca[cpuid].xHwProcNum = reg;
 
 		/* Init the acknowledge var which will be reset by
 		 * the secondary cpu when it awakens from its OF
@@ -975,45 +989,85 @@ prom_hold_cpus(unsigned long mem)
 		 */
 		*acknowledge = (unsigned long)-1;
 
-#ifdef DEBUG_PROM
-		prom_print(RELOC("    3) spinloop       = 0x"));
-		prom_print_hex(spinloop);
-		prom_print_nl();
-		prom_print(RELOC("    3) *spinloop      = 0x"));
-		prom_print_hex(*spinloop);
-		prom_print_nl();
-		prom_print(RELOC("    3) acknowledge    = 0x"));
-		prom_print_hex(acknowledge);
-		prom_print_nl();
-		prom_print(RELOC("    3) *acknowledge   = 0x"));
-		prom_print_hex(*acknowledge);
-		prom_print_nl();
-		prom_print(RELOC("    3) secondary_hold = 0x"));
-		prom_print_hex(secondary_hold);
-		prom_print_nl();
-#endif
-		call_prom(RELOC("start-cpu"), 3, 0, node, secondary_hold, cpuid);
-		prom_print(RELOC("..."));
-		for ( i = 0 ; (i < 100000000) && 
-			      (*acknowledge == ((unsigned long)-1)); i++ ) ;
-#ifdef DEBUG_PROM
-		{
-			unsigned long *p = 0x0;
-			prom_print(RELOC("    4) 0x0 = 0x"));
-			prom_print_hex(*p);
-			prom_print_nl();
+		propsize = call_prom(RELOC("getprop"), 4, 1, node,
+				     RELOC("ibm,ppc-interrupt-server#s"), 
+				     &interrupt_server, 
+				     sizeof(interrupt_server));
+		if (propsize < 0) {
+			/* no property.  old hardware has no SMT */
+			cpu_threads = 1;
+			interrupt_server[0] = reg; /* fake it with phys id */
+		} else {
+			/* We have a threaded processor */
+			cpu_threads = propsize / sizeof(u32);
+			if (cpu_threads > MAX_CPU_THREADS) {
+				prom_print(RELOC("SMT: too many threads!\nSMT: found "));
+				prom_print_hex(cpu_threads);
+				prom_print(RELOC(", max is "));
+				prom_print_hex(MAX_CPU_THREADS);
+				prom_print_nl();
+				cpu_threads = 1; /* ToDo: panic? */
+			}
 		}
+
+		hw_cpu_num = interrupt_server[0];
+		if (hw_cpu_num != _prom->cpu) {
+			/* Primary Thread of non-boot cpu */
+			prom_print_hex(cpuid);
+			prom_print(RELOC(" : starting cpu "));
+			prom_print(path);
+			prom_print(RELOC("..."));
+			call_prom(RELOC("start-cpu"), 3, 0, node, 
+				  secondary_hold, cpuid);
+
+			for ( i = 0 ; (i < 100000000) && 
+			      (*acknowledge == ((unsigned long)-1)); i++ ) ;
+
+			if (*acknowledge == cpuid) {
+				prom_print(RELOC("ok\n"));
+#ifdef CONFIG_SMP
+				/* Set the number of active processors. */
+				_systemcfg->processorCount++;
+				cpu_set(cpuid, RELOC(cpu_available_map));
+				cpu_set(cpuid, RELOC(cpu_possible_map));
+				cpu_set(cpuid, RELOC(cpu_present_at_boot));
 #endif
-		if (*acknowledge == cpuid) {
-			prom_print(RELOC("ok\n"));
-			/* Set the number of active processors. */
-			_systemcfg->processorCount++;
-			_xPaca[cpuid].active = 1;
-		} else {
-			prom_print(RELOC("failed: "));
-			prom_print_hex(*acknowledge);
+			} else {
+				prom_print(RELOC("failed: "));
+				prom_print_hex(*acknowledge);
+				prom_print_nl();
+				/* prom_panic(RELOC("cpu failed to start")); */
+			}
+		}
+#ifdef CONFIG_SMP
+		else {
+			prom_print_hex(cpuid);
+			prom_print(RELOC(" : booting  cpu "));
+			prom_print(path);
+			prom_print_nl();
+			cpu_set(cpuid, RELOC(cpu_available_map));
+			cpu_set(cpuid, RELOC(cpu_possible_map));
+			cpu_set(cpuid, RELOC(cpu_online_map));
+			cpu_set(cpuid, RELOC(cpu_present_at_boot));
+		}
+
+		/* Init paca for secondary threads.   They start later. */
+		for (i=1; i < cpu_threads; i++) {
+			cpuid++;
+			_xPaca[cpuid].xHwProcNum = interrupt_server[i];
+			prom_print_hex(interrupt_server[i]);
+			prom_print(RELOC(" : preparing thread ... "));
+			if (_naca->smt_state) {
+				cpu_set(cpuid, RELOC(cpu_available_map));
+				cpu_set(cpuid, RELOC(cpu_present_at_boot));
+				prom_print(RELOC("available"));
+			} else {
+				prom_print(RELOC("not available"));
+			}
 			prom_print_nl();
 		}
+#endif
+		cpuid++;
 	}
 #ifdef CONFIG_HMT
 	/* Only enable HMT on processors that provide support. */
@@ -1023,10 +1077,10 @@ prom_hold_cpus(unsigned long mem)
 		prom_print(RELOC("    starting secondary threads\n"));
 
 		for (i = 0; i < NR_CPUS; i += 2) {
-			if (!_xPaca[i].active)
+			if (!cpu_online(i))
 				continue;
 
-			if (i == boot_cpuid) {
+			if (i == 0) {
 				unsigned long pir = _get_PIR();
 				if (__is_processor(PV_PULSAR)) {
 					RELOC(hmt_thread_data)[i].pir = 
@@ -1036,7 +1090,8 @@ prom_hold_cpus(unsigned long mem)
 						pir & 0x3ff;
 				}
 			}
-			_xPaca[i+1].active = 1;
+/* 			cpu_set(i+1, cpu_online_map); */
+			cpu_set(i+1, RELOC(cpu_possible_map));
 		}
 		_systemcfg->processorCount *= 2;
 	} else {
@@ -1049,6 +1104,105 @@ prom_hold_cpus(unsigned long mem)
 #endif
 }
 
+static void
+smt_setup(void)
+{
+	char *p, *q;
+	char my_smt_enabled = SMT_DYNAMIC;
+	unsigned long my_smt_snooze_delay; 
+	ihandle prom_options = NULL;
+	char option[9];
+	unsigned long offset = reloc_offset();
+        struct naca_struct *_naca = RELOC(naca);
+	char found = 0;
+
+	if (strstr(RELOC(cmd_line), RELOC("smt-enabled="))) {
+		for (q = RELOC(cmd_line); (p = strstr(q, RELOC("smt-enabled="))) != 0; ) {
+			q = p + 12;
+			if (p > RELOC(cmd_line) && p[-1] != ' ')
+				continue;
+			found = 1;
+			if (q[0] == 'o' && q[1] == 'f' && 
+			    q[2] == 'f' && (q[3] == ' ' || q[3] == '\0')) {
+				my_smt_enabled = SMT_OFF;
+			} else if (q[0]=='o' && q[1] == 'n' && 
+				   (q[2] == ' ' || q[2] == '\0')) {
+				my_smt_enabled = SMT_ON;
+			} else {
+				my_smt_enabled = SMT_DYNAMIC;
+			} 
+		}
+	}
+	if (!found) {
+		prom_options = (ihandle)call_prom(RELOC("finddevice"), 1, 1, RELOC("/options"));
+		if (prom_options != (ihandle) -1) {
+			call_prom(RELOC("getprop"), 
+				4, 1, prom_options,
+				RELOC("ibm,smt-enabled"), 
+				option, 
+				sizeof(option));
+			if (option[0] != 0) {
+				found = 1;
+				if (!strcmp(option, "off"))	
+					my_smt_enabled = SMT_OFF;
+				else if (!strcmp(option, "on"))	
+					my_smt_enabled = SMT_ON;
+				else
+					my_smt_enabled = SMT_DYNAMIC;
+			}
+		}
+	}
+
+	if (!found )
+		my_smt_enabled = SMT_DYNAMIC; /* default to on */
+
+	found = 0;
+	if (my_smt_enabled) {
+		if (strstr(RELOC(cmd_line), RELOC("smt-snooze-delay="))) {
+			for (q = RELOC(cmd_line); (p = strstr(q, RELOC("smt-snooze-delay="))) != 0; ) {
+				q = p + 17;
+				if (p > RELOC(cmd_line) && p[-1] != ' ')
+					continue;
+				found = 1;
+				/* Don't use simple_strtoul() because _ctype & others aren't RELOC'd */
+				my_smt_snooze_delay = 0;
+				while (*q >= '0' && *q <= '9') {
+					my_smt_snooze_delay = my_smt_snooze_delay * 10 + *q - '0';
+					q++;
+				}
+			}
+		}
+
+		if (!found) {
+			prom_options = (ihandle)call_prom(RELOC("finddevice"), 1, 1, RELOC("/options"));
+			if (prom_options != (ihandle) -1) {
+				call_prom(RELOC("getprop"), 
+					4, 1, prom_options,
+					RELOC("ibm,smt-snooze-delay"), 
+					option, 
+					sizeof(option));
+				if (option[0] != 0) {
+					found = 1;
+					/* Don't use simple_strtoul() because _ctype & others aren't RELOC'd */
+					my_smt_snooze_delay = 0;
+					q = option;
+					while (*q >= '0' && *q <= '9') {
+						my_smt_snooze_delay = my_smt_snooze_delay * 10 + *q - '0';
+						q++;
+					}
+				}
+			}
+		}
+
+		if (!found) {
+			my_smt_snooze_delay = 30000; /* default value */
+		}
+	} else {
+		my_smt_snooze_delay = 0; /* default value */
+	}
+	_naca->smt_snooze_delay = my_smt_snooze_delay;
+	_naca->smt_state = my_smt_enabled;
+}
 
 /*
  * We enter here early on, when the Open Firmware prom is still
@@ -1060,7 +1214,7 @@ prom_init(unsigned long r3, unsigned lon
 	  unsigned long r6, unsigned long r7)
 {
 	unsigned long mem;
-	ihandle prom_root, prom_cpu;
+	ihandle prom_mmu,prom_root, prom_cpu;
 	phandle cpu_pkg;
 	unsigned long offset = reloc_offset();
 	long l;
@@ -1092,12 +1246,12 @@ prom_init(unsigned long r3, unsigned lon
 				       RELOC("/chosen"));
 
 	if ((long)_prom->chosen <= 0)
-		prom_exit();
+		prom_panic(RELOC("cannot find chosen")); /* msg won't be printed :( */
 
         if ((long)call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
 			    RELOC("stdout"), &getprop_rval,
 			    sizeof(getprop_rval)) <= 0)
-                prom_exit();
+                prom_panic(RELOC("cannot find stdout"));
 
         _prom->stdout = (ihandle)(unsigned long)getprop_rval;
 
@@ -1123,7 +1277,7 @@ prom_init(unsigned long r3, unsigned lon
         if ((long)call_prom(RELOC("getprop"), 4, 1, _prom->chosen,
 			    RELOC("cpu"), &getprop_rval,
 			    sizeof(getprop_rval)) <= 0)
-                prom_exit();
+                prom_panic(RELOC("cannot find boot cpu"));
 
 	prom_cpu = (ihandle)(unsigned long)getprop_rval;
 	cpu_pkg = call_prom(RELOC("instance-to-package"), 1, 1, prom_cpu);
@@ -1131,11 +1285,9 @@ prom_init(unsigned long r3, unsigned lon
 		cpu_pkg, RELOC("reg"),
 		&getprop_rval, sizeof(getprop_rval));
 	_prom->cpu = (int)(unsigned long)getprop_rval;
-	_xPaca[_prom->cpu].active = 1;
-#ifdef CONFIG_SMP
-	cpu_set(_prom->cpu, RELOC(cpu_online_map));
-#endif
-	RELOC(boot_cpuid) = _prom->cpu;
+	_xPaca[0].xHwProcNum = _prom->cpu;
+
+	RELOC(boot_cpuid) = 0;
 
 #ifdef DEBUG_PROM
   	prom_print(RELOC("Booting CPU hw index = 0x"));
@@ -1158,6 +1310,15 @@ prom_init(unsigned long r3, unsigned lon
 		mem = DOUBLEWORD_ALIGN(mem + strlen(d) + 1);
 	}
 
+	RELOC(cmd_line[0]) = 0;
+	if ((long)_prom->chosen > 0) {
+		call_prom(RELOC("getprop"), 4, 1, _prom->chosen, 
+			  RELOC("bootargs"), p, sizeof(cmd_line));
+		if (p != NULL && p[0] != 0)
+			strncpy(RELOC(cmd_line), p, sizeof(cmd_line));
+	}
+	RELOC(cmd_line[sizeof(cmd_line) - 1]) = 0;
+
 	mem = prom_initialize_lmb(mem);
 
 	mem = prom_bi_rec_reserve(mem);
@@ -1169,11 +1330,12 @@ prom_init(unsigned long r3, unsigned lon
         /* Initialize some system info into the Naca early... */
         mem = prom_initialize_naca(mem);
 
+	smt_setup();
+	
         /* If we are on an SMP machine, then we *MUST* do the
          * following, regardless of whether we have an SMP
          * kernel or not.
          */
-        if (_systemcfg->processorCount > 1)
 	        prom_hold_cpus(mem);
 
 #ifdef DEBUG_PROM
@@ -1188,9 +1350,34 @@ prom_init(unsigned long r3, unsigned lon
 	if (_systemcfg->platform == PLATFORM_PSERIES)
 		prom_initialize_tce_table();
 
-	prom_print(RELOC("Calling quiesce ...\n"));
-	call_prom(RELOC("quiesce"), 0, 0);
-	phys = KERNELBASE - offset;
+ 	if ((long) call_prom(RELOC("getprop"), 4, 1,
+				_prom->chosen,
+				RELOC("mmu"),
+				&getprop_rval,
+				sizeof(getprop_rval)) <= 0) {	
+                prom_panic(RELOC(" no MMU found\n"));
+	}
+
+	/* We assume the phys. address size is 3 cells */
+	RELOC(prom_mmu) = (ihandle)(unsigned long)getprop_rval;
+
+	if ((long)call_prom(RELOC("call-method"), 4, 4,
+				RELOC("translate"),
+				prom_mmu,
+				(void *)(KERNELBASE - offset),
+				(void *)1) != 0) {
+		prom_print(RELOC(" (translate failed) "));
+	} else {
+		prom_print(RELOC(" (translate ok) "));
+		phys = (unsigned long)_prom->args.rets[3];
+	}
+
+	/* If OpenFirmware version >= 3, then use quiesce call */
+	if (_prom->version >= 3) {
+		prom_print(RELOC("Calling quiesce ...\n"));
+		call_prom(RELOC("quiesce"), 0, 0);
+		phys = KERNELBASE - offset;
+	}
 
 	prom_print(RELOC("returning from prom_init\n"));
 	return phys;
@@ -1308,46 +1495,6 @@ check_display(unsigned long mem)
 	return DOUBLEWORD_ALIGN(mem);
 }
 
-void
-virt_irq_init(void)
-{
-	int i;
-	for (i = 0; i < NR_IRQS; i++)
-		virt_irq_to_real_map[i] = UNDEFINED_IRQ;
-	for (i = 0; i < NR_HW_IRQS; i++)
-		real_irq_to_virt_map[i] = UNDEFINED_IRQ;
-}
-
-/* Create a mapping for a real_irq if it doesn't already exist.
- * Return the virtual irq as a convenience.
- */
-unsigned long
-virt_irq_create_mapping(unsigned long real_irq)
-{
-	unsigned long virq;
-	if (naca->interrupt_controller == IC_OPEN_PIC)
-		return real_irq;	/* no mapping for openpic (for now) */
-	virq = real_irq_to_virt(real_irq);
-	if (virq == UNDEFINED_IRQ) {
-		/* Assign a virtual IRQ number */
-		if (real_irq < NR_IRQS && virt_irq_to_real(real_irq) == UNDEFINED_IRQ) {
-			/* A 1-1 mapping will work. */
-			virq = real_irq;
-		} else {
-			while (last_virt_irq < NR_IRQS &&
-			       virt_irq_to_real(++last_virt_irq) != UNDEFINED_IRQ)
-				/* skip irq's in use */;
-			if (last_virt_irq >= NR_IRQS)
-				panic("Too many IRQs are required on this system.  NR_IRQS=%d\n", NR_IRQS);
-			virq = last_virt_irq;
-		}
-		virt_irq_to_real_map[virq] = real_irq;
-		real_irq_to_virt_map[real_irq] = virq;
-	}
-	return virq;
-}
-
-
 static int __init
 prom_next_node(phandle *nodep)
 {
@@ -1381,8 +1528,7 @@ copy_device_tree(unsigned long mem_start
 
 	root = call_prom(RELOC("peer"), 1, 1, (phandle)0);
 	if (root == (phandle)0) {
-		prom_print(RELOC("couldn't get device tree root\n"));
-		prom_exit();
+		prom_panic(RELOC("couldn't get device tree root\n"));
 	}
 	allnextp = &RELOC(allnodes);
 	mem_start = DOUBLEWORD_ALIGN(mem_start);
@@ -1444,6 +1590,23 @@ inspect_node(phandle node, struct device
 		*prev_propp = PTRUNRELOC(pp);
 		prev_propp = &pp->next;
 	}
+
+	/* Add a "linux_phandle" value */
+        if (np->node) {
+		u32 ibm_phandle = 0;
+		int len;
+
+                /* First see if "ibm,phandle" exists and use its value */
+                len = (int)
+                        call_prom(RELOC("getprop"), 4, 1, node, RELOC("ibm,phandle"),
+                                  &ibm_phandle, sizeof(ibm_phandle));
+                if (len < 0) {
+                        np->linux_phandle = np->node;
+                } else {
+                        np->linux_phandle = ibm_phandle;
+		}
+	}
+
 	*prev_propp = 0;
 
 	/* get the node's full name */
@@ -1477,8 +1640,6 @@ finish_device_tree(void)
 {
 	unsigned long mem = klimit;
 
-	virt_irq_init();
-
 	mem = finish_node(allnodes, mem, NULL, 0, 0);
 	dev_tree_size = mem - (unsigned long) allnodes;
 
@@ -1487,7 +1648,7 @@ finish_device_tree(void)
 
 	klimit = mem;
 
-	rtas.dev = find_devices("rtas");
+	rtas.dev = of_find_node_by_name(NULL, "rtas");
 }
 
 static unsigned long __init
@@ -1704,7 +1865,7 @@ finish_node_interrupts(struct device_nod
 		n = map_interrupt(&irq, &ic, np, ints, intrcells);
 		if (n <= 0)
 			continue;
-		np->intrs[i].line = openpic_to_irq(virt_irq_create_mapping(irq[0]));
+		np->intrs[i].line = irq_offset_up(irq[0]);
 		if (n > 1)
 			np->intrs[i].sense = irq[1];
 		if (n > 2) {
@@ -1939,11 +2100,14 @@ int
 machine_is_compatible(const char *compat)
 {
 	struct device_node *root;
-	
-	root = find_path_device("/");
-	if (root == 0)
-		return 0;
-	return device_is_compatible(root, compat);
+	int rc = 0;
+  
+	root = of_find_node_by_path("/");
+	if (root) {
+		rc = device_is_compatible(root, compat);
+		of_node_put(root);
+	}
+	return rc;
 }
 
 /*
@@ -1983,6 +2147,550 @@ find_path_device(const char *path)
 	return NULL;
 }
 
+/*******
+ *
+ * New implementation of the OF "find" APIs, return a refcounted
+ * object, call of_node_put() when done.  The device tree and list
+ * are protected by a rw_lock.
+ *
+ * Note that property management will need some locking as well,
+ * this isn't dealt with yet.
+ *
+ *******/
+
+/**
+ *	of_find_node_by_name - Find a node by its "name" property
+ *	@from:	The node to start searching from or NULL, the node
+ *		you pass will not be searched, only the next one
+ *		will; typically, you pass what the previous call
+ *		returned. of_node_put() will be called on it
+ *	@name:	The name string to match against
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_node_by_name(struct device_node *from,
+	const char *name)
+{
+	struct device_node *np;
+
+	read_lock(&devtree_lock);
+	np = from ? from->allnext : allnodes;
+	for (; np != 0; np = np->allnext)
+		if (np->name != 0 && strcasecmp(np->name, name) == 0
+		    && of_node_get(np))
+			break;
+	if (from)
+		of_node_put(from);
+	read_unlock(&devtree_lock);
+	return np;
+}
+
+/**
+ *	of_find_node_by_type - Find a node by its "device_type" property
+ *	@from:	The node to start searching from or NULL, the node
+ *		you pass will not be searched, only the next one
+ *		will; typically, you pass what the previous call
+ *		returned. of_node_put() will be called on it
+ *	@name:	The type string to match against
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_node_by_type(struct device_node *from,
+	const char *type)
+{
+	struct device_node *np;
+
+	read_lock(&devtree_lock);
+	np = from ? from->allnext : allnodes;
+	for (; np != 0; np = np->allnext)
+		if (np->type != 0 && strcasecmp(np->type, type) == 0
+		    && of_node_get(np))
+			break;
+	if (from)
+		of_node_put(from);
+	read_unlock(&devtree_lock);
+	return np;
+}
+EXPORT_SYMBOL(of_find_node_by_type);
+
+/**
+ *	of_find_compatible_node - Find a node based on type and one of the
+ *                                tokens in its "compatible" property
+ *	@from:		The node to start searching from or NULL, the node
+ *			you pass will not be searched, only the next one
+ *			will; typically, you pass what the previous call
+ *			returned. of_node_put() will be called on it
+ *	@type:		The type string to match "device_type" or NULL to ignore
+ *	@compatible:	The string to match to one of the tokens in the device
+ *			"compatible" list.
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_compatible_node(struct device_node *from,
+	const char *type, const char *compatible)
+{
+	struct device_node *np;
+
+	read_lock(&devtree_lock);
+	np = from ? from->allnext : allnodes;
+	for (; np != 0; np = np->allnext) {
+		if (type != NULL
+		    && !(np->type != 0 && strcasecmp(np->type, type) == 0))
+			continue;
+		if (device_is_compatible(np, compatible) && of_node_get(np))
+			break;
+	}
+	if (from)
+		of_node_put(from);
+	read_unlock(&devtree_lock);
+	return np;
+}
+
+/**
+ *	of_find_node_by_path - Find a node matching a full OF path
+ *	@path:	The full path to match
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_node_by_path(const char *path)
+{
+	struct device_node *np = allnodes;
+
+	read_lock(&devtree_lock);
+	for (; np != 0; np = np->allnext)
+		if (np->full_name != 0 && strcasecmp(np->full_name, path) == 0
+		    && of_node_get(np))
+			break;
+	read_unlock(&devtree_lock);
+	return np;
+}
+
+/**
+ *	of_find_all_nodes - Get next node in global list
+ *	@prev:	Previous node or NULL to start iteration
+ *		of_node_put() will be called on it
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_find_all_nodes(struct device_node *prev)
+{
+	struct device_node *np;
+
+	read_lock(&devtree_lock);
+	np = prev ? prev->allnext : allnodes;
+	for (; np != 0; np = np->allnext)
+		if (of_node_get(np))
+			break;
+	if (prev)
+		of_node_put(prev);
+	read_unlock(&devtree_lock);
+	return np;
+}
+
+/**
+ *	of_get_parent - Get a node's parent if any
+ *	@node:	Node to get parent
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_get_parent(const struct device_node *node)
+{
+	struct device_node *np;
+
+	if (!node)
+		return NULL;
+
+	read_lock(&devtree_lock);
+	np = of_node_get(node->parent);
+	read_unlock(&devtree_lock);
+	return np;
+}
+
+/**
+ *	of_get_next_child - Iterate a node childs
+ *	@node:	parent node
+ *	@prev:	previous child of the parent node, or NULL to get first
+ *
+ *	Returns a node pointer with refcount incremented, use
+ *	of_node_put() on it when done.
+ */
+struct device_node *of_get_next_child(const struct device_node *node,
+	struct device_node *prev)
+{
+	struct device_node *next;
+
+	read_lock(&devtree_lock);
+	next = prev ? prev->sibling : node->child;
+	for (; next != 0; next = next->sibling)
+		if (of_node_get(next))
+			break;
+	if (prev)
+		of_node_put(prev);
+	read_unlock(&devtree_lock);
+	return next;
+}
+
+/**
+ *	of_node_get - Increment refcount of a node
+ *	@node:	Node to inc refcount, NULL is supported to
+ *		simplify writing of callers
+ *
+ *	Returns the node itself or NULL if gone.
+ */
+struct device_node *of_node_get(struct device_node *node)
+{
+	if (node && !OF_IS_STALE(node)) {
+		atomic_inc(&node->_users);
+		return node;
+	}
+	return NULL;
+}
+
+/**
+ *	of_node_put - Decrement refcount of a node
+ *	@node:	Node to dec refcount, NULL is supported to
+ *		simplify writing of callers
+ *
+ */
+void of_node_put(struct device_node *node)
+{
+	if (!node)
+		return;
+
+	WARN_ON(0 == atomic_read(&node->_users));
+
+	if (OF_IS_STALE(node)) {
+		if (atomic_dec_and_test(&node->_users)) {
+			of_node_cleanup(node);
+			return;
+		}
+	}
+	else
+		atomic_dec(&node->_users);
+}
+
+/**
+ *	of_node_cleanup - release a dynamically allocated node
+ *	@arg:  Node to be released
+ */
+static void of_node_cleanup(struct device_node *node)
+{
+	struct property *prop = node->properties;
+
+	if (!OF_IS_DYNAMIC(node))
+		return;
+	while (prop) {
+		struct property *next = prop->next;
+		kfree(prop->name);
+		kfree(prop->value);
+		kfree(prop);
+		prop = next;
+	}
+	kfree(node->intrs);
+	kfree(node->addrs);
+	kfree(node->full_name);
+	kfree(node);
+}
+
+/**
+ *	derive_parent - basically like dirname(1)
+ *	@path:  the full_name of a node to be added to the tree
+ *
+ *	Returns the node which should be the parent of the node
+ *	described by path.  E.g., for path = "/foo/bar", returns
+ *	the node with full_name = "/foo".
+ */
+static struct device_node *derive_parent(const char *path)
+{
+	struct device_node *parent = NULL;
+	char *parent_path = "/";
+	size_t parent_path_len = strrchr(path, '/') - path + 1;
+
+	/* reject if path is "/" */
+	if (!strcmp(path, "/"))
+		return NULL;
+
+	if (strrchr(path, '/') != path) {
+		parent_path = kmalloc(parent_path_len, GFP_KERNEL);
+		if (!parent_path)
+			return NULL;
+		strlcpy(parent_path, path, parent_path_len);
+	}
+	parent = of_find_node_by_path(parent_path);
+	if (strcmp(parent_path, "/"))
+		kfree(parent_path);
+	return parent;
+}
+
+/*
+ * Routines for "runtime" addition and removal of device tree nodes.
+ */
+
+/*
+ * Given a path and a property list, construct an OF device node, add
+ * it to the device tree and global list, and place it in
+ * /proc/device-tree.  This function may sleep.
+ */
+int of_add_node(const char *path, struct property *proplist)
+{
+	struct device_node *np;
+	int err = 0;
+
+	np = kmalloc(sizeof(struct device_node), GFP_KERNEL);
+	if (!np)
+		return -ENOMEM;
+
+	memset(np, 0, sizeof(*np));
+
+	np->full_name = kmalloc(strlen(path) + 1, GFP_KERNEL);
+	if (!np->full_name) {
+		kfree(np);
+		return -ENOMEM;
+	}
+	strcpy(np->full_name, path);
+
+	np->properties = proplist;
+	OF_MARK_DYNAMIC(np);
+	of_node_get(np);
+	np->parent = derive_parent(path);
+	if (!np->parent) {
+		kfree(np);
+		return -EINVAL; /* could also be ENOMEM, though */
+	}
+
+	if (0 != (err = of_finish_dynamic_node(np))) {
+		kfree(np);
+		return err;
+	}
+
+	write_lock(&devtree_lock);
+	np->sibling = np->parent->child;
+	np->allnext = allnodes;
+	np->parent->child = np;
+	allnodes = np;
+	write_unlock(&devtree_lock);
+
+	add_node_proc_entries(np);
+
+	of_node_put(np->parent);
+	of_node_put(np);
+	return 0;
+}
+
+/*
+ * Remove an OF device node from the system.
+ */
+int of_remove_node(struct device_node *np)
+{
+	struct device_node *parent, *child;
+
+	parent = of_get_parent(np);
+	child = of_get_next_child(np, NULL);
+	if (child && !child->child && !child->sibling) {
+		/* For now, we will allow removal of a
+		 * node with one and only one child, so
+		 * that we can support removing a slot with
+		 * an IOA in it.  More general support for
+		 * subtree removal to be implemented later, if
+		 * necessary.
+		 */
+		of_remove_node(child);
+	}
+	else if (child) {
+		of_node_put(child);
+		of_node_put(parent);
+		return -EINVAL;
+	}
+	of_node_put(child);
+
+	write_lock(&devtree_lock);
+	OF_MARK_STALE(np);
+	remove_node_proc_entries(np);
+	if (allnodes == np)
+		allnodes = np->allnext;
+	else {
+		struct device_node *prev;
+		for (prev = allnodes;
+		     prev->allnext != np;
+		     prev = prev->allnext)
+			;
+		prev->allnext = np->allnext;
+	}
+
+	if (np->parent->child == np)
+		np->parent->child = np->sibling;
+	else {
+		struct device_node *prevsib;
+		for (prevsib = np->parent->child;
+		     prevsib->sibling != np;
+		     prevsib = prevsib->sibling)
+			;
+		prevsib->sibling = np->sibling;
+	}
+	write_unlock(&devtree_lock);
+	of_node_put(parent);
+	return 0;
+}
+
+/*
+ * Add a node to /proc/device-tree.
+ */
+static void add_node_proc_entries(struct device_node *np)
+{
+	struct proc_dir_entry *ent;
+
+	ent = proc_mkdir(strrchr(np->full_name, '/') + 1, np->parent->pde);
+	if (ent)
+		proc_device_tree_add_node(np, ent);
+}
+
+static void remove_node_proc_entries(struct device_node *np)
+{
+	struct property *pp = np->properties;
+	struct device_node *parent = np->parent;
+
+	while (pp) {
+		remove_proc_entry(pp->name, np->pde);
+		pp = pp->next;
+	}
+
+	/* Assuming that symlinks have the same parent directory as
+	 * np->pde.
+	 */
+	if (np->name_link)
+		remove_proc_entry(np->name_link->name, parent->pde);
+	if (np->addr_link)
+		remove_proc_entry(np->addr_link->name, parent->pde);
+	if (np->pde)
+		remove_proc_entry(np->pde->name, parent->pde);
+}
+
+/*
+ * Fix up the uninitialized fields in a new device node:
+ * name, type, n_addrs, addrs, n_intrs, intrs, and pci-specific fields
+ *
+ * A lot of boot-time code is duplicated here, because functions such
+ * as finish_node_interrupts, interpret_pci_props, etc. cannot use the
+ * slab allocator.
+ *
+ * This should probably be split up into smaller chunks.
+ */
+
+static int of_finish_dynamic_node(struct device_node *node)
+{
+	struct device_node *parent = of_get_parent(node);
+	u32 *regs;
+	unsigned int *ints;
+	int intlen, intrcells;
+	int i, j, n, err = 0;
+	unsigned int *irq;
+	struct device_node *ic;
+ 
+	node->name = get_property(node, "name", 0);
+	node->type = get_property(node, "device_type", 0);
+
+	if (!parent) {
+		err = -ENODEV;
+		goto out;
+	}
+
+	/* do the work of interpret_pci_props */
+	if (parent->type && !strcmp(parent->type, "pci")) {
+		struct address_range *adr;
+		struct pci_reg_property *pci_addrs;
+		int i, l;
+
+		pci_addrs = (struct pci_reg_property *)
+			get_property(node, "assigned-addresses", &l);
+		if (pci_addrs != 0 && l >= sizeof(struct pci_reg_property)) {
+			i = 0;
+			adr = kmalloc(sizeof(struct address_range) * 
+				      (l / sizeof(struct pci_reg_property)),
+				      GFP_KERNEL);
+			if (!adr) {
+				err = -ENOMEM;
+				goto out;
+			}
+			while ((l -= sizeof(struct pci_reg_property)) >= 0) {
+				adr[i].space = pci_addrs[i].addr.a_hi;
+				adr[i].address = pci_addrs[i].addr.a_lo;
+				adr[i].size = pci_addrs[i].size_lo;
+				++i;
+			}
+			node->addrs = adr;
+			node->n_addrs = i;
+		}
+	}
+
+	/* now do the work of finish_node_interrupts */
+
+	ints = (unsigned int *) get_property(node, "interrupts", &intlen);
+	if (!ints)
+		goto out;
+
+	intrcells = prom_n_intr_cells(node);
+	intlen /= intrcells * sizeof(unsigned int);
+	node->n_intrs = intlen;
+	node->intrs = kmalloc(sizeof(struct interrupt_info) * intlen,
+			      GFP_KERNEL);
+	if (!node->intrs) {
+		err = -ENOMEM;
+		goto out;
+	}
+
+	for (i = 0; i < intlen; ++i) {
+		node->intrs[i].line = 0;
+		node->intrs[i].sense = 1;
+		n = map_interrupt(&irq, &ic, node, ints, intrcells);
+		if (n <= 0)
+			continue;
+		node->intrs[i].line = irq_offset_up(irq[0]);
+		if (n > 1)
+			node->intrs[i].sense = irq[1];
+		if (n > 2) {
+			printk(KERN_DEBUG "hmmm, got %d intr cells for %s:", n,
+			       node->full_name);
+			for (j = 0; j < n; ++j)
+				printk(" %d", irq[j]);
+			printk("\n");
+		}
+		ints += intrcells;
+	}
+
+       /* now do the rough equivalent of update_dn_pci_info, this
+        * probably is not correct for phb's, but should work for
+	* IOAs and slots.
+        */
+
+       node->phb = parent->phb;
+
+       regs = (u32 *)get_property(node, "reg", 0);
+       if (regs) {
+               node->busno = (regs[0] >> 16) & 0xff;
+               node->devfn = (regs[0] >> 8) & 0xff;
+       }
+
+	/* fixing up tce_table */
+
+	if(strcmp(node->name, "pci") == 0 &&
+                get_property(node, "ibm,dma-window", NULL)) {
+                node->bussubno = node->busno;
+                create_pci_bus_tce_table((unsigned long)node);
+        }
+	else
+		node->tce_table = parent->tce_table;
+
+out:
+	of_node_put(parent);
+	return err;
+}
+
 /*
  * Find the device_node with a given phandle.
  */
@@ -1992,7 +2700,7 @@ find_phandle(phandle ph)
 	struct device_node *np;
 
 	for (np = allnodes; np != 0; np = np->allnext)
-		if (np->node == ph)
+		if (np->linux_phandle == ph)
 			return np;
 	return NULL;
 }
@@ -2082,17 +2790,6 @@ print_properties(struct device_node *np)
 #endif
 
 
-void __init
-abort()
-{
-#ifdef CONFIG_XMON
-	xmon(NULL);
-#endif
-	for (;;)
-		prom_exit();
-}
-
-
 /* Verify bi_recs are good */
 static struct bi_record *
 prom_bi_rec_verify(struct bi_record *bi_recs)
diff -purN linux-2.5/arch/ppc64/kernel/ras.c linuxppc64-2.5/arch/ppc64/kernel/ras.c
--- linux-2.5/arch/ppc64/kernel/ras.c	2003-06-07 01:59:39.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/ras.c	2003-11-21 04:51:10.000000000 +0000
@@ -1,4 +1,3 @@
-
 /*
  * ras.c
  * Copyright (C) 2001 Dave Engebretsen IBM Corporation
@@ -70,27 +69,29 @@ static int __init init_ras_IRQ(void)
 	struct device_node *np;
 	unsigned int *ireg, len, i;
 
-	if((np = find_path_device("/event-sources/internal-errors")) &&
-	   (ireg = (unsigned int *)get_property(np, "open-pic-interrupt", 
-						&len))) {
-		for(i=0; i<(len / sizeof(*ireg)); i++) {
-			request_irq(virt_irq_create_mapping(*(ireg)) + NUM_8259_INTERRUPTS, 
+	if ((np = of_find_node_by_path("/event-sources/internal-errors")) &&
+	    (ireg = (unsigned int *)get_property(np, "open-pic-interrupt",
+						 &len))) {
+		for (i=0; i<(len / sizeof(*ireg)); i++) {
+			request_irq(irq_offset_up(*(ireg)), 
 				    ras_error_interrupt, 0, 
 				    "RAS_ERROR", NULL);
 			ireg++;
 		}
 	}
+	of_node_put(np);
 
-	if((np = find_path_device("/event-sources/epow-events")) &&
-	   (ireg = (unsigned int *)get_property(np, "open-pic-interrupt", 
-						&len))) {
-		for(i=0; i<(len / sizeof(*ireg)); i++) {
-			request_irq(virt_irq_create_mapping(*(ireg)) + NUM_8259_INTERRUPTS, 
+	if ((np = of_find_node_by_path("/event-sources/epow-events")) &&
+	    (ireg = (unsigned int *)get_property(np, "open-pic-interrupt",
+						 &len))) {
+		for (i=0; i<(len / sizeof(*ireg)); i++) {
+			request_irq(irq_offset_up(*(ireg)),
 				    ras_epow_interrupt, 0, 
 				    "RAS_EPOW", NULL);
 			ireg++;
 		}
 	}
+	of_node_put(np);
 
 	return 1;
 }
@@ -112,7 +113,7 @@ ras_epow_interrupt(int irq, void *dev_id
 
 	status = rtas_call(rtas_token("check-exception"), 6, 1, NULL, 
 			   0x500, irq, 
-			   EPOW_WARNING | POWERMGM_EVENTS, 
+			   RTAS_EPOW_WARNING | RTAS_POWERMGM_EVENTS, 
 			   1,  /* Time Critical */
 			   __pa(&log_entry), size);
 
@@ -120,6 +121,10 @@ ras_epow_interrupt(int irq, void *dev_id
 		    *((unsigned long *)&log_entry), status); 
 	printk(KERN_WARNING 
 		"EPOW <0x%lx 0x%lx>\n",*((unsigned long *)&log_entry), status);
+
+	/* format and print the extended information */
+	log_error((char *)&log_entry, ERR_TYPE_RTAS_LOG, 0);
+	
 	return IRQ_HANDLED;
 }
 
@@ -137,15 +142,23 @@ ras_error_interrupt(int irq, void *dev_i
 	struct rtas_error_log log_entry;
 	unsigned int size = sizeof(log_entry);
 	long status = 0xdeadbeef;
+	int fatal;
 
 	status = rtas_call(rtas_token("check-exception"), 6, 1, NULL, 
 			   0x500, irq, 
-			   INTERNAL_ERROR, 
+			   RTAS_INTERNAL_ERROR, 
 			   1, /* Time Critical */
 			   __pa(&log_entry), size);
 
-	if((status != 1) && 
-	   (log_entry.severity >= SEVERITY_ERROR_SYNC)) {
+	if ((status == 0) && (log_entry.severity >= SEVERITY_ERROR_SYNC)) 
+		fatal = 1;
+	else
+		fatal = 0;
+
+	/* format and print the extended information */
+	log_error((char *)&log_entry, ERR_TYPE_RTAS_LOG, fatal); 
+
+	if (fatal) {
 		udbg_printf("HW Error <0x%lx 0x%lx>\n",
 			    *((unsigned long *)&log_entry), status);
 		printk(KERN_EMERG 
@@ -155,6 +168,7 @@ ras_error_interrupt(int irq, void *dev_i
 #ifndef DEBUG
 		/* Don't actually power off when debugging so we can test
 		 * without actually failing while injecting errors.
+		 * Error data will not be logged to syslog.
 		 */
 		ppc_md.power_off();
 #endif
diff -purN linux-2.5/arch/ppc64/kernel/rtas-proc.c linuxppc64-2.5/arch/ppc64/kernel/rtas-proc.c
--- linux-2.5/arch/ppc64/kernel/rtas-proc.c	2003-04-21 19:42:07.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/rtas-proc.c	2003-11-21 04:51:10.000000000 +0000
@@ -20,6 +20,7 @@
 #include <linux/ctype.h>
 #include <linux/time.h>
 #include <linux/string.h>
+#include <linux/init.h>
 
 #include <asm/uaccess.h>
 #include <asm/bitops.h>
@@ -27,6 +28,7 @@
 #include <asm/io.h>
 #include <asm/prom.h>
 #include <asm/rtas.h>
+#include <asm/proc_fs.h>
 #include <asm/machdep.h> /* for ppc_md */
 #include <asm/time.h>
 
@@ -161,6 +163,8 @@ static ssize_t ppc_rtas_tone_volume_writ
 		size_t count, loff_t *ppos);
 static ssize_t ppc_rtas_tone_volume_read(struct file * file, char * buf,
 		size_t count, loff_t *ppos);
+static ssize_t ppc_rtas_rmo_buf_read(struct file *file, char *buf,
+				    size_t count, loff_t *ppos);
 
 struct file_operations ppc_rtas_poweron_operations = {
 	.read =		ppc_rtas_poweron_read,
@@ -185,6 +189,10 @@ struct file_operations ppc_rtas_tone_vol
 	.write =	ppc_rtas_tone_volume_write
 };
 
+static struct file_operations ppc_rtas_rmo_buf_ops = {
+	.read =		ppc_rtas_rmo_buf_read,
+};
+
 int ppc_rtas_find_all_sensors (void);
 int ppc_rtas_process_sensor(struct individual_sensor s, int state, 
 		int error, char * buf);
@@ -200,39 +208,42 @@ void proc_rtas_init(void)
 {
 	struct proc_dir_entry *entry;
 
-	rtas_node = find_devices("rtas");
+	rtas_node = of_find_node_by_name(NULL, "rtas");
 	if ((rtas_node == NULL) || (systemcfg->platform == PLATFORM_ISERIES_LPAR)) {
 		return;
 	}
 	
-	if (proc_rtas == NULL) {
-		proc_rtas = proc_mkdir("rtas", 0);
+	if (proc_ppc64.rtas == NULL) {
+		proc_ppc64_init();
 	}
 
-	if (proc_rtas == NULL) {
+	if (proc_ppc64.rtas == NULL) {
 		printk(KERN_ERR "Failed to create /proc/rtas in proc_rtas_init\n");
 		return;
 	}
 
 	/* /proc/rtas entries */
 
-	entry = create_proc_entry("progress", S_IRUGO|S_IWUSR, proc_rtas);
+	entry = create_proc_entry("progress", S_IRUGO|S_IWUSR, proc_ppc64.rtas);
 	if (entry) entry->proc_fops = &ppc_rtas_progress_operations;
 
-	entry = create_proc_entry("clock", S_IRUGO|S_IWUSR, proc_rtas); 
+	entry = create_proc_entry("clock", S_IRUGO|S_IWUSR, proc_ppc64.rtas); 
 	if (entry) entry->proc_fops = &ppc_rtas_clock_operations;
 
-	entry = create_proc_entry("poweron", S_IWUSR|S_IRUGO, proc_rtas); 
+	entry = create_proc_entry("poweron", S_IWUSR|S_IRUGO, proc_ppc64.rtas); 
 	if (entry) entry->proc_fops = &ppc_rtas_poweron_operations;
 
-	create_proc_read_entry("sensors", S_IRUGO, proc_rtas, 
+	create_proc_read_entry("sensors", S_IRUGO, proc_ppc64.rtas, 
 			ppc_rtas_sensor_read, NULL);
 	
-	entry = create_proc_entry("frequency", S_IWUSR|S_IRUGO, proc_rtas); 
+	entry = create_proc_entry("frequency", S_IWUSR|S_IRUGO, proc_ppc64.rtas); 
 	if (entry) entry->proc_fops = &ppc_rtas_tone_freq_operations;
 
-	entry = create_proc_entry("volume", S_IWUSR|S_IRUGO, proc_rtas); 
+	entry = create_proc_entry("volume", S_IWUSR|S_IRUGO, proc_ppc64.rtas); 
 	if (entry) entry->proc_fops = &ppc_rtas_tone_volume_operations;
+
+	entry = create_proc_entry("rmo_buffer", S_IRUSR, proc_ppc64.rtas);
+	if (entry) entry->proc_fops = &ppc_rtas_rmo_buf_ops;
 }
 
 /* ****************************************************************** */
@@ -851,3 +862,28 @@ static ssize_t ppc_rtas_tone_volume_read
 	*ppos += n;
 	return n;
 }
+
+#define RMO_READ_BUF_MAX 30
+
+/* RTAS Userspace access */
+static ssize_t ppc_rtas_rmo_buf_read(struct file *file, char __user *buf,
+				    size_t count, loff_t *ppos)
+{
+	char kbuf[RMO_READ_BUF_MAX];
+	int n;
+
+	n = sprintf(kbuf, "%016lx %x\n", rtas_rmo_buf, RTAS_RMOBUF_MAX);
+	if (n > count)
+		n = count;
+
+	if (ppos && *ppos != 0)
+		return 0;
+
+	if (copy_to_user(buf, kbuf, n))
+		return -EFAULT;
+
+	if (ppos)
+		*ppos = n;
+	
+	return n;
+}
diff -purN linux-2.5/arch/ppc64/kernel/rtas.c linuxppc64-2.5/arch/ppc64/kernel/rtas.c
--- linux-2.5/arch/ppc64/kernel/rtas.c	2003-09-02 06:46:42.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/rtas.c	2003-11-21 04:51:10.000000000 +0000
@@ -16,6 +16,7 @@
 #include <linux/types.h>
 #include <linux/spinlock.h>
 #include <linux/module.h>
+#include <linux/init.h>
 
 #include <asm/prom.h>
 #include <asm/proc_fs.h>
@@ -28,6 +29,8 @@
 #include <asm/system.h>
 #include <asm/abs_addr.h>
 #include <asm/udbg.h>
+#include <asm/delay.h>
+#include <asm/uaccess.h>
 
 struct flash_block_list_header rtas_firmware_flash_list = {0, 0};
 
@@ -59,7 +62,7 @@ struct rtas_t rtas = { 
 extern unsigned long reloc_offset(void);
 
 spinlock_t rtas_data_buf_lock = SPIN_LOCK_UNLOCKED;
-char rtas_data_buf[RTAS_DATA_BUF_SIZE];
+char rtas_data_buf[RTAS_DATA_BUF_SIZE]__page_aligned;
 
 void
 phys_call_rtas(int token, int nargs, int nret, ...)
@@ -180,18 +183,18 @@ rtas_call(int token, int nargs, int nret
 }
 
 /* Given an RTAS status code of 990n compute the hinted delay of 10^n
- * (last digit) milliseconds.  For now we bound at n=3 (1 sec).
+ * (last digit) milliseconds.  For now we bound at n=5 (100 sec).
  */
 unsigned int
 rtas_extended_busy_delay_time(int status)
 {
 	int order = status - 9900;
-	unsigned int ms;
+	unsigned long ms;
 
 	if (order < 0)
 		order = 0;	/* RTC depends on this for -2 clock busy */
-	else if (order > 3)
-		order = 3;	/* bound */
+	else if (order > 5)
+		order = 5;	/* bound */
 
 	/* Use microseconds for reasonable accuracy */
 	for (ms = 1000; order > 0; order--)
@@ -199,6 +202,80 @@ rtas_extended_busy_delay_time(int status
 	return ms / (1000000/HZ); /* round down is fine */
 }
 
+int
+rtas_get_power_level(int powerdomain, int *level)
+{
+	int token = rtas_token("get-power-level");
+	long powerlevel;
+	int rc;
+
+	if (token == RTAS_UNKNOWN_SERVICE)
+		return RTAS_UNKNOWN_OP;
+
+	while(1) {
+		rc = (int) rtas_call(token, 1, 2, &powerlevel, powerdomain);
+		if (rc == RTAS_BUSY)
+			udelay(1);
+		else
+			break;
+	}
+	*level = (int) powerlevel;
+	return rc;
+}
+
+int
+rtas_get_sensor(int sensor, int index, int *state)
+{
+	int token = rtas_token("get-sensor-state");
+	unsigned int wait_time;
+	long returned_state;
+	int rc;
+
+	if (token == RTAS_UNKNOWN_SERVICE)
+		return RTAS_UNKNOWN_OP;
+
+	while (1) {
+		rc = (int) rtas_call(token, 2, 2, &returned_state, sensor,
+					index);
+		if (rc == RTAS_BUSY)
+			udelay(1);
+		else if (rtas_is_extended_busy(rc)) {
+			wait_time = rtas_extended_busy_delay_time(rc);
+			udelay(wait_time * 1000);
+		}
+		else
+			break;
+	}
+	*state = (int) returned_state;
+	return rc;
+}
+
+int
+rtas_set_indicator(int indicator, int index, int new_value)
+{
+	int token = rtas_token("set-indicator");
+	unsigned int wait_time;
+	int rc;
+
+	if (token == RTAS_UNKNOWN_SERVICE)
+		return RTAS_UNKNOWN_OP;
+
+	while (1) {
+		rc = (int) rtas_call(token, 3, 1, NULL, indicator, index,
+					new_value);
+		if (rc == RTAS_BUSY)
+			udelay(1);
+		else if (rtas_is_extended_busy(rc)) {
+			wait_time = rtas_extended_busy_delay_time(rc);
+			udelay(wait_time * 1000);
+		}
+		else
+			break;
+	}
+
+	return rc;
+}
+
 #define FLASH_BLOCK_LIST_VERSION (1UL)
 static void
 rtas_flash_firmware(void)
@@ -308,9 +385,51 @@ rtas_halt(void)
         rtas_power_off();
 }
 
-EXPORT_SYMBOL(proc_ppc64);
+unsigned long rtas_rmo_buf = 0;
+
+asmlinkage int ppc_rtas(struct rtas_args __user *uargs)
+{
+	struct rtas_args args;
+	unsigned long flags;
+
+	if (!capable(CAP_SYS_ADMIN))
+		return -EPERM;
+
+	if (copy_from_user(&args, uargs, 3 * sizeof(u32)) != 0)
+		return -EFAULT;
+
+	if (args.nargs > ARRAY_SIZE(args.args)
+	    || args.nret > ARRAY_SIZE(args.args)
+	    || args.nargs + args.nret > ARRAY_SIZE(args.args))
+		return -EINVAL;
+
+	/* Copy in args. */
+	if (copy_from_user(args.args, uargs->args,
+			   args.nargs * sizeof(rtas_arg_t)) != 0)
+		return -EFAULT;
+
+	spin_lock_irqsave(&rtas.lock, flags);
+	get_paca()->xRtas = args;
+	enter_rtas((void *)__pa((unsigned long)&get_paca()->xRtas));
+	args = get_paca()->xRtas;
+	spin_unlock_irqrestore(&rtas.lock, flags);
+
+	/* Copy out args. */
+	if (copy_to_user(uargs->args + args.nargs,
+			 args.args + args.nargs,
+			 args.nret * sizeof(rtas_arg_t)) != 0)
+		return -EFAULT;
+
+	return 0;
+}
+
+
 EXPORT_SYMBOL(rtas_firmware_flash_list);
 EXPORT_SYMBOL(rtas_token);
 EXPORT_SYMBOL(rtas_call);
 EXPORT_SYMBOL(rtas_data_buf);
 EXPORT_SYMBOL(rtas_data_buf_lock);
+EXPORT_SYMBOL(rtas_extended_busy_delay_time);
+EXPORT_SYMBOL(rtas_get_sensor);
+EXPORT_SYMBOL(rtas_get_power_level);
+EXPORT_SYMBOL(rtas_set_indicator);
diff -purN linux-2.5/arch/ppc64/kernel/rtas_flash.c linuxppc64-2.5/arch/ppc64/kernel/rtas_flash.c
--- linux-2.5/arch/ppc64/kernel/rtas_flash.c	2003-03-26 04:30:59.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/rtas_flash.c	2003-10-23 19:11:59.000000000 +0000
@@ -14,15 +14,64 @@
  */
 
 #include <linux/module.h>
-#include <linux/proc_fs.h>
+
+#include <linux/config.h>
 #include <linux/init.h>
+#include <asm/proc_fs.h>
+#include <asm/delay.h>
 #include <asm/uaccess.h>
 #include <asm/rtas.h>
 
 #define MODULE_VERSION "1.0"
 #define MODULE_NAME "rtas_flash"
 
-#define FIRMWARE_FLASH_NAME "firmware_flash"
+#define FIRMWARE_FLASH_NAME "firmware_flash"   
+#define FIRMWARE_UPDATE_NAME "firmware_update"
+#define MANAGE_FLASH_NAME "manage_flash"
+#define VALIDATE_FLASH_NAME "validate_flash"
+
+/* General RTAS Status Codes */
+#define RTAS_RC_SUCCESS  0
+#define RTAS_RC_HW_ERR	-1
+#define RTAS_RC_BUSY	-2
+
+/* Flash image status values */
+#define FLASH_AUTH           -9002 /* RTAS Not Service Authority Partition */
+#define FLASH_NO_OP          -1099 /* No operation initiated by user */	
+#define FLASH_IMG_SHORT	     -1005 /* Flash image shorter than expected */
+#define FLASH_IMG_BAD_LEN    -1004 /* Bad length value in flash list block */
+#define FLASH_IMG_NULL_DATA  -1003 /* Bad data value in flash list block */
+#define FLASH_IMG_READY      0     /* Firmware img ready for flash on reboot */
+
+/* Manage image status values */
+#define MANAGE_AUTH          -9002 /* RTAS Not Service Authority Partition */
+#define MANAGE_ACTIVE_ERR    -9001 /* RTAS Cannot Overwrite Active Img */
+#define MANAGE_NO_OP         -1099 /* No operation initiated by user */
+#define MANAGE_PARAM_ERR     -3    /* RTAS Parameter Error */
+#define MANAGE_HW_ERR        -1    /* RTAS Hardware Error */
+
+/* Validate image status values */
+#define VALIDATE_AUTH          -9002 /* RTAS Not Service Authority Partition */
+#define VALIDATE_NO_OP         -1099 /* No operation initiated by the user */
+#define VALIDATE_INCOMPLETE    -1002 /* User copied < VALIDATE_BUF_SIZE */
+#define VALIDATE_READY	       -1001 /* Firmware image ready for validation */
+#define VALIDATE_PARAM_ERR     -3    /* RTAS Parameter Error */
+#define VALIDATE_HW_ERR        -1    /* RTAS Hardware Error */
+#define VALIDATE_TMP_UPDATE    0     /* Validate Return Status */
+#define VALIDATE_FLASH_AUTH    1     /* Validate Return Status */
+#define VALIDATE_INVALID_IMG   2     /* Validate Return Status */
+#define VALIDATE_CUR_UNKNOWN   3     /* Validate Return Status */
+#define VALIDATE_TMP_COMMIT_DL 4     /* Validate Return Status */
+#define VALIDATE_TMP_COMMIT    5     /* Validate Return Status */
+#define VALIDATE_TMP_UPDATE_DL 6     /* Validate Return Status */
+
+/* ibm,manage-flash-image operation tokens */
+#define RTAS_REJECT_TMP_IMG   0
+#define RTAS_COMMIT_TMP_IMG   1
+
+/* Array sizes */
+#define VALIDATE_BUF_SIZE 4096    
+#define RTAS_MSG_MAXLEN   64
 
 /* Local copy of the flash block list.
  * We only allow one open of the flash proc file and create this
@@ -34,21 +83,35 @@
  * is treated as the number of entries currently in the block
  * (i.e. not a byte count).  This is all fixed on release.
  */
-static struct flash_block_list *flist;
-static char *flash_msg;
-static int flash_possible;
-
-static int rtas_flash_open(struct inode *inode, struct file *file)
-{
-	if ((file->f_mode & FMODE_WRITE) && flash_possible) {
-		if (flist)
-			return -EBUSY;
-		flist = (struct flash_block_list *)get_zeroed_page(GFP_KERNEL);
-		if (!flist)
-			return -ENOMEM;
-	}
-	return 0;
-}
+
+/* Status int must be first member of struct */
+struct rtas_update_flash_t
+{
+	int status;			/* Flash update status */
+	struct flash_block_list *flist; /* Local copy of flash block list */
+};
+
+/* Status int must be first member of struct */
+struct rtas_manage_flash_t
+{
+	int status;			/* Returned status */
+	unsigned int op;		/* Reject or commit image */
+};
+
+/* Status int must be first member of struct */
+struct rtas_validate_flash_t
+{
+	int status;		 	/* Returned status */	
+	char buf[VALIDATE_BUF_SIZE]; 	/* Candidate image buffer */
+	unsigned int buf_size;		/* Size of image buf */
+	unsigned int update_results;	/* Update results token */
+};
+
+static spinlock_t flash_file_open_lock = SPIN_LOCK_UNLOCKED;
+static struct proc_dir_entry *firmware_flash_pde = NULL;
+static struct proc_dir_entry *firmware_update_pde = NULL;
+static struct proc_dir_entry *validate_pde = NULL;
+static struct proc_dir_entry *manage_pde = NULL;
 
 /* Do simple sanity checks on the flash image. */
 static int flash_list_valid(struct flash_block_list *flist)
@@ -57,32 +120,29 @@ static int flash_list_valid(struct flash
 	int i;
 	unsigned long block_size, image_size;
 
-	flash_msg = NULL;
 	/* Paranoid self test here.  We also collect the image size. */
 	image_size = 0;
 	for (f = flist; f; f = f->next) {
 		for (i = 0; i < f->num_blocks; i++) {
 			if (f->blocks[i].data == NULL) {
-				flash_msg = "error: internal error null data\n";
-				return 0;
+				return FLASH_IMG_NULL_DATA;
 			}
 			block_size = f->blocks[i].length;
 			if (block_size <= 0 || block_size > PAGE_SIZE) {
-				flash_msg = "error: internal error bad length\n";
-				return 0;
+				return FLASH_IMG_BAD_LEN;
 			}
 			image_size += block_size;
 		}
 	}
+
 	if (image_size < (256 << 10)) {
-		if (image_size < 2)
-			flash_msg = NULL;	/* allow "clear" of image */
-		else
-			flash_msg = "error: flash image short\n";
-		return 0;
+		if (image_size < 2) 
+			return FLASH_NO_OP;
 	}
+
 	printk(KERN_INFO "FLASH: flash image with %ld bytes stored for hardware flash on reboot\n", image_size);
-	return 1;
+
+	return FLASH_IMG_READY;
 }
 
 static void free_flash_list(struct flash_block_list *f)
@@ -101,40 +161,80 @@ static void free_flash_list(struct flash
 
 static int rtas_flash_release(struct inode *inode, struct file *file)
 {
-	if (flist) {
-		/* Always clear saved list on a new attempt. */
+	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
+	struct rtas_update_flash_t *uf;
+	
+	uf = (struct rtas_update_flash_t *) dp->data;
+	if (uf->flist) {    
+		/* File was opened in write mode for a new flash attempt */
+		/* Clear saved list */
 		if (rtas_firmware_flash_list.next) {
 			free_flash_list(rtas_firmware_flash_list.next);
 			rtas_firmware_flash_list.next = NULL;
 		}
 
-		if (flash_list_valid(flist))
-			rtas_firmware_flash_list.next = flist;
+		if (uf->status != FLASH_AUTH)  
+			uf->status = flash_list_valid(uf->flist);
+
+		if (uf->status == FLASH_IMG_READY) 
+			rtas_firmware_flash_list.next = uf->flist;
 		else
-			free_flash_list(flist);
-		flist = NULL;
+			free_flash_list(uf->flist);
+
+		uf->flist = NULL;
 	}
+
+	atomic_dec(&dp->count);
 	return 0;
 }
 
+static void get_flash_status_msg(int status, char *buf)
+{
+	char *msg;
+
+	switch (status) {
+	case FLASH_AUTH:
+		msg = "error: this partition does not have service authority\n";
+		break;
+	case FLASH_NO_OP:
+		msg = "info: no firmware image for flash\n";
+		break;
+	case FLASH_IMG_SHORT:
+		msg = "error: flash image short\n";
+		break;
+	case FLASH_IMG_BAD_LEN:
+		msg = "error: internal error bad length\n";
+		break;
+	case FLASH_IMG_NULL_DATA:
+		msg = "error: internal error null data\n";
+		break;
+	case FLASH_IMG_READY:
+		msg = "ready: firmware image ready for flash on reboot\n";
+		break;
+	default:
+		sprintf(buf, "error: unexpected status value %d\n", status);
+		return;
+	}
+
+	strcpy(buf, msg);	
+}
+
 /* Reading the proc file will show status (not the firmware contents) */
 static ssize_t rtas_flash_read(struct file *file, char *buf,
 			       size_t count, loff_t *ppos)
 {
+	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
+	struct rtas_update_flash_t *uf;
+	char msg[RTAS_MSG_MAXLEN];
 	int error;
-	char *msg;
 	int msglen;
 
-	if (!flash_possible) {
-		msg = "error: this partition does not have service authority\n";
-	} else if (flist) {
-		msg = "info: this file is busy for write by some process\n";
-	} else if (flash_msg) {
-		msg = flash_msg;	/* message from last flash attempt */
-	} else if (rtas_firmware_flash_list.next) {
-		msg = "ready: firmware image ready for flash on reboot\n";
-	} else {
-		msg = "info: no firmware image for flash\n";
+	uf = (struct rtas_update_flash_t *) dp->data;
+
+	if (!strcmp(dp->name, FIRMWARE_FLASH_NAME)) {
+		get_flash_status_msg(uf->status, msg);
+	} else {	   /* FIRMWARE_UPDATE_NAME */
+		sprintf(msg, "%d\n", uf->status);
 	}
 	msglen = strlen(msg);
 	if (msglen > count)
@@ -147,7 +247,8 @@ static ssize_t rtas_flash_read(struct fi
 	if (error)
 		return -EINVAL;
 
-	copy_to_user(buf, msg, msglen);
+	if (copy_to_user(buf, msg, msglen))
+		return -EFAULT;
 
 	if (ppos)
 		*ppos = msglen;
@@ -162,14 +263,28 @@ static ssize_t rtas_flash_read(struct fi
 static ssize_t rtas_flash_write(struct file *file, const char *buffer,
 				size_t count, loff_t *off)
 {
-	size_t len = count;
+	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
+	struct rtas_update_flash_t *uf;
 	char *p;
 	int next_free;
-	struct flash_block_list *fl = flist;
+	struct flash_block_list *fl;
+
+	uf = (struct rtas_update_flash_t *) dp->data;
 
-	if (!flash_possible || len == 0)
-		return len;	/* discard data */
+	if (uf->status == FLASH_AUTH || count == 0)
+		return count;	/* discard data */
 
+	/* In the case that the image is not ready for flashing, the memory
+	 * allocated for the block list will be freed upon the release of the 
+	 * proc file
+	 */
+	if (uf->flist == NULL) {
+		uf->flist = (struct flash_block_list *) get_zeroed_page(GFP_KERNEL);
+		if (!uf->flist)
+			return -ENOMEM;
+	}
+
+	fl = uf->flist;
 	while (fl->next)
 		fl = fl->next; /* seek to last block_list for append */
 	next_free = fl->num_blocks;
@@ -182,47 +297,387 @@ static ssize_t rtas_flash_write(struct f
 		next_free = 0;
 	}
 
-	if (len > PAGE_SIZE)
-		len = PAGE_SIZE;
+	if (count > PAGE_SIZE)
+		count = PAGE_SIZE;
 	p = (char *)get_zeroed_page(GFP_KERNEL);
 	if (!p)
 		return -ENOMEM;
-	if(copy_from_user(p, buffer, len)) {
+	
+	if(copy_from_user(p, buffer, count)) {
 		free_page((unsigned long)p);
 		return -EFAULT;
 	}
 	fl->blocks[next_free].data = p;
-	fl->blocks[next_free].length = len;
+	fl->blocks[next_free].length = count;
 	fl->num_blocks++;
 
-	return len;
+	return count;
+}
+
+static int rtas_excl_open(struct inode *inode, struct file *file)
+{
+	struct proc_dir_entry *dp = PDE(inode);
+
+	/* Enforce exclusive open with use count of PDE */
+	spin_lock(&flash_file_open_lock);
+	if (atomic_read(&dp->count) > 1) {
+		spin_unlock(&flash_file_open_lock);
+		return -EBUSY;
+	}
+
+	atomic_inc(&dp->count);
+	spin_unlock(&flash_file_open_lock);
+	
+	return 0;
+}
+
+static int rtas_excl_release(struct inode *inode, struct file *file)
+{
+	struct proc_dir_entry *dp = PDE(inode);
+
+	atomic_dec(&dp->count);
+
+	return 0;
+}
+
+static void manage_flash(struct rtas_manage_flash_t *args_buf)
+{
+	unsigned int wait_time;
+	s32 rc;
+
+	while (1) {
+		rc = (s32) rtas_call(rtas_token("ibm,manage-flash-image"), 1, 
+				1, NULL, (long) args_buf->op);
+		if (rc == RTAS_RC_BUSY)
+			udelay(1);
+		else if (rtas_is_extended_busy(rc)) {
+			wait_time = rtas_extended_busy_delay_time(rc);
+			udelay(wait_time * 1000);
+		} else
+			break;
+	}
+
+	args_buf->status = rc;
+}
+
+static ssize_t manage_flash_read(struct file *file, char *buf,
+			       size_t count, loff_t *ppos)
+{
+	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
+	struct rtas_manage_flash_t *args_buf;
+	char msg[RTAS_MSG_MAXLEN];
+	int msglen;
+	int error;
+
+	args_buf = (struct rtas_manage_flash_t *) dp->data;
+	if (args_buf == NULL)
+		return 0;
+
+	msglen = sprintf(msg, "%d\n", args_buf->status);
+	if (msglen > count)
+		msglen = count;
+
+	if (ppos && *ppos != 0)
+		return 0;	/* be cheap */
+
+	error = verify_area(VERIFY_WRITE, buf, msglen);
+	if (error)
+		return -EINVAL;
+
+	if (copy_to_user(buf, msg, msglen))
+		return -EFAULT;
+
+	if (ppos)
+		*ppos = msglen;
+	return msglen;
+}
+
+static ssize_t manage_flash_write(struct file *file, const char *buf,
+				size_t count, loff_t *off)
+{
+	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
+	struct rtas_manage_flash_t *args_buf;
+	const char reject_str[] = "0";
+	const char commit_str[] = "1";
+	int op;
+
+	args_buf = (struct rtas_manage_flash_t *) dp->data;
+	if ((args_buf->status == MANAGE_AUTH) || (count == 0))
+		return count;
+		
+	op = -1;
+	if (buf) {
+		if (strncmp(buf, reject_str, strlen(reject_str)) == 0) 
+			op = RTAS_REJECT_TMP_IMG;
+		else if (strncmp(buf, commit_str, strlen(commit_str)) == 0) 
+			op = RTAS_COMMIT_TMP_IMG;
+	}
+	
+	if (op == -1)   /* buf is empty, or contains invalid string */
+		return -EINVAL;
+
+	args_buf->op = op;
+	manage_flash(args_buf);
+
+	return count;
+}
+
+static void validate_flash(struct rtas_validate_flash_t *args_buf)
+{
+	int token = rtas_token("ibm,validate-flash-image");
+	unsigned int wait_time;
+	long update_results;
+	s32 rc;	
+
+	rc = 0;
+	while(1) {
+		spin_lock(&rtas_data_buf_lock);
+		memcpy(rtas_data_buf, args_buf->buf, VALIDATE_BUF_SIZE);
+		rc = (s32) rtas_call(token, 2, 2, &update_results, 
+				     __pa(rtas_data_buf), args_buf->buf_size);
+		memcpy(args_buf->buf, rtas_data_buf, VALIDATE_BUF_SIZE);
+		spin_unlock(&rtas_data_buf_lock);
+			
+		if (rc == RTAS_RC_BUSY)
+			udelay(1);
+		else if (rtas_is_extended_busy(rc)) {
+			wait_time = rtas_extended_busy_delay_time(rc);
+			udelay(wait_time * 1000);
+		} else
+			break;
+	}
+
+	args_buf->status = rc;
+	args_buf->update_results = (u32) update_results;
+}
+
+static int get_validate_flash_msg(struct rtas_validate_flash_t *args_buf, 
+		                   char *msg)
+{
+	int n;
+
+	if (args_buf->status >= VALIDATE_TMP_UPDATE) { 
+		n = sprintf(msg, "%d\n", args_buf->update_results);
+		if ((args_buf->update_results >= VALIDATE_CUR_UNKNOWN) ||
+		    (args_buf->update_results == VALIDATE_TMP_UPDATE))
+			n += sprintf(msg + n, "%s\n", args_buf->buf);
+	} else {
+		n = sprintf(msg, "%d\n", args_buf->status);
+	}
+	return n;
+}
+
+static ssize_t validate_flash_read(struct file *file, char *buf,
+			       size_t count, loff_t *ppos)
+{
+	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
+	struct rtas_validate_flash_t *args_buf;
+	char msg[RTAS_MSG_MAXLEN];
+	int msglen;
+	int error;
+
+	args_buf = (struct rtas_validate_flash_t *) dp->data;
+
+	if (ppos && *ppos != 0)
+		return 0;	/* be cheap */
+	
+	msglen = get_validate_flash_msg(args_buf, msg);
+	if (msglen > count)
+		msglen = count;
+
+	error = verify_area(VERIFY_WRITE, buf, msglen);
+	if (error)
+		return -EINVAL;
+
+	if (copy_to_user(buf, msg, msglen))
+		return -EFAULT;
+
+	if (ppos)
+		*ppos = msglen;
+	return msglen;
+}
+
+static ssize_t validate_flash_write(struct file *file, const char *buf,
+				size_t count, loff_t *off)
+{
+	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
+	struct rtas_validate_flash_t *args_buf;
+	int rc;
+
+	args_buf = (struct rtas_validate_flash_t *) dp->data;
+
+	if (dp->data == NULL) {
+		dp->data = kmalloc(sizeof(struct rtas_validate_flash_t), 
+				GFP_KERNEL);
+		if (dp->data == NULL) 
+			return -ENOMEM;
+	}
+
+	/* We are only interested in the first 4K of the
+	 * candidate image */
+	if ((*off >= VALIDATE_BUF_SIZE) || 
+		(args_buf->status == VALIDATE_AUTH)) {
+		*off += count;
+		return count;
+	}
+
+	if (*off + count >= VALIDATE_BUF_SIZE)  {
+		count = VALIDATE_BUF_SIZE - *off;
+		args_buf->status = VALIDATE_READY;	
+	} else {
+		args_buf->status = VALIDATE_INCOMPLETE;
+	}
+
+	if (verify_area(VERIFY_READ, buf, count)) {
+		rc = -EFAULT;
+		goto done;
+	}
+	if (copy_from_user(args_buf->buf + *off, buf, count)) {
+		rc = -EFAULT;
+		goto done;
+	}
+
+	*off += count;
+	rc = count;
+done:
+	if (rc < 0) {
+		kfree(dp->data);
+		dp->data = NULL;
+	}
+	return rc;
+}
+
+static int validate_flash_release(struct inode *inode, struct file *file)
+{
+	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
+	struct rtas_validate_flash_t *args_buf;
+
+	args_buf = (struct rtas_validate_flash_t *) dp->data;
+
+	if (args_buf->status == VALIDATE_READY) {
+		args_buf->buf_size = VALIDATE_BUF_SIZE;
+		validate_flash(args_buf);
+	}
+
+	atomic_dec(&dp->count);
+
+	return 0;
+}
+
+static inline void remove_flash_pde(struct proc_dir_entry *dp)
+{
+	if (dp) {
+		if (dp->data != NULL)
+			kfree(dp->data);
+		remove_proc_entry(dp->name, proc_ppc64.rtas);
+	}
+}
+
+static inline int initialize_flash_pde_data(const char *rtas_call_name, 
+		                            size_t buf_size,
+					    struct proc_dir_entry *dp)
+{
+	int *status;
+	int token;
+
+	dp->data = kmalloc(buf_size, GFP_KERNEL);
+	if (dp->data == NULL) {
+		remove_flash_pde(dp);
+		return -ENOMEM;
+	}
+
+	memset(dp->data, 0, buf_size);
+
+	/* This code assumes that the status int is the first member of the
+	 * struct 
+	 */
+	status = (int *) dp->data;
+	token = rtas_token(rtas_call_name);
+	if (token == RTAS_UNKNOWN_SERVICE)
+		*status = FLASH_AUTH;
+	else
+		*status = FLASH_NO_OP;
+
+	return 0;
+}
+
+static inline struct proc_dir_entry * create_flash_pde(const char *filename, 
+					struct file_operations *fops)
+{
+	struct proc_dir_entry *ent = NULL;
+
+	ent = create_proc_entry(filename, S_IRUSR | S_IWUSR, proc_ppc64.rtas);
+	if (ent != NULL) {
+		ent->nlink = 1;
+		ent->proc_fops = fops;
+		ent->owner = THIS_MODULE;
+	}
+
+	return ent;
 }
 
 static struct file_operations rtas_flash_operations = {
 	.read		= rtas_flash_read,
 	.write		= rtas_flash_write,
-	.open		= rtas_flash_open,
+	.open		= rtas_excl_open,
 	.release	= rtas_flash_release,
 };
 
+static struct file_operations manage_flash_operations = {
+	.read		= manage_flash_read,
+	.write		= manage_flash_write,
+	.open		= rtas_excl_open,
+	.release	= rtas_excl_release,
+};
+
+static struct file_operations validate_flash_operations = {
+	.read		= validate_flash_read,
+	.write		= validate_flash_write,
+	.open		= rtas_excl_open,
+	.release	= validate_flash_release,
+};
 
 int __init rtas_flash_init(void)
 {
-	struct proc_dir_entry *ent = NULL;
+	int rc;
 
 	if (!proc_ppc64.rtas) {
 		printk(KERN_WARNING "rtas proc dir does not already exist");
 		return -ENOENT;
 	}
 
-	if (rtas_token("ibm,update-flash-64-and-reboot") != RTAS_UNKNOWN_SERVICE)
-		flash_possible = 1;
-
-	if ((ent = create_proc_entry(FIRMWARE_FLASH_NAME, S_IRUSR | S_IWUSR, proc_ppc64.rtas)) != NULL) {
-		ent->nlink = 1;
-		ent->proc_fops = &rtas_flash_operations;
-		ent->owner = THIS_MODULE;
-	}
+	firmware_flash_pde = create_flash_pde(FIRMWARE_FLASH_NAME, 
+					      &rtas_flash_operations);
+	rc = initialize_flash_pde_data("ibm,update-flash-64-and-reboot",
+			 	       sizeof(struct rtas_update_flash_t), 
+				       firmware_flash_pde);
+	if (rc != 0)
+		return rc;
+	
+	firmware_update_pde = create_flash_pde(FIRMWARE_UPDATE_NAME, 
+					       &rtas_flash_operations);
+	rc = initialize_flash_pde_data("ibm,update-flash-64-and-reboot",
+			 	       sizeof(struct rtas_update_flash_t), 
+				       firmware_update_pde);
+	if (rc != 0)
+		return rc;
+	
+	validate_pde = create_flash_pde(VALIDATE_FLASH_NAME, 
+			      		&validate_flash_operations);
+	rc = initialize_flash_pde_data("ibm,validate-flash-image",
+		                       sizeof(struct rtas_validate_flash_t), 
+				       validate_pde);
+	if (rc != 0)
+		return rc;
+	
+	manage_pde = create_flash_pde(MANAGE_FLASH_NAME, 
+				      &manage_flash_operations);
+	rc = initialize_flash_pde_data("ibm,manage-flash-image",
+			               sizeof(struct rtas_manage_flash_t),
+				       manage_pde);
+	if (rc != 0)
+		return rc;
+	
 	return 0;
 }
 
@@ -230,7 +685,10 @@ void __exit rtas_flash_cleanup(void)
 {
 	if (!proc_ppc64.rtas)
 		return;
-	remove_proc_entry(FIRMWARE_FLASH_NAME, proc_ppc64.rtas);
+	remove_flash_pde(firmware_flash_pde);
+	remove_flash_pde(firmware_update_pde);
+	remove_flash_pde(validate_pde);
+	remove_flash_pde(manage_pde);
 }
 
 module_init(rtas_flash_init);
diff -purN linux-2.5/arch/ppc64/kernel/rtasd.c linuxppc64-2.5/arch/ppc64/kernel/rtasd.c
--- linux-2.5/arch/ppc64/kernel/rtasd.c	2003-08-19 02:46:23.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/rtasd.c	2003-11-21 04:51:10.000000000 +0000
@@ -17,11 +17,15 @@
 #include <linux/proc_fs.h>
 #include <linux/init.h>
 #include <linux/vmalloc.h>
+#include <linux/spinlock.h>
 
 #include <asm/uaccess.h>
 #include <asm/io.h>
 #include <asm/rtas.h>
 #include <asm/prom.h>
+#include <asm/nvram.h>
+#include <asm/atomic.h>
+#include <asm/proc_fs.h>
 
 #if 0
 #define DEBUG(A...)	printk(KERN_ERR A)
@@ -29,13 +33,10 @@
 #define DEBUG(A...)
 #endif
 
-static spinlock_t rtas_log_lock = SPIN_LOCK_UNLOCKED;
+static spinlock_t log_lock = SPIN_LOCK_UNLOCKED;
 
 DECLARE_WAIT_QUEUE_HEAD(rtas_log_wait);
 
-#define LOG_NUMBER		64		/* must be a power of two */
-#define LOG_NUMBER_MASK		(LOG_NUMBER-1)
-
 static char *rtas_log_buf;
 static unsigned long rtas_log_start;
 static unsigned long rtas_log_size;
@@ -43,22 +44,173 @@ static unsigned long rtas_log_size;
 static int surveillance_requested;
 static unsigned int rtas_event_scan_rate;
 static unsigned int rtas_error_log_max;
+static unsigned int rtas_error_log_buffer_max;
 
-#define EVENT_SCAN_ALL_EVENTS	0xf0000000
-#define SURVEILLANCE_TOKEN	9000
-#define SURVEILLANCE_TIMEOUT	1
-#define SURVEILLANCE_SCANRATE	1
+extern spinlock_t proc_ppc64_lock;
+extern volatile int no_more_logging;
 
-struct proc_dir_entry *proc_rtas;
+volatile int error_log_cnt = 0;
 
 /*
  * Since we use 32 bit RTAS, the physical address of this must be below
  * 4G or else bad things happen. Allocate this in the kernel data and
  * make it big enough.
  */
-#define RTAS_ERROR_LOG_MAX 1024
 static unsigned char logdata[RTAS_ERROR_LOG_MAX];
 
+/* To see this info, grep RTAS /var/log/messages and each entry
+ * will be collected together with obvious begin/end.
+ * There will be a unique identifier on the begin and end lines.
+ * This will persist across reboots.
+ *
+ * format of error logs returned from RTAS:
+ * bytes	(size)	: contents
+ * --------------------------------------------------------
+ * 0-7		(8)	: rtas_error_log
+ * 8-47		(40)	: extended info
+ * 48-51	(4)	: vendor id
+ * 52-1023 (vendor specific) : location code and debug data
+ */
+static void printk_log_rtas(char *buf, int len)
+{
+
+	int i,j,n;
+	int perline = 16;
+	char buffer[64];
+	char * str = "RTAS event";
+
+	printk(RTAS_ERR "%d -------- %s begin --------\n", error_log_cnt, str);
+
+	/*
+	 * Print perline bytes on each line, each line will start
+	 * with RTAS and a changing number, so syslogd will
+	 * print lines that are otherwise the same.  Separate every
+	 * 4 bytes with a space.
+	 */
+	for (i=0; i < len; i++) {
+		j = i % perline;
+		if (j == 0) {
+			memset(buffer, 0, sizeof(buffer));
+			n = sprintf(buffer, "RTAS %d:", i/perline);
+		}
+
+		if ((i % 4) == 0)
+			n += sprintf(buffer+n, " ");
+
+		n += sprintf(buffer+n, "%02x", (unsigned char)buf[i]);
+
+		if (j == (perline-1))
+			printk(KERN_ERR "%s\n", buffer);
+	}
+	if ((i % perline) != 0)
+		printk(KERN_ERR "%s\n", buffer);
+
+	printk(RTAS_ERR "%d -------- %s end ----------\n", error_log_cnt, str);
+}
+
+static int log_rtas_len(char * buf)
+{
+	int len;
+	struct rtas_error_log *err;
+
+	/* rtas fixed header */
+	len = 8;
+	err = (struct rtas_error_log *)buf;
+	if (err->extended_log_length) {
+
+		/* extended header */
+		len += err->extended_log_length;
+
+		if (len > RTAS_ERROR_LOG_MAX)
+			len = RTAS_ERROR_LOG_MAX;
+	}
+	return len;
+}
+
+/*
+ * First write to nvram, if fatal error, that is the only
+ * place we log the info.  The error will be picked up
+ * on the next reboot by rtasd.  If not fatal, run the
+ * method for the type of error.  Currently, only RTAS
+ * errors have methods implemented, but in the future
+ * there might be a need to store data in nvram before a
+ * call to panic().
+ *
+ * XXX We write to nvram periodically, to indicate error has
+ * been written and sync'd, but there is a possibility
+ * that if we don't shutdown correctly, a duplicate error
+ * record will be created on next reboot.
+ */
+void pSeries_log_error(char *buf, unsigned int err_type, int fatal)
+{
+	unsigned long offset;
+	unsigned long s;
+	int len = 0;
+
+	DEBUG("logging event\n");
+
+	if (buf == NULL)
+		return;
+
+	spin_lock_irqsave(&log_lock, s);
+
+	/* get length and increase count */
+	switch (err_type & ERR_TYPE_MASK) {
+	case ERR_TYPE_RTAS_LOG:
+		len = log_rtas_len(buf);
+		if (!(err_type & ERR_FLAG_BOOT))
+			error_log_cnt++;
+		break;
+	case ERR_TYPE_KERNEL_PANIC:
+	default:
+		spin_unlock_irqrestore(&log_lock, s);
+		return;
+	}
+
+	/* Write error to NVRAM */
+	if (!no_more_logging && !(err_type & ERR_FLAG_BOOT))
+		nvram_write_error_log(buf, len, err_type);
+
+	/* Check to see if we need to or have stopped logging */
+	if (fatal || no_more_logging) {
+		no_more_logging = 1;
+		spin_unlock_irqrestore(&log_lock, s);
+		return;
+	}
+
+	/* call type specific method for error */
+	switch (err_type & ERR_TYPE_MASK) {
+	case ERR_TYPE_RTAS_LOG:
+		/* put into syslog and error_log file */
+		printk_log_rtas(buf, len);
+
+		offset = rtas_error_log_buffer_max *
+			((rtas_log_start+rtas_log_size) & LOG_NUMBER_MASK);
+
+		/* First copy over sequence number */
+		memcpy(&rtas_log_buf[offset], (void *) &error_log_cnt, sizeof(int));
+
+		/* Second copy over error log data */
+		offset += sizeof(int);
+		memcpy(&rtas_log_buf[offset], buf, len);
+
+		if (rtas_log_size < LOG_NUMBER)
+			rtas_log_size += 1;
+		else
+			rtas_log_start += 1;
+
+		spin_unlock_irqrestore(&log_lock, s);
+		wake_up_interruptible(&rtas_log_wait);
+		break;
+	case ERR_TYPE_KERNEL_PANIC:
+	default:
+		spin_unlock_irqrestore(&log_lock, s);
+		return;
+	}
+
+}
+
+
 static int rtas_log_open(struct inode * inode, struct file * file)
 {
 	return 0;
@@ -69,36 +221,50 @@ static int rtas_log_release(struct inode
 	return 0;
 }
 
+/* This will check if all events are logged, if they are then, we
+ * know that we can safely clear the events in NVRAM.
+ * Next we'll sit and wait for something else to log.
+ */
 static ssize_t rtas_log_read(struct file * file, char * buf,
 			 size_t count, loff_t *ppos)
 {
 	int error;
 	char *tmp;
+	unsigned long s;
 	unsigned long offset;
 
-	if (!buf || count < rtas_error_log_max)
+	if (!buf || count < rtas_error_log_buffer_max)
 		return -EINVAL;
 
-	count = rtas_error_log_max;
+	count = rtas_error_log_buffer_max;
 
 	error = verify_area(VERIFY_WRITE, buf, count);
 	if (error)
-		return -EINVAL;
+		return -EFAULT;
 
-	tmp = kmalloc(rtas_error_log_max, GFP_KERNEL);
+	tmp = kmalloc(count, GFP_KERNEL);
 	if (!tmp)
 		return -ENOMEM;
 
+
+	spin_lock_irqsave(&log_lock, s);
+	/* if it's 0, then we know we got the last one (the one in NVRAM) */
+	if (rtas_log_size == 0 && !no_more_logging)
+		nvram_clear_error_log();
+	spin_unlock_irqrestore(&log_lock, s);
+
+
 	error = wait_event_interruptible(rtas_log_wait, rtas_log_size);
 	if (error)
 		goto out;
 
-	spin_lock(&rtas_log_lock);
-	offset = rtas_error_log_max * (rtas_log_start & LOG_NUMBER_MASK);
+	spin_lock_irqsave(&log_lock, s);
+	offset = rtas_error_log_buffer_max * (rtas_log_start & LOG_NUMBER_MASK);
 	memcpy(tmp, &rtas_log_buf[offset], count);
+
 	rtas_log_start += 1;
 	rtas_log_size -= 1;
-	spin_unlock(&rtas_log_lock);
+	spin_unlock_irqrestore(&log_lock, s);
 
 	error = copy_to_user(buf, tmp, count) ? -EFAULT : count;
 out:
@@ -121,28 +287,6 @@ struct file_operations proc_rtas_log_ope
 	.release =	rtas_log_release,
 };
 
-static void log_rtas(char *buf)
-{
-	unsigned long offset;
-
-	DEBUG("logging rtas event\n");
-
-	spin_lock(&rtas_log_lock);
-
-	offset = rtas_error_log_max *
-			((rtas_log_start+rtas_log_size) & LOG_NUMBER_MASK);
-
-	memcpy(&rtas_log_buf[offset], buf, rtas_error_log_max);
-
-	if (rtas_log_size < LOG_NUMBER)
-		rtas_log_size += 1;
-	else
-		rtas_log_start += 1;
-
-	spin_unlock(&rtas_log_lock);
-	wake_up_interruptible(&rtas_log_wait);
-}
-
 static int enable_surveillance(void)
 {
 	int error;
@@ -165,11 +309,12 @@ static int get_eventscan_parms(void)
 	struct device_node *node;
 	int *ip;
 
-	node = find_path_device("/rtas");
+	node = of_find_node_by_path("/rtas");
 
 	ip = (int *)get_property(node, "rtas-event-scan-rate", NULL);
 	if (ip == NULL) {
 		printk(KERN_ERR "rtasd: no rtas-event-scan-rate\n");
+		of_node_put(node);
 		return -1;
 	}
 	rtas_event_scan_rate = *ip;
@@ -178,6 +323,7 @@ static int get_eventscan_parms(void)
 	ip = (int *)get_property(node, "rtas-error-log-max", NULL);
 	if (ip == NULL) {
 		printk(KERN_ERR "rtasd: no rtas-error-log-max\n");
+		of_node_put(node);
 		return -1;
 	}
 	rtas_error_log_max = *ip;
@@ -187,6 +333,7 @@ static int get_eventscan_parms(void)
 		printk(KERN_ERR "rtasd: truncated error log from %d to %d bytes\n", rtas_error_log_max, RTAS_ERROR_LOG_MAX);
 		rtas_error_log_max = RTAS_ERROR_LOG_MAX;
 	}
+	of_node_put(node);
 
 	return 0;
 }
@@ -195,10 +342,12 @@ extern long sys_sched_get_priority_max(i
 
 static int rtasd(void *unused)
 {
+	unsigned int err_type;
 	int cpu = 0;
 	int error;
 	int first_pass = 1;
 	int event_scan = rtas_token("event-scan");
+	int rc;
 
 	if (event_scan == RTAS_UNKNOWN_SERVICE || get_eventscan_parms() == -1)
 		goto error;
@@ -209,6 +358,9 @@ static int rtasd(void *unused)
 		goto error;
 	}
 
+	/* We can use rtas_log_buf now */
+	no_more_logging = 0;
+
 	DEBUG("will sleep for %d jiffies\n", (HZ*60/rtas_event_scan_rate) / 2);
 
 	daemonize("rtasd");
@@ -219,6 +371,16 @@ static int rtasd(void *unused)
 	current->nice = sys_sched_get_priority_max(SCHED_FIFO) + 1;
 #endif
 
+	/* See if we have any error stored in NVRAM */
+	memset(logdata, 0, rtas_error_log_max);
+
+	rc = nvram_read_error_log(logdata, rtas_error_log_max, &err_type);
+	if (!rc) {
+		if (err_type != ERR_FLAG_ALREADY_LOGGED) {
+			pSeries_log_error(logdata, err_type | ERR_FLAG_BOOT, 0);
+		}
+	}
+
 repeat:
 	for (cpu = 0; cpu < NR_CPUS; cpu++) {
 		if (!cpu_online(cpu))
@@ -231,7 +393,7 @@ repeat:
 		do {
 			memset(logdata, 0, rtas_error_log_max);
 			error = rtas_call(event_scan, 4, 1, NULL,
-					EVENT_SCAN_ALL_EVENTS, 0,
+					RTAS_EVENT_SCAN_ALL_EVENTS, 0,
 					__pa(logdata), rtas_error_log_max);
 			if (error == -1) {
 				printk(KERN_ERR "event-scan failed\n");
@@ -239,7 +401,7 @@ repeat:
 			}
 
 			if (error == 0)
-				log_rtas(logdata);
+				pSeries_log_error(logdata, ERR_TYPE_RTAS_LOG, 0);
 
 		} while(error == 0);
 
@@ -273,25 +435,29 @@ static int __init rtas_init(void)
 {
 	struct proc_dir_entry *entry;
 
-	if (proc_rtas == NULL) {
-		proc_rtas = proc_mkdir("rtas", 0);
+	if (proc_ppc64.rtas == NULL) {
+		proc_ppc64_init();
 	}
 
-	if (proc_rtas == NULL) {
-		printk(KERN_ERR "Failed to create /proc/rtas in rtas_init\n");
-	} else {
-		entry = create_proc_entry("error_log", S_IRUSR, proc_rtas);
-		if (entry)
-			entry->proc_fops = &proc_rtas_log_operations;
-		else
-			printk(KERN_ERR "Failed to create rtas/error_log proc entry\n");
+	if (proc_ppc64.rtas == NULL) {
+		printk(KERN_ERR "rtas_init: /proc/ppc64/rtas does not exist.");
+		return -EIO;
 	}
 
+	entry = create_proc_entry("error_log", S_IRUSR, proc_ppc64.rtas);
+	if (entry)
+		entry->proc_fops = &proc_rtas_log_operations;
+	else
+		printk(KERN_ERR "Failed to create rtas/error_log proc entry\n");
+
 	if (kernel_thread(rtasd, 0, CLONE_FS) < 0)
 		printk(KERN_ERR "Failed to start RTAS daemon\n");
 
 	printk(KERN_ERR "RTAS daemon started\n");
 
+	/* Make room for the sequence number */
+	rtas_error_log_buffer_max = rtas_error_log_max + sizeof(int);
+
 	return 0;
 }
 
diff -purN linux-2.5/arch/ppc64/kernel/scanlog.c linuxppc64-2.5/arch/ppc64/kernel/scanlog.c
--- linux-2.5/arch/ppc64/kernel/scanlog.c	2003-08-31 23:14:08.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/scanlog.c	2003-11-21 04:51:10.000000000 +0000
@@ -28,6 +28,7 @@
 #include <asm/uaccess.h>
 #include <asm/rtas.h>
 #include <asm/prom.h>
+#include <asm/proc_fs.h>
 
 #define MODULE_VERSION "1.0"
 #define MODULE_NAME "scanlog"
@@ -43,9 +44,6 @@ static int scanlog_debug;
 static unsigned int ibm_scan_log_dump;			/* RTAS token */
 static struct proc_dir_entry *proc_ppc64_scan_log_dump;	/* The proc file */
 
-extern struct proc_dir_entry *proc_rtas;
-
-
 static ssize_t scanlog_read(struct file *file, char *buf,
 			    size_t count, loff_t *ppos)
 {
@@ -207,15 +205,16 @@ int __init scanlog_init(void)
 		return -EIO;
 	}
 
-	if (proc_rtas == NULL)
-                proc_rtas = proc_mkdir("rtas", 0);
+	if (proc_ppc64.rtas == NULL) {
+		proc_ppc64_init();
+	}
 
-	if (proc_rtas == NULL) {
+	if (proc_ppc64.rtas == NULL) {
 		printk(KERN_ERR "Failed to create /proc/rtas in scanlog_init\n");
 		return -EIO;
 	}
 
-        ent = create_proc_entry("scan-log-dump",  S_IRUSR, proc_rtas);
+        ent = create_proc_entry("scan-log-dump",  S_IRUSR, proc_ppc64.rtas);
 	if (ent) {
 		ent->proc_fops = &scanlog_fops;
 		/* Ideally we could allocate a buffer < 4G */
diff -purN linux-2.5/arch/ppc64/kernel/setup.c linuxppc64-2.5/arch/ppc64/kernel/setup.c
--- linux-2.5/arch/ppc64/kernel/setup.c	2003-10-08 02:53:40.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/setup.c	2003-11-21 06:45:02.000000000 +0000
@@ -38,6 +38,7 @@
 #include <asm/paca.h>
 #include <asm/ppcdebug.h>
 #include <asm/time.h>
+#include <asm/cputable.h>
 #include <asm/sections.h>
 
 extern unsigned long klimit;
@@ -58,6 +59,9 @@ extern void iSeries_init_early( void );
 extern void pSeries_init_early( void );
 extern void pSeriesLP_init_early(void);
 extern void mm_init_ppc64( void ); 
+extern void pseries_secondary_smp_init(unsigned long); 
+extern int  idle_setup(void);
+extern void vpa_init(int cpu);
 
 unsigned long decr_overclock = 1;
 unsigned long decr_overclock_proc0 = 1;
@@ -137,12 +141,14 @@ void __init disable_early_printk(void)
 }
 
 /*
- * Do some initial setup of the system.  The paramters are those which 
+ * Do some initial setup of the system.  The parameters are those which 
  * were passed in from the bootloader.
  */
 void setup_system(unsigned long r3, unsigned long r4, unsigned long r5,
 		  unsigned long r6, unsigned long r7)
 {
+        unsigned int ret, i;
+
 #ifdef CONFIG_XMON_DEFAULT
 	debugger = xmon;
 	debugger_bpt = xmon_bpt;
@@ -183,10 +189,29 @@ void setup_system(unsigned long r3, unsi
 #endif
 	}
 
+#ifdef CONFIG_PPC_PSERIES
 	if (systemcfg->platform & PLATFORM_PSERIES) {
 		early_console_initialized = 1;
 		register_console(&udbg_console);
+		finish_device_tree();
+		chrp_init(r3, r4, r5, r6, r7);
+
+#ifdef CONFIG_SMP
+		/* Start secondary threads on SMT systems */
+		for (i = 0; i < NR_CPUS; i++) {
+			if(cpu_available(i)  && !cpu_possible(i)) {
+				printk("%16.16x : starting thread\n", i);
+				rtas_call(rtas_token("start-cpu"), 3, 1, 
+					  (void *)&ret,
+					  get_hard_smp_processor_id(i), 
+					  *((unsigned long *)pseries_secondary_smp_init), i);
+				cpu_set(i, cpu_possible_map);
+				systemcfg->processorCount++;
+			}
+		}
+#endif
 	}
+#endif
 
 	printk("Starting Linux PPC64 %s\n", UTS_RELEASE);
 
@@ -204,12 +229,16 @@ void setup_system(unsigned long r3, unsi
 	printk("htab_data.num_ptegs           = 0x%lx\n", htab_data.htab_num_ptegs);
 	printk("-----------------------------------------------------\n");
 
-	if (systemcfg->platform & PLATFORM_PSERIES) {
-		finish_device_tree();
-		chrp_init(r3, r4, r5, r6, r7);
+	mm_init_ppc64();
+
+#if defined(CONFIG_SMP) && defined(CONFIG_PPC_PSERIES)
+	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
+		vpa_init(boot_cpuid);
 	}
+#endif
 
-	mm_init_ppc64();
+	/* Select the correct idle loop for the platform. */
+	idle_setup();
 
 	switch (systemcfg->platform) {
 #ifdef CONFIG_PPC_ISERIES
@@ -277,36 +306,14 @@ static int show_cpuinfo(struct seq_file 
 	seq_printf(m, "processor\t: %lu\n", cpu_id);
 	seq_printf(m, "cpu\t\t: ");
 
-	switch (PVR_VER(pvr)) {
-	case PV_NORTHSTAR:
-		seq_printf(m, "RS64-II (northstar)\n");
-		break;
-	case PV_PULSAR:
-		seq_printf(m, "RS64-III (pulsar)\n");
-		break;
-	case PV_POWER4:
-		seq_printf(m, "POWER4 (gp)\n");
-		break;
-	case PV_ICESTAR:
-		seq_printf(m, "RS64-III (icestar)\n");
-		break;
-	case PV_SSTAR:
-		seq_printf(m, "RS64-IV (sstar)\n");
-		break;
-	case PV_POWER4p:
-		seq_printf(m, "POWER4+ (gq)\n");
-		break;
-	case PV_630:
-		seq_printf(m, "POWER3 (630)\n");
-		break;
-	case PV_630p:
-		seq_printf(m, "POWER3 (630+)\n");
-		break;
-	default:
-		seq_printf(m, "Unknown (%08x)\n", pvr);
-		break;
-	}
+	if (cur_cpu_spec->pvr_mask)
+		seq_printf(m, "%s", cur_cpu_spec->cpu_name);
+	else
+		seq_printf(m, "unknown (%08x)", pvr);
+
+	seq_printf(m, "\n");
 
+#ifdef CONFIG_PPC_PSERIES
 	/*
 	 * Assume here that all clock rates are the same in a
 	 * smp system.  -- Cort
@@ -315,15 +322,17 @@ static int show_cpuinfo(struct seq_file 
 		struct device_node *cpu_node;
 		int *fp;
 
-		cpu_node = find_type_devices("cpu");
+		cpu_node = of_find_node_by_type(NULL, "cpu");
 		if (cpu_node) {
 			fp = (int *) get_property(cpu_node, "clock-frequency",
 						  NULL);
 			if (fp)
 				seq_printf(m, "clock\t\t: %dMHz\n",
 					   *fp / 1000000);
+			of_node_put(cpu_node);
 		}
 	}
+#endif
 
 	if (ppc_md.setup_residual != NULL)
 		ppc_md.setup_residual(m, cpu_id);
@@ -353,13 +362,11 @@ struct seq_operations cpuinfo_op = {
 };
 
 /*
- * Fetch the cmd_line from open firmware. */
+ * Fetch the cmd_line from open firmware. 
+ */
 void parse_cmd_line(unsigned long r3, unsigned long r4, unsigned long r5,
 		  unsigned long r6, unsigned long r7)
 {
-	struct device_node *chosen;
-	char *p;
-
 #ifdef CONFIG_BLK_DEV_INITRD
 	if ((initrd_start == 0) && r3 && r4 && r4 != 0xdeadbeef) {
 		initrd_start = (r3 >= KERNELBASE) ? r3 : (unsigned long)__va(r3);
@@ -375,12 +382,20 @@ void parse_cmd_line(unsigned long r3, un
 	strlcpy(cmd_line, CONFIG_CMDLINE, sizeof(cmd_line));
 #endif /* CONFIG_CMDLINE */
 
-	chosen = find_devices("chosen");
+#ifdef CONFIG_PPC_PSERIES
+	{
+	struct device_node *chosen;
+
+	chosen = of_find_node_by_name(NULL, "chosen");
 	if (chosen != NULL) {
+		char *p;
 		p = get_property(chosen, "bootargs", NULL);
 		if (p != NULL && p[0] != 0)
 			strlcpy(cmd_line, p, sizeof(cmd_line));
+		of_node_put(chosen);
+	}
 	}
+#endif
 
 	/* Look for mem= option on command line */
 	if (strstr(cmd_line, "mem=")) {
@@ -406,28 +421,7 @@ void parse_cmd_line(unsigned long r3, un
 }
 
 
-char *bi_tag2str(unsigned long tag)
-{
-	switch (tag) {
-	case BI_FIRST:
-		return "BI_FIRST";
-	case BI_LAST:
-		return "BI_LAST";
-	case BI_CMD_LINE:
-		return "BI_CMD_LINE";
-	case BI_BOOTLOADER_ID:
-		return "BI_BOOTLOADER_ID";
-	case BI_INITRD:
-		return "BI_INITRD";
-	case BI_SYSMAP:
-		return "BI_SYSMAP";
-	case BI_MACHTYPE:
-		return "BI_MACHTYPE";
-	default:
-		return "BI_UNKNOWN";
-	}
-}
-
+#ifdef CONFIG_PPC_PSERIES
 int parse_bootinfo(void)
 {
 	struct bi_record *rec;
@@ -445,8 +439,7 @@ int parse_bootinfo(void)
 			memcpy(cmd_line, (void *)rec->data, rec->size);
 			break;
 		case BI_SYSMAP:
-			sysmap = (char *)((rec->data[0] >= (KERNELBASE))
-					? rec->data[0] : (unsigned long)__va(rec->data[0]));
+			sysmap = __va(rec->data[0]);
 			sysmap_size = rec->data[1];
 			break;
 #ifdef CONFIG_BLK_DEV_INITRD
@@ -462,6 +455,7 @@ int parse_bootinfo(void)
 
 	return 0;
 }
+#endif
 
 int __init ppc_init(void)
 {
diff -purN linux-2.5/arch/ppc64/kernel/signal.c linuxppc64-2.5/arch/ppc64/kernel/signal.c
--- linux-2.5/arch/ppc64/kernel/signal.c	2003-11-16 21:52:15.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/signal.c	2003-11-19 20:14:41.000000000 +0000
@@ -95,7 +95,7 @@ long sys_rt_sigsuspend(sigset_t *unewset
 	regs->gpr[3] = EINTR;
 	regs->ccr |= 0x10000000;
 	while (1) {
-		current->state = TASK_INTERRUPTIBLE;
+		set_current_state(TASK_INTERRUPTIBLE);
 		schedule();
 		if (do_signal(&saveset, regs))
 			return regs->gpr[3];
diff -purN linux-2.5/arch/ppc64/kernel/signal32.c linuxppc64-2.5/arch/ppc64/kernel/signal32.c
--- linux-2.5/arch/ppc64/kernel/signal32.c	2003-11-16 21:54:29.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/signal32.c	2003-11-21 05:10:26.000000000 +0000
@@ -93,7 +93,7 @@ struct rt_sigframe_32 {
 	 * it is a pointer to the user context in the rt stack frame
 	 */
 	u32 puc;
-	struct siginfo32  info;
+	struct compat_siginfo  info;
 	struct ucontext32 uc;
 };
 
@@ -133,7 +133,7 @@ long sys32_sigsuspend(old_sigset_t mask,
 	regs->gpr[3] = EINTR;
 	regs->ccr |= 0x10000000;
 	while (1) {
-		current->state = TASK_INTERRUPTIBLE;
+		set_current_state(TASK_INTERRUPTIBLE);
 		schedule();
 		if (do_signal32(&saveset, regs))
 			/*
@@ -639,7 +639,7 @@ long sys32_rt_sigpending(compat_sigset_t
 }
 
 
-static int copy_siginfo_to_user32(siginfo_t32 *d, siginfo_t *s)
+static int copy_siginfo_to_user32(compat_siginfo_t *d, siginfo_t *s)
 {
 	int err;
 
@@ -681,7 +681,7 @@ static int copy_siginfo_to_user32(siginf
 	return err;
 }
 
-long sys32_rt_sigtimedwait(compat_sigset_t *uthese, siginfo_t32 *uinfo,
+long sys32_rt_sigtimedwait(compat_sigset_t *uthese, compat_siginfo_t *uinfo,
 		struct compat_timespec *uts, compat_size_t sigsetsize)
 {
 	sigset_t s;
@@ -714,7 +714,7 @@ long sys32_rt_sigtimedwait(compat_sigset
 
 
 
-static siginfo_t * siginfo32to64(siginfo_t *d, siginfo_t32 *s)
+static siginfo_t * siginfo32to64(siginfo_t *d, compat_siginfo_t *s)
 {
 	d->si_signo = s->si_signo;
 	d->si_errno = s->si_errno;
@@ -758,14 +758,14 @@ static siginfo_t * siginfo32to64(siginfo
  * (msr in 32-bit mode) and the register representation of a signed int
  * (msr in 64-bit mode) is performed.
  */
-long sys32_rt_sigqueueinfo(u32 pid, u32 sig, siginfo_t32 *uinfo)
+long sys32_rt_sigqueueinfo(u32 pid, u32 sig, compat_siginfo_t *uinfo)
 {
 	siginfo_t info;
-	siginfo_t32 info32;
+	compat_siginfo_t info32;
 	int ret;
 	mm_segment_t old_fs = get_fs();
 	
-	if (copy_from_user (&info32, uinfo, sizeof(siginfo_t32)))
+	if (copy_from_user (&info32, uinfo, sizeof(compat_siginfo_t)))
 		return -EFAULT;
     	/* XXX: Is this correct? */
 	siginfo32to64(&info, &info32);
@@ -812,7 +812,7 @@ int sys32_rt_sigsuspend(compat_sigset_t*
 	regs->gpr[3] = EINTR;
 	regs->ccr |= 0x10000000;
 	while (1) {
-		current->state = TASK_INTERRUPTIBLE;
+		set_current_state(TASK_INTERRUPTIBLE);
 		schedule();
 		if (do_signal32(&saveset, regs))
 			/*
diff -purN linux-2.5/arch/ppc64/kernel/smp.c linuxppc64-2.5/arch/ppc64/kernel/smp.c
--- linux-2.5/arch/ppc64/kernel/smp.c	2003-10-08 02:53:40.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/smp.c	2003-11-21 06:45:02.000000000 +0000
@@ -50,13 +50,21 @@
 #include <asm/xics.h>
 #include <asm/cputable.h>
 
+#ifdef CONFIG_KDB
+#include <linux/kdb.h>
+#endif
+
 int smp_threads_ready;
 unsigned long cache_decay_ticks;
 
-/* initialised so it doesn't end up in bss */
+/* Initialised so it doesn't end up in bss */
+cpumask_t cpu_possible_map    = CPU_MASK_NONE;
 cpumask_t cpu_online_map = CPU_MASK_NONE;
+cpumask_t cpu_available_map   = CPU_MASK_NONE;
+cpumask_t cpu_present_at_boot = CPU_MASK_NONE;
 
 EXPORT_SYMBOL(cpu_online_map);
+EXPORT_SYMBOL(cpu_possible_map);
 
 static struct smp_ops_t *smp_ops;
 
@@ -67,6 +75,8 @@ extern unsigned char stab_array[];
 extern int cpu_idle(void *unused);
 void smp_call_function_interrupt(void);
 void smp_message_pass(int target, int msg, unsigned long data, int wait);
+extern long register_vpa(unsigned long flags, unsigned long proc,
+			 unsigned long vpa);
 
 #define smp_message_pass(t,m,d,w) smp_ops->message_pass((t),(m),(d),(w))
 
@@ -77,6 +87,24 @@ static inline void set_tb(unsigned int u
 	mttbl(lower);
 }
 
+#ifdef CONFIG_KDB
+	/* save regs here before calling kdb_ipi */
+struct pt_regs *kdb_smp_regs[NR_CPUS];
+	
+/* called for each processor.. drop each into kdb. */
+static void smp_kdb_stop_proc(void *dummy)
+{
+    kdb_ipi(kdb_smp_regs[smp_processor_id()], NULL);
+}
+	
+void smp_kdb_stop(void)
+{
+    int ret=0;
+    ret = smp_call_function(smp_kdb_stop_proc, NULL, 1, 0);
+}
+#endif
+
+
 #ifdef CONFIG_PPC_ISERIES
 static unsigned long iSeries_smp_message[NR_CPUS];
 
@@ -135,7 +163,7 @@ static int smp_iSeries_probe(void)
 	for (i=0; i < NR_CPUS; ++i) {
 		lpPaca = paca[i].xLpPacaPtr;
 		if (lpPaca->xDynProcStatus < 2) {
-			paca[i].active = 1;
+			/*paca[i].active = 1;*/
 			++np;
 		}
 	}
@@ -181,7 +209,6 @@ void __init smp_init_iSeries(void)
 	smp_ops->probe        = smp_iSeries_probe;
 	smp_ops->kick_cpu     = smp_iSeries_kick_cpu;
 	smp_ops->setup_cpu    = smp_iSeries_setup_cpu;
-#warning fix for iseries
 	systemcfg->processorCount	= smp_iSeries_numProcs();
 }
 #endif
@@ -266,6 +293,17 @@ static void __init smp_space_timers(unsi
 }
 
 #ifdef CONFIG_PPC_PSERIES
+void vpa_init(int cpu)
+{
+	unsigned long flags;
+
+	/* Register the Virtual Processor Area (VPA) */
+	printk(KERN_INFO "register_vpa: cpu 0x%x\n", cpu);
+	flags = 1UL << (63 - 18);
+	paca[cpu].xLpPaca.xSLBCount = 64; /* SLB restore highwater mark */
+	register_vpa(flags, cpu, __pa((unsigned long)&(paca[cpu].xLpPaca))); 
+}
+
 static void __devinit pSeries_setup_cpu(int cpu)
 {
 	if (OpenPIC_Addr) {
@@ -295,6 +333,8 @@ smp_xics_message_pass(int target, int ms
 	}
 }
 
+extern void xics_request_IPIs(void);
+
 static int __init smp_xics_probe(void)
 {
 	int i;
@@ -305,7 +345,6 @@ static int __init smp_xics_probe(void)
 			nr_cpus++;
 	}
 #ifdef CONFIG_SMP
-	extern void xics_request_IPIs(void);
 	xics_request_IPIs();
 #endif
 
@@ -372,6 +411,9 @@ void smp_message_recv(int msg, struct pt
 {
 	switch( msg ) {
 	case PPC_MSG_CALL_FUNCTION:
+#ifdef CONFIG_KDB
+	        kdb_smp_regs[smp_processor_id()]=regs;
+#endif
 		smp_call_function_interrupt();
 		break;
 	case PPC_MSG_RESCHEDULE: 
@@ -480,13 +522,13 @@ int smp_call_function (void (*func) (voi
 	while (atomic_read(&data.started) != cpus) {
 		HMT_low();
 		if (--timeout == 0) {
+			printk("smp_call_function on cpu %d: other cpus not "
+			       "responding (%d)\n", smp_processor_id(),
+			       atomic_read(&data.started));
 #ifdef CONFIG_DEBUG_KERNEL
 			if (debugger)
 				debugger(0);
 #endif
-			printk("smp_call_function on cpu %d: other cpus not "
-			       "responding (%d)\n", smp_processor_id(),
-			       atomic_read(&data.started));
 			goto out;
 		}
 	}
@@ -496,15 +538,15 @@ int smp_call_function (void (*func) (voi
 		while (atomic_read(&data.finished) != cpus) {
 			HMT_low();
 			if (--timeout == 0) {
-#ifdef CONFIG_DEBUG_KERNEL
-				if (debugger)
-					debugger(0);
-#endif
 				printk("smp_call_function on cpu %d: other "
 				       "cpus not finishing (%d/%d)\n",
 				       smp_processor_id(),
 				       atomic_read(&data.finished),
 				       atomic_read(&data.started));
+#ifdef CONFIG_DEBUG_KERNEL
+				if (debugger)
+					debugger(0);
+#endif
 				goto out;
 			}
 		}
@@ -513,6 +555,7 @@ int smp_call_function (void (*func) (voi
 	ret = 0;
 
 out:
+	call_data = NULL;
 	HMT_medium();
 	spin_unlock(&call_lock);
 	return ret;
@@ -520,9 +563,19 @@ out:
 
 void smp_call_function_interrupt(void)
 {
-	void (*func) (void *info) = call_data->func;
-	void *info = call_data->info;
-	int wait = call_data->wait;
+	void (*func) (void *info);
+	void *info;
+	int wait;
+
+	/* call_data will be NULL if the sender timed out while
+	 * waiting on us to receive the call.
+	 */
+	if (!call_data)
+		return;
+
+	func = call_data->func;
+	info = call_data->info;
+	wait = call_data->wait;
 
 	/*
 	 * Notify initiating CPU that I've grabbed the data and am
@@ -658,6 +711,14 @@ int __devinit start_secondary(void *unus
 	if (smp_ops->take_timebase)
 		smp_ops->take_timebase();
 
+	get_paca()->yielded = 0;
+
+#ifdef CONFIG_PPC_PSERIES
+	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
+		vpa_init(cpu); 
+	}
+#endif
+
 	local_irq_enable();
 
 	return cpu_idle(NULL);
diff -purN linux-2.5/arch/ppc64/kernel/stab.c linuxppc64-2.5/arch/ppc64/kernel/stab.c
--- linux-2.5/arch/ppc64/kernel/stab.c	2003-09-07 01:24:09.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/stab.c	2003-09-12 11:01:40.000000000 +0000
@@ -23,6 +23,7 @@
 #include <asm/pmc.h>
 #include <asm/cputable.h>
 
+
 int make_ste(unsigned long stab, unsigned long esid, unsigned long vsid);
 void make_slbe(unsigned long esid, unsigned long vsid, int large,
 	       int kernel_segment);
diff -purN linux-2.5/arch/ppc64/kernel/sys_ppc32.c linuxppc64-2.5/arch/ppc64/kernel/sys_ppc32.c
--- linux-2.5/arch/ppc64/kernel/sys_ppc32.c	2003-10-16 13:54:39.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/sys_ppc32.c	2003-11-21 05:10:26.000000000 +0000
@@ -2878,3 +2878,46 @@ long ppc32_fadvise64(int fd, u32 unused,
 			     advice);
 }
 
+long ppc32_fadvise64_64(int fd, int advice, u32 offset_high, u32 offset_low,
+			u32 len_high, u32 len_low)
+{
+	return sys_fadvise64(fd, (u64)offset_high << 32 | offset_low,
+			     (u64)len_high << 32 | len_low, advice);
+}
+
+extern long sys_timer_create(clockid_t, sigevent_t *, timer_t *);
+
+long ppc32_timer_create(clockid_t clock,
+			struct compat_sigevent __user *ev32,
+			timer_t __user *timer_id)
+{
+	sigevent_t event;
+	timer_t t;
+	long err;
+	mm_segment_t savefs;
+
+	if (ev32 == NULL)
+		return sys_timer_create(clock, NULL, timer_id);
+
+	memset(&event, 0, sizeof(event));
+	if (!access_ok(VERIFY_READ, ev32, sizeof(struct compat_sigevent))
+	    || __get_user(event.sigev_value.sival_int,
+			  &ev32->sigev_value.sival_int)
+	    || __get_user(event.sigev_signo, &ev32->sigev_signo)
+	    || __get_user(event.sigev_notify, &ev32->sigev_notify)
+	    || __get_user(event.sigev_notify_thread_id,
+			  &ev32->sigev_notify_thread_id))
+		return -EFAULT;
+
+	if (!access_ok(VERIFY_WRITE, timer_id, sizeof(timer_t)))
+		return -EFAULT;
+
+	savefs = get_fs();
+	err = sys_timer_create(clock, &event, &t);
+	set_fs(savefs);
+
+	if (err == 0)
+		err = __put_user(t, timer_id);
+
+	return err;
+}
diff -purN linux-2.5/arch/ppc64/kernel/syscalls.c linuxppc64-2.5/arch/ppc64/kernel/syscalls.c
--- linux-2.5/arch/ppc64/kernel/syscalls.c	2003-09-02 04:37:31.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/syscalls.c	2003-11-17 18:51:47.000000000 +0000
@@ -41,6 +41,7 @@
 #include <asm/ipc.h>
 #include <asm/semaphore.h>
 #include <asm/time.h>
+#include <asm/unistd.h>
 
 extern unsigned long wall_jiffies;
 
@@ -234,3 +235,6 @@ asmlinkage time_t sys64_time(time_t* tlo
 
 	return secs;
 }
+
+/* Only exists on P-series. */
+cond_syscall(ppc_rtas);
diff -purN linux-2.5/arch/ppc64/kernel/time.c linuxppc64-2.5/arch/ppc64/kernel/time.c
--- linux-2.5/arch/ppc64/kernel/time.c	2003-10-08 02:53:40.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/time.c	2003-11-18 09:04:18.000000000 +0000
@@ -91,6 +91,9 @@ unsigned      tb_to_us;
 unsigned long processor_freq;
 spinlock_t rtc_lock = SPIN_LOCK_UNLOCKED;
 
+unsigned long tb_to_ns_scale;
+unsigned long tb_to_ns_shift;
+
 struct gettimeofday_struct do_gtod;
 
 extern unsigned long wall_jiffies;
@@ -312,12 +315,10 @@ int timer_interrupt(struct pt_regs * reg
 
 /*
  * Scheduler clock - returns current time in nanosec units.
- *
- * This is wrong, but my CPUs run at 1GHz, so nyer nyer.
  */
 unsigned long long sched_clock(void)
 {
-	return get_tb();
+	return mulhdu(get_tb(), tb_to_ns_scale) << tb_to_ns_shift;
 }
 
 /*
@@ -473,9 +474,22 @@ void __init time_init(void)
 	/* This function is only called on the boot processor */
 	unsigned long flags;
 	struct rtc_time tm;
+	struct div_result res;
+	unsigned long scale, shift;
 
 	ppc_md.calibrate_decr();
 
+	/* Compute scale factor for sched_clock. */
+	/* The calibrate_decr() function has set tb_ticks_per_sec */
+	div128_by_32(1000000000, 0, tb_ticks_per_sec, &res);
+	scale = res.result_low;
+	for (shift = 0; res.result_high != 0; ++shift) {
+		scale = (scale >> 1) | (res.result_high << 63);
+		res.result_high >>= 1;
+	}
+	tb_to_ns_scale = scale;
+	tb_to_ns_shift = shift;
+
 #ifdef CONFIG_PPC_ISERIES
 	if (!piranha_simulator)
 #endif
diff -purN linux-2.5/arch/ppc64/kernel/traps.c linuxppc64-2.5/arch/ppc64/kernel/traps.c
--- linux-2.5/arch/ppc64/kernel/traps.c	2003-07-28 04:00:17.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/traps.c	2003-11-21 06:45:02.000000000 +0000
@@ -16,6 +16,7 @@
  * This file handles the architecture-dependent parts of hardware exceptions
  */
 
+#include <linux/config.h>
 #include <linux/errno.h>
 #include <linux/sched.h>
 #include <linux/kernel.h>
@@ -26,7 +27,6 @@
 #include <linux/user.h>
 #include <linux/a.out.h>
 #include <linux/interrupt.h>
-#include <linux/config.h>
 #include <linux/init.h>
 #include <linux/module.h>
 
@@ -40,8 +40,10 @@
 extern int fix_alignment(struct pt_regs *);
 extern void bad_page_fault(struct pt_regs *, unsigned long, int);
 
+#ifdef CONFIG_PPC_PSERIES
 /* This is true if we are using the firmware NMI handler (typically LPAR) */
 extern int fwnmi_active;
+#endif
 
 #ifdef CONFIG_DEBUG_KERNEL
 void (*debugger)(struct pt_regs *regs);
@@ -96,6 +98,7 @@ _exception(int signr, siginfo_t *info, s
 	force_sig_info(signr, info, current);
 }
 
+#ifdef CONFIG_PPC_PSERIES
 /* Get the error information for errors coming through the
  * FWNMI vectors.  The pt_regs' r3 will be updated to reflect
  * the actual r3 if possible, and a ptr to the error log entry
@@ -128,10 +131,12 @@ static void FWNMI_release_errinfo(void)
 	if (ret != 0)
 		printk("FWNMI: nmi-interlock failed: %ld\n", ret);
 }
+#endif
 
 void
 SystemResetException(struct pt_regs *regs)
 {
+#ifdef CONFIG_PPC_PSERIES
 	if (fwnmi_active) {
 		struct rtas_error_log *errhdr = FWNMI_get_errinfo(regs);
 		if (errhdr) {
@@ -139,6 +144,7 @@ SystemResetException(struct pt_regs *reg
 		}
 		FWNMI_release_errinfo();
 	}
+#endif
 
 #ifdef CONFIG_DEBUG_KERNEL
 	if (debugger)
@@ -154,6 +160,7 @@ SystemResetException(struct pt_regs *reg
 	/* What should we do here? We could issue a shutdown or hard reset. */
 }
 
+#ifdef CONFIG_PPC_PSERIES
 /* 
  * See if we can recover from a machine check exception.
  * This is only called on power4 (or above) and only via
@@ -190,6 +197,7 @@ static int recover_mce(struct pt_regs *r
 	}
 	return 0;
 }
+#endif
 
 /*
  * Handle a machine check.
@@ -207,6 +215,7 @@ static int recover_mce(struct pt_regs *r
 void
 MachineCheckException(struct pt_regs *regs)
 {
+#ifdef CONFIG_PPC_PSERIES
 	struct rtas_error_log err, *errp;
 
 	if (fwnmi_active) {
@@ -217,6 +226,7 @@ MachineCheckException(struct pt_regs *re
 		if (errp && recover_mce(regs, err))
 			return;
 	}
+#endif
 
 #ifdef CONFIG_DEBUG_KERNEL
 	if (debugger_fault_handler) {
diff -purN linux-2.5/arch/ppc64/kernel/udbg.c linuxppc64-2.5/arch/ppc64/kernel/udbg.c
--- linux-2.5/arch/ppc64/kernel/udbg.c	2003-03-26 04:30:59.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/udbg.c	2003-10-10 16:14:31.000000000 +0000
@@ -127,8 +127,10 @@ udbg_write(const char *s, int n)
 {
 	int remain = n;
 	char c;
+
 	if (!ppc_md.udbg_putc)
-		for (;;);	/* stop here for cpuctl */
+		return 0;
+
 	if ( s && *s != '\0' ) {
 		while ( (( c = *s++ ) != '\0') && (remain-- > 0)) {
 			ppc_md.udbg_putc(c);
diff -purN linux-2.5/arch/ppc64/kernel/viopath.c linuxppc64-2.5/arch/ppc64/kernel/viopath.c
--- linux-2.5/arch/ppc64/kernel/viopath.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/viopath.c	2003-11-21 05:43:24.000000000 +0000
@@ -0,0 +1,755 @@
+/* -*- linux-c -*-
+ *  arch/ppc64/kernel/viopath.c
+ *
+ *  iSeries Virtual I/O Message Path code
+ *
+ *  Authors: Dave Boutcher <boutcher@us.ibm.com>
+ *           Ryan Arnold <ryanarn@us.ibm.com>
+ *           Colin Devilbiss <devilbis@us.ibm.com>
+ *
+ * (C) Copyright 2000-2003 IBM Corporation
+ *
+ * This code is used by the iSeries virtual disk, cd,
+ * tape, and console to communicate with OS/400 in another
+ * partition.
+ *
+ * This program is free software;  you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of the
+ * License, or (at your option) anyu later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software Foundation,
+ * Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ *
+ */
+#include <linux/config.h>
+#include <asm/uaccess.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/errno.h>
+#include <linux/vmalloc.h>
+#include <linux/string.h>
+#include <linux/proc_fs.h>
+#include <linux/pci.h>
+#include <linux/wait.h>
+
+#include <asm/hardirq.h>	/* for is_atomic */
+
+#include <asm/iSeries/LparData.h>
+#include <asm/iSeries/HvLpEvent.h>
+#include <asm/iSeries/HvLpConfig.h>
+#include <asm/iSeries/HvCallCfg.h>
+#include <asm/iSeries/mf.h>
+#include <asm/iSeries/iSeries_proc.h>
+#include <asm/iSeries/vio.h>
+
+extern struct pci_dev *iSeries_vio_dev;
+
+/* Status of the path to each other partition in the system.
+ * This is overkill, since we will only ever establish connections
+ * to our hosting partition and the primary partition on the system.
+ * But this allows for other support in the future.
+ */
+static struct viopathStatus {
+	int isOpen:1;		/* Did we open the path?            */
+	int isActive:1;		/* Do we have a mon msg outstanding */
+	int users[VIO_MAX_SUBTYPES];
+	HvLpInstanceId mSourceInst;
+	HvLpInstanceId mTargetInst;
+	int numberAllocated;
+} viopathStatus[HVMAXARCHITECTEDLPS];
+
+static spinlock_t statuslock = SPIN_LOCK_UNLOCKED;
+
+/*
+ * For each kind of event we allocate a buffer that is
+ * guaranteed not to cross a page boundary
+ */
+static unsigned char event_buffer[VIO_MAX_SUBTYPES * 256] __page_aligned;
+static atomic_t event_buffer_available[VIO_MAX_SUBTYPES];
+static int event_buffer_initialised;
+
+static void handleMonitorEvent(struct HvLpEvent *event);
+
+/*
+ * We use this structure to handle asynchronous responses.  The caller
+ * blocks on the semaphore and the handler posts the semaphore.  However,
+ * if in_atomic() is true in the caller, then wait_atomic is used ...
+ */
+struct doneAllocParms_t {
+	struct semaphore *sem;
+	int number;
+	volatile unsigned long *wait_atomic;
+	int used_wait_atomic;
+};
+
+/* Put a sequence number in each mon msg.  The value is not
+ * important.  Start at something other than 0 just for
+ * readability.  wrapping this is ok.
+ */
+static u8 viomonseq = 22;
+
+/* Our hosting logical partition.  We get this at startup
+ * time, and different modules access this variable directly.
+ */
+HvLpIndex viopath_hostLp = 0xff;	/* HvLpIndexInvalid */
+EXPORT_SYMBOL(viopath_hostLp);
+HvLpIndex viopath_ourLp = 0xff;
+EXPORT_SYMBOL(viopath_ourLp);
+
+/* For each kind of incoming event we set a pointer to a
+ * routine to call.
+ */
+static vio_event_handler_t *vio_handler[VIO_MAX_SUBTYPES];
+
+static unsigned char e2a(unsigned char x)
+{
+	switch (x) {
+	case 0xF0:
+		return '0';
+	case 0xF1:
+		return '1';
+	case 0xF2:
+		return '2';
+	case 0xF3:
+		return '3';
+	case 0xF4:
+		return '4';
+	case 0xF5:
+		return '5';
+	case 0xF6:
+		return '6';
+	case 0xF7:
+		return '7';
+	case 0xF8:
+		return '8';
+	case 0xF9:
+		return '9';
+	case 0xC1:
+		return 'A';
+	case 0xC2:
+		return 'B';
+	case 0xC3:
+		return 'C';
+	case 0xC4:
+		return 'D';
+	case 0xC5:
+		return 'E';
+	case 0xC6:
+		return 'F';
+	case 0xC7:
+		return 'G';
+	case 0xC8:
+		return 'H';
+	case 0xC9:
+		return 'I';
+	case 0xD1:
+		return 'J';
+	case 0xD2:
+		return 'K';
+	case 0xD3:
+		return 'L';
+	case 0xD4:
+		return 'M';
+	case 0xD5:
+		return 'N';
+	case 0xD6:
+		return 'O';
+	case 0xD7:
+		return 'P';
+	case 0xD8:
+		return 'Q';
+	case 0xD9:
+		return 'R';
+	case 0xE2:
+		return 'S';
+	case 0xE3:
+		return 'T';
+	case 0xE4:
+		return 'U';
+	case 0xE5:
+		return 'V';
+	case 0xE6:
+		return 'W';
+	case 0xE7:
+		return 'X';
+	case 0xE8:
+		return 'Y';
+	case 0xE9:
+		return 'Z';
+	}
+	return ' ';
+}
+
+/* Handle reads from the proc file system
+ */
+static int proc_read(char *buf, char **start, off_t offset,
+		     int blen, int *eof, void *data)
+{
+	HvLpEvent_Rc hvrc;
+	DECLARE_MUTEX_LOCKED(Semaphore);
+	dma_addr_t dmaa =
+	    pci_map_single(iSeries_vio_dev, buf, PAGE_SIZE,
+			   PCI_DMA_FROMDEVICE);
+	int len = PAGE_SIZE;
+
+	if (len > blen)
+		len = blen;
+
+	memset(buf, 0x00, len);
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_config | vioconfigget,
+			HvLpEvent_AckInd_DoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp),
+			(u64)(unsigned long)&Semaphore, VIOVERSION << 16,
+			((u64)dmaa) << 32, len, 0, 0);
+	if (hvrc != HvLpEvent_Rc_Good)
+		printk("viopath hv error on op %d\n", (int) hvrc);
+
+	down(&Semaphore);
+
+	pci_unmap_single(iSeries_vio_dev, dmaa, PAGE_SIZE,
+			 PCI_DMA_FROMDEVICE);
+
+	sprintf(buf + strlen(buf), "SRLNBR=");
+	buf[strlen(buf)] = e2a(xItExtVpdPanel.mfgID[2]);
+	buf[strlen(buf)] = e2a(xItExtVpdPanel.mfgID[3]);
+	buf[strlen(buf)] = e2a(xItExtVpdPanel.systemSerial[1]);
+	buf[strlen(buf)] = e2a(xItExtVpdPanel.systemSerial[2]);
+	buf[strlen(buf)] = e2a(xItExtVpdPanel.systemSerial[3]);
+	buf[strlen(buf)] = e2a(xItExtVpdPanel.systemSerial[4]);
+	buf[strlen(buf)] = e2a(xItExtVpdPanel.systemSerial[5]);
+	buf[strlen(buf)] = '\n';
+	*eof = 1;
+	return strlen(buf);
+}
+
+/* Handle writes to our proc file system
+ */
+static int proc_write(struct file *file, const char *buffer,
+		      unsigned long count, void *data)
+{
+	/* Doesn't do anything today!!!
+	 */
+	return count;
+}
+
+/* setup our proc file system entries
+ */
+static void vio_proc_init(struct proc_dir_entry *iSeries_proc)
+{
+	struct proc_dir_entry *ent;
+	ent = create_proc_entry("config", S_IFREG | S_IRUSR, iSeries_proc);
+	if (!ent)
+		return;
+	ent->nlink = 1;
+	ent->data = NULL;
+	ent->read_proc = proc_read;
+	ent->write_proc = proc_write;
+}
+
+/* See if a given LP is active.  Allow for invalid lps to be passed in
+ * and just return invalid
+ */
+int viopath_isactive(HvLpIndex lp)
+{
+	if (lp == HvLpIndexInvalid)
+		return 0;
+	if (lp < HVMAXARCHITECTEDLPS)
+		return viopathStatus[lp].isActive;
+	else
+		return 0;
+}
+EXPORT_SYMBOL(viopath_isactive);
+
+/*
+ * We cache the source and target instance ids for each
+ * partition.  
+ */
+HvLpInstanceId viopath_sourceinst(HvLpIndex lp)
+{
+	return viopathStatus[lp].mSourceInst;
+}
+EXPORT_SYMBOL(viopath_sourceinst);
+
+HvLpInstanceId viopath_targetinst(HvLpIndex lp)
+{
+	return viopathStatus[lp].mTargetInst;
+}
+EXPORT_SYMBOL(viopath_targetinst);
+
+/*
+ * Send a monitor message.  This is a message with the acknowledge
+ * bit on that the other side will NOT explicitly acknowledge.  When
+ * the other side goes down, the hypervisor will acknowledge any
+ * outstanding messages....so we will know when the other side dies.
+ */
+static void sendMonMsg(HvLpIndex remoteLp)
+{
+	HvLpEvent_Rc hvrc;
+
+	viopathStatus[remoteLp].mSourceInst =
+		HvCallEvent_getSourceLpInstanceId(remoteLp,
+				HvLpEvent_Type_VirtualIo);
+	viopathStatus[remoteLp].mTargetInst =
+		HvCallEvent_getTargetLpInstanceId(remoteLp,
+				HvLpEvent_Type_VirtualIo);
+
+	/*
+	 * Deliberately ignore the return code here.  if we call this
+	 * more than once, we don't care.
+	 */
+	vio_setHandler(viomajorsubtype_monitor, handleMonitorEvent);
+
+	hvrc = HvCallEvent_signalLpEventFast(remoteLp, HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_monitor, HvLpEvent_AckInd_DoAck,
+			HvLpEvent_AckType_DeferredAck,
+			viopathStatus[remoteLp].mSourceInst,
+			viopathStatus[remoteLp].mTargetInst,
+			viomonseq++, 0, 0, 0, 0, 0);
+
+	if (hvrc == HvLpEvent_Rc_Good)
+		viopathStatus[remoteLp].isActive = 1;
+	else {
+		printk(KERN_WARNING_VIO "could not connect to partition %d\n",
+				remoteLp);
+		viopathStatus[remoteLp].isActive = 0;
+	}
+}
+
+static void handleMonitorEvent(struct HvLpEvent *event)
+{
+	HvLpIndex remoteLp;
+	int i;
+
+	/*
+	 * This handler is _also_ called as part of the loop
+	 * at the end of this routine, so it must be able to
+	 * ignore NULL events...
+	 */
+	if (!event)
+		return;
+
+	/*
+	 * First see if this is just a normal monitor message from the
+	 * other partition
+	 */
+	if (event->xFlags.xFunction == HvLpEvent_Function_Int) {
+		remoteLp = event->xSourceLp;
+		if (!viopathStatus[remoteLp].isActive)
+			sendMonMsg(remoteLp);
+		return;
+	}
+
+	/*
+	 * This path is for an acknowledgement; the other partition
+	 * died
+	 */
+	remoteLp = event->xTargetLp;
+	if ((event->xSourceInstanceId != viopathStatus[remoteLp].mSourceInst) ||
+	    (event->xTargetInstanceId != viopathStatus[remoteLp].mTargetInst)) {
+		printk(KERN_WARNING_VIO "ignoring ack....mismatched instances\n");
+		return;
+	}
+
+	printk(KERN_WARNING_VIO "partition %d ended\n", remoteLp);
+
+	viopathStatus[remoteLp].isActive = 0;
+
+	/*
+	 * For each active handler, pass them a NULL
+	 * message to indicate that the other partition
+	 * died
+	 */
+	for (i = 0; i < VIO_MAX_SUBTYPES; i++) {
+		if (vio_handler[i] != NULL)
+			(*vio_handler[i])(NULL);
+	}
+}
+
+int vio_setHandler(int subtype, vio_event_handler_t *beh)
+{
+	subtype = subtype >> VIOMAJOR_SUBTYPE_SHIFT;
+	if ((subtype < 0) || (subtype >= VIO_MAX_SUBTYPES))
+		return -EINVAL;
+	if (vio_handler[subtype] != NULL)
+		return -EBUSY;
+	vio_handler[subtype] = beh;
+	return 0;
+}
+EXPORT_SYMBOL(vio_setHandler);
+
+int vio_clearHandler(int subtype)
+{
+	subtype = subtype >> VIOMAJOR_SUBTYPE_SHIFT;
+	if ((subtype < 0) || (subtype >= VIO_MAX_SUBTYPES))
+		return -EINVAL;
+	if (vio_handler[subtype] == NULL)
+		return -EAGAIN;
+	vio_handler[subtype] = NULL;
+	return 0;
+}
+EXPORT_SYMBOL(vio_clearHandler);
+
+static void handleConfig(struct HvLpEvent *event)
+{
+	if (!event)
+		return;
+	if (event->xFlags.xFunction == HvLpEvent_Function_Int) {
+		printk(KERN_WARNING_VIO
+		       "unexpected config request from partition %d",
+		       event->xSourceLp);
+
+		if ((event->xFlags.xFunction == HvLpEvent_Function_Int) &&
+		    (event->xFlags.xAckInd == HvLpEvent_AckInd_DoAck)) {
+			event->xRc = HvLpEvent_Rc_InvalidSubtype;
+			HvCallEvent_ackLpEvent(event);
+		}
+		return;
+	}
+
+	up((struct semaphore *)event->xCorrelationToken);
+}
+
+/*
+ * Initialization of the hosting partition
+ */
+void vio_set_hostlp(void)
+{
+	/*
+	 * If this has already been set then we DON'T want to either change
+	 * it or re-register the proc file system
+	 */
+	if (viopath_hostLp != HvLpIndexInvalid)
+		return;
+
+	/*
+	 * Figure out our hosting partition.  This isn't allowed to change
+	 * while we're active
+	 */
+	viopath_ourLp = HvLpConfig_getLpIndex();
+	viopath_hostLp = HvCallCfg_getHostingLpIndex(viopath_ourLp);
+
+	/* If we have a valid hosting LP, create a proc file system entry
+	 * for config information
+	 */
+	if (viopath_hostLp != HvLpIndexInvalid) {
+		iSeries_proc_callback(&vio_proc_init);
+		vio_setHandler(viomajorsubtype_config, handleConfig);
+	}
+}
+EXPORT_SYMBOL(vio_set_hostlp);
+
+static void vio_handleEvent(struct HvLpEvent *event, struct pt_regs *regs)
+{
+	HvLpIndex remoteLp;
+	int subtype = (event->xSubtype & VIOMAJOR_SUBTYPE_MASK)
+		>> VIOMAJOR_SUBTYPE_SHIFT;
+
+	if (event->xFlags.xFunction == HvLpEvent_Function_Int) {
+		remoteLp = event->xSourceLp;
+		/*
+		 * The isActive is checked because if the hosting partition
+		 * went down and came back up it would not be active but it
+		 * would have different source and target instances, in which
+		 * case we'd want to reset them.  This case really protects
+		 * against an unauthorized active partition sending interrupts
+		 * or acks to this linux partition.
+		 */
+		if (viopathStatus[remoteLp].isActive
+		    && (event->xSourceInstanceId !=
+			viopathStatus[remoteLp].mTargetInst)) {
+			printk(KERN_WARNING_VIO
+			       "message from invalid partition. "
+			       "int msg rcvd, source inst (%d) doesnt match (%d)\n",
+			       viopathStatus[remoteLp].mTargetInst,
+			       event->xSourceInstanceId);
+			return;
+		}
+
+		if (viopathStatus[remoteLp].isActive
+		    && (event->xTargetInstanceId !=
+			viopathStatus[remoteLp].mSourceInst)) {
+			printk(KERN_WARNING_VIO
+			       "message from invalid partition. "
+			       "int msg rcvd, target inst (%d) doesnt match (%d)\n",
+			       viopathStatus[remoteLp].mSourceInst,
+			       event->xTargetInstanceId);
+			return;
+		}
+	} else {
+		remoteLp = event->xTargetLp;
+		if (event->xSourceInstanceId !=
+		    viopathStatus[remoteLp].mSourceInst) {
+			printk(KERN_WARNING_VIO
+			       "message from invalid partition. "
+			       "ack msg rcvd, source inst (%d) doesnt match (%d)\n",
+			       viopathStatus[remoteLp].mSourceInst,
+			       event->xSourceInstanceId);
+			return;
+		}
+
+		if (event->xTargetInstanceId !=
+		    viopathStatus[remoteLp].mTargetInst) {
+			printk(KERN_WARNING_VIO
+			       "message from invalid partition. "
+			       "viopath: ack msg rcvd, target inst (%d) doesnt match (%d)\n",
+			       viopathStatus[remoteLp].mTargetInst,
+			       event->xTargetInstanceId);
+			return;
+		}
+	}
+
+	if (vio_handler[subtype] == NULL) {
+		printk(KERN_WARNING_VIO
+		       "unexpected virtual io event subtype %d from partition %d\n",
+		       event->xSubtype, remoteLp);
+		/* No handler.  Ack if necessary */
+		if ((event->xFlags.xFunction == HvLpEvent_Function_Int) &&
+		    (event->xFlags.xAckInd == HvLpEvent_AckInd_DoAck)) {
+			event->xRc = HvLpEvent_Rc_InvalidSubtype;
+			HvCallEvent_ackLpEvent(event);
+		}
+		return;
+	}
+
+	/* This innocuous little line is where all the real work happens */
+	(*vio_handler[subtype])(event);
+}
+
+static void viopath_donealloc(void *parm, int number)
+{
+	struct doneAllocParms_t *parmsp = (struct doneAllocParms_t *)parm;
+
+	parmsp->number = number;
+	if (parmsp->used_wait_atomic)
+		*(parmsp->wait_atomic) = 0;
+	else
+		up(parmsp->sem);
+}
+
+static int allocateEvents(HvLpIndex remoteLp, int numEvents)
+{
+	struct doneAllocParms_t parms;
+	DECLARE_MUTEX_LOCKED(Semaphore);
+	volatile unsigned long wait_atomic = 1;
+
+	if (in_atomic()) {
+		parms.used_wait_atomic = 1;
+		parms.wait_atomic = &wait_atomic;
+	} else {
+		parms.used_wait_atomic = 0;
+		parms.sem = &Semaphore;
+	}
+	mf_allocateLpEvents(remoteLp, HvLpEvent_Type_VirtualIo, 250,	/* It would be nice to put a real number here! */
+			    numEvents, &viopath_donealloc, &parms);
+	if (in_atomic()) {
+		while (wait_atomic)
+			mb();
+	} else
+		down(&Semaphore);
+	return parms.number;
+}
+
+int viopath_open(HvLpIndex remoteLp, int subtype, int numReq)
+{
+	int i;
+	unsigned long flags;
+	int tempNumAllocated;
+
+	if ((remoteLp >= HvMaxArchitectedLps) || (remoteLp == HvLpIndexInvalid))
+		return -EINVAL;
+
+	subtype = subtype >> VIOMAJOR_SUBTYPE_SHIFT;
+	if ((subtype < 0) || (subtype >= VIO_MAX_SUBTYPES))
+		return -EINVAL;
+
+	spin_lock_irqsave(&statuslock, flags);
+
+	if (!event_buffer_initialised) {
+		for (i = 0; i < VIO_MAX_SUBTYPES; i++)
+			atomic_set(&event_buffer_available[i], 1);
+		event_buffer_initialised = 1;
+	}
+
+	viopathStatus[remoteLp].users[subtype]++;
+
+	if (!viopathStatus[remoteLp].isOpen) {
+		viopathStatus[remoteLp].isOpen = 1;
+		HvCallEvent_openLpEventPath(remoteLp, HvLpEvent_Type_VirtualIo);
+
+		/*
+		 * Don't hold the spinlock during an operation that
+		 * can sleep.
+		 */
+		spin_unlock_irqrestore(&statuslock, flags);
+		tempNumAllocated = allocateEvents(remoteLp, 1);
+		spin_lock_irqsave(&statuslock, flags);
+
+		viopathStatus[remoteLp].numberAllocated += tempNumAllocated;
+
+		if (viopathStatus[remoteLp].numberAllocated == 0) {
+			HvCallEvent_closeLpEventPath(remoteLp,
+					HvLpEvent_Type_VirtualIo);
+
+			spin_unlock_irqrestore(&statuslock, flags);
+			return -ENOMEM;
+		}
+
+		viopathStatus[remoteLp].mSourceInst =
+			HvCallEvent_getSourceLpInstanceId(remoteLp,
+					HvLpEvent_Type_VirtualIo);
+		viopathStatus[remoteLp].mTargetInst =
+			HvCallEvent_getTargetLpInstanceId(remoteLp,
+					HvLpEvent_Type_VirtualIo);
+		HvLpEvent_registerHandler(HvLpEvent_Type_VirtualIo,
+					  &vio_handleEvent);
+		sendMonMsg(remoteLp);
+		printk(KERN_INFO_VIO
+		       "Opening connection to partition %d, setting sinst %d, tinst %d\n",
+		       remoteLp, viopathStatus[remoteLp].mSourceInst,
+		       viopathStatus[remoteLp].mTargetInst);
+	}
+
+	spin_unlock_irqrestore(&statuslock, flags);
+	tempNumAllocated = allocateEvents(remoteLp, numReq);
+	spin_lock_irqsave(&statuslock, flags);
+	viopathStatus[remoteLp].numberAllocated += tempNumAllocated;
+	spin_unlock_irqrestore(&statuslock, flags);
+
+	return 0;
+}
+EXPORT_SYMBOL(viopath_open);
+
+int viopath_close(HvLpIndex remoteLp, int subtype, int numReq)
+{
+	unsigned long flags;
+	int i;
+	int numOpen;
+	struct doneAllocParms_t doneAllocParms;
+	DECLARE_MUTEX_LOCKED(Semaphore);
+
+	if ((remoteLp >= HvMaxArchitectedLps) || (remoteLp == HvLpIndexInvalid))
+		return -EINVAL;
+
+	subtype = subtype >> VIOMAJOR_SUBTYPE_SHIFT;
+	if ((subtype < 0) || (subtype >= VIO_MAX_SUBTYPES))
+		return -EINVAL;
+
+	spin_lock_irqsave(&statuslock, flags);
+	/*
+	 * If the viopath_close somehow gets called before a
+	 * viopath_open it could decrement to -1 which is a non
+	 * recoverable state so we'll prevent this from
+	 * happening.
+	 */
+	if (viopathStatus[remoteLp].users[subtype] > 0)
+		viopathStatus[remoteLp].users[subtype]--;
+
+	spin_unlock_irqrestore(&statuslock, flags);
+
+	doneAllocParms.sem = &Semaphore;
+	mf_deallocateLpEvents(remoteLp, HvLpEvent_Type_VirtualIo,
+			      numReq, &viopath_donealloc, &doneAllocParms);
+	down(&Semaphore);
+
+	spin_lock_irqsave(&statuslock, flags);
+	for (i = 0, numOpen = 0; i < VIO_MAX_SUBTYPES; i++)
+		numOpen += viopathStatus[remoteLp].users[i];
+
+	if ((viopathStatus[remoteLp].isOpen) && (numOpen == 0)) {
+		printk(KERN_INFO_VIO "Closing connection to partition %d",
+				remoteLp);
+
+		HvCallEvent_closeLpEventPath(remoteLp,
+					     HvLpEvent_Type_VirtualIo);
+		viopathStatus[remoteLp].isOpen = 0;
+		viopathStatus[remoteLp].isActive = 0;
+
+		for (i = 0; i < VIO_MAX_SUBTYPES; i++)
+			atomic_set(&event_buffer_available[i], 0);
+		event_buffer_initialised = 0;
+	}
+	spin_unlock_irqrestore(&statuslock, flags);
+	return 0;
+}
+EXPORT_SYMBOL(viopath_close);
+
+void *vio_get_event_buffer(int subtype)
+{
+	subtype = subtype >> VIOMAJOR_SUBTYPE_SHIFT;
+	if ((subtype < 0) || (subtype >= VIO_MAX_SUBTYPES))
+		return NULL;
+
+	if (atomic_dec_if_positive(&event_buffer_available[subtype]) == 0)
+		return &event_buffer[subtype * 256];
+	else
+		return NULL;
+}
+EXPORT_SYMBOL(vio_get_event_buffer);
+
+void vio_free_event_buffer(int subtype, void *buffer)
+{
+	subtype = subtype >> VIOMAJOR_SUBTYPE_SHIFT;
+	if ((subtype < 0) || (subtype >= VIO_MAX_SUBTYPES)) {
+		printk(KERN_WARNING_VIO
+		       "unexpected subtype %d freeing event buffer\n",
+		       subtype);
+		return;
+	}
+
+	if (atomic_read(&event_buffer_available[subtype]) != 0) {
+		printk(KERN_WARNING_VIO
+		       "freeing unallocated event buffer, subtype %d\n",
+		       subtype);
+		return;
+	}
+
+	if (buffer != &event_buffer[subtype * 256]) {
+		printk(KERN_WARNING_VIO
+		       "freeing invalid event buffer, subtype %d\n",
+		       subtype);
+	}
+
+	atomic_set(&event_buffer_available[subtype], 1);
+}
+EXPORT_SYMBOL(vio_free_event_buffer);
+
+static const struct vio_error_entry vio_no_error =
+    { 0, 0, "Non-VIO Error" };
+static const struct vio_error_entry vio_unknown_error =
+    { 0, EIO, "Unknown Error" };
+
+static const struct vio_error_entry vio_default_errors[] = {
+	{0x0001, EIO, "No Connection"},
+	{0x0002, EIO, "No Receiver"},
+	{0x0003, EIO, "No Buffer Available"},
+	{0x0004, EBADRQC, "Invalid Message Type"},
+	{0x0000, 0, NULL},
+};
+
+const struct vio_error_entry *vio_lookup_rc(
+		const struct vio_error_entry *local_table, u16 rc)
+{
+	const struct vio_error_entry *cur;
+
+	if (!rc)
+		return &vio_no_error;
+	if (local_table)
+		for (cur = local_table; cur->rc; ++cur)
+			if (cur->rc == rc)
+				return cur;
+	for (cur = vio_default_errors; cur->rc; ++cur)
+		if (cur->rc == rc)
+			return cur;
+	return &vio_unknown_error;
+}
+EXPORT_SYMBOL(vio_lookup_rc);
diff -purN linux-2.5/arch/ppc64/kernel/xics.c linuxppc64-2.5/arch/ppc64/kernel/xics.c
--- linux-2.5/arch/ppc64/kernel/xics.c	2003-09-03 04:01:38.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/kernel/xics.c	2003-11-14 15:57:08.000000000 +0000
@@ -35,6 +35,7 @@ void xics_disable_irq(u_int irq);
 void xics_mask_and_ack_irq(u_int irq);
 void xics_end_irq(u_int irq);
 void xics_set_affinity(unsigned int irq_nr, cpumask_t cpumask);
+void ppc64_boot_msg(unsigned int src, const char *msg);
 
 struct hw_interrupt_type xics_pic = {
 	" XICS     ",
@@ -58,7 +59,6 @@ struct hw_interrupt_type xics_8259_pic =
 };
 
 #define XICS_IPI		2
-#define XICS_IRQ_OFFSET		0x10
 #define XICS_IRQ_SPURIOUS	0
 
 /* Want a priority other than 0.  Various HW issues require this. */
@@ -202,7 +202,7 @@ static void pSeriesLP_qirr_info(int n_cp
 {
 	unsigned long lpar_rc;
 
-	lpar_rc = plpar_ipi(n_cpu, value);
+	lpar_rc = plpar_ipi(get_hard_smp_processor_id(n_cpu), value);
 	if (lpar_rc != H_Success)
 		panic("bad return code qirr - rc = %lx\n", lpar_rc); 
 }
@@ -214,14 +214,12 @@ xics_ops pSeriesLP_ops = {
 	pSeriesLP_qirr_info
 };
 
-void xics_enable_irq(u_int virq)
+void xics_enable_irq(unsigned int irq)
 {
-	u_int irq;
 	long call_status;
 	unsigned int server;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = irq_offset_down(irq);
 	if (irq == XICS_IPI)
 		return;
 
@@ -251,13 +249,11 @@ void xics_enable_irq(u_int virq)
 	}
 }
 
-void xics_disable_irq(u_int virq)
+void xics_disable_irq(unsigned int irq)
 {
-	u_int irq;
 	long call_status;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = irq_offset_down(irq);
 	if (irq == XICS_IPI)
 		return;
 
@@ -278,20 +274,20 @@ void xics_disable_irq(u_int virq)
 	}
 }
 
-void xics_end_irq(u_int	irq)
+void xics_end_irq(unsigned int irq)
 {
 	int cpu = smp_processor_id();
 
 	iosync();
-	ops->xirr_info_set(cpu, ((0xff<<24) |
-				 (virt_irq_to_real(irq-XICS_IRQ_OFFSET))));
+	ops->xirr_info_set(cpu, ((0xff<<24) | (irq_offset_down(irq))));
+
 }
 
 void xics_mask_and_ack_irq(u_int irq)
 {
 	int cpu = smp_processor_id();
 
-	if (irq < XICS_IRQ_OFFSET) {
+	if (irq < irq_offset_value()) {
 		i8259_pic.ack(irq);
 		iosync();
 		ops->xirr_info_set(cpu, ((0xff<<24) |
@@ -315,13 +311,14 @@ int xics_get_irq(struct pt_regs *regs)
 		irq = i8259_irq(cpu);
 		if (irq == -1) {
 			/* Spurious cascaded interrupt.  Still must ack xics */
-                        xics_end_irq(XICS_IRQ_OFFSET + xics_irq_8259_cascade);
+			xics_end_irq(irq_offset_up(xics_irq_8259_cascade));
+
 			irq = -1;
 		}
 	} else if (vec == XICS_IRQ_SPURIOUS) {
 		irq = -1;
 	} else {
-		irq = real_irq_to_virt(vec) + XICS_IRQ_OFFSET;
+		irq = irq_offset_up(vec);
 	}
 	return irq;
 }
@@ -379,6 +376,16 @@ void xics_setup_cpu(void)
 
 #endif /* CONFIG_SMP */
 
+void
+xics_init_irq_desc(irq_desc_t *desc)
+{
+	/* Don't mess with the handler if already set.
+	 * This leaves the setup of isa handlers undisturbed.
+	 */
+	if (!desc->handler)
+		desc->handler = &xics_pic;
+}
+
 void xics_init_IRQ(void)
 {
 	int i;
@@ -398,7 +405,7 @@ void xics_init_IRQ(void)
 	ibm_int_on  = rtas_token("ibm,int-on");
 	ibm_int_off = rtas_token("ibm,int-off");
 
-	np = find_type_devices("PowerPC-External-Interrupt-Presentation");
+	np = of_find_node_by_type(NULL, "PowerPC-External-Interrupt-Presentation");
 	if (!np) {
 		printk(KERN_WARNING "Can't find Interrupt Presentation\n");
 		udbg_printf("Can't find Interrupt Presentation\n");
@@ -433,13 +440,15 @@ nextnode:
 		if (indx >= NR_CPUS) break;
 	}
 
-	np = np->next;
+	np = of_find_node_by_type(np, "PowerPC-External-Interrupt-Presentation");
 	if ((indx < NR_CPUS) && np) goto nextnode;
 
 	/* Find the server numbers for the boot cpu. */
-	for (np = find_type_devices("cpu"); np; np = np->next) {
+	for (np = of_find_node_by_type(NULL, "cpu");
+	     np;
+	     np = of_find_node_by_type(np, "cpu")) {
 		ireg = (uint *)get_property(np, "reg", &ilen);
-		if (ireg && ireg[0] == smp_processor_id()) {
+		if (ireg && ireg[0] == hard_smp_processor_id()) {
 			ireg = (uint *)get_property(np, "ibm,ppc-interrupt-gserver#s", &ilen);
 			i = ilen / sizeof(int);
 			if (ireg && i > 0) {
@@ -449,11 +458,12 @@ nextnode:
 			break;
 		}
 	}
+	of_node_put(np);
 
 	intr_base = inodes[0].addr;
 	intr_size = (ulong)inodes[0].size;
 
-	np = find_type_devices("interrupt-controller");
+	np = of_find_node_by_type(NULL, "interrupt-controller");
 	if (!np) {
 		printk(KERN_WARNING "xics:  no ISA Interrupt Controller\n");
 		xics_irq_8259_cascade_real = -1;
@@ -466,7 +476,8 @@ nextnode:
 			while (1);
 		}
 		xics_irq_8259_cascade_real = *ireg;
-		xics_irq_8259_cascade = virt_irq_create_mapping(xics_irq_8259_cascade_real);
+		xics_irq_8259_cascade = xics_irq_8259_cascade_real;
+		of_node_put(np);
 	}
 
 	if (systemcfg->platform == PLATFORM_PSERIES) {
@@ -474,8 +485,8 @@ nextnode:
 		for (i = 0; i < NR_CPUS; ++i) {
 			if (!cpu_possible(i))
 				continue;
-			xics_per_cpu[i] = __ioremap((ulong)inodes[i].addr, 
-						    (ulong)inodes[i].size,
+			xics_per_cpu[i] = __ioremap((ulong)inodes[get_hard_smp_processor_id(i)].addr, 
+						    (ulong)inodes[get_hard_smp_processor_id(i)].size,
 						    _PAGE_NO_CACHE);
 		}
 #else
@@ -494,9 +505,7 @@ nextnode:
 	xics_8259_pic.enable = i8259_pic.enable;
 	xics_8259_pic.disable = i8259_pic.disable;
 	for (i = 0; i < 16; ++i)
-		irq_desc[i].handler = &xics_8259_pic;
-	for (; i < NR_IRQS; ++i)
-		irq_desc[i].handler = &xics_pic;
+		get_real_irq_desc(i)->handler = &xics_8259_pic;
 
 	ops->cppr_info(boot_cpuid, 0xff);
 	iosync();
@@ -512,7 +521,7 @@ static int __init xics_setup_i8259(void)
 {
 	if (naca->interrupt_controller == IC_PPC_XIC &&
 	    xics_irq_8259_cascade != -1) {
-		if (request_irq(xics_irq_8259_cascade + XICS_IRQ_OFFSET,
+		if (request_irq(irq_offset_up(xics_irq_8259_cascade), 
 				no_action, 0, "8259 cascade", 0))
 			printk(KERN_ERR "xics_init_IRQ: couldn't get 8259 cascade\n");
 		i8259_init();
@@ -524,19 +533,14 @@ arch_initcall(xics_setup_i8259);
 #ifdef CONFIG_SMP
 void xics_request_IPIs(void)
 {
-	real_irq_to_virt_map[XICS_IPI] = virt_irq_to_real_map[XICS_IPI] =
-		XICS_IPI;
-	/* IPIs are marked SA_INTERRUPT as they must run with irqs disabled */
-	request_irq(XICS_IPI + XICS_IRQ_OFFSET, xics_ipi_action, SA_INTERRUPT,
-		    "IPI", 0);
-	irq_desc[XICS_IPI+XICS_IRQ_OFFSET].status |= IRQ_PER_CPU;
+	request_irq(irq_offset_up(XICS_IPI), xics_ipi_action, SA_INTERRUPT, "IPI", 0);
+	get_real_irq_desc(irq_offset_up(XICS_IPI))->status |= IRQ_PER_CPU;
 }
 #endif
 
-void xics_set_affinity(unsigned int virq, cpumask_t cpumask)
+void xics_set_affinity(unsigned int irq, cpumask_t cpumask)
 {
-        irq_desc_t *desc = irq_desc + virq;
-	unsigned int irq;
+	irq_desc_t *desc = get_irq_desc(irq);
 	unsigned long flags;
 	long status;
 	unsigned long xics_status[2];
@@ -544,8 +548,7 @@ void xics_set_affinity(unsigned int virq
 	cpumask_t allcpus = CPU_MASK_ALL;
 	cpumask_t tmp = CPU_MASK_NONE;
 
-	virq -= XICS_IRQ_OFFSET;
-	irq = virt_irq_to_real(virq);
+	irq = irq_offset_down(irq);
 	if (irq == XICS_IPI)
 		return;
 
@@ -566,7 +569,7 @@ void xics_set_affinity(unsigned int virq
 		cpus_and(tmp, cpu_online_map, cpumask);
 		if (cpus_empty(tmp))
 			goto out;
-		newmask = first_cpu(cpumask);
+		newmask = get_hard_smp_processor_id(first_cpu(cpumask));
 	}
 
 	status = rtas_call(ibm_set_xive, 3, 1, NULL,
diff -purN linux-2.5/arch/ppc64/mm/imalloc.c linuxppc64-2.5/arch/ppc64/mm/imalloc.c
--- linux-2.5/arch/ppc64/mm/imalloc.c	2002-08-16 06:30:31.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/mm/imalloc.c	2003-10-23 14:10:29.000000000 +0000
@@ -18,55 +18,264 @@
 rwlock_t imlist_lock = RW_LOCK_UNLOCKED;
 struct vm_struct * imlist = NULL;
 
-struct vm_struct *get_im_area(unsigned long size)
+static int get_free_im_addr(unsigned long size, unsigned long *im_addr)
 {
 	unsigned long addr;
-	struct vm_struct **p, *tmp, *area;
-  
-	area = (struct vm_struct *) kmalloc(sizeof(*area), GFP_KERNEL);
-	if (!area)
-		return NULL;
+	struct vm_struct **p, *tmp;
+
 	addr = IMALLOC_START;
-	write_lock(&imlist_lock);
 	for (p = &imlist; (tmp = *p) ; p = &tmp->next) {
 		if (size + addr < (unsigned long) tmp->addr)
 			break;
-		addr = tmp->size + (unsigned long) tmp->addr;
-		if (addr > IMALLOC_END-size) {
-			write_unlock(&imlist_lock);
-			kfree(area);
+		if ((unsigned long)tmp->addr >= IMALLOC_START) 
+			addr = tmp->size + (unsigned long) tmp->addr;
+		if (addr > IMALLOC_END-size) 
+			return 1;
+	}
+	*im_addr = addr;
+
+	return 0;
+}
+
+/* Return whether the region described by v_addr and size overlaps
+ * the region described by vm.  Overlapping regions meet the 
+ * following conditions:
+ * 1) The regions share some part of the address space
+ * 2) The regions aren't identical
+ * 3) The first region is not a subset of the second
+ */
+static inline int im_region_overlaps(unsigned long v_addr, unsigned long size,
+		     struct vm_struct *vm)
+{
+	return (v_addr + size > (unsigned long) vm->addr + vm->size &&
+		v_addr < (unsigned long) vm->addr + vm->size) ||
+	       (v_addr < (unsigned long) vm->addr &&
+		v_addr + size > (unsigned long) vm->addr);
+}
+
+/* Return whether the region described by v_addr and size is a subset
+ * of the region described by vm
+ */
+static inline int im_region_is_subset(unsigned long v_addr, unsigned long size,
+			struct vm_struct *vm)
+{
+	return (int) (v_addr >= (unsigned long) vm->addr && 
+	              v_addr < (unsigned long) vm->addr + vm->size &&
+	    	      size < vm->size);
+}
+
+/* Determine imalloc status of region described by v_addr and size.
+ * Can return one of the following:
+ * IM_REGION_UNUSED   -  Entire region is unallocated in imalloc space.
+ * IM_REGION_SUBSET -    Region is a subset of a region that is already
+ * 			 allocated in imalloc space.
+ * 		         vm will be assigned to a ptr to the parent region.
+ * IM_REGION_EXISTS -    Exact region already allocated in imalloc space.
+ *                       vm will be assigned to a ptr to the existing imlist
+ *                       member.
+ * IM_REGION_OVERLAPS -  A portion of the region is already allocated in 
+ *                       imalloc space.
+ */
+static int im_region_status(unsigned long v_addr, unsigned long size, 
+		    struct vm_struct **vm)
+{
+	struct vm_struct *tmp;
+
+	for (tmp = imlist; tmp; tmp = tmp->next) 
+		if (v_addr < (unsigned long) tmp->addr + tmp->size) 
+			break;
+					
+	if (tmp) {
+		if (im_region_overlaps(v_addr, size, tmp))
+			return IM_REGION_OVERLAP;
+
+		*vm = tmp;
+		if (im_region_is_subset(v_addr, size, tmp))
+			return IM_REGION_SUBSET;
+		else if (v_addr == (unsigned long) tmp->addr && 
+		 	 size == tmp->size) 
+			return IM_REGION_EXISTS;
+	}
+
+	*vm = NULL;
+	return IM_REGION_UNUSED;
+}
+
+static struct vm_struct * split_im_region(unsigned long v_addr, 
+		unsigned long size, struct vm_struct *parent)
+{
+	struct vm_struct *vm1 = NULL;
+	struct vm_struct *vm2 = NULL;
+	struct vm_struct *new_vm = NULL;
+	
+	vm1 = (struct vm_struct *) kmalloc(sizeof(*vm1), GFP_KERNEL);
+	if (vm1	== NULL) {
+		printk(KERN_ERR "%s() out of memory\n", __FUNCTION__);
+		return NULL;
+	}
+
+	if (v_addr == (unsigned long) parent->addr) {
+	        /* Use existing parent vm_struct to represent child, allocate
+		 * new one for the remainder of parent range
+		 */
+		vm1->size = parent->size - size;
+		vm1->addr = (void *) (v_addr + size);
+		vm1->next = parent->next;
+
+		parent->size = size;
+		parent->next = vm1;
+		new_vm = parent;
+	} else if (v_addr + size == (unsigned long) parent->addr + 
+			parent->size) {
+		/* Allocate new vm_struct to represent child, use existing
+		 * parent one for remainder of parent range
+		 */
+		vm1->size = size;
+		vm1->addr = (void *) v_addr;
+		vm1->next = parent->next;
+		new_vm = vm1;
+
+		parent->size -= size;
+		parent->next = vm1;
+	} else {
+	        /* Allocate two new vm_structs for the new child and 
+		 * uppermost remainder, and use existing parent one for the
+		 * lower remainder of parent range
+		 */
+		vm2 = (struct vm_struct *) kmalloc(sizeof(*vm2), GFP_KERNEL);
+		if (vm2 == NULL) {
+			printk(KERN_ERR "%s() out of memory\n", __FUNCTION__);
+			kfree(vm1);
 			return NULL;
 		}
+
+		vm1->size = size;
+		vm1->addr = (void *) v_addr;
+		vm1->next = vm2;
+		new_vm = vm1;
+
+		vm2->size = ((unsigned long) parent->addr + parent->size) - 
+				(v_addr + size);
+		vm2->addr = (void *) v_addr + size;
+		vm2->next = parent->next;
+
+		parent->size = v_addr - (unsigned long) parent->addr;
+		parent->next = vm1;
 	}
+
+	return new_vm;
+}
+
+static struct vm_struct * __add_new_im_area(unsigned long req_addr, 
+					    unsigned long size)
+{
+	struct vm_struct **p, *tmp, *area;
+		
+	for (p = &imlist; (tmp = *p) ; p = &tmp->next) {
+		if (req_addr + size <= (unsigned long)tmp->addr)
+			break;
+	}
+	
+	area = (struct vm_struct *) kmalloc(sizeof(*area), GFP_KERNEL);
+	if (!area)
+		return NULL;
 	area->flags = 0;
-	area->addr = (void *)addr;
+	area->addr = (void *)req_addr;
 	area->size = size;
 	area->next = *p;
 	*p = area;
+
+	return area;
+}
+
+static struct vm_struct * __im_get_area(unsigned long req_addr, 
+					unsigned long size,
+					int criteria)
+{
+	struct vm_struct *tmp;
+	int status;
+
+	status = im_region_status(req_addr, size, &tmp);
+	if ((criteria & status) == 0) {
+		return NULL;
+	}
+	
+	switch (status) {
+	case IM_REGION_UNUSED:
+		tmp = __add_new_im_area(req_addr, size);
+		break;
+	case IM_REGION_SUBSET:
+		tmp = split_im_region(req_addr, size, tmp);
+		break;
+	case IM_REGION_EXISTS:
+		break;
+	default:
+		printk(KERN_ERR "%s() unexpected imalloc region status\n",
+				__FUNCTION__);
+		tmp = NULL;
+	}
+
+	return tmp;
+}
+
+struct vm_struct * im_get_free_area(unsigned long size)
+{
+	struct vm_struct *area;
+	unsigned long addr;
+	
+	write_lock(&imlist_lock);
+	if (get_free_im_addr(size, &addr)) {
+		printk(KERN_ERR "%s() cannot obtain addr for size 0x%lx\n",
+				__FUNCTION__, size);
+		area = NULL;
+		goto next_im_done;
+	}
+
+	area = __im_get_area(addr, size, IM_REGION_UNUSED);
+	if (area == NULL) {
+		printk(KERN_ERR 
+		       "%s() cannot obtain area for addr 0x%lx size 0x%lx\n",
+			__FUNCTION__, addr, size);
+	}
+next_im_done:
 	write_unlock(&imlist_lock);
 	return area;
 }
 
-void ifree(void * addr)
+struct vm_struct * im_get_area(unsigned long v_addr, unsigned long size,
+		int criteria)
+{
+	struct vm_struct *area;
+
+	write_lock(&imlist_lock);
+	area = __im_get_area(v_addr, size, criteria);
+	write_unlock(&imlist_lock);
+	return area;
+}
+
+unsigned long im_free(void * addr)
 {
 	struct vm_struct **p, *tmp;
+	unsigned long ret_size = 0;
   
 	if (!addr)
-		return;
+		return ret_size;
 	if ((PAGE_SIZE-1) & (unsigned long) addr) {
-		printk(KERN_ERR "Trying to ifree() bad address (%p)\n", addr);
-		return;
+		printk(KERN_ERR "Trying to %s bad address (%p)\n", __FUNCTION__,			addr);
+		return ret_size;
 	}
 	write_lock(&imlist_lock);
 	for (p = &imlist ; (tmp = *p) ; p = &tmp->next) {
 		if (tmp->addr == addr) {
+			ret_size = tmp->size;
 			*p = tmp->next;
 			kfree(tmp);
 			write_unlock(&imlist_lock);
-			return;
+			return ret_size;
 		}
 	}
 	write_unlock(&imlist_lock);
-	printk(KERN_ERR "Trying to ifree() nonexistent area (%p)\n", addr);
+	printk(KERN_ERR "Trying to %s nonexistent area (%p)\n", __FUNCTION__,
+			addr);
+	return ret_size;
 }
-
diff -purN linux-2.5/arch/ppc64/mm/init.c linuxppc64-2.5/arch/ppc64/mm/init.c
--- linux-2.5/arch/ppc64/mm/init.c	2003-09-19 06:55:11.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/mm/init.c	2003-10-23 14:10:29.000000000 +0000
@@ -67,6 +67,7 @@
 struct mmu_context_queue_t mmu_context_queue;
 int mem_init_done;
 unsigned long ioremap_bot = IMALLOC_BASE;
+static unsigned long phbs_io_bot = PHBS_IO_BASE;
 
 extern pgd_t swapper_pg_dir[];
 extern struct task_struct *current_set[NR_CPUS];
@@ -74,6 +75,9 @@ extern struct task_struct *current_set[N
 extern pgd_t ioremap_dir[];
 pgd_t * ioremap_pgd = (pgd_t *)&ioremap_dir;
 
+static void * __ioremap_com(unsigned long addr, unsigned long pa, 
+			    unsigned long ea, unsigned long size, 
+			    unsigned long flags);
 static void map_io_page(unsigned long va, unsigned long pa, int flags);
 
 unsigned long klimit = (unsigned long)_end;
@@ -133,12 +137,10 @@ ioremap(unsigned long addr, unsigned lon
 #endif
 }
 
-extern struct vm_struct * get_im_area( unsigned long size );
-
 void *
 __ioremap(unsigned long addr, unsigned long size, unsigned long flags)
 {
-	unsigned long pa, ea, i;
+	unsigned long pa, ea;
 
 	/*
 	 * Choose an address to map it to.
@@ -157,26 +159,163 @@ __ioremap(unsigned long addr, unsigned l
 
 	if (mem_init_done) {
 		struct vm_struct *area;
-		area = get_im_area(size);
-		if (area == 0)
+		area = im_get_free_area(size);
+		if (area == NULL)
 			return NULL;
 		ea = (unsigned long)(area->addr);
-	} 
-	else {
+	} else {
 		ea = ioremap_bot;
 		ioremap_bot += size;
 	}
 
-	if ((flags & _PAGE_PRESENT) == 0)
-		flags |= pgprot_val(PAGE_KERNEL);
-	if (flags & (_PAGE_NO_CACHE | _PAGE_WRITETHRU))
-		flags |= _PAGE_GUARDED;
+	return __ioremap_com(addr, pa, ea, size, flags);
+}
 
-	for (i = 0; i < size; i += PAGE_SIZE) {
-		map_io_page(ea+i, pa+i, flags);
+#define IS_PAGE_ALIGNED(_val) ((_val) == ((_val) & PAGE_MASK))
+
+int __ioremap_explicit(unsigned long pa, unsigned long ea,
+		       unsigned long size, unsigned long flags)
+{
+	struct vm_struct *area;
+	
+	/* For now, require page-aligned values for pa, ea, and size */
+	if (!IS_PAGE_ALIGNED(pa) || !IS_PAGE_ALIGNED(ea) ||
+	    !IS_PAGE_ALIGNED(size)) {
+		printk(KERN_ERR	"unaligned value in %s\n", __FUNCTION__);
+		return 1;
+	}
+	
+	if (!mem_init_done) {
+		/* Two things to consider in this case:
+		 * 1) No records will be kept (imalloc, etc) that the region
+		 *    has been remapped
+		 * 2) It won't be easy to iounmap() the region later (because
+		 *    of 1)
+		 */
+		;
+	} else {
+		area = im_get_area(ea, size, IM_REGION_UNUSED|IM_REGION_SUBSET);
+		if (area == NULL) {
+			printk(KERN_ERR "could not obtain imalloc area for ea 0x%lx\n", ea);
+			return 1;
+		}
+		if (ea != (unsigned long) area->addr) {
+			printk(KERN_ERR "unexpected addr return from im_get_area\n");
+			return 1;
+		}
+	}
+	
+	if (__ioremap_com(pa, pa, ea, size, flags) != (void *) ea) {
+		printk(KERN_ERR "__ioremap_com() returned unexpected addr\n");
+		return 1;
 	}
 
-	return (void *) (ea + (addr & ~PAGE_MASK));
+	return 0;
+}
+
+static void unmap_im_area_pte(pmd_t *pmd, unsigned long address,
+				  unsigned long size)
+{
+	unsigned long end;
+	pte_t *pte;
+
+	if (pmd_none(*pmd))
+		return;
+	if (pmd_bad(*pmd)) {
+		pmd_ERROR(*pmd);
+		pmd_clear(pmd);
+		return;
+	}
+
+	pte = pte_offset_kernel(pmd, address);
+	address &= ~PMD_MASK;
+	end = address + size;
+	if (end > PMD_SIZE)
+		end = PMD_SIZE;
+
+	do {
+		pte_t page;
+		page = ptep_get_and_clear(pte);
+		address += PAGE_SIZE;
+		pte++;
+		if (pte_none(page))
+			continue;
+		if (pte_present(page))
+			continue;
+		printk(KERN_CRIT "Whee.. Swapped out page in kernel page table\n");
+	} while (address < end);
+}
+
+static void unmap_im_area_pmd(pgd_t *dir, unsigned long address,
+				  unsigned long size)
+{
+	unsigned long end;
+	pmd_t *pmd;
+
+	if (pgd_none(*dir))
+		return;
+	if (pgd_bad(*dir)) {
+		pgd_ERROR(*dir);
+		pgd_clear(dir);
+		return;
+	}
+
+	pmd = pmd_offset(dir, address);
+	address &= ~PGDIR_MASK;
+	end = address + size;
+	if (end > PGDIR_SIZE)
+		end = PGDIR_SIZE;
+
+	do {
+		unmap_im_area_pte(pmd, address, end - address);
+		address = (address + PMD_SIZE) & PMD_MASK;
+		pmd++;
+	} while (address < end);
+}
+
+/*  
+ * Unmap an IO region and remove it from imalloc'd list.
+ * Access to IO memory should be serialized by driver.
+ * This code is modeled after vmalloc code - unmap_vm_area()
+ *
+ * XXX	what about calls before mem_init_done (ie python_countermeasures())	
+ */
+void pSeries_iounmap(void *addr)
+{
+	unsigned long address, start, end, size;
+	struct mm_struct *mm;
+	pgd_t *dir;
+
+	if (!mem_init_done) {
+		return;
+	}
+	
+	/* addr could be in EEH or IO region, map it to IO region regardless.
+	 */
+	addr = (void *) (IO_TOKEN_TO_ADDR(addr) & PAGE_MASK);
+	
+	if ((size = im_free(addr)) == 0) {
+		return;
+	}
+
+	address = (unsigned long)addr; 
+	start = address;
+	end = address + size;
+
+	mm = &ioremap_mm;
+	spin_lock(&mm->page_table_lock);
+
+	dir = pgd_offset_i(address);
+	flush_cache_all();
+	do {
+		unmap_im_area_pmd(dir, address, end - address);
+		address = (address + PGDIR_SIZE) & PGDIR_MASK;
+		dir++;
+	} while (address && (address < end));
+	__flush_tlb_range(mm, start, end);
+
+	spin_unlock(&mm->page_table_lock);
+	return;
 }
 
 void iounmap(void *addr) 
@@ -186,10 +325,52 @@ void iounmap(void *addr) 
 	return;
 #else
 	/* DRENG / PPPBBB todo */
-	return;
+	return pSeries_iounmap(addr);
 #endif
 }
 
+int iounmap_explicit(void *addr, unsigned long size)
+{
+	struct vm_struct *area;
+	
+	/* addr could be in EEH or IO region, map it to IO region regardless.
+	 */
+	addr = (void *) (IO_TOKEN_TO_ADDR(addr) & PAGE_MASK);
+
+	/* Verify that the region either exists or is a subset of an existing
+	 * region.  In the latter case, split the parent region to create 
+	 * the exact region 
+	 */
+	area = im_get_area((unsigned long) addr, size, 
+			    IM_REGION_EXISTS | IM_REGION_SUBSET);
+	if (area == NULL) {
+		printk(KERN_ERR "%s() cannot unmap nonexistant range 0x%lx\n",
+				__FUNCTION__, (unsigned long) addr);
+		return 1;
+	}
+
+	iounmap(area->addr);
+	return 0;
+}
+
+static void * __ioremap_com(unsigned long addr, unsigned long pa, 
+			    unsigned long ea, unsigned long size, 
+			    unsigned long flags)
+{
+	unsigned long i;
+	
+	if ((flags & _PAGE_PRESENT) == 0)
+		flags |= pgprot_val(PAGE_KERNEL);
+	if (flags & (_PAGE_NO_CACHE | _PAGE_WRITETHRU))
+		flags |= _PAGE_GUARDED;
+
+	for (i = 0; i < size; i += PAGE_SIZE) {
+		map_io_page(ea+i, pa+i, flags);
+	}
+
+	return (void *) (ea + (addr & ~PAGE_MASK));
+}
+
 /*
  * map_io_page currently only called by __ioremap
  * map_io_page adds an entry to the ioremap page table
@@ -727,6 +908,19 @@ void update_mmu_cache(struct vm_area_str
 		    0x300, local);
 }
 
+void * reserve_phb_iospace(unsigned long size)
+{
+	void *virt_addr;
+		
+	if (phbs_io_bot >= IMALLOC_BASE) 
+		panic("reserve_phb_iospace(): phb io space overflow\n");
+			
+	virt_addr = (void *) phbs_io_bot;
+	phbs_io_bot += size;
+
+	return virt_addr;
+}
+
 kmem_cache_t *zero_cache;
 
 static void zero_ctor(void *pte, kmem_cache_t *cache, unsigned long flags)
diff -purN linux-2.5/arch/ppc64/mm/numa.c linuxppc64-2.5/arch/ppc64/mm/numa.c
--- linux-2.5/arch/ppc64/mm/numa.c	2003-09-28 23:26:35.000000000 +0000
+++ linuxppc64-2.5/arch/ppc64/mm/numa.c	2003-10-14 12:26:47.000000000 +0000
@@ -46,29 +46,29 @@ static inline void map_cpu_to_node(int c
 
 static int __init parse_numa_properties(void)
 {
-	struct device_node *cpu;
-	struct device_node *memory;
+	struct device_node *cpu = NULL;
+	struct device_node *memory = NULL;
 	int *cpu_associativity;
 	int *memory_associativity;
 	int depth;
 	int max_domain = 0;
 
-	cpu = find_type_devices("cpu");
+	cpu = of_find_node_by_type(NULL, "cpu");
 	if (!cpu)
-		return -1;
+		goto err;
 
-	memory = find_type_devices("memory");
+	memory = of_find_node_by_type(NULL, "memory");
 	if (!memory)
-		return -1;
+		goto err;
 
 	cpu_associativity = (int *)get_property(cpu, "ibm,associativity", NULL);
 	if (!cpu_associativity)
-		return -1;
+		goto err;
 
 	memory_associativity = (int *)get_property(memory, "ibm,associativity",
 						   NULL);
 	if (!memory_associativity)
-		return -1;
+		goto err;
 
 	/* find common depth */
 	if (cpu_associativity[0] < memory_associativity[0])
@@ -76,7 +76,7 @@ static int __init parse_numa_properties(
 	else
 		depth = memory_associativity[0];
 
-	for (cpu = find_type_devices("cpu"); cpu; cpu = cpu->next) {
+	for (; cpu; cpu = of_find_node_by_type(cpu, "cpu")) {
 		int *tmp;
 		int cpu_nr, numa_domain;
 
@@ -106,8 +106,7 @@ static int __init parse_numa_properties(
 		map_cpu_to_node(cpu_nr, numa_domain);
 	}
 
-	for (memory = find_type_devices("memory"); memory;
-	     memory = memory->next) {
+	for (; memory; memory = of_find_node_by_type(memory, "memory")) {
 		int *tmp1, *tmp2;
 		unsigned long i;
 		unsigned long start = 0;
@@ -196,6 +195,10 @@ new_range:
 	numnodes = max_domain + 1;
 
 	return 0;
+err:
+	of_node_put(cpu);
+	of_node_put(memory);
+	return -1;
 }
 
 void setup_nonnuma(void)
diff -purN linux-2.5/drivers/block/Makefile linuxppc64-2.5/drivers/block/Makefile
--- linux-2.5/drivers/block/Makefile	2003-10-16 04:38:46.000000000 +0000
+++ linuxppc64-2.5/drivers/block/Makefile	2003-11-21 06:45:02.000000000 +0000
@@ -38,3 +38,5 @@ obj-$(CONFIG_BLK_DEV_DAC960)	+= DAC960.o
 obj-$(CONFIG_BLK_DEV_UMEM)	+= umem.o
 obj-$(CONFIG_BLK_DEV_NBD)	+= nbd.o
 obj-$(CONFIG_BLK_DEV_CRYPTOLOOP) += cryptoloop.o
+
+obj-$(CONFIG_VIODASD)		+= viodasd.o
diff -purN linux-2.5/drivers/block/viodasd.c linuxppc64-2.5/drivers/block/viodasd.c
--- linux-2.5/drivers/block/viodasd.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/block/viodasd.c	2003-11-21 05:44:11.000000000 +0000
@@ -0,0 +1,1353 @@
+/* -*- linux-c -*-
+ * viodasd.c
+ *  Authors: Dave Boutcher <boutcher@us.ibm.com>
+ *           Ryan Arnold <ryanarn@us.ibm.com>
+ *           Colin Devilbiss <devilbis@us.ibm.com>
+ *
+ * (C) Copyright 2000 IBM Corporation
+ * 
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of the
+ * License, or (at your option) any later version.
+ * 
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ * 
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA 
+ ***************************************************************************
+ * This routine provides access to disk space (termed "DASD" in historical
+ * IBM terms) owned and managed by an OS/400 partition running on the
+ * same box as this Linux partition.
+ *
+ * All disk operations are performed by sending messages back and forth to 
+ * the OS/400 partition. 
+ * 
+ * This device driver can either use its own major number, or it can
+ * pretend to be an IDE drive (grep 'IDE[0-9]_MAJOR' ../../include/linux/major.h).
+ * This is controlled with a CONFIG option.  You can either call this an
+ * elegant solution to the fact that a lot of software doesn't recognize
+ * a new disk major number...or you can call this a really ugly hack.
+ * Your choice.
+ */
+
+#include <linux/major.h>
+#include <linux/config.h>
+#include <linux/fs.h>
+#include <linux/blkpg.h>
+
+/* Changelog:
+	2001-11-27	devilbis	Added first pass at complete IDE emulation
+	2002-07-07      boutcher        Added randomness
+ */
+
+/* Decide if we are using our own major or pretending to be an IDE drive
+ *
+ * If we are using our own major, we only support 7 partitions per physical
+ * disk....so with minor numbers 0-255 we get a maximum of 32 disks.  If we
+ * are emulating IDE, we get 63 partitions per disk, with a maximum of 4
+ * disks per major, but common practice is to place only 2 devices in /dev
+ * for each IDE major, for a total of 20 (since there are 10 IDE majors).
+ */
+
+#ifdef CONFIG_VIODASD_IDE
+static const int major_table[] = {
+	IDE0_MAJOR,
+	IDE1_MAJOR,
+	IDE2_MAJOR,
+	IDE3_MAJOR,
+	IDE4_MAJOR,
+	IDE5_MAJOR,
+	IDE6_MAJOR,
+	IDE7_MAJOR,
+	IDE8_MAJOR,
+	IDE9_MAJOR,
+};
+enum {
+	DEV_PER_MAJOR = 2,
+	PARTITION_SHIFT = 6,
+};
+static int major_to_index(int major)
+{
+	switch(major) {
+	case IDE0_MAJOR: return 0;
+	case IDE1_MAJOR: return 1;
+	case IDE2_MAJOR: return 2;
+	case IDE3_MAJOR: return 3;
+	case IDE4_MAJOR: return 4;
+	case IDE5_MAJOR: return 5;
+	case IDE6_MAJOR: return 6;
+	case IDE7_MAJOR: return 7;
+	case IDE8_MAJOR: return 8;
+	case IDE9_MAJOR: return 9;
+	default:
+		return -1;
+	}
+}
+#define VIOD_DEVICE_NAME "ide"
+#define VIOD_GENHD_NAME "hd"
+#else				/* !CONFIG_VIODASD_IDE */
+static const int major_table[] = {
+	VIODASD_MAJOR,
+};
+enum {
+	DEV_PER_MAJOR = 32,
+	PARTITION_SHIFT = 3,
+};
+static int major_to_index(int major)
+{
+	if(major != VIODASD_MAJOR)
+		return -1;
+	return 0;
+}
+#define VIOD_DEVICE_NAME "viod"
+#ifdef CONFIG_DEVFS_FS
+#define VIOD_GENHD_NAME "viod"
+#else
+#define VIOD_GENHD_NAME "iseries/vd"
+#endif
+#endif				/* CONFIG_VIODASD_IDE */
+
+#define DEVICE_NR(dev) (devt_to_diskno(dev))
+#define LOCAL_END_REQUEST
+
+#include <linux/sched.h>
+#include <linux/timer.h>
+#include <asm/uaccess.h>
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <linux/blkdev.h>
+#include <linux/genhd.h>
+#include <linux/hdreg.h>
+#include <linux/fd.h>
+#include <linux/buffer_head.h>
+#include <linux/proc_fs.h>
+#include <linux/errno.h>
+#include <linux/init.h>
+#include <linux/vmalloc.h>
+#include <linux/string.h>
+#include <linux/pci.h>
+#include <linux/root_dev.h>
+#include <linux/kdev_t.h>
+
+#include <asm/iSeries/HvTypes.h>
+#include <asm/iSeries/HvLpEvent.h>
+#include <asm/iSeries/HvLpConfig.h>
+#include <asm/iSeries/vio.h>
+#include <asm/iSeries/iSeries_proc.h>
+
+MODULE_DESCRIPTION("iSeries Virtual DASD");
+MODULE_AUTHOR("Dave Boutcher");
+MODULE_LICENSE("GPL");
+
+#define VIODASD_VERS "1.50"
+
+enum {
+	NUM_MAJORS = sizeof(major_table) / sizeof(major_table[0]),
+	MAX_DISKNO = DEV_PER_MAJOR * NUM_MAJORS,
+	MAX_DISK_NAME = 16, /* maximum length of a gendisk->name */
+};
+
+static volatile int	viodasd_max_disk = MAX_DISKNO - 1;
+static spinlock_t	viodasd_spinlock = SPIN_LOCK_UNLOCKED;
+
+static inline int devt_to_diskno(dev_t dev)
+{
+	return major_to_index(MAJOR(dev)) * DEV_PER_MAJOR +
+	    (MINOR(dev) >> PARTITION_SHIFT);
+}
+
+#define VIOMAXREQ	16
+#define VIOMAXBLOCKDMA	12
+
+#define DEVICE_NO(cell)	((struct viodasd_device *)(cell) - &viodasd_devices[0])
+
+extern struct pci_dev *iSeries_vio_dev;
+
+struct openData {
+	u64 mDiskLen;
+	u16 mMaxDisks;
+	u16 mCylinders;
+	u16 mTracks;
+	u16 mSectors;
+	u16 mBytesPerSector;
+};
+
+struct rwData {			// Used during rw
+	u64 mOffset;
+	struct {
+		u32 mToken;
+		u32 reserved;
+		u64 mLen;
+	} dmaInfo[VIOMAXBLOCKDMA];
+};
+
+struct vioblocklpevent {
+	struct HvLpEvent event;
+	u32 mReserved1;
+	u16 mVersion;
+	u16 mSubTypeRc;
+	u16 mDisk;
+	u16 mFlags;
+	union {
+		struct openData openData;
+		struct rwData rwData;
+		struct {
+			u64 changed;
+		} check;
+	} u;
+};
+
+#define vioblockflags_ro   0x0001
+
+enum vioblocksubtype {
+	vioblockopen = 0x0001,
+	vioblockclose = 0x0002,
+	vioblockread = 0x0003,
+	vioblockwrite = 0x0004,
+	vioblockflush = 0x0005,
+	vioblockcheck = 0x0007
+};
+
+static DECLARE_WAIT_QUEUE_HEAD(viodasd_wait);
+struct viodasd_waitevent {
+	struct semaphore *sem;
+	int rc;
+	union {
+		int changed;	/* Used only for check_change */
+		u16 subRC;
+	} data;
+};
+
+static const struct vio_error_entry viodasd_err_table[] = {
+	{ 0x0201, EINVAL, "Invalid Range" },
+	{ 0x0202, EINVAL, "Invalid Token" },
+	{ 0x0203, EIO, "DMA Error" },
+	{ 0x0204, EIO, "Use Error" },
+	{ 0x0205, EIO, "Release Error" },
+	{ 0x0206, EINVAL, "Invalid Disk" },
+	{ 0x0207, EBUSY, "Cant Lock" },
+	{ 0x0208, EIO, "Already Locked" },
+	{ 0x0209, EIO, "Already Unlocked" },
+	{ 0x020A, EIO, "Invalid Arg" },
+	{ 0x020B, EIO, "Bad IFS File" },
+	{ 0x020C, EROFS, "Read Only Device" },
+	{ 0x02FF, EIO, "Internal Error" },
+	{ 0x0000, 0, NULL },
+};
+
+/*
+ * Figure out the biggest I/O request (in sectors) we can accept
+ */
+#define VIODASD_MAXSECTORS (4096 / 512 * VIOMAXBLOCKDMA)
+
+/*
+ * Keep some statistics on what's happening for the PROC file system
+ */
+static struct {
+	long tot;
+	long nobh;
+	long ntce[VIOMAXBLOCKDMA];
+} viod_stats[MAX_DISKNO][2];
+
+/*
+ * Number of disk I/O requests we've sent to OS/400
+ */
+static int num_req_outstanding;
+
+/*
+ * This is our internal structure for keeping track of disk devices
+ */
+struct viodasd_device {
+	int useCount;
+	u16 cylinders;
+	u16 tracks;
+	u16 sectors;
+	u16 bytesPerSector;
+	u64 size;
+	int readOnly;
+        struct request_queue *queue;
+	spinlock_t q_lock;
+        struct gendisk *disk;
+	struct block_device *bdev;
+}	viodasd_devices[MAX_DISKNO];
+
+static struct hd_struct *devt_to_partition(dev_t dev)
+{
+	return viodasd_devices[devt_to_diskno(dev)].disk->
+		part[MINOR(dev) & ((1 << PARTITION_SHIFT) - 1)];
+}
+
+/*
+ * When we get a disk I/O request we take it off the general request queue
+ * and put it here.
+ */
+static LIST_HEAD(reqlist);
+
+/*
+ * Handle reads from the proc file system
+ */
+static int proc_read(char *buf, char **start, off_t offset,
+		     int blen, int *eof, void *data)
+{
+	int len = 0;
+	int i;
+	int j;
+
+#if defined(MODULE)
+	len +=
+	    sprintf(buf + len,
+		    "viod Module opened %d times.  Major number %d\n",
+		    MOD_IN_USE, major_table[0]);
+#endif
+	len +=
+	    sprintf(buf + len, "viod %d possible devices\n", MAX_DISKNO);
+
+	for (i = 0; i < 16; i++) {
+		if (viod_stats[i][0].tot || viod_stats[i][1].tot) {
+			len +=
+			    sprintf(buf + len,
+				    "DISK %2.2d: rd %-10.10ld wr %-10.10ld (no buffer list rd %-10.10ld wr %-10.10ld\n",
+				    i, viod_stats[i][0].tot,
+				    viod_stats[i][1].tot,
+				    viod_stats[i][0].nobh,
+				    viod_stats[i][1].nobh);
+
+			len += sprintf(buf + len, "rd DMA: ");
+
+			for (j = 0; j < VIOMAXBLOCKDMA; j++)
+				len += sprintf(buf + len, " [%2.2d] %ld",
+					       j,
+					       viod_stats[i][0].ntce[j]);
+
+			len += sprintf(buf + len, "\nwr DMA: ");
+
+			for (j = 0; j < VIOMAXBLOCKDMA; j++)
+				len += sprintf(buf + len, " [%2.2d] %ld",
+					       j,
+					       viod_stats[i][1].ntce[j]);
+			len += sprintf(buf + len, "\n");
+		}
+	}
+
+	*eof = 1;
+	return len;
+}
+
+/*
+ * Handle writes to our proc file system
+ */
+static int proc_write(struct file *file, const char *buffer,
+		      unsigned long count, void *data)
+{
+	return count;
+}
+
+/*
+ * setup our proc file system entries
+ */
+void viodasd_proc_init(struct proc_dir_entry *iSeries_proc)
+{
+	struct proc_dir_entry *ent;
+
+	ent = create_proc_entry("viodasd", S_IFREG | S_IRUSR, iSeries_proc);
+	if (!ent)
+		return;
+	ent->nlink = 1;
+	ent->data = NULL;
+	ent->read_proc = proc_read;
+	ent->write_proc = proc_write;
+}
+
+/*
+ * clean up our proc file system entries
+ */
+void viodasd_proc_delete(struct proc_dir_entry *iSeries_proc)
+{
+	remove_proc_entry("viodasd", iSeries_proc);
+}
+
+/*
+ * End a request
+ */
+static void viodasd_end_request(struct request *req, int uptodate,
+		int num_sectors)
+{
+	if (!uptodate)
+		num_sectors = req->current_nr_sectors;
+	if (end_that_request_first(req, uptodate, num_sectors))
+		return;
+        add_disk_randomness(req->rq_disk);
+	end_that_request_last(req);
+}
+
+/*
+ * This rebuilds the partition information for a single disk device
+ */
+static int viodasd_revalidate(struct gendisk *gendisk)
+{
+    struct viodasd_device *device =
+	    (struct viodasd_device *)gendisk->private_data;
+
+    set_capacity(gendisk, device->size >> 9);
+    return 0;
+}
+
+static u16 access_flags(mode_t mode)
+{
+	u16 flags = 0;
+	if (!(mode & FMODE_WRITE))
+		flags |= vioblockflags_ro;
+	return flags;
+}
+
+static void internal_register_disk(int diskno)
+{
+	static int registered[MAX_DISKNO];
+	struct gendisk *gendisk = viodasd_devices[diskno].disk;
+	int i;
+
+	if (registered[diskno])
+		return;
+	registered[diskno] = 1;
+
+	if (diskno == 0) {
+		printk(KERN_INFO_VIO "%s: Currently %d disks connected\n",
+		       VIOD_DEVICE_NAME, (int)viodasd_max_disk + 1);
+		if (viodasd_max_disk > (MAX_DISKNO - 1))
+			printk(KERN_INFO_VIO "Only examining the first %d\n",
+			       MAX_DISKNO);
+	}
+
+	printk(KERN_INFO_VIO
+	       "%s: Disk %2.2d size %dM, sectors %d, heads %d, cylinders %d\n", 
+               VIOD_DEVICE_NAME, diskno,
+	       (int) viodasd_devices[diskno].size >> 20,
+	       (int) viodasd_devices[diskno].sectors,
+	       (int) viodasd_devices[diskno].tracks,
+	       (int) viodasd_devices[diskno].cylinders);
+
+	for (i = 1; i < (1 << PARTITION_SHIFT); ++i) {
+		struct hd_struct *partition = gendisk->part[i - 1];
+		if (partition && partition->nr_sects)
+			printk(KERN_INFO_VIO
+			       "%s: Disk %2.2d partition %2.2d start sector %ld, # sector %ld\n",
+			       VIOD_DEVICE_NAME, diskno, i,
+			       partition->start_sect, partition->nr_sects);
+	}
+}
+
+
+/*
+ * This is the actual open code.  It gets called from the external
+ * open entry point, as well as from the init code when we're figuring
+ * out what disks we have
+ */
+static int internal_open(int device_no, u16 flags)
+{
+	struct gendisk *gendisk;
+	HvLpEvent_Rc hvrc;
+	/* This semaphore is raised in the interrupt handler */
+	DECLARE_MUTEX_LOCKED(Semaphore);
+	struct viodasd_waitevent we = { .sem = &Semaphore };
+
+	/* Check that we are dealing with a valid hosting partition */
+	if (viopath_hostLp == HvLpIndexInvalid) {
+		printk(KERN_WARNING_VIO "Invalid hosting partition\n");
+		return -EIO;
+	}
+
+	/* Send the open event to OS/400 */
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_blockio | vioblockopen,
+			HvLpEvent_AckInd_DoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp),
+			(u64)(unsigned long)&we, VIOVERSION << 16,
+			((u64)device_no << 48) | ((u64)flags << 32), 0, 0, 0);
+	if (hvrc != 0) {
+		printk(KERN_WARNING_VIO "bad rc on signalLpEvent %d\n",
+				(int)hvrc);
+		return -EIO;
+	}
+
+	/* Wait for the interrupt handler to get the response */
+	down(&Semaphore);
+
+	/* Check the return code */
+	if (we.rc != 0) {
+		const struct vio_error_entry *err =
+			vio_lookup_rc(viodasd_err_table, we.data.subRC);
+		/*
+		 * Temporary patch to quiet down the viodasd when drivers
+		 * are probing for drives, especially lvm.  Collin is aware
+		 * and is working on this.
+		 */
+#if 0
+		printk(KERN_WARNING_VIO "bad rc opening disk: %d:0x%04x (%s)\n",
+				(int) we.rc, we.data.subRC, err->msg);
+#endif
+		return -err->errno;
+	}
+	
+	/*
+	 * If this is the first open of this device, update the device
+	 * information.  If this is NOT the first open, assume that it
+	 * isn't changing
+	 */
+	gendisk = viodasd_devices[device_no].disk;
+	if (viodasd_devices[device_no].useCount == 0) {
+		if (viodasd_devices[device_no].size > 0)
+                        set_capacity(gendisk,
+					viodasd_devices[device_no].size >> 9);
+	} else if (get_capacity(gendisk) !=
+			viodasd_devices[device_no].size >> 9)
+		/*
+		 * If the size of the device changed, weird things
+		 * are happening!
+		 */
+		printk(KERN_WARNING_VIO
+		       "disk size change (%d to %d sectors) for device %d\n",
+		       (int)get_capacity(gendisk),
+		       (int)viodasd_devices[device_no].size >> 9, device_no);
+
+	internal_register_disk(device_no);
+
+	/* Bump the use count */
+	viodasd_devices[device_no].useCount++;
+	return 0;
+}
+
+/*
+ * This is the actual release code.  It gets called from the external
+ * release entry point, as well as from the init code when we're figuring
+ * out what disks we have.
+ */
+static int internal_release(int device_no, u16 flags)
+{
+	/* Send the event to OS/400.  We DON'T expect a response */
+	HvLpEvent_Rc hvrc;
+
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_blockio | vioblockclose,
+			HvLpEvent_AckInd_NoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp), 0,
+			VIOVERSION << 16,
+			((u64)device_no << 48) | ((u64)flags << 32), 0, 0, 0);
+	viodasd_devices[device_no].useCount--;
+	if (hvrc != 0) {
+		printk(KERN_WARNING_VIO
+		       "bad rc sending event to OS/400 %d\n", (int)hvrc);
+		return -EIO;
+	}
+	return 0;
+}
+
+
+/*
+ * External open entry point.
+ */
+static int viodasd_open(struct inode *inode, struct file *fil)
+{
+	int device_no;
+	int old_max_disk = viodasd_max_disk;
+
+	/* Do a bunch of sanity checks */
+	if (!inode) {
+		printk(KERN_WARNING_VIO "no inode provided in open\n");
+		return -ENODEV;
+	}
+
+	if (major_to_index(MAJOR(inode->i_rdev)) < 0) {
+		printk(KERN_WARNING_VIO
+		       "Weird error...wrong major number on open\n");
+		return -ENODEV;
+	}
+
+	device_no = DEVICE_NR(inode->i_rdev);
+	if ((device_no > MAX_DISKNO) || (device_no < 0)) {
+		printk(KERN_WARNING_VIO
+		       "Invalid device number %d in open\n", device_no);
+		return -ENODEV;
+	}
+	if (!viodasd_devices[device_no].bdev)
+		viodasd_devices[device_no].bdev = inode->i_bdev;
+
+	/* Call the actual open code */
+	if (internal_open(device_no, access_flags(fil ? fil->f_mode : 0)) == 0) {
+		int i;
+		MOD_INC_USE_COUNT;
+		/* For each new disk: */
+		/* update the disk's geometry via internal_open and register it */
+		for (i = old_max_disk + 1; i <= viodasd_max_disk; ++i) {
+			internal_open(i, vioblockflags_ro);
+			internal_release(i, vioblockflags_ro);
+		}
+		return 0;
+	} else
+		return -EIO;
+}
+
+/* External release entry point.
+ */
+static int viodasd_release(struct inode *ino, struct file *fil)
+{
+	int device_no;
+
+	/* Do a bunch of sanity checks */
+	if (!ino) {
+		printk(KERN_WARNING_VIO "no inode provided in release\n");
+		return -ENODEV;
+	}
+
+	if (major_to_index(MAJOR(ino->i_rdev)) < 0) {
+		printk(KERN_WARNING_VIO
+		       "Weird error...wrong major number on release\n");
+		return -ENODEV;
+	}
+
+	device_no = DEVICE_NR(ino->i_rdev);
+
+	if (device_no > MAX_DISKNO || device_no < 0) {
+		printk(KERN_WARNING_VIO
+		       "Tried to release invalid disk number %d\n", device_no);
+		return -ENODEV;
+	}
+
+	/* Call the actual release code */
+	internal_release(device_no, access_flags(fil ? fil->f_mode : 0));
+
+	MOD_DEC_USE_COUNT;
+	return 0;
+}
+
+/* External ioctl entry point.
+ */
+static int viodasd_ioctl(struct inode *ino, struct file *fil,
+			 unsigned int cmd, unsigned long arg)
+{
+	int device_no;
+	int err;
+	struct hd_struct *partition;
+	DECLARE_MUTEX_LOCKED(Semaphore);
+
+	/* Sanity checks */
+	if (!ino) {
+		printk(KERN_WARNING_VIO "no inode provided in ioctl\n");
+		return -ENODEV;
+	}
+
+	if (major_to_index(MAJOR(ino->i_rdev)) < 0) {
+		printk(KERN_WARNING_VIO
+		       "Weird error...wrong major number on ioctl\n");
+		return -ENODEV;
+	}
+
+	device_no = DEVICE_NR(ino->i_rdev);
+	if (device_no > viodasd_max_disk) {
+		printk(KERN_WARNING_VIO
+		       "Invalid device number %d in ioctl\n", device_no);
+		return -ENODEV;
+	}
+
+	partition = devt_to_partition(ino->i_rdev);
+
+	switch (cmd) {
+	case HDIO_GETGEO:
+	{
+		unsigned char sectors;
+		unsigned char heads;
+		unsigned short cylinders;
+
+		struct hd_geometry *geo =
+		    (struct hd_geometry *) arg;
+		if (geo == NULL)
+			return -EINVAL;
+
+		err = verify_area(VERIFY_WRITE, geo, sizeof(*geo));
+		if (err)
+			return err;
+
+		sectors = viodasd_devices[device_no].sectors;
+		if (sectors == 0)
+			sectors = 32;
+
+		heads = viodasd_devices[device_no].tracks;
+		if (heads == 0)
+			heads = 64;
+
+		cylinders = viodasd_devices[device_no].cylinders;
+		if (cylinders == 0)
+			cylinders =
+			    partition->nr_sects / (sectors *
+						   heads);
+
+		put_user(sectors, &geo->sectors);
+		put_user(heads, &geo->heads);
+		put_user(cylinders, &geo->cylinders);
+
+		put_user(partition->start_sect,
+			 (long *) &geo->start);
+
+		return 0;
+	}
+
+
+#define PRTIOC(x)	\
+	case x: printk(KERN_WARNING_VIO "got unsupported FD ioctl " #x "\n"); \
+                          return -EINVAL;
+	PRTIOC(FDCLRPRM);
+	PRTIOC(FDSETPRM);
+	PRTIOC(FDDEFPRM);
+	PRTIOC(FDGETPRM);
+	PRTIOC(FDMSGON);
+	PRTIOC(FDMSGOFF);
+	PRTIOC(FDFMTBEG);
+	PRTIOC(FDFMTTRK);
+	PRTIOC(FDFMTEND);
+	PRTIOC(FDSETEMSGTRESH);
+	PRTIOC(FDSETMAXERRS);
+	PRTIOC(FDGETMAXERRS);
+	PRTIOC(FDGETDRVTYP);
+	PRTIOC(FDSETDRVPRM);
+	PRTIOC(FDGETDRVPRM);
+	PRTIOC(FDGETDRVSTAT);
+	PRTIOC(FDPOLLDRVSTAT);
+	PRTIOC(FDRESET);
+	PRTIOC(FDGETFDCSTAT);
+	PRTIOC(FDWERRORCLR);
+	PRTIOC(FDWERRORGET);
+	PRTIOC(FDRAWCMD);
+	PRTIOC(FDEJECT);
+	PRTIOC(FDTWADDLE);
+	}
+
+	return -EINVAL;
+}
+
+/*
+ * Send an actual I/O request to OS/400
+ */
+static int send_request(struct request *req)
+{
+	u64 start;
+	int direction;
+	int nsg;
+	u16 viocmd;
+	HvLpEvent_Rc hvrc;
+	struct vioblocklpevent *bevent;
+	struct scatterlist sg[VIOMAXBLOCKDMA];
+	int sgindex;
+	int statindex;
+        int device_no = DEVICE_NO(req->rq_disk->private_data);
+
+	/* More paranoia checks */
+	if ((req->sector + req->nr_sectors) > get_capacity(req->rq_disk)) {
+		printk(KERN_WARNING_VIO "Invalid request offset & length\n");
+		printk(KERN_WARNING_VIO
+				"req->sector: %ld, req->nr_sectors: %ld\n",
+				req->sector, req->nr_sectors);
+		printk(KERN_WARNING_VIO "device: %s\n",
+				req->rq_disk->disk_name);
+		return -1;
+	}
+
+	if (rq_data_dir(req) == READ) {
+		direction = PCI_DMA_FROMDEVICE;
+		viocmd = viomajorsubtype_blockio | vioblockread;
+		statindex = 0;
+	} else {
+		direction = PCI_DMA_TODEVICE;
+		viocmd = viomajorsubtype_blockio | vioblockwrite;
+		statindex = 1;
+	}
+
+	/* Update totals */
+	viod_stats[device_no][statindex].tot++;
+
+	/* Now build the scatter-gather list */
+        nsg = blk_rq_map_sg(req->q, req, sg);
+	nsg = pci_map_sg(iSeries_vio_dev, sg, nsg, direction);
+	/* Update stats */
+	viod_stats[device_no][statindex].ntce[nsg]++;
+
+	/* This optimization handles a single DMA block */
+	if (nsg == 1)
+		hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+				HvLpEvent_Type_VirtualIo,
+				viomajorsubtype_blockio | viocmd,
+				HvLpEvent_AckInd_DoAck,
+				HvLpEvent_AckType_ImmediateAck,
+				viopath_sourceinst(viopath_hostLp),
+				viopath_targetinst(viopath_hostLp),
+				(u64)(unsigned long)req, VIOVERSION << 16,
+				((u64)device_no << 48), start,
+				((u64)sg[0].dma_address) << 32,
+				sg[0].dma_length);
+	else {
+		bevent = (struct vioblocklpevent *)
+			vio_get_event_buffer(viomajorsubtype_blockio);
+		if (bevent == NULL) {
+			printk(KERN_WARNING_VIO
+			       "error allocating disk event buffer\n");
+			return -1;
+		}
+
+		/*
+		 * Now build up the actual request.  Note that we store
+		 * the pointer to the request buffer in the correlation
+		 * token so we can match this response up later
+		 */
+		memset(bevent, 0, sizeof(struct vioblocklpevent));
+		bevent->event.xFlags.xValid = 1;
+		bevent->event.xFlags.xFunction = HvLpEvent_Function_Int;
+		bevent->event.xFlags.xAckInd = HvLpEvent_AckInd_DoAck;
+		bevent->event.xFlags.xAckType = HvLpEvent_AckType_ImmediateAck;
+		bevent->event.xType = HvLpEvent_Type_VirtualIo;
+		bevent->event.xSubtype = viocmd;
+		bevent->event.xSourceLp = HvLpConfig_getLpIndex();
+		bevent->event.xTargetLp = viopath_hostLp;
+		bevent->event.xSizeMinus1 =
+			offsetof(struct vioblocklpevent, u.rwData.dmaInfo) +
+			(sizeof(bevent->u.rwData.dmaInfo[0]) * nsg) - 1;
+		bevent->event.xSourceInstanceId =
+			viopath_sourceinst(viopath_hostLp);
+		bevent->event.xTargetInstanceId =
+			viopath_targetinst(viopath_hostLp);
+		bevent->event.xCorrelationToken = (u64)(unsigned long)req;
+		bevent->mVersion = VIOVERSION;
+		bevent->mDisk = device_no;
+		bevent->u.rwData.mOffset = start;
+
+		/*
+		 * Copy just the dma information from the sg list
+		 * into the request
+		 */
+		for (sgindex = 0; sgindex < nsg; sgindex++) {
+			bevent->u.rwData.dmaInfo[sgindex].mToken =
+				sg[sgindex].dma_address;
+			bevent->u.rwData.dmaInfo[sgindex].mLen =
+				sg[sgindex].dma_length;
+		}
+
+		/* Send the request */
+		hvrc = HvCallEvent_signalLpEvent(&bevent->event);
+		vio_free_event_buffer(viomajorsubtype_blockio, bevent);
+	}
+
+	if (hvrc != HvLpEvent_Rc_Good) {
+		printk(KERN_WARNING_VIO
+		       "error sending disk event to OS/400 (rc %d)\n",
+		       (int)hvrc);
+		return -1;
+	}
+	/* If the request was successful, bump the number of outstanding */
+	num_req_outstanding++;
+	return 0;
+}
+
+/*
+ * This is the external request processing routine
+ */
+static void do_viodasd_request(request_queue_t *q)
+{
+	for (;;) {
+		struct request *req;
+		struct gendisk *gendisk;
+
+		/*
+		 * inlined INIT_REQUEST here because we don't define
+		 * MAJOR_NR before blk.h
+		 */
+                if ((req = elv_next_request(q)) == NULL)
+                	return;
+		/* check that request contains a valid command */
+		if (!blk_fs_request(req)) {
+			viodasd_end_request(req, 0, 0);
+			continue;
+		}
+
+		gendisk = req->rq_disk;
+		if (major_to_index(gendisk->major) < 0)
+			panic(VIOD_DEVICE_NAME ": request list destroyed");
+
+		if (get_capacity(gendisk) == 0) {
+			printk(KERN_WARNING_VIO
+					"Ouch! get_capacity(gendisk) is 0\n");
+			viodasd_end_request(req, 0, 0);
+			continue;
+		}
+
+		/* If the queue is plugged, don't dequeue anything right now */
+		if (blk_queue_plugged(q))
+			return;
+
+		/*
+		 * If we already have the maximum number of requests
+		 * outstanding to OS/400 just bail out. We'll come
+		 * back later.
+		 */
+		if (num_req_outstanding >= VIOMAXREQ)
+			return;
+
+		/* get the current request, then dequeue it from the queue */
+		blkdev_dequeue_request(req);
+
+		/* Try sending the request */
+		if (send_request(req) == 0)
+			list_add_tail(&req->queuelist, &reqlist);
+		else
+			viodasd_end_request(req, 0, 0);
+	}
+}
+
+/*
+ * Check for changed disks
+ */
+static int viodasd_check_change(struct gendisk *gendisk)
+{
+	struct viodasd_waitevent we;
+	HvLpEvent_Rc hvrc;
+	int device_no = major_to_index(gendisk->major);
+
+	/* This semaphore is raised in the interrupt handler */
+	DECLARE_MUTEX_LOCKED(Semaphore);
+
+	/* Check that we are dealing with a valid hosting partition */
+	if (viopath_hostLp == HvLpIndexInvalid) {
+		printk(KERN_WARNING_VIO "Invalid hosting partition\n");
+		return -EIO;
+	}
+
+	we.sem = &Semaphore;
+
+	/* Send the open event to OS/400 */
+	hvrc = HvCallEvent_signalLpEventFast(viopath_hostLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_blockio | vioblockcheck,
+			HvLpEvent_AckInd_DoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(viopath_hostLp),
+			viopath_targetinst(viopath_hostLp),
+			(u64)(unsigned long)&we, VIOVERSION << 16,
+			((u64)device_no << 48), 0, 0, 0);
+	if (hvrc != 0) {
+		printk(KERN_WARNING_VIO "bad rc on signalLpEvent %d\n",
+				(int)hvrc);
+		return -EIO;
+	}
+
+	/* Wait for the interrupt handler to get the response */
+	down(&Semaphore);
+
+	/* Check the return code.  If bad, assume no change */
+	if (we.rc != 0) {
+		printk(KERN_WARNING_VIO
+				"bad rc %d on check_change. Assuming no change\n",
+				(int)we.rc);
+		return 0;
+	}
+
+	return we.data.changed;
+}
+
+/*
+ * Our file operations table
+ */
+static struct block_device_operations viodasd_fops = {
+	.open = viodasd_open,
+	.release = viodasd_release,
+	.ioctl = viodasd_ioctl,
+	.media_changed = viodasd_check_change,
+	.revalidate_disk = viodasd_revalidate
+};
+
+/* returns the total number of scatterlist elements converted */
+static int block_event_to_scatterlist(const struct vioblocklpevent *bevent,
+		struct scatterlist *sg, int *total_len)
+{
+	int i, numsg;
+	const struct rwData *rwData = &bevent->u.rwData;
+	static const int offset =
+		offsetof(struct vioblocklpevent, u.rwData.dmaInfo);
+	static const int element_size = sizeof(rwData->dmaInfo[0]);
+
+	numsg = ((bevent->event.xSizeMinus1 + 1) - offset) / element_size;
+	if (numsg > VIOMAXBLOCKDMA)
+		numsg = VIOMAXBLOCKDMA;
+
+	*total_len = 0;
+	memset(sg, 0, sizeof(sg[0]) * VIOMAXBLOCKDMA);
+
+	for (i = 0; (i < numsg) && (rwData->dmaInfo[i].mLen > 0); ++i) {
+		sg[i].dma_address = rwData->dmaInfo[i].mToken;
+		sg[i].dma_length = rwData->dmaInfo[i].mLen;
+		*total_len += rwData->dmaInfo[i].mLen;
+	}
+	return i;
+}
+
+static struct request *find_request_with_token(u64 token)
+{
+	struct request *req = blkdev_entry_to_request(reqlist.next);
+	while ((&req->queuelist != &reqlist) &&
+	       ((u64) (unsigned long)req != token))
+		req = blkdev_entry_to_request(req->queuelist.next);
+	if (&req->queuelist == &reqlist)
+		return NULL;
+	return req;
+}
+
+/*
+ * Restart all queues, starting with the one _after_ the major given,
+ * thus reducing the chance of starvation of disks with late majors.
+ */
+static void viodasd_restart_all_queues_starting_from(int first_major)
+{
+	int i, first_index = major_to_index(first_major);
+	for(i = first_index + 1; i < NUM_MAJORS; ++i)
+		do_viodasd_request(viodasd_devices[i].queue);
+	for(i = 0; i <= first_index; ++i)
+		do_viodasd_request(viodasd_devices[i].queue);
+}
+
+/*
+ * For read and write requests, decrement the number of outstanding requests,
+ * Free the DMA buffers we allocated, and find the matching request by
+ * using the buffer pointer we stored in the correlation token.
+ */
+static int viodasd_handleReadWrite(struct vioblocklpevent *bevent)
+{
+	int num_sg, num_sect, pci_direction, total_len, major;
+	struct request *req;
+	struct scatterlist sg[VIOMAXBLOCKDMA];
+	struct HvLpEvent *event = &bevent->event;
+	unsigned long irq_flags;
+
+	num_sg = block_event_to_scatterlist(bevent, sg, &total_len);
+	num_sect = total_len >> 9;
+	if (event->xSubtype == (viomajorsubtype_blockio | vioblockread))
+		pci_direction = PCI_DMA_FROMDEVICE;
+	else
+		pci_direction = PCI_DMA_TODEVICE;
+	pci_unmap_sg(iSeries_vio_dev, sg, num_sg, pci_direction);
+
+
+	/*
+	 * Since this is running in interrupt mode, we need to make sure
+	 * we're not stepping on any global I/O operations
+	 */
+	spin_lock_irqsave(&viodasd_spinlock, irq_flags);
+
+	num_req_outstanding--;
+
+	/*
+	 * Now find the matching request in OUR list (remember we moved
+	 * the request from the global list to our list when we got it)
+	 */
+	req = find_request_with_token(bevent->event.xCorrelationToken);
+	if (req == NULL) {
+		printk(KERN_WARNING_VIO
+		       "Yikes! No request matching 0x%lx found\n",
+		       bevent->event.xCorrelationToken);
+		spin_unlock_irqrestore(&viodasd_spinlock, irq_flags);
+		return -1;
+	}
+
+	/* Remove the request from our list */
+	list_del_init(&req->queuelist);
+	major = req->rq_disk->major;
+
+	if (event->xRc != HvLpEvent_Rc_Good) {
+		const struct vio_error_entry *err;
+		err = vio_lookup_rc(viodasd_err_table, bevent->mSubTypeRc);
+		printk(KERN_WARNING_VIO "read/write error %d:0x%04x (%s)\n",
+				event->xRc, bevent->mSubTypeRc, err->msg);
+		viodasd_end_request(req, 0, 0);
+	} else {
+		if (num_sect != req->current_nr_sectors)
+			printk(KERN_WARNING_VIO
+			       "Yikes...# sect doesn't match %d %d!!!\n",
+			       num_sect, req->current_nr_sectors);
+		viodasd_end_request(req, 1, num_sect);
+	}
+
+	/* Finally, try to get more requests off of this device's queue */
+	viodasd_restart_all_queues_starting_from(major);
+
+	spin_unlock_irqrestore(&viodasd_spinlock, irq_flags);
+
+	return 0;
+}
+
+/* This routine handles incoming block LP events */
+static void vioHandleBlockEvent(struct HvLpEvent *event)
+{
+	struct vioblocklpevent *bevent = (struct vioblocklpevent *)event;
+	struct viodasd_waitevent *pwe;
+
+	if (event == NULL)
+		/* Notification that a partition went away! */
+		return;
+	/* First, we should NEVER get an int here...only acks */
+	if (event->xFlags.xFunction == HvLpEvent_Function_Int) {
+		printk(KERN_WARNING_VIO
+		       "Yikes! got an int in viodasd event handler!\n");
+		if (event->xFlags.xAckInd == HvLpEvent_AckInd_DoAck) {
+			event->xRc = HvLpEvent_Rc_InvalidSubtype;
+			HvCallEvent_ackLpEvent(event);
+		}
+	}
+
+	switch (event->xSubtype & VIOMINOR_SUBTYPE_MASK) {
+	case vioblockopen:
+		/*
+		 * Handle a response to an open request.  We get all the
+		 * disk information in the response, so update it.  The
+		 * correlation token contains a pointer to a waitevent
+		 * structure that has a semaphore in it.  update the
+		 * return code in the waitevent structure and post the
+		 * semaphore to wake up the guy who sent the request
+		 */
+		pwe = (struct viodasd_waitevent *)(unsigned long)event->
+			xCorrelationToken;
+		pwe->rc = event->xRc;
+		pwe->data.subRC = bevent->mSubTypeRc;
+		if (event->xRc == HvLpEvent_Rc_Good) {
+			const struct openData *data = &bevent->u.openData;
+			struct viodasd_device *device =
+				&viodasd_devices[bevent->mDisk];
+			device->readOnly =
+				bevent->mFlags & vioblockflags_ro;
+			device->size = data->mDiskLen;
+			device->cylinders = data->mCylinders;
+			device->tracks = data->mTracks;
+			device->sectors = data->mSectors;
+			device->bytesPerSector = data->mBytesPerSector;
+			viodasd_max_disk = data->mMaxDisks;
+		}
+		up(pwe->sem);
+		break;
+	case vioblockclose:
+		break;
+	case vioblockcheck:
+		pwe = (struct viodasd_waitevent *)(unsigned long)event->
+			xCorrelationToken;
+		pwe->rc = event->xRc;
+		pwe->data.changed = bevent->u.check.changed;
+		up(pwe->sem);
+		break;
+	case vioblockflush:
+		up((void *)(unsigned long)event->xCorrelationToken);
+		break;
+	case vioblockread:
+	case vioblockwrite:
+		viodasd_handleReadWrite(bevent);
+		break;
+
+	default:
+		printk(KERN_WARNING_VIO "invalid subtype!");
+		if (event->xFlags.xAckInd == HvLpEvent_AckInd_DoAck) {
+			event->xRc = HvLpEvent_Rc_InvalidSubtype;
+			HvCallEvent_ackLpEvent(event);
+		}
+	}
+}
+
+static const char *major_name(int major)
+{
+	static char major_names[NUM_MAJORS][MAX_DISK_NAME];
+	int index = major_to_index(major);
+
+	if (index < 0)
+		return NULL;
+	if (major_names[index][0] == '\0') {
+		if (index == 0)
+			strcpy(major_names[index], VIOD_GENHD_NAME);
+		else
+			sprintf(major_names[index], VIOD_GENHD_NAME"%d", index);
+	}
+	return major_names[index];
+}
+
+static const char *disk_names(int diskno)
+{
+        static char name[MAX_DISK_NAME];
+        char suffix[MAX_DISK_NAME];
+        int idx = 0;
+        int i, j;
+
+        /* convert the disk number to a letter(s) */
+        /* 0=a 25=z 26=aa 27=a, ....              */
+        do {
+                suffix[idx++] = 'a' + (diskno % 26);
+                diskno /= 26;
+        } while (diskno-- && (idx < MAX_DISK_NAME - 1));
+
+        suffix[idx] = 0;
+        /* reverse the array */
+        for (i = 0, j = idx - 1; i < j; i++, j--) {
+                char c = suffix[i];
+		suffix[i] = suffix[j];
+		suffix[j] = c;
+	}
+
+        /* put the name all together and return it */
+        snprintf(name, MAX_DISK_NAME, "%s%s", VIOD_GENHD_NAME, suffix);
+        return name;
+}
+
+
+static void viodasd_cleanup_major(int major)
+{
+	int i;
+
+        for (i = 0; i < DEV_PER_MAJOR; i++) {
+		int device_no = DEV_PER_MAJOR * major_to_index(major) + i;
+
+		blk_cleanup_queue(viodasd_devices[device_no].disk->queue);
+		del_gendisk(viodasd_devices[device_no].disk);
+		put_disk(viodasd_devices[device_no].disk);
+		kfree(viodasd_devices[device_no].disk);
+		unregister_blkdev(major, major_name(major));
+		viodasd_devices[device_no].disk = NULL;
+	}
+}
+
+/* in case of bad return code, caller must cleanup2() for this device */
+static int __init viodasd_init_major(int major)
+{
+	struct gendisk *gendisk;
+	int i;
+
+        /* register the block device */
+	if (register_blkdev(major, major_name(major))) {
+		printk(KERN_WARNING "Unable to get major number %s\n",
+				major_name(major));
+		return -1;
+	}
+	for (i = 0; i < DEV_PER_MAJOR; i++) {
+		int deviceno = DEV_PER_MAJOR * major_to_index(major) + i;
+
+		/* create the request queue for the disk */
+		spin_lock_init(&viodasd_devices[deviceno].q_lock);
+		viodasd_devices[deviceno].queue =
+			blk_init_queue(do_viodasd_request,
+				&viodasd_devices[deviceno].q_lock);
+		if (viodasd_devices[deviceno].queue == NULL)
+			return -ENOMEM;
+
+		/* inialize the struct */
+        	gendisk = alloc_disk(1 << PARTITION_SHIFT);
+		if (gendisk == NULL)
+			return -ENOMEM;
+        	viodasd_devices[deviceno].disk = gendisk;
+		gendisk->major = major;
+        	gendisk->first_minor= i * (1 << PARTITION_SHIFT);
+        	strncpy(gendisk->disk_name, disk_names(deviceno),
+				MAX_DISK_NAME);
+        	strncpy(gendisk->devfs_name, disk_names(deviceno),
+				MAX_DISK_NAME);
+        	gendisk->fops = &viodasd_fops;
+		gendisk->queue = viodasd_devices[deviceno].queue;
+		gendisk->flags = 0;
+        	gendisk->private_data = (void *)&viodasd_devices[deviceno];
+		/* to be assigned later */
+		set_capacity(gendisk, 0);
+	
+		/* register us in the global list */
+		add_disk(gendisk);
+	}
+
+	return 0;
+}
+
+/*
+ * Initialize the whole device driver.  Handle module and non-module
+ * versions
+ */
+static int __init viodasd_init(void)
+{
+	int i, j;
+
+	/* Try to open to our host lp */
+	if (viopath_hostLp == HvLpIndexInvalid)
+		vio_set_hostlp();
+
+	if (viopath_hostLp == HvLpIndexInvalid) {
+		printk(KERN_WARNING_VIO "%s: invalid hosting partition\n",
+		       VIOD_DEVICE_NAME);
+		return -EIO;
+	}
+
+	printk(KERN_INFO_VIO
+	       "%s: Disk vers %s, major %d, max disks %d, hosting partition %d\n",
+	       VIOD_DEVICE_NAME, VIODASD_VERS, major_table[0], MAX_DISKNO,
+	       viopath_hostLp);
+
+	/* Actually open the path to the hosting partition */
+	if (viopath_open(viopath_hostLp, viomajorsubtype_blockio,
+				VIOMAXREQ + 2)) {
+		printk(KERN_WARNING_VIO
+		       "error opening path to host partition %d\n",
+		       viopath_hostLp);
+		return -EIO;
+	} else
+		printk("%s: opened path to hosting partition %d\n",
+		       VIOD_DEVICE_NAME, viopath_hostLp);
+
+	/*
+	 * Initialize our request handler
+	 */
+	vio_setHandler(viomajorsubtype_blockio, vioHandleBlockEvent);
+
+	for (i = 0; i < NUM_MAJORS; ++i) {
+		int init_rc = viodasd_init_major(major_table[i]);
+		if (init_rc < 0) {
+			for (j = 0; j <= i; ++j)
+				viodasd_cleanup_major(major_table[j]);
+			return init_rc;
+		}
+	}
+
+	viodasd_max_disk = MAX_DISKNO - 1;
+	for (i = 0; (i <= viodasd_max_disk) && (i < MAX_DISKNO); i++) {
+		// Note that internal_open has side effects:
+		//  a) it updates the size of the disk
+		//  b) it updates viodasd_max_disk
+		//  c) it registers the disk if it has not done so already
+		if (internal_open(i, vioblockflags_ro) == 0)
+			internal_release(i, vioblockflags_ro);
+	}
+
+	/* 
+	 * Create the proc entry
+	 */
+	iSeries_proc_callback(&viodasd_proc_init);
+
+	return 0;
+}
+module_init(viodasd_init);
+
+#if 0
+void viodasd_exit(void)
+{
+	int i;
+	for(i = 0; i < NUM_MAJORS; ++i)
+		viodasd_cleanup_major(major_table[i]);
+
+	CLEANIT(viodasd_devices);
+
+	viopath_close(viopath_hostLp, viomajorsubtype_blockio, VIOMAXREQ + 2);
+	iSeries_proc_callback(&viodasd_proc_delete);
+
+}
+
+module_exit(viodasd_exit);
+#endif
diff -purN linux-2.5/drivers/char/Makefile linuxppc64-2.5/drivers/char/Makefile
--- linux-2.5/drivers/char/Makefile	2003-10-22 05:10:32.000000000 +0000
+++ linuxppc64-2.5/drivers/char/Makefile	2003-11-21 06:45:02.000000000 +0000
@@ -43,6 +43,7 @@ obj-$(CONFIG_SH_SCI)		+= sh-sci.o generi
 obj-$(CONFIG_HVC_CONSOLE)	+= hvc_console.o
 obj-$(CONFIG_RAW_DRIVER)	+= raw.o
 obj-$(CONFIG_SGI_L1_SERIAL)	+= sn_serial.o
+obj-$(CONFIG_VIOCONS) += viocons.o
 
 obj-$(CONFIG_PRINTER) += lp.o
 obj-$(CONFIG_TIPAR) += tipar.o
diff -purN linux-2.5/drivers/char/viocons.c linuxppc64-2.5/drivers/char/viocons.c
--- linux-2.5/drivers/char/viocons.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/char/viocons.c	2003-11-21 05:44:15.000000000 +0000
@@ -0,0 +1,1343 @@
+/* -*- linux-c -*-
+ *
+ *  drivers/char/viocons.c
+ *
+ *  iSeries Virtual Terminal
+ *
+ *  Authors: Dave Boutcher <boutcher@us.ibm.com>
+ *           Ryan Arnold <ryanarn@us.ibm.com>
+ *           Colin Devilbiss <devilbis@us.ibm.com>
+ *
+ * (C) Copyright 2000, 2001, 2002, 2003 IBM Corporation
+ *
+ * This program is free software;  you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of the
+ * License, or (at your option) anyu later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software Foundation,
+ * Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ */
+#include <linux/config.h>
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/proc_fs.h>
+#include <linux/errno.h>
+#include <linux/vmalloc.h>
+#include <linux/mm.h>
+#include <linux/console.h>
+#include <linux/module.h>
+#include <asm/uaccess.h>
+#include <linux/init.h>
+#include <linux/wait.h>
+#include <linux/spinlock.h>
+#include <asm/ioctls.h>
+#include <linux/kd.h>
+#include <linux/tty.h>
+
+#include <asm/iSeries/vio.h>
+
+#include <asm/iSeries/HvLpEvent.h>
+#include <asm/iSeries/HvCallEvent.h>
+#include <asm/iSeries/HvLpConfig.h>
+#include <asm/iSeries/HvCall.h>
+
+/* Check that the tty_driver_data actually points to our stuff
+ */
+#define VIOTTY_PARANOIA_CHECK 1
+#define VIOTTY_MAGIC (0x0DCB)
+
+static DECLARE_WAIT_QUEUE_HEAD(viocons_wait_queue);
+
+#define VTTY_PORTS 10
+#define VIOTTY_SERIAL_START 65
+
+static u64 sndMsgSeq[VTTY_PORTS];
+static u64 sndMsgAck[VTTY_PORTS];
+
+static spinlock_t consolelock = SPIN_LOCK_UNLOCKED;
+
+/*
+ * The structure of the events that flow between us and OS/400.  You can't
+ * mess with this unless the OS/400 side changes too
+ */
+struct viocharlpevent {
+	struct HvLpEvent event;
+	u32 reserved;
+	u16 version;
+	u16 subtype_result_code;
+	u8 virtual_device;
+	u8 len;
+	u8 data[VIOCHAR_MAX_DATA];
+};
+
+#define VIOCHAR_WINDOW		10
+#define VIOCHAR_HIGHWATERMARK	3
+
+enum viocharsubtype {
+	viocharopen = 0x0001,
+	viocharclose = 0x0002,
+	viochardata = 0x0003,
+	viocharack = 0x0004,
+	viocharconfig = 0x0005
+};
+
+enum viochar_rc {
+	viochar_rc_ebusy = 1
+};
+
+/* When we get writes faster than we can send it to the partition,
+ * buffer the data here.  There is one set of buffers for each virtual
+ * port.
+ * Note that used is a bit map of used buffers.
+ * It had better have enough bits to hold NUM_BUF
+ * the bitops assume it is a multiple of unsigned long
+ */
+#define NUM_BUF (8)
+#define OVERFLOW_SIZE VIOCHAR_MAX_DATA
+
+static struct overflow_buffer {
+	unsigned long used;
+	u8 *buffer[NUM_BUF];
+	int bufferBytes[NUM_BUF];
+	int curbuf;
+	int bufferOverflow;
+	int overflowMessage;
+} overflow[VTTY_PORTS];
+
+static struct tty_driver viotty_driver;
+static struct tty_driver viottyS_driver;
+
+static struct termios *viotty_termios[VTTY_PORTS];
+static struct termios *viottyS_termios[VTTY_PORTS];
+static struct termios *viotty_termios_locked[VTTY_PORTS];
+static struct termios *viottyS_termios_locked[VTTY_PORTS];
+
+void hvlog(char *fmt, ...)
+{
+	int i;
+	static char buf[256];
+	va_list args;
+
+	va_start(args, fmt);
+	i = vsnprintf(buf, sizeof(buf) - 1, fmt, args);
+	va_end(args);
+	buf[i++] = '\r';
+	HvCall_writeLogBuffer(buf, i);
+
+}
+
+/* Our port information.  We store a pointer to one entry in the
+ * tty_driver_data
+ */
+static struct port_info_tag {
+	int magic;
+	struct tty_struct *tty;
+	HvLpIndex lp;
+	u8 vcons;
+	u8 port;
+} port_info[VTTY_PORTS];
+
+/*
+ * Make sure we're pointing to a valid port_info structure.  Shamelessly
+ * plagerized from serial.c
+ */
+static inline int viotty_paranoia_check(struct port_info_tag *pi,
+					char *name, const char *routine)
+{
+#ifdef VIOTTY_PARANOIA_CHECK
+	static const char *badmagic = KERN_WARNING
+		"Warning: bad magic number for port_info struct (%s) in %s\n";
+	static const char *badinfo = KERN_WARNING
+		"Warning: null port_info for (%s) in %s\n";
+
+	if (!pi) {
+		printk(badinfo, name, routine);
+		return 1;
+	}
+	if (pi->magic != VIOTTY_MAGIC) {
+		printk(badmagic, name, routine);
+		return 1;
+	}
+#endif
+	return 0;
+}
+
+/*
+ * Add data to our pending-send buffers.  
+ *
+ * NOTE: Don't use printk in here because it gets nastily recursive.
+ * hvlog can be used to log to the hypervisor buffer
+ */
+static int buffer_add(u8 port, const char *buf, size_t len, int userFlag)
+{
+	size_t bleft = len;
+	size_t curlen;
+	char *cbuf = (char *) buf;
+	int nextbuf;
+	unsigned long flags;
+	struct overflow_buffer *pov = &overflow[port];
+
+	while (bleft > 0) {
+		/*
+		 * Addition 05/01/2003 by Ryan Arnold :  If we are going
+		 * to have to copy_from_user() and the current buffer is
+		 * already partially filled then we want to increment to
+		 * the next buffer and try to see if that one is
+		 * completely empty instead.  This is OK since, if
+		 * pov->curbuf is being used when we hit this it probably
+		 * means that it was filled last iteration or last time
+		 * this function was called.
+		 */
+		if (userFlag && (test_bit(pov->curbuf, &pov->used) != 0)) {
+			nextbuf = (pov->curbuf + 1) % NUM_BUF;
+			pov->curbuf = nextbuf;
+			/*
+			 * In the following case should the next buffer be
+			 * used then we don't want to add to it and we'll
+			 * kick out an error message to the hvlog.
+			 */
+			if (test_bit(pov->curbuf, &pov->used) != 0) {
+				hvlog("No overflow buffers available for copy_from_user().\n");
+				pov->bufferOverflow++;
+				pov->overflowMessage = 1;
+				return len - bleft;
+			}
+		}
+
+		/*
+		 * If there is no space left in the current buffer, we have
+		 * filled everything up, so return.  If we filled the previous
+		 * buffer we would already have moved to the next one.
+		 * If userFlag, then we'll never hit this code branch
+		 * unless the buffer is empty, at which point we'll step
+		 * over it.
+		 */
+		if (pov->bufferBytes[pov->curbuf] == OVERFLOW_SIZE) {
+			hvlog("No overflow buffer available for memcpy().\n",
+					pov->curbuf);
+			pov->bufferOverflow++;
+			pov->overflowMessage = 1;
+			return len - bleft;
+		}
+
+		/*
+		 * See if this buffer has been allocated.  If not, allocate it
+		 */
+		if (pov->buffer[pov->curbuf] == NULL) {
+			pov->buffer[pov->curbuf] =
+			    kmalloc(OVERFLOW_SIZE, GFP_ATOMIC);
+			if (pov->buffer[pov->curbuf] == NULL) {
+				hvlog("kmalloc failed allocating space for buffer %d.\n",
+						pov->curbuf);
+				return len - bleft;
+			}
+		}
+
+		/*
+		 * Addition 05/01/2003 by Ryan Arnold :  Copy the data
+		 * into the buffer.  Since we don't want to hold a
+		 * spinlock during a copy_from_user() operation we won't.
+		 * This also means that we can't copy into partially used
+		 * buffers because we may be interrupted between the
+		 * copy_from_user() invocation and the grab of the
+		 * spinlock by a call to send_buffers() which would throw
+		 * the bufferBytes field for pov->curbuf out of whack
+		 * resulting in the wrong data being output.  If we
+		 * aren'te executing copy_from_user() we can hold a
+		 * spinlock and execute memcpy() and protect the
+		 * bufferBytes[] updated, and used operation all at
+		 * once without fear of interrupt, meaning we can copy
+		 * into partially used buffers.
+		 */
+		if (userFlag) {
+			curlen = OVERFLOW_SIZE - pov->bufferBytes[pov->curbuf];
+			if (curlen != OVERFLOW_SIZE) {
+				/*
+				 * This should never happen but if it does we
+				 * want to know about it.
+				 */
+				hvlog("During userFlag, curlen != OVERFLOW_SIZE.\n");
+			}
+			copy_from_user(pov->buffer[pov->curbuf] +
+				       pov->bufferBytes[pov->curbuf], cbuf,
+				       curlen);
+			spin_lock_irqsave(&consolelock, flags);
+		} else {
+			spin_lock_irqsave(&consolelock, flags);
+			/*
+			 * Figure out how much we can copy into this buffer.
+			 */
+			if (bleft <
+			    (OVERFLOW_SIZE - pov->bufferBytes[pov->curbuf]))
+				curlen = bleft;
+			else
+				curlen = OVERFLOW_SIZE -
+				    pov->bufferBytes[pov->curbuf];
+
+			memcpy(pov->buffer[pov->curbuf] +
+			       pov->bufferBytes[pov->curbuf], cbuf,
+			       curlen);
+		}
+
+		pov->bufferBytes[pov->curbuf] += curlen;
+		cbuf += curlen;
+		bleft -= curlen;
+
+		/*
+		 * Turn on the "used" bit for this buffer.  If it's
+		 * already on, that's fine.  It won't be on for userFlag
+		 * and needs to be set because an interrupt by
+		 * send_buffers() could have turned it off between our
+		 * copy_from_user() and spin_lock_irqsave() calls.
+		 */
+		set_bit(pov->curbuf, &pov->used);
+
+		/*
+		 * Now see if we've filled this buffer.  If not then
+		 * we'll try to use it again later.  If we've filled it
+		 * up then we'll advance the curbuf to the next in the
+		 * circular queue.
+		 */
+		if (pov->bufferBytes[pov->curbuf] == OVERFLOW_SIZE) {
+			nextbuf = (pov->curbuf + 1) % NUM_BUF;
+			/*
+			 * Move to the next buffer if it hasn't been used yet
+			 */
+			if (test_bit(nextbuf, &pov->used) == 0)
+				pov->curbuf = nextbuf;
+		}
+		spin_unlock_irqrestore(&consolelock, flags);
+	}
+	return len;
+}
+
+/*
+ * Initialize the common fields in a charLpEvent
+ */
+static void initDataEvent(struct viocharlpevent *viochar, HvLpIndex lp)
+{
+	memset(viochar, 0, sizeof(struct viocharlpevent));
+
+	viochar->event.xFlags.xValid = 1;
+	viochar->event.xFlags.xFunction = HvLpEvent_Function_Int;
+	viochar->event.xFlags.xAckInd = HvLpEvent_AckInd_NoAck;
+	viochar->event.xFlags.xAckType = HvLpEvent_AckType_DeferredAck;
+	viochar->event.xType = HvLpEvent_Type_VirtualIo;
+	viochar->event.xSubtype = viomajorsubtype_chario | viochardata;
+	viochar->event.xSourceLp = HvLpConfig_getLpIndex();
+	viochar->event.xTargetLp = lp;
+	viochar->event.xSizeMinus1 = sizeof(struct viocharlpevent);
+	viochar->event.xSourceInstanceId = viopath_sourceinst(lp);
+	viochar->event.xTargetInstanceId = viopath_targetinst(lp);
+}
+
+/*
+ * Send pending data
+ *
+ * NOTE: Don't use printk in here because it gets nastily recursive.
+ * hvlog can be used to log to the hypervisor buffer
+ */
+static void send_buffers(u8 port, HvLpIndex lp)
+{
+	HvLpEvent_Rc hvrc;
+	int nextbuf;
+	struct viocharlpevent *viochar;
+	unsigned long flags;
+	struct overflow_buffer *pov = &overflow[port];
+
+	spin_lock_irqsave(&consolelock, flags);
+
+	viochar = (struct viocharlpevent *)
+	    vio_get_event_buffer(viomajorsubtype_chario);
+
+	/*
+	 * Make sure we got a buffer
+	 */
+	if (viochar == NULL) {
+		hvlog("Yikes...can't get viochar buffer\n");
+		spin_unlock_irqrestore(&consolelock, flags);
+		return;
+	}
+
+	if (pov->used == 0) {
+		hvlog("in sendbuffers, but no buffers used\n");
+		vio_free_event_buffer(viomajorsubtype_chario, viochar);
+		spin_unlock_irqrestore(&consolelock, flags);
+		return;
+	}
+
+	/*
+	 * curbuf points to the buffer we're filling.  We want to
+	 * start sending AFTER this one.  
+	 */
+	nextbuf = (pov->curbuf + 1) % NUM_BUF;
+
+	/*
+	 * Loop until we find a buffer with the used bit on
+	 */
+	while (test_bit(nextbuf, &pov->used) == 0)
+		nextbuf = (nextbuf + 1) % NUM_BUF;
+
+	initDataEvent(viochar, lp);
+
+	/*
+	 * While we have buffers with data, and our send window
+	 * is open, send them
+	 */
+	while ((test_bit(nextbuf, &pov->used)) &&
+	       ((sndMsgSeq[port] - sndMsgAck[port]) < VIOCHAR_WINDOW)) {
+		viochar->len = pov->bufferBytes[nextbuf];
+		viochar->event.xCorrelationToken = sndMsgSeq[port]++;
+		viochar->event.xSizeMinus1 =
+			offsetof(struct viocharlpevent, data) + viochar->len;
+
+		memcpy(viochar->data, pov->buffer[nextbuf], viochar->len);
+
+		hvrc = HvCallEvent_signalLpEvent(&viochar->event);
+		if (hvrc) {
+			/*
+			 * MUST unlock the spinlock before doing a printk
+			 */
+			vio_free_event_buffer(viomajorsubtype_chario, viochar);
+			spin_unlock_irqrestore(&consolelock, flags);
+
+			printk(KERN_WARNING_VIO
+			       "console error sending event! return code %d\n",
+			       (int)hvrc);
+			return;
+		}
+
+		/*
+		 * clear the used bit, zero the number of bytes in
+		 * this buffer, and move to the next buffer
+		 */
+		clear_bit(nextbuf, &pov->used);
+		pov->bufferBytes[nextbuf] = 0;
+		nextbuf = (nextbuf + 1) % NUM_BUF;
+	}
+
+
+	/*
+	 * If we have emptied all the buffers, start at 0 again.
+	 * this will re-use any allocated buffers
+	 */
+	if (pov->used == 0) {
+		pov->curbuf = 0;
+
+		if (pov->overflowMessage)
+			pov->overflowMessage = 0;
+
+		if (port_info[port].tty) {
+			if ((port_info[port].tty->flags &
+						(1 << TTY_DO_WRITE_WAKEUP)) &&
+			    (port_info[port].tty->ldisc.write_wakeup))
+				(port_info[port].tty->ldisc.write_wakeup)(
+						port_info[port].tty);
+			wake_up_interruptible(&port_info[port].tty->write_wait);
+		}
+	}
+
+	vio_free_event_buffer(viomajorsubtype_chario, viochar);
+	spin_unlock_irqrestore(&consolelock, flags);
+}
+
+/*
+ * Our internal writer.  Gets called both from the console device and
+ * the tty device.  the tty pointer will be NULL if called from the console.
+ *
+ * NOTE: Don't use printk in here because it gets nastily recursive.  hvlog
+ * can be used to log to the hypervisor buffer
+ */
+static int internal_write(struct tty_struct *tty, const char *buf,
+			  size_t len, int userFlag)
+{
+	HvLpEvent_Rc hvrc;
+	size_t bleft = len;
+	size_t curlen;
+	const char *curbuf = buf;
+	struct viocharlpevent *viochar;
+	unsigned long flags;
+	struct port_info_tag *pi = NULL;
+	HvLpIndex lp;
+	u8 port;
+
+	/*
+	 * Changed 05/01/2003 by Ryan Arnold :  We spinlock so that
+	 * we can guarentee that the tty doesn't get changed on us
+	 * between when we fetch the driver data and when we paranoia
+	 * check.  It is unlikely that this will ever happen but
+	 * we'll do it anyway.
+	 */
+	spin_lock_irqsave(&consolelock, flags);
+	if (tty) {
+		pi = (struct port_info_tag *) tty->driver_data;
+		if (!pi || viotty_paranoia_check(pi, tty->name,
+					"viotty_internal_write")) {
+			spin_unlock_irqrestore(&consolelock, flags);
+			return -ENODEV;
+		}
+		lp = pi->lp;
+		port = pi->port;
+	} else {
+		/*
+		 * If this is the console device, use the lp from the
+		 * first port entry
+		 */
+		port = 0;
+		lp = port_info[0].lp;
+	}
+	spin_unlock_irqrestore(&consolelock, flags);
+
+	/* Always put console output in the hypervisor console log */
+	if (port == 0)
+		HvCall_writeLogBuffer(buf, len);
+
+	/*
+	 * If the path to this LP is closed, don't bother doing anything
+	 * more. just dump the data on the floor
+	 */
+	if (!viopath_isactive(lp))
+		return len;
+
+	/* If there is already data queued for this port, send it. */
+	if (overflow[port].used)
+		send_buffers(port, lp);
+
+	viochar = (struct viocharlpevent *)
+	    vio_get_event_buffer(viomajorsubtype_chario);
+	/* Make sure we got a buffer */
+	if (viochar == NULL) {
+		hvlog("Yikes...can't get viochar buffer\n");
+		return -1;
+	}
+
+	initDataEvent(viochar, lp);
+
+	while ((bleft > 0) && (overflow[port].used == 0) &&
+	       ((sndMsgSeq[port] - sndMsgAck[port]) < VIOCHAR_WINDOW)) {
+		if (bleft > VIOCHAR_MAX_DATA)
+			curlen = VIOCHAR_MAX_DATA;
+		else
+			curlen = bleft;
+
+		viochar->len = curlen;
+		viochar->event.xCorrelationToken = sndMsgSeq[port]++;
+
+		if (userFlag)
+			copy_from_user(viochar->data, curbuf, curlen);
+		else
+			memcpy(viochar->data, curbuf, curlen);
+
+		viochar->event.xSizeMinus1 =
+		    offsetof(struct viocharlpevent, data) + curlen;
+
+		hvrc = HvCallEvent_signalLpEvent(&viochar->event);
+		if (hvrc) {
+			vio_free_event_buffer(viomajorsubtype_chario, viochar);
+
+			hvlog("viocons: error sending event! %d\n", (int)hvrc);
+			return len - bleft;
+		}
+
+		curbuf += curlen;
+		bleft -= curlen;
+	}
+
+	/* If we didn't send it all, buffer as much of it as we can. */
+	if (bleft > 0)
+		bleft -= buffer_add(port, curbuf, bleft, userFlag);
+	vio_free_event_buffer(viomajorsubtype_chario, viochar);
+
+	return len - bleft;
+}
+
+
+/*
+ * console device write
+ */
+static void viocons_write(struct console *co, const char *s, unsigned count)
+{
+	int index;
+	int foundcr;
+	int slicebegin;
+	int sliceend;
+
+	static const char nl = '\n';
+	static const char cr = '\r';
+
+	/*
+	 * This parser will ensure that all single instances of
+	 * either \n or \r are matched into carriage return/line feed
+	 * combinations.  It also allows for instances where there
+	 * already exist \n\r combinations as well as the reverse,
+	 * \r\n combinations.
+	 */
+	foundcr = 0;
+	slicebegin = 0;
+	sliceend = 0;
+
+	for (index = 0; index < count; index++) {
+		if (!foundcr && (s[index] == nl)) {
+			if ((sliceend > slicebegin) && (sliceend < count)) {
+				internal_write(NULL, &s[slicebegin],
+					       sliceend - slicebegin, 0);
+				slicebegin = sliceend;
+			}
+			internal_write(NULL, &cr, 1, 0);
+		}
+		if (foundcr && (s[index] != nl) && (index >= 2) &&
+				(s[index - 2] != nl)) {
+			internal_write(NULL, &s[slicebegin],
+					sliceend - slicebegin, 0);
+			slicebegin = sliceend;
+			internal_write(NULL, &nl, 1, 0);
+		}
+		sliceend++;
+		foundcr = (s[index] == cr);
+	}
+
+	internal_write(NULL, &s[slicebegin], sliceend - slicebegin, 0);
+
+	if (count > 1) {
+		if (foundcr && (s[count - 1] != nl))
+			internal_write(NULL, &nl, 1, 0);
+		else if ((s[count - 1] == nl) && (s[count - 2] != cr))
+			internal_write(NULL, &cr, 1, 0);
+	}
+}
+
+/*
+ * Work out a the device associate with this console
+ */
+static struct tty_driver *viocons_device(struct console *c, int *index)
+{
+	*index = c->index;
+	return &viotty_driver;
+}
+
+/*
+ * Do console device setup
+ */
+static int __init viocons_setup(struct console *co, char *options)
+{
+	return 0;
+}
+
+/*
+ * console device I/O methods
+ */
+static struct console viocons = {
+	.name = "ttyS",
+	.write = viocons_write,
+	.device = viocons_device,
+	.setup = viocons_setup,
+	.flags = CON_PRINTBUFFER,
+	.index = -1,
+};
+
+/*
+ * TTY Open method
+ */
+static int viotty_open(struct tty_struct *tty, struct file *filp)
+{
+	int port;
+	unsigned long flags;
+
+	port = tty->index;
+
+	if (port >= VIOTTY_SERIAL_START)
+		port -= VIOTTY_SERIAL_START;
+
+	if ((port < 0) || (port >= VTTY_PORTS))
+		return -ENODEV;
+
+	spin_lock_irqsave(&consolelock, flags);
+
+	/* If some other TTY is already connected here, reject the open */
+	if ((port_info[port].tty) && (port_info[port].tty != tty)) {
+		spin_unlock_irqrestore(&consolelock, flags);
+		printk(KERN_WARNING_VIO
+		       "console attempt to open device twice from different ttys\n");
+		return -EBUSY;
+	}
+	tty->driver_data = &port_info[port];
+	port_info[port].tty = tty;
+	spin_unlock_irqrestore(&consolelock, flags);
+
+	return 0;
+}
+
+/*
+ * TTY Close method
+ */
+static void viotty_close(struct tty_struct *tty, struct file *filp)
+{
+	unsigned long flags;
+	struct port_info_tag *pi = NULL;
+
+	spin_lock_irqsave(&consolelock, flags);
+	pi = (struct port_info_tag *) tty->driver_data;
+
+	if (!pi || viotty_paranoia_check(pi, tty->name, "viotty_close")) {
+		spin_unlock_irqrestore(&consolelock, flags);
+		return;
+	}
+
+/*	if (atomic_read(&tty->count) == 1) { */
+	if (tty->count == 1)
+		pi->tty = NULL;
+
+	spin_unlock_irqrestore(&consolelock, flags);
+
+}
+
+/*
+ * TTY Write method
+ */
+static int viotty_write(struct tty_struct *tty, int from_user,
+			const unsigned char *buf, int count)
+{
+	return internal_write(tty, buf, count, from_user);
+}
+
+/*
+ * TTY put_char method
+ */
+static void viotty_put_char(struct tty_struct *tty, unsigned char ch)
+{
+	internal_write(tty, &ch, 1, 0);
+}
+
+/*
+ * TTY flush_chars method
+ */
+static void viotty_flush_chars(struct tty_struct *tty)
+{
+}
+
+/*
+ * TTY write_room method
+ */
+static int viotty_write_room(struct tty_struct *tty)
+{
+	int i;
+	int room = 0;
+	struct port_info_tag *pi = NULL;
+	unsigned long flags;
+
+	spin_lock_irqsave(&consolelock, flags);
+	pi = (struct port_info_tag *) tty->driver_data;
+	if (!pi || viotty_paranoia_check(pi, tty->name, "viotty_sendbuffers")) {
+		spin_unlock_irqrestore(&consolelock, flags);
+		return 0;
+	}
+
+	/*
+	 * If no buffers are used, return the max size.
+	 */
+	if (overflow[pi->port].used == 0) {
+		spin_unlock_irqrestore(&consolelock, flags);
+		return VIOCHAR_MAX_DATA * NUM_BUF;
+	}
+
+	/*
+	 * We retain the spinlock because we want to get an accurate
+	 * count and it can change on us between each operation if we
+	 * don't hold the spinlock.
+	 */
+	for (i = 0; ((i < NUM_BUF) && (room < VIOCHAR_MAX_DATA)); i++)
+		room += (OVERFLOW_SIZE - overflow[pi->port].bufferBytes[i]);
+	spin_unlock_irqrestore(&consolelock, flags);
+
+	if (room > VIOCHAR_MAX_DATA)
+		room = VIOCHAR_MAX_DATA;
+	return room;
+}
+
+/*
+ * TTY chars_in_buffer_room method
+ */
+static int viotty_chars_in_buffer(struct tty_struct *tty)
+{
+	return 0;
+}
+
+static void viotty_flush_buffer(struct tty_struct *tty)
+{
+}
+
+static int viotty_ioctl(struct tty_struct *tty, struct file *file,
+			unsigned int cmd, unsigned long arg)
+{
+	switch (cmd) {
+	/*
+	 * the ioctls below read/set the flags usually shown in the leds
+	 * don't use them - they will go away without warning
+	 */
+	case KDGETLED:
+	case KDGKBLED:
+		return put_user(0, (char *) arg);
+
+	case KDSKBLED:
+		return 0;
+	}
+
+	return n_tty_ioctl(tty, file, cmd, arg);
+}
+
+static void viotty_throttle(struct tty_struct *tty)
+{
+}
+
+static void viotty_unthrottle(struct tty_struct *tty)
+{
+}
+
+static void viotty_set_termios(struct tty_struct *tty,
+			       struct termios *old_termios)
+{
+}
+
+static void viotty_stop(struct tty_struct *tty)
+{
+}
+
+static void viotty_start(struct tty_struct *tty)
+{
+}
+
+static void viotty_hangup(struct tty_struct *tty)
+{
+}
+
+static void viotty_break(struct tty_struct *tty, int break_state)
+{
+}
+
+static void viotty_send_xchar(struct tty_struct *tty, char ch)
+{
+}
+
+static void viotty_wait_until_sent(struct tty_struct *tty, int timeout)
+{
+}
+
+/*
+ * Handle an open charLpEvent.  Could be either interrupt or ack
+ */
+static void vioHandleOpenEvent(struct HvLpEvent *event)
+{
+	unsigned long flags;
+	struct viocharlpevent *cevent = (struct viocharlpevent *)event;
+	u8 port = cevent->virtual_device;
+	int reject = 0;
+
+	/*
+	 * Change 05/01/2003 by Ryan Arnold:  The following two local
+	 * variables are being removed because they aren't actually
+	 * used once they are ste.  The porper action is to set the
+	 * parameter event's xRc and mSubTypeRc fields.  This fixes
+	 * the bug where a successfull open is returned to the client
+	 * even when the console is in use by another partition and
+	 * the open event actuall failed.  Since the event ptr was
+	 * being re0used we were always sending back the same
+	 * event->xRc and cevent->mSubTypeRc that we were getting
+	 * from the original event.
+	 *
+	 * u16 eventSubtypeRc;
+	 * u8 eventRc;
+	 */
+
+	if (event->xFlags.xFunction == HvLpEvent_Function_Ack) {
+		if (port >= VTTY_PORTS)
+			return;
+
+		spin_lock_irqsave(&consolelock, flags);
+		/* Got the lock, don't cause console output */
+
+		if (event->xRc == HvLpEvent_Rc_Good) {
+			sndMsgSeq[port] = sndMsgAck[port] = 0;
+			/*
+			 * Changed 05/01/2003 by Ryan Arnold: this linve was
+			 * moved UP into this if block because, in its
+			 * previous position it prevent the primary partition
+			 * from EVER getting the console because of the order
+			 * of operations was such that the hosting partion
+			 * aws always accepted as the target LP regardless of
+			 * whether the event->xRc was good or not.  This
+			 * fix allows connections from the primary partition
+			 * but once one is connected from the primary
+			 * partition nothing short of a reboot of linux will
+			 * allow access from the hosting partition again
+			 * without a required iSeries fix.
+			 */
+			port_info[port].lp = event->xTargetLp;
+		}
+		spin_unlock_irqrestore(&consolelock, flags);
+
+		if (event->xRc != HvLpEvent_Rc_Good)
+			printk(KERN_WARNING_VIO
+			       "viocons: event->xRc != HvLpEvent_Rc_Good, event->xRc == (%d).\n",
+			       event->xRc);
+
+		if (event->xCorrelationToken != 0) {
+			unsigned long semptr = event->xCorrelationToken;
+			up((struct semaphore *) semptr);
+		} else
+			printk(KERN_WARNING_VIO
+			       "console: wierd...got open ack without semaphore\n");
+		return;
+	}
+
+	/*
+	 * This had better require an ack, otherwise complain
+	 */
+	if (event->xFlags.xAckInd != HvLpEvent_AckInd_DoAck) {
+		printk(KERN_WARNING_VIO
+		       "console: viocharopen without ack bit!\n");
+		return;
+	}
+
+	spin_lock_irqsave(&consolelock, flags);
+	/* Got the lock, don't cause console output */
+
+	/* Make sure this is a good virtual tty */
+	if (port >= VTTY_PORTS) {
+		/*
+		 * Change 05/01/2003 by Ryan Arnold: This is where
+		 * the local variable assignments were changed over
+		 * to re-assigning values to the original event data
+		 * members since we reuse the event.  This was also
+		 * change in the two other else if & else blocks
+		 * below.
+		 */
+		event->xRc = HvLpEvent_Rc_SubtypeError;
+		cevent->subtype_result_code = viorc_openRejected;
+		/*
+		 * Flag state here since we can't printk while holding
+		 * a spinlock.
+		 */
+		reject = 1;
+	} else if ((port_info[port].lp != HvLpIndexInvalid) &&
+		   (port_info[port].lp != event->xSourceLp)) {
+		/*
+		 * If this is tty is already connected to a different
+		 * partition, fail.
+		 */
+		event->xRc = HvLpEvent_Rc_SubtypeError;
+		cevent->subtype_result_code = viorc_openRejected;
+		reject = 2;
+	} else {
+		port_info[port].lp = event->xSourceLp;
+		event->xRc = HvLpEvent_Rc_Good;
+		cevent->subtype_result_code = viorc_good;
+		sndMsgSeq[port] = sndMsgAck[port] = 0;
+		reject = 0;
+	}
+
+	spin_unlock_irqrestore(&consolelock, flags);
+
+	if (reject == 1)
+		printk("viocons: console open rejected : bad virtual tty.\n");
+	else if (reject == 2)
+		printk("viocons: console open rejected : console in exclusive use by another partition.\n");
+
+	/* Return the acknowledgement */
+	HvCallEvent_ackLpEvent(event);
+}
+
+/*
+ * Handle a close open charLpEvent.  Could be either interrupt or ack
+ */
+static void vioHandleCloseEvent(struct HvLpEvent *event)
+{
+	unsigned long flags;
+	struct viocharlpevent *cevent = (struct viocharlpevent *)event;
+	u8 port = cevent->virtual_device;
+
+	if (event->xFlags.xFunction == HvLpEvent_Function_Int) {
+		if (port >= VTTY_PORTS)
+			return;
+
+		/* For closes, just mark the console partition invalid */
+		spin_lock_irqsave(&consolelock, flags);
+		/* Got the lock, don't cause console output */
+
+		if (port_info[port].lp == event->xSourceLp)
+			port_info[port].lp = HvLpIndexInvalid;
+
+		spin_unlock_irqrestore(&consolelock, flags);
+		printk(KERN_INFO_VIO
+		       "console close from %d\n", event->xSourceLp);
+	} else
+		printk(KERN_WARNING_VIO
+		       "console got unexpected close acknowlegement\n");
+}
+
+/*
+ * Handle a config charLpEvent.  Could be either interrupt or ack
+ */
+static void vioHandleConfig(struct HvLpEvent *event)
+{
+	struct viocharlpevent *cevent = (struct viocharlpevent *)event;
+	int len;
+
+	len = cevent->len;
+	HvCall_writeLogBuffer(cevent->data, cevent->len);
+
+	if (cevent->data[0] == 0x01)
+		printk(KERN_INFO_VIO
+		       "console window resized to %d: %d: %d: %d\n",
+		       cevent->data[1], cevent->data[2],
+		       cevent->data[3], cevent->data[4]);
+	else
+		printk(KERN_WARNING_VIO "console unknown config event\n");
+	return;
+}
+
+/*
+ * Handle a data charLpEvent. 
+ */
+static void vioHandleData(struct HvLpEvent *event)
+{
+	struct tty_struct *tty;
+	unsigned long flags;
+	struct viocharlpevent *cevent = (struct viocharlpevent *)event;
+	struct port_info_tag *pi;
+	int len;
+	u8 port = cevent->virtual_device;
+
+#if 1 
+if (xmon_rcv_chars(cevent->data, cevent->len))
+	return;
+#endif
+
+	if (port >= VTTY_PORTS) {
+		printk(KERN_WARNING_VIO
+		       "console data on invalid virtual device %d\n", port);
+		return;
+	}
+	/*
+	 * Change 05/01/2003 - Ryan Arnold: If a partition other than
+	 * the current exclusive partition tries to send us data
+	 * events then just drop them on the floor because we don't
+	 * want his stinking data.  He isn't authorized to receive
+	 * data because he wasn't the first one to get the console,
+	 * therefore he shouldn't be allowed to send data either.
+	 * This will work without an iSeries fix.
+	 */
+	if (port_info[port].lp != event->xSourceLp)
+		return;
+
+	tty = port_info[port].tty;
+
+	if (tty == NULL) {
+		printk(KERN_WARNING_VIO "no tty for virtual device %d\n", port);
+		return;
+	}
+
+	if (tty->magic != TTY_MAGIC) {
+		printk(KERN_WARNING_VIO "tty bad magic\n");
+		return;
+	}
+
+	/*
+	 * Hold the spinlock so that we don't take an interrupt that
+	 * changes tty between the time we fetch the port_info_tag
+	 * pointer and the time we paranoia check.
+	 */
+	spin_lock_irqsave(&consolelock, flags);
+
+	/*
+	 * Just to be paranoid, make sure the tty points back to this port
+	 */
+	pi = (struct port_info_tag *)tty->driver_data;
+	if (!pi || viotty_paranoia_check(pi, tty->name, "vioHandleData")) {
+		spin_unlock_irqrestore(&consolelock, flags);
+		return;
+	}
+	spin_unlock_irqrestore(&consolelock, flags);
+
+	len = cevent->len;
+	if (len == 0)
+		return;
+
+	/*
+	 * Don't log the user's input to the hypervisor log or their password
+	 * will appear on a hypervisor log display.
+	 */
+
+	/* Don't copy more bytes than there is room for in the buffer */
+	if (tty->flip.count + len > TTY_FLIPBUF_SIZE) {
+		len = TTY_FLIPBUF_SIZE - tty->flip.count;
+		printk(KERN_WARNING_VIO "console input buffer overflow!\n");
+	}
+
+	memcpy(tty->flip.char_buf_ptr, cevent->data, len);
+	memset(tty->flip.flag_buf_ptr, TTY_NORMAL, len);
+
+	/* Update the kernel buffer end */
+	tty->flip.count += len;
+	tty->flip.char_buf_ptr += len;
+	tty->flip.flag_buf_ptr += len;
+	tty_flip_buffer_push(tty);
+}
+
+/*
+ * Handle an ack charLpEvent. 
+ */
+static void vioHandleAck(struct HvLpEvent *event)
+{
+	struct viocharlpevent *cevent = (struct viocharlpevent *)event;
+	unsigned long flags;
+	u8 port = cevent->virtual_device;
+
+	if (port >= VTTY_PORTS) {
+		printk(KERN_WARNING_VIO
+		       "viocons: data on invalid virtual device\n");
+		return;
+	}
+
+	spin_lock_irqsave(&consolelock, flags);
+	sndMsgAck[port] = event->xCorrelationToken;
+	spin_unlock_irqrestore(&consolelock, flags);
+
+	if (overflow[port].used)
+		send_buffers(port, port_info[port].lp);
+}
+
+/*
+ * Handle charLpEvents and route to the appropriate routine
+ */
+static void vioHandleCharEvent(struct HvLpEvent *event)
+{
+	int charminor;
+
+	if (event == NULL)
+		return;
+
+	charminor = event->xSubtype & VIOMINOR_SUBTYPE_MASK;
+	switch (charminor) {
+	case viocharopen:
+		vioHandleOpenEvent(event);
+		break;
+	case viocharclose:
+		vioHandleCloseEvent(event);
+		break;
+	case viochardata:
+		vioHandleData(event);
+		break;
+	case viocharack:
+		vioHandleAck(event);
+		break;
+	case viocharconfig:
+		vioHandleConfig(event);
+		break;
+	default:
+		if ((event->xFlags.xFunction == HvLpEvent_Function_Int) &&
+		    (event->xFlags.xAckInd == HvLpEvent_AckInd_DoAck)) {
+			event->xRc = HvLpEvent_Rc_InvalidSubtype;
+			HvCallEvent_ackLpEvent(event);
+		}
+	}
+}
+
+/*
+ * Send an open event
+ */
+static int send_open(HvLpIndex remoteLp, void *sem)
+{
+	return HvCallEvent_signalLpEventFast(remoteLp,
+			HvLpEvent_Type_VirtualIo,
+			viomajorsubtype_chario | viocharopen,
+			HvLpEvent_AckInd_DoAck, HvLpEvent_AckType_ImmediateAck,
+			viopath_sourceinst(remoteLp),
+			viopath_targetinst(remoteLp),
+			(u64)(unsigned long)sem, VIOVERSION << 16,
+			0, 0, 0, 0);
+}
+
+static struct tty_operations serial_ops = {
+	.open = viotty_open,
+	.close = viotty_close,
+	.write = viotty_write,
+	.put_char = viotty_put_char,
+	.flush_chars = viotty_flush_chars,
+	.write_room = viotty_write_room,
+	.chars_in_buffer = viotty_chars_in_buffer,
+	.flush_buffer = viotty_flush_buffer,
+	.ioctl = viotty_ioctl,
+	.throttle = viotty_throttle,
+	.unthrottle = viotty_unthrottle,
+	.set_termios = viotty_set_termios,
+	.stop = viotty_stop,
+	.start = viotty_start,
+	.hangup = viotty_hangup,
+	.break_ctl = viotty_break,
+	.send_xchar = viotty_send_xchar,
+	.wait_until_sent = viotty_wait_until_sent,
+};
+
+int __init viocons_init2(void)
+{
+	DECLARE_MUTEX_LOCKED(Semaphore);
+	int rc;
+
+	/* Now open to the primary LP */
+	printk(KERN_INFO_VIO "console open path to primary\n");
+	/* +2 for fudge */
+	rc = viopath_open(HvLpConfig_getPrimaryLpIndex(),
+			viomajorsubtype_chario, VIOCHAR_WINDOW + 2);
+	if (rc)
+		printk(KERN_WARNING_VIO "console error opening to primary %d\n",
+				rc);
+
+	if (viopath_hostLp == HvLpIndexInvalid)
+		vio_set_hostlp();
+
+	/*
+	 * And if the primary is not the same as the hosting LP, open to the 
+	 * hosting lp
+	 */
+	if ((viopath_hostLp != HvLpIndexInvalid) &&
+	    (viopath_hostLp != HvLpConfig_getPrimaryLpIndex())) {
+		printk(KERN_INFO_VIO "console open path to hosting (%d)\n",
+				viopath_hostLp);
+		rc = viopath_open(viopath_hostLp, viomajorsubtype_chario,
+				VIOCHAR_WINDOW + 2);	/* +2 for fudge */
+		if (rc)
+			printk(KERN_WARNING_VIO
+				"console error opening to partition %d: %d\n",
+				viopath_hostLp, rc);
+	}
+
+	if (vio_setHandler(viomajorsubtype_chario, vioHandleCharEvent) < 0)
+		printk(KERN_WARNING_VIO
+				"Error seting handler for console events!\n");
+
+	printk(KERN_INFO_VIO "console major number is %d\n", TTY_MAJOR);
+
+	/* First, try to open the console to the hosting lp.
+	 * Wait on a semaphore for the response.
+	 */
+	if ((viopath_isactive(viopath_hostLp)) &&
+	    (send_open(viopath_hostLp, (void *)&Semaphore) == 0)) {
+		printk(KERN_INFO_VIO
+			"opening console to hosting partition %d\n",
+			viopath_hostLp);
+		//down(&Semaphore);
+		while (atomic_read(&Semaphore.count) == 0)
+			mb();
+		atomic_set(&Semaphore.count, 0);
+	}
+
+	/*
+	 * If we don't have an active console, try the primary
+	 */
+	if ((!viopath_isactive(port_info[0].lp)) &&
+	    (viopath_isactive(HvLpConfig_getPrimaryLpIndex())) &&
+	    (send_open(HvLpConfig_getPrimaryLpIndex(), (void *)&Semaphore)
+	     == 0)) {
+		printk(KERN_INFO_VIO "opening console to primary partition\n");
+		//down(&Semaphore);
+		while (atomic_read(&Semaphore.count) == 0)
+			mb();
+		atomic_set(&Semaphore.count, 0);
+	}
+	return 0;
+}
+
+static int viocons_init3(void)
+{
+	int ret = viocons_init2();
+
+	if (ret)
+		return ret;
+
+	/* Initialize the tty_driver structure */
+	memset(&viotty_driver, 0, sizeof(struct tty_driver));
+	viotty_driver.magic = TTY_DRIVER_MAGIC;
+	viotty_driver.owner = THIS_MODULE;
+	viotty_driver.driver_name = "vioconsole";
+	viotty_driver.devfs_name = "vcs/";
+	viotty_driver.name = "tty";
+	viotty_driver.major = TTY_MAJOR;
+	viotty_driver.minor_start = 1;
+	viotty_driver.num = VTTY_PORTS;
+	viotty_driver.type = TTY_DRIVER_TYPE_CONSOLE;
+	viotty_driver.subtype = 1;
+	viotty_driver.init_termios = tty_std_termios;
+	viotty_driver.flags = TTY_DRIVER_REAL_RAW | TTY_DRIVER_RESET_TERMIOS;
+	viotty_driver.termios = viotty_termios;
+	viotty_driver.termios_locked = viotty_termios_locked;
+	tty_set_operations(&viotty_driver, &serial_ops);
+
+	viottyS_driver = viotty_driver;
+	viottyS_driver.devfs_name = "tts/";
+	viottyS_driver.name = "ttyS";
+	viottyS_driver.major = TTY_MAJOR;
+	viottyS_driver.minor_start = VIOTTY_SERIAL_START;
+	viottyS_driver.type = TTY_DRIVER_TYPE_SERIAL;
+	viottyS_driver.termios = viottyS_termios;
+	viottyS_driver.termios_locked = viottyS_termios_locked;
+
+	if (tty_register_driver(&viotty_driver))
+		printk(KERN_WARNING_VIO "Couldn't register console driver\n");
+
+	if (tty_register_driver(&viottyS_driver))
+		printk(KERN_WARNING_VIO "Couldn't register console S driver\n");
+	/* Now create the vcs and vcsa devfs entries so mingetty works */
+#if defined(CONFIG_DEVFS_FS)
+	{
+		struct tty_driver temp_driver = viotty_driver;
+		int i;
+
+		temp_driver.name = "vcs%d";
+		for (i = 0; i < VTTY_PORTS; i++)
+			tty_register_devfs(&temp_driver,
+					   0, i + temp_driver.minor_start);
+
+		temp_driver.name = "vcsa%d";
+		for (i = 0; i < VTTY_PORTS; i++)
+			tty_register_devfs(&temp_driver,
+					   0, i + temp_driver.minor_start);
+
+		/*
+		 * For compatibility with some earlier code only!
+		 * This will go away!!!
+		 */
+		temp_driver.name = "viocons/%d";
+		temp_driver.name_base = 0;
+		for (i = 0; i < VTTY_PORTS; i++)
+			tty_register_devfs(&temp_driver,
+					   0, i + temp_driver.minor_start);
+	}
+#endif
+
+	return 0;
+}
+
+static int __init viocons_init(void)
+{
+	int i;
+
+	printk(KERN_INFO_VIO "registering console\n");
+	for (i = 0; i < VTTY_PORTS; i++) {
+		port_info[i].port = i;
+		port_info[i].lp = HvLpIndexInvalid;
+		port_info[i].magic = VIOTTY_MAGIC;
+	}
+	HvCall_setLogBufferFormatAndCodepage(HvCall_LogBuffer_ASCII, 437);
+	register_console(&viocons);
+	return 0;
+}
+
+console_initcall(viocons_init);
+module_init(viocons_init3);
diff -purN linux-2.5/drivers/net/e100/e100_main.c linuxppc64-2.5/drivers/net/e100/e100_main.c
--- linux-2.5/drivers/net/e100/e100_main.c	2003-09-25 03:34:49.000000000 +0000
+++ linuxppc64-2.5/drivers/net/e100/e100_main.c	2003-09-29 12:39:13.000000000 +0000
@@ -1500,7 +1500,7 @@ e100_setup_tcb_pool(tcb_t *head, unsigne
 		pcurr_tcb->tcb_skb = NULL;
 	}
 
-	wmb();
+	mb();
 }
 
 /***************************************************************************/
@@ -1753,7 +1753,7 @@ e100_watchdog(struct net_device *dev)
 	/* Check for command completion on next watchdog timer. */
 	e100_dump_stats_cntrs(bdp);
 
-	wmb();
+	mb();
 
 	/* relaunch watchdog timer in 2 sec */
 	mod_timer(&(bdp->watchdog_timer), jiffies + (2 * HZ));
@@ -2229,7 +2229,7 @@ e100_prepare_xmit_buff(struct e100_priva
 
 	bdp->tcb_pool.tail = NEXT_TCB_TOUSE(bdp->tcb_pool.tail);
 
-	wmb();
+	mb();
 
 	e100_start_cu(bdp, tcb);
 
@@ -2516,7 +2516,7 @@ e100_clr_cntrs(struct e100_private *bdp)
 	/* clear the dump counter complete word */
 	pcmd_complete = e100_cmd_complete_location(bdp);
 	*pcmd_complete = 0;
-	wmb();
+	mb();
 
 	if (!e100_wait_exec_cmplx(bdp, bdp->stat_cnt_phys, SCB_CUC_DUMP_ADDR, 0))
 		return false;
@@ -2651,7 +2651,7 @@ e100_exec_non_cu_cmd(struct e100_private
 	ntcb_hdr->cb_status = 0;
 	ntcb_hdr->cb_lnk_ptr = 0;
 
-	wmb();
+	mb();
 	if (in_interrupt())
 		return e100_delayed_exec_non_cu_cmd(bdp, command);
 
diff -purN linux-2.5/drivers/net/e100/e100_test.c linuxppc64-2.5/drivers/net/e100/e100_test.c
--- linux-2.5/drivers/net/e100/e100_test.c	2003-05-09 02:16:29.000000000 +0000
+++ linuxppc64-2.5/drivers/net/e100/e100_test.c	2003-05-28 20:29:48.000000000 +0000
@@ -316,7 +316,7 @@ e100_diag_loopback_alloc(struct e100_pri
 	memset((void *) ((u8 *) tbd + sizeof (tbd_t)), 0xFF, 512);
 	/* The value of second 512 bytes is BA */
 	memset((void *) ((u8 *) tbd + sizeof (tbd_t) + 512), 0xBA, 512);
-	wmb();
+	mb();
 	rfd = pci_alloc_consistent(bdp->pdev, sizeof (rfd_t), &dma_handle);
 
 	if (rfd == NULL) {
@@ -335,7 +335,7 @@ e100_diag_loopback_alloc(struct e100_pri
 	bdp->loopback.dma_handle = dma_handle;
 	bdp->loopback.tcb = tcb;
 	bdp->loopback.rfd = rfd;
-	wmb();
+	mb();
 	return true;
 }
 
diff -purN linux-2.5/drivers/net/veth.c linuxppc64-2.5/drivers/net/veth.c
--- linux-2.5/drivers/net/veth.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/net/veth.c	2003-11-21 05:44:51.000000000 +0000
@@ -0,0 +1,1840 @@
+/* File veth.c created by Kyle A. Lucke on Mon Aug  7 2000. */
+
+/**************************************************************************/
+/*                                                                        */
+/* IBM eServer iSeries Virtual Ethernet Device Driver                     */
+/* Copyright (C) 2001 Kyle A. Lucke (klucke@us.ibm.com), IBM Corp.        */
+/*                                                                        */
+/*  This program is free software; you can redistribute it and/or modify  */
+/*  it under the terms of the GNU General Public License as published by  */
+/*  the Free Software Foundation; either version 2 of the License, or     */
+/*  (at your option) any later version.                                   */
+/*                                                                        */
+/*  This program is distributed in the hope that it will be useful,       */
+/*  but WITHOUT ANY WARRANTY; without even the implied warranty of        */
+/*  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the         */
+/*  GNU General Public License for more details.                          */
+/*                                                                        */
+/*  You should have received a copy of the GNU General Public License     */
+/*  along with this program; if not, write to the Free Software           */
+/*  Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  */
+/*                                                                   USA  */
+/*                                                                        */
+/* This module contains the implementation of a virtual ethernet device   */
+/* for use with iSeries LPAR Linux.  It utilizes low-level message passing*/
+/* provided by the hypervisor to enable an ethernet-like network device   */
+/* that can be used to enable inter-partition communications on the same  */
+/* physical iSeries.                                                      */
+/*                                                                        */
+/* The iSeries LPAR hypervisor has currently defined the ability for a    */
+/* partition to communicate on up to 16 different virtual ethernets, all  */
+/* dynamically configurable, at least for an OS/400 partition.  The       */
+/* dynamic nature is not supported for Linux yet.                         */
+/*                                                                        */
+/* Each virtual ethernet a given Linux partition participates in will     */
+/* cause a network device with the form ethXX to be created,              */
+/*                                                                        */
+/* The virtual ethernet a given ethXX virtual ethernet device talks on    */
+/* can be determined either by dumping /proc/iSeries/veth/vethX, where    */
+/* X is the virtual ethernet number, and the netdevice name will be       */
+/* printed out.  The virtual ethernet a given ethX device communicates on */
+/* is also printed to the printk() buffer at module load time.            */
+/*                                                                        */
+/* This driver (and others like it on other partitions) is responsible for*/
+/* routing packets to and from other partitions.  The MAC addresses used  */
+/* by the virtual ethernets contain meaning, and should not be modified.  */
+/* Doing so could disable the ability of your Linux partition to          */
+/* communicate with the other OS/400 partitions on your physical iSeries. */
+/* Similarly, setting the MAC address to something other than the         */
+/* "virtual burned-in" address is not allowed, for the same reason.       */
+/*                                                                        */
+/* Notes:                                                                 */
+/*                                                                        */
+/* 1. Although there is the capability to talk on multiple shared         */
+/*    ethernets to communicate to the same partition, each shared         */
+/*    ethernet to a given partition X will use a finite, shared amount    */
+/*    of hypervisor messages to do the communication.  So having 2 shared */
+/*    ethernets to the same remote partition DOES NOT double the          */
+/*    available bandwidth.  Each of the 2 shared ethernets will share the */
+/*    same bandwidth available to another.                                */
+/*                                                                        */
+/* 2. It is allowed to have a virtual ethernet that does not communicate  */
+/*    with any other partition.  It won't do anything, but it's allowed.  */
+/*                                                                        */
+/* 3. There is no "loopback" mode for a virtual ethernet device.  If you  */
+/*    send a packet to your own mac address, it will just be dropped, you */
+/*    won't get it on the receive side.  Such a thing could be done,      */
+/*    but my default driver DOES NOT do so.                               */
+/*                                                                        */
+/* 4. Multicast addressing is implemented via broadcasting the multicast  */
+/*    frames to other partitions.  It is the responsibility of the        */
+/*    receiving partition to filter the addresses desired.                */
+/*                                                                        */
+/* 5. This module utilizes several different bottom half handlers for     */
+/*    non-high-use path function (setup, error handling, etc.).  Multiple */
+/*    bottom halves were used because only one would not keep up to the   */
+/*    much faster iSeries device drivers this Linux driver is talking to. */
+/*    All hi-priority work (receiving frames, handling frame acks) is done*/
+/*    in the interrupt handler for maximum performance.                   */
+/*                                                                        */
+/* Tunable parameters:                                                    */
+/*                                                                        */
+/* VethBuffersToAllocate: This compile time option defaults to 120. It can*/
+/* be safely changed to something greater or less than the default.  It   */
+/* controls how much memory Linux will allocate per remote partition it is*/
+/* communicating with.  The user can play with this to see how it affects */
+/* performance, packets dropped, etc.  Without trying to understand the   */
+/* complete driver, it can be thought of as the maximum number of packets */
+/* outstanding to a remote partition at a time.                           */
+/*                                                                        */
+/**************************************************************************/
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/version.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/ioport.h>
+#include <linux/pci.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+#include <linux/etherdevice.h>
+#include <linux/skbuff.h>
+#include <linux/init.h>
+#include <linux/delay.h>
+#include <linux/mm.h>
+#ifdef SIOCETHTOOL
+#include <linux/ethtool.h>
+#endif
+#include <asm/iSeries/mf.h>
+#include <asm/uaccess.h>
+
+#include "veth.h"
+#include <asm/iSeries/HvLpConfig.h>
+#include <asm/iSeries/veth-proc.h>
+#include <asm/iSeries/HvTypes.h>
+#include <asm/iSeries/iSeries_proc.h>
+#include <asm/iSeries/iSeries_dma.h>
+#include <asm/semaphore.h>
+#include <linux/proc_fs.h>
+
+#define veth_printk(fmt, args...) \
+printk(KERN_INFO "%s: " fmt, __FILE__, ## args)
+
+#define veth_error(fmt, args...) \
+printk(KERN_ERR "(%s:%3.3d) ERROR: " fmt, __FILE__, __LINE__ , ## args)
+
+static char *version __initdata =
+	"v1.06 05/04/2003  Kyle Lucke, klucke@us.ibm.com\n";
+
+#define VethBuffersToAllocate 120
+
+static struct VethFabricMgr *mFabricMgr = NULL;
+static struct proc_dir_entry *veth_proc_root = NULL;
+
+DECLARE_MUTEX_LOCKED(VethProcSemaphore);
+
+static int veth_open(struct net_device *dev);
+static int veth_close(struct net_device *dev);
+static int veth_start_xmit(struct sk_buff *skb, struct net_device *dev);
+static int veth_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd);
+static void veth_handleEvent(struct HvLpEvent *, struct pt_regs *);
+static void veth_handleAck(struct HvLpEvent *);
+static void veth_handleInt(struct HvLpEvent *);
+static void veth_open_connections(void);
+static void veth_openConnection(u8);
+static void veth_closeConnection(u8);
+static void veth_intFinishOpeningConnections(void *, int number);
+static void veth_finishOpeningConnections(void *);
+static void veth_finishOpeningConnectionsLocked(struct VethLpConnection *);
+static int veth_multicast_wanted(struct veth_port *port, u64 dest);
+static void veth_set_multicast_list(struct net_device *dev);
+
+static void veth_sendCap(struct VethLpConnection *);
+static void veth_sendMonitor(struct VethLpConnection *);
+static void veth_takeCap(struct VethLpConnection *, struct VethLpEvent *);
+static void veth_takeCapAck(struct VethLpConnection *, struct VethLpEvent *);
+static void veth_takeMonitorAck(struct VethLpConnection *,
+				struct VethLpEvent *);
+static void veth_msgsInit(struct VethLpConnection *cnx);
+static void veth_recycleMsgByNum(struct VethLpConnection *, u16);
+static void veth_recycleMsg(struct VethLpConnection *, struct VethMsg *);
+static void veth_capTask(void *);
+static void veth_capAckTask(void *);
+static void veth_monitorAckTask(void *);
+static void veth_takeFrames(struct VethLpConnection *, struct VethLpEvent *);
+static int veth_pTransmit(struct sk_buff *skb, HvLpIndex remoteLp,
+			  struct net_device *dev);
+static struct net_device_stats *veth_get_stats(struct net_device *dev);
+static void veth_intFinishMsgsInit(void *, int);
+static void veth_finishMsgsInit(struct VethLpConnection *cnx);
+static void veth_intFinishCapTask(void *, int);
+static void veth_finishCapTask(struct VethLpConnection *cnx);
+static void veth_finishCapTaskLocked(struct VethLpConnection *cnx);
+static void veth_finishSendCap(struct VethLpConnection *cnx);
+static void veth_timedAck(unsigned long connectionPtr);
+static void veth_startQueues(void);
+static void veth_failMe(struct VethLpConnection *cnx);
+
+static int proc_veth_dump_connection(char *page, char **start, off_t off,
+				     int count, int *eof, void *data);
+static int proc_veth_dump_port(char *page, char **start, off_t off, int count,
+			       int *eof, void *data);
+
+
+extern struct pci_dev *iSeries_veth_dev;
+static struct net_device *veth_devices[16];
+static int veth_dev_queue_stopped[16];
+static int veth_num_devices; /* = 0 */
+
+#define VETH_MAX_MTU		9000
+
+MODULE_AUTHOR("Kyle Lucke <klucke@us.ibm.com>");
+MODULE_DESCRIPTION("iSeries Virtual ethernet driver");
+MODULE_LICENSE("GPL");
+
+int VethModuleReopen = 1;
+
+static void
+show_packet(struct sk_buff *skb, char c)
+{
+	int i;
+
+	for (i = 0; i < 60; i++) {
+		if (i >= skb->len)
+			break;
+
+		printk("%02x%c", (unsigned)skb->data[i], c);
+	}
+	printk("\n");
+}
+
+static inline HvLpEvent_Rc 
+veth_signalevent(struct VethLpConnection *cnx, u16 subtype, 
+		 HvLpEvent_AckInd ackind, HvLpEvent_AckType acktype,
+		 u64 token,
+		 u64 data1, u64 data2, u64 data3, u64 data4, u64 data5)
+{
+	return HvCallEvent_signalLpEventFast(cnx->remote_lp,
+					     HvLpEvent_Type_VirtualLan,
+					     subtype, ackind, acktype,
+					     cnx->src_inst,
+					     cnx->dst_inst,
+					     token, data1, data2, data3,
+					     data4, data5);
+}
+
+struct net_device * __init
+veth_probe_one(int idx)
+{
+	struct net_device *dev;
+	struct veth_port *port;
+	int rc;
+
+	dev = alloc_etherdev(sizeof (struct veth_port));
+	if (! dev) {
+		veth_error("Unable to allocate net_device structure!\n");
+		return NULL;
+	}
+
+	port = (struct veth_port *) dev->priv;
+
+	memset(port, 0, sizeof(*port));
+	
+	port->mDev = dev;
+	rwlock_init(&port->mcast_gate);
+
+	dev->dev_addr[0] = 0x02;
+	dev->dev_addr[1] = 0x01;
+	dev->dev_addr[2] = 0xff;
+	dev->dev_addr[3] = idx;
+	dev->dev_addr[4] = 0xff;
+	dev->dev_addr[5] = HvLpConfig_getLpIndex_outline();
+
+	dev->mtu = VETH_MAX_MTU;
+
+	memcpy(&port->mMyAddress, dev->dev_addr, 6);
+
+	dev->open = &veth_open;
+	dev->hard_start_xmit = &veth_start_xmit;
+	dev->stop = &veth_close;
+	dev->get_stats = veth_get_stats;
+	dev->set_multicast_list = &veth_set_multicast_list;
+	dev->do_ioctl = &veth_ioctl;
+
+	rc = register_netdev(dev);
+	if (rc != 0) {
+		veth_printk
+			("Failed to register an ethernet device (veth=%d)\n",
+			 idx);
+		kfree(dev);
+		return NULL;
+	}
+
+	veth_printk("Found an ethernet device %s (veth=%d) (addr=%p)\n",
+		    dev->name, idx, dev);
+
+	return dev;
+}
+
+int __init
+veth_probe(void)
+{
+	int vlans_found = 0;
+	u16 vlan_map = HvLpConfig_getVirtualLanIndexMap();
+	int i;
+
+	memset(veth_devices, 0, sizeof (struct net_device *) * 16);
+	memset(veth_dev_queue_stopped, 0, sizeof (int) * 16);
+
+	for (i = 0; vlan_map != 0; vlan_map <<= 1, i++) {
+		struct net_device *dev = NULL;
+
+		if (! (vlan_map & 0x8000))
+			continue;
+
+		vlans_found++;
+		dev = veth_probe_one(i);
+
+		if (dev) {
+			mFabricMgr->mPorts[i] = (struct veth_port *)dev->priv;
+			veth_devices[veth_num_devices] = dev;
+			veth_num_devices++;
+		}
+	}
+
+	if (vlans_found == 0)
+		return -ENODEV;
+
+	return 0;
+}
+
+void
+veth_proc_delete(struct proc_dir_entry *iSeries_proc)
+{
+	int i = 0;
+	HvLpIndex thisLp = HvLpConfig_getLpIndex_outline();
+	u16 vlanMap = HvLpConfig_getVirtualLanIndexMap();
+	int vlanIndex = 0;
+
+	for (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {
+		if (i == thisLp)
+			continue;
+
+		if (HvLpConfig_doLpsCommunicateOnVirtualLan(thisLp, i)) {
+			char name[10];
+			sprintf(name, "lpar%d", i);
+			remove_proc_entry(name, veth_proc_root);
+		}
+	}
+
+	while (vlanMap != 0) {
+		if (vlanMap & 0x8000) {
+			char name[10];
+			sprintf(name, "veth%d", vlanIndex);
+			remove_proc_entry(name, veth_proc_root);
+		}
+
+		++vlanIndex;
+		vlanMap = vlanMap << 1;
+	}
+
+	remove_proc_entry("veth", iSeries_proc);
+
+	up(&VethProcSemaphore);
+}
+
+void __exit
+veth_module_cleanup(void)
+{
+	int i;
+	struct VethFabricMgr *myFm = mFabricMgr;
+
+	if (! mFabricMgr)
+		return;
+
+	VethModuleReopen = 0;
+	
+	for (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {
+		struct VethLpConnection *cnx = &(mFabricMgr->mConnection[i]);
+		unsigned long flags;
+
+		spin_lock_irqsave(&cnx->status_gate, flags);
+		veth_closeConnection(i);
+		spin_unlock_irqrestore(&cnx->status_gate, flags);
+	}
+	
+	flush_scheduled_work();
+	
+	HvLpEvent_unregisterHandler(HvLpEvent_Type_VirtualLan);
+	
+	mb();
+	mFabricMgr = NULL;
+	mb();
+	
+	down(&VethProcSemaphore);
+	
+	iSeries_proc_callback(&veth_proc_delete);
+	
+	down(&VethProcSemaphore);
+	
+	for (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {
+		struct VethLpConnection *cnx = &myFm->mConnection[i];
+
+		if (cnx->mNumberAllocated + cnx->mNumberRcvMsgs > 0) {
+			mf_deallocateLpEvents(cnx->remote_lp,
+					      HvLpEvent_Type_VirtualLan,
+					      cnx->mNumberAllocated
+					      + cnx->mNumberRcvMsgs,
+					      NULL, NULL);
+		}
+		
+		if (cnx->mMsgs)
+			kfree(cnx->mMsgs);
+	}
+	
+	for (i = 0; i < HvMaxArchitectedVirtualLans; ++i) {
+		struct net_device *dev;
+
+		if (! myFm->mPorts[i])
+			continue;
+
+		dev = myFm->mPorts[i]->mDev;
+		myFm->mPorts[i] = NULL;
+
+		mb();
+			
+		if (dev) {
+			veth_printk("Unregistering %s (veth=%d)\n",
+				    dev->name, i);
+			unregister_netdev(dev);
+			kfree(dev);
+		}
+	}
+	
+	kfree(myFm);
+}
+
+module_exit(veth_module_cleanup);
+
+void
+veth_proc_init(struct proc_dir_entry *iSeries_proc)
+{
+	long i = 0;
+	HvLpIndex thisLp = HvLpConfig_getLpIndex_outline();
+	u16 vlanMap = HvLpConfig_getVirtualLanIndexMap();
+	long vlanIndex = 0;
+
+	veth_proc_root = proc_mkdir("veth", iSeries_proc);
+	if (! veth_proc_root)
+		return;
+
+	for (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {
+		if (i == thisLp)
+			continue;
+
+		if (HvLpConfig_doLpsCommunicateOnVirtualLan(thisLp, i)) {
+			struct proc_dir_entry *ent;
+			char name[10];
+
+			sprintf(name, "lpar%d", (int) i);
+			ent = create_proc_entry(name, S_IFREG | S_IRUSR,
+						veth_proc_root);
+			if (! ent)
+				return;
+			ent->nlink = 1;
+			ent->data = (void *) i;
+			ent->read_proc = proc_veth_dump_connection;
+			ent->write_proc = NULL;
+		}
+	}
+
+	while (vlanMap != 0) {
+		if (vlanMap & 0x8000) {
+			struct proc_dir_entry *ent;
+			char name[10];
+			sprintf(name, "veth%d", (int) vlanIndex);
+			ent = create_proc_entry(name, S_IFREG | S_IRUSR,
+						veth_proc_root);
+			if (! ent)
+				return;
+			ent->nlink = 1;
+			ent->data = (void *) vlanIndex;
+			ent->read_proc = proc_veth_dump_port;
+			ent->write_proc = NULL;
+		}
+
+		++vlanIndex;
+		vlanMap = vlanMap << 1;
+	}
+
+	up(&VethProcSemaphore);
+}
+
+int __init
+veth_module_init(void)
+{
+	int i;
+	int rc;
+
+	mFabricMgr = kmalloc(sizeof (struct VethFabricMgr), GFP_KERNEL);
+	if (! mFabricMgr) {
+		veth_error("Unable to allocate fabric manager\n");
+		return -ENOMEM;
+	}
+
+	memset(mFabricMgr, 0, sizeof (*mFabricMgr));
+	veth_printk("Initializing veth module, fabric mgr (address=%p)\n",
+		    mFabricMgr);
+
+	mFabricMgr->mEyecatcher = 0x56455448464D4752ULL;
+	mFabricMgr->mThisLp = HvLpConfig_getLpIndex_outline();
+
+	for (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {
+		struct VethLpConnection *cnx =
+			&mFabricMgr->mConnection[i];
+
+		cnx->mEyecatcher = 0x564554484C50434EULL;
+		veth_failMe(cnx);
+		spin_lock_init(&cnx->ack_gate);
+		spin_lock_init(&cnx->status_gate);
+	}
+
+	rc = veth_probe();
+	if (rc != 0)
+		return rc;
+
+	veth_printk("%s", version);
+	veth_open_connections();
+	iSeries_proc_callback(&veth_proc_init);
+
+	return 0;
+}
+
+module_init(veth_module_init);
+
+static void
+veth_failMe(struct VethLpConnection *cnx)
+{
+	cnx->status.mSentCap = 0;
+	cnx->status.mCapAcked = 0;
+	cnx->status.mGotCap = 0;
+	cnx->status.mGotCapAcked = 0;
+	cnx->status.mSentMonitor = 0;
+	cnx->status.mFailed = 1;
+}
+
+static int
+veth_open(struct net_device *dev)
+{
+	struct veth_port *port = (struct veth_port *) dev->priv;
+
+	memset(&port->stats, 0, sizeof (port->stats));
+
+	netif_start_queue(dev);
+
+	return 0;
+}
+
+static int
+veth_close(struct net_device *dev)
+{
+	netif_stop_queue(dev);
+
+	return 0;
+}
+
+static struct net_device_stats *
+veth_get_stats(struct net_device *dev)
+{
+	struct veth_port *port = (struct veth_port *) dev->priv;
+
+	return (&port->stats);
+}
+
+static int
+veth_start_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	unsigned char *frame = skb->data;
+	struct veth_port *port = (struct veth_port *) dev->priv;
+	int i;
+	int rc = 1;
+	int individual_rc;
+	int skb_len = skb->len;
+
+	if (! mFabricMgr) {
+		veth_error("NULL fabric manager with active ports!\n");
+		netif_stop_queue(dev);
+		BUG();
+		return 1;
+	}
+
+	if (! (frame[0] & 0x01)) {
+		/* unicast packet */
+		HvLpIndex remoteLp = frame[5];
+
+		if ((remoteLp != mFabricMgr->mThisLp)
+		    &&
+		    (HvLpConfig_doLpsCommunicateOnVirtualLan
+		     (mFabricMgr->mThisLp, remoteLp))) {
+			rc = veth_pTransmit(skb, remoteLp, dev);
+		} else {
+			dev_kfree_skb(skb);
+			rc = 0;
+		}
+	} else {
+		/* broadcast or multicast */
+		for (i = 0; i < HVMAXARCHITECTEDLPS; ++i) {
+			if (i == mFabricMgr->mThisLp)
+				continue;
+
+			if (HvLpConfig_doLpsCommunicateOnVirtualLan
+			    (mFabricMgr->mThisLp, i)) {
+				struct sk_buff *clone =
+					skb_clone(skb, GFP_ATOMIC);
+				
+				if (! clone) {
+					veth_error("skb_clone failed %p\n",
+						   skb);
+					rc = 0;
+					break;
+				}
+				
+				/* the ack handles deleting the skb */
+				individual_rc = veth_pTransmit(clone, i, dev);
+				
+				/* tx failed, we need to free the sbk */
+				if (individual_rc != 0)
+					dev_kfree_skb(clone);
+				
+				/* if we didn't fail from lack of
+				 * buffers, the tx as a whole is
+				 * successful */
+				if (individual_rc != 1)
+					rc = 0;
+			}
+		}
+
+		/* broadcast/multicast - If every connection is out of
+		   buffers (highly unlikely) then we leave rc set to 1
+		   and stop the queue. If any connection fails for any
+		   reason other than out of buffers, then we say the
+		   tx succeeded.
+		 */
+		if (rc == 0)
+			dev_kfree_skb(skb);
+	}
+
+	if (rc != 0) {
+		if (rc == 1) {
+			/* reasons for stopping the queue:
+			   - a non broadcast/multicast packet was destined for a connection that is out of buffers
+			   - a broadcast/multicast packet and every connection was out of buffers
+			 */
+
+			int number = dev->dev_addr[3];
+			++veth_dev_queue_stopped[number];
+			netif_stop_queue(dev);
+		} else {
+			/* reasons for not stopping the queue:
+			   - a non broadcast/multicast packet was destined for a failed connection
+			   - a broadcast/multicast packet and at least one connection had available buffers
+			 */
+			dev_kfree_skb(skb);
+			rc = 0;
+		}
+	} else {
+		port->stats.tx_packets++;
+		port->stats.tx_bytes += skb_len;
+	}
+
+	return rc;
+}
+
+static int
+veth_pTransmit(struct sk_buff *skb, HvLpIndex remoteLp, struct net_device *dev)
+{
+	struct VethLpConnection *cnx =
+		mFabricMgr->mConnection + remoteLp;
+	HvLpEvent_Rc rc;
+	u32 dma_address, dma_length;
+	struct VethMsg *msg = NULL;
+
+/* 	printk("Tx (%d):", remoteLp); */
+/* 	show_packet(skb, ':'); */
+
+	if (cnx->status.mFailed)
+		return 2;
+
+	VETHSTACKPOP(&(cnx->mMsgStack), msg);
+
+	if (! msg)
+		return 1;
+
+	if ((skb->len - 14) > VETH_MAX_MTU) {
+		veth_recycleMsg(cnx, msg);
+		return 2;
+	}
+
+	dma_length = skb->len;
+	dma_address = pci_map_single(iSeries_veth_dev, skb->data,
+				     dma_length, PCI_DMA_TODEVICE);
+	
+	/* Is it really necessary to check the length and address
+	 * fields of the first entry here? */
+	if (dma_address != NO_TCE) {
+		msg->skb = skb;
+		msg->mEvent.mSendData.mAddress[0] = dma_address;
+		msg->mEvent.mSendData.mLength[0] = dma_length;
+		msg->mEvent.mSendData.mEofMask = 1;
+		set_bit(0, &(msg->mInUse));
+		rc = veth_signalevent(cnx,
+				      VethEventTypeFrames,
+				      HvLpEvent_AckInd_NoAck,
+				      HvLpEvent_AckType_ImmediateAck,
+				      msg->mIndex,
+				      msg->mEvent.raw[0],
+				      msg->mEvent.raw[1],
+				      msg->mEvent.raw[2],
+				      msg->mEvent.raw[3],
+				      msg->mEvent.raw[4]);
+	} else {
+		struct veth_port *port = (struct veth_port *) dev->priv;
+		rc = -1;	/* Bad return code */
+		port->stats.tx_errors++;
+	}
+	
+	if (rc != HvLpEvent_Rc_Good) {
+		msg->skb = NULL;
+		/* need to set in use to make veth_recycleMsg in case
+		 * this was a mapping failure */
+		set_bit(0, &(msg->mInUse));
+		veth_recycleMsg(cnx, msg);
+		return 2;
+	}
+
+	return 0;
+}
+
+static int
+veth_ioctl(struct net_device *dev, struct ifreq *ifr, int cmd)
+{
+#ifdef SIOCETHTOOL
+	struct ethtool_cmd ecmd;
+
+	if (cmd != SIOCETHTOOL)
+		return -EOPNOTSUPP;
+	if (copy_from_user(&ecmd, ifr->ifr_data, sizeof (ecmd)))
+		return -EFAULT;
+	switch (ecmd.cmd) {
+	case ETHTOOL_GSET:
+		ecmd.supported =
+		    (SUPPORTED_1000baseT_Full |
+		     SUPPORTED_Autoneg | SUPPORTED_FIBRE);
+		ecmd.advertising =
+		    (SUPPORTED_1000baseT_Full |
+		     SUPPORTED_Autoneg | SUPPORTED_FIBRE);
+
+		ecmd.port = PORT_FIBRE;
+		ecmd.transceiver = XCVR_INTERNAL;
+		ecmd.phy_address = 0;
+		ecmd.speed = SPEED_1000;
+		ecmd.duplex = DUPLEX_FULL;
+		ecmd.autoneg = AUTONEG_ENABLE;
+		ecmd.maxtxpkt = 120;
+		ecmd.maxrxpkt = 120;
+		if (copy_to_user(ifr->ifr_data, &ecmd, sizeof (ecmd)))
+			return -EFAULT;
+		return 0;
+
+	case ETHTOOL_GDRVINFO:{
+			struct ethtool_drvinfo info = { ETHTOOL_GDRVINFO };
+			strncpy(info.driver, "veth", sizeof (info.driver) - 1);
+			info.driver[sizeof (info.driver) - 1] = '\0';
+			strncpy(info.version, "1.0", sizeof (info.version) - 1);
+			if (copy_to_user(ifr->ifr_data, &info, sizeof (info)))
+				return -EFAULT;
+			return 0;
+		}
+		/* get link status */
+	case ETHTOOL_GLINK:{
+			struct ethtool_value edata = { ETHTOOL_GLINK };
+			edata.data = 1;
+			if (copy_to_user(ifr->ifr_data, &edata, sizeof (edata)))
+				return -EFAULT;
+			return 0;
+		}
+
+	default:
+		break;
+	}
+
+#endif
+	return -EOPNOTSUPP;
+}
+
+static void
+veth_set_multicast_list(struct net_device *dev)
+{
+	char *addrs;
+	struct veth_port *port = (struct veth_port *) dev->priv;
+	u64 newAddress = 0;
+	unsigned long flags;
+
+	write_lock_irqsave(&port->mcast_gate, flags);
+
+	if (dev->flags & IFF_PROMISC) {	/* set promiscuous mode */
+		port->mPromiscuous = 1;
+	} else {
+		struct dev_mc_list *dmi = dev->mc_list;
+
+		if ((dev->flags & IFF_ALLMULTI) || (dev->mc_count > 12)) {
+			port->all_mcast = 1;
+		} else {
+			int i;
+			/* Update table */
+			port->mNumAddrs = 0;
+
+			for (i = 0; ((i < dev->mc_count) && (i < 12)); i++) {	/* for each address in the list */
+				addrs = dmi->dmi_addr;
+				dmi = dmi->next;
+				if (addrs[0] & 0x01) {/* multicast address? */
+					memcpy(&newAddress, addrs, 6);
+					port->mMcasts[port->mNumAddrs] =
+					    newAddress;
+					mb();
+					port->mNumAddrs = port->mNumAddrs + 1;
+				}
+			}
+		}
+	}
+
+	write_unlock_irqrestore(&port->mcast_gate, flags);
+}
+
+static void
+veth_handleEvent(struct HvLpEvent *event, struct pt_regs *regs)
+{
+	if (event->xFlags.xFunction == HvLpEvent_Function_Ack)
+		veth_handleAck(event);
+	else if (event->xFlags.xFunction == HvLpEvent_Function_Int)
+		veth_handleInt(event);
+}
+
+static void
+veth_handleAck(struct HvLpEvent *event)
+{
+	struct VethLpConnection *cnx =
+	    &(mFabricMgr->mConnection[event->xTargetLp]);
+	struct VethLpEvent *vethEvent = (struct VethLpEvent *) event;
+
+	switch (event->xSubtype) {
+	case VethEventTypeCap:
+		veth_takeCapAck(cnx, vethEvent);
+		break;
+	case VethEventTypeMonitor:
+		veth_takeMonitorAck(cnx, vethEvent);
+		break;
+	default:
+		veth_error("Unknown ack type %d from lpar %d\n",
+				  event->xSubtype,
+				  cnx->remote_lp);
+
+	};
+}
+
+static void
+veth_handleInt(struct HvLpEvent *event)
+{
+	int i = 0;
+	struct VethLpConnection *cnx =
+	    &(mFabricMgr->mConnection[event->xSourceLp]);
+	struct VethLpEvent *vethEvent = (struct VethLpEvent *) event;
+
+	switch (event->xSubtype) {
+	case VethEventTypeCap:
+		veth_takeCap(cnx, vethEvent);
+		break;
+	case VethEventTypeMonitor:
+		/* do nothing... this'll hang out here til we're dead,
+		 * and the hypervisor will return it for us. */
+		break;
+	case VethEventTypeFramesAck:
+		for (i = 0; i < VethMaxFramesMsgsAcked; ++i) {
+			u16 msg =
+				vethEvent->mDerivedData.mFramesAckData.mToken[i];
+			veth_recycleMsgByNum(cnx, msg);
+		}
+		break;
+	case VethEventTypeFrames:
+		veth_takeFrames(cnx, vethEvent);
+		break;
+	default:
+		veth_error("Unknown interrupt type %d from lpar %d\n",
+				  event->xSubtype, cnx->remote_lp);
+	};
+}
+
+static void
+veth_open_connections(void)
+{
+	int i = 0;
+	int this_lp = mFabricMgr->mThisLp;
+
+	HvLpEvent_registerHandler(HvLpEvent_Type_VirtualLan,
+				  &veth_handleEvent);
+
+	/* Run through the active lps and open connections to the ones
+	 * we need to */
+	/* FIXME: is there any reason to do this backwards? */
+	for (i = HVMAXARCHITECTEDLPS - 1; i >= 0; --i) {
+		struct VethLpConnection *cnx = &mFabricMgr->mConnection[i];
+		unsigned long flags;
+
+		if (i == this_lp)
+			continue;
+
+		init_timer(&cnx->ack_timer);
+		
+		if (HvLpConfig_doLpsCommunicateOnVirtualLan(this_lp, i)) {
+			spin_lock_irqsave(&cnx->status_gate, flags);
+			veth_openConnection(i);
+			spin_unlock_irqrestore(&cnx->status_gate, flags);
+		}
+	}
+}
+
+static void
+veth_intFinishOpeningConnections(void *parm, int number)
+{
+	struct VethLpConnection *cnx = (struct VethLpConnection *) parm;
+	cnx->mAllocTaskTq.data = parm;
+	cnx->mNumberAllocated = number;
+	schedule_work(&cnx->mAllocTaskTq);
+}
+
+static void
+veth_finishOpeningConnections(void *parm)
+{
+	unsigned long flags;
+	struct VethLpConnection *cnx = (struct VethLpConnection *) parm;
+	spin_lock_irqsave(&cnx->status_gate, flags);
+	veth_finishOpeningConnectionsLocked(cnx);
+	spin_unlock_irqrestore(&cnx->status_gate, flags);
+}
+
+static void
+veth_finishOpeningConnectionsLocked(struct VethLpConnection *cnx)
+{
+	if (cnx->mNumberAllocated >= 2) {
+		cnx->status.mCapMonAlloced = 1;
+		veth_sendCap(cnx);
+	} else {
+		veth_error("Couldn't allocate base msgs for lpar %d, only got %d\n",
+			   cnx->remote_lp, cnx->mNumberAllocated);
+		veth_failMe(cnx);
+	}
+}
+
+static void
+veth_openConnection(u8 remoteLp)
+{
+	unsigned long flags;
+	u64 i = 0;
+	struct VethLpConnection *cnx = &mFabricMgr->mConnection[remoteLp];
+
+	INIT_WORK(&cnx->mCapTaskTq, veth_capTask, NULL);
+	INIT_WORK(&cnx->mCapAckTaskTq, veth_capAckTask, NULL);
+	INIT_WORK(&cnx->mMonitorAckTaskTq, veth_monitorAckTask, NULL);
+	INIT_WORK(&cnx->mAllocTaskTq, veth_finishOpeningConnections, NULL);
+
+	cnx->remote_lp = remoteLp;
+
+	spin_lock_irqsave(&cnx->ack_gate, flags);
+
+	memset(&cnx->mEventData, 0xff, sizeof (cnx->mEventData));
+	cnx->mNumAcks = 0;
+
+	HvCallEvent_openLpEventPath(remoteLp, HvLpEvent_Type_VirtualLan);
+
+	/* clean up non-acked msgs */
+	for (i = 0; i < cnx->mNumMsgs; ++i)
+		veth_recycleMsgByNum(cnx, i);
+
+	cnx->status.mOpen = 1;
+
+	cnx->src_inst = 
+		HvCallEvent_getSourceLpInstanceId(remoteLp,
+						  HvLpEvent_Type_VirtualLan);
+	cnx->dst_inst =
+		HvCallEvent_getTargetLpInstanceId(remoteLp,
+						  HvLpEvent_Type_VirtualLan);
+
+	if (! cnx->status.mCapMonAlloced) {
+		cnx->mAllocTaskTq.func =
+			(void *) veth_finishOpeningConnections;
+		mf_allocateLpEvents(remoteLp, HvLpEvent_Type_VirtualLan,
+				    sizeof (struct VethLpEvent), 2,
+				    &veth_intFinishOpeningConnections,
+				    cnx);
+	} else {
+		veth_finishOpeningConnectionsLocked(cnx);
+	}
+
+	spin_unlock_irqrestore(&cnx->ack_gate, flags);
+}
+
+static void
+veth_closeConnection(u8 remoteLp)
+{
+	struct VethLpConnection *cnx =
+	    &(mFabricMgr->mConnection[remoteLp]);
+	unsigned long flags;
+
+	del_timer_sync(&cnx->ack_timer);
+
+	if (cnx->status.mOpen == 1) {
+		HvCallEvent_closeLpEventPath(remoteLp,
+					     HvLpEvent_Type_VirtualLan);
+		cnx->status.mOpen = 0;
+		veth_failMe(cnx);
+
+		/* reset ack data */
+		spin_lock_irqsave(&cnx->ack_gate, flags);
+
+		memset(&cnx->mEventData, 0xff, sizeof (cnx->mEventData));
+		cnx->mNumAcks = 0;
+
+		spin_unlock_irqrestore(&cnx->ack_gate, flags);
+	}
+
+}
+
+static void
+veth_msgsInit(struct VethLpConnection *cnx)
+{
+	cnx->mAllocTaskTq.func = (void *) veth_finishMsgsInit;
+	mf_allocateLpEvents(cnx->remote_lp,
+			    HvLpEvent_Type_VirtualLan,
+			    sizeof (struct VethLpEvent),
+			    cnx->mMyCap.mNumberBuffers,
+			    &veth_intFinishMsgsInit, cnx);
+}
+
+static void
+veth_intFinishMsgsInit(void *parm, int number)
+{
+	struct VethLpConnection *cnx = (struct VethLpConnection *) parm;
+	cnx->mAllocTaskTq.data = parm;
+	cnx->mNumberRcvMsgs = number;
+	schedule_work(&cnx->mAllocTaskTq);
+}
+
+static void
+veth_intFinishCapTask(void *parm, int number)
+{
+	struct VethLpConnection *cnx = (struct VethLpConnection *) parm;
+	cnx->mAllocTaskTq.data = parm;
+	if (number > 0)
+		cnx->mNumberLpAcksAlloced += number;
+	schedule_work(&cnx->mAllocTaskTq);
+}
+
+static void
+veth_finishMsgsInit(struct VethLpConnection *cnx)
+{
+	int i = 0;
+	unsigned int numberGotten = 0;
+	u64 amountOfHeapToGet =
+		cnx->mMyCap.mNumberBuffers *
+		sizeof (struct VethMsg);
+	unsigned long flags;
+	spin_lock_irqsave(&cnx->status_gate, flags);
+
+	if (cnx->mNumberRcvMsgs >=
+	    cnx->mMyCap.mNumberBuffers) {
+		struct VethMsg *msgs;
+
+		msgs = kmalloc(amountOfHeapToGet, GFP_ATOMIC);
+
+		cnx->mMsgs = msgs;
+
+		if (msgs) {
+			memset(msgs, 0, amountOfHeapToGet);
+
+			for (i = 0;
+			     i < cnx->mMyCap.mNumberBuffers;
+			     ++i) {
+				msgs[i].mIndex = i;
+				++numberGotten;
+				VETHSTACKPUSH(&(cnx->mMsgStack),
+					      (cnx->mMsgs + i));
+			}
+			if (numberGotten > 0) {
+				cnx->mNumMsgs = numberGotten;
+			}
+		}
+	}
+
+	cnx->mMyCap.mNumberBuffers =
+	    cnx->mNumMsgs;
+
+	if (cnx->mNumMsgs < 10)
+		cnx->mMyCap.mThreshold = 1;
+	else if (cnx->mNumMsgs < 20)
+		cnx->mMyCap.mThreshold = 4;
+	else if (cnx->mNumMsgs < 40)
+		cnx->mMyCap.mThreshold = 10;
+	else
+		cnx->mMyCap.mThreshold = 20;
+
+	cnx->mMyCap.mTimer = VethAckTimeoutUsec;
+
+	veth_finishSendCap(cnx);
+
+	spin_unlock_irqrestore(&cnx->status_gate, flags);
+}
+
+static void
+veth_sendCap(struct VethLpConnection *cnx)
+{
+	if (cnx->mMsgs == NULL) {
+		cnx->mMyCap.mNumberBuffers =
+		    VethBuffersToAllocate;
+		veth_msgsInit(cnx);
+	} else {
+		veth_finishSendCap(cnx);
+	}
+}
+
+static void
+veth_finishSendCap(struct VethLpConnection *cnx)
+{
+	HvLpEvent_Rc rc;
+	u64 *rawcap = (u64 *) &cnx->mMyCap;
+
+	rc = veth_signalevent(cnx, VethEventTypeCap,
+			      HvLpEvent_AckInd_DoAck,
+			      HvLpEvent_AckType_ImmediateAck,
+			      0, rawcap[0], rawcap[1], rawcap[2], rawcap[3],
+			      rawcap[4]);
+
+	if ( (rc == HvLpEvent_Rc_PartitionDead)
+	     || (rc == HvLpEvent_Rc_PathClosed)) {
+		cnx->status.mSentCap = 0;
+	} else if (rc != HvLpEvent_Rc_Good) {
+		veth_error("Couldn't send cap to lpar %d, rc %x\n",
+				  cnx->remote_lp, (int) rc);
+		veth_failMe(cnx);
+	} else {
+		cnx->status.mSentCap = 1;
+	}
+}
+
+static void
+veth_takeCap(struct VethLpConnection *cnx, struct VethLpEvent *event)
+{
+	if (!test_and_set_bit(0, &(cnx->mCapTaskPending))) {
+		cnx->mCapTaskTq.data = cnx;
+		memcpy(&cnx->mCapEvent, event,
+		       sizeof (cnx->mCapEvent));
+		schedule_work(&cnx->mCapTaskTq);
+	} else {
+		veth_error("Received a capabilities from lpar %d while already processing one\n",
+			   cnx->remote_lp);
+		event->mBaseEvent.xRc = HvLpEvent_Rc_BufferNotAvailable;
+		HvCallEvent_ackLpEvent((struct HvLpEvent *) event);
+	}
+}
+
+static void
+veth_takeCapAck(struct VethLpConnection *cnx, struct VethLpEvent *event)
+{
+	if (!test_and_set_bit(0, &(cnx->mCapAckTaskPending))) {
+		cnx->mCapAckTaskTq.data = cnx;
+		memcpy(&cnx->mCapAckEvent, event,
+		       sizeof (cnx->mCapAckEvent));
+		schedule_work(&cnx->mCapAckTaskTq);
+	} else {
+		veth_error("Received a capabilities ack from lpar %d while already processing one\n",
+			   cnx->remote_lp);
+	}
+}
+
+static void
+veth_takeMonitorAck(struct VethLpConnection *cnx,
+		    struct VethLpEvent *event)
+{
+	if (!test_and_set_bit(0, &(cnx->mMonitorAckTaskPending))) {
+		cnx->mMonitorAckTaskTq.data = cnx;
+		memcpy(&cnx->mMonitorAckEvent, event,
+		       sizeof (cnx->mMonitorAckEvent));
+		schedule_work(&cnx->mMonitorAckTaskTq);
+	} else {
+		veth_error("Received a monitor ack from lpar %d while already processing one\n",
+			   cnx->remote_lp);
+	}
+}
+
+static void
+veth_recycleMsgByNum(struct VethLpConnection *cnx, u16 msg)
+{
+	if (msg < cnx->mNumMsgs) {
+		struct VethMsg *myMsg = cnx->mMsgs + msg;
+		veth_recycleMsg(cnx, myMsg);
+	}
+}
+
+static void
+veth_recycleMsg(struct VethLpConnection *cnx, struct VethMsg *myMsg)
+{
+	u32 dma_address, dma_length;
+
+	if (test_and_clear_bit(0, &(myMsg->mInUse))) {
+		dma_address = myMsg->mEvent.mSendData.mAddress[0];
+		dma_length = myMsg->mEvent.mSendData.mLength[0];
+
+		pci_unmap_single(iSeries_veth_dev, dma_address, dma_length,
+				 PCI_DMA_TODEVICE);
+
+		if (myMsg->skb != NULL) {
+			dev_kfree_skb_any(myMsg->skb);
+			myMsg->skb = NULL;
+		}
+
+		memset(&(myMsg->mEvent.mSendData), 0,
+		       sizeof (struct VethFramesData));
+		VETHSTACKPUSH(&cnx->mMsgStack, myMsg);
+	} else {
+		if (cnx->status.mOpen) {
+			veth_error("Received a frames ack for msg %d from lpar %d while not outstanding\n",
+				   myMsg->mIndex, cnx->remote_lp);
+		}
+	}
+
+	veth_startQueues();
+}
+
+static void
+veth_startQueues(void)
+{
+	int i;
+
+	for (i = 0; i < veth_num_devices; ++i)
+		netif_wake_queue(veth_devices[i]);
+}
+
+static void
+veth_capTask(void *parm)
+{
+	struct VethLpConnection *cnx = (struct VethLpConnection *) parm;
+	struct VethLpEvent *event = &cnx->mCapEvent;
+	unsigned long flags;
+	struct VethCapData *remoteCap = &(cnx->mRemoteCap);
+	u64 numAcks = 0;
+	spin_lock_irqsave(&cnx->status_gate, flags);
+	cnx->status.mGotCap = 1;
+
+	memcpy(remoteCap, &(event->mDerivedData.mCapabilitiesData),
+	       sizeof (cnx->mRemoteCap));
+
+	if ((remoteCap->mNumberBuffers <= VethMaxFramesMsgs)
+	    && (remoteCap->mNumberBuffers != 0)
+	    && (remoteCap->mThreshold <=
+		VethMaxFramesMsgsAcked)
+	    && (remoteCap->mThreshold != 0)) {
+		numAcks =
+		    (remoteCap->mNumberBuffers /
+		     remoteCap->mThreshold) + 1;
+
+		if (cnx->mNumberLpAcksAlloced < numAcks) {
+			numAcks = numAcks - cnx->mNumberLpAcksAlloced;
+			cnx->mAllocTaskTq.func =
+			    (void *) (void *) veth_finishCapTask;
+			mf_allocateLpEvents(cnx->remote_lp,
+					    HvLpEvent_Type_VirtualLan,
+					    sizeof (struct VethLpEvent),
+					    numAcks, &veth_intFinishCapTask,
+					    cnx);
+		} else
+			veth_finishCapTaskLocked(cnx);
+	} else {
+		veth_error("Received incompatible capabilities from lpar %d\n",
+			   cnx->remote_lp);
+		event->mBaseEvent.xRc = HvLpEvent_Rc_InvalidSubtypeData;
+		HvCallEvent_ackLpEvent((struct HvLpEvent *) event);
+	}
+
+	clear_bit(0, &(cnx->mCapTaskPending));
+	spin_unlock_irqrestore(&cnx->status_gate, flags);
+}
+
+static void
+veth_capAckTask(void *parm)
+{
+	struct VethLpConnection *cnx = (struct VethLpConnection *) parm;
+	struct VethLpEvent *event = &cnx->mCapAckEvent;
+	unsigned long flags;
+
+	spin_lock_irqsave(&cnx->status_gate, flags);
+
+	if (event->mBaseEvent.xRc == HvLpEvent_Rc_Good) {
+		cnx->status.mCapAcked = 1;
+
+		if ((cnx->status.mGotCap == 1)
+		    && (cnx->status.mGotCapAcked == 1)) {
+			if (cnx->status.mSentMonitor != 1)
+				veth_sendMonitor(cnx);
+		}
+	} else {
+		veth_printk("Bad rc(%d) from lpar %d on capabilities\n",
+			    event->mBaseEvent.xRc, cnx->remote_lp);
+		veth_failMe(cnx);
+	}
+
+	clear_bit(0, &(cnx->mCapAckTaskPending));
+	spin_unlock_irqrestore(&cnx->status_gate, flags);
+}
+
+static void
+veth_monitorAckTask(void *parm)
+{
+	struct VethLpConnection *cnx = (struct VethLpConnection *) parm;
+	unsigned long flags;
+
+	spin_lock_irqsave(&cnx->status_gate, flags);
+
+	veth_failMe(cnx);
+
+	veth_printk("Monitor ack returned for lpar %d\n",
+		    cnx->remote_lp);
+
+	if (cnx->status.mOpen) {
+		veth_closeConnection(cnx->remote_lp);
+
+		udelay(100);
+
+		schedule_work(&cnx->mMonitorAckTaskTq);
+	} else {
+		if (VethModuleReopen) {
+			veth_openConnection(cnx->remote_lp);
+		} else {
+			int i = 0;
+
+			for (i = 0; i < cnx->mNumMsgs; ++i)
+				veth_recycleMsgByNum(cnx, i);
+		}
+		clear_bit(0, &(cnx->mMonitorAckTaskPending));
+	}
+
+	spin_unlock_irqrestore(&cnx->status_gate, flags);
+}
+
+#define number_of_pages(v, l) ((((unsigned long)(v) & ((1 << 12) - 1)) + (l) + 4096 - 1) / 4096)
+#define page_offset(v) ((unsigned long)(v) & ((1 << 12) - 1))
+
+static void
+veth_takeFrames(struct VethLpConnection *cnx, struct VethLpEvent *event)
+{
+	int i = 0;
+	struct veth_port *port = NULL;
+	struct BufList {
+		union {
+			struct {
+				u32 token2;
+				u32 garbage;
+			} token1;
+			u64 address;
+		} addr;
+		u64 size;
+	};
+	struct BufList myBufList[4];	/* max pages per frame */
+	struct BufList remoteList[VethMaxFramesPerMsg];	/* max frags per frame */
+	unsigned long flags;
+
+	memset(myBufList, 0, sizeof(myBufList));
+	memset(remoteList, 0, sizeof(VethMaxFramesPerMsg));
+
+	do {
+		int nfrags = 0;
+		u16 length = 0;
+
+		/* a 0 address marks the end of the valid entries */
+		if (event->mDerivedData.mSendData.mAddress[i] == 0)
+			break;
+
+		/* make sure that we have at least 1 EOF entry in the
+		 * remaining entries */
+		if (!(event->mDerivedData.mSendData.mEofMask >> i)) {
+			veth_printk
+			    ("bad lp event: missing EOF frag in event mEofMask 0x%x i %d\n",
+			     event->mDerivedData.mSendData.mEofMask, i);
+			break;
+		}
+
+		/* add up length of non-EOF frags */
+		do {
+			remoteList[nfrags].addr.token1.token2 =
+			    event->mDerivedData.mSendData.mAddress[i + nfrags];
+			remoteList[nfrags].addr.token1.garbage = 0;
+			length += remoteList[nfrags].size =
+			    event->mDerivedData.mSendData.mLength[i + nfrags];
+		} while (! (event->mDerivedData.mSendData.mEofMask
+			    & (1 << (i + nfrags++))));
+
+		/* length == total length of all framgents */
+		/* nfrags == # of fragments in this frame */
+
+		if ((length - 14) <= VETH_MAX_MTU) {
+			struct sk_buff *skb = alloc_skb(length, GFP_ATOMIC);
+
+			if (skb != NULL) {
+				HvLpDma_Rc rc = HvLpDma_Rc_Good;
+
+				/* build the buffer list for the dma operation */
+				int numPages = number_of_pages((skb->data), length);	/* number of pages in this fragment of the complete buffer */
+				myBufList[0].addr.address =
+				    (0x8000000000000000LL |
+				     (virt_to_absolute
+				      ((unsigned long) skb->data)));
+				myBufList[0].size =
+				    (numPages > 1) 
+					? (4096 - page_offset(skb->data))
+					: length;
+				if (numPages > 1) {
+					myBufList[1].addr.address =
+					    (0x8000000000000000LL |
+					     (virt_to_absolute
+					      ((unsigned long) skb->data +
+					       myBufList[0].size)));
+					myBufList[1].size =
+					    (numPages > 2) 
+						? 4096 
+						: length - myBufList[0].size;
+					if (numPages > 2) {
+						myBufList[2].addr.address =
+						    (0x8000000000000000LL |
+						     (virt_to_absolute
+						      ((unsigned long) skb->
+						       data +
+						       myBufList[0].size +
+						       myBufList[1].size)));
+						myBufList[2].size =
+						    (numPages >
+						     3) ? 4096 : length -
+						    myBufList[0].size -
+						    myBufList[1].size;
+						if (numPages > 3) {
+							myBufList[3].addr.
+							    address =
+							    0x8000000000000000LL
+							    |
+							    (virt_to_absolute
+							     ((unsigned long)
+							      skb->data +
+							      myBufList[0].
+							      size +
+							      myBufList[1].
+							      size +
+							      myBufList[2].
+							      size));
+							myBufList[3].size =
+							    length -
+							    myBufList[0].size -
+							    myBufList[1].size -
+							    myBufList[2].size;
+						}
+					}
+				}
+				rc = HvCallEvent_dmaBufList(
+					HvLpEvent_Type_VirtualLan,
+					event->mBaseEvent.xSourceLp,
+					HvLpDma_Direction_RemoteToLocal,
+					cnx->src_inst,
+					cnx->dst_inst,
+					HvLpDma_AddressType_RealAddress,
+					HvLpDma_AddressType_TceIndex,
+					0x8000000000000000LL |
+					(virt_to_absolute
+					 ((unsigned long) &myBufList)),
+					0x8000000000000000LL |
+					(virt_to_absolute
+					 ((unsigned long) &remoteList)), length);
+
+				if (rc == HvLpDma_Rc_Good) {
+					HvLpVirtualLanIndex vlan = skb->data[9];
+					u64 dest =
+					    *((u64 *) skb->
+					      data) & 0xFFFFFFFFFFFF0000;
+
+					if (((vlan < HvMaxArchitectedVirtualLans) && ((port = mFabricMgr->mPorts[vlan]) != NULL)) && ((dest == port->mMyAddress) ||	/* it's for me */
+																      (dest == 0xFFFFFFFFFFFF0000) ||	/* it's a broadcast */
+																      (veth_multicast_wanted(port, dest)) ||	/* it's one of my multicasts */
+																      (port->mPromiscuous == 1))) {	/* I'm promiscuous */
+						skb_put(skb, length);
+						skb->dev = port->mDev;
+						skb->protocol =
+						    eth_type_trans(skb,
+								   port->mDev);
+						skb->ip_summed = CHECKSUM_NONE;
+						netif_rx(skb);	/* send it up */
+						port->stats.rx_packets++;
+						port->stats.rx_bytes += length;
+
+					} else {
+						dev_kfree_skb_irq(skb);
+					}
+				} else {
+					dev_kfree_skb_irq(skb);
+				}
+			}
+		} else {
+			break;
+		}
+		i += nfrags;
+	} while (i < VethMaxFramesPerMsg);
+
+	/* Ack it */
+	spin_lock_irqsave(&cnx->ack_gate, flags);
+	
+	if (cnx->mNumAcks < VethMaxFramesMsgsAcked) {
+		cnx->mEventData.mAckData.mToken[cnx->mNumAcks] =
+			event->mBaseEvent.xCorrelationToken;
+		++cnx->mNumAcks;
+		
+		if (cnx->mNumAcks == cnx->mRemoteCap.mThreshold) {
+			HvLpEvent_Rc rc;
+
+			rc = veth_signalevent(cnx,
+					      VethEventTypeFramesAck,
+					      HvLpEvent_AckInd_NoAck,
+					      HvLpEvent_AckType_ImmediateAck,
+					      0,
+					      cnx->mEventData.raw[0],
+					      cnx->mEventData.raw[1],
+					      cnx->mEventData.raw[2],
+					      cnx->mEventData.raw[3],
+					      cnx->mEventData.raw[4]);
+			
+			if (rc != HvLpEvent_Rc_Good) {
+				veth_error("Bad lp event return code(%x) acking frames from lpar %d\n",
+					   (int) rc, cnx->remote_lp);
+			}
+			
+			cnx->mNumAcks = 0;
+			
+			memset(&cnx->mEventData, 0xff, sizeof(cnx->mEventData));
+		}
+		
+	}
+	
+	spin_unlock_irqrestore(&cnx->ack_gate, flags);
+}
+
+#undef number_of_pages
+#undef page_offset
+
+static void
+veth_timedAck(unsigned long connectionPtr)
+{
+	unsigned long flags;
+	HvLpEvent_Rc rc;
+	struct VethLpConnection *cnx =
+	    (struct VethLpConnection *) connectionPtr;
+	/* Ack all the events */
+	spin_lock_irqsave(&cnx->ack_gate, flags);
+
+	if (cnx->mNumAcks > 0) {
+		rc = veth_signalevent(cnx, VethEventTypeFramesAck,
+				      HvLpEvent_AckInd_NoAck,
+				      HvLpEvent_AckType_ImmediateAck,
+				      0,
+				      cnx->mEventData.raw[0],
+				      cnx->mEventData.raw[1],
+				      cnx->mEventData.raw[2],
+				      cnx->mEventData.raw[3],
+				      cnx->mEventData.raw[4]);
+
+		if (rc != HvLpEvent_Rc_Good) {
+			veth_error("Bad lp event return code(%x) acking frames from lpar %d!\n",
+				   (int) rc, cnx->remote_lp);
+		}
+
+		cnx->mNumAcks = 0;
+
+		memset(&cnx->mEventData, 0xff, sizeof(cnx->mEventData));
+	}
+
+	spin_unlock_irqrestore(&cnx->ack_gate, flags);
+
+	veth_startQueues();
+
+	/* Reschedule the timer */
+	cnx->ack_timer.expires = jiffies + cnx->mTimeout;
+	add_timer(&cnx->ack_timer);
+}
+
+static int
+veth_multicast_wanted(struct veth_port *port, u64 mac_addr)
+{
+	int wanted = 0;
+	int i;
+	unsigned long flags;
+
+	if (! (((char *) &mac_addr)[0] & 0x01))
+		return 0;
+
+	read_lock_irqsave(&port->mcast_gate, flags);
+
+	if (port->all_mcast) {
+		wanted = 1;
+		goto out;
+	}
+
+	for (i = 0; i < port->mNumAddrs; ++i) {
+		if (port->mMcasts[i] == mac_addr) {
+			wanted = 1;
+			break;
+		}
+	}
+
+ out:
+	read_unlock_irqrestore(&port->mcast_gate, flags);
+
+	return wanted;
+}
+
+static void
+veth_sendMonitor(struct VethLpConnection *cnx)
+{
+	HvLpEvent_Rc rc;
+
+	rc = veth_signalevent(cnx, VethEventTypeMonitor,
+			      HvLpEvent_AckInd_DoAck,
+			      HvLpEvent_AckType_DeferredAck,
+			      0, 0, 0, 0, 0, 0);
+
+	if (rc == HvLpEvent_Rc_Good) {
+		cnx->status.mSentMonitor = 1;
+		cnx->status.mFailed = 0;
+
+		/* Start the ACK timer */
+		init_timer(&cnx->ack_timer);
+		cnx->ack_timer.function = veth_timedAck;
+		cnx->ack_timer.data = (unsigned long) cnx;
+		cnx->ack_timer.expires = jiffies + cnx->mTimeout;
+		add_timer(&cnx->ack_timer);
+
+	} else {
+		veth_error("Monitor send to lpar %d failed with rc %x\n",
+				  cnx->remote_lp, (int) rc);
+		veth_failMe(cnx);
+	}
+}
+
+static void
+veth_finishCapTask(struct VethLpConnection *cnx)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&cnx->status_gate, flags);
+	veth_finishCapTaskLocked(cnx);
+	spin_unlock_irqrestore(&cnx->status_gate, flags);
+}
+
+static void
+veth_finishCapTaskLocked(struct VethLpConnection *cnx)
+{
+	struct VethLpEvent *event = &cnx->mCapEvent;
+	struct VethCapData *remoteCap = &(cnx->mRemoteCap);
+	int numAcks =
+	    (remoteCap->mNumberBuffers /
+	     remoteCap->mThreshold) + 1;
+
+	/* Convert timer to jiffies */
+	if (cnx->mMyCap.mTimer)
+		cnx->mTimeout =
+		    remoteCap->mTimer * HZ / 1000000;
+	else
+		cnx->mTimeout = VethAckTimeoutUsec * HZ / 1000000;
+
+	if (cnx->mNumberLpAcksAlloced >= numAcks) {
+		HvLpEvent_Rc rc =
+		    HvCallEvent_ackLpEvent((struct HvLpEvent *) event);
+
+		if (rc == HvLpEvent_Rc_Good) {
+			cnx->status.mGotCapAcked = 1;
+
+			if (cnx->status.mSentCap != 1) {
+				cnx->dst_inst =
+				    HvCallEvent_getTargetLpInstanceId
+				    (cnx->remote_lp,
+				     HvLpEvent_Type_VirtualLan);
+
+				veth_sendCap(cnx);
+			} else if (cnx->status.mCapAcked == 1) {
+				if (cnx->status.
+				    mSentMonitor != 1)
+					veth_sendMonitor(cnx);
+			}
+		} else {
+			veth_error("Failed to ack remote cap for lpar %d with rc %x\n",
+				   cnx->remote_lp, (int) rc);
+			veth_failMe(cnx);
+		}
+	} else {
+		veth_error("Couldn't allocate all the frames ack events for lpar %d\n",
+			   cnx->remote_lp);
+		event->mBaseEvent.xRc = HvLpEvent_Rc_BufferNotAvailable;
+		HvCallEvent_ackLpEvent((struct HvLpEvent *) event);
+	}
+}
+
+static int
+proc_veth_dump_connection(char *page, char **start, off_t off, int count,
+			  int *eof, void *data)
+{
+	char *out = page;
+	long cnx_num = (long) data;
+	int len = 0;
+	struct VethLpConnection *cnx = NULL;
+
+	if ((cnx_num < 0) || (cnx_num > HVMAXARCHITECTEDLPS)
+	    || !mFabricMgr) {
+		veth_error("Got bad data from /proc file system\n");
+		len = sprintf(page, "ERROR\n");
+	} else {
+		cnx = &mFabricMgr->mConnection[cnx_num];
+
+		out += sprintf(out, "Remote Lp:\t%d\n", cnx->remote_lp);
+		out += sprintf(out, "Source Inst:\t%04X\n",
+			       cnx->src_inst);
+		out += sprintf(out, "Target Inst:\t%04X\n",
+			       cnx->dst_inst);
+		out += sprintf(out, "Num Msgs:\t%d\n", cnx->mNumMsgs);
+		out += sprintf(out, "Num Lp Acks:\t%d\n",
+			       cnx->mNumberLpAcksAlloced);
+		out += sprintf(out, "Num Acks:\t%d\n", cnx->mNumAcks);
+
+		out += sprintf(out, "<");
+
+		if (cnx->status.mOpen)
+			out += sprintf(out, "Open/");
+
+		if (cnx->status.mCapMonAlloced)
+			out += sprintf(out, "CapMonAlloced/");
+
+		if (cnx->status.mBaseMsgsAlloced)
+			out += sprintf(out, "BaseMsgsAlloced/");
+
+		if (cnx->status.mSentCap)
+			out += sprintf(out, "SentCap/");
+
+		if (cnx->status.mCapAcked)
+			out += sprintf(out, "CapAcked/");
+
+		if (cnx->status.mGotCap)
+			out += sprintf(out, "GotCap/");
+
+		if (cnx->status.mGotCapAcked)
+			out += sprintf(out, "GotCapAcked/");
+
+		if (cnx->status.mSentMonitor)
+			out += sprintf(out, "SentMonitor/");
+
+		if (cnx->status.mPopulatedRings)
+			out += sprintf(out, "PopulatedRings/");
+
+		if (cnx->status.mFailed)
+			out += sprintf(out, "Failed/");
+
+		if (*(out - 1) == '<') {
+			out--;
+		} else {
+			BUG_ON(*(out-1) != '/');
+			out += sprintf(out, ">");
+		}
+
+		out += sprintf(out, "\n");
+
+		out += sprintf(out,
+			       "Capabilities (System:<Version/Buffers/Threshold/Timeout>):\n");
+		out += sprintf(out, "\tLocal:<");
+		out += sprintf(out, "%d/%d/%d/%d>\n", cnx->mMyCap.mVersion,
+			       cnx->mMyCap.mNumberBuffers,
+			       cnx->mMyCap.mThreshold, cnx->mMyCap.mTimer);
+		out += sprintf(out, "\tRemote:<");
+		out += sprintf(out, "%d/%d/%d/%d>\n", cnx->mRemoteCap.mVersion,
+			       cnx->mRemoteCap.mNumberBuffers,
+			       cnx->mRemoteCap.mThreshold, cnx->mRemoteCap.mTimer);
+		len = out - page;
+	}
+	len -= off;
+	if (len < count) {
+		*eof = 1;
+		if (len <= 0)
+			return 0;
+	} else
+		len = count;
+	*start = page + off;
+	return len;
+}
+
+static int
+proc_veth_dump_port(char *page, char **start, off_t off, int count, int *eof,
+		    void *data)
+{
+	char *out = page;
+	long whichPort = (long) data;
+	int len = 0;
+	struct veth_port *port = NULL;
+
+	if ((whichPort < 0) || (whichPort > HvMaxArchitectedVirtualLans)
+	    || (mFabricMgr == NULL)) {
+		len = sprintf(page, "Virtual ethernet is not configured.\n");
+	} else {
+		int i, j;
+		port = mFabricMgr->mPorts[whichPort];
+
+		if (port != NULL) {
+			u64 tmp;
+
+			out += sprintf(out, "Net device:\t%p\n", port->mDev);
+			out += sprintf(out, "Net device name:\t%s\n", port->mDev->name);
+			out += sprintf(out, "Address:\t");
+			tmp = port->mMyAddress;
+			for (j = 0; j < ETH_ALEN; j++) {
+				out += sprintf(out, "%02X",
+					       (unsigned)(tmp >> 56));
+				tmp <<= 8;
+			}
+			printk("\n");
+			out += sprintf(out, "Promiscuous:\t%d\n", port->mPromiscuous);
+			out += sprintf(out, "All multicast:\t%d\n", port->all_mcast);
+			out += sprintf(out, "Number multicast:\t%d\n", port->mNumAddrs);
+
+			for (i = 0; i < port->mNumAddrs; ++i) {
+				tmp = port->mMcasts[i];
+				for (j = 0; j < ETH_ALEN; j++) {
+					out += sprintf(out, "%02X",
+						       (unsigned)(tmp >> 56));
+					tmp <<= 8;
+				}
+			}
+		} else {
+			out += sprintf(page, "veth%ld is not configured.\n",
+				       whichPort);
+		}
+
+		len = out - page;
+	}
+	len -= off;
+	if (len < count) {
+		*eof = 1;
+		if (len <= 0)
+			return 0;
+	} else
+		len = count;
+	*start = page + off;
+	return len;
+}
diff -purN linux-2.5/drivers/net/veth.h linuxppc64-2.5/drivers/net/veth.h
--- linux-2.5/drivers/net/veth.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/net/veth.h	2003-11-21 05:44:52.000000000 +0000
@@ -0,0 +1,172 @@
+/* File veth.h created by Kyle A. Lucke on Mon Aug  7 2000. */
+
+/* Change Activity: */
+/* End Change Activity */
+
+#ifndef _VETH_H
+#define _VETH_H
+
+#include <asm/iSeries/HvTypes.h>
+#include <asm/iSeries/HvLpEvent.h>
+#include <linux/netdevice.h>
+
+#define VethEventTypeCap (0)
+#define VethEventTypeFrames (1)
+#define VethEventTypeMonitor (2)
+#define VethEventTypeFramesAck (3)
+
+#define VethMaxFramesMsgsAcked (20)
+#define VethMaxFramesMsgs (0xFFFF)
+#define VethMaxFramesPerMsg (6)
+#define VethAckTimeoutUsec (1000000)
+
+#define VETHSTACK(T) \
+	struct VethStack##T \
+	{ \
+		struct T *head; \
+		spinlock_t lock; \
+	}
+#define VETHSTACKCTOR(s) \
+	do { (s)->head = NULL; spin_lock_init(&(s)->lock); } while(0)
+#define VETHSTACKPUSH(s, p) \
+	do { \
+		unsigned long flags; \
+		spin_lock_irqsave(&(s)->lock,flags); \
+		(p)->next = (s)->head; \
+		(s)->head = (p); \
+		spin_unlock_irqrestore(&(s)->lock, flags); \
+	} while(0)
+
+#define VETHSTACKPOP(s,p) \
+	do { \
+		unsigned long flags; \
+		spin_lock_irqsave(&(s)->lock,flags); \
+		(p) = (s)->head; \
+		if ((s)->head != NULL) { \
+			(s)->head = (s)->head->next; \
+		} \
+		spin_unlock_irqrestore(&(s)->lock, flags); \
+	} while(0)
+
+struct VethFramesData {
+	u32 mAddress[6];
+	u16 mLength[6];
+	u32 mEofMask:6;
+	u32 mReserved:26;
+};
+
+struct VethFramesAckData {
+	u16 mToken[VethMaxFramesMsgsAcked];
+};
+
+struct VethCapData {
+	u8 mVersion;
+	u8 mReserved1;
+	u16 mNumberBuffers;
+	u16 mThreshold;
+	u16 mReserved2;
+	u32 mTimer;
+	u32 mReserved3;
+	u64 mReserved4;
+	u64 mReserved5;
+	u64 mReserved6;
+};
+
+struct VethFastPathData {
+	u64 mData1;
+	u64 mData2;
+	u64 mData3;
+	u64 mData4;
+	u64 mData5;
+};
+
+struct VethLpEvent {
+	struct HvLpEvent mBaseEvent;
+	union {
+		struct VethFramesData mSendData;
+		struct VethCapData mCapabilitiesData;
+		struct VethFramesAckData mFramesAckData;
+		struct VethFastPathData mFastPathData;
+	} mDerivedData;
+
+};
+
+struct VethMsg {
+	struct VethMsg *next;
+	union {
+		struct VethFramesData mSendData;
+		u64 raw[5];
+	} mEvent;
+	int mIndex;
+	unsigned long mInUse;
+	struct sk_buff *skb;
+};
+
+struct VethLpConnection {
+	u64 mEyecatcher;
+	HvLpIndex remote_lp;
+	HvLpInstanceId src_inst;
+	HvLpInstanceId dst_inst;
+	u32 mNumMsgs;
+	struct VethMsg *mMsgs;
+	int mNumberRcvMsgs;
+	int mNumberLpAcksAlloced;
+	union {
+		struct VethFramesAckData mAckData;
+		u64 raw[5];
+	} mEventData;
+	spinlock_t ack_gate;
+	u32 mNumAcks;
+	spinlock_t status_gate;
+	struct {
+		u64 mOpen:1;
+		u64 mCapMonAlloced:1;
+		u64 mBaseMsgsAlloced:1;
+		u64 mSentCap:1;
+		u64 mCapAcked:1;
+		u64 mGotCap:1;
+		u64 mGotCapAcked:1;
+		u64 mSentMonitor:1;
+		u64 mPopulatedRings:1;
+		u64 mReserved:54;
+		u64 mFailed:1;
+	} status;
+	struct VethCapData mMyCap;
+	struct VethCapData mRemoteCap;
+	unsigned long mCapAckTaskPending;
+	struct work_struct mCapAckTaskTq;
+	struct VethLpEvent mCapAckEvent;
+	unsigned long mCapTaskPending;
+	struct work_struct mCapTaskTq;
+	struct VethLpEvent mCapEvent;
+	unsigned long mMonitorAckTaskPending;
+	struct work_struct mMonitorAckTaskTq;
+	struct VethLpEvent mMonitorAckEvent;
+	unsigned long mAllocTaskPending;
+	struct work_struct mAllocTaskTq;
+	int mNumberAllocated;
+	struct timer_list ack_timer;
+	u32 mTimeout;
+	VETHSTACK(VethMsg) mMsgStack;
+};
+
+#define HVMAXARCHITECTEDVIRTUALLANS 16
+struct veth_port {
+	struct net_device *mDev;
+	struct net_device_stats stats;
+	u64 mMyAddress;
+	int mPromiscuous;
+	int all_mcast;
+	rwlock_t mcast_gate;
+	int mNumAddrs;
+	u64 mMcasts[12];
+};
+
+struct VethFabricMgr {
+	u64 mEyecatcher;
+	HvLpIndex mThisLp;
+	struct VethLpConnection mConnection[HVMAXARCHITECTEDLPS];
+	struct veth_port *mPorts[HVMAXARCHITECTEDVIRTUALLANS];
+};
+
+#endif	/* _VETH_H */
diff -purN linux-2.5/drivers/pci/Makefile linuxppc64-2.5/drivers/pci/Makefile
--- linux-2.5/drivers/pci/Makefile	2003-09-26 16:11:09.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/Makefile	2003-10-03 18:53:00.000000000 +0000
@@ -22,6 +22,7 @@ obj-$(CONFIG_ALPHA) += setup-bus.o setup
 obj-$(CONFIG_ARM) += setup-bus.o setup-irq.o
 obj-$(CONFIG_PARISC) += setup-bus.o
 obj-$(CONFIG_SUPERH) += setup-bus.o setup-irq.o
+obj-$(CONFIG_PPC64) += setup-bus.o
 obj-$(CONFIG_PPC32) += setup-irq.o
 obj-$(CONFIG_PPC64) += setup-bus.o
 obj-$(CONFIG_SGI_IP27) += setup-irq.o
diff -purN linux-2.5/drivers/pci/hotplug/Kconfig linuxppc64-2.5/drivers/pci/hotplug/Kconfig
--- linux-2.5/drivers/pci/hotplug/Kconfig	2003-10-08 22:33:16.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/hotplug/Kconfig	2003-11-19 17:10:13.000000000 +0000
@@ -122,5 +122,28 @@ config HOTPLUG_PCI_CPCI_GENERIC
 
 	  When in doubt, say N.
 
+config HOTPLUG_PCI_RPA
+	tristate "RPA PCI Hotplug driver"
+	depends on HOTPLUG_PCI && PPC64
+	help
+	  Say Y here if you have a a RPA system that supports PCI Hotplug.
+
+	  To compile this driver as a module, choose M here: the
+	  module will be called rpaphp.
+
+	  When in doubt, say N.
+
+config HOTPLUG_PCI_RPA_DLPAR
+	tristate "PPC64 Dynamic Logical Partitioning for I/O slots"
+ 	depends on HOTPLUG_PCI_RPA
+ 	help
+	  Say Y here if your system supports Dynamic Logical Partitioning
+	  for I/O slots.
+
+	  To compile this driver as a module, choose M here: the
+	  module will be called rpadlpar_io.
+ 
+ 	  When in doubt, say N.
+
 endmenu
 
diff -purN linux-2.5/drivers/pci/hotplug/Makefile linuxppc64-2.5/drivers/pci/hotplug/Makefile
--- linux-2.5/drivers/pci/hotplug/Makefile	2003-06-26 00:24:41.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/hotplug/Makefile	2003-11-19 17:10:13.000000000 +0000
@@ -9,6 +9,8 @@ obj-$(CONFIG_HOTPLUG_PCI_IBM)		+= ibmphp
 obj-$(CONFIG_HOTPLUG_PCI_ACPI)		+= acpiphp.o
 obj-$(CONFIG_HOTPLUG_PCI_CPCI_ZT5550)	+= cpcihp_zt5550.o
 obj-$(CONFIG_HOTPLUG_PCI_CPCI_GENERIC)	+= cpcihp_generic.o
+obj-$(CONFIG_HOTPLUG_PCI_RPA)		+= rpaphp.o
+obj-$(CONFIG_HOTPLUG_PCI_RPA_DLPAR)	+= rpadlpar_io.o
 
 pci_hotplug-objs	:=	pci_hotplug_core.o
 
@@ -33,6 +35,12 @@ acpiphp-objs		:=	acpiphp_core.o	\
 				acpiphp_pci.o	\
 				acpiphp_res.o
 
+rpaphp-objs		:=	rpaphp_core.o	\
+				rpaphp_pci.o	
+
+rpadlpar_io-objs	:=	rpadlpar_core.o \
+				rpadlpar_sysfs.o
+
 ifdef CONFIG_HOTPLUG_PCI_ACPI
   EXTRA_CFLAGS  += -D_LINUX -I$(TOPDIR)/drivers/acpi
   ifdef CONFIG_ACPI_DEBUG
diff -purN linux-2.5/drivers/pci/hotplug/rpadlpar.h linuxppc64-2.5/drivers/pci/hotplug/rpadlpar.h
--- linux-2.5/drivers/pci/hotplug/rpadlpar.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/hotplug/rpadlpar.h	2003-11-19 17:06:10.000000000 +0000
@@ -0,0 +1,23 @@
+/*
+ * Interface for Dynamic Logical Partitioning of I/O Slots
+ *
+ * John Rose <johnrose@austin.ibm.com>
+ * October 2003
+ *
+ * Copyright (C) 2003 IBM.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+#ifndef _RPADLPAR_IO_H_
+#define _RPADLPAR_IO_H_
+
+extern int dlpar_sysfs_init(void);
+extern void dlpar_sysfs_exit(void);
+
+extern int dlpar_add_slot(char *drc_name);
+extern int dlpar_remove_slot(char *drc_name);
+
+#endif
diff -purN linux-2.5/drivers/pci/hotplug/rpadlpar_core.c linuxppc64-2.5/drivers/pci/hotplug/rpadlpar_core.c
--- linux-2.5/drivers/pci/hotplug/rpadlpar_core.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/hotplug/rpadlpar_core.c	2003-11-19 17:06:16.000000000 +0000
@@ -0,0 +1,315 @@
+/*
+ * Interface for Dynamic Logical Partitioning of I/O Slots
+ *
+ * John Rose <johnrose@austin.ibm.com>
+ * October 2003
+ *
+ * Copyright (C) 2003 IBM.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+#include <linux/init.h>
+#include <linux/pci.h>
+#include <asm/pci-bridge.h>
+#include "../pci.h"
+#include "rpaphp.h"
+#include "rpadlpar.h"
+
+#define MODULE_VERSION "1.0"
+#define MODULE_NAME "rpadlpar_io"
+
+static inline int is_hotplug_capable(struct device_node *dn)
+{
+	unsigned char *ptr = get_property(dn, "ibm,fw-pci-hot-plug-ctrl", NULL);
+
+	return (int) (ptr != NULL);
+}
+
+static char *get_node_drc_name(struct device_node *dn)
+{
+	char *ptr = NULL;
+	int *drc_names;
+
+	if ((drc_names = (int *) get_property(dn, "ibm,drc-names", NULL)))
+		ptr = (char *) &drc_names[1];
+
+	return ptr;
+}
+
+static struct device_node *find_php_slot_node(char *drc_name)
+{
+	struct device_node *np = NULL;
+	char *name;
+
+	while ((np = of_find_node_by_type(np, "pci")))
+		if (is_hotplug_capable(np)) {
+			name = get_node_drc_name(np);
+			if (name && (!strcmp(drc_name, name)))
+				break;
+		}
+
+	return np;
+}
+
+static inline struct hotplug_slot *find_php_slot(char *drc_name)
+{
+	struct kobject *k;
+
+	if (!(k = kset_find_obj(&pci_hotplug_slots_subsys.kset, drc_name)))
+		return NULL;
+
+	return to_hotplug_slot(k);
+}
+
+static struct slot *find_slot(char *drc_name)
+{
+	struct hotplug_slot *php_slot;
+
+	if (!(php_slot = find_php_slot(drc_name)))
+		return NULL;
+
+	return (struct slot *) php_slot->private;
+}
+
+static void rpadlpar_claim_one_bus(struct pci_bus *b)
+{
+	struct list_head *ld;
+	struct pci_bus *child_bus;
+
+	for (ld = b->devices.next; ld != &b->devices; ld = ld->next) {
+		struct pci_dev *dev = pci_dev_b(ld);
+		int i;
+
+		for (i = 0; i < PCI_NUM_RESOURCES; i++) {
+			struct resource *r = &dev->resource[i];
+
+			if (r->parent || !r->start || !r->flags)
+				continue;
+			rpaphp_claim_resource(dev, i);
+		}
+	}
+
+	list_for_each_entry(child_bus, &b->children, node)
+		rpadlpar_claim_one_bus(child_bus);
+}
+
+static int pci_add_secondary_bus(struct device_node *dn,
+		struct pci_dev *bridge_dev)
+{
+	struct pci_controller *hose = dn->phb;
+	struct pci_bus *child;
+	u8 sec_busno;
+
+	/* Get busno of downstream bus */
+	pci_read_config_byte(bridge_dev, PCI_SECONDARY_BUS, &sec_busno);
+
+	/* Allocate and add to children of bridge_dev->bus */
+	child = pci_add_new_bus(bridge_dev->bus, bridge_dev, sec_busno);
+	if (!child) {
+		printk(KERN_ERR "%s: could not add secondary bus\n", __FUNCTION__);
+		return 1;
+	}
+
+	sprintf(child->name, "PCI Bus #%02x", child->number);
+
+	/* Fixup subordinate bridge bases and resources */
+	pcibios_fixup_bus(child);
+
+	/* Claim new bus resources */
+	rpadlpar_claim_one_bus(bridge_dev->bus);
+
+	if (hose->last_busno < child->number)
+	    	hose->last_busno = child->number;
+
+	dn->bussubno = child->number;
+
+	/* ioremap() for child bus */
+	if (remap_bus_range(child)) {
+		printk(KERN_ERR "%s: could not ioremap() child bus\n",
+				__FUNCTION__);
+		return 1;
+	}
+
+	return 0;
+}
+
+static struct pci_dev *dlpar_pci_add_bus(struct device_node *dn)
+{
+	struct pci_controller *hose = dn->phb;
+	struct pci_dev *dev = NULL;
+
+	/* Scan phb bus for devices, adding new ones to bus->devices */
+	if (!pci_scan_slot(hose->bus, dn->devfn)) {
+		printk(KERN_ERR "%s: found no devices on bus\n", __FUNCTION__);
+		return NULL;
+	}
+
+	/* Add new devices to global lists.  Register in proc, sysfs. */
+	pci_bus_add_devices(hose->bus);
+
+	/* Confirm new bridge dev was created */
+	if (!(dev = rpaphp_find_pci_dev(dn))) {
+		printk(KERN_ERR "%s: failed to add pci device\n", __FUNCTION__);
+		return NULL;
+	}
+
+	if (dev->hdr_type != PCI_HEADER_TYPE_BRIDGE)  {
+		printk(KERN_ERR "%s: unexpected header type %d\n",
+				__FUNCTION__, dev->hdr_type);
+		return NULL;
+	}
+
+	if (pci_add_secondary_bus(dn, dev))
+		return NULL;
+
+	return dev;
+}
+
+static int dlpar_pci_remove_bus(struct pci_dev *bridge_dev)
+{
+	struct pci_bus *secondary_bus;
+
+	if (!bridge_dev) {
+		printk(KERN_ERR "%s: %s() unexpected null device\n", 
+				MODULE_NAME, __FUNCTION__);
+		return 1;
+	}
+
+	secondary_bus = bridge_dev->subordinate;
+
+	if (unmap_bus_range(secondary_bus)) {
+		printk(KERN_ERR "%s: failed to unmap bus range\n", 
+				__FUNCTION__);
+		return 1;
+	}
+
+	pci_remove_bus_device(bridge_dev);
+
+	return 0;
+}
+
+/**
+ * dlpar_add_slot - DLPAR add an I/O Slot
+ * @drc_name: drc-name of newly added slot
+ *
+ * Make the hotplug module and the kernel aware
+ * of a newly added I/O Slot.
+ * Return Codes -
+ * 0			Success
+ * -ENODEV		Not a valid drc_name
+ * -EINVAL		Slot already added
+ * -EIO			Internal PCI Error
+ */
+int dlpar_add_slot(char *drc_name)
+{
+	struct device_node *dn = find_php_slot_node(drc_name);
+	struct pci_dev *dev;
+
+	if (!dn)
+		return -ENODEV;
+
+	/* Check for existing hotplug slot */
+	if (find_slot(drc_name))
+		return -EINVAL;
+
+	/* Add pci bus */
+	dev = dlpar_pci_add_bus(dn);
+	if (!dev) {
+		printk(KERN_ERR "%s: unable to add bus %s\n", __FUNCTION__,
+				drc_name);
+		return -EIO;
+	}
+
+	/* Add hotplug slot for new bus */
+	if (rpaphp_add_slot(drc_name)) {
+		printk(KERN_ERR "%s: unable to add hotplug slot %s\n",
+				__FUNCTION__, drc_name);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+/**
+ * dlpar_remove_slot - DLPAR remove an I/O Slot
+ * @drc_name: drc-name of newly added slot
+ *
+ * Remove the kernel and hotplug representations
+ * of an I/O Slot.
+ * Return Codes:
+ * 0			Success
+ * -ENODEV		Not a valid drc_name
+ * -EINVAL		Slot already removed
+ * -EIO			Internal PCI Error
+ */
+int dlpar_remove_slot(char *drc_name)
+{
+	struct device_node *dn = find_php_slot_node(drc_name);
+	struct slot *slot;
+	struct pci_dev *bridge_dev;
+
+	if (!dn)
+		return -ENODEV;
+
+	if (!(slot = find_slot(drc_name)))
+		return -EINVAL;
+
+	bridge_dev = slot->bridge;
+	if (!bridge_dev) {
+		printk(KERN_ERR "%s: %s(): unexpected null bridge device\n",
+				MODULE_NAME, __FUNCTION__);
+		return -EIO;
+	}
+
+	/* Remove hotplug slot */
+	if (rpaphp_remove_slot(slot)) {
+		printk(KERN_ERR "%s: %s(): unable to remove hotplug slot %s\n",
+				MODULE_NAME, __FUNCTION__, drc_name);
+		return -EIO;
+	}
+
+	/* Remove pci bus */
+	if (dlpar_pci_remove_bus(bridge_dev)) {
+		printk(KERN_ERR "%s: %s() unable to remove pci bus %s\n",
+				MODULE_NAME, __FUNCTION__, drc_name);
+		return -EIO;
+	}
+
+	return 0;
+}
+
+static inline int is_dlpar_capable(void)
+{
+	int rc = rtas_token("ibm,configure-connector");
+
+	return (int) (rc != RTAS_UNKNOWN_SERVICE);
+}
+
+int __init rpadlpar_io_init(void)
+{
+	int rc;
+
+	if (!is_dlpar_capable()) {
+		printk(KERN_WARNING "partition not DLPAR capable, exiting %s\n",
+				MODULE_NAME);
+		return -EPERM;
+	}
+
+	if ((rc = dlpar_sysfs_init()))
+		return rc;
+
+	return 0;
+}
+
+void rpadlpar_io_exit(void)
+{
+	dlpar_sysfs_exit();
+	return;
+}
+
+module_init(rpadlpar_io_init);
+module_exit(rpadlpar_io_exit);
+MODULE_LICENSE("GPL");
diff -purN linux-2.5/drivers/pci/hotplug/rpadlpar_sysfs.c linuxppc64-2.5/drivers/pci/hotplug/rpadlpar_sysfs.c
--- linux-2.5/drivers/pci/hotplug/rpadlpar_sysfs.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/hotplug/rpadlpar_sysfs.c	2003-11-19 17:06:21.000000000 +0000
@@ -0,0 +1,148 @@
+/*
+ * Interface for Dynamic Logical Partitioning of I/O Slots
+ *
+ * John Rose <johnrose@austin.ibm.com>
+ * October 2003
+ *
+ * Copyright (C) 2003 IBM.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+#include <linux/kobject.h>
+#include <linux/string.h>
+#include "pci_hotplug.h"
+#include "rpadlpar.h"
+
+#define DLPAR_KOBJ_NAME       "control"
+#define ADD_SLOT_ATTR_NAME    "add_slot"
+#define REMOVE_SLOT_ATTR_NAME "remove_slot"
+
+#define MAX_DRC_NAME_LEN 64
+
+/* Store return code of dlpar operation in attribute struct */
+struct dlpar_io_attr {
+	int rc;
+	struct attribute attr;
+	ssize_t (*store)(struct dlpar_io_attr *dlpar_attr, const char *buf,
+		size_t nbytes);
+};
+
+/* Common show callback for all attrs, display the return code
+ * of the dlpar op */
+static ssize_t
+dlpar_attr_show(struct kobject * kobj, struct attribute * attr, char * buf)
+{
+	struct dlpar_io_attr *dlpar_attr = container_of(attr,
+						struct dlpar_io_attr, attr);
+	return sprintf(buf, "%d\n", dlpar_attr->rc);
+}
+
+static ssize_t
+dlpar_attr_store(struct kobject * kobj, struct attribute * attr,
+		 const char *buf, size_t nbytes)
+{
+	struct dlpar_io_attr *dlpar_attr = container_of(attr,
+						struct dlpar_io_attr, attr);
+	return dlpar_attr->store ?
+		dlpar_attr->store(dlpar_attr, buf, nbytes) : 0;
+}
+
+static struct sysfs_ops dlpar_attr_sysfs_ops = {
+	.show = dlpar_attr_show,
+	.store = dlpar_attr_store,
+};
+
+static ssize_t add_slot_store(struct dlpar_io_attr *dlpar_attr,
+				const char *buf, size_t nbytes)
+{
+	char drc_name[MAX_DRC_NAME_LEN];
+	char *end;
+
+	if (nbytes > MAX_DRC_NAME_LEN)
+		return 0;
+
+	memcpy(drc_name, buf, nbytes);
+
+	if (!(end = strchr(drc_name, '\n')))
+		end = &drc_name[nbytes];
+	*end = '\0';
+
+	dlpar_attr->rc = dlpar_add_slot(drc_name);
+
+	return nbytes;
+}
+
+static ssize_t remove_slot_store(struct dlpar_io_attr *dlpar_attr,
+		 		const char *buf, size_t nbytes)
+{
+	char drc_name[MAX_DRC_NAME_LEN];
+	char *end;
+
+	if (nbytes > MAX_DRC_NAME_LEN)
+		return 0;
+
+	memcpy(drc_name, buf, nbytes);
+
+	if (!(end = strchr(drc_name, '\n')))
+		end = &drc_name[nbytes];
+	*end = '\0';
+
+	dlpar_attr->rc = dlpar_remove_slot(drc_name);
+
+	return nbytes;
+}
+
+static struct dlpar_io_attr add_slot_attr = {
+	.rc = 0,
+	.attr = { .name = ADD_SLOT_ATTR_NAME, .mode = 0644, },
+	.store = add_slot_store,
+};
+
+static struct dlpar_io_attr remove_slot_attr = {
+	.rc = 0,
+	.attr = { .name = REMOVE_SLOT_ATTR_NAME, .mode = 0644},
+	.store = remove_slot_store,
+};
+
+static struct attribute *default_attrs[] = {
+	&add_slot_attr.attr,
+	&remove_slot_attr.attr,
+	NULL,
+};
+
+static void dlpar_io_release(struct kobject *kobj)
+{
+	/* noop */
+	return;	
+}
+
+struct kobj_type ktype_dlpar_io = {
+	.release = dlpar_io_release,
+	.sysfs_ops = &dlpar_attr_sysfs_ops,
+	.default_attrs = default_attrs,
+};
+
+struct kset dlpar_io_kset = {
+	.subsys = &pci_hotplug_slots_subsys,
+	.kobj = {.name = DLPAR_KOBJ_NAME, .ktype=&ktype_dlpar_io,},
+	.ktype = &ktype_dlpar_io,
+};
+
+int dlpar_sysfs_init(void)
+{
+	if (kset_register(&dlpar_io_kset)) {
+		printk(KERN_ERR "rpadlpar_io: cannot register kset for %s\n",
+				dlpar_io_kset.kobj.name);
+		return -EINVAL;
+	}
+
+	return 0;
+}
+
+void dlpar_sysfs_exit(void)
+{
+	kset_unregister(&dlpar_io_kset);
+}
diff -purN linux-2.5/drivers/pci/hotplug/rpaphp.h linuxppc64-2.5/drivers/pci/hotplug/rpaphp.h
--- linux-2.5/drivers/pci/hotplug/rpaphp.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/hotplug/rpaphp.h	2003-11-17 23:08:19.000000000 +0000
@@ -0,0 +1,106 @@
+/*
+ * PPC64 PCI Hot Plug Controller Driver
+ *
+ * Copyright (c) 2003 Linda Xie <lxie@us.ibm.com>
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or (at
+ * your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to <lxie@us.ibm.com>,
+ *
+ */
+
+#ifndef _PPC64PHP_H
+#define _PPC64PHP_H
+#include "pci_hotplug.h"
+
+#define DR_INDICATOR 9002
+#define DR_ENTITY_SENSE 9003
+
+#define POWER_ON	100
+#define POWER_OFF	0
+
+#define LED_OFF		0 
+#define LED_ON		1	/* continuous on */ 
+#define LED_ID		2	/* slow blinking */
+#define LED_ACTION	3	/* fast blinking */
+
+#define SLOT_NAME_SIZE 12
+
+/* Error status from rtas_get-sensor */
+#define NEED_POWER    -9000     /* slot must be power up and unisolated to get state */
+#define PWR_ONLY      -9001     /* slot must be powerd up to get state, leave isolated */
+#define ERR_SENSE_USE -9002     /* No DR operation will succeed, slot is unusable  */
+
+/* Sensor values from rtas_get-sensor */
+#define EMPTY           0       /* No card in slot */
+#define PRESENT         1       /* Card in slot */
+
+#if !defined(CONFIG_HOTPLUG_PCI_MODULE)
+	#define MY_NAME "rpaphp"
+#else
+	#define MY_NAME THIS_MODULE->name
+#endif
+
+
+#define dbg(format, arg...)					\
+	do {							\
+		if (rpaphp_debug)				\
+			printk(KERN_DEBUG "%s: " format,	\
+				MY_NAME , ## arg); 		\
+	} while (0)
+#define err(format, arg...) printk(KERN_ERR "%s: " format, MY_NAME , ## arg)
+#define info(format, arg...) printk(KERN_INFO "%s: " format, MY_NAME , ## arg)
+#define warn(format, arg...) printk(KERN_WARNING "%s: " format, MY_NAME , ## arg)
+
+#define SLOT_MAGIC	0x67267322
+
+/* slot states */
+
+#define	NOT_VALID	3
+#define	NOT_CONFIGURED	2
+#define	CONFIGURED	1
+#define	EMPTY		0
+
+/*
+ * struct slot - slot information for each *physical* slot
+ */
+struct slot {
+	u32	magic;
+        int     state;
+        u32     index;
+        u32     type;
+        u32     power_domain;
+        char    *name;
+	struct	device_node *dn;/* slot's device_node in OFDT		*/
+				/* dn has phb info			*/
+	struct	pci_dev	*bridge;/* slot's pci_dev in pci_devices	*/
+
+	struct	pci_dev	*dev;	/* pci_dev of device in this slot 	*/
+				/* it will be used for unconfig		*/ 
+				/* NULL if slot is empty		*/
+
+	struct  hotplug_slot    *hotplug_slot;
+	struct list_head	rpaphp_slot_list;
+};
+
+extern struct pci_dev *rpaphp_find_pci_dev(struct device_node *dn);
+extern int rpaphp_add_slot(char *slot_name);
+extern int rpaphp_remove_slot(struct slot *slot);
+extern int rpaphp_claim_resource(struct pci_dev *dev, int resource);
+
+#endif /* _PPC64PHP_H */
diff -purN linux-2.5/drivers/pci/hotplug/rpaphp_core.c linuxppc64-2.5/drivers/pci/hotplug/rpaphp_core.c
--- linux-2.5/drivers/pci/hotplug/rpaphp_core.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/hotplug/rpaphp_core.c	2003-11-17 23:08:20.000000000 +0000
@@ -0,0 +1,1044 @@
+/*
+ * PRA PCI Hot Plug Controller Driver
+ * Copyright (c) 2003 Linda Xie <lxie@us.ibm.com>
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or (at
+ * your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to <lxie@us.ibm.com>
+ *
+ */
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/pci.h>
+#include <linux/slab.h>
+#include <linux/smp.h>
+#include <linux/smp_lock.h>
+#include <linux/init.h>
+#include <asm/rtas.h>		/* rtas_call */
+#include <asm/pci-bridge.h>	/* for pci_controller */
+#include "../pci.h"		/* for pci_add_new_bus*/
+				/* and pci_do_scan_bus*/
+#include "rpaphp.h"
+#include "pci_hotplug.h"
+
+
+static int debug; 
+static struct semaphore rpaphp_sem; 
+static int rpaphp_debug;
+static LIST_HEAD (rpaphp_slot_head);
+static int num_slots = 0;
+
+#define DRIVER_VERSION	"0.1"
+#define DRIVER_AUTHOR	"Linda Xie <lxie@us.ibm.com>"
+#define DRIVER_DESC	"RPA HOT Plug PCI Controller Driver"
+
+MODULE_AUTHOR(DRIVER_AUTHOR);
+MODULE_DESCRIPTION(DRIVER_DESC);
+MODULE_LICENSE("GPL");
+MODULE_PARM(debug, "i");
+MODULE_PARM_DESC(debug, "Debugging mode enabled or not");
+
+static int enable_slot		(struct hotplug_slot *slot);
+static int disable_slot		(struct hotplug_slot *slot);
+static int set_attention_status (struct hotplug_slot *slot, u8 value);
+static int get_power_status	(struct hotplug_slot *slot, u8 *value);
+static int get_attention_status	(struct hotplug_slot *slot, u8 *value);
+static int get_adapter_status	(struct hotplug_slot *slot, u8 *value);
+static int get_max_bus_speed	(struct hotplug_slot *hotplug_slot, enum pci_bus_speed *value);
+static int get_cur_bus_speed	(struct hotplug_slot *hotplug_slot, enum pci_bus_speed *value);
+
+static struct hotplug_slot_ops rpaphp_hotplug_slot_ops = {
+	.owner			= THIS_MODULE,
+	.enable_slot		= enable_slot,
+	.disable_slot		= disable_slot,
+	.set_attention_status	= set_attention_status,
+	.get_power_status	= get_power_status,
+	.get_attention_status	= get_attention_status,
+	.get_adapter_status	= get_adapter_status,
+	.get_max_bus_speed	= get_max_bus_speed,
+	.get_cur_bus_speed	= get_cur_bus_speed,
+};
+
+static int rpaphp_get_sensor_state(int index, int *state)
+{
+	int rc;
+
+        rc = rtas_get_sensor(DR_ENTITY_SENSE, index, state);
+			
+        if (rc) {
+		if (rc ==  NEED_POWER || rc == PWR_ONLY) {
+			dbg("%s: slot must be power up to get sensor-state\n", 
+				__FUNCTION__);
+		} else if (rc == ERR_SENSE_USE) 
+			info("%s: slot is unusable\n", __FUNCTION__);
+		   else err("%s failed to get sensor state\n", __FUNCTION__);
+	}
+	return rc;
+}
+
+static struct pci_dev *rpaphp_find_bridge_pdev(struct slot *slot)
+{
+	struct pci_dev		*retval_dev = NULL;
+			
+	retval_dev = rpaphp_find_pci_dev(slot->dn);	
+
+	return retval_dev;
+}
+
+static struct pci_dev *rpaphp_find_adapter_pdev(struct slot *slot)
+{
+	struct pci_dev * retval_dev = NULL;
+
+	retval_dev = rpaphp_find_pci_dev(slot->dn->child);	
+
+	return retval_dev;
+}
+
+
+/* Inline functions to check the sanity of a pointer that is passed to us */
+static inline int slot_paranoia_check(struct slot *slot, const char *function)
+{
+	if (!slot) {
+		dbg("%s - slot == NULL\n", function);
+		return -1;
+	}
+	
+	if (!slot->hotplug_slot) {
+		dbg("%s - slot->hotplug_slot == NULL!\n", function);
+		return -1;
+	}
+	return 0;
+}
+
+static inline struct slot *get_slot(struct hotplug_slot *hotplug_slot, const char *function)
+{
+	struct slot *slot;
+
+	if (!hotplug_slot) {
+		dbg("%s - hotplug_slot == NULL\n", function);
+		return NULL;
+	}
+
+	slot = (struct slot *)hotplug_slot->private;
+	if (slot_paranoia_check(slot, function))
+                return NULL;
+	return slot;
+}
+
+static inline int rpaphp_set_attention_status(struct slot *slot, u8 status)
+{
+	int	rc;
+
+	dbg("Entry %s: status=%d\n", __FUNCTION__, status);
+	
+	/* status: LED_OFF or LED_ON */
+	rc = rtas_set_indicator(DR_INDICATOR, slot->index, status);
+	if (rc)
+		err("slot(%s) set attention-status(%d) failed! rc=0x%x\n", 
+			slot->name, status, rc); 
+
+	dbg("Exit %s, rc=0x%x\n", __FUNCTION__, rc);
+
+	return rc;
+}
+
+static int rpaphp_get_power_status(struct slot *slot, u8 *value)
+{
+	int	rc;
+
+        rc = rtas_get_power_level(slot->power_domain, (int *)value);
+        if (rc) 
+                err("failed to get power-level for slot(%s), rc=0x%x\n", 
+			slot->name, rc);
+	
+        return rc;
+}
+
+static int rpaphp_get_attention_status(struct slot *slot)
+{
+
+	return slot->hotplug_slot->info->attention_status;
+}
+
+/**
+ * set_attention_status - set attention LED
+ * echo 0 > attention -- set LED OFF
+ * echo 1 > attention -- set LED ON
+ * echo 2 > attention -- set LED ID(identify, light is blinking)
+ *
+ */
+static int set_attention_status (struct hotplug_slot *hotplug_slot, u8 value)
+{
+	int retval = 0;
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+
+	if (slot == NULL)
+		return -ENODEV;
+
+	dbg("%s - Entry: slot[%s] value[0x%x]\n", 
+		__FUNCTION__, slot->name, value);
+	down(&rpaphp_sem);
+	switch (value) {
+		case 0:
+			retval = rpaphp_set_attention_status(slot, LED_OFF);
+			hotplug_slot->info->attention_status = 0;
+			break;
+
+		case 1:
+		default:
+			retval = rpaphp_set_attention_status(slot, LED_ON);
+			hotplug_slot->info->attention_status = 1;
+			break;
+
+		case 2:
+			retval = rpaphp_set_attention_status(slot, LED_ID);
+			hotplug_slot->info->attention_status = 2;
+			break;
+
+	}
+	up(&rpaphp_sem);
+
+	dbg("%s - Exit: rc[%d]\n",  __FUNCTION__, retval);
+	return retval;
+}
+
+/**
+ * get_power_status - get power status of a slot
+ * @hotplug_slot: slot to get status
+ * @value: pointer to store status
+ *
+ *
+ */
+static int get_power_status (struct hotplug_slot *hotplug_slot, u8 *value)
+{
+	int retval;
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+	
+	if (slot == NULL)
+		return -ENODEV;
+
+	down(&rpaphp_sem);
+	retval = rpaphp_get_power_status(slot, value);
+	up(&rpaphp_sem);
+
+	return retval;
+}
+
+/**
+ * get_attention_status - get attention LED status
+ *
+ *
+ */
+static int get_attention_status (struct hotplug_slot *hotplug_slot, u8 *value)
+{
+	int retval = 0;
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+
+	if (slot == NULL)
+		return -ENODEV;
+
+
+	dbg("%s - Entry: slot[%s]\n",
+		__FUNCTION__, slot->name);
+
+	down(&rpaphp_sem);
+	*value = rpaphp_get_attention_status(slot);
+	up(&rpaphp_sem);
+
+	dbg("%s - Exit: value[0x%x] rc[%d]\n",
+		__FUNCTION__, *value, retval);
+	return retval;
+}
+
+/*
+ * get_adapter_status - get  the status of a slot
+ * 
+ * 0-- slot is empty
+ * 1-- adapter is configured
+ * 2-- adapter is not configured
+ * 3-- not valid
+ */
+static int rpaphp_get_adapter_status(struct slot *slot, int is_init, u8 *value)
+{
+	int	state, rc;
+
+	dbg("Entry %s\n", __FUNCTION__);
+
+	*value 		  = NOT_VALID;	
+
+	rc = rpaphp_get_sensor_state(slot->index, &state);	
+		
+	if (rc) 
+		goto exit;		
+
+	if (state == PRESENT) {
+		dbg("slot is occupied\n");
+	   
+		if (!is_init) /* at run-time slot->state can be changed by */
+			  /* config/unconfig adapter	 		   */
+			*value = slot->state;
+		else {
+		if (!slot->dn->child) 
+			dbg("%s: %s is not valid OFDT node\n", 
+				__FUNCTION__, slot->dn->full_name);
+		else 
+			if (rpaphp_find_pci_dev(slot->dn->child)) 
+				*value = CONFIGURED;
+			else {
+				dbg("%s: can't find pdev of adapter in slot[%s]\n",
+					__FUNCTION__, slot->name);
+				*value = NOT_CONFIGURED;	
+				}
+		}
+	}
+	else
+		if (state == EMPTY) {
+		dbg("slot is empty\n");
+			*value = state;
+		}
+		 
+exit:    dbg("Exit %s slot[%s] has adapter-status %d rtas call's rc=0x%x\n",
+		__FUNCTION__, slot->name, *value, rc);
+
+	return rc;
+}
+
+static int get_adapter_status (struct hotplug_slot *hotplug_slot, u8 *value)
+{
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+	int retval = 0;
+
+	if (slot == NULL)
+		return -ENODEV;
+
+	down(&rpaphp_sem);
+
+	/*  have to go through this */
+	retval = rpaphp_get_adapter_status(slot, 0, value);
+
+	up(&rpaphp_sem);
+
+	return retval;
+}
+
+
+static int get_max_bus_speed (struct hotplug_slot *hotplug_slot, enum pci_bus_speed *value)
+{
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+
+	if (slot == NULL)
+		return -ENODEV;
+	
+	dbg("%s - Entry: slot->name[%s] slot->type[%d]\n",
+		__FUNCTION__, slot->name, slot->type);
+
+	down(&rpaphp_sem);	
+
+	switch (slot->type) {
+		case 1:	
+		case 2:
+		case 3:
+		case 4:
+		case 5:
+		case 6:
+			*value = PCI_SPEED_33MHz;	/* speed for case 1-6 */
+			break;
+		case 7:
+		case 8:
+			*value = PCI_SPEED_66MHz;
+			break;
+		case 11:
+		case 14:
+			*value = PCI_SPEED_66MHz_PCIX;
+			break;
+		case 12:
+		case 15:
+			*value = PCI_SPEED_100MHz_PCIX;
+			break;
+		case 13:
+		case 16:
+			*value = PCI_SPEED_133MHz_PCIX;
+			break;
+		default:
+			*value = PCI_SPEED_UNKNOWN;
+			break;
+ 
+	}
+
+	up(&rpaphp_sem);	
+
+	return 0;
+}
+
+
+/* return dummy value because not sure if PRA provides any method... */
+static int get_cur_bus_speed (struct hotplug_slot *hotplug_slot, enum pci_bus_speed *value)
+{
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+
+	if (slot == NULL)
+		return -ENODEV;
+
+	*value = PCI_SPEED_UNKNOWN;
+
+	return 0;
+}
+
+/* 
+ * rpaphp_validate_slot - make sure the name of the slot matches
+ * 				the location code , if the slots is not
+ *				empty.
+ */
+static int rpaphp_validate_slot(const char *slot_name, const int slot_index)
+{
+	struct device_node	*dn;
+	int			retval = 0;
+	
+	dbg("Entry %s: (name: %s index: 0x%x\n", 
+		__FUNCTION__, slot_name, slot_index);
+
+	for(dn = find_all_nodes(); dn; dn = dn->next) { 
+
+		int 		*index;
+		unsigned char	*loc_code;
+
+		index  = (int *)get_property(dn, "ibm,my-drc-index", NULL);
+
+		if (index && *index == slot_index) {
+		char *slash, tmp_str[128];
+
+			loc_code = get_property(dn, "ibm,loc-code", NULL);     
+		if (!loc_code) {
+			retval = -1;
+			goto exit;
+		}
+
+		dbg("%s: name=%s loc-code=%s index=0x%x\n",
+			__FUNCTION__, slot_name, loc_code, slot_index);
+		
+		strcpy(tmp_str, loc_code);
+		slash = strrchr(tmp_str, '/');
+		if (slash) {
+			*slash = '\0';
+		}
+		if (strcmp(slot_name, tmp_str)) 
+			retval = -1;
+		goto exit;	
+		}
+
+	}
+
+exit:
+	dbg("Exit %s with retval=%d\n", __FUNCTION__, retval);
+
+	return retval;
+}
+
+/* Must be called before pci_bus_add_devices */
+static void rpaphp_fixup_new_devices(struct pci_bus *bus)
+{
+	struct pci_dev *dev;
+	
+	dbg("Enter rpaphp_fixup_new_devices()\n");
+
+	list_for_each_entry(dev, &bus->devices, bus_list) {
+	/*
+	 * Skip already-present devices (which are on the
+	 * global device list.)
+	 */
+		if (list_empty(&dev->global_list)) {
+			int i;
+			pcibios_fixup_device_resources(dev, bus);
+			pci_read_irq_line(dev);
+			for (i = 0; i < PCI_NUM_RESOURCES; i++) {
+                        	struct resource *r = &dev->resource[i];
+                        	if (r->parent || !r->start || !r->flags)
+                                	continue;
+                        	rpaphp_claim_resource(dev, i);
+                	}
+
+		}
+	}
+}
+
+static struct pci_dev *rpaphp_config_adapter(struct slot *slot) 
+{
+	struct pci_bus 		*pci_bus;
+	struct device_node	*dn;
+	int 			num;
+	struct pci_dev		*dev = NULL;
+
+	dbg("Entry %s: slot[%s]\n",
+		__FUNCTION__, slot->name); 
+
+	if (slot->bridge) {
+				
+		pci_bus = slot->bridge->subordinate;
+		
+		if (!pci_bus) {
+			err("%s: can't find bus structure\n", __FUNCTION__);
+			goto exit;
+		}
+
+		for (dn = slot->dn->child; dn; dn = dn->sibling) {
+			dbg("child dn's devfn=[%x]\n", dn->devfn);
+				num = pci_scan_slot(pci_bus, 
+				PCI_DEVFN(PCI_SLOT(dn->devfn),  0));
+
+				dbg("pci_scan_slot return num=%d\n", num);
+
+			if (num) {
+				dbg("%s: calling rpaphp_fixup_new_devices()\n",
+					__FUNCTION__);
+				rpaphp_fixup_new_devices(pci_bus);
+				pci_bus_add_devices(pci_bus);
+			}
+		}
+
+		dev = rpaphp_find_pci_dev(slot->dn->child);
+	}
+	else {
+		/* slot is not enabled */
+		err("slot doesn't have pci_dev structure\n");
+		dev = NULL;
+		goto exit;
+	} 	
+
+exit:	
+	dbg("Exit %s: pci_dev %s\n", __FUNCTION__, dev? "found":"not found");
+
+	return dev;
+}
+
+static int rpaphp_unconfig_adapter(struct slot *slot) 
+{
+	int			retval = 0;
+
+	dbg("Entry %s: slot[%s]\n", 
+		__FUNCTION__, slot->name); 
+	if (!slot->dev) {
+		info("%s: no card in slot[%s]\n",
+			__FUNCTION__, slot->name);
+
+		retval = -EINVAL;
+		goto exit;	
+	}
+
+
+        /* remove the device from the pci core */
+        pci_remove_bus_device(slot->dev);
+
+        pci_dev_put(slot->dev);
+        slot->state = NOT_CONFIGURED;
+	
+	dbg("%s: adapter in slot[%s] unconfigured.\n", __FUNCTION__, slot->name);
+		
+exit:
+	dbg("Exit %s, rc=0x%x\n", __FUNCTION__, retval);
+
+	return retval;
+		
+}
+
+/* free up the memory user be a slot */
+
+static void rpaphp_release_slot(struct hotplug_slot *hotplug_slot)
+{
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+	
+	if (slot == NULL)
+		return;
+
+	dbg("%s - Entry: slot[%s]\n",
+		__FUNCTION__, slot->name);
+	kfree(slot->hotplug_slot->info);
+	kfree(slot->hotplug_slot->name);
+	kfree(slot->hotplug_slot);
+	pci_dev_put(slot->bridge);
+	pci_dev_put(slot->dev);
+	kfree(slot);
+	dbg("%s - Exit\n", __FUNCTION__);
+}
+
+int rpaphp_remove_slot(struct slot *slot)
+{
+	int retval = 0;
+
+	dbg("%s - Entry: slot[%s]\n",
+		__FUNCTION__, slot->name);
+
+  	sysfs_remove_link(slot->hotplug_slot->kobj.parent,
+                          slot->bridge->slot_name);
+	
+	list_del(&slot->rpaphp_slot_list);
+	retval = pci_hp_deregister(slot->hotplug_slot);
+	if (retval)
+		err("Problem unregistering a slot %s\n", slot->name);
+
+	kfree(slot->hotplug_slot->info);
+	kfree(slot->hotplug_slot->name);
+	kfree(slot->hotplug_slot);
+	kfree(slot);
+	num_slots--;
+
+	dbg("%s - Exit: rc[%d]\n", __FUNCTION__, retval);
+	return retval;	
+}
+
+static int is_php_dn(struct device_node *dn, int **indexes,  int **names, int **types, int **power_domains)
+{
+	*indexes = (int *)get_property(dn, "ibm,drc-indexes", NULL);
+	if (!indexes)
+		return(0);
+
+	/* &names[1] contains NULL terminated slot names */
+	*names = (int *)get_property(dn, "ibm,drc-names", NULL);
+	if (!names) 
+		return(0);
+
+	/* &types[1] contains NULL terminated slot types */
+	*types = (int *)get_property(dn, "ibm,drc-types", NULL);
+	if (!types)
+		return(0);
+
+	/* power_domains[1...n] are the slot power domains */
+	*power_domains = (int *)get_property(dn,
+		"ibm,drc-power-domains", NULL);
+	if (!power_domains) 
+		return(0);
+
+	if (!get_property(dn, "ibm,fw-pci-hot-plug-ctrl", NULL))
+		return(0);
+
+	return(1);
+}
+
+static struct slot *alloc_slot_struct(void)
+{
+	struct slot *slot;
+
+	slot = kmalloc(sizeof(struct slot), GFP_KERNEL);
+	if (!slot) 
+		return (NULL);
+	memset(slot, 0, sizeof(struct slot));
+	slot->hotplug_slot = kmalloc(sizeof(struct hotplug_slot), 	
+		GFP_KERNEL);
+	if (!slot->hotplug_slot) {
+		kfree(slot);
+		return (NULL);
+        }                
+	memset(slot->hotplug_slot, 0, sizeof(struct hotplug_slot));
+	slot->hotplug_slot->info = kmalloc(sizeof(struct hotplug_slot_info), 
+		GFP_KERNEL);
+	if (!slot->hotplug_slot->info) {
+		kfree(slot->hotplug_slot);
+		kfree(slot);
+		return (NULL);
+	}
+	memset(slot->hotplug_slot->info, 0, sizeof(struct hotplug_slot_info));
+	slot->hotplug_slot->name = kmalloc(SLOT_NAME_SIZE, GFP_KERNEL);
+	if (!slot->hotplug_slot->name) {
+		kfree(slot->hotplug_slot->info);
+		kfree(slot->hotplug_slot);
+		kfree(slot);
+		return (NULL);
+	}
+	return (slot);
+}
+
+static int setup_hotplug_slot_info(struct slot *slot)
+{
+	dbg("%s Initilize the slot info structure ...\n",
+		__FUNCTION__);
+
+	rpaphp_get_power_status(slot, 
+		&slot->hotplug_slot->info->power_status);  
+
+	rpaphp_get_adapter_status(slot, 1,
+		&slot->hotplug_slot->info->adapter_status); 
+
+	if (slot->hotplug_slot->info->adapter_status == NOT_VALID) {
+		dbg("%s: NOT_VALID: skip dn->full_name=%s\n", 
+			__FUNCTION__, slot->dn->full_name);
+		    kfree(slot->hotplug_slot->info);
+		    kfree(slot->hotplug_slot->name);
+		    kfree(slot->hotplug_slot);
+		    kfree(slot);
+		return (-1);
+	}
+	return (0);
+}
+
+static int register_slot(struct slot *slot)
+{
+	int retval; 
+
+	retval = pci_hp_register(slot->hotplug_slot);
+	if (retval) {
+		err("pci_hp_register failed with error %d\n", retval);
+		rpaphp_release_slot(slot->hotplug_slot);
+		return (retval);
+	}
+	/* create symlink between slot->name and it's bus_id */
+	dbg("%s: sysfs_create_link: %s --> %s\n", __FUNCTION__,
+		slot->bridge->slot_name, slot->name);					
+	retval = sysfs_create_link(slot->hotplug_slot->kobj.parent,
+			&slot->hotplug_slot->kobj,
+			slot->bridge->slot_name);
+	if (retval) {
+		err("sysfs_create_link failed with error %d\n", retval);
+		rpaphp_release_slot(slot->hotplug_slot);
+		return (retval);
+	}
+	/* add slot to our internal list */
+	dbg("%s adding slot[%s] to rpaphp_slot_list\n", 
+		__FUNCTION__, slot->name);
+
+	list_add(&slot->rpaphp_slot_list, &rpaphp_slot_head);
+
+	info("Slot [%s] (bus_id=%s) registered\n", 
+		slot->name, slot->bridge->slot_name);
+	return (0);
+}
+
+/*************************************
+ * Add  Hot Plug slot(s) to sysfs
+ *
+ ************************************/
+int rpaphp_add_slot(char *slot_name)
+{
+	struct slot		*slot;
+	int 			retval = 0;
+	int 			i;
+        struct device_node 	*dn;
+        int 			*indexes, *names, *types, *power_domains;
+        char 			*name, *type;
+
+	dbg("Entry %s: %s\n", __FUNCTION__,
+			slot_name? slot_name: "init");
+
+	for (dn = find_all_nodes(); dn; dn = dn->next) {
+
+		if (dn->name != 0 && strcmp(dn->name, "pci") == 0)	{
+			if (!is_php_dn(dn, &indexes, &names, &types, &power_domains))
+				continue;
+			
+			dbg("%s : found device_node in OFDT full_name=%s, name=%s\n",
+				__FUNCTION__, dn->full_name, dn->name);
+
+			name = (char *)&names[1];
+			type = (char *)&types[1];
+			
+			dbg("%s: indexes=%d\n", __FUNCTION__, indexes[0]);
+
+			for (i = 0; i < indexes[0]; 
+				i++, 
+				name += (strlen(name) + 1),
+				type += (strlen(type) + 1)) {
+
+				dbg("%s: name[%s] index[%x]\n",
+					__FUNCTION__, name, indexes[i+1]);
+
+				if (slot_name && strcmp(slot_name, name)) 
+					continue;
+		
+				if (rpaphp_validate_slot(name, indexes[i + 1])) {
+					dbg("%s: slot(%s, 0x%x) is invalid.\n",
+						__FUNCTION__, name, indexes[i+ 1]);
+					continue;
+				}
+
+				if (!(slot = alloc_slot_struct())) {
+					retval = -ENOMEM;
+					goto exit;
+				}
+
+				slot->name = slot->hotplug_slot->name;
+				slot->index = indexes[i + 1];
+				strcpy(slot->name, name);
+				slot->type = simple_strtoul(type, NULL, 10);	
+				if (slot->type < 1  || slot->type > 16)
+					slot->type = 0;
+				slot->power_domain = power_domains[i + 1];
+				slot->magic = SLOT_MAGIC;
+				slot->hotplug_slot->private = slot;
+				slot->hotplug_slot->ops = &rpaphp_hotplug_slot_ops;
+				slot->hotplug_slot->release = &rpaphp_release_slot;
+				slot->dn = dn;
+
+				/*
+			 	* Initilize the slot info structure with some known 
+			 	* good values.
+			 	*/
+				if (setup_hotplug_slot_info(slot))
+					continue;
+
+				slot->bridge = rpaphp_find_bridge_pdev(slot);
+				if (!slot->bridge && slot_name) { /* slot being added doesn't have pci_dev yet*/
+					dbg("%s: no pci_dev for bridge dn %s\n", 
+							__FUNCTION__, slot_name);
+					    kfree(slot->hotplug_slot->info);
+					    kfree(slot->hotplug_slot->name);
+					    kfree(slot->hotplug_slot);
+					    kfree(slot);
+					continue;
+				}
+ 
+				/* find slot's pci_dev if it's not empty*/
+				if (slot->hotplug_slot->info->adapter_status == EMPTY) {
+					slot->state = EMPTY;  /* slot is empty */
+					slot->dev = NULL;
+				}
+				else {  /* slot is occupied */
+					if(!(slot->dn->child)) { /* non-empty slot has to have child */
+						err("%s: slot[%s]'s device_node doesn't have child for adapter\n",
+						__FUNCTION__, slot->name);
+						kfree(slot->hotplug_slot->info);
+						kfree(slot->hotplug_slot->name);
+						kfree(slot->hotplug_slot);
+						kfree(slot);
+						continue;
+
+					}
+					
+					slot->dev = rpaphp_find_adapter_pdev(slot);
+
+					if (!slot->dev && slot_name) { 
+						 /* adapter being added doesn't have pci_dev yet */
+						slot->dev = rpaphp_config_adapter(slot);
+						if (!slot->dev) {
+							err("%s: add new adapter device for slot[%s] failed\n",
+							__FUNCTION__, slot->name);
+							kfree(slot->hotplug_slot->info);
+							kfree(slot->hotplug_slot->name);
+							kfree(slot->hotplug_slot);
+							kfree(slot);
+							pci_dev_put(slot->bridge);
+							continue;
+
+						}
+					}
+
+					if(slot->dev) {
+						slot->state = CONFIGURED;
+						pci_dev_get(slot->dev);
+					}
+					else
+						slot->state = NOT_CONFIGURED;
+				}
+				dbg("%s registering slot:path[%s] index[%x], name[%s] pdomain[%x] type[%d]\n",
+					__FUNCTION__, dn->full_name, slot->index, slot->name, 
+					slot->power_domain, slot->type);	
+
+				if ((retval = register_slot(slot)))
+					goto exit;
+
+				num_slots++;
+			
+				if (slot_name)  
+					goto exit;
+
+			}/* for indexes */
+		}/* "pci" */
+	}/* find_all_nodes */
+exit:
+	dbg("%s - Exit: num_slots=%d rc[%d]\n", 
+		__FUNCTION__, num_slots, retval);
+	return retval;
+}
+
+/*
+ * init_slots - initialize 'struct slot' structures for each slot
+ *
+ */
+static int init_slots (void)
+{
+	int 			retval = 0;
+
+	dbg("Entry %s\n", __FUNCTION__);
+
+	retval = rpaphp_add_slot(NULL);
+
+	dbg("Exit %s with retval=%d\n", __FUNCTION__, retval);
+
+	return retval;
+}
+
+
+static int init_rpa (void)
+{
+	int 			retval = 0;
+
+	dbg("Entry %s\n", __FUNCTION__);
+
+	init_MUTEX(&rpaphp_sem);
+	
+	/* initialize internal data structure etc. */
+	retval = init_slots();
+	if (!num_slots)
+		retval = -ENODEV;
+	
+	dbg("Exit %s with retval=%d, num_slots=%d\n", 
+		__FUNCTION__, retval, num_slots);
+
+	return retval;
+}
+
+static void cleanup_slots (void)
+{
+	struct list_head *tmp, *n;
+	struct slot *slot;
+
+	/*
+	 * Unregister all of our slots with the pci_hotplug subsystem,
+	 * and free up all memory that we had allocated.
+	 * memory will be freed in release_slot callback. 
+	 */
+
+	list_for_each_safe (tmp, n, &rpaphp_slot_head) {
+		slot = list_entry(tmp, struct slot, rpaphp_slot_list);
+		sysfs_remove_link(slot->hotplug_slot->kobj.parent, 
+			slot->bridge->slot_name);
+		list_del(&slot->rpaphp_slot_list);
+		pci_hp_deregister(slot->hotplug_slot);
+	}
+
+	return;
+}
+
+
+static int __init rpaphp_init(void)
+{
+	int retval = 0;
+
+	dbg("Entry %s\n", __FUNCTION__);
+	info(DRIVER_DESC " version: " DRIVER_VERSION "\n");
+
+	rpaphp_debug = debug;
+
+	/* read all the PRA info from the system */
+	retval = init_rpa();
+
+	dbg("Exit %s with retval=%d\n", __FUNCTION__, retval);
+	return retval;
+}
+
+
+static void __exit rpaphp_exit(void)
+{
+	cleanup_slots();
+}
+
+
+static int enable_slot(struct hotplug_slot *hotplug_slot)
+{
+	int retval = 0, state;
+
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+
+	if (slot == NULL)
+		return -ENODEV;
+
+	dbg("%s - Entry: slot[%s]\n",
+		__FUNCTION__, slot->name);
+	
+	dbg("ENABLING SLOT %s\n", slot->name);
+
+	down(&rpaphp_sem);
+
+	retval = rpaphp_get_sensor_state(slot->index, &state);	
+		
+	if (retval) 
+		goto exit;		
+
+	dbg("%s: sensor state[%d]\n", __FUNCTION__, state);
+
+	/* if slot is not empty, enable the adapter */	
+	if (state == PRESENT) {
+		dbg("%s : slot[%s] is occupid.\n", __FUNCTION__, slot->name);
+
+		if ((slot->dev = rpaphp_config_adapter(slot)) != NULL) {
+			slot->state = CONFIGURED;
+
+			dbg("%s: adapter %s in slot[%s] has been configured\n",
+				__FUNCTION__, slot->dev->slot_name,
+				slot->name);
+		}
+		else {
+			slot->state = NOT_CONFIGURED;
+
+			dbg("%s: no pci_dev struct for adapter in slot[%s]\n",
+				__FUNCTION__, slot->name);
+		}
+
+	}
+	else if (state == EMPTY) { 
+		dbg("%s : slot[%s] is empty\n", __FUNCTION__, slot->name);
+		slot->state = EMPTY;
+	}
+	else {
+		err("%s: slot[%s] is in invalid state\n", __FUNCTION__, slot->name);
+		slot->state = NOT_VALID;
+		retval = -EINVAL;
+	}
+	
+exit:	
+	if (slot->state != NOT_VALID)
+		rpaphp_set_attention_status(slot, LED_ON);
+	else
+		rpaphp_set_attention_status(slot, LED_ID);
+
+	up(&rpaphp_sem);
+	dbg("%s - Exit: rc[%d]\n",  __FUNCTION__, retval);
+	
+        return retval;
+}
+
+static int disable_slot(struct hotplug_slot *hotplug_slot)
+{
+	int	retval;
+	struct slot *slot = get_slot(hotplug_slot, __FUNCTION__);
+	
+
+	if (slot == NULL)
+		return -ENODEV;
+	
+	dbg("%s - Entry: slot[%s]\n",
+		__FUNCTION__, slot->name);
+	dbg("DISABLING SLOT %s\n", slot->name);
+
+	down(&rpaphp_sem);
+
+	rpaphp_set_attention_status(slot, LED_ID);
+
+	retval = rpaphp_unconfig_adapter(slot);
+			
+	rpaphp_set_attention_status(slot, LED_OFF);
+
+	up(&rpaphp_sem);
+
+	dbg("%s - Exit: rc[%d]\n",  __FUNCTION__, retval);
+        return retval;
+}
+
+module_init(rpaphp_init);
+module_exit(rpaphp_exit);
+
+EXPORT_SYMBOL_GPL(rpaphp_add_slot);
+EXPORT_SYMBOL_GPL(rpaphp_remove_slot);
diff -purN linux-2.5/drivers/pci/hotplug/rpaphp_pci.c linuxppc64-2.5/drivers/pci/hotplug/rpaphp_pci.c
--- linux-2.5/drivers/pci/hotplug/rpaphp_pci.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/hotplug/rpaphp_pci.c	2003-11-17 23:08:21.000000000 +0000
@@ -0,0 +1,75 @@
+/*
+ * PRA PCI Hot Plug Controller Driver
+ * Copyright (c) 2003 Linda Xie <lxie@us.ibm.com>
+ *
+ * All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation; either version 2 of the License, or (at
+ * your option) any later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY OR FITNESS FOR A PARTICULAR PURPOSE, GOOD TITLE or
+ * NON INFRINGEMENT.  See the GNU General Public License for more
+ * details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.
+ *
+ * Send feedback to <lxie@us.ibm.com>
+ *
+ */
+#include <linux/pci.h>
+#include <asm/pci-bridge.h>	/* for pci_controller */
+#include "rpaphp.h"
+
+
+struct pci_dev *rpaphp_find_pci_dev(struct device_node *dn)
+{
+	struct pci_dev		*retval_dev = NULL, *dev = NULL;
+
+	while ((dev = pci_get_device(PCI_ANY_ID, PCI_ANY_ID, dev)) != NULL) {
+		if(!dev->bus) 
+			continue;
+	
+		if (dev->devfn != dn->devfn) 
+			continue;
+		
+		if (dn->phb->global_number == pci_domain_nr(dev->bus) &&
+		    dn->busno == dev->bus->number) {
+			retval_dev = dev;
+			break;
+		}
+	}
+
+	return retval_dev;
+	
+}
+ 
+int rpaphp_claim_resource(struct pci_dev *dev, int resource)
+{
+	struct resource *res = &dev->resource[resource];
+	struct resource *root = pci_find_parent_resource(dev, res);
+	char *dtype = resource < PCI_BRIDGE_RESOURCES ? "device" : "bridge";
+	int err;
+
+	err = -EINVAL;
+	if (root != NULL) {
+		err = request_resource(root, res);
+	}
+
+	if (err) {
+		err("PCI: %s region %d of %s %s [%lx:%lx]\n",
+		       root ? "Address space collision on" :
+			      "No parent found for",
+		       resource, dtype, pci_name(dev), res->start, res->end);
+	}
+
+	return err;
+}
+
+EXPORT_SYMBOL_GPL(rpaphp_find_pci_dev);
+EXPORT_SYMBOL_GPL(rpaphp_claim_resource);
diff -purN linux-2.5/drivers/pci/pci-sysfs.c linuxppc64-2.5/drivers/pci/pci-sysfs.c
--- linux-2.5/drivers/pci/pci-sysfs.c	2003-08-15 01:17:20.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/pci-sysfs.c	2003-09-12 11:04:02.000000000 +0000
@@ -15,6 +15,7 @@
 
 #include <linux/config.h>
 #include <linux/kernel.h>
+#include <linux/stat.h>
 #include <linux/pci.h>
 #include <linux/stat.h>
 
diff -purN linux-2.5/drivers/pci/probe.c linuxppc64-2.5/drivers/pci/probe.c
--- linux-2.5/drivers/pci/probe.c	2003-08-06 15:34:30.000000000 +0000
+++ linuxppc64-2.5/drivers/pci/probe.c	2003-11-05 22:12:33.000000000 +0000
@@ -176,7 +176,7 @@ void __devinit pci_read_bridge_bases(str
 		limit |= (io_limit_hi << 16);
 	}
 
-	if (base && base <= limit) {
+	if (base <= limit) {
 		res->flags = (io_base_lo & PCI_IO_RANGE_TYPE_MASK) | IORESOURCE_IO;
 		res->start = base;
 		res->end = limit + 0xfff;
@@ -552,6 +552,7 @@ int __devinit pci_scan_slot(struct pci_b
 		struct pci_dev *dev;
 
 		dev = pci_scan_device(bus, devfn);
+#if 0
 		if (func == 0) {
 			if (!dev)
 				break;
@@ -560,6 +561,10 @@ int __devinit pci_scan_slot(struct pci_b
 				continue;
 			dev->multifunction = 1;
 		}
+#else
+		if (!dev)
+			continue;
+#endif
 
 		/* Fix up broken headers */
 		pci_fixup_device(PCI_FIXUP_HEADER, dev);
diff -purN linux-2.5/drivers/scsi/sg.c linuxppc64-2.5/drivers/scsi/sg.c
--- linux-2.5/drivers/scsi/sg.c	2003-10-20 22:15:18.000000000 +0000
+++ linuxppc64-2.5/drivers/scsi/sg.c	2003-10-24 08:46:15.000000000 +0000
@@ -1332,6 +1332,9 @@ sg_add(struct class_device *cdev)
 	unsigned long iflags;
 	int k, error;
 
+	if (scsidp->type == 255)
+		return 0;
+
 	disk = alloc_disk(1);
 	if (!disk)
 		return -ENOMEM;
diff -purN linux-2.5/drivers/scsi/sym53c8xx_2/sym_glue.c linuxppc64-2.5/drivers/scsi/sym53c8xx_2/sym_glue.c
--- linux-2.5/drivers/scsi/sym53c8xx_2/sym_glue.c	2003-09-11 00:33:22.000000000 +0000
+++ linuxppc64-2.5/drivers/scsi/sym53c8xx_2/sym_glue.c	2003-09-29 12:39:33.000000000 +0000
@@ -2159,8 +2159,7 @@ sym53c8xx_pci_init(struct pci_dev *pdev,
 
 	/* If the chip can do Memory Write Invalidate, enable it */
 	if (chip->features & FE_WRIE) {
-		if (pci_set_mwi(pdev))
-			return -1;
+			pci_set_mwi(pdev);
 	}
 
 	/*
diff -purN linux-2.5/fs/proc/proc_devtree.c linuxppc64-2.5/fs/proc/proc_devtree.c
--- linux-2.5/fs/proc/proc_devtree.c	2003-10-08 21:27:19.000000000 +0000
+++ linuxppc64-2.5/fs/proc/proc_devtree.c	2003-10-15 20:59:40.000000000 +0000
@@ -11,6 +11,20 @@
 #include <asm/prom.h>
 #include <asm/uaccess.h>
 
+#ifndef HAVE_ARCH_DEVTREE_FIXUPS
+static inline void set_node_proc_entry(struct device_node *np, struct proc_dir_entry *de)
+{
+}
+
+static void inline set_node_name_link(struct device_node *np, struct proc_dir_entry *de)
+{
+}
+
+static void inline set_node_addr_link(struct device_node *np, struct proc_dir_entry *de)
+{
+}
+#endif
+
 static struct proc_dir_entry *proc_device_tree;
 
 /*
@@ -44,7 +58,7 @@ static int property_read_proc(char *page
 /*
  * Process a node, adding entries for its children and its properties.
  */
-static void add_node(struct device_node *np, struct proc_dir_entry *de)
+void proc_device_tree_add_node(struct device_node *np, struct proc_dir_entry *de)
 {
 	struct property *pp;
 	struct proc_dir_entry *ent;
@@ -53,6 +67,7 @@ static void add_node(struct device_node 
 	int l;
 	struct proc_dir_entry *list, **lastp, *al;
 
+	set_node_proc_entry(np, de);
 	lastp = &list;
 	for (pp = np->properties; pp != 0; pp = pp->next) {
 		/*
@@ -70,7 +85,8 @@ static void add_node(struct device_node 
 		*lastp = ent;
 		lastp = &ent->next;
 	}
-	for (child = np->child; child != 0; child = child->sibling) {
+	child = NULL;
+	while ((child = of_get_next_child(np, child))) {
 		p = strrchr(child->full_name, '/');
 		if (p == 0)
 			p = child->full_name;
@@ -85,7 +101,7 @@ static void add_node(struct device_node 
 			break;
 		*lastp = ent;
 		lastp = &ent->next;
-		add_node(child, ent);
+		proc_device_tree_add_node(child, ent);
 
 		/*
 		 * If we left the address part on the name, consider
@@ -98,26 +114,32 @@ static void add_node(struct device_node 
 		 * If this is the first node with a given name property,
 		 * add a symlink with the name property as its name.
 		 */
-		for (sib = np->child; sib != child; sib = sib->sibling)
+		sib = NULL;
+		while ((sib = of_get_next_child(np, sib)) && sib != child)
 			if (sib->name && strcmp(sib->name, child->name) == 0)
 				break;
 		if (sib == child && strncmp(p, child->name, l) != 0) {
 			al = proc_symlink(child->name, de, ent->name);
-			if (al == 0)
+			if (al == 0) {
+				of_node_put(sib);
 				break;
+			}
+			set_node_name_link(child, al);
 			*lastp = al;
 			lastp = &al->next;
 		}
-
+		of_node_put(sib);
 		/*
 		 * Add another directory with the @address part as its name.
 		 */
 		al = proc_symlink(at, de, ent->name);
 		if (al == 0)
 			break;
+		set_node_addr_link(child, al);
 		*lastp = al;
 		lastp = &al->next;
 	}
+	of_node_put(child);
 	*lastp = 0;
 	de->subdir = list;
 }
@@ -133,10 +155,11 @@ void proc_device_tree_init(void)
 	proc_device_tree = proc_mkdir("device-tree", 0);
 	if (proc_device_tree == 0)
 		return;
-	root = find_path_device("/");
+	root = of_find_node_by_path("/");
 	if (root == 0) {
 		printk(KERN_ERR "/proc/device-tree: can't find root\n");
 		return;
 	}
-	add_node(root, proc_device_tree);
+	proc_device_tree_add_node(root, proc_device_tree);
+	of_node_put(root);
 }
diff -purN linux-2.5/include/asm-ppc/unistd.h linuxppc64-2.5/include/asm-ppc/unistd.h
--- linux-2.5/include/asm-ppc/unistd.h	2003-08-23 02:15:18.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc/unistd.h	2003-11-19 22:02:56.000000000 +0000
@@ -259,8 +259,9 @@
 #define __NR_statfs64		252
 #define __NR_fstatfs64		253
 #define __NR_fadvise64_64	254
+#define __NR_rtas		255
 
-#define __NR_syscalls		255
+#define __NR_syscalls		256
 
 #define __NR(n)	#n
 
@@ -279,6 +280,7 @@
 		register unsigned long __sc_5  __asm__ ("r5");		\
 		register unsigned long __sc_6  __asm__ ("r6");		\
 		register unsigned long __sc_7  __asm__ ("r7");		\
+		register unsigned long __sc_8  __asm__ ("r8");		\
 									\
 		__sc_loadargs_##nr(name, args);				\
 		__asm__ __volatile__					\
@@ -287,10 +289,10 @@
 			: "=&r" (__sc_0),				\
 			  "=&r" (__sc_3),  "=&r" (__sc_4),		\
 			  "=&r" (__sc_5),  "=&r" (__sc_6),		\
-			  "=&r" (__sc_7)				\
+			  "=&r" (__sc_7),  "=&r" (__sc_8)		\
 			: __sc_asm_input_##nr				\
 			: "cr0", "ctr", "memory",			\
-			  "r8", "r9", "r10","r11", "r12");		\
+			  "r9", "r10","r11", "r12");			\
 		__sc_ret = __sc_3;					\
 		__sc_err = __sc_0;					\
 	}								\
@@ -318,6 +320,9 @@
 #define __sc_loadargs_5(name, arg1, arg2, arg3, arg4, arg5)		\
 	__sc_loadargs_4(name, arg1, arg2, arg3, arg4);			\
 	__sc_7 = (unsigned long) (arg5)
+#define __sc_loadargs_6(name, arg1, arg2, arg3, arg4, arg5, arg6)	\
+	__sc_loadargs_5(name, arg1, arg2, arg3, arg4, arg5);		\
+	__sc_8 = (unsigned long) (arg6)
 
 #define __sc_asm_input_0 "0" (__sc_0)
 #define __sc_asm_input_1 __sc_asm_input_0, "1" (__sc_3)
@@ -325,6 +330,7 @@
 #define __sc_asm_input_3 __sc_asm_input_2, "3" (__sc_5)
 #define __sc_asm_input_4 __sc_asm_input_3, "4" (__sc_6)
 #define __sc_asm_input_5 __sc_asm_input_4, "5" (__sc_7)
+#define __sc_asm_input_6 __sc_asm_input_5, "6" (__sc_8)
 
 #define _syscall0(type,name)						\
 type name(void)								\
@@ -362,6 +368,12 @@ type name(type1 arg1, type2 arg2, type3 
 	__syscall_nr(5, type, name, arg1, arg2, arg3, arg4, arg5);	\
 }
 
+#define _syscall6(type,name,type1,arg1,type2,arg2,type3,arg3,type4,arg4,type5,arg5,type6,arg6) \
+type name(type1 arg1, type2 arg2, type3 arg3, type4 arg4, type5 arg5, type6 arg6) \
+{									\
+	__syscall_nr(6, type, name, arg1, arg2, arg3, arg4, arg5, arg6); \
+}
+
 #ifdef __KERNEL__
 
 #define __NR__exit __NR_exit
diff -purN linux-2.5/include/asm-ppc64/cputable.h linuxppc64-2.5/include/asm-ppc64/cputable.h
--- linux-2.5/include/asm-ppc64/cputable.h	2003-10-01 22:32:13.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/cputable.h	2003-10-28 18:47:22.000000000 +0000
@@ -74,10 +74,20 @@ extern struct cpu_spec		*cur_cpu_spec;
 #define FW_FEATURE_COPY		(1UL<<4)	
 #define FW_FEATURE_ASR		(1UL<<5)	
 #define FW_FEATURE_DEBUG	(1UL<<6)	
-#define FW_FEATURE_PERF		(1UL<<7)	
-#define FW_FEATURE_DUMP		(1UL<<8)	
-#define FW_FEATURE_INTERRUPT	(1UL<<9)	
-#define FW_FEATURE_MIGRATE	(1UL<<10)	
+#define FW_FEATURE_TERM		(1UL<<7)	
+#define FW_FEATURE_PERF		(1UL<<8)	
+#define FW_FEATURE_DUMP		(1UL<<9)	
+#define FW_FEATURE_INTERRUPT	(1UL<<10)	
+#define FW_FEATURE_MIGRATE	(1UL<<11)	
+#define FW_FEATURE_PERFMON	(1UL<<12)	
+#define FW_FEATURE_CRQ   	(1UL<<13)	
+#define FW_FEATURE_VIO   	(1UL<<14)	
+#define FW_FEATURE_RDMA   	(1UL<<15)	
+#define FW_FEATURE_LLAN   	(1UL<<16)	
+#define FW_FEATURE_BULK   	(1UL<<17)	
+#define FW_FEATURE_XDABR   	(1UL<<18)	
+#define FW_FEATURE_MULTITCE   	(1UL<<19)	
+#define FW_FEATURE_SPLPAR   	(1UL<<20)	
 
 typedef struct {
     unsigned long val;
@@ -144,11 +154,24 @@ extern firmware_feature_t firmware_featu
 	.llong 99b;	 		        \
 	.previous
 
-#define END_FTR_SECTION_IFSET(msk)	END_FTR_SECTION((msk), (msk))
-#define END_FTR_SECTION_IFCLR(msk)	END_FTR_SECTION((msk), 0)
+#else
+
+#define BEGIN_FTR_SECTION		"98:\n"
+#define END_FTR_SECTION(msk, val)		\
+"99:\n"						\
+"	.section __ftr_fixup,\"a\";\n"		\
+"	.align 3;\n"				\
+"	.llong "#msk";\n"			\
+"	.llong "#val";\n"			\
+"	.llong 98b;\n"			        \
+"	.llong 99b;\n"	 		        \
+"	.previous\n"
 
 #endif /* __ASSEMBLY__ */
 
+#define END_FTR_SECTION_IFSET(msk)	END_FTR_SECTION((msk), (msk))
+#define END_FTR_SECTION_IFCLR(msk)	END_FTR_SECTION((msk), 0)
+
 #endif /* __ASM_PPC_CPUTABLE_H */
 #endif /* __KERNEL__ */
 
diff -purN linux-2.5/include/asm-ppc64/elf.h linuxppc64-2.5/include/asm-ppc64/elf.h
--- linux-2.5/include/asm-ppc64/elf.h	2003-09-30 21:11:46.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/elf.h	2003-11-19 21:34:28.000000000 +0000
@@ -54,7 +54,7 @@
 
 #define ELF_NGREG	48	/* includes nip, msr, lr, etc. */
 #define ELF_NFPREG	33	/* includes fpscr */
-#define ELF_NVRREG	33	/* includes vscr */
+#define ELF_NVRREG	34	/* includes vscr */
 
 typedef unsigned long elf_greg_t64;
 typedef elf_greg_t64 elf_gregset_t64[ELF_NGREG];
@@ -82,6 +82,23 @@ typedef elf_greg_t32 elf_gregset_t32[ELF
 typedef double elf_fpreg_t;
 typedef elf_fpreg_t elf_fpregset_t[ELF_NFPREG];
 
+/* Altivec registers */
+/*
+ * The entries with indexes 0-31 contain the corresponding vector registers. 
+ * The entry with index 32 contains the vscr as the last word (offset 12) 
+ * within the quadword.  This allows the vscr to be stored as either a 
+ * quadword (since it must be copied via a vector register to/from storage) 
+ * or as a word.  The entry with index 33 contains the vrsave as the first 
+ * word (offset 0) within the quadword.
+ *
+ * This definition of the VMX state is compatible with the current PPC32 
+ * ptrace interface.  This allows signal handling and ptrace to use the same 
+ * structures.  This also simplifies the implementation of a bi-arch 
+ * (combined (32- and 64-bit) gdb.
+ */
+typedef __vector128 elf_vrreg_t;
+typedef elf_vrreg_t elf_vrregset_t[ELF_NVRREG];
+
 /*
  * This is used to ensure we don't load something for the wrong architecture.
  */
diff -purN linux-2.5/include/asm-ppc64/hvcall.h linuxppc64-2.5/include/asm-ppc64/hvcall.h
--- linux-2.5/include/asm-ppc64/hvcall.h	2003-09-07 01:40:37.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/hvcall.h	2003-11-14 04:34:13.000000000 +0000
@@ -9,6 +9,14 @@
 #define H_PTEG_Full	-6	/* PTEG is full */
 #define H_Not_Found	-7	/* PTE was not found" */
 #define H_Reserved_DABR	-8	/* DABR address is reserved by the hypervisor on this processor" */
+#define H_NoMem                 -9
+#define H_Authority            -10
+#define H_Permission           -11
+#define H_Dropped              -12
+#define H_SourceParm           -13
+#define H_DestParm             -14
+#define H_RemoteParm           -15
+#define H_Resource             -16
 
 /* Flags */
 #define H_LARGE_PAGE		(1UL<<(63-16))
@@ -58,6 +66,16 @@
 #define H_IPOLL			0x70
 #define H_XIRR			0x74
 #define H_PERFMON		0x7c
+#define H_MIGRATE_DMA		0x78
+#define H_REGISTER_VPA		0xDC
+#define H_CEDE		        0xE0
+#define H_CONFER		0xE4
+#define H_PROD		        0xE8
+#define H_GET_PPP		0xEC
+#define H_SET_PPP		0xF0
+#define H_SET_PURR		0xF4
+#define H_PIC		        0xF8
+#define H_POLL_PENDING	        0x1D8
 
 /* plpar_hcall() -- Generic call interface using above opcodes
  *
@@ -76,6 +94,8 @@ long plpar_hcall(unsigned long opcode,
 		 unsigned long *out2,
 		 unsigned long *out3);
 
+#define HVSC			".long 0x44000022\n"
+
 /* Same as plpar_hcall but for those opcodes that return no values
  * other than status.  Slightly more efficient.
  */
diff -purN linux-2.5/include/asm-ppc64/hw_irq.h linuxppc64-2.5/include/asm-ppc64/hw_irq.h
--- linux-2.5/include/asm-ppc64/hw_irq.h	2003-02-19 02:59:01.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/hw_irq.h	2003-10-22 13:10:35.000000000 +0000
@@ -21,18 +21,15 @@ extern void ppc_irq_dispatch_handler(str
 
 #ifdef CONFIG_PPC_ISERIES
 
-extern void __no_use_sti(void);
-extern void __no_use_cli(void);
-extern void __no_use_restore_flags(unsigned long);
-extern unsigned long __no_use_save_flags(void);
-extern void __no_use_set_lost(unsigned long);
-extern void __no_lpq_restore_flags(unsigned long);
-
-#define local_irq_disable()			__no_use_cli()
-#define local_irq_enable()			__no_use_sti()
-#define local_save_flags(flags)	((flags) = __no_use_save_flags())
-#define local_irq_restore(flags)	__no_use_restore_flags((unsigned long)flags)
-#define local_irq_save(flags)	({local_save_flags(flags);local_irq_disable();})
+extern unsigned long local_get_flags(void);
+extern unsigned long local_irq_disable(void);
+extern void local_irq_restore(unsigned long);
+
+#define local_irq_enable()	local_irq_restore(1)
+#define local_save_flags(flags)	((flags) = local_get_flags())
+#define local_irq_save(flags)	((flags) = local_irq_disable())
+
+#define irqs_disabled()		(local_get_flags() == 0)
 
 #else
 
@@ -69,11 +66,33 @@ static inline void __do_save_and_cli(uns
 
 #define local_irq_save(flags)          __do_save_and_cli(&flags)
 
+#define irqs_disabled()				\
+({						\
+	unsigned long flags;			\
+	local_save_flags(flags);		\
+	!(flags & MSR_EE);			\
+})
+
 #endif /* CONFIG_PPC_ISERIES */
 
-#define mask_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->disable) irq_desc[irq].handler->disable(irq);})
-#define unmask_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->enable) irq_desc[irq].handler->enable(irq);})
-#define ack_irq(irq) ({if (irq_desc[irq].handler && irq_desc[irq].handler->ack) irq_desc[irq].handler->ack(irq);})
+#define mask_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->disable)	\
+			desc->handler->disable(irq);		\
+	})
+#define unmask_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->enable)	\
+			desc->handler->enable(irq);		\
+	})
+#define ack_irq(irq)						\
+	({							\
+	 	irq_desc_t *desc = get_irq_desc(irq);		\
+		if (desc->handler && desc->handler->ack)	\
+			desc->handler->ack(irq);		\
+	})
 
 /* Should we handle this via lost interrupts and IPIs or should we don't care like
  * we do now ? --BenH.
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvCall.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvCall.h
--- linux-2.5/include/asm-ppc64/iSeries/HvCall.h	2002-12-08 05:08:27.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvCall.h	2003-11-21 06:45:03.000000000 +0000
@@ -23,25 +23,16 @@
 //	drive the hypervisor from the OS.
 //
 //===========================================================================
+#ifndef _HVCALL_H
+#define _HVCALL_H
 
 //-------------------------------------------------------------------
 // Standard Includes
 //-------------------------------------------------------------------
-#ifndef  _HVCALLSC_H
-#include "HvCallSc.h"
-#endif
-
-#ifndef  _HVTYPES_H
+#include <asm/iSeries/HvCallSc.h>
 #include <asm/iSeries/HvTypes.h>
-#endif
-
 #include <asm/paca.h>
 
-//-------------------------------------------------------------------
-// Constants
-//-------------------------------------------------------------------
-#ifndef _HVCALL_H
-#define _HVCALL_H
 /*
 enum HvCall_ReturnCode
 {
@@ -211,5 +202,4 @@ static inline void HvCall_setDebugBus(un
 	HvCall1(HvCallBaseSetDebugBus, val);
 }
 
-#endif // _HVCALL_H
-
+#endif /* _HVCALL_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvCallCfg.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallCfg.h
--- linux-2.5/include/asm-ppc64/iSeries/HvCallCfg.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallCfg.h	2003-11-21 06:45:03.000000000 +0000
@@ -23,23 +23,18 @@
 //	drive the hypervisor from the OS.
 //
 //=====================================================================================
+#ifndef _HVCALLCFG_H
+#define _HVCALLCFG_H
 
 //-------------------------------------------------------------------
 // Standard Includes
 //-------------------------------------------------------------------
-#ifndef  _HVCALLSC_H
-#include "HvCallSc.h"
-#endif
-
-#ifndef  _HVTYPES_H
+#include <asm/iSeries/HvCallSc.h>
 #include <asm/iSeries/HvTypes.h>
-#endif
 
 //-------------------------------------------------------------------------------------
 // Constants
 //-------------------------------------------------------------------------------------
-#ifndef _HVCALLCFG_H
-#define _HVCALLCFG_H
 
 enum HvCallCfg_ReqQual
 {
@@ -215,5 +210,4 @@ static inline HvLpIndex	HvCallCfg_getHos
 
 }
 
-#endif // _HVCALLCFG_H
-
+#endif /* _HVCALLCFG_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvCallEvent.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallEvent.h
--- linux-2.5/include/asm-ppc64/iSeries/HvCallEvent.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallEvent.h	2003-11-21 06:45:03.000000000 +0000
@@ -17,44 +17,27 @@
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
 
-//==================================================================
-//
-//	This file contains the "hypervisor call" interface which is used to
-//	drive the hypervisor from the OS.
-//
-//==================================================================
-
-//-------------------------------------------------------------------
-// Standard Includes
-//-------------------------------------------------------------------
-#ifndef  _HVCALLSC_H
-#include <asm/iSeries/HvCallSc.h>
-#endif
+/*
+ *	This file contains the "hypervisor call" interface which is used to
+ *	drive the hypervisor from the OS.
+ */
+#ifndef _HVCALLEVENT_H
+#define _HVCALLEVENT_H
 
-#ifndef  _HVTYPES_H
+/*
+ * Standard Includes
+ */
+#include <asm/iSeries/HvCallSc.h>
 #include <asm/iSeries/HvTypes.h>
-#endif
-
 #include <asm/abs_addr.h>
 
-//-------------------------------------------------------------------
-// Other Includes
-//-------------------------------------------------------------------
-
-//-------------------------------------------------------------------
-// Constants
-//-------------------------------------------------------------------
-#ifndef _HVCALLEVENT_H
-#define _HVCALLEVENT_H
-
 struct HvLpEvent;
 
 typedef u8 HvLpEvent_Type;
 typedef u8 HvLpEvent_AckInd;
 typedef u8 HvLpEvent_AckType;
 
-struct	HvCallEvent_PackedParms
-{
+struct	HvCallEvent_PackedParms {
 	u8		xAckType:1;
 	u8		xAckInd:1;
 	u8		xRsvd:1;
@@ -68,8 +51,7 @@ struct	HvCallEvent_PackedParms
 typedef u8 HvLpDma_Direction;
 typedef u8 HvLpDma_AddressType;
 
-struct	HvCallEvent_PackedDmaParms
-{
+struct	HvCallEvent_PackedDmaParms {
 	u8		xDirection:1;
 	u8		xLocalAddrType:1;
 	u8		xRemoteAddrType:1;
@@ -101,69 +83,63 @@ typedef u64 HvLpDma_Rc;
 #define HvCallEventSetLpEventQueueInterruptProc		HvCallEvent + 14
 #define HvCallEventRouter15				HvCallEvent + 15
 
-//======================================================================
-static inline void		HvCallEvent_getOverflowLpEvents(u8 queueIndex)
+static inline void HvCallEvent_getOverflowLpEvents(u8 queueIndex)
 {
 	HvCall1(HvCallEventGetOverflowLpEvents,queueIndex);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 }
-//======================================================================
-static inline void		HvCallEvent_setInterLpQueueIndex(u8 queueIndex)
+
+static inline void HvCallEvent_setInterLpQueueIndex(u8 queueIndex)
 {
 	HvCall1(HvCallEventSetInterLpQueueIndex,queueIndex);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 }
-//======================================================================
-static inline void		HvCallEvent_setLpEventStack(u8 queueIndex,
-					     char * eventStackAddr,
-					     u32 eventStackSize)
+
+static inline void HvCallEvent_setLpEventStack(u8 queueIndex,
+		char *eventStackAddr, u32 eventStackSize)
 {
 	u64 abs_addr;
-	abs_addr = virt_to_absolute( (unsigned long) eventStackAddr );
 
-	HvCall3(HvCallEventSetLpEventStack, queueIndex, abs_addr, eventStackSize);
+	abs_addr = virt_to_absolute((unsigned long)eventStackAddr);
+	HvCall3(HvCallEventSetLpEventStack, queueIndex, abs_addr,
+			eventStackSize);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 }
-//======================================================================
-static inline void		HvCallEvent_setLpEventQueueInterruptProc(u8 queueIndex,
-							  u16 lpLogicalProcIndex)
+
+static inline void HvCallEvent_setLpEventQueueInterruptProc(u8 queueIndex,
+		u16 lpLogicalProcIndex)
 {
-	HvCall2(HvCallEventSetLpEventQueueInterruptProc,queueIndex,lpLogicalProcIndex);
+	HvCall2(HvCallEventSetLpEventQueueInterruptProc, queueIndex,
+			lpLogicalProcIndex);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 }
-//=====================================================================
-static inline HvLpEvent_Rc HvCallEvent_signalLpEvent(struct HvLpEvent* event)
+
+static inline HvLpEvent_Rc HvCallEvent_signalLpEvent(struct HvLpEvent *event)
 {
 	u64 abs_addr;
 	HvLpEvent_Rc retVal;
+
 #ifdef DEBUG_SENDEVENT
-	printk("HvCallEvent_signalLpEvent: *event = %016lx\n ", (unsigned long)event);
+	printk("HvCallEvent_signalLpEvent: *event = %016lx\n ",
+			(unsigned long)event);
 #endif
-	abs_addr = virt_to_absolute( (unsigned long) event );
+	abs_addr = virt_to_absolute((unsigned long)event);
 	retVal = (HvLpEvent_Rc)HvCall1(HvCallEventSignalLpEvent, abs_addr);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//=====================================================================
-static inline HvLpEvent_Rc  HvCallEvent_signalLpEventFast(HvLpIndex targetLp,
-					   HvLpEvent_Type type,
-					   u16 subtype,
-					   HvLpEvent_AckInd ackInd,
-					   HvLpEvent_AckType ackType,
-					   HvLpInstanceId sourceInstanceId,
-					   HvLpInstanceId targetInstanceId,
-					   u64 correlationToken,
-					   u64 eventData1,
-					   u64 eventData2,
-					   u64 eventData3,
-					   u64 eventData4,
-					   u64 eventData5)
+
+static inline HvLpEvent_Rc HvCallEvent_signalLpEventFast(HvLpIndex targetLp,
+		HvLpEvent_Type type, u16 subtype, HvLpEvent_AckInd ackInd,
+		HvLpEvent_AckType ackType, HvLpInstanceId sourceInstanceId,
+		HvLpInstanceId targetInstanceId, u64 correlationToken,
+		u64 eventData1, u64 eventData2, u64 eventData3,
+		u64 eventData4, u64 eventData5)
 {
 	HvLpEvent_Rc retVal;
 
 	// Pack the misc bits into a single Dword to pass to PLIC
-	union
-	{
+	union {
 		struct HvCallEvent_PackedParms	parms;
 		u64		dword;
 	} packed;
@@ -177,88 +153,84 @@ static inline HvLpEvent_Rc  HvCallEvent_
 	packed.parms.xTargetInstId	= targetInstanceId;
 
 	retVal = (HvLpEvent_Rc)HvCall7(HvCallEventSignalLpEventParms,
-				       packed.dword,
-				       correlationToken,
-				       eventData1,eventData2,
-				       eventData3,eventData4,
-				       eventData5);
+			packed.dword, correlationToken, eventData1,eventData2,
+			eventData3,eventData4, eventData5);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//====================================================================
-static inline HvLpEvent_Rc	HvCallEvent_ackLpEvent(struct HvLpEvent* event)
+
+static inline HvLpEvent_Rc HvCallEvent_ackLpEvent(struct HvLpEvent *event)
 {
 	u64 abs_addr;
 	HvLpEvent_Rc retVal;
-	abs_addr = virt_to_absolute( (unsigned long) event );
 
+	abs_addr = virt_to_absolute((unsigned long)event);
 	retVal = (HvLpEvent_Rc)HvCall1(HvCallEventAckLpEvent, abs_addr);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//====================================================================
-static inline HvLpEvent_Rc   HvCallEvent_cancelLpEvent(struct HvLpEvent* event)
+
+static inline HvLpEvent_Rc HvCallEvent_cancelLpEvent(struct HvLpEvent *event)
 {
 	u64 abs_addr;
 	HvLpEvent_Rc retVal;
-	abs_addr = virt_to_absolute( (unsigned long) event );
 
+	abs_addr = virt_to_absolute((unsigned long)event);
 	retVal = (HvLpEvent_Rc)HvCall1(HvCallEventCancelLpEvent, abs_addr);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//===================================================================
-static inline HvLpInstanceId	HvCallEvent_getSourceLpInstanceId(HvLpIndex targetLp, HvLpEvent_Type type)
+
+static inline HvLpInstanceId HvCallEvent_getSourceLpInstanceId(
+		HvLpIndex targetLp, HvLpEvent_Type type)
 {
 	HvLpInstanceId retVal;	
-	retVal = HvCall2(HvCallEventGetSourceLpInstanceId,targetLp,type);
+
+	retVal = HvCall2(HvCallEventGetSourceLpInstanceId, targetLp, type);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//===================================================================
-static inline HvLpInstanceId	HvCallEvent_getTargetLpInstanceId(HvLpIndex targetLp, HvLpEvent_Type type)
+
+static inline HvLpInstanceId HvCallEvent_getTargetLpInstanceId(
+		HvLpIndex targetLp, HvLpEvent_Type type)
 {
 	HvLpInstanceId retVal;	
-	retVal = HvCall2(HvCallEventGetTargetLpInstanceId,targetLp,type);
+
+	retVal = HvCall2(HvCallEventGetTargetLpInstanceId, targetLp, type);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//===================================================================
-static inline void		HvCallEvent_openLpEventPath(HvLpIndex targetLp,
-					     HvLpEvent_Type type)
+
+static inline void HvCallEvent_openLpEventPath(HvLpIndex targetLp,
+		HvLpEvent_Type type)
 {
-	HvCall2(HvCallEventOpenLpEventPath,targetLp,type);
+	HvCall2(HvCallEventOpenLpEventPath, targetLp, type);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 }
-//===================================================================
-static inline void		HvCallEvent_closeLpEventPath(HvLpIndex targetLp,
-					      HvLpEvent_Type type)
+
+static inline void HvCallEvent_closeLpEventPath(HvLpIndex targetLp,
+		HvLpEvent_Type type)
 {
-	HvCall2(HvCallEventCloseLpEventPath,targetLp,type);
+	HvCall2(HvCallEventCloseLpEventPath, targetLp, type);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 }
-//===================================================================
-static inline HvLpDma_Rc	HvCallEvent_dmaBufList(HvLpEvent_Type type,
-					HvLpIndex remoteLp,
-					HvLpDma_Direction direction,
-					HvLpInstanceId localInstanceId,
-					HvLpInstanceId remoteInstanceId,
-					HvLpDma_AddressType localAddressType,
-					HvLpDma_AddressType remoteAddressType,
-					// Do these need to be converted to
-					// absolute addresses?
-					u64 localBufList,
-					u64 remoteBufList,
 
-					u32 transferLength)
+static inline HvLpDma_Rc HvCallEvent_dmaBufList(HvLpEvent_Type type,
+		HvLpIndex remoteLp, HvLpDma_Direction direction,
+		HvLpInstanceId localInstanceId,
+		HvLpInstanceId remoteInstanceId,
+		HvLpDma_AddressType localAddressType,
+		HvLpDma_AddressType remoteAddressType,
+		/* Do these need to be converted to absolute addresses? */
+		u64 localBufList, u64 remoteBufList, u32 transferLength)
 {
-	HvLpDma_Rc retVal;	
+	HvLpDma_Rc retVal;
 	// Pack the misc bits into a single Dword to pass to PLIC
-	union
-	{
+	union {
 		struct HvCallEvent_PackedDmaParms	parms;
 		u64		dword;
 	} packed;
+
 	packed.parms.xDirection		= direction;
 	packed.parms.xLocalAddrType	= localAddressType;
 	packed.parms.xRemoteAddrType	= remoteAddressType;
@@ -270,32 +242,27 @@ static inline HvLpDma_Rc	HvCallEvent_dma
 	packed.parms.xRemoteInstId	= remoteInstanceId;
 
 	retVal = (HvLpDma_Rc)HvCall4(HvCallEventDmaBufList,
-				     packed.dword,
-				     localBufList,
-				     remoteBufList,
-				     transferLength);
+			packed.dword, localBufList, remoteBufList,
+			transferLength);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//=================================================================
-static inline HvLpDma_Rc	HvCallEvent_dmaSingle(HvLpEvent_Type type,
-				       HvLpIndex remoteLp,
-				       HvLpDma_Direction direction,
-				       HvLpInstanceId localInstanceId,
-				       HvLpInstanceId remoteInstanceId,
-				       HvLpDma_AddressType localAddressType,
-				       HvLpDma_AddressType remoteAddressType,
-				       u64 localAddrOrTce,
-				       u64 remoteAddrOrTce,
-				       u32 transferLength)
+
+static inline HvLpDma_Rc HvCallEvent_dmaSingle(HvLpEvent_Type type,
+		HvLpIndex remoteLp, HvLpDma_Direction direction,
+		HvLpInstanceId localInstanceId,
+		HvLpInstanceId remoteInstanceId,
+		HvLpDma_AddressType localAddressType,
+		HvLpDma_AddressType remoteAddressType,
+		u64 localAddrOrTce, u64 remoteAddrOrTce, u32 transferLength)
 {
-	HvLpDma_Rc retVal;	
+	HvLpDma_Rc retVal;
 	// Pack the misc bits into a single Dword to pass to PLIC
-	union
-	{
+	union {
 		struct HvCallEvent_PackedDmaParms	parms;
 		u64		dword;
 	} packed;
+
 	packed.parms.xDirection		= direction;
 	packed.parms.xLocalAddrType	= localAddressType;
 	packed.parms.xRemoteAddrType	= remoteAddressType;
@@ -307,29 +274,24 @@ static inline HvLpDma_Rc	HvCallEvent_dma
 	packed.parms.xRemoteInstId	= remoteInstanceId;
 
 	retVal = (HvLpDma_Rc)HvCall4(HvCallEventDmaSingle,
-				     packed.dword,
-				     localAddrOrTce,
-				     remoteAddrOrTce,
-				     transferLength);
+			packed.dword, localAddrOrTce, remoteAddrOrTce,
+			transferLength);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//=================================================================
-static inline HvLpDma_Rc	HvCallEvent_dmaToSp(void* local, u32 remote, u32 length, HvLpDma_Direction dir)
+
+static inline HvLpDma_Rc HvCallEvent_dmaToSp(void* local, u32 remote,
+		u32 length, HvLpDma_Direction dir)
 {
 	u64 abs_addr;
 	HvLpDma_Rc retVal;
-	abs_addr = virt_to_absolute( (unsigned long) local );
-    
-	retVal = (HvLpDma_Rc)HvCall4(HvCallEventDmaToSp, 
-				     abs_addr,
-				     remote,
-				     length,
-				     dir);
+
+	abs_addr = virt_to_absolute((unsigned long)local);
+	retVal = (HvLpDma_Rc)HvCall4(HvCallEventDmaToSp, abs_addr, remote,
+			length, dir);
 	// getPaca()->adjustHmtForNoOfSpinLocksHeld();
 	return retVal;
 }
-//================================================================
 
-#endif // _HVCALLEVENT_H
 
+#endif /* _HVCALLEVENT_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvCallHpt.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallHpt.h
--- linux-2.5/include/asm-ppc64/iSeries/HvCallHpt.h	2002-06-09 09:59:38.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallHpt.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _HVCALLHPT_H
+#define _HVCALLHPT_H
 
 //============================================================================
 //
@@ -24,30 +26,13 @@
 //
 //============================================================================
 
-//-------------------------------------------------------------------
-// Standard Includes
-//-------------------------------------------------------------------
-#ifndef  _HVCALLSC_H
-#include "HvCallSc.h"
-#endif
-
-#ifndef  _HVTYPES_H
+#include <asm/iSeries/HvCallSc.h>
 #include <asm/iSeries/HvTypes.h>
-#endif
-
-//-------------------------------------------------------------------
-// Other Includes
-//-------------------------------------------------------------------
-
-#ifndef _PPC_MMU_H
 #include <asm/mmu.h>
-#endif
 
 //-----------------------------------------------------------------------------
 // Constants
 //-----------------------------------------------------------------------------
-#ifndef _HVCALLHPT_H
-#define _HVCALLHPT_H
 
 #define HvCallHptGetHptAddress		HvCallHpt +  0
 #define HvCallHptGetHptPages		HvCallHpt +  1
@@ -139,5 +124,4 @@ static inline void		HvCallHpt_addValidat
 
 //=============================================================================
 
-#endif // _HVCALLHPT_H
-
+#endif /* _HVCALLHPT_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvCallPci.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallPci.h
--- linux-2.5/include/asm-ppc64/iSeries/HvCallPci.h	2002-03-26 07:32:21.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallPci.h	2003-11-21 06:45:03.000000000 +0000
@@ -31,6 +31,8 @@
 //	drive the hypervisor from SLIC.
 //
 //============================================================================
+#ifndef _HVCALLPCI_H
+#define _HVCALLPCI_H
 
 //-------------------------------------------------------------------
 // Forward declarations 
@@ -39,24 +41,12 @@
 //-------------------------------------------------------------------
 // Standard Includes
 //-------------------------------------------------------------------
-#ifndef  _HVCALLSC_H
-#include "HvCallSc.h"
-#endif
-
-#ifndef  _HVTYPES_H
+#include <asm/iSeries/HvCallSc.h>
 #include <asm/iSeries/HvTypes.h>
-#endif
-
-//-------------------------------------------------------------------
-// Other Includes
-//-------------------------------------------------------------------
-
 
 //-----------------------------------------------------------------------------
 // Constants
 //-----------------------------------------------------------------------------
-#ifndef _HVCALLPCI_H
-#define _HVCALLPCI_H
 
 struct HvCallPci_DsaAddr { // make sure this struct size is 64-bits total
 	u16		busNumber;
@@ -694,4 +684,4 @@ static inline int HvCallPci_getBusAdapte
 	return xRetSize;
 }
 //============================================================================
-#endif // _HVCALLPCI_H
+#endif /* _HVCALLPCI_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvCallSc.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallSc.h
--- linux-2.5/include/asm-ppc64/iSeries/HvCallSc.h	2002-06-09 09:59:38.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallSc.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,14 +16,11 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
-
-#ifndef  _HVTYPES_H
-#include <asm/iSeries/HvTypes.h>
-#endif
-
 #ifndef _HVCALLSC_H
 #define _HVCALLSC_H
 
+#include <asm/iSeries/HvTypes.h>
+
 #define HvCallBase		0x8000000000000000
 #define HvCallCc		0x8001000000000000
 #define HvCallCfg		0x8002000000000000
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvCallSm.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallSm.h
--- linux-2.5/include/asm-ppc64/iSeries/HvCallSm.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallSm.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _HVCALLSM_H
+#define _HVCALLSM_H
 
 //============================================================================
 //
@@ -27,19 +29,12 @@
 //-------------------------------------------------------------------
 // Standard Includes
 //-------------------------------------------------------------------
-#ifndef  _HVCALLSC_H
-#include "HvCallSc.h"
-#endif
-
-#ifndef  _HVTYPES_H
+#include <asm/iSeries/HvCallSc.h>
 #include <asm/iSeries/HvTypes.h>
-#endif
 
 //-----------------------------------------------------------------------------
 // Constants
 //-----------------------------------------------------------------------------
-#ifndef _HVCALLSM_H
-#define _HVCALLSM_H
 
 #define HvCallSmGet64BitsOfAccessMap	HvCallSm  + 11
 
@@ -54,5 +49,4 @@ static inline u64		HvCallSm_get64BitsOfA
 	return retval;
 }
 //============================================================================
-#endif // _HVCALLSM_H
-
+#endif /* _HVCALLSM_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvCallXm.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallXm.h
--- linux-2.5/include/asm-ppc64/iSeries/HvCallXm.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvCallXm.h	2003-11-21 06:45:03.000000000 +0000
@@ -8,6 +8,8 @@
 //	drive the hypervisor from SLIC.
 //
 //============================================================================
+#ifndef _HVCALLXM_H
+#define _HVCALLXM_H
 
 //-------------------------------------------------------------------
 // Forward declarations 
@@ -16,24 +18,12 @@
 //-------------------------------------------------------------------
 // Standard Includes
 //-------------------------------------------------------------------
-#ifndef  _HVCALLSC_H
-#include "HvCallSc.h"
-#endif
-
-#ifndef  _HVTYPES_H
+#include <asm/iSeries/HvCallSc.h>
 #include <asm/iSeries/HvTypes.h>
-#endif
-
-//-------------------------------------------------------------------
-// Other Includes
-//-------------------------------------------------------------------
-
 
 //-----------------------------------------------------------------------------
 // Constants
 //-----------------------------------------------------------------------------
-#ifndef _HVCALLXM_H
-#define _HVCALLXM_H
 
 #define HvCallXmGetTceTableParms	HvCallXm +  0
 #define HvCallXmTestBus			HvCallXm +  1
@@ -102,5 +92,4 @@ static inline u64	HvCallXm_loadTod(void)
 }
 //=====================================================================================
 
-#endif // _HVCALLXM_H
-
+#endif /* _HVCALLXM_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvLpConfig.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvLpConfig.h
--- linux-2.5/include/asm-ppc64/iSeries/HvLpConfig.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvLpConfig.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _HVLPCONFIG_H
+#define _HVLPCONFIG_H
 
 //===========================================================================
 //
@@ -24,24 +26,10 @@
 //
 //===========================================================================
 
-#ifndef  _HVCALLCFG_H
-#include "HvCallCfg.h"
-#endif
-
-#ifndef  _HVTYPES_H
+#include <asm/iSeries/HvCallCfg.h>
 #include <asm/iSeries/HvTypes.h>
-#endif
-
-#ifndef  _ITLPNACA_H
 #include <asm/iSeries/ItLpNaca.h>
-#endif
-
-#ifndef  _LPARDATA_H
 #include <asm/iSeries/LparData.h>
-#endif
-
-#ifndef _HVLPCONFIG_H
-#define _HVLPCONFIG_H
 
 //-------------------------------------------------------------------
 // Constants
@@ -289,4 +277,4 @@ static inline HvLpIndex		HvLpConfig_getH
 }
 //================================================================
 
-#endif // _HVLPCONFIG_H
+#endif /* _HVLPCONFIG_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvLpEvent.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvLpEvent.h
--- linux-2.5/include/asm-ppc64/iSeries/HvLpEvent.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvLpEvent.h	2003-11-21 06:45:03.000000000 +0000
@@ -28,10 +28,7 @@
 #include <asm/types.h>
 #include <asm/ptrace.h>
 #include <asm/iSeries/HvTypes.h>
-#ifndef _HVCALLEVENT_H
 #include <asm/iSeries/HvCallEvent.h>
-#endif
-
 
 //=====================================================================
 //
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvReleaseData.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvReleaseData.h
--- linux-2.5/include/asm-ppc64/iSeries/HvReleaseData.h	2002-04-23 04:01:41.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvReleaseData.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _HVRELEASEDATA_H
+#define _HVRELEASEDATA_H
 
 //=============================================================================
 //
@@ -23,15 +25,7 @@
 //   release so that it can be changed in the future (ie, the virtual 
 //   address of the OS's NACA).
 //
-//-----------------------------------------------------------------------------
-// Standard Includes
-//-----------------------------------------------------------------------------
-#ifndef	_PPC64_TYPES_H
-#include	<asm/types.h>
-#endif
-
-#ifndef _HVRELEASEDATA_H
-#define _HVRELEASEDATA_H
+#include <asm/types.h>
 
 //=============================================================================
 //
@@ -67,4 +61,4 @@ struct	HvReleaseData
 	char	xRsvd3[20];		// Reserved			x2C-x3F
 };
 
-#endif // _HVRELEASEDATA_H
+#endif /* _HVRELEASEDATA_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/HvTypes.h linuxppc64-2.5/include/asm-ppc64/iSeries/HvTypes.h
--- linux-2.5/include/asm-ppc64/iSeries/HvTypes.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/HvTypes.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _HVTYPES_H
+#define _HVTYPES_H
 
 //===========================================================================
 //                                                             Header File Id
@@ -29,13 +31,7 @@
 //
 //===========================================================================
 
-#ifndef _PPC_TYPES_H
-#include        <asm/types.h>
-#endif
-
-
-#ifndef _HVTYPES_H
-#define _HVTYPES_H
+#include <asm/types.h>
 
 //-------------------------------------------------------------------
 // Typedefs
@@ -124,4 +120,4 @@ struct HvLpBufferList {
 	u64 len;
 };
 
-#endif // _HVTYPES_H
+#endif /* _HVTYPES_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/IoHriProcessorVpd.h linuxppc64-2.5/include/asm-ppc64/iSeries/IoHriProcessorVpd.h
--- linux-2.5/include/asm-ppc64/iSeries/IoHriProcessorVpd.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/IoHriProcessorVpd.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,18 +16,15 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _IOHRIPROCESSORVPD_H
+#define _IOHRIPROCESSORVPD_H
 
 //===================================================================
 //
 //	This struct maps Processor Vpd that is DMAd to SLIC by CSP 
 //
 
-#ifndef	_TYPES_H
 #include <asm/types.h>
-#endif
-
-#ifndef _IOHRIPROCESSORVPD_H
-#define _IOHRIPROCESSORVPD_H
 
 struct IoHriProcessorVpd
 {
@@ -87,4 +84,5 @@ struct IoHriProcessorVpd
 
 	char xProcSrc[72];		// CSP format SRC		xB8-xFF
 };
-#endif // _IOHRIPROCESSORVPD_H
+
+#endif /* _IOHRIPROCESSORVPD_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/ItExtVpdPanel.h linuxppc64-2.5/include/asm-ppc64/iSeries/ItExtVpdPanel.h
--- linux-2.5/include/asm-ppc64/iSeries/ItExtVpdPanel.h	2002-07-18 22:09:42.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/ItExtVpdPanel.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _ITEXTVPDPANEL_H
+#define _ITEXTVPDPANEL_H
 
 /*
  *
@@ -31,12 +33,8 @@
  * Standard Includes
  *------------------------------------------------------------------- 
 */
-#ifndef	_PPC_TYPES_H
-#include	<asm/types.h>
-#endif
+#include <asm/types.h>
 
-#ifndef _ITEXTVPDPANEL_H
-#define _ITEXTVPDPANEL_H
 struct ItExtVpdPanel
 {
   // Definition of the Extended Vpd On Panel Data Area
diff -purN linux-2.5/include/asm-ppc64/iSeries/ItIplParmsReal.h linuxppc64-2.5/include/asm-ppc64/iSeries/ItIplParmsReal.h
--- linux-2.5/include/asm-ppc64/iSeries/ItIplParmsReal.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/ItIplParmsReal.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _ITIPLPARMSREAL_H
+#define _ITIPLPARMSREAL_H
 
 //==============================================================================
 //
@@ -31,12 +33,7 @@
 //-------------------------------------------------------------------
 // Standard Includes
 //-------------------------------------------------------------------
-#ifndef	_PPC_TYPES_H
-#include	<asm/types.h>
-#endif
-
-#ifndef _ITIPLPARMSREAL_H
-#define _ITIPLPARMSREAL_H
+#include <asm/types.h>
 
 struct ItIplParmsReal
 {
@@ -75,4 +72,5 @@ struct ItIplParmsReal
 	u64	xRsvd12;		// Reserved				x30-x37
 	u64	xRsvd13;		// Reserved				x38-x3F
 };
-#endif // _ITIPLPARMSREAL_H
+
+#endif /* _ITIPLPARMSREAL_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/ItLpNaca.h linuxppc64-2.5/include/asm-ppc64/iSeries/ItLpNaca.h
--- linux-2.5/include/asm-ppc64/iSeries/ItLpNaca.h	2003-02-18 18:25:13.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/ItLpNaca.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _ITLPNACA_H
+#define _ITLPNACA_H
 
 //=============================================================================
 //
@@ -24,10 +26,6 @@
 //
 //=============================================================================
 
-
-#ifndef _ITLPNACA_H
-#define _ITLPNACA_H
-
 struct ItLpNaca
 {
 //=============================================================================
@@ -87,4 +85,4 @@ struct ItLpNaca
 
 //=============================================================================
 
-#endif // _ITLPNACA_H
+#endif /* _ITLPNACA_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/ItLpPaca.h linuxppc64-2.5/include/asm-ppc64/iSeries/ItLpPaca.h
--- linux-2.5/include/asm-ppc64/iSeries/ItLpPaca.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/ItLpPaca.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _ITLPPACA_H
+#define _ITLPPACA_H
 
 //=============================================================================
 //                                   
@@ -24,13 +26,7 @@
 //    
 //
 //----------------------------------------------------------------------------
-#ifndef  _PPC_TYPES_H
 #include <asm/types.h>
-#endif
-
-#ifndef _ITLPPACA_H
-#define _ITLPPACA_H
-
 
 struct ItLpPaca
 {
@@ -110,7 +106,10 @@ struct ItLpPaca
 	u64     xPDCSavedSPRG1;         // Saved SPRG1 for PMC int      x68-x6F
 	u64     xPDCSavedSRR0;          // Saved SRR0 for PMC int       x70-x77
 	volatile u32 xVirtualDecr;	// Virtual DECR for shared procsx78-x7B
-	u32	    xRsvd2_2;		// Reserved			x7C-x7F
+	u16     xSLBCount;              // # of SLBs to maintain        x7C-x7D
+	u8      xIdle;                  // Indicate OS is idle          x7E
+	u8      xRsvd2_2;               // Reserved                     x7F
+
 
 //=============================================================================
 // CACHE_LINE_3 0x0100 - 0x007F: This line is shared with other processors
@@ -131,4 +130,5 @@ struct ItLpPaca
 
 
 };
-#endif // _ITLPPACA_H
+
+#endif /* _ITLPPACA_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/ItLpQueue.h linuxppc64-2.5/include/asm-ppc64/iSeries/ItLpQueue.h
--- linux-2.5/include/asm-ppc64/iSeries/ItLpQueue.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/ItLpQueue.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _ITLPQUEUE_H
+#define _ITLPQUEUE_H
 
 //=============================================================================
 //
@@ -24,18 +26,11 @@
 //	events to an LP.  
 //    
 
-#ifndef _PPC_TYPES_H
 #include <asm/types.h>
-#endif
 #include <asm/ptrace.h>
 
-
 struct HvLpEvent;
 
-
-#ifndef _ITLPQUEUE_H
-#define _ITLPQUEUE_H
-
 #define ITMaxLpQueues 8
 
 #define NotUsed		0	// Queue will not be used by PLIC
@@ -94,6 +89,4 @@ static __inline__ void process_iSeries_e
 	: : : "r0", "r3" );	
 }
 
-
-//=============================================================================
-#endif // _ITLPQUEUE_H
+#endif /* _ITLPQUEUE_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/ItLpRegSave.h linuxppc64-2.5/include/asm-ppc64/iSeries/ItLpRegSave.h
--- linux-2.5/include/asm-ppc64/iSeries/ItLpRegSave.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/ItLpRegSave.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _ITLPREGSAVE_H
+#define _ITLPREGSAVE_H
 
 //=====================================================================================
 //
@@ -24,9 +26,6 @@
 //    
 //
 
-#ifndef _ITLPREGSAVE_H
-#define _ITLPREGSAVE_H
-
 struct ItLpRegSave
 {
 	u32	xDesc;		// Eye catcher  "LpRS" ebcdic	000-003
@@ -84,4 +83,5 @@ struct ItLpRegSave
 
 	u8	xRsvd3[176];	// Reserved			350-3FF
 };
-#endif // _ITLPREGSAVE_H
+
+#endif /* _ITLPREGSAVE_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/ItVpdAreas.h linuxppc64-2.5/include/asm-ppc64/iSeries/ItVpdAreas.h
--- linux-2.5/include/asm-ppc64/iSeries/ItVpdAreas.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/ItVpdAreas.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,6 +16,8 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
+#ifndef _ITVPDAREAS_H
+#define _ITVPDAREAS_H
 
 //=====================================================================================
 //
@@ -23,13 +25,7 @@
 //	the OS from PLIC (most of which start from the SP).
 //
 
-#ifndef _PPC_TYPES_H
-#include        <asm/types.h>
-#endif
-
-
-#ifndef _ITVPDAREAS_H
-#define _ITVPDAREAS_H
+#include <asm/types.h>
 
 // VPD Entry index is carved in stone - cannot be changed (easily).
 #define ItVpdCecVpd				   0
@@ -97,4 +93,4 @@ struct	ItVpdAreas
 	void * xSlicVpdAdrs[ItVpdMaxEntries];// Array of VPD buffers	130-1EF
 };
 
-#endif // _ITVPDAREAS_H
+#endif /* _ITVPDAREAS_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/LparMap.h linuxppc64-2.5/include/asm-ppc64/iSeries/LparMap.h
--- linux-2.5/include/asm-ppc64/iSeries/LparMap.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/LparMap.h	2003-11-21 06:45:03.000000000 +0000
@@ -16,14 +16,11 @@
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307 USA
  */
-
-#ifndef	_PPC_TYPES_H
-#include	<asm/types.h>
-#endif
-
 #ifndef _LPARMAP_H
 #define _LPARMAP_H
 
+#include <asm/types.h>
+
 /* The iSeries hypervisor will set up mapping for one or more 
  * ESID/VSID pairs (in SLB/segment registers) and will set up
  * mappings of one or more ranges of pages to VAs.
diff -purN linux-2.5/include/asm-ppc64/iSeries/iSeries_dma.h linuxppc64-2.5/include/asm-ppc64/iSeries/iSeries_dma.h
--- linux-2.5/include/asm-ppc64/iSeries/iSeries_dma.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/iSeries_dma.h	2003-11-21 06:45:03.000000000 +0000
@@ -21,9 +21,7 @@
 #define _ISERIES_DMA_H
 
 #include <asm/types.h>
-#ifndef __LINUX_SPINLOCK_H
 #include <linux/spinlock.h>
-#endif
 
 // NUM_TCE_LEVELS defines the largest contiguous block
 // of dma (tce) space we can get.  NUM_TCE_LEVELS = 10 
@@ -94,4 +92,4 @@ extern void              create_virtual_
 
 extern void		 create_pci_bus_tce_table( unsigned busNumber );
 
-#endif // _ISERIES_DMA_H
+#endif /* _ISERIES_DMA_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/iSeries_io.h linuxppc64-2.5/include/asm-ppc64/iSeries/iSeries_io.h
--- linux-2.5/include/asm-ppc64/iSeries/iSeries_io.h	2002-02-14 12:14:36.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/iSeries_io.h	2003-11-21 06:45:03.000000000 +0000
@@ -1,8 +1,9 @@
+#ifndef _ISERIES_IO_H
+#define _ISERIES_IO_H
+
 #include <linux/config.h>
 
 #ifdef CONFIG_PPC_ISERIES
-#ifndef _ISERIES_IO_H
-#define _ISERIES_IO_H
 #include <linux/types.h>
 /************************************************************************/
 /* File iSeries_io.h created by Allan Trautman on Thu Dec 28 2000.      */
@@ -41,6 +42,5 @@ extern void* iSeries_memset_io(void *des
 extern void* iSeries_memcpy_toio(void *dest, void *source, size_t n);
 extern void* iSeries_memcpy_fromio(void *dest, void *source, size_t n);
 
-#endif /*  _ISERIES_IO_H         */
-#endif /*  CONFIG_PPC_ISERIES  */
-
+#endif /* CONFIG_PPC_ISERIES */
+#endif /* _ISERIES_IO_H */
diff -purN linux-2.5/include/asm-ppc64/iSeries/iSeries_irq.h linuxppc64-2.5/include/asm-ppc64/iSeries/iSeries_irq.h
--- linux-2.5/include/asm-ppc64/iSeries/iSeries_irq.h	2002-02-14 12:14:37.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/iSeries_irq.h	2003-11-21 06:45:03.000000000 +0000
@@ -1,19 +1,11 @@
-
 #ifndef	__ISERIES_IRQ_H__
 #define	__ISERIES_IRQ_H__
 
-
 #ifdef __cplusplus
 extern "C" {
 #endif
 
-unsigned int iSeries_startup_IRQ(unsigned int);
-void iSeries_shutdown_IRQ(unsigned int);
-void iSeries_enable_IRQ(unsigned int);
-void iSeries_disable_IRQ(unsigned int);
-void iSeries_end_IRQ(unsigned int);
 void iSeries_init_IRQ(void);
-void iSeries_init_irqMap(int);
 int  iSeries_allocate_IRQ(HvBusNumber, HvSubBusNumber, HvAgentId);
 int  iSeries_assign_IRQ(int, HvBusNumber, HvSubBusNumber, HvAgentId);
 void iSeries_activate_IRQs(void);
diff -purN linux-2.5/include/asm-ppc64/iSeries/vio.h linuxppc64-2.5/include/asm-ppc64/iSeries/vio.h
--- linux-2.5/include/asm-ppc64/iSeries/vio.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/iSeries/vio.h	2003-11-21 05:46:23.000000000 +0000
@@ -0,0 +1,129 @@
+/* -*- linux-c -*-
+ *  drivers/char/vio.h
+ *
+ *  iSeries Virtual I/O Message Path header
+ *
+ *  Authors: Dave Boutcher <boutcher@us.ibm.com>
+ *           Ryan Arnold <ryanarn@us.ibm.com>
+ *           Colin Devilbiss <devilbis@us.ibm.com>
+ *
+ * (C) Copyright 2000 IBM Corporation
+ * 
+ * This header file is used by the iSeries virtual I/O device
+ * drivers.  It defines the interfaces to the common functions
+ * (implemented in drivers/char/viopath.h) as well as defining
+ * common functions and structures.  Currently (at the time I 
+ * wrote this comment) the iSeries virtual I/O device drivers
+ * that use this are 
+ *   drivers/block/viodasd.c 
+ *   drivers/char/viocons.c
+ *   drivers/char/viotape.c
+ *   drivers/cdrom/viocd.c
+ *
+ * The iSeries virtual ethernet support (veth.c) uses a whole
+ * different set of functions.
+ * 
+ * This program is free software;  you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation; either version 2 of the
+ * License, or (at your option) anyu later version.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of 
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.  
+ *
+ * You should have received a copy of the GNU General Public License 
+ * along with this program; if not, write to the Free Software Foundation,
+ * Inc., 59 Temple Place, Suite 330, Boston, MA 02111-1307 USA
+ *
+ */
+#ifndef _VIO_H
+#define _VIO_H
+
+#include <asm/iSeries/HvTypes.h>
+#include <asm/iSeries/HvLpEvent.h>
+
+/* iSeries virtual I/O events use the subtype field in
+ * HvLpEvent to figure out what kind of vio event is coming
+ * in.  We use a table to route these, and this defines
+ * the maximum number of distinct subtypes
+ */
+#define VIO_MAX_SUBTYPES 7
+
+/* Each subtype can register a handler to process their events.
+ * The handler must have this interface.
+ */
+typedef void (vio_event_handler_t) (struct HvLpEvent * event);
+
+int viopath_open(HvLpIndex remoteLp, int subtype, int numReq);
+int viopath_close(HvLpIndex remoteLp, int subtype, int numReq);
+int vio_setHandler(int subtype, vio_event_handler_t * beh);
+int vio_clearHandler(int subtype);
+int viopath_isactive(HvLpIndex lp);
+HvLpInstanceId viopath_sourceinst(HvLpIndex lp);
+HvLpInstanceId viopath_targetinst(HvLpIndex lp);
+void vio_set_hostlp(void);
+void *vio_get_event_buffer(int subtype);
+void vio_free_event_buffer(int subtype, void *buffer);
+
+extern HvLpIndex viopath_hostLp;
+extern HvLpIndex viopath_ourLp;
+
+#define VIO_MESSAGE "iSeries virtual I/O: "
+#define KERN_DEBUG_VIO KERN_DEBUG VIO_MESSAGE
+#define KERN_INFO_VIO KERN_INFO VIO_MESSAGE
+#define KERN_WARNING_VIO KERN_WARNING VIO_MESSAGE
+
+#define VIOCHAR_MAX_DATA 200
+
+#define VIOMAJOR_SUBTYPE_MASK 0xff00
+#define VIOMINOR_SUBTYPE_MASK 0x00ff
+#define VIOMAJOR_SUBTYPE_SHIFT 8
+
+#define VIOVERSION            0x0101
+
+/*
+This is the general structure for VIO errors; each module should have a table
+of them, and each table should be terminated by an entry of { 0, 0, NULL }.
+Then, to find a specific error message, a module should pass its local table
+and the return code.
+*/
+struct vio_error_entry {
+	u16 rc;
+	int errno;
+	const char *msg;
+};
+const struct vio_error_entry *vio_lookup_rc(const struct vio_error_entry
+					    *local_table, u16 rc);
+
+enum viosubtypes {
+	viomajorsubtype_monitor = 0x0100,
+	viomajorsubtype_blockio = 0x0200,
+	viomajorsubtype_chario = 0x0300,
+	viomajorsubtype_config = 0x0400,
+	viomajorsubtype_cdio = 0x0500,
+	viomajorsubtype_tape = 0x0600
+};
+
+
+enum vioconfigsubtype {
+	vioconfigget = 0x0001,
+};
+
+enum viorc {
+	viorc_good = 0x0000,
+	viorc_noConnection = 0x0001,
+	viorc_noReceiver = 0x0002,
+	viorc_noBufferAvailable = 0x0003,
+	viorc_invalidMessageType = 0x0004,
+	viorc_invalidRange = 0x0201,
+	viorc_invalidToken = 0x0202,
+	viorc_DMAError = 0x0203,
+	viorc_useError = 0x0204,
+	viorc_releaseError = 0x0205,
+	viorc_invalidDisk = 0x0206,
+	viorc_openRejected = 0x0301
+};
+
+#endif /* _VIO_H */
diff -purN linux-2.5/include/asm-ppc64/io.h linuxppc64-2.5/include/asm-ppc64/io.h
--- linux-2.5/include/asm-ppc64/io.h	2003-09-16 16:07:45.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/io.h	2003-10-23 14:10:29.000000000 +0000
@@ -120,11 +120,15 @@ extern void _outsl_ns(volatile u32 *port
  * Map in an area of physical address space, for accessing
  * I/O devices etc.
  */
+extern int __ioremap_explicit(unsigned long p_addr, unsigned long v_addr,
+		     	      unsigned long size, unsigned long flags);
 extern void *__ioremap(unsigned long address, unsigned long size,
 		       unsigned long flags);
 extern void *ioremap(unsigned long address, unsigned long size);
 #define ioremap_nocache(addr, size)	ioremap((addr), (size))
+extern int iounmap_explicit(void *addr, unsigned long size);
 extern void iounmap(void *addr);
+extern void * reserve_phb_iospace(unsigned long size);
 
 /*
  * Change virtual addresses to physical addresses and vv, for
diff -purN linux-2.5/include/asm-ppc64/irq.h linuxppc64-2.5/include/asm-ppc64/irq.h
--- linux-2.5/include/asm-ppc64/irq.h	2003-04-23 07:49:34.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/irq.h	2003-09-23 05:27:07.000000000 +0000
@@ -11,35 +11,16 @@
 
 #include <asm/atomic.h>
 
+#define NR_IRQS			512
+
 extern void disable_irq(unsigned int);
 extern void disable_irq_nosync(unsigned int);
 extern void enable_irq(unsigned int);
 
-/*
- * this is the maximum number of virtual irqs we will use.
- */
-#define NR_IRQS			512
-
-#define NUM_8259_INTERRUPTS	16
-
-/* Interrupt numbers are virtual in case they are sparsely
- * distributed by the hardware.
- */
-#define NR_HW_IRQS		8192
-extern unsigned short real_irq_to_virt_map[NR_HW_IRQS];
-extern unsigned short virt_irq_to_real_map[NR_IRQS];
-/* Create a mapping for a real_irq if it doesn't already exist.
- * Return the virtual irq as a convenience.
- */
-unsigned long virt_irq_create_mapping(unsigned long real_irq);
-
-/* These funcs map irqs between real and virtual */
-static inline unsigned long real_irq_to_virt(unsigned long real_irq) {
-	return real_irq_to_virt_map[real_irq];
-}
-static inline unsigned long virt_irq_to_real(unsigned long virt_irq) {
-	return virt_irq_to_real_map[virt_irq];
-}
+extern void *_get_irq_desc(unsigned int irq);
+extern void *_get_real_irq_desc(unsigned int irq);
+#define get_irq_desc(irq) ((irq_desc_t *)_get_irq_desc(irq))
+#define get_real_irq_desc(irq) ((irq_desc_t *)_get_real_irq_desc(irq))
 
 /*
  * This gets called from serial.c, which is now used on
@@ -51,7 +32,34 @@ static __inline__ int irq_canonicalize(i
 	return irq;
 }
 
-#define NR_MASK_WORDS	((NR_IRQS + 63) / 64)
+/*
+ * Because many systems have two overlapping names spaces for
+ * interrupts (ISA and XICS for example), and the ISA interrupts
+ * have historically not been easy to renumber, we allow ISA
+ * interrupts to take values 0 - 15, and shift up the remaining 
+ * interrupts by 0x10.  
+ *
+ * This would be nice to remove at some point as it adds confusion
+ * and adds a nasty end case if any platform native interrupts have 
+ * values within 0x10 of the end of that namespace.
+ */
+
+#define NUM_ISA_INTERRUPTS	0x10
+
+extern inline int irq_offset_up(int irq)
+{
+	return(irq + NUM_ISA_INTERRUPTS);
+}
+
+extern inline int irq_offset_down(int irq)
+{
+	return(irq - NUM_ISA_INTERRUPTS);
+}
+
+extern inline int irq_offset_value(void)
+{
+	return NUM_ISA_INTERRUPTS;
+}
 
 #endif /* _ASM_IRQ_H */
 #endif /* __KERNEL__ */
diff -purN linux-2.5/include/asm-ppc64/kdb.h linuxppc64-2.5/include/asm-ppc64/kdb.h
--- linux-2.5/include/asm-ppc64/kdb.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/kdb.h	2003-10-13 19:47:30.000000000 +0000
@@ -0,0 +1,82 @@
+/*
+ * Minimalist Kernel Debugger
+ *
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) Scott Lurndal (slurn@engr.sgi.com)
+ * Copyright (C) Scott Foehner (sfoehner@engr.sgi.com)
+ * Copyright (C) Srinivasa Thirumalachar (sprasad@engr.sgi.com)
+ *
+ * See the file LIA-COPYRIGHT for additional information.
+ *
+ * Written March 1999 by Scott Lurndal at Silicon Graphics, Inc.
+ *
+ * Modifications from:
+ *      Richard Bass                    1999/07/20
+ *              Many bug fixes and enhancements.
+ *      Scott Foehner
+ *              Port to ia64
+ *	Scott Lurndal			1999/12/12
+ *		v1.0 restructuring.
+ */
+#if !defined(_ASM_KDB_H)
+#define _ASM_KDB_H
+	/*
+	 * KDB_ENTER() is a macro which causes entry into the kernel
+	 * debugger from any point in the kernel code stream.  If it 
+	 * is intended to be used from interrupt level, it must  use
+	 * a non-maskable entry method.
+	 */
+#define KDB_ENTER()	kdb(KDB_REASON_CALL,0,0);
+
+#ifndef ElfW
+# if ELFCLASSM == ELFCLASS32
+#  define ElfW(x)  Elf32_ ## x
+#  define ELFW(x)  ELF32_ ## x
+# else
+#  define ElfW(x)  Elf64_ ## x
+#  define ELFW(x)  ELF64_ ## x
+# endif
+#endif
+
+	/*
+	 * Define the exception frame for this architecture
+	 */
+struct pt_regs;
+typedef struct pt_regs	*kdb_eframe_t;
+
+	/*
+	 * Needed for exported symbols.
+	 */
+typedef unsigned long kdb_machreg_t;
+
+#define kdb_machreg_fmt		"0x%016lx"
+#define kdb_machreg_fmt0	"0x%016lx"
+#define kdb_bfd_vma_fmt		"0x%016lx"
+#define kdb_bfd_vma_fmt0	"0x%016lx"
+#define kdb_elfw_addr_fmt	"0x%016lx"
+#define kdb_elfw_addr_fmt0	"0x%016lx"
+
+	/*
+	 * Per cpu arch specific kdb state.  Must be in range 0xff000000.
+	 */
+#define KDB_STATE_A_IF		0x01000000	/* Saved IF flag */
+
+	 /*
+	  * Interface from kernel trap handling code to kernel debugger.
+	  */
+extern int	kdba_callback_die(struct pt_regs *, int, long, void*);
+extern int	kdba_callback_bp(struct pt_regs *, int, long, void*);
+extern int	kdba_callback_debug(struct pt_regs *, int, long, void *);
+
+#include <linux/types.h>
+extern int kdba_putarea_size(unsigned long to_xxx, void *from, size_t size);
+extern int kdba_getarea_size(void *to, unsigned long from_xxx, size_t size);
+
+static inline int
+kdba_verify_rw(unsigned long addr, size_t size)
+{
+	unsigned char data[size];
+	return(kdba_getarea_size(data, addr, size) || kdba_putarea_size(addr, data, size));
+}
+
+#endif	/* ASM_KDB_H */
diff -purN linux-2.5/include/asm-ppc64/kdbprivate.h linuxppc64-2.5/include/asm-ppc64/kdbprivate.h
--- linux-2.5/include/asm-ppc64/kdbprivate.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/kdbprivate.h	2003-10-13 19:50:10.000000000 +0000
@@ -0,0 +1,120 @@
+/*
+ * Minimalist Kernel Debugger
+ *
+ * Copyright (C) 1999 Silicon Graphics, Inc.
+ * Copyright (C) Scott Lurndal (slurn@engr.sgi.com)
+ * Copyright (C) Scott Foehner (sfoehner@engr.sgi.com)
+ * Copyright (C) Srinivasa Thirumalachar (sprasad@engr.sgi.com)
+ *
+ * See the file LIA-COPYRIGHT for additional information.
+ *
+ * Written March 1999 by Scott Lurndal at Silicon Graphics, Inc.
+ *
+ * Modifications from:
+ *      Richard Bass                    1999/07/20
+ *              Many bug fixes and enhancements.
+ *      Scott Foehner
+ *              Port to ia64
+ *	Scott Lurndal			1999/12/12
+ *		v1.0 restructuring.
+ *	Keith Owens			2000/05/23
+ *		KDB v1.2
+ */
+#if !defined(_ASM_KDBPRIVATE_H)
+#define _ASM_KDBPRIVATE_H
+
+typedef unsigned long kdb_machinst_t;
+
+	/*
+	 * KDB_MAXBPT describes the total number of breakpoints
+	 * supported by this architecure.  
+	 */
+#define KDB_MAXBPT	4
+	/*
+	 * KDB_MAXHARDBPT describes the total number of hardware
+	 * breakpoint registers that exist.
+	 */
+#define KDB_MAXHARDBPT	 1
+        /*
+         * Provide space for KDB_MAX_COMMANDS commands.
+         */
+#define KDB_MAX_COMMANDS        125
+
+	/*
+	 * Platform specific environment entries
+	 */
+#define KDB_PLATFORM_ENV	"IDMODE=PPC64", "BYTESPERWORD=8", "IDCOUNT=16"
+
+	/*
+	 * Define the direction that the stack grows
+	 */
+#define KDB_STACK_DIRECTION	-1	/* Stack grows down */
+
+	/*
+	 * Support for ia32 debug registers 
+	 */
+typedef struct _kdbhard_bp {
+	kdb_machreg_t	bph_reg;	/* Register this breakpoint uses */
+
+	unsigned int	bph_free:1;	/* Register available for use */
+	unsigned int	bph_data:1;	/* Data Access breakpoint */
+
+	unsigned int	bph_write:1;	/* Write Data breakpoint */
+	unsigned int	bph_mode:2;	/* 0=inst, 1=write, 2=io, 3=read */
+	unsigned int	bph_length:2;	/* 0=1, 1=2, 2=BAD, 3=4 (bytes) */
+} kdbhard_bp_t;
+
+extern kdbhard_bp_t	kdb_hardbreaks[/* KDB_MAXHARDBPT */];
+
+#define PPC64_BREAKPOINT_INSTRUCTION 0x7fe00008    
+#define PPC64_ADJUST_OFFSET 0x00   
+
+#define KDB_HAVE_LONGJMP 
+#ifdef KDB_HAVE_LONGJMP
+typedef struct __kdb_jmp_buf {
+	unsigned int regs[100];
+} kdb_jmp_buf;
+extern int kdb_setjmp(kdb_jmp_buf *);
+extern void kdba_longjmp(kdb_jmp_buf *, int);
+extern kdb_jmp_buf  kdbjmpbuf[];
+#endif	/* KDB_HAVE_LONGJMP */
+
+
+/*
+ A traceback table typically follows each function.
+ The find_tb_table() func will fill in this struct.  Note that the struct
+ is not an exact match with the encoded table defined by the ABI.  It is
+ defined here more for programming convenience.
+ */
+typedef struct {
+    unsigned long	flags;		/* flags: */
+#define KDBTBTAB_FLAGSGLOBALLINK	(1L<<47)
+#define KDBTBTAB_FLAGSISEPROL		(1L<<46)
+#define KDBTBTAB_FLAGSHASTBOFF		(1L<<45)
+#define KDBTBTAB_FLAGSINTPROC		(1L<<44)
+#define KDBTBTAB_FLAGSHASCTL		(1L<<43)
+#define KDBTBTAB_FLAGSTOCLESS		(1L<<42)
+#define KDBTBTAB_FLAGSFPPRESENT		(1L<<41)
+#define KDBTBTAB_FLAGSNAMEPRESENT	(1L<<38)
+#define KDBTBTAB_FLAGSUSESALLOCA	(1L<<37)
+#define KDBTBTAB_FLAGSSAVESCR		(1L<<33)
+#define KDBTBTAB_FLAGSSAVESLR		(1L<<32)
+#define KDBTBTAB_FLAGSSTORESBC		(1L<<31)
+#define KDBTBTAB_FLAGSFIXUP		(1L<<30)
+#define KDBTBTAB_FLAGSPARMSONSTK	(1L<<0)
+    unsigned char	fp_saved;	/* num fp regs saved f(32-n)..f31 */
+    unsigned char	gpr_saved;	/* num gpr's saved */
+    unsigned char	fixedparms;	/* num fixed point parms */
+    unsigned char	floatparms;	/* num float parms */
+    unsigned char	parminfo[32];	/* types of args.  null terminated */
+#define KDBTBTAB_PARMFIXED 1
+#define KDBTBTAB_PARMSFLOAT 2
+#define KDBTBTAB_PARMDFLOAT 3
+    unsigned int	tb_offset;	/* offset from start of func */
+    unsigned long	funcstart;	/* addr of start of function */
+    char		name[64];	/* name of function (null terminated)*/
+    kdb_symtab_t	symtab;		/* fake symtab entry */
+} kdbtbtable_t;
+int kdba_find_tb_table(kdb_machreg_t eip, kdbtbtable_t *tab);
+
+#endif	/* !_ASM_KDBPRIVATE_H */
diff -purN linux-2.5/include/asm-ppc64/machdep.h linuxppc64-2.5/include/asm-ppc64/machdep.h
--- linux-2.5/include/asm-ppc64/machdep.h	2003-06-07 01:59:39.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/machdep.h	2003-11-21 04:51:10.000000000 +0000
@@ -11,6 +11,7 @@
 
 #include <linux/config.h>
 #include <linux/seq_file.h>
+#include <linux/irq.h>
 
 struct pt_regs;
 struct pci_bus;	
@@ -67,6 +68,7 @@ struct machdep_calls {
 	void		(*get_cpuinfo)(struct seq_file *m);
 
 	void		(*init_IRQ)(void);
+	void		(*init_irq_desc)(irq_desc_t *desc);
 	int		(*get_irq)(struct pt_regs *);
 
 	/* Optional, may be NULL. */
@@ -89,6 +91,12 @@ struct machdep_calls {
 	unsigned char	(*udbg_getc)(void);
 	int		(*udbg_getc_poll)(void);
 
+	/* Interface for platform error logging */
+	void 		(*log_error)(char *buf, unsigned int err_type, int fatal);
+
+	ssize_t		(*nvram_write)(char *buf, size_t count, loff_t *index);
+	ssize_t		(*nvram_read)(char *buf, size_t count, loff_t *index);	
+
 #ifdef CONFIG_SMP
 	/* functions for dealing with other cpus */
 	struct smp_ops_t smp_ops;
@@ -113,5 +121,11 @@ void ppc64_attention_msg(unsigned int sr
 /* Print a dump progress message. */
 void ppc64_dump_msg(unsigned int src, const char *msg);
 
+static inline void log_error(char *buf, unsigned int err_type, int fatal)
+{
+	if (ppc_md.log_error)
+		ppc_md.log_error(buf, err_type, fatal);
+}
+
 #endif /* _PPC64_MACHDEP_H */
 #endif /* __KERNEL__ */
diff -purN linux-2.5/include/asm-ppc64/memory.h linuxppc64-2.5/include/asm-ppc64/memory.h
--- linux-2.5/include/asm-ppc64/memory.h	2003-10-01 22:32:13.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/memory.h	2003-11-06 20:34:42.000000000 +0000
@@ -42,23 +42,28 @@ static inline void isync(void)
 #endif
 
 /* Macros for adjusting thread priority (hardware multi-threading) */
-
-#if defined(CONFIG_PPC_ISERIES) || defined(CONFIG_HMT)
+#define HMT_very_low()    asm volatile("or 31,31,31   # very low priority")
 #define HMT_low()	asm volatile("or 1,1,1		# low priority")
+#define HMT_medium_low()  asm volatile("or 6,6,6      # medium low priority")
 #define HMT_medium()	asm volatile("or 2,2,2		# medium priority")
+#define HMT_medium_high() asm volatile("or 5,5,5      # medium high priority")
 #define HMT_high()	asm volatile("or 3,3,3		# high priority")
 
+#define HMT_VERY_LOW    "\tor   31,31,31        # very low priority\n"
 #define HMT_LOW		"\tor	1,1,1		# low priority\n"
+#define HMT_MEDIUM_LOW  "\tor   6,6,6           # medium low priority\n"
 #define HMT_MEDIUM	"\tor	2,2,2		# medium priority\n"
+#define HMT_MEDIUM_HIGH "\tor   5,5,5           # medium high priority\n"
 #define HMT_HIGH	"\tor	3,3,3		# high priority\n"
-#else
-#define HMT_low()	do { } while(0)
-#define HMT_medium()	do { } while(0)
-#define HMT_high()	do { } while(0)
 
-#define HMT_LOW
-#define HMT_MEDIUM
-#define HMT_HIGH
-#endif
+/* 
+ * Various operational modes for SMT
+ * Off    : never run threaded
+ * On     : always run threaded
+ * Dynamic: Allow the system to switch modes as needed
+ */
+#define SMT_OFF      0
+#define SMT_ON       1
+#define SMT_DYNAMIC  2
 
 #endif
diff -purN linux-2.5/include/asm-ppc64/naca.h linuxppc64-2.5/include/asm-ppc64/naca.h
--- linux-2.5/include/asm-ppc64/naca.h	2003-03-26 04:30:59.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/naca.h	2003-11-06 20:34:42.000000000 +0000
@@ -37,7 +37,12 @@ struct naca_struct {
 	u32 dCacheL1LinesPerPage;	/* L1 d-cache lines / page   0x64 */
 	u32 iCacheL1LogLineSize;	/* L1 i-cache line size Log2 0x68 */
 	u32 iCacheL1LinesPerPage;	/* L1 i-cache lines / page   0x6c */
-	u64 resv0[2];                   /* Reserved           0x70 - 0x7F */
+	u64 smt_snooze_delay;           /* Delay (in usec) before    0x70 */
+                                        /* entering ST mode               */
+	u8  smt_state;                  /* 0 = SMT off               0x78 */
+	                                /* 1 = SMT on                     */
+	                                /* 2 = SMT dynamic                */
+	u8  resv0[7];                   /* Reserved           0x70 - 0x7F */
 };
 
 extern struct naca_struct *naca;
diff -purN linux-2.5/include/asm-ppc64/nvram.h linuxppc64-2.5/include/asm-ppc64/nvram.h
--- linux-2.5/include/asm-ppc64/nvram.h	2002-12-30 12:29:15.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/nvram.h	2003-11-21 04:51:10.000000000 +0000
@@ -11,6 +11,12 @@
 #ifndef _PPC64_NVRAM_H
 #define _PPC64_NVRAM_H
 
+#define NVRW_CNT 0x20
+#define NVRAM_HEADER_LEN 16 /* sizeof(struct nvram_header) */
+#define NVRAM_BLOCK_LEN 16
+#define NVRAM_MAX_REQ (2080/NVRAM_BLOCK_LEN)
+#define NVRAM_MIN_REQ (1056/NVRAM_BLOCK_LEN)
+
 #define NVRAM_AS0  0x74
 #define NVRAM_AS1  0x75
 #define NVRAM_DATA 0x77
@@ -28,4 +34,37 @@
 #define MOTO_RTC_CONTROLA       0x1FF8
 #define MOTO_RTC_CONTROLB       0x1FF9
 
+#define NVRAM_SIG_SP	0x02	/* support processor */
+#define NVRAM_SIG_OF	0x50	/* open firmware config */
+#define NVRAM_SIG_FW	0x51	/* general firmware */
+#define NVRAM_SIG_HW	0x52	/* hardware (VPD) */
+#define NVRAM_SIG_SYS	0x70	/* system env vars */
+#define NVRAM_SIG_CFG	0x71	/* config data */
+#define NVRAM_SIG_ELOG	0x72	/* error log */
+#define NVRAM_SIG_VEND	0x7e	/* vendor defined */
+#define NVRAM_SIG_FREE	0x7f	/* Free space */
+#define NVRAM_SIG_OS	0xa0	/* OS defined */
+
+/* If change this size, then change the size of NVNAME_LEN */
+struct nvram_header {
+	unsigned char signature;
+	unsigned char checksum;
+	unsigned short length;
+	char name[12];
+};
+
+struct nvram_partition {
+	struct list_head partition;
+	struct nvram_header header;
+	unsigned int index;
+};
+
+
+ssize_t pSeries_nvram_read(char *buf, size_t count, loff_t *index);
+ssize_t pSeries_nvram_write(char *buf, size_t count, loff_t *index);
+int nvram_write_error_log(char * buff, int length, unsigned int err_type);
+int nvram_read_error_log(char * buff, int length, unsigned int * err_type);
+int nvram_clear_error_log(void);
+void nvram_print_partitions(char * label);
+
 #endif /* _PPC64_NVRAM_H */
diff -purN linux-2.5/include/asm-ppc64/paca.h linuxppc64-2.5/include/asm-ppc64/paca.h
--- linux-2.5/include/asm-ppc64/paca.h	2003-09-01 23:50:18.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/paca.h	2003-11-18 09:09:58.000000000 +0000
@@ -61,7 +61,7 @@ struct paca_struct {
 	struct ItLpRegSave *xLpRegSavePtr; /* Pointer to LpRegSave for PLIC	0x08 */
 	u64 xCurrent;  		        /* Pointer to current			0x10 */
 	u16 xPacaIndex;			/* Logical processor number		0x18 */
-	u16 active;			/* Is this cpu active?			0x1a */
+        u16 xHwProcNum;                 /* Physical processor number            0x1A */
 	u32 default_decr;		/* Default decrementer value		0x1c */	
 	u64 unused1;
 	u64 xKsave;			/* Saved Kernel stack addr or zero	0x28 */
@@ -94,7 +94,9 @@ struct paca_struct {
 	u32 *prof_buffer;		/* iSeries profiling buffer		0x38 */
 	u32 *prof_stext;		/* iSeries start of kernel text		0x40 */
 	u32 prof_len;			/* iSeries length of profile buffer -1	0x48 */
-	u8  rsvd2[128-76];		/*					0x4C */
+	u8  yielded;                    /* 0 = this processor is running        0x4c */
+	                                /* 1 = this processor is yielded             */
+	u8  rsvd2[128-77];		/*					0x49 */
 
 /*=====================================================================================
  * CACHE_LINE_3 0x0100 - 0x017F
@@ -117,7 +119,7 @@ struct paca_struct {
 	struct ItLpRegSave xRegSav;	/* Register save for proc */
 
 /*=====================================================================================
- * CACHE_LINE_17-18 0x0800 - 0x0EFF Reserved
+ * CACHE_LINE_17-18 0x0800 - 0x08FF Reserved
  *=====================================================================================
  */
 	struct rtas_args xRtas;		/* Per processor RTAS struct */
@@ -126,10 +128,12 @@ struct paca_struct {
 	u8 rsvd5[256-16-sizeof(struct rtas_args)];
 
 /*=====================================================================================
- * CACHE_LINE_19-30 0x0800 - 0x0EFF Reserved
+ * CACHE_LINE_19-30 0x0900 - 0x0EFF Reserved
  *=====================================================================================
  */
-	u8 rsvd6[0x600];
+	u64 slb_shadow[0x20];
+	u64 dispatch_log;
+	u8  rsvd6[0x500 - 0x8];
 
 /*=====================================================================================
  * CACHE_LINE_31 0x0F00 - 0x0F7F Exception stack
diff -purN linux-2.5/include/asm-ppc64/pci.h linuxppc64-2.5/include/asm-ppc64/pci.h
--- linux-2.5/include/asm-ppc64/pci.h	2003-10-16 03:16:27.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/pci.h	2003-11-17 23:08:19.000000000 +0000
@@ -135,6 +135,17 @@ extern void
 pcibios_resource_to_bus(struct pci_dev *dev, struct pci_bus_region *region,
 			struct resource *res);
 
+extern int
+unmap_bus_range(struct pci_bus *bus);
+
+extern int
+remap_bus_range(struct pci_bus *bus);
+
+extern void
+pcibios_fixup_device_resources(struct pci_dev *dev, struct pci_bus *bus);
+
+extern int pci_read_irq_line(struct pci_dev *dev);
+
 #endif	/* __KERNEL__ */
 
 #endif /* __PPC64_PCI_H */
diff -purN linux-2.5/include/asm-ppc64/pgtable.h linuxppc64-2.5/include/asm-ppc64/pgtable.h
--- linux-2.5/include/asm-ppc64/pgtable.h	2003-10-10 05:16:19.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/pgtable.h	2003-10-23 14:10:29.000000000 +0000
@@ -51,10 +51,11 @@
  * Define the address range of the imalloc VM area.
  * (used for ioremap)
  */
-#define IMALLOC_START (ioremap_bot)
+#define IMALLOC_START     (ioremap_bot)
 #define IMALLOC_VMADDR(x) ((unsigned long)(x))
-#define IMALLOC_BASE  (0xE000000000000000)
-#define IMALLOC_END   (IMALLOC_BASE + VALID_EA_BITS)
+#define PHBS_IO_BASE  	  (0xE000000000000000)	/* Reserve 2 gigs for PHBs */
+#define IMALLOC_BASE      (0xE000000080000000)  
+#define IMALLOC_END       (IMALLOC_BASE + VALID_EA_BITS)
 
 /*
  * Define the address range mapped virt <-> physical
@@ -399,6 +400,17 @@ void pgtable_cache_init(void);
 extern void hpte_init_pSeries(void);
 extern void hpte_init_iSeries(void);
 
+/* imalloc region types */
+#define IM_REGION_UNUSED	0x1
+#define IM_REGION_SUBSET	0x2
+#define IM_REGION_EXISTS	0x4
+#define IM_REGION_OVERLAP	0x8
+
+extern struct vm_struct * im_get_free_area(unsigned long size);
+extern struct vm_struct * im_get_area(unsigned long v_addr, unsigned long size,
+			int region_type);
+unsigned long im_free(void *addr);
+
 typedef pte_t *pte_addr_t;
 
 long pSeries_lpar_hpte_insert(unsigned long hpte_group,
diff -purN linux-2.5/include/asm-ppc64/ppc32.h linuxppc64-2.5/include/asm-ppc64/ppc32.h
--- linux-2.5/include/asm-ppc64/ppc32.h	2003-01-17 03:02:40.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/ppc32.h	2003-11-21 05:10:26.000000000 +0000
@@ -40,12 +40,7 @@
 
 /* These are here to support 32-bit syscalls on a 64-bit kernel. */
 
-typedef union sigval32 {
-	int sival_int;
-	unsigned int sival_ptr;
-} sigval_t32;
-
-typedef struct siginfo32 {
+typedef struct compat_siginfo {
 	int si_signo;
 	int si_errno;
 	int si_code;
@@ -69,7 +64,7 @@ typedef struct siginfo32 {
 		struct {
 			compat_pid_t _pid;		/* sender's pid */
 			compat_uid_t _uid;		/* sender's uid */
-			sigval_t32 _sigval;
+			compat_sigval_t _sigval;
 		} _rt;
 
 		/* SIGCHLD */
@@ -92,7 +87,7 @@ typedef struct siginfo32 {
 			int _fd;
 		} _sigpoll;
 	} _sifields;
-} siginfo_t32;
+} compat_siginfo_t;
 
 #define __old_sigaction32	old_sigaction32
 
@@ -134,6 +129,20 @@ struct ucontext32 { 
 	sigset_t	  uc_sigmask;	/* mask last for extensibility */
 };
 
+typedef struct compat_sigevent {
+	compat_sigval_t sigev_value;
+	int sigev_signo;
+	int sigev_notify;
+	union {
+		int _pad[SIGEV_PAD_SIZE];
+		int _tid;
+		struct {
+			compat_uptr_t _function;
+			compat_uptr_t _attribute;
+		} _sigev_thread;
+	} _sigev_un;
+} compat_sigevent_t;
+
 struct ipc_kludge_32 {
 	unsigned int msgp;
 	int msgtyp;
diff -purN linux-2.5/include/asm-ppc64/proc_fs.h linuxppc64-2.5/include/asm-ppc64/proc_fs.h
--- linux-2.5/include/asm-ppc64/proc_fs.h	2003-03-26 04:30:59.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/proc_fs.h	2003-11-21 04:51:10.000000000 +0000
@@ -34,5 +34,6 @@ struct proc_ppc64_t {
 };
 
 extern struct proc_ppc64_t proc_ppc64;
+extern int proc_ppc64_init(void);
 
 #endif /* _PPC64_PROC_FS_H */
diff -purN linux-2.5/include/asm-ppc64/processor.h linuxppc64-2.5/include/asm-ppc64/processor.h
--- linux-2.5/include/asm-ppc64/processor.h	2003-10-01 22:41:11.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/processor.h	2003-11-08 00:04:40.000000000 +0000
@@ -371,6 +371,7 @@
 #define	PV_ICESTAR	0x0036
 #define	PV_SSTAR	0x0037
 #define	PV_POWER4p	0x0038
+#define	PV_POWER5	0x003A
 #define	PV_630        	0x0040
 #define	PV_630p	        0x0041
 
@@ -378,6 +379,7 @@
 #define PLATFORM_PSERIES      0x0100
 #define PLATFORM_PSERIES_LPAR 0x0101
 #define PLATFORM_ISERIES_LPAR 0x0201
+#define PLATFORM_LPAR         0x0001
 	
 /*
  * List of interrupt controllers.
diff -purN linux-2.5/include/asm-ppc64/prom.h linuxppc64-2.5/include/asm-ppc64/prom.h
--- linux-2.5/include/asm-ppc64/prom.h	2003-08-15 00:07:45.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/prom.h	2003-10-28 17:14:58.000000000 +0000
@@ -14,6 +14,8 @@
  * as published by the Free Software Foundation; either version
  * 2 of the License, or (at your option) any later version.
  */
+#include <linux/proc_fs.h>
+#include <asm/atomic.h>
 
 #define PTRRELOC(x)     ((typeof(x))((unsigned long)(x) - offset))
 #define PTRUNRELOC(x)   ((typeof(x))((unsigned long)(x) + offset))
@@ -47,6 +49,17 @@ struct pci_address {
 	u32 a_lo;
 };
 
+struct isa_address {
+	u32 a_hi;
+	u32 a_lo;
+};
+
+struct isa_range {
+	struct isa_address isa_addr;
+	struct pci_address pci_addr;
+	unsigned int size;
+};
+
 struct pci_range32 {
 	struct pci_address child_addr;
 	unsigned int  parent_addr;
@@ -120,6 +133,7 @@ struct device_node {
 	char	*name;
 	char	*type;
 	phandle	node;
+	phandle linux_phandle;
 	int	n_addrs;
 	struct	address_range *addrs;
 	int	n_intrs;
@@ -143,7 +157,43 @@ struct device_node {
 	struct	device_node *sibling;
 	struct	device_node *next;	/* next device of same type */
 	struct	device_node *allnext;	/* next in list of all nodes */
-};
+	struct  proc_dir_entry *pde;       /* this node's proc directory */
+	struct  proc_dir_entry *name_link; /* name symlink */
+	struct  proc_dir_entry *addr_link; /* addr symlink */
+	atomic_t _users;                 /* reference count */
+	unsigned long _flags;
+};
+
+/* flag descriptions */
+#define OF_STALE   0 /* node is slated for deletion */
+#define OF_DYNAMIC 1 /* node and properties were allocated via kmalloc */
+
+#define OF_IS_STALE(x) test_bit(OF_STALE, &x->_flags)
+#define OF_MARK_STALE(x) set_bit(OF_STALE, &x->_flags)
+#define OF_IS_DYNAMIC(x) test_bit(OF_DYNAMIC, &x->_flags)
+#define OF_MARK_DYNAMIC(x) set_bit(OF_DYNAMIC, &x->_flags)
+
+/*
+ * Until 32-bit ppc can add proc_dir_entries to its device_node
+ * definition, we cannot refer to pde, name_link, and addr_link
+ * in arch-independent code.
+ */
+#define HAVE_ARCH_DEVTREE_FIXUPS
+
+static inline void set_node_proc_entry(struct device_node *dn, struct proc_dir_entry *de)
+{
+	dn->pde = de;
+}
+
+static void inline set_node_name_link(struct device_node *dn, struct proc_dir_entry *de)
+{
+	dn->name_link = de;
+}
+
+static void inline set_node_addr_link(struct device_node *dn, struct proc_dir_entry *de)
+{
+	dn->addr_link = de;
+}
 
 typedef u32 prom_arg_t;
 
@@ -168,22 +218,43 @@ struct prom_t {
 };
 
 extern struct prom_t prom;
+extern char *of_stdout_device;
 
 extern int boot_cpuid;
 
-/* Prototypes */
-extern void abort(void);
-extern unsigned long prom_init(unsigned long, unsigned long, unsigned long,
-    unsigned long, unsigned long);
-extern void prom_print(const char *msg);
-extern void relocate_nodes(void);
-extern void finish_device_tree(void);
+/* OBSOLETE: Old stlye node lookup */
 extern struct device_node *find_devices(const char *name);
 extern struct device_node *find_type_devices(const char *type);
 extern struct device_node *find_path_device(const char *path);
 extern struct device_node *find_compatible_devices(const char *type,
 						   const char *compat);
 extern struct device_node *find_all_nodes(void);
+
+/* New style node lookup */
+extern struct device_node *of_find_node_by_name(struct device_node *from,
+	const char *name);
+extern struct device_node *of_find_node_by_type(struct device_node *from,
+	const char *type);
+extern struct device_node *of_find_compatible_node(struct device_node *from,
+	const char *type, const char *compat);
+extern struct device_node *of_find_node_by_path(const char *path);
+extern struct device_node *of_find_all_nodes(struct device_node *prev);
+extern struct device_node *of_get_parent(const struct device_node *node);
+extern struct device_node *of_get_next_child(const struct device_node *node,
+					     struct device_node *prev);
+extern struct device_node *of_node_get(struct device_node *node);
+extern void of_node_put(struct device_node *node);
+
+/* For updating the device tree at runtime */
+extern int of_add_node(const char *path, struct property *proplist);
+extern int of_remove_node(struct device_node *np);
+
+/* Other Prototypes */
+extern unsigned long prom_init(unsigned long, unsigned long, unsigned long,
+	unsigned long, unsigned long);
+extern void prom_print(const char *msg);
+extern void relocate_nodes(void);
+extern void finish_device_tree(void);
 extern int device_is_compatible(struct device_node *device, const char *);
 extern int machine_is_compatible(const char *compat);
 extern unsigned char *get_property(struct device_node *node, const char *name,
diff -purN linux-2.5/include/asm-ppc64/ptrace.h linuxppc64-2.5/include/asm-ppc64/ptrace.h
--- linux-2.5/include/asm-ppc64/ptrace.h	2003-03-26 03:38:55.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/ptrace.h	2003-11-19 21:34:28.000000000 +0000
@@ -16,7 +16,7 @@
  * that the overall structure is a multiple of 16 bytes in length.
  *
  * Note that the offsets of the fields in this struct correspond with
- * the PT_* values below.  This simplifies arch/ppc/kernel/ptrace.c.
+ * the PT_* values below.  This simplifies arch/ppc64/kernel/ptrace.c.
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
@@ -120,13 +120,41 @@ struct pt_regs32 {
 #define PT_RESULT 43
 
 #define PT_FPR0	48
+
+/* Kernel and userspace will both use this PT_FPSCR value.  32-bit apps will have
+ * visibility to the asm-ppc/ptrace.h header instead of this one.
+ */
+#define PT_FPSCR (PT_FPR0 + 32 + 1)	  /* each FP reg occupies 1 slot in 64-bit space */
+
 #ifdef __KERNEL__
-#define PT_FPSCR (PT_FPR0 + 32 + 1)	  /* each FP reg occupies 1 slot in this space */
-#define PT_FPSCR32 (PT_FPR0 + 2*32 + 1)	  /* To the 32-bit user - each FP reg occupies 2 slots in this space */
-#else
-#define PT_FPSCR (PT_FPR0 + 2*32 + 1)	/* each FP reg occupies 2 slots in this space -- Fix when 64-bit apps. */
+#define PT_FPSCR32 (PT_FPR0 + 2*32 + 1)	  /* each FP reg occupies 2 32-bit userspace slots */
 #endif
 
+#define PT_VR0 82	/* each Vector reg occupies 2 slots in 64-bit */
+#define PT_VSCR (PT_VR0 + 32*2 + 1)
+#define PT_VRSAVE (PT_VR0 + 33*2)
+
+#ifdef __KERNEL__
+#define PT_VR0_32 164	/* each Vector reg occupies 4 slots in 32-bit */
+#define PT_VSCR_32 (PT_VR0 + 32*4 + 3)
+#define PT_VRSAVE_32 (PT_VR0 + 33*4)
+#endif
+
+/*
+ * Get/set all the altivec registers vr0..vr31, vscr, vrsave, in one go. 
+ * The transfer totals 34 quadword.  Quadwords 0-31 contain the 
+ * corresponding vector registers.  Quadword 32 contains the vscr as the 
+ * last word (offset 12) within that quadword.  Quadword 33 contains the 
+ * vrsave as the first word (offset 0) within the quadword.
+ *
+ * This definition of the VMX state is compatible with the current PPC32 
+ * ptrace interface.  This allows signal handling and ptrace to use the same 
+ * structures.  This also simplifies the implementation of a bi-arch 
+ * (combined (32- and 64-bit) gdb.
+ */
+#define PTRACE_GETVRREGS	18
+#define PTRACE_SETVRREGS	19
+
 /* Additional PTRACE requests implemented on PowerPC. */
 #define PPC_PTRACE_GETREGS	      0x99  /* Get GPRs 0 - 31 */
 #define PPC_PTRACE_SETREGS	      0x98  /* Set GPRs 0 - 31 */
diff -purN linux-2.5/include/asm-ppc64/rtas.h linuxppc64-2.5/include/asm-ppc64/rtas.h
--- linux-2.5/include/asm-ppc64/rtas.h	2003-09-02 06:46:42.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/rtas.h	2003-11-21 04:51:10.000000000 +0000
@@ -19,6 +19,16 @@
 #define RTAS_UNKNOWN_SERVICE (-1)
 #define RTAS_INSTANTIATE_MAX (1UL<<30) /* Don't instantiate rtas at/above this value */
 
+/* Buffer size for ppc_rtas system call. */
+#define RTAS_RMOBUF_MAX (64 * 1024)
+
+/* RTAS return codes */
+#define RTAS_BUSY		-2	/* RTAS Return Status - Busy */
+#define RTAS_EXTENDED_DELAY_MIN 9900
+#define RTAS_EXTENDED_DELAY_MAX 9905
+
+#define RTAS_UNKNOWN_OP		-1099	/* Return Status - Unknown RTAS Token */
+
 /*
  * In general to call RTAS use rtas_token("string") to lookup
  * an RTAS token for the given string (e.g. "event-scan").
@@ -57,11 +67,11 @@ struct rtas_t {
 };
 
 /* Event classes */
-#define INTERNAL_ERROR		0x80000000 /* set bit 0 */
-#define EPOW_WARNING		0x40000000 /* set bit 1 */
-#define POWERMGM_EVENTS		0x20000000 /* set bit 2 */
-#define HOTPLUG_EVENTS		0x10000000 /* set bit 3 */
-#define EVENT_SCAN_ALL_EVENTS	0xf0000000
+#define RTAS_INTERNAL_ERROR		0x80000000 /* set bit 0 */
+#define RTAS_EPOW_WARNING		0x40000000 /* set bit 1 */
+#define RTAS_POWERMGM_EVENTS		0x20000000 /* set bit 2 */
+#define RTAS_HOTPLUG_EVENTS		0x10000000 /* set bit 3 */
+#define RTAS_EVENT_SCAN_ALL_EVENTS	0xf0000000
 
 /* event-scan returns */
 #define SEVERITY_FATAL		0x5
@@ -165,6 +175,9 @@ extern void call_rtas_display_status(cha
 extern void rtas_restart(char *cmd);
 extern void rtas_power_off(void);
 extern void rtas_halt(void);
+extern int rtas_get_sensor(int sensor, int index, int *state);
+extern int rtas_get_power_level(int powerdomain, int *level);
+extern int rtas_set_indicator(int indicator, int index, int new_value);
 
 /* Given an RTAS status code of 9900..9905 compute the hinted delay */
 unsigned int rtas_extended_busy_delay_time(int status);
@@ -173,13 +186,41 @@ static inline int rtas_is_extended_busy(
 	return status >= 9900 && status <= 9909;
 }
 
+extern void pSeries_log_error(char *buf, unsigned int err_type, int fatal);
+
+/* Error types logged.  */
+#define ERR_FLAG_ALREADY_LOGGED	0x0
+#define ERR_FLAG_BOOT		0x1 	/* log was pulled from NVRAM on boot */
+#define ERR_TYPE_RTAS_LOG	0x2	/* from rtas event-scan */
+#define ERR_TYPE_KERNEL_PANIC	0x4	/* from panic() */
+
+/* All the types and not flags */
+#define ERR_TYPE_MASK	(ERR_TYPE_RTAS_LOG | ERR_TYPE_KERNEL_PANIC)
+
+#define RTAS_ERR KERN_ERR "RTAS: "
+ 
+#define RTAS_ERROR_LOG_MAX 2048
+ 
+ 
+/* Event Scan Parameters */
+#define EVENT_SCAN_ALL_EVENTS	0xf0000000
+#define SURVEILLANCE_TOKEN	9000
+#define SURVEILLANCE_TIMEOUT	1
+#define SURVEILLANCE_SCANRATE	1
+#define LOG_NUMBER		64		/* must be a power of two */
+#define LOG_NUMBER_MASK		(LOG_NUMBER-1)
+
 /* Some RTAS ops require a data buffer and that buffer must be < 4G.
  * Rather than having a memory allocator, just use this buffer
  * (get the lock first), make the RTAS call.  Copy the data instead
  * of holding the buffer for long.
  */
-#define RTAS_DATA_BUF_SIZE 1024
+
+#define RTAS_DATA_BUF_SIZE 4096
 extern spinlock_t rtas_data_buf_lock;
 extern char rtas_data_buf[RTAS_DATA_BUF_SIZE];
 
+/* RMO buffer reserved for user-space RTAS use */
+extern unsigned long rtas_rmo_buf;
+
 #endif /* _PPC64_RTAS_H */
diff -purN linux-2.5/include/asm-ppc64/sigcontext.h linuxppc64-2.5/include/asm-ppc64/sigcontext.h
--- linux-2.5/include/asm-ppc64/sigcontext.h	2003-03-26 03:38:55.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/sigcontext.h	2003-11-19 21:34:28.000000000 +0000
@@ -21,6 +21,27 @@ struct sigcontext {
 	struct pt_regs	*regs;
 	elf_gregset_t	gp_regs;
 	elf_fpregset_t	fp_regs;
+/*
+ * To maintain compatibility with current implementations the sigcontext is 
+ * extended by appending a pointer (v_regs) to a quadword type (elf_vrreg_t) 
+ * followed by an unstructured (vmx_reserve) field of 69 doublewords.  This 
+ * allows the array of vector registers to be quadword aligned independent of 
+ * the alignment of the containing sigcontext or ucontext. It is the 
+ * responsibility of the code setting the sigcontext to set this pointer to 
+ * either NULL (if this processor does not support the VMX feature) or the 
+ * address of the first quadword within the allocated (vmx_reserve) area.
+ *
+ * The pointer (v_regs) of vector type (elf_vrreg_t) is type compatible with 
+ * an array of 34 quadword entries (elf_vrregset_t).  The entries with 
+ * indexes 0-31 contain the corresponding vector registers.  The entry with 
+ * index 32 contains the vscr as the last word (offset 12) within the 
+ * quadword.  This allows the vscr to be stored as either a quadword (since 
+ * it must be copied via a vector register to/from storage) or as a word.  
+ * The entry with index 33 contains the vrsave as the first word (offset 0) 
+ * within the quadword.
+ */
+	elf_vrreg_t	*v_regs;
+	long		vmx_reserve[ELF_NVRREG+ELF_NVRREG+1];
 };
 
 #endif /* _ASM_PPC64_SIGCONTEXT_H */
diff -purN linux-2.5/include/asm-ppc64/smp.h linuxppc64-2.5/include/asm-ppc64/smp.h
--- linux-2.5/include/asm-ppc64/smp.h	2003-08-19 02:46:23.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/smp.h	2003-11-18 09:08:41.000000000 +0000
@@ -22,21 +22,40 @@
 #include <linux/cpumask.h>
 #include <linux/kernel.h>
 
-#ifdef CONFIG_SMP
-
 #ifndef __ASSEMBLY__
 
 #include <asm/paca.h>
 
+#ifdef CONFIG_SMP
+
 extern void smp_message_pass(int target, int msg, unsigned long data, int wait);
 extern void smp_send_tlb_invalidate(int);
 extern void smp_send_xmon_break(int cpu);
 struct pt_regs;
 extern void smp_message_recv(int, struct pt_regs *);
 
-#define cpu_possible(cpu)	paca[cpu].active
 
 #define smp_processor_id() (get_paca()->xPacaIndex)
+#define hard_smp_processor_id() (get_paca()->xHwProcNum)
+
+/*
+ * Retrieve the state of a CPU:
+ * online:          CPU is in a normal run state
+ * possible:        CPU is a candidate to be made online
+ * available:       CPU is candidate for the 'possible' pool
+ *                  Used to get SMT threads started at boot time.
+ * present_at_boot: CPU was available at boot time.  Used in DLPAR
+ *                  code to handle special cases for processor start up.
+ */
+extern cpumask_t cpu_present_at_boot;
+extern cpumask_t cpu_online_map;
+extern cpumask_t cpu_possible_map;
+extern cpumask_t cpu_available_map;
+
+#define cpu_present_at_boot(cpu) cpu_isset(cpu, cpu_present_at_boot)
+#define cpu_online(cpu)          cpu_isset(cpu, cpu_online_map) 
+#define cpu_possible(cpu)        cpu_isset(cpu, cpu_possible_map) 
+#define cpu_available(cpu)       cpu_isset(cpu, cpu_available_map) 
 
 /* Since OpenPIC has only 4 IPIs, we use slightly different message numbers.
  *
@@ -50,7 +69,11 @@ extern void smp_message_recv(int, struct
 void smp_init_iSeries(void);
 void smp_init_pSeries(void);
 
-#endif /* __ASSEMBLY__ */
 #endif /* !(CONFIG_SMP) */
+#endif /* __ASSEMBLY__ */
+
+#define get_hard_smp_processor_id(CPU) (paca[(CPU)].xHwProcNum)
+#define set_hard_smp_processor_id(CPU, VAL) do { (paca[(CPU)].xHwProcNum = VAL); } while (0)
+
 #endif /* !(_PPC64_SMP_H) */
 #endif /* __KERNEL__ */
diff -purN linux-2.5/include/asm-ppc64/spinlock.h linuxppc64-2.5/include/asm-ppc64/spinlock.h
--- linux-2.5/include/asm-ppc64/spinlock.h	2002-09-10 09:50:15.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/spinlock.h	2003-11-14 18:45:32.000000000 +0000
@@ -6,16 +6,27 @@
  *
  * Copyright (C) 2001 Paul Mackerras <paulus@au.ibm.com>, IBM
  * Copyright (C) 2001 Anton Blanchard <anton@au.ibm.com>, IBM
- *
- * Type of int is used as a full 64b word is not necessary.
+ * Copyright (C) 2002 Dave Engebretsen <engebret@us.ibm.com>, IBM
+ *   Rework to support virtual processors
  *
  * This program is free software; you can redistribute it and/or
  * modify it under the terms of the GNU General Public License
  * as published by the Free Software Foundation; either version
  * 2 of the License, or (at your option) any later version.
  */
+
+#include <asm/hvcall.h>
+
+/*
+ * The following define is being used to select basic or shared processor
+ * locking when running on an RPA platform.  As we do more performance
+ * tuning, I would expect this selection mechanism to change.  Dave E. 
+ */
+#define SPLPAR_LOCKS
+#define HVSC			".long 0x44000022\n"
+
 typedef struct {
-	volatile unsigned int lock;
+	volatile unsigned long lock;
 } spinlock_t;
 
 #ifdef __KERNEL__
@@ -25,15 +36,15 @@ typedef struct {
 
 static __inline__ int _raw_spin_trylock(spinlock_t *lock)
 {
-	unsigned int tmp;
+	unsigned long tmp;
 
 	__asm__ __volatile__(
-"1:	lwarx		%0,0,%1		# spin_trylock\n\
-	cmpwi		0,%0,0\n\
+"1:	ldarx		%0,0,%1		# spin_trylock\n\
+	cmpdi		0,%0,0\n\
 	li		%0,0\n\
 	bne-		2f\n\
 	li		%0,1\n\
-	stwcx.		%0,0,%1\n\
+	stdcx.		13,0,%1\n\
 	bne-		1b\n\
 	isync\n\
 2:"	: "=&r"(tmp)
@@ -43,28 +54,115 @@ static __inline__ int _raw_spin_trylock(
 	return tmp;
 }
 
+/*
+ * Spin lock states:
+ *   0        : Unlocked
+ *   Negative : Locked.  Value is paca pointer (0xc...0) of holder
+ */
+#ifdef CONFIG_PPC_ISERIES
+static __inline__ void _raw_spin_lock(spinlock_t *lock)
+{
+	unsigned long tmp, tmp2;
+
+	__asm__ __volatile__(
+	"b		2f		# spin_lock\n\
+1:"
+	HMT_LOW
+"       ldx		%0,0,%2         # load the lock value\n\
+	cmpdi		0,%0,0          # if not locked, try to acquire\n\
+	beq-		2f\n\
+        lwz             5,0x280(%0)     # load yield counter\n\
+        andi.           %1,5,1          # if even then spin\n\
+        beq             1b\n\
+        lwsync                          # if odd, give up cycles\n\
+        ldx             %1,0,%2         # reverify the lock holder\n\
+        cmpd            %0,%1\n\
+        bne             1b              # new holder so restart\n\
+        li              3,0x25          # yield hcall 0x8-12 \n\
+        rotrdi          3,3,1           #   put the bits in the right spot\n\
+        lhz             4,0x18(%0)      # processor number\n\
+        sldi            4,4,32          #   move into top half of word\n\
+        or              5,5,4           # r5 has yield cnt - or it in\n\
+        li              4,2             # yield to processor\n\
+        li              0,-1            # indicate an hcall\n\
+        sc                              # do the hcall \n\
+        b               1b\n\
+2: \n"
+	HMT_MEDIUM
+" 	ldarx		%0,0,%2\n\
+	cmpdi		0,%0,0\n\
+	bne-		1b\n\
+	stdcx.		13,0,%2\n\
+	bne-		2b\n\
+	isync"
+	: "=&r"(tmp), "=&r"(tmp2)
+	: "r"(&lock->lock)
+	: "r0", "r3", "r4", "r5", "ctr", "cr0", "cr1", "cr2", "cr3", "cr4", 
+	  "xer", "memory");
+}
+#else
+#ifdef SPLPAR_LOCKS
 static __inline__ void _raw_spin_lock(spinlock_t *lock)
 {
-	unsigned int tmp;
+	unsigned long tmp, tmp2;
 
 	__asm__ __volatile__(
 	"b		2f		# spin_lock\n\
 1:"
 	HMT_LOW
-"	lwzx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne+		1b\n"
+"       ldx		%0,0,%2         # load the lock value\n\
+	cmpdi		0,%0,0          # if not locked, try to acquire\n\
+	beq-		2f\n\
+        lwz             5,0x280(%0)     # load dispatch counter\n\
+        andi.           %1,5,1          # if even then spin\n\
+        beq             1b\n\
+        lwsync                          # if odd, give up cycles\n\
+        ldx             %1,0,%2         # reverify the lock holder\n\
+        cmpd            %0,%1\n\
+        bne             1b              # new holder so restart\n\
+        li              3,0xE4          # give up the cycles H_CONFER\n\
+        lhz             4,0x18(%0)      # processor number\n\
+                                        # r5 has dispatch cnt already\n"
+	HVSC
+"        b               1b\n\
+2: \n"
 	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
+" 	ldarx		%0,0,%2\n\
+	cmpdi		0,%0,0\n\
 	bne-		1b\n\
-	stwcx.		%2,0,%1\n\
+	stdcx.		13,0,%2\n\
+	bne-		2b\n\
+	isync"
+	: "=&r"(tmp), "=&r"(tmp2)
+	: "r"(&lock->lock)
+	: "r3", "r4", "r5", "cr0", "cr1", "ctr", "xer", "memory");
+}
+#else
+static __inline__ void _raw_spin_lock(spinlock_t *lock)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+       "b		2f		# spin_lock\n\
+1:"
+	HMT_LOW
+"       ldx		%0,0,%1         # load the lock value\n\
+	cmpdi		0,%0,0          # if not locked, try to acquire\n\
+	bne+		1b\n\
+2: \n"
+	HMT_MEDIUM
+" 	ldarx		%0,0,%1\n\
+	cmpdi		0,%0,0\n\
+	bne-		1b\n\
+	stdcx.		13,0,%1\n\
 	bne-		2b\n\
 	isync"
 	: "=&r"(tmp)
-	: "r"(&lock->lock), "r"(1)
+	: "r"(&lock->lock)
 	: "cr0", "memory");
 }
+#endif
+#endif
 
 static __inline__ void _raw_spin_unlock(spinlock_t *lock)
 {
@@ -81,25 +179,35 @@ static __inline__ void _raw_spin_unlock(
  * can "mix" irq-safe locks - any writer needs to get a
  * irq-safe write-lock, but readers can get non-irqsafe
  * read-locks.
+ *
+ * Write lock states:
+ *   0        : Unlocked
+ *   Positive : Reader count
+ *   Negative : Writer locked.  Value is paca pointer (0xc...0) of holder
+ *
+ * If lock is not held, try to acquire.
+ * If lock is held by a writer, confer cycles to the holder.
+ * If lock is help by reader(s), spin.  Need to experiment with confer all
+ *   option.  This is likely a pretty weak optimization and may not be 
+ *   worth the additional path length.
  */
 typedef struct {
-	volatile signed int lock;
+	volatile signed long lock;
 } rwlock_t;
 
 #define RW_LOCK_UNLOCKED (rwlock_t) { 0 }
 
 static __inline__ int _raw_read_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
-	unsigned int ret;
+	unsigned long tmp;
+	unsigned long ret;
 
 	__asm__ __volatile__(
-"1:	lwarx		%0,0,%2		# read_trylock\n\
+"1:	ldarx		%0,0,%2		# read_trylock\n\
 	li		%1,0\n\
-	extsw		%0,%0\n\
 	addic.		%0,%0,1\n\
 	ble-		2f\n\
-	stwcx.		%0,0,%2\n\
+	stdcx.		%0,0,%2\n\
 	bne-		1b\n\
 	li		%1,1\n\
 	isync\n\
@@ -110,39 +218,118 @@ static __inline__ int _raw_read_trylock(
 	return ret;
 }
 
+#ifdef CONFIG_PPC_ISERIES
 static __inline__ void _raw_read_lock(rwlock_t *rw)
 {
-	unsigned int tmp;
+	unsigned long tmp, tmp2;
 
 	__asm__ __volatile__(
 	"b		2f		# read_lock\n\
 1:"
 	HMT_LOW
-"	lwax		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	blt+		1b\n"
+"	ldx		%0,0,%2\n\
+	cmpdi		0,%0,0\n\
+	bge-		2f\n\
+        lwz             5,0x280(%0)     # load yield counter\n\
+        andi.           %1,5,1          # if even then spin\n\
+        beq             1b\n\
+        lwsync                          # if odd, give up cycles\n\
+        ldx             %1,0,%2         # reverify the lock holder\n\
+        cmpd            %0,%1\n\
+        bne             1b              # new holder so restart\n\
+        li              3,0x25          # yield hcall 0x8-12 \n\
+        rotrdi          3,3,1           #   put the bits in the right spot\n\
+        lhz             4,0x18(%0)      # processor number\n\
+        sldi            4,4,32          #   move into top half of word\n\
+        or              5,5,4           # r5 has yield cnt - or it in\n\
+        li              4,2             # yield to processor\n\
+        li              0,-1            # indicate an hcall\n\
+        sc                              # do the hcall \n\
+2: \n"
 	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	extsw		%0,%0\n\
+" 	ldarx		%0,0,%2\n\
 	addic.		%0,%0,1\n\
 	ble-		1b\n\
-	stwcx.		%0,0,%1\n\
+	stdcx.		%0,0,%2\n\
+	bne-		2b\n\
+	isync"
+	: "=&r"(tmp), "=&r"(tmp2)
+	: "r"(&rw->lock)
+	: "r0", "r3", "r4", "r5", "ctr", "cr0", "cr1", "cr2", "cr3", "cr4", 
+	  "xer", "memory");
+}
+#else
+#ifdef SPLPAR_LOCKS
+static __inline__ void _raw_read_lock(rwlock_t *rw)
+{
+	unsigned long tmp, tmp2;
+
+	__asm__ __volatile__(
+	"b		2f		# read_lock\n\
+1:"
+	HMT_LOW
+"	ldx		%0,0,%2\n\
+	cmpdi		0,%0,0\n\
+	bge-		2f\n\
+        lwz             5,0x280(%0)     # load dispatch counter\n\
+        andi.           %1,5,1          # if even then spin\n\
+        beq             1b\n\
+        lwsync                          # if odd, give up cycles\n\
+        ldx             %1,0,%2         # reverify the lock holder\n\
+        cmpd            %0,%1\n\
+        bne             1b              # new holder so restart\n\
+        li              3,0xE4          # give up the cycles H_CONFER\n\
+        lhz             4,0x18(%0)      # processor number\n\
+                                        # r5 has dispatch cnt already\n"
+	HVSC
+"2: \n"
+	HMT_MEDIUM
+" 	ldarx		%0,0,%2\n\
+	addic.		%0,%0,1\n\
+	ble-		1b\n\
+	stdcx.		%0,0,%2\n\
+	bne-		2b\n\
+	isync"
+	: "=&r"(tmp), "=&r"(tmp2)
+	: "r"(&rw->lock)
+	: "r3", "r4", "r5", "cr0", "cr1", "ctr", "xer", "memory");
+}
+#else
+static __inline__ void _raw_read_lock(rwlock_t *rw)
+{
+	unsigned long tmp;
+
+	__asm__ __volatile__(
+	"b		2f		# read_lock\n\
+1:"
+	HMT_LOW
+"	ldx		%0,0,%1\n\
+	cmpdi		0,%0,0\n\
+	blt+		1b\n\
+2: \n"
+	HMT_MEDIUM
+" 	ldarx		%0,0,%1\n\
+	addic.		%0,%0,1\n\
+	ble-		1b\n\
+	stdcx.		%0,0,%1\n\
 	bne-		2b\n\
 	isync"
 	: "=&r"(tmp)
 	: "r"(&rw->lock)
 	: "cr0", "memory");
 }
+#endif
+#endif
 
 static __inline__ void _raw_read_unlock(rwlock_t *rw)
 {
-	unsigned int tmp;
+	unsigned long tmp;
 
 	__asm__ __volatile__(
 	"eieio				# read_unlock\n\
-1:	lwarx		%0,0,%1\n\
+1:	ldarx		%0,0,%1\n\
 	addic		%0,%0,-1\n\
-	stwcx.		%0,0,%1\n\
+	stdcx.		%0,0,%1\n\
 	bne-		1b"
 	: "=&r"(tmp)
 	: "r"(&rw->lock)
@@ -151,15 +338,15 @@ static __inline__ void _raw_read_unlock(
 
 static __inline__ int _raw_write_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
-	unsigned int ret;
+	unsigned long tmp;
+	unsigned long ret;
 
 	__asm__ __volatile__(
-"1:	lwarx		%0,0,%2		# write_trylock\n\
-	cmpwi		0,%0,0\n\
+"1:	ldarx		%0,0,%2		# write_trylock\n\
+	cmpdi		0,%0,0\n\
 	li		%1,0\n\
 	bne-		2f\n\
-	stwcx.		%3,0,%2\n\
+	stdcx.		13,0,%2\n\
 	bne-		1b\n\
 	li		%1,1\n\
 	isync\n\
@@ -170,28 +357,112 @@ static __inline__ int _raw_write_trylock
 	return ret;
 }
 
+#ifdef CONFIG_PPC_ISERIES
+static __inline__ void _raw_write_lock(rwlock_t *rw)
+{
+	unsigned long tmp, tmp2;
+
+	__asm__ __volatile__(
+	"b		2f		# spin_lock\n\
+1:"
+	HMT_LOW
+"       ldx		%0,0,%2         # load the lock value\n\
+	cmpdi		0,%0,0          # if not locked(0), try to acquire\n\
+	beq-		2f\n\
+        bgt             1b              # negative(0xc..)->cycles to holder\n"
+"3:     lwz             5,0x280(%0)     # load yield counter\n\
+        andi.           %1,5,1          # if even then spin\n\
+        beq             1b\n\
+        lwsync                          # if odd, give up cycles\n\
+        ldx             %1,0,%2         # reverify the lock holder\n\
+        cmpd            %0,%1\n\
+        bne             1b              # new holder so restart\n\
+        lhz             4,0x18(%0)      # processor number\n\
+        sldi            4,4,32          #   move into top half of word\n\
+        or              5,5,4           # r5 has yield cnt - or it in\n\
+        li              3,0x25          # yield hcall 0x8-12 \n\
+        rotrdi          3,3,1           #   put the bits in the right spot\n\
+        li              4,2             # yield to processor\n\
+        li              0,-1            # indicate an hcall\n\
+        sc                              # do the hcall \n\
+2: \n"
+	HMT_MEDIUM
+" 	ldarx		%0,0,%2\n\
+	cmpdi		0,%0,0\n\
+	bne-		1b\n\
+	stdcx.		13,0,%2\n\
+	bne-		2b\n\
+	isync"
+	: "=&r"(tmp), "=&r"(tmp2)
+	: "r"(&rw->lock)
+	: "r0", "r3", "r4", "r5", "ctr", "cr0", "cr1", "cr2", "cr3", "cr4", 
+	  "xer", "memory");
+}
+#else
+#ifdef SPLPAR_LOCKS
+static __inline__ void _raw_write_lock(rwlock_t *rw)
+{
+	unsigned long tmp, tmp2;
+
+	__asm__ __volatile__(
+	"b		2f		# spin_lock\n\
+1:"
+	HMT_LOW
+"       ldx		%0,0,%2         # load the lock value\n\
+        li              3,0xE4          # give up the cycles H_CONFER\n\
+	cmpdi		0,%0,0          # if not locked(0), try to acquire\n\
+	beq-		2f\n\
+        blt             3f              # negative(0xc..)->confer to holder\n\
+        b               1b\n"
+"3:      lwz             5,0x280(%0)     # load dispatch counter\n\
+        andi.           %1,5,1          # if even then spin\n\
+        beq             1b\n\
+        lwsync                          # if odd, give up cycles\n\
+        ldx             %1,0,%2         # reverify the lock holder\n\
+        cmpd            %0,%1\n\
+        bne             1b              # new holder so restart\n\
+        lhz             4,0x18(%0)      # processor number\n\
+                                        # r5 has dispatch cnt already\n"
+	HVSC
+"        b               1b\n\
+2: \n"
+	HMT_MEDIUM
+" 	ldarx		%0,0,%2\n\
+	cmpdi		0,%0,0\n\
+	bne-		1b\n\
+	stdcx.		13,0,%2\n\
+	bne-		2b\n\
+	isync"
+	: "=&r"(tmp), "=&r"(tmp2)
+	: "r"(&rw->lock)
+	: "r3", "r4", "r5", "cr0", "cr1", "ctr", "xer", "memory");
+}
+#else
 static __inline__ void _raw_write_lock(rwlock_t *rw)
 {
-	unsigned int tmp;
+	unsigned long tmp;
 
 	__asm__ __volatile__(
-	"b		2f		# write_lock\n\
+	"b		2f		# spin_lock\n\
 1:"
 	HMT_LOW
-	"lwax		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne+		1b\n"
+"       ldx		%0,0,%1         # load the lock value\n\
+	cmpdi		0,%0,0          # if not locked(0), try to acquire\n\
+	bne+		1b\n\
+2: \n"
 	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
+" 	ldarx		%0,0,%1\n\
+	cmpdi		0,%0,0\n\
 	bne-		1b\n\
-	stwcx.		%2,0,%1\n\
+	stdcx.		13,0,%1\n\
 	bne-		2b\n\
 	isync"
 	: "=&r"(tmp)
-	: "r"(&rw->lock), "r"(-1)
+	: "r"(&rw->lock)
 	: "cr0", "memory");
 }
+#endif
+#endif
 
 static __inline__ void _raw_write_unlock(rwlock_t *rw)
 {
@@ -214,7 +485,7 @@ static __inline__ int is_write_locked(rw
 
 #define rwlock_init(x)         do { *(x) = RW_LOCK_UNLOCKED; } while(0)
 
-#define rwlock_is_locked(x)	((x)->lock)
+#define rwlock_is_locked(x) ((x)->lock != 0)
 
 #endif /* __KERNEL__ */
 #endif /* __ASM_SPINLOCK_H */
diff -purN linux-2.5/include/asm-ppc64/system.h linuxppc64-2.5/include/asm-ppc64/system.h
--- linux-2.5/include/asm-ppc64/system.h	2003-06-24 04:58:49.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/system.h	2003-10-22 13:10:35.000000000 +0000
@@ -101,13 +101,6 @@ extern struct task_struct * _switch(stru
 struct pt_regs;
 extern void dump_regs(struct pt_regs *);
 
-#define irqs_disabled()				\
-({						\
-	unsigned long flags;			\
-	local_save_flags(flags);		\
-	!(flags & MSR_EE);			\
-})
-
 static inline int __is_processor(unsigned long pv)
 {
 	unsigned long pvr;
diff -purN linux-2.5/include/asm-ppc64/unistd.h linuxppc64-2.5/include/asm-ppc64/unistd.h
--- linux-2.5/include/asm-ppc64/unistd.h	2003-07-18 23:52:28.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/unistd.h	2003-11-17 18:51:47.000000000 +0000
@@ -264,8 +264,10 @@
 #define __NR_utimes		251
 #define __NR_statfs64		252
 #define __NR_fstatfs64		253
+#define __NR_fadvise64_64	254
+#define __NR_rtas		255
 
-#define __NR_syscalls		254
+#define __NR_syscalls		256
 #ifdef __KERNEL__
 #define NR_syscalls	__NR_syscalls
 #endif
diff -purN linux-2.5/include/asm-ppc64/xics.h linuxppc64-2.5/include/asm-ppc64/xics.h
--- linux-2.5/include/asm-ppc64/xics.h	2003-03-28 06:31:06.000000000 +0000
+++ linuxppc64-2.5/include/asm-ppc64/xics.h	2003-09-12 19:50:40.000000000 +0000
@@ -15,6 +15,7 @@
 #include <linux/cache.h>
 
 void xics_init_IRQ(void);
+void xics_init_irq_desc(irq_desc_t *);
 int xics_get_irq(struct pt_regs *);
 void xics_setup_cpu(void);
 void xics_cause_IPI(int cpu);
diff -purN linux-2.5/include/linux/compat.h linuxppc64-2.5/include/linux/compat.h
--- linux-2.5/include/linux/compat.h	2003-10-05 08:07:51.000000000 +0000
+++ linuxppc64-2.5/include/linux/compat.h	2003-11-21 05:10:27.000000000 +0000
@@ -97,5 +97,10 @@ struct compat_dirent {
 	char		d_name[256];
 };
 
+typedef union compat_sigval {
+	compat_int_t	sival_int;
+	compat_uptr_t	sival_ptr;
+} compat_sigval_t;
+
 #endif /* CONFIG_COMPAT */
 #endif /* _LINUX_COMPAT_H */
diff -purN linux-2.5/include/linux/proc_fs.h linuxppc64-2.5/include/linux/proc_fs.h
--- linux-2.5/include/linux/proc_fs.h	2003-09-13 00:22:02.000000000 +0000
+++ linuxppc64-2.5/include/linux/proc_fs.h	2003-11-18 09:08:41.000000000 +0000
@@ -131,7 +131,9 @@ extern void proc_tty_unregister_driver(s
 /*
  * proc_devtree.c
  */
+struct device_node;
 extern void proc_device_tree_init(void);
+extern void proc_device_tree_add_node(struct device_node *, struct proc_dir_entry *);
 
 /*
  * proc_rtas.c
