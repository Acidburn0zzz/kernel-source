diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/Kconfig linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/Kconfig
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/Kconfig	2004-04-12 17:54:05.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/Kconfig	2004-04-13 17:25:57.000000000 +0000
@@ -89,6 +89,16 @@ config PPC_PMAC
 	bool "Apple PowerMac G5 support"
 	select ADB_PMU
 
+config PPC_SPLPAR
+	depends on PPC_PSERIES
+	bool "Support for shared-processor logical partitions"
+	default n
+	help
+	  Enabling this option will make the kernel run more efficiently
+	  on logically-partitioned pSeries systems which use shared
+	  processors, that is, which share physical processors between
+	  two or more partitions.
+
 config PMAC_DART
 	bool "Enable DART/IOMMU on PowerMac (allow >2G of RAM)"
 	depends on PPC_PMAC
@@ -203,10 +213,21 @@ config SCANLOG
 	depends on PPC_RTAS
 
 config LPARCFG
-	bool "LPAR Configuration Data"
+	tristate "LPAR Configuration Data"
 	help
 	Provide system capacity information via human readable 
 	<key word>=<value> pairs through a /proc/ppc64/lparcfg interface.
+	LPARCFG uses the "Virtual Processor Utilization Values" framework for PURR 
+	support. 
+
+config PPC_VPURR
+	bool "Virtual Processor Utilization Values"
+	default n
+	depends on PPC_PSERIES
+	help
+	Provide framework to collect virtual processor utilization
+	periodically.  This function is used by "LPAR Configuration Data" for PURR support.  
+	If unsure say NO.
 
 endmenu
 
@@ -371,17 +392,46 @@ config DEBUGGER
 	  Include in-kernel hooks for kernel debuggers. Unless you are
 	  intending to debug the kernel, say N here.
 
-config XMON
-	bool "Include xmon kernel debugger"
+choice
+	optional
 	depends on DEBUGGER
+	prompt "Kernel Debugger"
+
+config XMON
+	bool "XMON"
 	help
 	  Include in-kernel hooks for the xmon kernel monitor/debugger.
 	  Unless you are intending to debug the kernel, say N here.
 
+config KDB
+	bool "KDB"
+	help
+	  Include in-kernel hooks for the kdb kernel monitor/debugger.
+	  Unless you are intending to debug the kernel, say N here.
+
+config KDB_MODULES
+	bool "Enable additional KDB modules"
+	depends on KDB
+	help
+	  Include additional KDB support for viewing buffer heads,
+	  pages, inodes, dentrys, vm areas and scsi devices and
+	  scsi commands.
+
+endchoice
+
+
 config XMON_DEFAULT
 	bool "Enable xmon by default"
 	depends on XMON
 
+config KDB_OFF
+	bool "Turn KDB off as default."
+	depends on KDB
+
+	help
+ 	   KDB will remain built into the kernel, but will be turned off. 
+	   "cat 1 > /proc/sys/kernel/kdb" to turn it on. 
+
 config PPCDBG
 	bool "Include PPCDBG realtime debugging"
 	depends on DEBUG_KERNEL
@@ -394,6 +444,13 @@ config DEBUG_INFO
 	  debugging info resulting in a larger kernel image.
 	  Say Y here only if you plan to use gdb to debug the kernel.
 	  If you don't debug the kernel, you can say N.
+
+config DEBUG_SPINLOCK_SLEEP
+	bool "Sleep-inside-spinlock checking"
+	depends on DEBUG_KERNEL
+	help
+	  If you say Y here, various routines which may sleep will become very
+	  noisy if they are called with a spinlock held.
 	  
 endmenu
 
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/LparData.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/LparData.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/LparData.c	2004-01-19 06:28:30.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/LparData.c	2004-04-16 23:30:39.000000000 +0000
@@ -10,6 +10,7 @@
 #include <asm/page.h>
 #include <stddef.h>
 #include <linux/threads.h>
+#include <linux/module.h>
 #include <asm/processor.h>
 #include <asm/ptrace.h>
 #include <asm/naca.h>
@@ -123,12 +124,14 @@ struct ItLpNaca itLpNaca = {
 		(u64)InstructionAccessSLB_Iseries /* 0x480 I-SLB */
 	}
 };
+EXPORT_SYMBOL(itLpNaca);
 
 /* May be filled in by the hypervisor so cannot end up in the BSS */
 struct ItIplParmsReal xItIplParmsReal __attribute__((__section__(".data"))); 
 
 /* May be filled in by the hypervisor so cannot end up in the BSS */
 struct ItExtVpdPanel xItExtVpdPanel __attribute__((__section__(".data")));
+EXPORT_SYMBOL(xItExtVpdPanel);
 
 #define maxPhysicalProcessors 32
 
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/Makefile linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/Makefile
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/Makefile	2004-04-12 17:54:10.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/Makefile	2004-04-13 17:25:58.000000000 +0000
@@ -44,6 +44,7 @@ obj-$(CONFIG_PPC_RTAS)		+= rtas-proc.o
 obj-$(CONFIG_SCANLOG)		+= scanlog.o
 obj-$(CONFIG_VIOPATH)		+= viopath.o
 obj-$(CONFIG_LPARCFG)		+= lparcfg.o
+obj-$(CONFIG_PPC_VPURR)		+= vpurr.o
 obj-$(CONFIG_HVC_CONSOLE)	+= hvconsole.o
 obj-$(CONFIG_BOOTX_TEXT)	+= btext.o
 
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/btext.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/btext.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/btext.c	2004-02-12 03:47:48.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/btext.c	2004-04-24 05:30:52.000000000 +0000
@@ -47,8 +47,6 @@ int force_printk_to_btext = 0;
 
 boot_infos_t disp_bi;
 
-extern char *klimit;
-
 /* This function will enable the early boot text when doing OF booting. This
  * way, xmon output should work too
  */
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/chrp_setup.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/chrp_setup.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/chrp_setup.c	2004-04-12 17:54:06.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/chrp_setup.c	2004-04-24 05:42:08.000000000 +0000
@@ -31,7 +31,6 @@
 #include <linux/interrupt.h>
 #include <linux/reboot.h>
 #include <linux/init.h>
-#include <linux/initrd.h>
 #include <linux/ioport.h>
 #include <linux/console.h>
 #include <linux/pci.h>
@@ -136,15 +135,10 @@ chrp_setup_arch(void)
 	/* init to some ~sane value until calibrate_delay() runs */
 	loops_per_jiffy = 50000000;
 
-#ifdef CONFIG_BLK_DEV_INITRD
-	/* this is fine for chrp */
-	initrd_below_start_ok = 1;
-	
-	if (initrd_start)
-		ROOT_DEV = Root_RAM0;
-	else
-#endif
-	ROOT_DEV = Root_SDA2;
+ 	if (ROOT_DEV == 0) {
+ 		printk("No ramdisk, default root is /dev/sda2\n");
+ 		ROOT_DEV = Root_SDA2;
+ 	}
 
 	printk("Boot arguments: %s\n", cmd_line);
 
@@ -239,17 +233,6 @@ chrp_init(unsigned long r3, unsigned lon
 	char * hypertas;
 	unsigned int len;
 
-#if 0 /* PPPBBB remove this later... -Peter */
-#ifdef CONFIG_BLK_DEV_INITRD
-	/* take care of initrd if we have one */
-	if ( r6 )
-	{
-		initrd_start = __va(r6);
-		initrd_end = __va(r6 + r7);
-	}
-#endif /* CONFIG_BLK_DEV_INITRD */
-#endif
-
 	ppc_md.setup_arch     = chrp_setup_arch;
 	ppc_md.get_cpuinfo    = chrp_get_cpuinfo;
 	if (naca->interrupt_controller == IC_OPEN_PIC) {
@@ -280,8 +263,13 @@ chrp_init(unsigned long r3, unsigned lon
          * using contents of device-tree/ibm,hypertas-functions.
          * Ultimately this functionality may be moved into prom.c prom_init().
          */
-	dn = of_find_node_by_path("/rtas");
 	cur_cpu_spec->firmware_features = 0;
+	dn = of_find_node_by_path("/rtas");
+	if (dn == NULL) {
+		printk(KERN_ERR "WARNING ! Cannot find RTAS in device-tree !\n");
+		goto no_rtas;
+	}
+
 	hypertas = get_property(dn, "ibm,hypertas-functions", &len);
 	if (hypertas) {
 		while (len > 0){
@@ -303,6 +291,7 @@ chrp_init(unsigned long r3, unsigned lon
 	}
 
 	of_node_put(dn);
+ no_rtas:
 	printk(KERN_INFO "firmware_features = 0x%lx\n", 
 	       cur_cpu_spec->firmware_features);
 }
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/eeh.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/eeh.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/eeh.c	2004-04-12 17:54:04.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/eeh.c	2004-04-23 03:44:47.000000000 +0000
@@ -49,6 +49,25 @@ static int eeh_subsystem_enabled;
 #define EEH_MAX_OPTS 4096
 static char *eeh_opts;
 static int eeh_opts_last;
+static int eeh_error_buf_size;
+
+/* Buffer for reporting slot-error-detail rtas calls */
+static unsigned char slot_errbuf[RTAS_ERROR_LOG_MAX];
+
+/* Workqueue data for EEH event device removal */
+struct eeh_event {
+	struct list_head	list;
+	struct pci_dev		*dev;
+	struct device_node	*dn;
+	unsigned long		reset_state;
+};
+
+static spinlock_t eeh_eventlist_lock = SPIN_LOCK_UNLOCKED;
+LIST_HEAD(eeh_eventlist);
+static void eeh_event_handler(void *);
+DECLARE_WORK(eeh_event_wq, eeh_event_handler, NULL);
+
+int (*eeh_disable_slot)(struct pci_dev *) = NULL;
 
 /* System monitoring statistics */
 static DEFINE_PER_CPU(unsigned long, total_mmio_ffs);
@@ -347,6 +366,89 @@ static unsigned long eeh_token_to_phys(u
 }
 
 /**
+ * eeh_panic - call panic() for an eeh event that cannot be handled
+ * @dev pci device that had an eeh event
+ * @reset_state current reset state of the device slot
+ */
+static void eeh_panic(struct pci_dev *dev, unsigned long reset_state)
+{
+	/*
+	 * XXX We should create a seperate sysctl for this.
+	 *
+	 * Since the panic_on_oops sysctl is used to halt the system
+	 * in light of potential corruption, we can use it here.
+	 */
+	if (panic_on_oops)
+		panic("EEH: MMIO failure (%ld) on device:%s %s\n", reset_state,
+		      pci_name(dev), pci_pretty_name(dev));
+	else {
+		__get_cpu_var(ignored_failures)++;
+		printk(KERN_INFO "EEH: MMIO failure (%ld) on device:%s %s\n",
+		       reset_state, pci_name(dev), pci_pretty_name(dev));
+	}
+}
+
+/**
+ * eeh_register_disable_func - allows the rpaphp module to let us know
+ *				they're there.
+ * @func - pointer to rpaphp disable slot routine
+ */
+void eeh_register_disable_func(int (*func)(struct pci_dev *))
+{
+	eeh_disable_slot = func;
+}
+EXPORT_SYMBOL(eeh_register_disable_func);
+
+/**
+ * eeh_event_handler - handle any eeh events to see if we can disable
+ *		       the device
+ * @dummy - unused
+ */
+static void eeh_event_handler(void *dummy)
+{
+	struct list_head	*tmp, *n;
+	struct eeh_event	*event;
+	unsigned long		log_event;
+	int			rc;
+
+	spin_lock(&eeh_eventlist_lock);
+
+	memset(slot_errbuf, 0, eeh_error_buf_size);
+
+	list_for_each_safe(tmp, n, &eeh_eventlist) {
+		event = list_entry(tmp, struct eeh_event, list);
+		rc = 1;
+
+		log_event = rtas_call(rtas_token("ibm,slot-error-detail"), 8, 1, NULL,
+				      event->dn->eeh_config_addr,
+				      BUID_HI(event->dn->phb->buid),
+				      BUID_LO(event->dn->phb->buid), NULL, 0,
+				      virt_to_phys(slot_errbuf), eeh_error_buf_size,
+				      2 /* Permanent Error */);
+		if (log_event)
+			log_error(slot_errbuf, ERR_TYPE_RTAS_LOG, 0);
+
+		if (strcmp(event->dn->name, "ethernet") == 0) {
+			if (eeh_disable_slot != NULL)
+				rc = eeh_disable_slot(event->dev);
+		}
+
+		if (rc != 0)
+			eeh_panic(event->dev, event->reset_state);
+		else
+			printk(KERN_INFO "EEH: MMIO failure (%ld) has caused device "
+				"%s %s to be removed\n", event->reset_state,
+				pci_name(event->dev), pci_pretty_name(event->dev));
+
+		pci_dev_put(event->dev);
+		list_del(&event->list);
+		kfree(event);
+	}
+
+	spin_unlock(&eeh_eventlist_lock);
+}
+
+/**
  * eeh_check_failure - check if all 1's data is due to EEH slot freeze
  * @token i/o token, should be address in the form 0xA....
  * @val value, should be all 1's (XXX why do we need this arg??)
@@ -366,10 +468,6 @@ unsigned long eeh_check_failure(void *to
 	struct pci_dev *dev;
 	struct device_node *dn;
 	unsigned long ret, rets[2];
-	static spinlock_t lock = SPIN_LOCK_UNLOCKED;
-	/* dont want this on the stack */
-	static unsigned char slot_err_buf[RTAS_ERROR_LOG_MAX];
-	unsigned long flags;
 
 	__get_cpu_var(total_mmio_ffs)++;
 
@@ -383,28 +481,20 @@ unsigned long eeh_check_failure(void *to
 		return val;
 
 	dn = pci_device_to_OF_node(dev);
-	if (!dn) {
-		pci_dev_put(dev);
-		return val;
-	}
+	if (!dn) 
+		goto ok_return;
 
 	/* Access to IO BARs might get this far and still not want checking. */
 	if (!(dn->eeh_mode & EEH_MODE_SUPPORTED) ||
-	    dn->eeh_mode & EEH_MODE_NOCHECK) {
-		pci_dev_put(dev);
-		return val;
-	}
+	    dn->eeh_mode & EEH_MODE_NOCHECK) 
+		goto ok_return;
 
         /* Make sure we aren't ISA */
-        if (!strcmp(dn->type, "isa")) {
-                pci_dev_put(dev);
-                return val;
-        }
+        if (!strcmp(dn->type, "isa")) 
+                goto ok_return;
 
-	if (!dn->eeh_config_addr) {
-		pci_dev_put(dev);
-		return val;
-	}
+	if (!dn->eeh_config_addr) 
+		goto ok_return;
 
 	/*
 	 * Now test for an EEH failure.  This is VERY expensive.
@@ -418,43 +508,31 @@ unsigned long eeh_check_failure(void *to
 			BUID_LO(dn->phb->buid));
 
 	if (ret == 0 && rets[1] == 1 && rets[0] >= 2) {
-		unsigned long slot_err_ret;
+		struct eeh_event 	*event;
 
-		spin_lock_irqsave(&lock, flags);
-		memset(slot_err_buf, 0, RTAS_ERROR_LOG_MAX);
-		slot_err_ret = rtas_call(rtas_token("ibm,slot-error-detail"),
-					 8, 1, NULL, dn->eeh_config_addr,
-					 BUID_HI(dn->phb->buid),
-					 BUID_LO(dn->phb->buid), NULL, 0,
-					 __pa(slot_err_buf),
-					 RTAS_ERROR_LOG_MAX,
-					 2 /* Permanent Error */);
-
-		if (slot_err_ret == 0)
-			log_error(slot_err_buf, ERR_TYPE_RTAS_LOG,
-				  1 /* Fatal */);
-
-		spin_unlock_irqrestore(&lock, flags);
-
-		/*
-		 * XXX We should create a separate sysctl for this.
-		 *
-		 * Since the panic_on_oops sysctl is used to halt
-		 * the system in light of potential corruption, we
-		 * can use it here.
-		 */
-		if (panic_on_oops) {
-			panic("EEH: MMIO failure (%ld) on device:%s %s\n",
-			      rets[0], pci_name(dev), pci_pretty_name(dev));
-		} else {
-			__get_cpu_var(ignored_failures)++;
-			printk(KERN_INFO "EEH: MMIO failure (%ld) on device:%s %s\n",
-			       rets[0], pci_name(dev), pci_pretty_name(dev));
+		/* prevent repeated reports of this failure */
+		dn->eeh_mode |= EEH_MODE_NOCHECK;
+
+		event = kmalloc(sizeof(*event), GFP_ATOMIC);
+		if (event == NULL) {
+			eeh_panic(dev, rets[0]);
+			goto ok_return;
 		}
+
+		event->dev = dev;
+		event->dn = dn;
+		event->reset_state = rets[0];
+
+		spin_lock(&eeh_eventlist_lock);
+		list_add(&event->list, &eeh_eventlist);
+		spin_unlock(&eeh_eventlist_lock);
+
+		schedule_work(&eeh_event_wq);
 	} else {
 		__get_cpu_var(false_positives)++;
 	}
 
+ok_return:
 	pci_dev_put(dev);
 	return val;
 }
@@ -568,10 +646,28 @@ static void *early_enable_eeh(struct dev
  */
 void __init eeh_init(void)
 {
-	struct device_node *phb;
+	struct device_node *phb, *np;
 	struct eeh_early_enable_info info;
+	u32 *prop;
 	char *eeh_force_off = strstr(saved_command_line, "eeh-force-off");
 
+	np = of_find_node_by_path("/rtas");
+	if (np == NULL) {
+		printk(KERN_WARNING "EEH: RTAS not found !\n");
+		return;
+	}
+	prop = (u32 *)get_property(np, "rtas-error-log-max", NULL);
+	if (prop == NULL) {
+		printk(KERN_WARNING "EEH: Can't fint rtas-error-log-max !\n");
+		eeh_error_buf_size = 1024;
+	} else
+		eeh_error_buf_size = (int)*prop;
+	if (eeh_error_buf_size > RTAS_ERROR_LOG_MAX) {
+		printk(KERN_WARNING "EEH: rtas-error-log-max is bigger than allocated "
+		       "buffer ! (%d vs %d)", eeh_error_buf_size, RTAS_ERROR_LOG_MAX);
+		eeh_error_buf_size = RTAS_ERROR_LOG_MAX;
+	}
+
 	ibm_set_eeh_option = rtas_token("ibm,set-eeh-option");
 	ibm_set_slot_reset = rtas_token("ibm,set-slot-reset");
 	ibm_read_slot_reset_state = rtas_token("ibm,read-slot-reset-state");
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/iSeries_setup.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/iSeries_setup.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/iSeries_setup.c	2004-03-30 15:45:59.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/iSeries_setup.c	2004-04-01 02:08:56.000000000 +0000
@@ -298,7 +298,6 @@ void __init iSeries_init_early(void)
 		initrd_start = (unsigned long)__va(naca->xRamDisk);
 		initrd_end = initrd_start + naca->xRamDiskSize * PAGE_SIZE;
 		initrd_below_start_ok = 1;	// ramdisk in kernel space
-		ROOT_DEV = Root_RAM0;
 		if (((rd_size * 1024) / PAGE_SIZE) < naca->xRamDiskSize)
 			rd_size = (naca->xRamDiskSize * PAGE_SIZE) / 1024;
 	} else
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/lparcfg.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/lparcfg.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/lparcfg.c	2004-02-27 05:33:08.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/lparcfg.c	2004-04-23 19:03:50.000000000 +0000
@@ -5,6 +5,7 @@
  *    Copyright (c) 2003 Dave Engebretsen
  * Will Schmidt willschm@us.ibm.com
  *    SPLPAR updates, Copyright (c) 2003 Will Schmidt IBM Corporation.
+ *    seq_file updates, Copyright (c) 2004 Will Schmidt IBM Corporation.
  * Nathan Lynch nathanl@austin.ibm.com
  *    Added lparcfg_write, Copyright (C) 2004 Nathan Lynch IBM Corporation.
  *
@@ -23,15 +24,40 @@
 #include <linux/errno.h>
 #include <linux/proc_fs.h>
 #include <linux/init.h>
+#include <linux/seq_file.h>
 #include <asm/uaccess.h>
 #include <asm/iSeries/HvLpConfig.h>
 #include <asm/iSeries/ItLpPaca.h>
+#include <asm/iSeries/LparData.h>
 #include <asm/hvcall.h>
 #include <asm/cputable.h>
+#include "vpurr.h"
 
-#define MODULE_VERS "1.0"
+#define MODULE_VERS "1.2"
 #define MODULE_NAME "lparcfg"
 
+/* #define LPARCFG_DEBUG */
+
+/* find a better place for this function... */
+void log_plpar_hcall_return(unsigned long rc,char * tag)
+{
+	if (rc==0) /* success, return */
+		return;
+/* check for null tag ? */
+	if (rc == H_Hardware)
+		printk(KERN_INFO "plpar-hcall (%s) failed with hardware fault\n",tag);
+	else if (rc == H_Function)
+		printk(KERN_INFO "plpar-hcall (%s) failed; function not allowed\n",tag);
+	else if (rc == H_Authority)
+		printk(KERN_INFO "plpar-hcall (%s) failed; not authorized to this function\n",tag);
+	else if (rc == H_Parameter)
+		printk(KERN_INFO "plpar-hcall (%s) failed; Bad parameter(s)\n",tag);
+	else
+		printk(KERN_INFO "plpar-hcall (%s) failed with unexpected rc(0x%lx)\n",tag,rc);
+
+}
+
+
 static struct proc_dir_entry *proc_ppc64_lparcfg;
 #define LPARCFG_BUFF_SIZE 4096
 
@@ -39,103 +65,20 @@ static struct proc_dir_entry *proc_ppc64
 
 #define lparcfg_write NULL
 
-static unsigned char e2a(unsigned char x)
-{
-        switch (x) {
-        case 0xF0:
-                return '0';
-        case 0xF1:
-                return '1';
-        case 0xF2:
-                return '2';
-        case 0xF3:
-                return '3';
-        case 0xF4:
-                return '4';
-        case 0xF5:
-                return '5';
-        case 0xF6:
-                return '6';
-        case 0xF7:
-                return '7';
-        case 0xF8:
-                return '8';
-        case 0xF9:
-                return '9';
-        case 0xC1:
-                return 'A';
-        case 0xC2:
-                return 'B';
-        case 0xC3:
-                return 'C';
-        case 0xC4:
-                return 'D';
-        case 0xC5:
-                return 'E';
-        case 0xC6:
-                return 'F';
-        case 0xC7:
-                return 'G';
-        case 0xC8:
-                return 'H';
-        case 0xC9:
-                return 'I';
-        case 0xD1:
-                return 'J';
-        case 0xD2:
-                return 'K';
-        case 0xD3:
-                return 'L';
-        case 0xD4:
-                return 'M';
-        case 0xD5:
-                return 'N';
-        case 0xD6:
-                return 'O';
-        case 0xD7:
-                return 'P';
-        case 0xD8:
-                return 'Q';
-        case 0xD9:
-                return 'R';
-        case 0xE2:
-                return 'S';
-        case 0xE3:
-                return 'T';
-        case 0xE4:
-                return 'U';
-        case 0xE5:
-                return 'V';
-        case 0xE6:
-                return 'W';
-        case 0xE7:
-                return 'X';
-        case 0xE8:
-                return 'Y';
-        case 0xE9:
-                return 'Z';
-        }
-        return ' ';
-}
+extern unsigned char e2a(unsigned char);
 
 /* 
  * Methods used to fetch LPAR data when running on an iSeries platform.
  */
-static int lparcfg_data(unsigned char *buf, unsigned long size)
+static int lparcfg_data(struct seq_file *m,void *v)
 {
-	unsigned long n = 0, pool_id, lp_index; 
+	unsigned long pool_id, lp_index; 
 	int shared, entitled_capacity, max_entitled_capacity;
 	int processors, max_processors;
 	struct paca_struct *lpaca = get_paca();
 
-	if((buf == NULL) || (size > LPARCFG_BUFF_SIZE)) {
-		return -EFAULT;
-	}
-	memset(buf, 0, size); 
-
 	shared = (int)(lpaca->xLpPacaPtr->xSharedProc);
-	n += scnprintf(buf, LPARCFG_BUFF_SIZE - n,
-		      "serial_number=%c%c%c%c%c%c%c\n", 
+	seq_printf(m, "serial_number=%c%c%c%c%c%c%c\n", 
 		      e2a(xItExtVpdPanel.mfgID[2]),
 		      e2a(xItExtVpdPanel.mfgID[3]),
 		      e2a(xItExtVpdPanel.systemSerial[1]),
@@ -144,32 +87,26 @@ static int lparcfg_data(unsigned char *b
 		      e2a(xItExtVpdPanel.systemSerial[4]),
 		      e2a(xItExtVpdPanel.systemSerial[5])); 
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "system_type=%c%c%c%c\n",
+	seq_printf(m, "system_type=%c%c%c%c\n",
 		      e2a(xItExtVpdPanel.machineType[0]),
 		      e2a(xItExtVpdPanel.machineType[1]),
 		      e2a(xItExtVpdPanel.machineType[2]),
 		      e2a(xItExtVpdPanel.machineType[3])); 
 
 	lp_index = HvLpConfig_getLpIndex(); 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_id=%d\n", (int)lp_index); 
+	seq_printf(m, "partition_id=%d\n", (int)lp_index); 
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "system_active_processors=%d\n", 
+	seq_printf(m, "system_active_processors=%d\n", 
 		      (int)HvLpConfig_getSystemPhysicalProcessors()); 
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "system_potential_processors=%d\n", 
+	seq_printf(m, "system_potential_processors=%d\n", 
 		      (int)HvLpConfig_getSystemPhysicalProcessors()); 
 
 	processors = (int)HvLpConfig_getPhysicalProcessors(); 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_active_processors=%d\n", processors);  
+	seq_printf(m, "partition_active_processors=%d\n", processors);  
 
 	max_processors = (int)HvLpConfig_getMaxPhysicalProcessors(); 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_potential_processors=%d\n", max_processors);  
+	seq_printf(m, "partition_potential_processors=%d\n", max_processors);  
 
 	if(shared) {
 		entitled_capacity = HvLpConfig_getSharedProcUnits(); 
@@ -178,23 +115,18 @@ static int lparcfg_data(unsigned char *b
 		entitled_capacity = processors * 100; 
 		max_entitled_capacity = max_processors * 100; 
 	}
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_entitled_capacity=%d\n", entitled_capacity);
+	seq_printf(m, "partition_entitled_capacity=%d\n", entitled_capacity);
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_max_entitled_capacity=%d\n", 
+	seq_printf(m, "partition_max_entitled_capacity=%d\n", 
 		      max_entitled_capacity);
 
 	if(shared) {
 		pool_id = HvLpConfig_getSharedPoolIndex(); 
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n, "pool=%d\n",
-			      (int)pool_id); 
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "pool_capacity=%d\n", (int)(HvLpConfig_getNumProcsInSharedPool(pool_id)*100)); 
+		seq_printf(m, "pool=%d\n", (int)pool_id); 
+		seq_printf(m, "pool_capacity=%d\n", (int)(HvLpConfig_getNumProcsInSharedPool(pool_id)*100)); 
 	}
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "shared_processor_mode=%d\n", shared);
+	seq_printf(m, "shared_processor_mode=%d\n", shared);
 
 	return 0;
 }
@@ -217,7 +149,7 @@ static int lparcfg_data(unsigned char *b
  *          XXXX - reserved (0)
  *              XXXX - Group Number
  *                  XXXX - Pool Number.
- *  R7 (PPOONNMMLLKKJJII)
+ *  R7 (IIJJKKLLMMNNOOPP).
  *      XX - reserved. (0)
  *        XX - bit 0-6 reserved (0).   bit 7 is Capped indicator.
  *          XX - variable processor Capacity Weight
@@ -225,168 +157,259 @@ static int lparcfg_data(unsigned char *b
  *              XXXX - Active processors in Physical Processor Pool.
  *                  XXXX  - Processors active on platform. 
  */
-unsigned int h_get_ppp(unsigned long *entitled,unsigned long  *unallocated,unsigned long *aggregation,unsigned long *resource)
+static unsigned int h_get_ppp(unsigned long *entitled,unsigned long  *unallocated,unsigned long *aggregation,unsigned long *resource)
 {
 	unsigned long rc;
 	rc = plpar_hcall_4out(H_GET_PPP,0,0,0,0,entitled,unallocated,aggregation,resource);
-	return 0;
+
+	log_plpar_hcall_return(rc,"H_GET_PPP");
+
+	return rc;
+}
+
+static void h_pic(unsigned long *pool_idle_time,unsigned long *num_procs)
+{
+	unsigned long rc;
+	unsigned long dummy;
+	rc = plpar_hcall(H_PIC,0,0,0,0,pool_idle_time,num_procs,&dummy);
+
+	log_plpar_hcall_return(rc,"H_PIC");
+}
+
+static unsigned long get_purr(void);
+/* get sum of purr across all processors.  if PPC_VPURR is not enabled, return zero. */
+/* this utilizes the existing functionality from vpurr.c */
+static unsigned long get_purr()
+{
+	unsigned long sum_purr=0;
+#ifdef CONFIG_PPC_VPURR	
+	int cpu;
+	struct cpu_util_store * cus;
+
+	for_each_online_cpu(cpu){
+		cus =   &per_cpu (cpu_util_sampler, cpu);
+		sum_purr += cus->current_purr;
+#ifdef PURR_DEBUG
+	printk(KERN_INFO "get_purr for cpu (%x) has value (%lx) \n",cpu,cus->current_purr);
+#endif
+                }
+#endif
+	return sum_purr;
 }
 
-/*
- * get_splpar_potential_characteristics().
- * Retrieve the potential_processors and max_entitled_capacity values
- * through the get-system-parameter rtas call.
- */
 #define SPLPAR_CHARACTERISTICS_TOKEN 20
 #define SPLPAR_MAXLENGTH 1026*(sizeof(char))
-unsigned int get_splpar_potential_characteristics(void)
+
+/*
+ * parse_system_parameter_string()
+ * Retrieve the potential_processors, max_entitled_capacity and friends 
+ * through the get-system-parameter rtas call.  Replace keyword strings as
+ * necessary.
+ */
+static void parse_system_parameter_string(struct seq_file *m)
 {
-	/* return 0 for now.  Underlying rtas functionality is not yet complete. 12/01/2003*/
-	return 0; 
-#if 0 
 	long call_status;
 	unsigned long ret[2];
 
-	char * buffer = kmalloc(SPLPAR_MAXLENGTH, GFP_KERNEL);
-
-	printk("token for ibm,get-system-parameter (0x%x)\n",rtas_token("ibm,get-system-parameter"));
+	char * local_buffer = kmalloc(SPLPAR_MAXLENGTH, GFP_KERNEL);
+	if (!local_buffer) {
+		printk(KERN_ERR "%s %s kmalloc failure at line %d \n",__FILE__,__FUNCTION__,__LINE__);
+		return;
+	}
 
+	spin_lock(&rtas_data_buf_lock);
+	memset(rtas_data_buf, 0, SPLPAR_MAXLENGTH); 
 	call_status = rtas_call(rtas_token("ibm,get-system-parameter"), 3, 1,
 				NULL,
 				SPLPAR_CHARACTERISTICS_TOKEN,
-				&buffer,
+				__pa(rtas_data_buf),
 				SPLPAR_MAXLENGTH,
 				(void *)&ret);
+	memcpy(local_buffer,rtas_data_buf, SPLPAR_MAXLENGTH);
+	spin_unlock(&rtas_data_buf_lock);
 
 	if (call_status!=0) {
-		printk("Error calling get-system-parameter (0x%lx)\n",call_status);
-		kfree(buffer);
-		return -1;
+		printk(KERN_INFO "%s %s Error calling get-system-parameter (0x%lx)\n",__FILE__,__FUNCTION__,call_status);
 	} else {
-		printk("get-system-parameter (%s)\n",buffer);
-		kfree(buffer);
-		/* TODO: Add code here to parse out value for system_potential_processors and partition_max_entitled_capacity */
-		return 1;
+		int splpar_strlen;
+		int idx,w_idx;
+		char * workbuffer = kmalloc(SPLPAR_MAXLENGTH, GFP_KERNEL);
+		if (!workbuffer) {
+			printk(KERN_ERR "%s %s kmalloc failure at line %d \n",__FILE__,__FUNCTION__,__LINE__);
+			return;
+		}
+
+#ifdef LPARCFG_DEBUG
+		printk(KERN_INFO "success calling get-system-parameter \n");
+#endif
+		splpar_strlen=local_buffer[0]*16+local_buffer[1];
+		local_buffer+=2; /* step over strlen value */
+
+		memset(workbuffer, 0, SPLPAR_MAXLENGTH);
+		w_idx=0; idx=0;
+		while ((*local_buffer) && (idx<splpar_strlen)) {
+			workbuffer[w_idx++]=local_buffer[idx++];
+			if ((local_buffer[idx]==',')||(local_buffer[idx]=='\0')) {
+				workbuffer[w_idx]='\0';
+				if (w_idx) /* avoid the empty string */
+				{
+					seq_printf(m, "%s\n",workbuffer);
+				}
+				memset(workbuffer, 0, SPLPAR_MAXLENGTH);
+				idx++; /* skip the comma */
+				w_idx=0;
+			} else if (local_buffer[idx]=='=') {
+				/* code here to replace workbuffer contents
+				 with different keyword strings */
+				if (0==strcmp(workbuffer,"MaxEntCap")) {
+					strcpy(workbuffer,"partition_max_entitled_capacity\0");
+					w_idx=strlen(workbuffer);
+				}
+				if (0==strcmp(workbuffer,"MaxPlatProcs")) {
+					strcpy(workbuffer,"system_potential_processors\0");
+					w_idx=strlen(workbuffer);
+				}
+			}
+		}
+		kfree(workbuffer);
+		local_buffer-=2; /* back up over strlen value */
 	}
+	kfree(local_buffer);
+	return;
+}
+
+static int lparcfg_count_active_processors(void);
+
+static int lparcfg_count_active_processors()
+{
+	struct device_node *cpus_dn = NULL;
+	int count=0;
+	for (cpus_dn = of_find_node_by_type(NULL, "cpu");
+		cpus_dn;
+		cpus_dn = of_find_node_by_type(cpus_dn, "cpu")) {
+#ifdef LPARCFG_DEBUG
+		printk(KERN_ERR "cpus_dn %p \n",cpus_dn);
 #endif
+		count++;
+		}
+	of_node_put(cpus_dn);
+	return count;
 }
 
-static int lparcfg_data(unsigned char *buf, unsigned long size)
+static int lparcfg_data(struct seq_file *m, void *v)
 {
-	unsigned long n = 0;
-	int shared, max_entitled_capacity;
-	int processors, system_active_processors, system_potential_processors;
-	struct device_node *root;
+	int system_active_processors;
+	struct device_node *rootdn;
 	const char *model = "";
 	const char *system_id = "";
 	unsigned int *lp_index_ptr, lp_index = 0;
 	struct device_node *rtas_node;
-	int *ip;
-	unsigned long h_entitled,h_unallocated,h_aggregation,h_resource;
+	int *lrdrp;
 
-	if((buf == NULL) || (size > LPARCFG_BUFF_SIZE)) {
-		return -EFAULT;
+	rootdn = find_path_device("/");
+	if (rootdn) {
+		model = get_property(rootdn, "model", NULL);
+		system_id = get_property(rootdn, "system-id", NULL);
+		lp_index_ptr = (unsigned int *)get_property(rootdn, "ibm,partition-no", NULL);
+		if (lp_index_ptr) lp_index = *lp_index_ptr;
 	}
-	memset(buf, 0, size); 
 
-	root = find_path_device("/");
-	if (root) {
-		model = get_property(root, "model", NULL);
-		system_id = get_property(root, "system-id", NULL);
-		lp_index_ptr = (unsigned int *)get_property(root, "ibm,partition-no", NULL);
-		if(lp_index_ptr) lp_index = *lp_index_ptr;
-	}
 
-	n  = scnprintf(buf, LPARCFG_BUFF_SIZE - n,
-		      "serial_number=%s\n", system_id); 
+	seq_printf(m,"%s %s \n",MODULE_NAME,MODULE_VERS);
+
+	seq_printf(m,"serial_number=%s\n", system_id); 
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "system_type=%s\n", model); 
+	seq_printf(m,"system_type=%s\n", model); 
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_id=%d\n", (int)lp_index); 
+	seq_printf(m,"partition_id=%d\n", (int)lp_index); 
 
 	rtas_node = find_path_device("/rtas");
-	ip = (int *)get_property(rtas_node, "ibm,lrdr-capacity", NULL);
-	if (ip == NULL) {
+	lrdrp = (int *)get_property(rtas_node, "ibm,lrdr-capacity", NULL);
+
+	if (lrdrp == NULL) {
 		system_active_processors = systemcfg->processorCount; 
 	} else {
-		system_active_processors = *(ip + 4);
-	}
+		system_active_processors = *(lrdrp + 4);
+	} 
 
 	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
+		unsigned long h_entitled,h_unallocated,h_aggregation,h_resource;
+		unsigned long pool_idle_time,pool_procs;
+		unsigned long purr;
+
 		h_get_ppp(&h_entitled,&h_unallocated,&h_aggregation,&h_resource);
-#ifdef DEBUG
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "R4=0x%lx\n", h_entitled);
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "R5=0x%lx\n", h_unallocated);
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "R6=0x%lx\n", h_aggregation);
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "R7=0x%lx\n", h_resource);
-#endif /* DEBUG */
-	}
 
-	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
-		system_potential_processors =  get_splpar_potential_characteristics();
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "system_active_processors=%ld\n", 
+		seq_printf(m, "R4=0x%lx\n", h_entitled);
+		seq_printf(m, "R5=0x%lx\n", h_unallocated);
+		seq_printf(m, "R6=0x%lx\n", h_aggregation);
+		seq_printf(m, "R7=0x%lx\n", h_resource);
+
+		h_pic(&pool_idle_time,&pool_procs);
+
+		purr = get_purr();
+
+		/* this call handles the ibm,get-system-parameter contents */
+		parse_system_parameter_string(m);
+
+		seq_printf(m, "partition_entitled_capacity=%ld\n",
+			      h_entitled);
+
+		seq_printf(m, "pool=%ld\n",
+			      (h_aggregation >> 0*8) & 0xffff);
+
+		seq_printf(m, "group=%ld\n",
+			      (h_aggregation >> 2*8) & 0xffff);
+
+		seq_printf(m, "system_active_processors=%ld\n", 
 			      (h_resource >> 2*8) & 0xffff);
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "system_potential_processors=%d\n", 
-			      system_potential_processors);
-	} else {
-		system_potential_processors = system_active_processors;
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "system_active_processors=%d\n", 
-			      system_active_processors);
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "system_potential_processors=%d\n", 
-			      system_potential_processors);
-	}
 
-	processors = systemcfg->processorCount;
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_active_processors=%d\n", processors);  
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_potential_processors=%d\n",
-		      system_active_processors);
+		seq_printf(m, "pool_capacity=%ld\n",
+			      (h_resource >> 3*8) & 0xffff);
 
-	/* max_entitled_capacity will come out of get_splpar_potential_characteristics() when that function is complete */
-	max_entitled_capacity = system_active_processors * 100; 
-	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "partition_entitled_capacity=%ld\n", h_entitled);
-	} else {
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "partition_entitled_capacity=%d\n", system_active_processors*100);
-	}
+		seq_printf(m, "capacity_weight=%ld\n",
+			      (h_resource>>5*8) & 0xFF);
 
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "partition_max_entitled_capacity=%d\n", 
-		      max_entitled_capacity);
+		seq_printf(m, "capped=%ld\n",
+			      (h_resource >> 6*8) & 0x40);
 
-	shared = 0;
-	n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-		      "shared_processor_mode=%d\n", shared);
+		seq_printf(m, "unallocated_variable_weight=%ld\n",
+			      (h_resource>>7*8) & 0xFF);
 
-	if (cur_cpu_spec->firmware_features & FW_FEATURE_SPLPAR) {
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "pool=%ld\n", (h_aggregation >> 0*8)&0xffff);
+		seq_printf(m, "unallocated_capacity=%ld\n",
+			      h_unallocated);
 
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "pool_capacity=%ld\n", (h_resource >> 3*8) &0xffff);
+		seq_printf(m, "pool_idle_time=%ld\n",
+			      pool_idle_time);
 
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "group=%ld\n", (h_aggregation >> 2*8)&0xffff);
+		seq_printf(m, "pool_num_procs=%ld\n",
+			      pool_procs);
+
+		seq_printf(m, "purr=%ld\n",
+			      purr);
+
+	} else /* non SPLPAR case */ {
+		seq_printf(m, "system_active_processors=%d\n",
+			      system_active_processors);
+
+		seq_printf(m, "system_potential_processors=%d\n",
+			      system_active_processors);
 
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "capped=%ld\n", (h_resource >> 6*8)&0x40);
+		seq_printf(m, "partition_max_entitled_capacity=%d\n",
+			      100*system_active_processors);
 
-		n += scnprintf(buf+n, LPARCFG_BUFF_SIZE - n,
-			      "capacity_weight=%d\n", (int)(h_resource>>5*8)&0xFF);
+		seq_printf(m, "partition_entitled_capacity=%d\n",
+			      system_active_processors*100);
 	}
+
+	seq_printf(m, "partition_active_processors=%d\n",
+			(int) lparcfg_count_active_processors());
+
+	seq_printf(m, "partition_potential_processors=%d\n",
+			system_active_processors);
+
+	seq_printf(m, "shared_processor_mode=%d\n",
+			paca[0].xLpPaca.xSharedProc);
+
 	return 0;
 }
 
@@ -484,58 +507,16 @@ out:
 
 #endif /* CONFIG_PPC_PSERIES */
 
-
-static ssize_t lparcfg_read(struct file *file, char *buf,
-			    size_t count, loff_t *ppos)
-{
-	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
-	unsigned long *data = (unsigned long *)dp->data;
-	unsigned long p;
-	ssize_t read;
-	char * pnt;
-
-	if (!data) {
-		printk(KERN_ERR "lparcfg: read failed no data\n");
-		return -EIO;
-	}
-
-	if(ppos) {
-		p = *ppos;
-	} else {
-		return -EFAULT;
-	}
-
-	if (p >= LPARCFG_BUFF_SIZE) return 0;
-
-	lparcfg_data((unsigned char *)data, LPARCFG_BUFF_SIZE); 
-	if (count > (strlen((char *)data) - p))
-		count = (strlen((char *)data)) - p;
-	read = 0;
-
-	pnt = (char *)(data) + p;
-	copy_to_user(buf, (void *)pnt, count);
-	read += count;
-	*ppos += read;
-	return read;
-}
-
 static int lparcfg_open(struct inode * inode, struct file * file)
 {
-	struct proc_dir_entry *dp = PDE(file->f_dentry->d_inode);
-	unsigned int *data = (unsigned int *)dp->data;
-
-	if (!data) {
-		printk(KERN_ERR "lparcfg: open failed no data\n");
-		return -EIO;
-	}
-
-	return 0;
+	return single_open(file,lparcfg_data,NULL);
 }
 
 struct file_operations lparcfg_fops = {
 	owner:		THIS_MODULE,
-	read:		lparcfg_read,
+	read:		seq_read,
 	open:		lparcfg_open,
+	release:	single_release,
 };
 
 int __init lparcfg_init(void)
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/open_pic_u3.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/open_pic_u3.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/open_pic_u3.c	2004-02-12 03:47:52.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/open_pic_u3.c	2004-02-26 10:56:03.000000000 +0000
@@ -251,6 +251,14 @@ static inline void openpic2_set_sense(u_
 				 (sense ? OPENPIC_SENSE_LEVEL : 0));
 }
 
+#if 0	/* not used */
+static int openpic2_get_sense(u_int irq)
+{
+	return openpic2_readfield(&GET_ISU(irq).Vector_Priority,
+				  OPENPIC_SENSE_LEVEL) != 0;
+}
+#endif
+
 static void openpic2_end_irq(unsigned int irq_nr)
 {
 	openpic2_eoi();
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/pSeries_iommu.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/pSeries_iommu.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/pSeries_iommu.c	2004-04-12 17:54:09.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/pSeries_iommu.c	2004-04-13 03:00:57.000000000 +0000
@@ -211,6 +211,7 @@ static void iommu_table_setparms(struct 
 	tbl->it_index = 0;
 	tbl->it_entrysize = sizeof(union tce_entry);
 	tbl->it_blocksize = 16;
+	tbl->it_type = TCE_PCI;
 }
 
 /*
@@ -246,6 +247,7 @@ static void iommu_table_setparms_lpar(st
 	tbl->it_index  = dma_window[0];
 	tbl->it_entrysize = sizeof(union tce_entry);
 	tbl->it_blocksize  = 16;
+	tbl->it_type = TCE_PCI;
 }
 
 
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/process.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/process.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/process.c	2004-04-22 08:40:31.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/process.c	2004-04-24 05:42:08.000000000 +0000
@@ -65,9 +65,6 @@ struct mm_struct ioremap_mm = {
 	.page_table_lock = SPIN_LOCK_UNLOCKED,
 };
 
-char *sysmap = NULL;
-unsigned long sysmap_size = 0;
-
 void enable_kernel_fp(void)
 {
 #ifdef CONFIG_SMP
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/setup.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/setup.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/setup.c	2004-04-12 17:54:06.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/setup.c	2004-04-24 05:42:09.000000000 +0000
@@ -188,30 +188,32 @@ void setup_system(unsigned long r3, unsi
 #ifdef CONFIG_PPC_PSERIES
 	case PLATFORM_PSERIES:
 		pSeries_init_early();
-#ifdef CONFIG_BLK_DEV_INITRD
-		initrd_start = initrd_end = 0;
-#endif
 		parse_bootinfo();
 		break;
 
 	case PLATFORM_PSERIES_LPAR:
 		pSeriesLP_init_early();
-#ifdef CONFIG_BLK_DEV_INITRD
-		initrd_start = initrd_end = 0;
-#endif
 		parse_bootinfo();
 		break;
 #endif /* CONFIG_PPC_PSERIES */
 #ifdef CONFIG_PPC_PMAC
 	case PLATFORM_POWERMAC:
 		pmac_init_early();
-#ifdef CONFIG_BLK_DEV_INITRD
-		initrd_start = initrd_end = 0;
-#endif
 		parse_bootinfo();
 #endif /* CONFIG_PPC_PMAC */
 	}
 
+	/* If we were passed an initrd, set the ROOT_DEV properly if the values
+	 * look sensible. If not, clear initrd reference.
+	 */
+#ifdef CONFIG_BLK_DEV_INITRD
+	if (initrd_start >= KERNELBASE && initrd_end >= KERNELBASE &&
+	    initrd_end > initrd_start)
+		ROOT_DEV = Root_RAM0;
+	else
+		initrd_start = initrd_end = 0;
+#endif /* CONFIG_BLK_DEV_INITRD */
+
 #ifdef CONFIG_BOOTX_TEXT
 	map_boot_text();
 	if (systemcfg->platform == PLATFORM_POWERMAC) {
@@ -425,15 +427,6 @@ struct seq_operations cpuinfo_op = {
 void parse_cmd_line(unsigned long r3, unsigned long r4, unsigned long r5,
 		  unsigned long r6, unsigned long r7)
 {
-#ifdef CONFIG_BLK_DEV_INITRD
-	if ((initrd_start == 0) && r3 && r4 && r4 != 0xdeadbeef) {
-		initrd_start = (r3 >= KERNELBASE) ? r3 : (unsigned long)__va(r3);
-		initrd_end = initrd_start + r4;
-		ROOT_DEV = Root_RAM0;
-		initrd_below_start_ok = 1;
-	}
-#endif
-
 	cmd_line[0] = 0;
 
 #ifdef CONFIG_CMDLINE
@@ -533,8 +526,6 @@ console_initcall(set_preferred_console);
 int parse_bootinfo(void)
 {
 	struct bi_record *rec;
-	extern char *sysmap;
-	extern unsigned long sysmap_size;
 
 	rec = prom.bi_recs;
 
@@ -546,18 +537,6 @@ int parse_bootinfo(void)
 		case BI_CMD_LINE:
 			strlcpy(cmd_line, (void *)rec->data, sizeof(cmd_line));
 			break;
-		case BI_SYSMAP:
-			sysmap = __va(rec->data[0]);
-			sysmap_size = rec->data[1];
-			break;
-#ifdef CONFIG_BLK_DEV_INITRD
-		case BI_INITRD:
-			initrd_start = (unsigned long)__va(rec->data[0]);
-			initrd_end = initrd_start + rec->data[1];
-			ROOT_DEV = Root_RAM0;
-			initrd_below_start_ok = 1;
-			break;
-#endif /* CONFIG_BLK_DEV_INITRD */
 		}
 	}
 
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/smp.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/smp.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/smp.c	2004-04-12 17:54:07.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/smp.c	2004-04-14 16:04:29.000000000 +0000
@@ -53,6 +53,10 @@
 #include <asm/cputable.h>
 #include <asm/system.h>
 
+#ifdef CONFIG_KDB
+#include <linux/kdb.h>
+#endif
+
 int smp_threads_ready;
 unsigned long cache_decay_ticks;
 
@@ -75,6 +79,23 @@ void smp_call_function_interrupt(void);
 extern long register_vpa(unsigned long flags, unsigned long proc,
 			 unsigned long vpa);
 
+#ifdef CONFIG_KDB
+	/* save regs here before calling kdb_ipi */
+struct pt_regs *kdb_smp_regs[NR_CPUS];
+	
+/* called for each processor.. drop each into kdb. */
+static void smp_kdb_stop_proc(void *dummy)
+{
+    kdb_ipi(kdb_smp_regs[smp_processor_id()], NULL);
+}
+	
+void smp_kdb_stop(void)
+{
+    int ret=0;
+    ret = smp_call_function(smp_kdb_stop_proc, NULL, 1, 0);
+}
+#endif
+
 /* Low level assembly function used to backup CPU 0 state */
 extern void __save_cpu_setup(void);
 
@@ -306,6 +327,7 @@ void __cpu_die(unsigned int cpu)
 void cpu_die(void)
 {
 	local_irq_disable();
+	pSeriesLP_cppr_info(0, 0);
 	rtas_stop_self();
 	/* Should never get here... */
 	BUG();
@@ -605,6 +627,9 @@ void smp_message_recv(int msg, struct pt
 {
 	switch(msg) {
 	case PPC_MSG_CALL_FUNCTION:
+#ifdef CONFIG_KDB
+	        kdb_smp_regs[smp_processor_id()]=regs;
+#endif
 		smp_call_function_interrupt();
 		break;
 	case PPC_MSG_RESCHEDULE: 
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/viopath.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/viopath.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/viopath.c	2004-03-19 07:10:24.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/viopath.c	2004-04-16 23:30:39.000000000 +0000
@@ -108,7 +108,7 @@ static vio_event_handler_t *vio_handler[
 #define VIOPATH_KERN_WARN	KERN_WARNING "viopath: "
 #define VIOPATH_KERN_INFO	KERN_INFO "viopath: "
 
-static unsigned char e2a(unsigned char x)
+unsigned char e2a(unsigned char x)
 {
 	switch (x) {
 	case 0xF0:
@@ -186,6 +186,7 @@ static unsigned char e2a(unsigned char x
 	}
 	return ' ';
 }
+EXPORT_SYMBOL(e2a);
 
 static int proc_viopath_show(struct seq_file *m, void *v)
 {
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/vpurr.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/vpurr.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/vpurr.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/vpurr.c	2004-03-20 10:56:41.000000000 +0000
@@ -0,0 +1,101 @@
+/*
+ * PPC64 Cpu util performace monitoring.
+ *
+ * Manish Ahuja mahuja@us.ibm.com
+ *    Copyright (c) 2004 Manish Ahuja IBM CORP.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ *
+ *	This file will also report many of the perf values for 2.6 
+ */
+
+#include <linux/config.h>
+#include <linux/module.h>
+#include <linux/types.h>
+#include <linux/errno.h>
+#include <linux/proc_fs.h>
+#include <linux/init.h>
+#include <asm/uaccess.h>
+#include <asm/hvcall.h>
+#include <asm/cputable.h>
+#include "vpurr.h"
+
+#define SAMPLE_TICK HZ
+
+DEFINE_PER_CPU(struct cpu_util_store, cpu_util_sampler);
+
+static void collect_startpurr(int cpu);
+
+/*
+ * This is a timer handler.  There is on per CPU. It gets scheduled
+ * every SAMPLE_TICK ticks.
+ */
+
+static void util_timer_func(unsigned long data)
+{
+	struct cpu_util_store * cus = &__get_cpu_var(cpu_util_sampler);
+	struct timer_list *tl = &cus->cpu_util_timer;
+
+	cus->current_purr = mfspr(PURR);
+	cus->tb = mftb();
+
+	/*printk(KERN_INFO "PURR VAL %ld %lld %lld\n", data, cus->current_purr, cus->tb);*/
+
+	mod_timer(tl, jiffies + SAMPLE_TICK);
+}
+
+/*
+ * One time function that gets called when all the cpu's are online 
+ * to start collection. It adds the timer to each cpu on the system.
+ * start_purr is collected during smp_init time in __cpu_up code
+ */
+
+static void start_util_timer(int cpu)
+{
+	struct cpu_util_store * cus = &per_cpu(cpu_util_sampler, cpu);
+	struct timer_list *tl = &cus->cpu_util_timer;
+
+	if (tl->function != NULL)
+		return;
+
+	init_timer(tl);
+	tl->expires = jiffies + SAMPLE_TICK;
+	tl->data = cpu;
+	tl->function = util_timer_func;
+	add_timer_on(tl, cpu);
+}
+
+static int __init cpu_util_init(void)
+{
+	int cpu;
+
+	if (PVR_VER(systemcfg->processor) == PV_POWER5) {
+		for_each_online_cpu(cpu){
+			collect_startpurr(cpu);
+			start_util_timer(cpu);
+		}
+	}
+
+	return 0;
+}
+
+__initcall(cpu_util_init);
+
+/* Collect starting purr, to collect starting purr from the
+ * cpu in question, we make a call to get that cpu and then run
+ */
+
+static void collect_startpurr(int cpu)
+{
+	struct cpu_util_store * cus = &per_cpu(cpu_util_sampler, cpu);	
+
+	set_cpus_allowed(current, cpumask_of_cpu(cpu));
+	BUG_ON(smp_processor_id() != cpu);
+
+	cus->start_purr = mfspr(PURR);
+	cus->tb = mftb();
+}
+
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/vpurr.h linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/vpurr.h
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/vpurr.h	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/vpurr.h	2004-04-07 16:48:30.000000000 +0000
@@ -0,0 +1,24 @@
+/*
+ *    Copyright (c) 2004 Manish Ahuja <mahuja@us.ibm.com> IBM CORP.
+ *
+ *    Module name: vpurr.h
+ *
+ *    Description:
+ *      Architecture- / platform-specific boot-time initialization code for
+ *      tracking purr utilization and other performace features in coming 
+ * 	releases for splpar/smt machines.
+ *
+ *      This program is free software; you can redistribute it and/or
+ *      modify it under the terms of the GNU General Public License
+ *      as published by the Free Software Foundation; either version
+ *      2 of the License, or (at your option) any later version.
+ */
+
+DECLARE_PER_CPU(struct cpu_util_store, cpu_util_sampler);
+
+struct cpu_util_store {
+        struct timer_list cpu_util_timer;
+        u64 start_purr;
+        u64 current_purr;
+        u64 tb;
+};
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/xics.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/xics.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/kernel/xics.c	2004-04-12 17:54:11.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/kernel/xics.c	2004-04-14 16:04:29.000000000 +0000
@@ -190,7 +190,7 @@ static void pSeriesLP_xirr_info_set(int 
 		      val64); 
 }
 
-static void pSeriesLP_cppr_info(int n_cpu, u8 value)
+void pSeriesLP_cppr_info(int n_cpu, u8 value)
 {
 	unsigned long lpar_rc;
 
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/lib/Makefile linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/lib/Makefile
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/lib/Makefile	2003-06-10 13:09:57.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/lib/Makefile	2004-03-19 03:01:36.000000000 +0000
@@ -4,3 +4,6 @@
 
 lib-y := checksum.o dec_and_lock.o string.o strcase.o
 lib-y += copypage.o memcpy.o copyuser.o
+
+lib-$(CONFIG_PPC_ISERIES) += locks.o
+lib-$(CONFIG_PPC_SPLPAR)  += locks.o
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/lib/locks.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/lib/locks.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/lib/locks.c	1970-01-01 00:00:00.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/lib/locks.c	2004-03-19 02:52:48.000000000 +0000
@@ -0,0 +1,90 @@
+/*
+ * Slow paths for spin and read/write lock operations.
+ *
+ * Copyright (C) 2001 Paul Mackerras <paulus@au.ibm.com>, IBM
+ * Copyright (C) 2001 Anton Blanchard <anton@au.ibm.com>, IBM
+ * Copyright (C) 2002 Dave Engebretsen <engebret@us.ibm.com>, IBM
+ *   Rework to support virtual processors
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License
+ * as published by the Free Software Foundation; either version
+ * 2 of the License, or (at your option) any later version.
+ */
+
+#include <linux/config.h>
+#include <linux/kernel.h>
+#include <linux/spinlock.h>
+#include <linux/module.h>
+#include <asm/hvcall.h>
+#include <asm/iSeries/HvCall.h>
+
+/*
+ * On a system with shared processors (that is, where a physical
+ * processor is multiplexed between several virtual processors),
+ * there is no point spinning on a lock if the holder of the lock
+ * isn't currently scheduled on a physical processor.  Instead
+ * we detect this situation and ask the hypervisor to give the
+ * rest of our timeslice to the lock holder.
+ */
+
+/* waiting for a spinlock... */
+void __spin_yield(spinlock_t *lock)
+{
+	unsigned int lock_value, holder_cpu, yield_count;
+	struct paca_struct *holder_paca;
+
+	lock_value = lock->lock;
+	if (lock_value == 0)
+		return;
+	holder_cpu = lock_value & 0xffff;
+	BUG_ON(holder_cpu >= NR_CPUS);
+	holder_paca = &paca[holder_cpu];
+	yield_count = holder_paca->xLpPaca.xYieldCount;
+	if ((yield_count & 1) == 0)
+		return;		/* virtual cpu is currently running */
+	rmb();
+	if (lock->lock != lock_value)
+		return;		/* something has changed */
+#ifdef CONFIG_PPC_ISERIES
+	HvCall2(HvCallBaseYieldProcessor, HvCall_YieldToProc,
+		((u64)holder_cpu << 32) | yield_count);
+#else
+	plpar_hcall_norets(H_CONFER, holder_cpu, yield_count);
+#endif
+}
+
+EXPORT_SYMBOL(__spin_yield);
+
+/*
+ * Waiting for a read lock or a write lock on a rwlock...
+ * This turns out to be the same for read and write locks, since
+ * we only know the holder if it is write-locked.
+ */
+void __rw_yield(rwlock_t *rw)
+{
+	int lock_value;
+	unsigned int holder_cpu, yield_count;
+	struct paca_struct *holder_paca;
+
+	lock_value = rw->lock;
+	if (lock_value >= 0)
+		return;		/* no write lock at present */
+	holder_cpu = lock_value & 0xffff;
+	BUG_ON(holder_cpu >= NR_CPUS);
+	holder_paca = &paca[holder_cpu];
+	yield_count = holder_paca->xLpPaca.xYieldCount;
+	if ((yield_count & 1) == 0)
+		return;		/* virtual cpu is currently running */
+	rmb();
+	if (rw->lock != lock_value)
+		return;		/* something has changed */
+#ifdef CONFIG_PPC_ISERIES
+	HvCall2(HvCallBaseYieldProcessor, HvCall_YieldToProc,
+		((u64)holder_cpu << 32) | yield_count);
+#else
+	plpar_hcall_norets(H_CONFER, holder_cpu, yield_count);
+#endif
+}
+
+EXPORT_SYMBOL(__rw_yield);
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/mm/init.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/mm/init.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/mm/init.c	2004-04-12 17:54:08.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/mm/init.c	2004-04-24 05:42:09.000000000 +0000
@@ -621,8 +621,6 @@ module_init(setup_kcore);
 void __init mem_init(void)
 {
 #ifndef CONFIG_DISCONTIGMEM
-	extern char *sysmap; 
-	extern unsigned long sysmap_size;
 	unsigned long addr;
 #endif
 	int codepages = 0;
@@ -656,12 +654,6 @@ void __init mem_init(void)
 
 	totalram_pages += free_all_bootmem();
 
-	if ( sysmap_size )
-		for (addr = (unsigned long)sysmap;
-		     addr < PAGE_ALIGN((unsigned long)sysmap+sysmap_size) ;
-		     addr += PAGE_SIZE)
-			SetPageReserved(virt_to_page(addr));
-	
 	for (addr = KERNELBASE; addr <= (unsigned long)__va(lmb_end_of_DRAM());
 	     addr += PAGE_SIZE) {
 		if (!PageReserved(virt_to_page(addr)))
diff -purN linux-post-2.6.6-rc2-20040424/arch/ppc64/mm/numa.c linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/mm/numa.c
--- linux-post-2.6.6-rc2-20040424/arch/ppc64/mm/numa.c	2004-04-12 17:54:46.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/arch/ppc64/mm/numa.c	2004-04-13 03:01:02.000000000 +0000
@@ -143,6 +143,7 @@ static int __init parse_numa_properties(
 		unsigned long size = 0;
 		int numa_domain;
 		int ranges;
+		int propsize;
 
 		tmp1 = (int *)get_property(memory, "reg", NULL);
 		if (!tmp1)
@@ -169,10 +170,21 @@ new_range:
 		if ((start + size) > MAX_MEMORY)
 			BUG();
 
+		/* Some versions of OF sometimes have an empty property for
+		 * associativity, so we need to get the size too.
+		 */
 		tmp2 = (int *)get_property(memory, "ibm,associativity",
-					   NULL);
+					   &propsize);
 		if (!tmp2)
 			continue;
+
+		if (!propsize) {
+			printk(KERN_INFO "Buggy OF? Empty ibm,associativity "
+			       "property for %s. Disabling NUMA.\n",
+			       memory->full_name);
+			goto err;
+		}
+
 		numa_domain = tmp2[depth];
 
 		/* FIXME */
diff -purN linux-post-2.6.6-rc2-20040424/drivers/pci/hotplug/rpaphp_core.c linuxppc64-post-2.6.6-rc2-20040424/drivers/pci/hotplug/rpaphp_core.c
--- linux-post-2.6.6-rc2-20040424/drivers/pci/hotplug/rpaphp_core.c	2004-04-11 19:11:18.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/drivers/pci/hotplug/rpaphp_core.c	2004-04-19 01:12:40.000000000 +0000
@@ -54,6 +54,8 @@ MODULE_AUTHOR(DRIVER_AUTHOR);
 MODULE_DESCRIPTION(DRIVER_DESC);
 MODULE_LICENSE("GPL");
 
+void eeh_register_disable_func(int (*)(struct pci_dev *));
+
 module_param(debug, int, 0644);
 
 static int enable_slot(struct hotplug_slot *slot);
@@ -64,6 +66,7 @@ static int get_attention_status(struct h
 static int get_adapter_status(struct hotplug_slot *slot, u8 * value);
 static int get_max_bus_speed(struct hotplug_slot *hotplug_slot, enum pci_bus_speed *value);
 static int get_cur_bus_speed(struct hotplug_slot *hotplug_slot, enum pci_bus_speed *value);
+static int rpaphp_disable_slot(struct pci_dev *dev);
 
 struct hotplug_slot_ops rpaphp_hotplug_slot_ops = {
 	.owner = THIS_MODULE,
@@ -388,12 +391,18 @@ static int __init rpaphp_init(void)
 {
 	info(DRIVER_DESC " version: " DRIVER_VERSION "\n");
 
+	/* let EEH know they can use hotplug */
+	eeh_register_disable_func(&rpaphp_disable_slot);
+
 	/* read all the PRA info from the system */
 	return init_rpa();
 }
 
 static void __exit rpaphp_exit(void)
 {
+	/* let EEH know we are going away */
+	eeh_register_disable_func(NULL);
+
 	cleanup_slots();
 }
 
@@ -428,6 +437,11 @@ static int enable_slot(struct hotplug_sl
 	return retval;
 }
 
+static int rpaphp_disable_slot(struct pci_dev *dev)
+{
+	return disable_slot(rpaphp_find_hotplug_slot(dev));
+}
+
 static int disable_slot(struct hotplug_slot *hotplug_slot)
 {
 	int retval;
diff -purN linux-post-2.6.6-rc2-20040424/drivers/pci/hotplug/rpaphp_pci.c linuxppc64-post-2.6.6-rc2-20040424/drivers/pci/hotplug/rpaphp_pci.c
--- linux-post-2.6.6-rc2-20040424/drivers/pci/hotplug/rpaphp_pci.c	2004-03-30 18:50:32.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/drivers/pci/hotplug/rpaphp_pci.c	2004-04-19 01:12:40.000000000 +0000
@@ -397,3 +397,19 @@ int rpaphp_enable_pci_slot(struct slot *
 	dbg("%s - Exit: rc[%d]\n", __FUNCTION__, retval);
 	return retval;
 }
+
+struct hotplug_slot *rpaphp_find_hotplug_slot(struct pci_dev *dev)
+{
+	struct list_head	*tmp, *n;
+	struct slot		*slot;
+
+	list_for_each_safe(tmp, n, &rpaphp_slot_head) {
+		slot = list_entry(tmp, struct slot, rpaphp_slot_list);
+		if (slot->dev.pci_dev == dev)
+			return slot->hotplug_slot;
+	}
+
+	return NULL;
+}
+
+EXPORT_SYMBOL_GPL(rpaphp_find_hotplug_slot);
diff -purN linux-post-2.6.6-rc2-20040424/include/asm-ppc64/hardirq.h linuxppc64-post-2.6.6-rc2-20040424/include/asm-ppc64/hardirq.h
--- linux-post-2.6.6-rc2-20040424/include/asm-ppc64/hardirq.h	2003-09-11 04:07:58.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/include/asm-ppc64/hardirq.h	2004-02-18 06:28:00.000000000 +0000
@@ -80,7 +80,8 @@ typedef struct {
 
 #define irq_enter()		(preempt_count() += HARDIRQ_OFFSET)
 
-#ifdef CONFIG_PREEMPT
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_DEBUG_SPINLOCK_SLEEP)
+#include <linux/smp_lock.h>
 # define in_atomic()	((preempt_count() & ~PREEMPT_ACTIVE) != kernel_locked())
 # define IRQ_EXIT_OFFSET (HARDIRQ_OFFSET-1)
 #else
diff -purN linux-post-2.6.6-rc2-20040424/include/asm-ppc64/prom.h linuxppc64-post-2.6.6-rc2-20040424/include/asm-ppc64/prom.h
--- linux-post-2.6.6-rc2-20040424/include/asm-ppc64/prom.h	2004-03-19 05:59:30.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/include/asm-ppc64/prom.h	2004-04-24 05:37:46.000000000 +0000
@@ -260,7 +260,6 @@ extern int of_remove_node(struct device_
 /* Other Prototypes */
 extern unsigned long prom_init(unsigned long, unsigned long, unsigned long,
 	unsigned long, unsigned long);
-extern void prom_print(const char *msg);
 extern void relocate_nodes(void);
 extern void finish_device_tree(void);
 extern int device_is_compatible(struct device_node *device, const char *);
diff -purN linux-post-2.6.6-rc2-20040424/include/asm-ppc64/spinlock.h linuxppc64-post-2.6.6-rc2-20040424/include/asm-ppc64/spinlock.h
--- linux-post-2.6.6-rc2-20040424/include/asm-ppc64/spinlock.h	2002-09-10 09:50:15.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/include/asm-ppc64/spinlock.h	2004-03-19 03:01:36.000000000 +0000
@@ -4,7 +4,7 @@
 /*
  * Simple spin lock operations.  
  *
- * Copyright (C) 2001 Paul Mackerras <paulus@au.ibm.com>, IBM
+ * Copyright (C) 2001-2004 Paul Mackerras <paulus@au.ibm.com>, IBM
  * Copyright (C) 2001 Anton Blanchard <anton@au.ibm.com>, IBM
  *
  * Type of int is used as a full 64b word is not necessary.
@@ -14,56 +14,72 @@
  * as published by the Free Software Foundation; either version
  * 2 of the License, or (at your option) any later version.
  */
+#include <linux/config.h>
+#include <linux/compiler.h>
+#include <linux/threads.h>
+#include <asm/memory.h>
+
 typedef struct {
 	volatile unsigned int lock;
 } spinlock_t;
 
+/*
+ * When we have shared processors, we need to be able to tell
+ * which virtual processor holds the lock, so we can tell the
+ * hypervisor to give our timeslice to them if they are not
+ * currently scheduled on a real processor.  To do this,
+ * we put paca->xPacaIndex + 0x10000 in the lock when it is
+ * held.
+ */
+
 #ifdef __KERNEL__
 #define SPIN_LOCK_UNLOCKED	(spinlock_t) { 0 }
 
 #define spin_is_locked(x)	((x)->lock != 0)
 
-static __inline__ int _raw_spin_trylock(spinlock_t *lock)
+/*
+ * This returns the old value in the lock, so we succeeded
+ * in getting the lock if the return value is 0.
+ */
+static __inline__ int __spin_trylock(spinlock_t *lock)
 {
-	unsigned int tmp;
+	unsigned int tmp, tmp2;
 
 	__asm__ __volatile__(
-"1:	lwarx		%0,0,%1		# spin_trylock\n\
+"1:	lwarx		%0,0,%2		# __spin_trylock\n\
 	cmpwi		0,%0,0\n\
-	li		%0,0\n\
 	bne-		2f\n\
-	li		%0,1\n\
-	stwcx.		%0,0,%1\n\
+	lhz		%1,24(13)\n\
+	oris		%1,%1,1\n\
+	stwcx.		%1,0,%2\n\
 	bne-		1b\n\
 	isync\n\
-2:"	: "=&r"(tmp)
-	: "r"(&lock->lock)
+2:"	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&lock->lock)
 	: "cr0", "memory");
 
 	return tmp;
 }
 
-static __inline__ void _raw_spin_lock(spinlock_t *lock)
+static __inline__ int _raw_spin_trylock(spinlock_t *lock)
 {
-	unsigned int tmp;
+	return __spin_trylock(lock) == 0;
+}
 
-	__asm__ __volatile__(
-	"b		2f		# spin_lock\n\
-1:"
-	HMT_LOW
-"	lwzx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne+		1b\n"
-	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne-		1b\n\
-	stwcx.		%2,0,%1\n\
-	bne-		2b\n\
-	isync"
-	: "=&r"(tmp)
-	: "r"(&lock->lock), "r"(1)
-	: "cr0", "memory");
+extern void __spin_yield(spinlock_t *);
+#if !defined(CONFIG_PPC_ISERIES) && !defined(CONFIG_PPC_SPLPAR)
+#define __spin_yield(x)		do { } while (0)
+#endif
+
+static __inline__ void _raw_spin_lock(spinlock_t *lock)
+{
+	while (unlikely(__spin_trylock(lock) != 0)) {
+		do {
+			HMT_low();
+			__spin_yield(lock);
+		} while (likely(lock->lock != 0));
+		HMT_medium();
+	}
 }
 
 static __inline__ void _raw_spin_unlock(spinlock_t *lock)
@@ -81,6 +97,10 @@ static __inline__ void _raw_spin_unlock(
  * can "mix" irq-safe locks - any writer needs to get a
  * irq-safe write-lock, but readers can get non-irqsafe
  * read-locks.
+ *
+ * For a write lock, we store 0x80000000 | paca->xPacaIndex,
+ * so that we can tell who holds the lock, which we need
+ * to know if we are running on shared processors.
  */
 typedef struct {
 	volatile signed int lock;
@@ -88,50 +108,48 @@ typedef struct {
 
 #define RW_LOCK_UNLOCKED (rwlock_t) { 0 }
 
-static __inline__ int _raw_read_trylock(rwlock_t *rw)
+/*
+ * This returns the old value in the lock + 1,
+ * so we got a read lock if the return value is > 0.
+ */
+static __inline__ int __read_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
-	unsigned int ret;
+	int tmp;
 
 	__asm__ __volatile__(
-"1:	lwarx		%0,0,%2		# read_trylock\n\
-	li		%1,0\n\
+"1:	lwarx		%0,0,%1		# read_trylock\n\
 	extsw		%0,%0\n\
 	addic.		%0,%0,1\n\
 	ble-		2f\n\
-	stwcx.		%0,0,%2\n\
+	stwcx.		%0,0,%1\n\
 	bne-		1b\n\
-	li		%1,1\n\
 	isync\n\
-2:"	: "=&r"(tmp), "=&r"(ret)
-	: "r"(&rw->lock)
-	: "cr0", "memory");
+2:"	: "=&r" (tmp)
+	: "r" (&rw->lock)
+	: "cr0", "xer", "memory");
 
-	return ret;
+	return tmp;
 }
 
-static __inline__ void _raw_read_lock(rwlock_t *rw)
+static __inline__ int _raw_read_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
+	return __read_trylock(rw) > 0;
+}
 
-	__asm__ __volatile__(
-	"b		2f		# read_lock\n\
-1:"
-	HMT_LOW
-"	lwax		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	blt+		1b\n"
-	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	extsw		%0,%0\n\
-	addic.		%0,%0,1\n\
-	ble-		1b\n\
-	stwcx.		%0,0,%1\n\
-	bne-		2b\n\
-	isync"
-	: "=&r"(tmp)
-	: "r"(&rw->lock)
-	: "cr0", "memory");
+extern void __rw_yield(rwlock_t *);
+#if !defined(CONFIG_PPC_ISERIES) && !defined(CONFIG_PPC_SPLPAR)
+#define __rw_yield(x)		do { } while (0)
+#endif
+
+static __inline__ void _raw_read_lock(rwlock_t *rw)
+{
+	while (unlikely(__read_trylock(rw) <= 0)) {
+		do {
+			HMT_low();
+			__rw_yield(rw);
+		} while (likely(rw->lock < 0));
+		HMT_medium();
+	}
 }
 
 static __inline__ void _raw_read_unlock(rwlock_t *rw)
@@ -149,48 +167,44 @@ static __inline__ void _raw_read_unlock(
 	: "cr0", "memory");
 }
 
-static __inline__ int _raw_write_trylock(rwlock_t *rw)
+/*
+ * This returns the old value in the lock,
+ * so we got the write lock if the return value is 0.
+ */
+static __inline__ int __write_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
-	unsigned int ret;
+	int tmp, tmp2;
 
 	__asm__ __volatile__(
 "1:	lwarx		%0,0,%2		# write_trylock\n\
 	cmpwi		0,%0,0\n\
-	li		%1,0\n\
 	bne-		2f\n\
-	stwcx.		%3,0,%2\n\
+	lhz		%1,24(13)\n\
+	oris		%1,%1,0x8000\n\
+	stwcx.		%1,0,%2\n\
 	bne-		1b\n\
-	li		%1,1\n\
 	isync\n\
-2:"	: "=&r"(tmp), "=&r"(ret)
-	: "r"(&rw->lock), "r"(-1)
+2:"	: "=&r" (tmp), "=&r" (tmp2)
+	: "r" (&rw->lock)
 	: "cr0", "memory");
 
-	return ret;
+	return tmp;
 }
 
-static __inline__ void _raw_write_lock(rwlock_t *rw)
+static __inline__ int _raw_write_trylock(rwlock_t *rw)
 {
-	unsigned int tmp;
+	return __write_trylock(rw) == 0;
+}
 
-	__asm__ __volatile__(
-	"b		2f		# write_lock\n\
-1:"
-	HMT_LOW
-	"lwax		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne+		1b\n"
-	HMT_MEDIUM
-"2:	lwarx		%0,0,%1\n\
-	cmpwi		0,%0,0\n\
-	bne-		1b\n\
-	stwcx.		%2,0,%1\n\
-	bne-		2b\n\
-	isync"
-	: "=&r"(tmp)
-	: "r"(&rw->lock), "r"(-1)
-	: "cr0", "memory");
+static __inline__ void _raw_write_lock(rwlock_t *rw)
+{
+	while (unlikely(__write_trylock(rw) != 0)) {
+		do {
+			HMT_low();
+			__rw_yield(rw);
+		} while (likely(rw->lock != 0));
+		HMT_medium();
+	}
 }
 
 static __inline__ void _raw_write_unlock(rwlock_t *rw)
diff -purN linux-post-2.6.6-rc2-20040424/include/asm-ppc64/xics.h linuxppc64-post-2.6.6-rc2-20040424/include/asm-ppc64/xics.h
--- linux-post-2.6.6-rc2-20040424/include/asm-ppc64/xics.h	2003-03-28 06:31:06.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/include/asm-ppc64/xics.h	2004-04-14 16:04:29.000000000 +0000
@@ -19,6 +19,9 @@ int xics_get_irq(struct pt_regs *);
 void xics_setup_cpu(void);
 void xics_cause_IPI(int cpu);
 
+/* first argument is ignored */
+void pSeriesLP_cppr_info(int n_cpu, u8 value);
+
 struct xics_ipi_struct {
 	volatile unsigned long value;
 } ____cacheline_aligned;
diff -purN linux-post-2.6.6-rc2-20040424/include/linux/preempt.h linuxppc64-post-2.6.6-rc2-20040424/include/linux/preempt.h
--- linux-post-2.6.6-rc2-20040424/include/linux/preempt.h	2004-02-25 10:42:02.000000000 +0000
+++ linuxppc64-post-2.6.6-rc2-20040424/include/linux/preempt.h	2004-02-26 05:42:10.000000000 +0000
@@ -25,6 +25,17 @@ do { \
 
 asmlinkage void preempt_schedule(void);
 
+#define preempt_check_resched() \
+do { \
+	if (unlikely(test_thread_flag(TIF_NEED_RESCHED))) \
+		preempt_schedule(); \
+} while (0)
+#else
+#define preempt_check_resched()		do { } while (0)
+#endif
+
+#if defined(CONFIG_PREEMPT) || defined(CONFIG_DEBUG_SPINLOCK_SLEEP)
+
 #define preempt_disable() \
 do { \
 	inc_preempt_count(); \
@@ -37,12 +48,6 @@ do { \
 	dec_preempt_count(); \
 } while (0)
 
-#define preempt_check_resched() \
-do { \
-	if (unlikely(test_thread_flag(TIF_NEED_RESCHED))) \
-		preempt_schedule(); \
-} while (0)
-
 #define preempt_enable() \
 do { \
 	preempt_enable_no_resched(); \
