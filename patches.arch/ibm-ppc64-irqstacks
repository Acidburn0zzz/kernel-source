
---

 linux-2.6.5-anton/arch/ppc64/Kconfig          |    7 ++
 linux-2.6.5-anton/arch/ppc64/kernel/irq.c     |   78 ++++++++++++++++++++++++--
 linux-2.6.5-anton/arch/ppc64/kernel/misc.S    |   24 ++++++++
 linux-2.6.5-anton/arch/ppc64/kernel/process.c |   23 +++++--
 linux-2.6.5-anton/arch/ppc64/xmon/xmon.c      |    2 
 linux-2.6.5-anton/include/asm-ppc64/bitops.h  |   14 ++++
 linux-2.6.5-anton/include/asm-ppc64/irq.h     |   24 +++++++-
 7 files changed, 157 insertions(+), 15 deletions(-)

diff -puN arch/ppc64/Kconfig~irqstacks arch/ppc64/Kconfig
--- linux-2.6.5/arch/ppc64/Kconfig~irqstacks	2004-05-04 04:29:45.485760151 +1000
+++ linux-2.6.5-anton/arch/ppc64/Kconfig	2004-05-04 04:29:45.532756653 +1000
@@ -508,6 +508,13 @@ config DEBUG_INFO
 	  Say Y here only if you plan to use gdb to debug the kernel.
 	  If you don't debug the kernel, you can say N.
 
+config IRQSTACKS
+	bool "Use separate kernel stacks when processing interrupts"
+	help
+	  If you say Y here the kernel will use separate kernel stacks
+	  for handling hard and soft interrupts.  This can help avoid
+	  overflowing the process kernel stacks.
+
 config DEBUG_SPINLOCK_SLEEP
 	bool "Sleep-inside-spinlock checking"
 	depends on DEBUG_KERNEL
diff -puN arch/ppc64/kernel/irq.c~irqstacks arch/ppc64/kernel/irq.c
--- linux-2.6.5/arch/ppc64/kernel/irq.c~irqstacks	2004-05-04 04:29:45.491759704 +1000
+++ linux-2.6.5-anton/arch/ppc64/kernel/irq.c	2004-05-04 04:59:22.852809607 +1000
@@ -370,8 +370,7 @@ skip:
 	return 0;
 }
 
-static inline int handle_irq_event(int irq, struct pt_regs *regs,
-				   struct irqaction *action)
+int handle_irq_event(int irq, struct pt_regs *regs, struct irqaction *action)
 {
 	int status = 0;
 	int retval = 0;
@@ -482,6 +481,9 @@ void ppc_irq_dispatch_handler(struct pt_
 	int cpu = smp_processor_id();
 	irq_desc_t *desc = get_irq_desc(irq);
 	irqreturn_t action_ret;
+#ifdef CONFIG_IRQSTACKS
+	struct thread_info *curtp, *irqtp;
+#endif
 
 	kstat_cpu(cpu).irqs[irq]++;
 
@@ -548,7 +550,23 @@ void ppc_irq_dispatch_handler(struct pt_
 	 */
 	for (;;) {
 		spin_unlock(&desc->lock);
-		action_ret = handle_irq_event(irq, regs, action);
+
+#ifdef CONFIG_IRQSTACKS
+		/* Switch to the irq stack to handle this */
+		curtp = current_thread_info();
+		irqtp = hardirq_ctx[smp_processor_id()];
+		if (curtp != irqtp) {
+			irqtp->task = curtp->task;
+			irqtp->flags = 0;
+			action_ret = call_handle_irq_event(irq, regs, action, irqtp);
+			irqtp->task = NULL;
+			if (irqtp->flags)
+				set_bits(irqtp->flags, &curtp->flags);
+		} else
+#else
+			action_ret = handle_irq_event(irq, regs, action);
+#endif
+
 		spin_lock(&desc->lock);
 		if (!noirqdebug)
 			note_interrupt(irq, desc, action_ret);
@@ -690,6 +708,7 @@ void __init init_IRQ(void)
 	once++;
 
 	ppc_md.init_IRQ();
+	irq_ctx_init();
 }
 
 static struct proc_dir_entry * root_irq_dir;
@@ -973,4 +992,55 @@ unsigned int real_irq_to_virt_slowpath(u
 
 }
 
-#endif
+#endif /* CONFIG_PPC_ISERIES */
+
+#ifdef CONFIG_IRQSTACKS
+static unsigned char softirq_stacks[NR_CPUS][THREAD_SIZE]
+	__attribute__((__aligned__(THREAD_SIZE)));
+static unsigned char hardirq_stacks[NR_CPUS][THREAD_SIZE] 
+	__attribute__((__aligned__(THREAD_SIZE)));
+
+struct thread_info *softirq_ctx[NR_CPUS];
+struct thread_info *hardirq_ctx[NR_CPUS];
+
+void irq_ctx_init(void)
+{
+	struct thread_info *tp;
+	int i;
+
+	for (i = 0; i < NR_CPUS; ++i) {
+		tp = (struct thread_info *) softirq_stacks[i];
+		softirq_ctx[i] = tp;
+		tp->cpu = i;
+		tp->preempt_count = SOFTIRQ_OFFSET;
+
+		tp = (struct thread_info *) hardirq_stacks[i];
+		hardirq_ctx[i] = tp;
+		tp->cpu = i;
+		tp->preempt_count = HARDIRQ_OFFSET;
+	}
+}
+
+void do_softirq(void)
+{
+	unsigned long flags;
+	struct thread_info *curtp, *irqtp;
+
+	if (in_interrupt())
+		return;
+
+	local_irq_save(flags);
+
+	if (local_softirq_pending()) {
+		curtp = current_thread_info();
+		irqtp = softirq_ctx[smp_processor_id()];
+		irqtp->task = curtp->task;
+		call_do_softirq(irqtp);
+		irqtp->task = NULL;
+	}
+
+	local_irq_restore(flags);
+}
+
+#endif /* CONFIG_IRQSTACKS */
+
diff -puN arch/ppc64/kernel/misc.S~irqstacks arch/ppc64/kernel/misc.S
--- linux-2.6.5/arch/ppc64/kernel/misc.S~irqstacks	2004-05-04 04:29:45.498759183 +1000
+++ linux-2.6.5-anton/arch/ppc64/kernel/misc.S	2004-05-04 04:29:45.539756132 +1000
@@ -102,6 +102,30 @@ _GLOBAL(local_irq_restore)
 	blr
 #endif /* CONFIG_PPC_ISERIES */
 
+#ifdef CONFIG_IRQSTACKS
+_GLOBAL(call_do_softirq)
+	mflr	r0
+	std	r0,16(r1)
+	stdu	r1,THREAD_SIZE-112(r3)
+	mr	r1,r3
+	bl	.__do_softirq
+	ld	r1,0(r1)
+	ld	r0,16(r1)
+	mtlr	r0
+	blr
+
+_GLOBAL(call_handle_irq_event)
+	mflr	r0
+	std	r0,16(r1)
+	stdu	r1,THREAD_SIZE-112(r6)
+	mr	r1,r6
+	bl	.handle_irq_event
+	ld	r1,0(r1)
+	ld	r0,16(r1)
+	mtlr	r0
+	blr
+#endif /* CONFIG_IRQSTACKS */
+
 /*
  * Flush instruction cache.
  */
diff -puN arch/ppc64/kernel/process.c~irqstacks arch/ppc64/kernel/process.c
--- linux-2.6.5/arch/ppc64/kernel/process.c~irqstacks	2004-05-04 04:29:45.504758737 +1000
+++ linux-2.6.5-anton/arch/ppc64/kernel/process.c	2004-05-04 04:32:35.625640514 +1000
@@ -457,19 +457,28 @@
 
 static int kstack_depth_to_print = 64;
 
-static inline int validate_sp(unsigned long sp, struct task_struct *p)
+static int validate_sp(unsigned long sp, struct task_struct *p)
 {
+	int cpu = task_cpu(p);
 	unsigned long stack_page = (unsigned long)p->thread_info;
 
-	if (sp < stack_page + sizeof(struct thread_struct))
-		return 0;
-	/* stack frames are at least 64 bytes */
-	if (sp > stack_page + THREAD_SIZE - 64)
-		return 0;
+	if (sp >= stack_page + sizeof(struct thread_struct)
+	    && sp <= stack_page + THREAD_SIZE - 112)
+		return 1;
+
+	stack_page = (unsigned long) hardirq_ctx[cpu];
+	if (sp >= stack_page + sizeof(struct thread_struct)
+	    && sp <= stack_page + THREAD_SIZE - 112)
+		return 1;
+
+	stack_page = (unsigned long) softirq_ctx[cpu];
+	if (sp >= stack_page + sizeof(struct thread_struct)
+	    && sp <= stack_page + THREAD_SIZE - 112)
+		return 1;
 
-	return 1;
+	return 0;
 }
-
+
 /*
  * These bracket the sleeping functions..
  */
diff -puN include/asm-ppc64/bitops.h~irqstacks include/asm-ppc64/bitops.h
--- linux-2.6.5/include/asm-ppc64/bitops.h~irqstacks	2004-05-04 04:29:45.510758290 +1000
+++ linux-2.6.5-anton/include/asm-ppc64/bitops.h	2004-05-04 04:29:45.545755685 +1000
@@ -154,6 +154,20 @@ static __inline__ int test_and_change_bi
 	return (old & mask) != 0;
 }
 
+static __inline__ void set_bits(unsigned long mask, unsigned long *addr)
+{
+	unsigned long old;
+
+	__asm__ __volatile__(
+"1:	ldarx	%0,0,%3		# set_bit\n\
+	or	%0,%0,%2\n\
+	stdcx.	%0,0,%3\n\
+	bne-	1b"
+	: "=&r" (old), "=m" (*addr)
+	: "r" (mask), "r" (addr), "m" (*addr)
+	: "cc");
+}
+
 /*
  * non-atomic versions
  */
diff -puN include/asm-ppc64/irq.h~irqstacks include/asm-ppc64/irq.h
--- linux-2.6.5/include/asm-ppc64/irq.h~irqstacks	2004-05-04 04:29:45.516757843 +1000
+++ linux-2.6.5-anton/include/asm-ppc64/irq.h	2004-05-04 04:31:09.606140458 +1000
@@ -9,6 +9,7 @@
  * 2 of the License, or (at your option) any later version.
  */
 
+#include <linux/threads.h>
 #include <asm/atomic.h>
 
 /*
@@ -75,9 +76,28 @@ static __inline__ int irq_canonicalize(i
 	return irq;
 }
 
-/* struct irqaction;
+struct irqaction;
 struct pt_regs;
-int handle_IRQ_event(unsigned int, struct pt_regs *, struct irqaction *); */
+int handle_irq_event(int, struct pt_regs *, struct irqaction *);
 
+#ifdef CONFIG_IRQSTACKS
+/*
+ * Per-cpu stacks for handling hard and soft interrupts.
+ */
+extern struct thread_info *hardirq_ctx[NR_CPUS];
+extern struct thread_info *softirq_ctx[NR_CPUS];
+
+extern void irq_ctx_init(void);
+extern void call_do_softirq(struct thread_info *tp);
+extern int call_handle_irq_event(int irq, struct pt_regs *regs,
+			struct irqaction *action, struct thread_info *tp);
+
+#define __ARCH_HAS_DO_SOFTIRQ
+
+#else
+#define irq_ctx_init()
+
+#endif /* CONFIG_IRQSTACKS */
+  
 #endif /* _ASM_IRQ_H */
 #endif /* __KERNEL__ */
diff -puN arch/ppc64/xmon/xmon.c~irqstacks arch/ppc64/xmon/xmon.c
--- linux-2.6.5/arch/ppc64/xmon/xmon.c~irqstacks	2004-05-04 05:01:11.037944455 +1000
+++ linux-2.6.5-anton/arch/ppc64/xmon/xmon.c	2004-05-04 05:01:13.313028792 +1000
@@ -941,8 +941,6 @@ static void xmon_show_stack(unsigned lon
 
 		if (!mread(sp, &newsp, sizeof(unsigned long)))
 			break;
-		if (newsp < sp)
-			break;
 
 		sp = newsp;
 	} while (count++ < xmon_depth_to_print);

_
