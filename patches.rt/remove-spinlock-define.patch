Subject: Linux-RT 2.6.25-rt
From: http://www.kernel.org/pub/linux/kernel/projects/rt/
Acked-by: Sven-Thorsten Dietrich <sdietrich@suse.de>
From ghaskins@novell.com Mon Mar 24 17:45:51 2008
Date: Fri, 07 Mar 2008 09:06:35 -0500
From: Gregory Haskins <ghaskins@novell.com>
To: mingo@elte.hu, rostedt@goodmis.org, tglx@linutronix.de,
     linux-rt-users@vger.kernel.org
Cc: ghaskins@novell.com, linux-kernel@vger.kernel.org
Subject: [PATCH] RT: fix spinlock preemption feature when PREEMPT_RT is
    enabled

    [ The following text is in the "utf-8" character set. ]
    [ Your display is set for the "iso-8859-1" character set.  ]
    [ Some characters may be displayed incorrectly. ]

kernel/spinlock.c implements two versions of spinlock wrappers around
the arch-specific implementations:

1) A simple passthrough which implies disabled preemption while spinning

2) A "preemptible waiter" version which uses trylock.

Currently, PREEMPT && SMP will turn on the preemptible feature, and
lockdep or PREEMPT_RT will disable it.  Disabling the feature for
lockdep makes perfect sense, but PREEMPT_RT is counter-intuitive.  My
guess is that this was inadvertent, so this patch once again enables
the feature for PREEMPT_RT.

(Since PREEMPT is set for PREEMPT_RT, we simply get rid of the extra
condition).

I have tested the PREEMPT_RT kernel with this patch and all seems well.
Therefore, if there *is* an issue with running preemptible versions of
these spinlocks under PREEMPT_RT, it is not immediately apparent why. 

Signed-off-by: Gregory Haskins <ghaskins@novell.com>
---

 kernel/spinlock.c |    2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

Index: linux-2.6.24.4-rt4/kernel/spinlock.c
===================================================================
--- linux-2.6.24.4-rt4.orig/kernel/spinlock.c	2008-03-24 19:06:12.000000000 -0400
+++ linux-2.6.24.4-rt4/kernel/spinlock.c	2008-03-24 19:07:19.000000000 -0400
@@ -117,7 +117,7 @@ EXPORT_SYMBOL(__write_trylock_irqsave);
  * not re-enabled during lock-acquire (which the preempt-spin-ops do):
  */
 #if !defined(CONFIG_PREEMPT) || !defined(CONFIG_SMP) || \
-	defined(CONFIG_DEBUG_LOCK_ALLOC) || defined(CONFIG_PREEMPT_RT)
+	defined(CONFIG_DEBUG_LOCK_ALLOC)
 
 void __lockfunc __read_lock(raw_rwlock_t *lock)
 {
