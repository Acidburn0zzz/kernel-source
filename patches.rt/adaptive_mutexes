From slert-devel-bounces+sdietrich=novell.com@suse.de Fri Feb 15 18:53:02 2008
Return-path: <slert-devel-bounces+sdietrich=novell.com@suse.de>
Received: from Relay1.suse.de ([149.44.160.87]) by emea5-mh.id5.novell.com
	with ESMTP (TLS encrypted); Fri, 15 Feb 2008 18:53:02 +0100
Received: from Fourier.suse.de (fourier.suse.de [149.44.160.40]) by
	Relay1.suse.de (Postfix) with ESMTP id 38F8B1C052AB for
	<sdietrich@novell.com>; Fri, 15 Feb 2008 18:53:02 +0100 (CET)
Received: from fourier.suse.de (localhost [127.0.0.1]) by Fourier.suse.de
	(Postfix) with ESMTP id 3356B1E4274D for <sdietrich@novell.com>; Fri, 15
	Feb 2008 18:53:02 +0100 (CET)
Received: from Relay1.suse.de (relay1.suse.de [149.44.160.87]) by
	Fourier.suse.de (Postfix) with ESMTP id C67FB1E42776 for
	<slert-devel@mailman.suse.de>; Fri, 15 Feb 2008 18:53:00 +0100 (CET)
Received: by Relay1.suse.de (Postfix) id C3AC81C052AF; Fri, 15 Feb 2008
	18:53:00 +0100 (CET)
Received: from relay1.suse.de (localhost [127.0.0.1]) by Relay1.suse.de
	(Postfix) with ESMTP id B7C3E1C052A7 for <slert-devel@suse.de>; Fri, 15 Feb
	2008 18:53:00 +0100 (CET)
X-Virus-Scanned: by amavisd-new at relay1.suse.de
X-Spam-Score: -2.499
X-Spam-Level: 
X-Spam-Status: No, score=-2.499 tagged_above=-20 required=5
	tests=[BAYES_00=-2.599, RDNS_DYNAMIC=0.1]
Received: from mx2.suse.de ([195.135.220.15]) by relay1.suse.de
	(relay1.suse.de [149.44.160.87]) (amavisd-new, port 10025) with ESMTP id
	GRIbn7q7jcRY for <slert-devel@suse.de>; Fri, 15 Feb 2008 18:52:58 +0100
	(CET)
Received: from novell1.haskins.net (75-130-111-13.dhcp.oxfr.ma.charter.com
	[75.130.111.13]) by mx2.suse.de (Postfix) with ESMTP id 450C5356F9 for
	<slert-devel@suse.de>; Fri, 15 Feb 2008 18:52:58 +0100 (CET)
Received: from novell1.haskins.net (localhost [127.0.0.1]) by
	novell1.haskins.net (Postfix) with ESMTP id 8E7E53FC1D5 for
	<slert-devel@suse.de>; Fri, 15 Feb 2008 12:26:05 -0500 (EST)
From: Gregory Haskins <ghaskins@novell.com>
To: slert-devel@suse.de
Date: Fri, 15 Feb 2008 12:26:05 -0500
Message-ID: <20080215172605.25573.15287.stgit@novell1.haskins.net>
In-Reply-To: <20080215172421.25573.85164.stgit@novell1.haskins.net>
References: <20080215172421.25573.85164.stgit@novell1.haskins.net>
User-Agent: StGIT/0.12.1
MIME-Version: 1.0
Content-Type: text/plain; charset="utf-8"
Subject: [slert-devel] [PATCH 06/10] adaptive mutexes
X-BeenThere: slert-devel@suse.de
X-Mailman-Version: 2.1.4
Precedence: list
List-Id: All things slert <slert-devel.suse.de>
List-Unsubscribe: <https://mailman.suse.de/mailman/listinfo/slert-devel>,
	<mailto:slert-devel-request@suse.de?subject=unsubscribe>
List-Archive: <https://mailman.suse.de/mailman/private/slert-devel>
List-Post: <mailto:slert-devel@suse.de>
List-Help: <mailto:slert-devel-request@suse.de?subject=help>
List-Subscribe: <https://mailman.suse.de/mailman/listinfo/slert-devel>,
	<mailto:slert-devel-request@suse.de?subject=subscribe>
Sender: slert-devel-bounces+sdietrich=novell.com@suse.de
Errors-To: slert-devel-bounces+sdietrich=novell.com@suse.de
X-Evolution-Source: imap://sdietrich@prv1-3.novell.com/
Content-Transfer-Encoding: 8bit

From: Peter W.Morreale <pmorreale@novell.com>

This patch adds the adaptive spin lock busywait to rtmutexes.  It adds
a new tunable: rtmutex_timeout, which is the companion to the
rtspin_timeout tunable.

Signed-off-by: Peter W. Morreale <pmorreale@novell.com>
---

 kernel/Kconfig.preempt    |   49 +++++++++++++++++++++++++++++++++++++++++----
 kernel/rtmutex.c          |   40 ++++++++++++++++++++-----------------
 kernel/rtmutex_adaptive.c |   13 +++++++++++-
 kernel/rtmutex_adaptive.h |   24 ++++++++++++++++++++--
 kernel/sysctl.c           |   10 +++++++++
 5 files changed, 111 insertions(+), 25 deletions(-)

diff --git a/kernel/Kconfig.preempt b/kernel/Kconfig.preempt
index 23d9113..654d56c 100644
--- a/kernel/Kconfig.preempt
+++ b/kernel/Kconfig.preempt
@@ -211,10 +211,51 @@ config RTSPINLOCK_DELAY
 	depends on PREEMPT_RT && ADAPTIVE_RTSPINLOCK
 	default "10000"
         help
-         This allows you to specify the delay between spin attempts for
-         rtspinlocks.  Larger values will allow the system to have higher
-         throughput at the expense of longer latencies for deadlock
-         avoidance.  The value is tunable at runtime via a sysctl.
+         This allows you to specify the maximum delay a task will use
+	 to wait for a rt spinlock before going to sleep.  Note that that
+	 although the delay is implemented as a preemptable loop, tasks
+	 of like priority cannot preempt each other and this setting can
+	 result in increased latencies.
+	 
+         The value is tunable at runtime via a sysctl.  A setting of 0
+	 (zero) disables the adaptive algorithm entirely.
+
+config ADAPTIVE_RTMUTEX
+        bool "Adaptive real-time mutexes"
+        default y
+        depends on ADAPTIVE_RTSPINLOCK
+        help
+         This option adds the rtspinlock spin/sleep algorithm to
+         rtmutexes.  In rtspinlocks, a significant gain in throughput
+         can be seen by allowing rtspinlocks to spin for a distinct
+         amount of time prior to going to sleep for deadlock avoidence.
+ 
+         Typically, mutexes are used when a critical section may need to
+         sleep due to a blocking operation.  In the event the critical 
+	 section does not need to sleep, an additional gain in throughput 
+	 can be seen by avoiding the extra overhead of sleeping.
+ 
+         This option alters the rtmutex code to use an adaptive
+         spin/sleep algorithm.  It will spin unless it determines it must
+         sleep to avoid deadlock.  This offers a best of both worlds
+         solution since we achieve both high-throughput and low-latency.
+ 
+         If unsure, say Y
+ 
+config RTMUTEX_DELAY
+        int "Default delay (in nanoseconds) for adaptive mutexes"
+        range 0 10000000
+        depends on ADAPTIVE_RTMUTEX
+        default "3000"
+        help
+         This allows you to specify the maximum delay a task will use
+	 to wait for a rt mutex before going to sleep.  Note that that
+	 although the delay is implemented as a preemptable loop, tasks
+	 of like priority cannot preempt each other and this setting can
+	 result in increased latencies.
+	 
+         The value is tunable at runtime via a sysctl.  A setting of 0
+	 (zero) disables the adaptive algorithm entirely.
 
 config SPINLOCK_BKL
 	bool "Old-Style Big Kernel Lock"
diff --git a/kernel/rtmutex.c b/kernel/rtmutex.c
index feb938f..64003fc 100644
--- a/kernel/rtmutex.c
+++ b/kernel/rtmutex.c
@@ -517,17 +517,16 @@ static void wakeup_next_waiter(struct rt_mutex *lock, int savestate)
 	 * Do the wakeup before the ownership change to give any spinning
 	 * waiter grantees a headstart over the other threads that will
 	 * trigger once owner changes.
+	 *
+	 * This may appear to be a race, but the barriers close the
+	 * window.
 	 */
-	if (!savestate)
-		wake_up_process(pendowner);
-	else {
-		smp_mb();
-		/*
-		 * This may appear to be a race, but the barriers close the
-		 * window.
-		 */
-		if ((pendowner->state != TASK_RUNNING)
-		    && (pendowner->state != TASK_RUNNING_MUTEX))
+	smp_mb();
+	if ((pendowner->state != TASK_RUNNING)
+	    && (pendowner->state != TASK_RUNNING_MUTEX)) {
+		if (!savestate)
+			wake_up_process(pendowner);
+		else
 			wake_up_process_mutex(pendowner);
 	}
 
@@ -760,7 +759,7 @@ rt_spin_lock_slowlock(struct rt_mutex *lock)
 		debug_rt_mutex_print_deadlock(&waiter);
 
 		/* adaptive_wait() returns 1 if we need to sleep */
-		if (adaptive_wait(lock, &waiter, &adaptive)) {
+		if (adaptive_wait(lock, 0, &waiter, &adaptive)) {
 			update_current(TASK_UNINTERRUPTIBLE, &saved_state);
 			if (waiter.task)
 				schedule_rt_mutex(lock);
@@ -971,6 +970,7 @@ rt_mutex_slowlock(struct rt_mutex *lock, int state,
 	int ret = 0, saved_lock_depth = -1;
 	struct rt_mutex_waiter waiter;
 	unsigned long flags;
+	DECLARE_ADAPTIVE_MUTEX_WAITER(adaptive);
 
 	debug_rt_mutex_init_waiter(&waiter);
 	waiter.task = NULL;
@@ -991,8 +991,6 @@ rt_mutex_slowlock(struct rt_mutex *lock, int state,
 	if (unlikely(current->lock_depth >= 0))
 		saved_lock_depth = rt_release_bkl(lock, flags);
 
-	set_current_state(state);
-
 	/* Setup the timer, when timeout != NULL */
 	if (unlikely(timeout))
 		hrtimer_start(&timeout->timer, timeout->timer.expires,
@@ -1045,6 +1043,9 @@ rt_mutex_slowlock(struct rt_mutex *lock, int state,
 			if (unlikely(ret))
 				break;
 		}
+
+		mutex_prepare_adaptive_wait(lock, &adaptive);
+
 		saved_flags = current->flags & PF_NOSCHED;
 		current->flags &= ~PF_NOSCHED;
 
@@ -1052,17 +1053,20 @@ rt_mutex_slowlock(struct rt_mutex *lock, int state,
 
 		debug_rt_mutex_print_deadlock(&waiter);
 
-		if (waiter.task)
-			schedule_rt_mutex(lock);
+		if (mutex_adaptive_wait(lock,
+					(state == TASK_INTERRUPTIBLE),
+					&waiter, &adaptive)) {
+			set_current_state(state);
+			if (waiter.task)
+				schedule_rt_mutex(lock);
+			set_current_state(TASK_RUNNING);
+		}
 
 		spin_lock_irq(&lock->wait_lock);
 
 		current->flags |= saved_flags;
-		set_current_state(state);
 	}
 
-	set_current_state(TASK_RUNNING);
-
 	if (unlikely(waiter.task))
 		remove_waiter(lock, &waiter, flags);
 
diff --git a/kernel/rtmutex_adaptive.c b/kernel/rtmutex_adaptive.c
index 4705db6..db779ec 100644
--- a/kernel/rtmutex_adaptive.c
+++ b/kernel/rtmutex_adaptive.c
@@ -34,6 +34,9 @@
 #include "rtmutex_adaptive.h"
 
 int rtspin_timeout __read_mostly = CONFIG_RTSPINLOCK_DELAY;
+#ifdef CONFIG_ADAPTIVE_RTMUTEX
+int rtmutex_timeout __read_mostly = CONFIG_RTMUTEX_DELAY;
+#endif
 
 /*
  * Adaptive-spinlocks will busywait when possible, and sleep only if
@@ -42,7 +45,8 @@ int rtspin_timeout __read_mostly = CONFIG_RTSPINLOCK_DELAY;
  * time before seeing that we need to break-out on the next iteration.
  */
 int
-adaptive_wait(struct rt_mutex *lock, struct rt_mutex_waiter *waiter,
+adaptive_wait(struct rt_mutex *lock, int interruptible,
+	      struct rt_mutex_waiter *waiter,
 	      struct adaptive_waiter *adaptive)
 {
 	int sleep = 0;
@@ -63,6 +67,13 @@ adaptive_wait(struct rt_mutex *lock, struct rt_mutex_waiter *waiter,
 		if (adaptive->owner != rt_mutex_owner(lock))
 			break;
 
+#ifdef CONFIG_ADAPTIVE_RTMUTEX
+		/*
+		 * Mutexes may need to check for signals...
+		 */
+		if (interruptible && signal_pending(current))
+			break;
+#endif
 		/*
 		 * If we got here, presumably the lock ownership is still
 		 * current.  We will use it to our advantage to be able to
diff --git a/kernel/rtmutex_adaptive.h b/kernel/rtmutex_adaptive.h
index ee6ec08..2d6ce8d 100644
--- a/kernel/rtmutex_adaptive.h
+++ b/kernel/rtmutex_adaptive.h
@@ -21,7 +21,8 @@ struct adaptive_waiter {
 /*
  * Returns 1 if we should sleep
  */
-int adaptive_wait(struct rt_mutex *lock, struct rt_mutex_waiter *waiter,
+int adaptive_wait(struct rt_mutex *lock, int interruptible,
+		  struct rt_mutex_waiter *waiter,
 		  struct adaptive_waiter *adative);
 
 static inline void
@@ -46,10 +47,29 @@ extern int rtspin_timeout;
 
 #define DECLARE_ADAPTIVE_WAITER(name) {}
 
-#define adaptive_wait(lock, waiter, busy) 1
+#define adaptive_wait(lock, intr, waiter, busy) 1
 #define prepare_adaptive_wait(lock, busy) {}
 
 #endif /* CONFIG_ADAPTIVE_RTSPINLOCK */
 
+#ifdef CONFIG_ADAPTIVE_RTMUTEX
+
+#define mutex_adaptive_wait         adaptive_wait
+#define mutex_prepare_adaptive_wait prepare_adaptive_wait
+
+extern int rtmutex_timeout;
+
+#define DECLARE_ADAPTIVE_MUTEX_WAITER(name) \
+     struct adaptive_waiter name = { .owner = NULL,               \
+                                     .timeout = rtmutex_timeout, }
+
+#else
+
+#define DECLARE_ADAPTIVE_MUTEX_WAITER(name) {}
+
+#define mutex_adaptive_wait(lock, intr, waiter, busy) 1
+#define mutex_prepare_adaptive_wait(lock, busy) {}
+
+#endif /* CONFIG_ADAPTIVE_RTMUTEX */
 
 #endif /* __KERNEL_RTMUTEX_ADAPTIVE_H */
diff --git a/kernel/sysctl.c b/kernel/sysctl.c
index 7f95167..f9c4321 100644
--- a/kernel/sysctl.c
+++ b/kernel/sysctl.c
@@ -975,6 +975,16 @@ static struct ctl_table kern_table[] = {
 		.mode		= 0644,
 		.proc_handler	= &proc_dointvec,
 	},
+#ifdef CONFIG_ADAPTIVE_RTMUTEX
+	{
+		.ctl_name       = CTL_UNNUMBERED,
+		.procname       = "rtmutex_timeout",
+		.data           = &rtmutex_timeout,
+		.maxlen         = sizeof(int),
+		.mode           = 0644,
+		.proc_handler   = &proc_dointvec,
+       },
+#endif
 #endif
 #ifdef CONFIG_PROC_FS
 	{

